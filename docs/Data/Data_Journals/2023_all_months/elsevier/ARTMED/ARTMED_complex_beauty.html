<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ARTMED_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="artmed---181">ARTMED - 181</h2>
<ul>
<li><details>
<summary>
(2023). Vulnerability of pangolin SARS-CoV-2 lineage assignment to
adversarial attack. <em>ARTMED</em>, <em>146</em>, 102722. (<a
href="https://doi.org/10.1016/j.artmed.2023.102722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pangolin is the most popular tool for SARS-CoV-2 lineage assignment. During COVID-19, healthcare professionals and policymakers required accurate and timely lineage assignment of SARS-CoV-2 genomes for pandemic response. Therefore, tools such as Pangolin use a machine learning model, pangoLEARN, for fast and accurate lineage assignment. Unfortunately, machine learning models are susceptible to adversarial attacks , in which minute changes to the inputs cause substantial changes in the model prediction. We present an attack that uses the pangoLEARN architecture to find perturbations that change the lineage assignment, often with only 2–3 base pair changes. The attacks we carried out show that pangolin is vulnerable to adversarial attack, with success rates between 0.98 and 1 for sequences from non-VoC lineages when pangoLEARN is used for lineage assignment. The attacks we carried out are almost never successful against VoC lineages because pangolin uses Usher and Scorpio – the non-machine-learning alternative methods for VoC lineage assignment. A malicious agent could use the proposed attack to fake or mask outbreaks or circulating lineages. Developers of software in the field of microbial genomics should be aware of the vulnerabilities of machine learning based models and mitigate such risks.},
  archive      = {J_ARTMED},
  author       = {Amiel Meiseles and Yair Motro and Lior Rokach and Jacob Moran-Gilad},
  doi          = {10.1016/j.artmed.2023.102722},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102722},
  shortjournal = {Artif. Intell. Med.},
  title        = {Vulnerability of pangolin SARS-CoV-2 lineage assignment to adversarial attack},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-task learning framework to predict the status of
central venous catheter based on radiographs. <em>ARTMED</em>,
<em>146</em>, 102721. (<a
href="https://doi.org/10.1016/j.artmed.2023.102721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospital patients can have catheters and lines inserted during the course of their admission to give medicines for the treatment of medical issues, especially the central venous catheter (CVC). However, malposition of CVC will lead to many complications, even death. Clinicians always detect the status of the catheter to avoid the above issues via X-ray images. To reduce the workload of clinicians and improve the efficiency of CVC status detection, a multi-task learning framework for catheter status classification based on the convolutional neural network (CNN) is proposed. The proposed framework contains three significant components which are modified HRNet, multi-task supervision including segmentation supervision and heatmap regression supervision as well as classification branch. The modified HRNet maintaining high-resolution features from the start to the end can ensure to generation of high-quality assisted information for classification. The multi-task supervision can assist in alleviating the presence of other line-like structures such as other tubes and anatomical structures shown in the X-ray image. Furthermore, during the inference, this module is also considered as an interpretation interface to show where the framework pays attention to. Eventually, the classification branch is proposed to predict the class of the status of the catheter. A public CVC dataset is utilized to evaluate the performance of the proposed method, which gains 0.823 AUC (Area under the ROC curve) and 82.6% accuracy in the test dataset . Compared with two state-of-the-art methods (ATCM method and EDMC method), the proposed method can perform best.},
  archive      = {J_ARTMED},
  author       = {Yuhan Wang and Hak Keung Lam and Yujia Xu and Faliang Yin and Kun Qian},
  doi          = {10.1016/j.artmed.2023.102721},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102721},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multi-task learning framework to predict the status of central venous catheter based on radiographs},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GCLR: A self-supervised representation learning pretext task
for glomerular filtration barrier segmentation in TEM images.
<em>ARTMED</em>, <em>146</em>, 102720. (<a
href="https://doi.org/10.1016/j.artmed.2023.102720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation of the three substructures of glomerular filtration barrier (GFB) in transmission electron microscopy (TEM) images holds immense potential for aiding pathologists in renal disease diagnosis. However, the labor-intensive nature of manual annotations limits the training data for a fully-supervised deep learning model. Addressing this, our study harnesses self-supervised representation learning (SSRL) to utilize vast unlabeled data and mitigate annotation scarcity. Our innovation, GCLR, is a hybrid pixel-level pretext task tailored for GFB segmentation, integrating two subtasks: global clustering (GC) and local restoration (LR). GC captures the overall GFB by learning global context representations, while LR refines three substructures by learning local detail representations. Experiments on 18,928 unlabeled glomerular TEM images for self-supervised pre-training and 311 labeled ones for fine-tuning demonstrate that our proposed GCLR obtains the state-of-the-art segmentation results for all three substructures of GFB with the Dice similarity coefficient of 86.56 ± 0.16%, 75.56 ± 0.36%, and 79.41 ± 0.16%, respectively, compared with other representative self-supervised pretext tasks. Our proposed GCLR also outperforms the fully-supervised pre-training methods based on the three large-scale public datasets – MitoEM, COCO, and ImageNet – with less training data and time.},
  archive      = {J_ARTMED},
  author       = {Guoyu Lin and Zhentai Zhang and Kaixing Long and Yiwen Zhang and Yanmeng Lu and Jian Geng and Zhitao Zhou and Qianjin Feng and Lijun Lu and Lei Cao},
  doi          = {10.1016/j.artmed.2023.102720},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102720},
  shortjournal = {Artif. Intell. Med.},
  title        = {GCLR: A self-supervised representation learning pretext task for glomerular filtration barrier segmentation in TEM images},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Text-to-movie authoring of anatomy lessons. <em>ARTMED</em>,
<em>146</em>, 102717. (<a
href="https://doi.org/10.1016/j.artmed.2023.102717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a need for a simple yet comprehensive tool to produce and edit pedagogical anatomy video courses, given the widespread usage of multimedia and 3D content in anatomy instruction. Anatomy teachers have minimal control over the present anatomical content generation pipeline. In this research, we provide an authoring tool for instructors that takes text written in the Anatomy Storyboard Language (ASL), a novel domain-specific language (DSL) and produces an animated video. ASL is a formal language that allows users to describe video shots as individual sentences while referencing anatomic structures from a large-scale ontology linked to 3D models. We describe an authoring tool that translates anatomy lessons written in ASL to finite state machines , which are then used to automatically generate 3D animation with the Unity 3D game engine. The proposed text-to-movie authoring tool was evaluated by four anatomy professors to create short lessons on the knee. Preliminary results demonstrate the ease of use and effectiveness of the tool for quickly drafting narrated video lessons in realistic medical anatomy teaching scenarios.},
  archive      = {J_ARTMED},
  author       = {Vaishnavi Ameya Murukutla and Elie Cattan and Benjamin Lecouteux and Remi Ronfard and Olivier Palombi},
  doi          = {10.1016/j.artmed.2023.102717},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102717},
  shortjournal = {Artif. Intell. Med.},
  title        = {Text-to-movie authoring of anatomy lessons},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VAP risk index: Early prediction and hospital phenotyping of
ventilator-associated pneumonia using machine learning. <em>ARTMED</em>,
<em>146</em>, 102715. (<a
href="https://doi.org/10.1016/j.artmed.2023.102715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ventilator-associated pneumonia (VAP) is a leading cause of morbidity and mortality in intensive care units (ICUs). Early identification of patients at risk of VAP enables early intervention, which in turn improves patient outcomes. We developed a predictive model for individualized risk assessment utilizing machine learning to identify patients at risk of developing VAP. The Philips eRI dataset, a multi-institution electronic medical record (EMR), was used for model development. For adult (≥18y) patients, we propose a set of criteria using indications of the start of a new antibiotic treatment temporally contiguous to a microbiological test to mark suspected infection events, of which those with a positive culture are labeled as presumed VAP if 1) the event occurs at least 48 h after intubation , and 2) there are no indications of community-acquired pneumonia (CAP) or other hospital-acquired infections (HAI) in the patient charts. The resulting VAP and no-VAP (control) cases were then used to build an ensemble of decision trees to predict the risk of VAP in the next 24 h using data on patients&#39; demographics, vitals, labs, and ventilator settings. The resulting model predicts the development of VAP 24 h in advance with an AUC of 76 % and AUPRC of 75 %. Additionally, we group hospitals that are similar in healthcare processes into distinct clusters and characterize VAP prediction for the identified hospital clusters. We show inter-hospital (teaching status and healthcare processes) and cohort-specific (age groups, gender, early vs late VAP, ICU mortality status) differences in VAP prediction and associated symptomologies. Our proposed VAP criteria use clinical actions to mark incidences of presumed VAP infection, which enables the development of models for early detection of these events. We curated a patient cohort using these criteria and used it to build a model for predicting impending VAP events prior to clinical suspicions. We present a clustering approach for tailoring the VAP prediction model for different hospital types based on their EMR data characteristics. The model provides an instantaneous risk score that allows early interventions and confirmatory diagnostic actions.},
  archive      = {J_ARTMED},
  author       = {Ali Samadani and Taiyao Wang and Kees van Zon and Leo Anthony Celi},
  doi          = {10.1016/j.artmed.2023.102715},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102715},
  shortjournal = {Artif. Intell. Med.},
  title        = {VAP risk index: Early prediction and hospital phenotyping of ventilator-associated pneumonia using machine learning},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Radiology report generation with medical knowledge and
multilevel image-report alignment: A new method and its verification.
<em>ARTMED</em>, <em>146</em>, 102714. (<a
href="https://doi.org/10.1016/j.artmed.2023.102714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical report generation is an integral part of computer-aided diagnosis aimed at reducing the workload of radiologists and physicians and alerting them of misdiagnosis risks. In general, medical report generation is an image captioning task. Since medical reports have long sequences with data bias, the existing medical report generation models lack medical knowledge and ignore the interaction alignment between the two modalities of reports and images. The current paper attempts to mitigate these deficiencies by proposing an approach based on knowledge enhancement with multilevel alignment (MKMIA). To this end, it includes a knowledge enhancement (MKE) module and a multilevel alignment module (MIRA). Specifically, the MKE deals with general medical knowledge (MK) and historical knowledge (HK) obtained via data training . The general knowledge is embedded in the form of a dictionary with characteristic organs (referred to as Key) and organ aliases, disease symptoms, etc. (referred to as Value). It provides explicit exception candidates to mitigate data bias. Historical knowledge ensures the comparison of similar cases to provide a better diagnosis. MIRA furnishes coarse-to-fine multilevel alignment, reducing the gap between image and text features, improving the knowledge enhancement module’s performance, and facilitating the generation of lengthy reports. Experimental results on two radiology report datasets (i.e., IU X-ray and MIMIC-CXR) proved the effectiveness of the proposed approach, achieving state-of-the-art performance.},
  archive      = {J_ARTMED},
  author       = {Guosheng Zhao and Zijian Zhao and Wuxian Gong and Feng Li},
  doi          = {10.1016/j.artmed.2023.102714},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102714},
  shortjournal = {Artif. Intell. Med.},
  title        = {Radiology report generation with medical knowledge and multilevel image-report alignment: A new method and its verification},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of multi-armed bandits to dose-finding clinical
designs. <em>ARTMED</em>, <em>146</em>, 102713. (<a
href="https://doi.org/10.1016/j.artmed.2023.102713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-armed bandits are very simple and powerful methods to determine actions to maximize a reward in a limited number of trials. An early phase in dose-finding clinical trials needs to identify the maximum tolerated dose among multiple doses by repeating the dose-assignment. We consider applying the superior selection performance of multi-armed bandits to dose-finding clinical designs. Among the multi-armed bandits, we first consider the use of Thompson sampling which determines actions based on random samples from a posterior distribution. In the small sample size , as shown in dose-finding trials, because the tails of posterior distribution are heavier and random samples are too much variability, we also consider an application of regularized Thompson sampling and greedy algorithm . The greedy algorithm determines a dose based on a posterior mean. In addition, we also propose a method to determine a dose based on a posterior mode. We evaluate the performance of our proposed designs for nine scenarios via simulation studies.},
  archive      = {J_ARTMED},
  author       = {Masahiro Kojima},
  doi          = {10.1016/j.artmed.2023.102713},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102713},
  shortjournal = {Artif. Intell. Med.},
  title        = {Application of multi-armed bandits to dose-finding clinical designs},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic and comprehensive review and investigation of
intelligent IoT-based healthcare systems in rural societies and
governments. <em>ARTMED</em>, <em>146</em>, 102702. (<a
href="https://doi.org/10.1016/j.artmed.2023.102702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare needs in rural areas differ significantly from those in urban areas. Addressing the healthcare challenges in rural communities is of paramount importance , as these regions often lack access to adequate healthcare facilities . Moreover, technological advancements, particularly in the realm of the Internet of Things (IoT), have brought about significant changes in the healthcare industry . IoT involves connecting real-world objects to digital devices, opening up various possibilities for improving healthcare delivery . One promising application of IoT is its use in monitoring the spread of diseases in remote villages through interconnected sensors and devices. Surprisingly, there has been a noticeable absence of comprehensive research on this topic. Therefore, the primary objective of this study is to conduct a thorough and systematic review of intelligent IoT-based healthcare systems in rural communities and their governance. The analysis covers research papers published until December 2022 to provide valuable insights for future researchers. The selected articles have been categorized into three main groups: monitoring, intelligent services, and body sensor networks . The findings indicate that IoT research has garnered significant attention within the healthcare community. Furthermore, the results illustrate the potential benefits of IoT for governments, especially in rural areas, in improving public health and strengthening economic ties. It is worth noting that establishing a robust security infrastructure is essential for implementing IoT effectively, given its innovative operational principles . In summary, this review enhances scholars&#39; understanding of the current state of IoT research in rural healthcare settings while highlighting areas that warrant further investigation. Additionally, it keeps healthcare professionals informed about the latest advancements and applications of IoT in rural healthcare.},
  archive      = {J_ARTMED},
  author       = {Yisu Ge and Guodao Zhang and Maytham N. Meqdad and Shuzheng Chen},
  doi          = {10.1016/j.artmed.2023.102702},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102702},
  shortjournal = {Artif. Intell. Med.},
  title        = {A systematic and comprehensive review and investigation of intelligent IoT-based healthcare systems in rural societies and governments},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Natural language processing with machine learning methods to
analyze unstructured patient-reported outcomes derived from electronic
health records: A systematic review. <em>ARTMED</em>, <em>146</em>,
102701. (<a href="https://doi.org/10.1016/j.artmed.2023.102701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language processing (NLP) combined with machine learning (ML) techniques are increasingly used to process unstructured/free-text patient-reported outcome (PRO) data available in electronic health records (EHRs). This systematic review summarizes the literature reporting NLP/ML systems/toolkits for analyzing PROs in clinical narratives of EHRs and discusses the future directions for the application of this modality in clinical care. We searched PubMed, Scopus, and Web of Science for studies written in English between 1/1/2000 and 12/31/2020. Seventy-nine studies meeting the eligibility criteria were included. We abstracted and summarized information related to the study purpose, patient population, type/source/amount of unstructured PRO data, linguistic features, and NLP systems/toolkits for processing unstructured PROs in EHRs. Most of the studies used NLP/ML techniques to extract PROs from clinical narratives ( n = 74) and mapped the extracted PROs into specific PRO domains for phenotyping or clustering purposes ( n = 26). Some studies used NLP/ML to process PROs for predicting disease progression or onset of adverse events ( n = 22) or developing/validating NLP/ML pipelines for analyzing unstructured PROs ( n = 19). Studies used different linguistic features, including lexical, syntactic , semantic, and contextual features, to process unstructured PROs. Among the 25 NLP systems/toolkits we identified, 15 used rule-based NLP, 6 used hybrid NLP , and 4 used non-neural ML algorithms embedded in NLP. This study supports the potential utility of different NLP/ML techniques in processing unstructured PROs available in EHRs for clinical care. Though using annotation rules for NLP/ML to analyze unstructured PROs is dominant, deploying novel neural ML-based methods is warranted.},
  archive      = {J_ARTMED},
  author       = {Jin-ah Sim and Xiaolei Huang and Madeline R. Horan and Christopher M. Stewart and Leslie L. Robison and Melissa M. Hudson and Justin N. Baker and I-Chan Huang},
  doi          = {10.1016/j.artmed.2023.102701},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102701},
  shortjournal = {Artif. Intell. Med.},
  title        = {Natural language processing with machine learning methods to analyze unstructured patient-reported outcomes derived from electronic health records: A systematic review},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SDA-net: Self-distillation driven deformable attentive
aggregation network for thyroid nodule identification in ultrasound
images. <em>ARTMED</em>, <em>146</em>, 102699. (<a
href="https://doi.org/10.1016/j.artmed.2023.102699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection and accurate identification of thyroid nodules are the major challenges in controlling and treating thyroid cancer that can be difficult even for expert physicians. Currently, many computer-aided diagnosis (CAD) systems have been developed to assist this clinical process. However, most of these systems are unable to well capture geometrically diverse thyroid nodule representations from ultrasound images with subtle and various characteristic differences, resulting in suboptimal diagnosis and lack of clinical interpretability , which may affect their credibility in the clinic. In this context, a novel end-to-end network equipped with a deformable attention network and a distillation-driven interaction aggregation module (DIAM) is developed for thyroid nodule identification. The deformable attention network learns to identify discriminative features of nodules under the guidance of the deformable attention module (DAM) and an online class activation mapping (CAM) mechanism and suggests the location of diagnostic features to provide interpretable predictions. DIAM is designed to take advantage of the complementarities of adjacent layers , thus enhancing the representation capabilities of aggregated features; driven by an efficient self-distillation mechanism, the identification process is complemented with more multi-scale semantic information to calibrate the diagnosis results. Experimental results on a large dataset with varying nodule appearances show that the proposed network can achieve competitive performance in nodule diagnosis and provide interpretability suitable for clinical needs.},
  archive      = {J_ARTMED},
  author       = {Minglei Li and Hang Zhou and Xiang Li and Pengfei Yan and Yuchen Jiang and Hao Luo and Xianli Zhou and Shen Yin},
  doi          = {10.1016/j.artmed.2023.102699},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102699},
  shortjournal = {Artif. Intell. Med.},
  title        = {SDA-net: Self-distillation driven deformable attentive aggregation network for thyroid nodule identification in ultrasound images},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A human-interpretable machine learning pipeline based on
ultrasound to support leiomyosarcoma diagnosis. <em>ARTMED</em>,
<em>146</em>, 102697. (<a
href="https://doi.org/10.1016/j.artmed.2023.102697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preoperative evaluation of myometrial tumors is essential to avoid delayed treatment and to establish the appropriate surgical approach. Specifically, the differential diagnosis of leiomyosarcoma (LMS) is particularly challenging due to the overlapping of clinical, laboratory and ultrasound features between fibroids and LMS. In this work, we present a human-interpretable machine learning (ML) pipeline to support the preoperative differential diagnosis of LMS from leiomyomas , based on both clinical data and gynecological ultrasound assessment of 68 patients (8 with LMS diagnosis). The pipeline provides the following novel contributions: (i) end-users have been involved both in the definition of the ML tasks and in the evaluation of the overall approach; (ii) clinical specialists get a full understanding of both the decision-making mechanisms of the ML algorithms and the impact of the features on each automatic decision. Moreover, the proposed pipeline addresses some of the problems concerning both the imbalance of the two classes by analyzing and selecting the best combination of the synthetic oversampling strategy of the minority class and the classification algorithm among different choices, and the explainability of the features at global and local levels. The results show very high performance of the best strategy (AUC = 0.99, F1 = 0.87) and the strong and stable impact of two ultrasound-based features (i.e., tumor borders and consistency of the lesions). Furthermore, the SHAP algorithm was exploited to quantify the impact of the features at the local level and a specific module was developed to provide a template-based natural language (NL) translation of the explanations for enhancing their interpretability and fostering the use of ML in the clinical setting.},
  archive      = {J_ARTMED},
  author       = {Angela Lombardi and Francesca Arezzo and Eugenio Di Sciascio and Carmelo Ardito and Michele Mongelli and Nicola Di Lillo and Fabiana Divina Fascilla and Erica Silvestris and Anila Kardhashi and Carmela Putino and Ambrogio Cazzolla and Vera Loizzi and Gerardo Cazzato and Gennaro Cormio and Tommaso Di Noia},
  doi          = {10.1016/j.artmed.2023.102697},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102697},
  shortjournal = {Artif. Intell. Med.},
  title        = {A human-interpretable machine learning pipeline based on ultrasound to support leiomyosarcoma diagnosis},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GRU-d-weibull: A novel real-time individualized endpoint
prediction. <em>ARTMED</em>, <em>146</em>, 102696. (<a
href="https://doi.org/10.1016/j.artmed.2023.102696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of healthcare digital transformation, using electronic health record (EHR) data to generate various endpoint estimates for active monitoring is highly desirable in chronic disease management. However, traditional predictive modeling strategies leveraging well-curated data sets can have limited real-world implementation potential due to various data quality issues in EHR data. We propose a novel predictive modeling approach, GRU-D-Weibull, which models Weibull distribution leveraging gated recurrent units with decay (GRU-D), for real-time individualized endpoint prediction and population level risk management using EHR data. We systematically evaluated the performance and showcased the real-world implementability of the proposed approach through individual level endpoint prediction using a cohort of patients with chronic kidney disease stage 4 (CKD4). A total of 536 features including ICD/CPT codes, medications, lab tests , vital measurements, and demographics were retrieved for 6879 CKD4 patients. The performance metrics including C-index, L1-loss, Parkes&#39; error, and predicted survival probability at time of event were compared between GRU-D-Weibull and other alternative approaches including accelerated failure time model (AFT), XGBoost based AFT (XGB(AFT)), random survival forest (RSF), and Nnet-survival. Both in-process and post-process calibrations were experimented on GRU-D-Weibull generated survival probabilities. GRU-D-Weibull demonstrated C-index of ~0.7 at index date, which increased to ~0.77 at 4.3 years of follow-up, comparable to that of RSF. GRU-D-Weibull achieved absolute L1-loss of ~1.1 years (sd ≈ ≈ 0.95) at CKD4 index date, and a minimum of ~0.45 year (sd ≈ ≈ 0.3) at 4 years of follow-up, comparing to second-ranked RSF of ~1.4 years (sd ≈ ≈ 1.1) at index date and ~0.64 years (sd ≈ ≈ 0.26) at 4 years. Both significantly outperform competing approaches. GRU-D-Weibull constrained predicted survival probability at time of event to smaller and more fixed range than competing models throughout follow-up. Significant correlations were observed between prediction error and missing proportions of all major categories of input features at index date (Corr ~0.1 to ~0.3), which faded away within 1 year after index date as more data became available. Through post training recalibration , we achieved a close alignment between the predicted and observed survival probabilities across multiple prediction horizons at different time points during follow-up. GRU-D-Weibull shows advantages over competing methods in handling missingness commonly encountered in EHR data and providing both probability and point estimates for diverse prediction horizons during follow-up. The experiment highlights the potential of GRU-D-Weibull as a suitable candidate for individualized endpoint risk management, utilizing real-time clinical data to generate various endpoint estimates for monitoring. Additional research is warranted to evaluate the influence of different data quality aspects on prediction performance. Furthermore, collaboration with clinicians is essential to explore the integration of this approach into clinical workflows and evaluate its effects on decision-making processes and patient outcomes.},
  archive      = {J_ARTMED},
  author       = {Xiaoyang Ruan and Liwei Wang and Charat Thongprayoon and Wisit Cheungpasitporn and Hongfang Liu},
  doi          = {10.1016/j.artmed.2023.102696},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102696},
  shortjournal = {Artif. Intell. Med.},
  title        = {GRU-D-weibull: A novel real-time individualized endpoint prediction},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal fine-tuning of clinical language models for
predicting COVID-19 outcomes. <em>ARTMED</em>, <em>146</em>, 102695. (<a
href="https://doi.org/10.1016/j.artmed.2023.102695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical prediction models tend only to incorporate structured healthcare data, ignoring information recorded in other data modalities, including free-text clinical notes. Here, we demonstrate how multimodal models that effectively leverage both structured and unstructured data can be developed for predicting COVID-19 outcomes. The models are trained end-to-end using a technique we refer to as multimodal fine-tuning, whereby a pre-trained language model is updated based on both structured and unstructured data. The multimodal models are trained and evaluated using a multicenter cohort of COVID-19 patients encompassing all encounters at the emergency department of six hospitals. Experimental results show that multimodal models, leveraging the notion of multimodal fine-tuning and trained to predict (i) 30-day mortality, (ii) safe discharge and (iii) readmission, outperform unimodal models trained using only structured or unstructured healthcare data on all three outcomes. Sensitivity analyses are performed to better understand how well the multimodal models perform on different patient groups, while an ablation study is conducted to investigate the impact of different types of clinical notes on model performance. We argue that multimodal models that make effective use of routinely collected healthcare data to predict COVID-19 outcomes may facilitate patient management and contribute to the effective use of limited healthcare resources.},
  archive      = {J_ARTMED},
  author       = {Aron Henriksson and Yash Pawar and Pontus Hedberg and Pontus Nauclér},
  doi          = {10.1016/j.artmed.2023.102695},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102695},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multimodal fine-tuning of clinical language models for predicting COVID-19 outcomes},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Source-free domain adaptive segmentation with class-balanced
complementary self-training. <em>ARTMED</em>, <em>146</em>, 102694. (<a
href="https://doi.org/10.1016/j.artmed.2023.102694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) plays a crucial role in transferring knowledge gained from a labeled source domain to effectively apply it in an unlabeled and diverse target domain. While UDA commonly involves training on data from both domains, accessing labeled data from the source domain is frequently constrained, citing concerns related to patient data privacy or intellectual property. The source-free UDA (SFUDA) can be promising to sidestep this difficulty. However, without the source domain supervision, the SFUDA methods can easily fall into the dilemma of “winner takes all”, in which the majority category can dominate the deep segmentor, and the minority categories are largely ignored. In addition, the over-confident pseudo-label noise in self-training-based UDA is a long-lasting problem. To sidestep these difficulties, we propose a novel class-balanced complementary self-training (CBCOST) framework for SFUDA segmentation. Specifically, we jointly optimize the pseudo-label-based self-training with two mutually reinforced components. The first class-wise balanced pseudo-label training (CBT) explicitly exploits the fine-grained class-wise confidence to select the class-wise balanced pseudo-labeled pixels with the adaptive within-class thresholds. Second, to alleviate the pseudo-labeled noise, we propose a complementary self-training (COST) to exclude the classes that do not belong to, with a heuristic complementary label selection scheme. We evaluated our CBCOST framework on both 2D and 3D cross-modality cardiac anatomical segmentation tasks and brain tumor segmentation tasks. Our experimental results showed that our CBCOST performs better than existing SFUDA methods and yields similar performance, compared with UDA methods with the source data.},
  archive      = {J_ARTMED},
  author       = {Yongsong Huang and Wanqing Xie and Mingzhen Li and Ethan Xiao and Jane You and Xiaofeng Liu},
  doi          = {10.1016/j.artmed.2023.102694},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102694},
  shortjournal = {Artif. Intell. Med.},
  title        = {Source-free domain adaptive segmentation with class-balanced complementary self-training},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence in physical rehabilitation: A
systematic review. <em>ARTMED</em>, <em>146</em>, 102693. (<a
href="https://doi.org/10.1016/j.artmed.2023.102693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical disabilities become more common with advancing age. Rehabilitation restores function, maintaining independence for longer. However, the poor availability and accessibility of rehabilitation limits its clinical impact. Artificial Intelligence (AI) guided interventions have improved many domains of healthcare, but whether rehabilitation can benefit from AI remains unclear. We conducted a systematic review of AI-supported physical rehabilitation technology tested in the clinical setting to understand: 1) availability of AI-supported physical rehabilitation technology; 2) its clinical effect; 3) and the barriers and facilitators to implementation. We searched in MEDLINE, EMBASE, CINAHL, Science Citation Index (Web of Science), CIRRIE (now NARIC), and OpenGrey. We identified 9054 articles and included 28 projects. AI solutions spanned five categories: App-based systems, robotic devices that replace function, robotic devices that restore function, gaming systems and wearables. We identified five randomised controlled trials (RCTs), which evaluated outcomes relating to physical function, activity, pain, and health-related quality of life. The clinical effects were inconsistent. Implementation barriers included technology literacy, reliability, and user fatigue. Enablers included greater access to rehabilitation programmes, remote monitoring of progress, reduction in manpower requirements and lower cost. Application of AI in physical rehabilitation is a growing field, but clinical effects have yet to be studied rigorously. Developers must strive to conduct robust clinical evaluations in the real-world setting and appraise post implementation experiences.},
  archive      = {J_ARTMED},
  author       = {Jennifer Sumner and Hui Wen Lim and Lin Siew Chong and Anjali Bundele and Amartya Mukhopadhyay and Geetha Kayambu},
  doi          = {10.1016/j.artmed.2023.102693},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102693},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence in physical rehabilitation: A systematic review},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine intelligence and medical cyber-physical system
architectures for smart healthcare: Taxonomy, challenges, opportunities,
and possible solutions. <em>ARTMED</em>, <em>146</em>, 102692. (<a
href="https://doi.org/10.1016/j.artmed.2023.102692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospitals use medical cyber-physical systems (MCPS) more often to give patients quality continuous care. MCPS isa life-critical, context-aware, networked system of medical equipment . It has been challenging to achieve high assurance in system software, interoperability, context-aware intelligence, autonomy, security and privacy, and device certifiability due to the necessity to create complicated MCPS that are safe and efficient. The MCPS system is shown in the paper as a newly developed application case study of artificial intelligence in healthcare. Applications for various CPS-based healthcare systems are discussed, such as telehealthcare systems for managing chronic diseases (cardiovascular diseases, epilepsy, hearing loss, and respiratory diseases), supporting medication intake management, and tele-homecare systems. The goal of this study is to provide a thorough overview of the essential components of the MCPS from several angles, including design, methodology, and important enabling technologies, including sensor networks, the Internet of Things (IoT), cloud computing , and multi-agent systems. Additionally, some significant applications are investigated, such as smart cities, which are regarded as one of the key applications that will offer new services for industrial systems, transportation networks, energy distribution, monitoring of environmental changes, business and commerce applications , emergency response, and other social and recreational activities.The four levels of an MCPS&#39;s general architecture—data collecting, data aggregation, cloud processing, and action—are shown in this study. Different encryption techniques must be employed to ensure data privacy inside each layer due to the variations in hardware and communication capabilities of each layer. We compare established and new encryption techniques based on how well they support safe data exchange, secure computing, and secure storage. Our thorough experimental study of each method reveals that, although enabling innovative new features like secure sharing and safe computing, developing encryption approaches significantly increases computational and storage overhead . To increase the usability of newly developed encryption schemes in an MCPS and to provide a comprehensive list of tools and databases to assist other researchers, we provide a list of opportunities and challenges for incorporating machine intelligence-based MCPS in healthcare applications in our paper&#39;s conclusion.},
  archive      = {J_ARTMED},
  author       = {Tawseef Ayoub Shaikh and Tabasum Rasool and Prabal Verma},
  doi          = {10.1016/j.artmed.2023.102692},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102692},
  shortjournal = {Artif. Intell. Med.},
  title        = {Machine intelligence and medical cyber-physical system architectures for smart healthcare: Taxonomy, challenges, opportunities, and possible solutions},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive review on federated learning based models
for healthcare applications. <em>ARTMED</em>, <em>146</em>, 102691. (<a
href="https://doi.org/10.1016/j.artmed.2023.102691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A disease is an abnormal condition that negatively impacts the functioning of the human body. Pathology determines the causes behind the disease and identifies its development mechanism and functional consequences. Each disease has different identification methods, including X-ray scans for pneumonia, covid-19, and lung cancer, whereas biopsy and CT-scan can identify the presence of skin cancer and Alzheimer&#39;s disease, respectively. Early disease detection leads to effective treatment and avoids abiding complications. Deep learning has provided a vast number of applications in medical sectors resulting in accurate and reliable early disease predictions. These models are utilized in the healthcare industry to provide supplementary assistance to doctors in identifying the presence of diseases. Majorly, these models are trained through secondary data sources since healthcare institutions refrain from sharing patients&#39; private data to ensure confidentiality , which limits the effectiveness of deep learning models due to the requirement of extensive datasets for training to achieve optimal results. Federated learning deals with the data in such a way that it doesn&#39;t exploit the privacy of a patient&#39;s data. In this work, a wide variety of disease detection models trained through federated learning have been rigorously reviewed. This meta-analysis provides an in-depth review of the federated learning architectures, federated learning types, hyperparameters, dataset utilization details, aggregation techniques, performance measures , and augmentation methods applied in the existing models during the development phase. The review also highlights various open challenges associated with the disease detection models trained through federated learning for future research.},
  archive      = {J_ARTMED},
  author       = {Shagun Sharma and Kalpna Guleria},
  doi          = {10.1016/j.artmed.2023.102691},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102691},
  shortjournal = {Artif. Intell. Med.},
  title        = {A comprehensive review on federated learning based models for healthcare applications},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating age and gender from electrocardiogram signals: A
comprehensive review of the past decade. <em>ARTMED</em>, <em>146</em>,
102690. (<a href="https://doi.org/10.1016/j.artmed.2023.102690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twelve lead electrocardiogram signals capture unique fingerprints about the body’s biological processes and electrical activity of heart muscles. Machine learning and deep learning-based models can learn the embedded patterns in the electrocardiogram to estimate complex metrics such as age and gender that depend on multiple aspects of human physiology. ECG estimated age with respect to the chronological age reflects the overall well-being of the cardiovascular system, with significant positive deviations indicating an aged cardiovascular system and a higher likelihood of cardiovascular mortality. Several conventional, machine learning, and deep learning-based methods have been proposed to estimate age from electronic health records, health surveys, and ECG data. This manuscript comprehensively reviews the methodologies proposed for ECG-based age and gender estimation over the last decade. Specifically, the review highlights that elevated ECG age is associated with atherosclerotic cardiovascular disease, abnormal peripheral endothelial dysfunction, and high mortality, among many other cardiovascular disorders. Furthermore, the survey presents overarching observations and insights across methods for age and gender estimation. This paper also presents several essential methodological improvements and clinical applications of ECG-estimated age and gender to encourage further improvements of the state-of-the-art methodologies.},
  archive      = {J_ARTMED},
  author       = {Mohammed Yusuf Ansari and Marwa Qaraqe and Fatme Charafeddine and Erchin Serpedin and Raffaella Righetti and Khalid Qaraqe},
  doi          = {10.1016/j.artmed.2023.102690},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102690},
  shortjournal = {Artif. Intell. Med.},
  title        = {Estimating age and gender from electrocardiogram signals: A comprehensive review of the past decade},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A monitoring framework for health care processes using
generalized additive models and auto-encoders. <em>ARTMED</em>,
<em>146</em>, 102689. (<a
href="https://doi.org/10.1016/j.artmed.2023.102689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a considerable focus on developing effective methods for monitoring health care processes. Utilizing Statistical Process Monitoring (SPM) approaches, particularly risk-adjusted control charts, has emerged as a highly promising approach for achieving robust frameworks for this aim. Considering risk-adjusted control charts, longitudinal health care process data is typically monitored by establishing a regression relationship between various risk factors (explanatory variables) and patient outcomes (response variables). While the majority of prior research has primarily employed logistic models in risk-adjusted control charts, there are more intricate health care processes that necessitate the incorporation of both parametric and nonparametric risk factors. In such scenarios, the Generalized Additive Model (GAM) proves to be a suitable choice, albeit it often introduces higher computational complexity and associated challenges. Surprisingly, there are limited instances where researchers have proposed advancements in this direction. The primary objective of this paper is to introduce an SPM framework for monitoring health care processes using a GAM over time, coupled with a novel risk-adjusted control chart driven by machine learning techniques . This control chart is implemented on a data set encompassing two stroke types: ischemic and hemorrhagic. The key focus of this study is to monitor the stability of the relationship between stroke types and predefined explanatory variables over time within this data set. Extensive simulation results, based on real data from patients with acute stroke, demonstrate the remarkable flexibility of the proposed method in terms of its detection capabilities compared to conventional approaches.},
  archive      = {J_ARTMED},
  author       = {Ali Yeganeh and Arne Johannssen and Nataliya Chukhrova and Mahdiyeh Erfanian and Mahmoud Reza Azarpazhooh and Negar Morovatdar},
  doi          = {10.1016/j.artmed.2023.102689},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102689},
  shortjournal = {Artif. Intell. Med.},
  title        = {A monitoring framework for health care processes using generalized additive models and auto-encoders},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Custom machine learning algorithm for large-scale disease
screening - taking heart disease data as an example. <em>ARTMED</em>,
<em>146</em>, 102688. (<a
href="https://doi.org/10.1016/j.artmed.2023.102688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease accounts for millions of deaths worldwide annually, representing a major public health concern. Large-scale heart disease screening can yield significant benefits both in terms of lives saved and economic costs. In this study, we introduce a novel algorithm that trains a patient-specific machine learning model, aligning with the real-world demands of extensive disease screening. Customization is achieved by concentrating on three key aspects: data processing , neural network architecture , and loss function formulation. Our approach integrates individual patient data to bolster model accuracy, ensuring dependable disease detection. We assessed our models using two prominent heart disease datasets: the Cleveland dataset and the UC Irvine (UCI) combination dataset. Our models showcased notable results, achieving accuracy and recall rates beyond 95 % for the Cleveland dataset and surpassing 97 % accuracy for the UCI dataset. Moreover, in terms of medical ethics and operability, our approach outperformed traditional, general-purpose machine learning algorithms . Our algorithm provides a powerful tool for large-scale disease screening and has the potential to save lives and reduce the economic burden of heart disease.},
  archive      = {J_ARTMED},
  author       = {Leran Chen and Ping Ji and Yongsheng Ma and Yiming Rong and Jingzheng Ren},
  doi          = {10.1016/j.artmed.2023.102688},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102688},
  shortjournal = {Artif. Intell. Med.},
  title        = {Custom machine learning algorithm for large-scale disease screening - taking heart disease data as an example},
  volume       = {146},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncovering hidden therapeutic indications through drug
repurposing with graph neural networks and heterogeneous data.
<em>ARTMED</em>, <em>145</em>, 102687. (<a
href="https://doi.org/10.1016/j.artmed.2023.102687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug repurposing has gained the attention of many in the recent years. The practice of repurposing existing drugs for new therapeutic uses helps to simplify the drug discovery process, which in turn reduces the costs and risks that are associated with de novo development. Representing biomedical data in the form of a graph is a simple and effective method to depict the underlying structure of the information. Using deep neural networks in combination with this data represents a promising approach to address drug repurposing. This paper presents BEHOR a more comprehensive version of the REDIRECTION model, which was previously presented. Both versions utilize the DISNET biomedical graph as the primary source of information, providing the model with extensive and intricate data to tackle the drug repurposing challenge. This new version&#39;s results for the reported metrics in the RepoDB test are 0.9604 for AUROC and 0.9518 for AUPRC. Additionally, a discussion is provided regarding some of the novel predictions to demonstrate the reliability of the model. The authors believe that BEHOR holds promise for generating drug repurposing hypotheses and could greatly benefit the field.},
  archive      = {J_ARTMED},
  author       = {Adrián Ayuso-Muñoz and Lucía Prieto-Santamaría and Esther Ugarte-Carro and Emilio Serrano and Alejandro Rodríguez-González},
  doi          = {10.1016/j.artmed.2023.102687},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102687},
  shortjournal = {Artif. Intell. Med.},
  title        = {Uncovering hidden therapeutic indications through drug repurposing with graph neural networks and heterogeneous data},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Annotation protocol and crowdsourcing multiple instance
learning classification of skin histological images: The CR-AI4SkIN
dataset. <em>ARTMED</em>, <em>145</em>, 102686. (<a
href="https://doi.org/10.1016/j.artmed.2023.102686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Pathology (DP) has experienced a significant growth in recent years and has become an essential tool for diagnosing and prognosis of tumors. The availability of Whole Slide Images (WSIs) and the implementation of Deep Learning (DL) algorithms have paved the way for the appearance of Artificial Intelligence (AI) systems that support the diagnosis process. These systems require extensive and varied data for their training to be successful. However, creating labeled datasets in histopathology is laborious and time-consuming. We have developed a crowdsourcing-multiple instance labeling/learning protocol that is applied to the creation and use of the CR-AI4SkIN dataset. 2 CR-AI4SkIN contains 271 WSIs of 7 Cutaneous Spindle Cell (CSC) neoplasms with expert and non-expert labels at region and WSI levels. It is the first dataset of these types of neoplasms made available. The regions selected by the experts are used to learn an automatic extractor of Regions of Interest (ROIs) from WSIs. To produce the embedding of each WSI, the representations of patches within the ROIs are obtained using a contrastive learning method, and then combined. Finally, they are fed to a Gaussian process-based crowdsourcing classifier, which utilizes the noisy non-expert WSI labels. We validate our crowdsourcing-multiple instance learning method in the CR-AI4SkIN dataset, addressing a binary classification problem (malign vs. benign). The proposed method obtains an F1 score of 0.7911 on the test set, outperforming three widely used aggregation methods for crowdsourcing tasks. Furthermore, our crowdsourcing method also outperforms the supervised model with expert labels on the test set (F1-score = 0.6035). The promising results support the proposed crowdsourcing multiple instance learning annotation protocol. It also validates the automatic extraction of interest regions and the use of contrastive embedding and Gaussian process classification to perform crowdsourcing classification tasks .},
  archive      = {J_ARTMED},
  author       = {Rocío del Amor and Jose Pérez-Cano and Miguel López-Pérez and Liria Terradez and Jose Aneiros-Fernandez and Sandra Morales and Javier Mateos and Rafael Molina and Valery Naranjo},
  doi          = {10.1016/j.artmed.2023.102686},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102686},
  shortjournal = {Artif. Intell. Med.},
  title        = {Annotation protocol and crowdsourcing multiple instance learning classification of skin histological images: The CR-AI4SkIN dataset},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced SpO2 estimation using explainable machine learning
and neck photoplethysmography. <em>ARTMED</em>, <em>145</em>, 102685.
(<a href="https://doi.org/10.1016/j.artmed.2023.102685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reflectance-based photoplethysmogram (PPG) sensors provide flexible options of measuring sites for blood oxygen saturation (SpO 2 ) measurement. But they are mostly limited by accuracy, especially when applied to different subjects, due to the diverse human characteristics (skin colors, hair density, etc. ) and usage conditions of different sensor settings. This study addresses the estimation of SpO 2 at non-standard measuring sites employing reflectance-based sensors. It proposes an automated construction of subject inclusion-exclusion criteria for SpO 2 measuring devices , using a combination of unsupervised clustering, supervised regression, and model explanations. This is perhaps among the first adaptation of SHAP to explain the clusters gleaned from unsupervised learning methods. As a wellness application case study , we developed a pillow-based wearable device to collect reflectance PPGs from both the brachiocephalic and carotid arteries around the neck . The experiment was conducted on 33 subjects, each under totally 80 different sensor settings. The proposed approach addressed the variations of humans and devices, as well as the heterogeneous mapping between signals and SpO 2 values. It identified effective device settings and characteristics of their applicable subject groups ( i.e. , subject inclusion-exclusion criteria). Overall, it reduced the root mean squared error (RMSE) by 16%, compared to an empirical formula and a plain SpO 2 estimation model.},
  archive      = {J_ARTMED},
  author       = {Yuhao Zhong and Ashish Jatav and Kahkashan Afrin and Tejaswini Shivaram and Satish T.S. Bukkapatnam},
  doi          = {10.1016/j.artmed.2023.102685},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102685},
  shortjournal = {Artif. Intell. Med.},
  title        = {Enhanced SpO2 estimation using explainable machine learning and neck photoplethysmography},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Medical concept embedding of real-valued electronic health
records with application to inflammatory bowel disease. <em>ARTMED</em>,
<em>145</em>, 102684. (<a
href="https://doi.org/10.1016/j.artmed.2023.102684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning approaches are gradually being applied to electronic health record (EHR) data, but they fail to incorporate medical diagnosis codes and real-valued laboratory tests into a single input sequence for temporal modeling. Therefore, the modeling misses the existing medical interrelations among codes and lab test results that should be exploited to promote early disease detection. To find connections between past diagnoses, represented by medical codes, and real-valued laboratory tests, in order to exploit the full potential of the EHR in medical diagnosis, we present a novel method to embed the two sources of data into a recurrent neural network . Experimenting with a database of Crohn&#39;s disease (CD), a type of inflammatory bowel disease , patients and their controls (~1:2.2), we show that the introduction of lab test results improves the network&#39;s predictive performance more than the introduction of past diagnoses but also, surprisingly, more than when both are combined. In addition, using bootstrapping, we generalize the analysis of the imbalanced database to a medical condition that simulates real-life prevalence of a high-risk CD group of first-degree relatives with results that make our embedding method ready to screen this group in the population.},
  archive      = {J_ARTMED},
  author       = {Hanan Mann and Aharon Bar Hillel and Raffi Lev-Tzion and Shira Greenfeld and Revital Kariv and Natan Lederman and Eran Matz and Iris Dotan and Dan Turner and Boaz Lerner},
  doi          = {10.1016/j.artmed.2023.102684},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102684},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical concept embedding of real-valued electronic health records with application to inflammatory bowel disease},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reconstruction of central arterial pressure waveform based
on CBi-SAN network from radial pressure waveform. <em>ARTMED</em>,
<em>145</em>, 102683. (<a
href="https://doi.org/10.1016/j.artmed.2023.102683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The central arterial pressure (CAP) is an important physiological indicator of the human cardiovascular system which represents one of the greatest threats to human health . Accurate non-invasive detection and reconstruction of CAP waveforms are crucial for the reliable treatment of cardiovascular system diseases. However, the traditional methods are reconstructed with relatively low accuracy, and some deep learning neural network models also have difficulty in extracting features, as a result, these methods have potential for further advancement. In this study, we proposed a novel model (CBi-SAN) to implement an end-to-end relationship from radial artery pressure (RAP) waveform to CAP waveform, which consisted of the convolutional neural network (CNN), the bidirectional long-short-time memory network (BiLSTM), and the self-attention mechanism to improve the performance of CAP reconstruction. The data on invasive measurements of CAP and RAP waveform were used in 62 patients before and after medication to develop and validate the performance of CBi-SAN model for reconstructing CAP waveform. We compared it with traditional methods and deep learning models in mean absolute error (MAE), root mean square error (RMSE), and Spearman correlation coefficient (SCC). Study results indicated the CBi-SAN model performed great performance on CAP waveform reconstruction (MAE: 2.23 ± 0.11 mmHg, RMSE: 2.21 ± 0.07 mmHg), concurrently, the best reconstruction effect was obtained in the central artery systolic pressure (CASP) and the central artery diastolic pressure(CADP) (RMSE CASP CASP : 2.94 ± 0.48 mmHg, RMSE CADP CADP : 1.96 ± 0.06 mmHg). These results implied the performance of the CAP reconstruction based on CBi-SAN model was superior to the existing methods, hopped to be effectively applied to clinical practice in the future.},
  archive      = {J_ARTMED},
  author       = {Hanguang Xiao and Wangwang Song and Chang Liu and Bo Peng and Mi Zhu and Bin Jiang and Zhi Liu},
  doi          = {10.1016/j.artmed.2023.102683},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102683},
  shortjournal = {Artif. Intell. Med.},
  title        = {Reconstruction of central arterial pressure waveform based on CBi-SAN network from radial pressure waveform},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Negation and speculation processing: A study on cue-scope
labelling and assertion classification in spanish clinical text.
<em>ARTMED</em>, <em>145</em>, 102682. (<a
href="https://doi.org/10.1016/j.artmed.2023.102682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Processing (NLP) based on new deep learning technology is contributing to the emergence of powerful solutions that help healthcare providers and researchers discover valuable patterns within insurmountable volumes of health records and scientific literature. Fundamental to the success of such solutions is the processing of negation and speculation. The article addresses this problem with state-of-the-art deep learning approaches from two perspectives: cue and scope labelling, and assertion classification. In light of the real struggle to access clinical annotated data, the study (a) proposes a methodology to automatically convert cue-scope annotations to assertion annotations; and (b) includes a range of scenarios with varying amounts of training data and adversarial test examples. The results expose the clear advantage of Transformer-based models in this regard, managing to overpass a series of baselines and the related work in the public corpus NUBes of clinical Spanish text.},
  archive      = {J_ARTMED},
  author       = {Naiara Perez and Montse Cuadros and German Rigau},
  doi          = {10.1016/j.artmed.2023.102682},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102682},
  shortjournal = {Artif. Intell. Med.},
  title        = {Negation and speculation processing: A study on cue-scope labelling and assertion classification in spanish clinical text},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extending the boundaries of cancer therapeutic complexity
with literature text mining. <em>ARTMED</em>, <em>145</em>, 102681. (<a
href="https://doi.org/10.1016/j.artmed.2023.102681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug combination therapy is a main pillar of cancer therapy. As the number of possible drug candidates for combinations grows, the development of optimal high complexity combination therapies (involving 4 or more drugs per treatment) such as RCHOP-I and FOLFIRINOX becomes increasingly challenging due to combinatorial explosion. In this paper, we propose a text mining (TM) based tool and workflow for rapid generation of high complexity combination treatments (HCCT) in order to extend the boundaries of complexity in cancer treatments. Our primary objectives were: (1) Characterize the existing limitations in combination therapy; (2) Develop and introduce the Plan Builder (PB) to utilize existing literature for drug combination effectively; (3) Evaluate PB&#39;s potential in accelerating the development of HCCT plans. Our results demonstrate that researchers and experts using PB are able to create HCCT plans at much greater speed and quality compared to conventional methods. By releasing PB, we hope to enable more researchers to engage with HCCT planning and demonstrate its clinical efficacy.},
  archive      = {J_ARTMED},
  author       = {Danna Niezni and Hillel Taub-Tabib and Yuval Harris and Hagit Sason and Yakir Amrusi and Dana Meron-Azagury and Maytal Avrashami and Shaked Launer-Wachs and Jon Borchardt and M. Kusold and Aryeh Tiktinsky and Tom Hope and Yoav Goldberg and Yosi Shamay},
  doi          = {10.1016/j.artmed.2023.102681},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102681},
  shortjournal = {Artif. Intell. Med.},
  title        = {Extending the boundaries of cancer therapeutic complexity with literature text mining},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated atrial fibrillation and ventricular fibrillation
recognition using a multi-angle dual-channel fusion network.
<em>ARTMED</em>, <em>145</em>, 102680. (<a
href="https://doi.org/10.1016/j.artmed.2023.102680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atrial fibrillation (AFIB) and ventricular fibrillation (VFIB) are two common cardiovascular diseases that cause numerous deaths worldwide. Medical staff usually adopt long-term ECGs as a tool to diagnose AFIB and VFIB. However, since ECG changes are occasionally subtle and similar, visual observation of ECG changes is challenging. To address this issue, we proposed a multi-angle dual-channel fusion network (MDF-Net) to automatically recognize AFIB and VFIB heartbeats in this work. MDF-Net can be seen as the fusion of a task-related component analysis (TRCA)-principal component analysis (PCA) network (TRPC-Net), a canonical correlation analysis (CCA)-PCA network (CPC-Net), and the linear support vector machine-weighted softmax with average (LS-WSA) method. TRPC-Net and CPC-Net are employed to extract deep task-related and correlation features, respectively, from two-lead ECGs, by which multi-angle feature-level information fusion is realized. Since the convolution kernels of the above methods can be directly extracted through TRCA, CCA and PCA technologies, their training time is faster than that of convolutional neural networks . Finally, LS-WSA is employed to fuse the above features at the decision level, by which the classification results are obtained. In distinguishing AFIB and VFIB heartbeats, the proposed method achieved accuracies of 99.39 % and 97.17 % in intra- and inter-patient experiments, respectively. In addition, this method performed well on noisy data and extremely imbalanced data, in which abnormal heatbeats are much less than normal heartbeats. Our proposed method has the potential to be used as a diagnostic tool in the clinic.},
  archive      = {J_ARTMED},
  author       = {Weiyi Yang and Di Wang and Wei Fan and Gong Zhang and Chunying Li and Tong Liu},
  doi          = {10.1016/j.artmed.2023.102680},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102680},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated atrial fibrillation and ventricular fibrillation recognition using a multi-angle dual-channel fusion network},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Facial wrinkle segmentation using weighted deep supervision
and semi-automatic labeling. <em>ARTMED</em>, <em>145</em>, 102679. (<a
href="https://doi.org/10.1016/j.artmed.2023.102679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial wrinkles are important indicators of human aging. Recently, a method using deep learning and a semi-automatic labeling was proposed to segment facial wrinkles, which showed much better performance than conventional image-processing-based methods. However, the difficulty of wrinkle segmentation remains challenging due to the thinness of wrinkles and their small proportion in the entire image. Therefore, performance improvement in wrinkle segmentation is still necessary. To address this issue, we propose a novel loss function that takes into account the thickness of wrinkles based on the semi-automatic labeling approach. First, considering the different spatial dimensions of the decoder in the U-Net architecture, we generated weighted wrinkle maps from ground truth. These weighted wrinkle maps were used to calculate the training losses more accurately than the existing deep supervision approach. This new loss computation approach is defined as weighted deep supervision in our study. The proposed method was evaluated using an image dataset obtained from a professional skin analysis device and labeled using semi-automatic labeling. In our experiment, the proposed weighted deep supervision showed higher Jaccard Similarity Index (JSI) performance for wrinkle segmentation compared to conventional deep supervision and traditional image processing methods. Additionally, we conducted experiments on the labeling using a semi-automatic labeling approach, which had not been explored in previous research, and compared it with human labeling. The semi-automatic labeling technology showed more consistent wrinkle labels than human-made labels. Furthermore, to assess the scalability of the proposed method to other domains, we applied it to retinal vessel segmentation . The results demonstrated superior performance of the proposed method compared to existing retinal vessel segmentation approaches . In conclusion, the proposed method offers high performance and can be easily applied to various biomedical domains and U-Net-based architectures. Therefore, the proposed approach will be beneficial for various biomedical imaging approaches. To facilitate this, we have made the source code of the proposed method publicly available at: https://github.com/resemin/WeightedDeepSupervision .},
  archive      = {J_ARTMED},
  author       = {Semin Kim and Huisu Yoon and Jongha Lee and Sangwook Yoo},
  doi          = {10.1016/j.artmed.2023.102679},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102679},
  shortjournal = {Artif. Intell. Med.},
  title        = {Facial wrinkle segmentation using weighted deep supervision and semi-automatic labeling},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnosis of alzheimer’s disease by joining dual attention
CNN and MLP based on structural MRIs, clinical and genetic data.
<em>ARTMED</em>, <em>145</em>, 102678. (<a
href="https://doi.org/10.1016/j.artmed.2023.102678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is an irreversible central nervous degenerative disease, while mild cognitive impairment (MCI) is a precursor state of AD. Accurate early diagnosis of AD is conducive to the prevention and early intervention treatment of AD. Although some computational methods have been developed for AD diagnosis, most employ only neuroimaging, ignoring other data (e.g., genetic, clinical) that may have potential disease information. In addition, the results of some methods lack interpretability. In this work, we proposed a novel method (called DANMLP) of joining dual attention convolutional neural network (CNN) and multilayer perceptron (MLP) for computer-aided AD diagnosis by integrating multi-modality data of the structural magnetic resonance imaging (sMRI), clinical data (i.e., demographics, neuropsychology), and APOE genetic data. Our DANMLP consists of four primary components: (1) the Patch-CNN for extracting the image characteristics from each local patch, (2) the position self-attention block for capturing the dependencies between features within a patch, (3) the channel self-attention block for capturing dependencies of inter-patch features, (4) two MLP networks for extracting the clinical features and outputting the AD classification results, respectively. Compared with other state-of-the-art methods in the 5CV test, DANMLP achieves 93% and 82.4% classification accuracy for the AD vs. MCI and MCI vs. NC tasks on the ADNI database, which is 0.2% ∼ ∼ 15.2% and 3.4% ∼ ∼ 26.8% higher than that of other five methods, respectively. The individualized visualization of focal areas can also help clinicians in the early diagnosis of AD. These results indicate that DANMLP can be effectively used for diagnosing AD and MCI patients.},
  archive      = {J_ARTMED},
  author       = {Yan-Rui Qiang and Shao-Wu Zhang and Jia-Ni Li and Yan Li and Qin-Yi Zhou and Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.artmed.2023.102678},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102678},
  shortjournal = {Artif. Intell. Med.},
  title        = {Diagnosis of alzheimer’s disease by joining dual attention CNN and MLP based on structural MRIs, clinical and genetic data},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Food4healthKG: Knowledge graphs for food recommendations
based on gut microbiota and mental health. <em>ARTMED</em>,
<em>145</em>, 102677. (<a
href="https://doi.org/10.1016/j.artmed.2023.102677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food is increasingly acknowledged as a powerful means to promote and maintain mental health. The introduction of the gut-brain axis has been instrumental in understanding the impact of food on mental health. It is widely reported that food can significantly influence gut microbiota metabolism, thereby playing a pivotal role in maintaining mental health. However, the vast amount of heterogeneous data published in recent research lacks systematic integration and application development. To remedy this, we construct a comprehensive knowledge graph, named Food4healthKG, focusing on food, gut microbiota, and mental diseases. The constructed workflow includes the integration of numerous heterogeneous data, entity linking to a normalized format, and the well-designed representation of the acquired knowledge. To illustrate the availability of Food4healthKG, we design two case studies: the knowledge query and the food recommendation based on Food4healthKG. Furthermore, we propose two evaluation methods to validate the quality of the results obtained from Food4healthKG. The results demonstrate the system’s effectiveness in practical applications, particularly in providing convincing food recommendations based on gut microbiota and mental health. Food4healthKG is accessible at https://github.com/ccszbd/Food4healthKG .},
  archive      = {J_ARTMED},
  author       = {Chengcheng Fu and Zhisheng Huang and Frank van Harmelen and Tingting He and Xingpeng Jiang},
  doi          = {10.1016/j.artmed.2023.102677},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102677},
  shortjournal = {Artif. Intell. Med.},
  title        = {Food4healthKG: Knowledge graphs for food recommendations based on gut microbiota and mental health},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Medical informed machine learning: A scoping review and
future research directions. <em>ARTMED</em>, <em>145</em>, 102676. (<a
href="https://doi.org/10.1016/j.artmed.2023.102676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining domain knowledge (DK) and machine learning is a recent research stream to overcome multiple issues like limited explainability, lack of data, and insufficient robustness. Most approaches applying informed machine learning (IML), however, are customized to solve one specific problem. This study analyzes the status of IML in medicine by conducting a scoping literature review based on an existing taxonomy. We identified 177 papers and analyzed them regarding the used DK, the implemented machine learning model, and the motives for performing IML. We find an immense role of expert knowledge and image data in medical IML. We then provide an overview and analysis of recent approaches and supply five directions for future research. This review can help develop future medical IML approaches by easily referencing existing solutions and shaping future research directions.},
  archive      = {J_ARTMED},
  author       = {Florian Leiser and Sascha Rank and Manuel Schmidt-Kraepelin and Scott Thiebes and Ali Sunyaev},
  doi          = {10.1016/j.artmed.2023.102676},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102676},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical informed machine learning: A scoping review and future research directions},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting kidney transplant survival using multiple feature
representations for HLAs. <em>ARTMED</em>, <em>145</em>, 102675. (<a
href="https://doi.org/10.1016/j.artmed.2023.102675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kidney transplantation can significantly enhance living standards for people suffering from end-stage renal disease. A significant factor that affects graft survival time (the time until the transplant fails and the patient requires another transplant) for kidney transplantation is the compatibility of the Human Leukocyte Antigens (HLAs) between the donor and recipient. In this paper, we propose 4 new biologically-relevant feature representations for incorporating HLA information into machine learning-based survival analysis algorithms. We evaluate our proposed HLA feature representations on a database of over 100,000 transplants and find that they improve prediction accuracy by about 1%, modest at the patient level but potentially significant at a societal level. Accurate prediction of survival times can improve transplant survival outcomes, enabling better allocation of donors to recipients and reducing the number of re-transplants due to graft failure with poorly matched donors.},
  archive      = {J_ARTMED},
  author       = {Mohammadreza Nemati and Haonan Zhang and Michael Sloma and Dulat Bekbolsynov and Hong Wang and Stanislaw Stepkowski and Kevin S. Xu},
  doi          = {10.1016/j.artmed.2023.102675},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102675},
  shortjournal = {Artif. Intell. Med.},
  title        = {Predicting kidney transplant survival using multiple feature representations for HLAs},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multitask joint learning with graph autoencoders for
predicting potential MiRNA-drug associations. <em>ARTMED</em>,
<em>145</em>, 102665. (<a
href="https://doi.org/10.1016/j.artmed.2023.102665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The occurrence of many diseases is associated with miRNA abnormalities. Predicting potential drug-miRNA associations is of great importance for both disease treatment and new drug discovery . Most computation-based approaches learn one task at a time, ignoring the information contained in other tasks in the same domain. Multitask learning can effectively enhance the prediction performance of a single task by extending the valid information of related tasks. In this paper, we presented a multitask joint learning framework (MTJL) with a graph autoencoder for predicting the associations between drugs and miRNAs. First, we combined multiple pieces of information to construct a high-quality similarity network of both drugs and miRNAs and then used a graph autoencoder (GAE) to learn their embedding representations separately. Second, to further improve the embedding quality of drugs, we added an auxiliary task to classify drugs using the learned representations. Finally, the embedding representations of drugs and miRNAs were linearly transformed to obtain the predictive association scores between them. A comparison with other state-of-the-art models shows that MTJL has the best prediction performance, and ablation experiments show that the auxiliary task can enhance the embedding quality and improve the robustness of the model. In addition, we show that MTJL has high utility in predicting potential associations between drugs and miRNAs by conducting two case studies .},
  archive      = {J_ARTMED},
  author       = {Yichen Zhong and Cong Shen and Xiaoting Xi and Yuxun Luo and Pingjian Ding and Lingyun Luo},
  doi          = {10.1016/j.artmed.2023.102665},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102665},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multitask joint learning with graph autoencoders for predicting potential MiRNA-drug associations},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph neural networks in EEG spike detection.
<em>ARTMED</em>, <em>145</em>, 102663. (<a
href="https://doi.org/10.1016/j.artmed.2023.102663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops new machine learning architectures that are more adept at detecting interictal epileptiform discharges (IEDs) in scalp EEG . A comparison of results using the average precision (AP) metric is made with the proposed models on two datasets obtained from Baptist Hospital of Miami and Temple University Hospital. Applying graph neural networks (GNNs) on functional connectivity (FC) maps of different frequency sub-bands to yield a novel architecture we call FC-GNN. Attention mechanism is applied on a complete graph to let the neural network select its important edges, hence bypassing the extraction of features, a model we refer to as CA-GNN. On the Baptist Hospital dataset, the results were as follows: Vanilla Self-Attention → 0 . 9029 ± →0.9029± 0.0431, Hierarchical Attention → 0 . 8546 ± →0.8546± 0.0587, Vanilla Visual Geometry Group (VGG) → 0 . 92 ± →0.92± 0.0618, Satelight → 0 . 9219 ± →0.9219± 0.046, FC-GNN → 0 . 9731 ± →0.9731± 0.0187, and CA-GNN → 0 . 9788 ± →0.9788± 0.0125. In the same order, the results on the Temple University Hospital dataset are 0.9692, 0.9113, 0.97, 0.9575, 0.963, and 0.9879. Based on the good results they yield, GNNs prove to have a strong potential in detecting epileptogenic activity. This study opens the door for the discovery of the powerful role played by GNNs in capturing IEDs, which is an essential step for identifying the epileptogenic networks of the affected brain and hence improving the prospects for more accurate 3D source localization.},
  archive      = {J_ARTMED},
  author       = {Ahmed Hossam Mohammed and Mercedes Cabrerizo and Alberto Pinzon and Ilker Yaylali and Prasanna Jayakar and Malek Adjouadi},
  doi          = {10.1016/j.artmed.2023.102663},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102663},
  shortjournal = {Artif. Intell. Med.},
  title        = {Graph neural networks in EEG spike detection},
  volume       = {145},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asymmetric cross-modal attention network with multimodal
augmented mixup for medical visual question answering. <em>ARTMED</em>,
<em>144</em>, 102667. (<a
href="https://doi.org/10.1016/j.artmed.2023.102667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insufficient training data is a common barrier to effectively learn multimodal information interactions and question semantics in existing medical Visual Question Answering (VQA) models. This paper proposes a new Asymmetric Cross Modal Attention network called ACMA, which constructs an image-guided attention and a question-guided attention to improve multimodal interactions from insufficient data. In addition, a Semantic Understanding Auxiliary (SUA) in the question-guided attention is newly designed to learn rich semantic embeddings for improving model performance on question understanding by integrating word-level and sentence-level information. Moreover, we propose a new data augmentation method called Multimodal Augmented Mixup (MAM) to train the ACMA, denoted as ACMA-MAM. The MAM incorporates various data augmentations and a vanilla mixup strategy to generate more non-repetitive data, which avoids time-consuming artificial data annotations and improves model generalization capability. Our ACMA-MAM outperforms state-of-the-art models on three publicly accessible medical VQA datasets (VQA-Rad, VQA-Slake, and PathVQA) with accuracies of 76.14 %, 83.13 %, and 53.83 % respectively, achieving improvements of 2.00 %, 1.32 %, and 1.59 % accordingly. Moreover, our model achieves F1 scores of 78.33 %, 82.83 %, and 51.86 %, surpassing the state-of-the-art models by 2.80 %, 1.15 %, and 1.37 % respectively.},
  archive      = {J_ARTMED},
  author       = {Yong Li and Qihao Yang and Fu Lee Wang and Lap-Kei Lee and Yingying Qu and Tianyong Hao},
  doi          = {10.1016/j.artmed.2023.102667},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102667},
  shortjournal = {Artif. Intell. Med.},
  title        = {Asymmetric cross-modal attention network with multimodal augmented mixup for medical visual question answering},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Empowering elderly care with intelligent IoT-driven smart
toilets for home-based infectious health monitoring. <em>ARTMED</em>,
<em>144</em>, 102666. (<a
href="https://doi.org/10.1016/j.artmed.2023.102666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic highlights the need for effective and non-intrusive methods to monitor the well-being of elderly individuals in their homes, especially for early detection of potential viral infections. Conspicuously, the present paper develops a Multi-scaled Long Short Term Memory (Ms-LSTM) model for the routine health monitoring of elderly patients to detect COVID-19. The proposed method offers home-based health diagnostics through urine analysis by leveraging the IoT-Fog-Cloud paradigm. Mainly, the proposed model constitutes a four-layered architecture: data acquisition, fog layer, cloud layer, and interface layer . Each layer serves distinct functionalities and provides specific services, thereby collectively enhancing the overall effectiveness of the model. The statistical results of the study demonstrate the superior performance of the proposed Ms-LSTM model in comparison to state-of-the-art methods, including Artificial Neural Networks (ANN), K-Nearest Neighbors (K-NN), Support Vector Machine (SVM), Random Forest , and LSTM. Further, the proposed model attains a mean temporal efficiency of 39.23 seconds. It exhibits high reliability (92.97%), stability (70.06%), and predictive accuracy (93.25%).},
  archive      = {J_ARTMED},
  author       = {Dheeraj Kumar and Sandeep Kumar Sood and Keshav Singh Rawat},
  doi          = {10.1016/j.artmed.2023.102666},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102666},
  shortjournal = {Artif. Intell. Med.},
  title        = {Empowering elderly care with intelligent IoT-driven smart toilets for home-based infectious health monitoring},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultra-fast ultrasound blood flow velocimetry for carotid
artery with deep learning. <em>ARTMED</em>, <em>144</em>, 102664. (<a
href="https://doi.org/10.1016/j.artmed.2023.102664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate measurement of blood flow velocity is important for the prevention and early diagnosis of atherosclerosis. However, due to the uncertainty of parameter settings, the autocorrelation velocimetry methods based on clutter filtering are prone to incorrectly filter out the near-wall blood flow signal, resulting in poor velocimetric accuracy. In addition, the Doppler coherent compounding acts as a low-pass filter, which also leads to low values of blood flow velocity estimated by the above methods. Motivated by this status quo, here we propose a deep learning estimator that combines clutter filtering and blood flow velocimetry based on the adaptive property of one-dimensional convolutional neural network (1DCNN). The estimator is operated by first extracting the blood flow signal from the original Doppler echo signal through an affine transformation of the 1D convolution, and then converting the extracted signal into the desired blood flow velocity using a linear transformation function. The effectiveness of the proposed method is verified by simulation as well as in vivo carotid artery data. Compared with typical velocimetry methods such as high-pass filtering (HPF) and singular value decomposition (SVD), the results show that the normalized root means square error (NRMSE) obtained by 1DCNN is reduced by 54.99 % and 53.50 % for forward blood flow velocimetry, and 70.99 % and 69.50 % for reverse blood flow velocimetry, respectively. Consistently, the in vivo measurements demonstrate that the goodness-of-fit of the proposed estimator is improved by 8.72 % and 4.74 % for five subjects. Moreover, the estimation time consumed by 1DCNN is greatly reduced, which costs only 2.91 % of the time of HPF and 12.83 % of the time of SVD. In conclusion, the proposed estimator is a better alternative to the current blood flow velocimetry, and is capable of providing more accurate diagnosis information for vascular diseases in clinical applications.},
  archive      = {J_ARTMED},
  author       = {Bingbing He and Jian Lei and Xun Lang and Zhiyao Li and Wang Cui and Yufeng Zhang},
  doi          = {10.1016/j.artmed.2023.102664},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102664},
  shortjournal = {Artif. Intell. Med.},
  title        = {Ultra-fast ultrasound blood flow velocimetry for carotid artery with deep learning},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated ICD coding using extreme multi-label long text
transformer-based models. <em>ARTMED</em>, <em>144</em>, 102662. (<a
href="https://doi.org/10.1016/j.artmed.2023.102662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encouraged by the success of pretrained Transformer models in many natural language processing tasks, their use for International Classification of Diseases (ICD) coding tasks is now actively being explored. In this study, we investigated two existing Transformer-based models (PLM-ICD and XR-Transformer) and proposed a novel Transformer-based model (XR-LAT), aiming to address the extreme label set and long text classification challenges that are posed by automated ICD coding tasks. The Transformer-based model PLM-ICD, which currently holds the state-of-the-art (SOTA) performance on the ICD coding benchmark datasets MIMIC-III and MIMIC-II, was selected as our baseline model for further optimisation on both datasets. In addition, we extended the capabilities of the leading model in the general extreme multi-label text classification domain, XR-Transformer, to support longer sequences and trained it on both datasets. Moreover, we proposed a novel model, XR-LAT, which was also trained on both datasets. XR-LAT is a recursively trained model chain on a predefined hierarchical code tree with label-wise attention, knowledge transferring and dynamic negative sampling mechanisms. Our optimised PLM-ICD models, which were trained with longer total and chunk sequence lengths , significantly outperformed the current SOTA PLM-ICD models, and achieved the highest micro-F1 scores of 60.8 % and 50.9 % on MIMIC-III and MIMIC-II, respectively. The XR-Transformer model, although SOTA in the general domain, did not perform well across all metrics. The best XR-LAT based models obtained results that were competitive with the current SOTA PLM-ICD models, including improving the macro-AUC by 2.1 % and 5.1 % on MIMIC-III and MIMIC-II, respectively. Our optimised PLM-ICD models are the new SOTA models for automated ICD coding on both datasets, while our novel XR-LAT models perform competitively with the previous SOTA PLM-ICD models.},
  archive      = {J_ARTMED},
  author       = {Leibo Liu and Oscar Perez-Concha and Anthony Nguyen and Vicki Bennett and Louisa Jorm},
  doi          = {10.1016/j.artmed.2023.102662},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102662},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated ICD coding using extreme multi-label long text transformer-based models},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated tabulation of clinical trial results: A joint
entity and relation extraction approach with transformer-based language
representations. <em>ARTMED</em>, <em>144</em>, 102661. (<a
href="https://doi.org/10.1016/j.artmed.2023.102661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidence-based medicine, the practice in which healthcare professionals refer to the best available evidence when making decisions , forms the foundation of modern healthcare. However, it relies on labour-intensive systematic reviews , where domain specialists must aggregate and extract information from thousands of publications, primarily of randomised controlled trial (RCT) results, into evidence tables. This paper investigates automating evidence table generation by decomposing the problem across two language processing tasks : named entity recognition , which identifies key entities within text, such as drug names, and relation extraction , which maps their relationships for separating them into ordered tuples. We focus on the automatic tabulation of sentences from published RCT abstracts that report the results of the study outcomes. Two deep neural net models were developed as part of a joint extraction pipeline, using the principles of transfer learning and transformer-based language representations. To train and test these models, a new gold-standard corpus was developed, comprising over 550 result sentences from six disease areas. This approach demonstrated significant advantages, with our system performing well across multiple natural language processing tasks and disease areas, as well as in generalising to disease domains unseen during training. Furthermore, we show these results were achievable through training our models on as few as 170 example sentences. The final system is a proof of concept that the generation of evidence tables can be semi-automated, representing a step towards fully automating systematic reviews.},
  archive      = {J_ARTMED},
  author       = {Jetsun Whitton and Anthony Hunter},
  doi          = {10.1016/j.artmed.2023.102661},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102661},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated tabulation of clinical trial results: A joint entity and relation extraction approach with transformer-based language representations},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing length of stay prediction by learning
similarity-aware representations for hospitalized patients.
<em>ARTMED</em>, <em>144</em>, 102660. (<a
href="https://doi.org/10.1016/j.artmed.2023.102660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on predicting the length of stay for patients on the first day of admission and propose a predictive model named DGLoS. In order to capture the influence of various complex factors on the length of stay as well as the dependencies among various factors, DGLoS uses a deep neural network to model both the patient information and diagnostic information . Targeting at different attribution types, we utilize different coding methods to convert raw data to the input features. Besides, we find that similar patients have closer lengths of stay. Therefore, we further design a module based on graph representation learning to generate patients’ similarity-aware representations, capturing the similarity between patients and therefore enhancing predictions. These similarity-aware representations are incorporated into the output of the deep neural network to jointly perform the prediction. We have conducted comprehensive experiments on a real-world hospitalization dataset. The performance comparison shows that our proposed DGLoS model improves predictive performance and the significance test demonstrates the improvement is significant. The ablation study verifies the effectiveness of each of the proposed components and the hyper-parameter investigation shows the robustness of the proposed model.},
  archive      = {J_ARTMED},
  author       = {Tianzi Zang and Yanmin Zhu and Xinrui Huang and Xinchen Yang and Qiuxia Chen and Jiadi Yu and Feilong Tang},
  doi          = {10.1016/j.artmed.2023.102660},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102660},
  shortjournal = {Artif. Intell. Med.},
  title        = {Enhancing length of stay prediction by learning similarity-aware representations for hospitalized patients},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interpretable deep learning model for time-series
electronic health records: Case study of delirium prediction in critical
care. <em>ARTMED</em>, <em>144</em>, 102659. (<a
href="https://doi.org/10.1016/j.artmed.2023.102659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) models have received increasing attention in the clinical setting, particularly in intensive care units (ICU). In this context, the interpretability of the outcomes estimated by the DL models is an essential step towards increasing adoption of DL models in clinical practice. To address this challenge, we propose an ante-hoc, interpretable neural network model. Our proposed model, named double self-attention architecture (DSA), uses two attention-based mechanisms, including self-attention and effective attention. It can capture the importance of input variables in general, as well as changes in importance along the time dimension for the outcome of interest. We evaluated our model using two real-world clinical datasets covering 22840 patients in predicting onset of delirium 12 h and 48 h in advance. Additionally, we compare the descriptive performance of our model with three post-hoc interpretable algorithms as well as with the opinion of clinicians based on the published literature and clinical experience. We find that our model covers the majority of the top-10 variables ranked by the other three post-hoc interpretable algorithms as well as the clinical opinion, with the advantage of taking into account both, the dependencies among variables as well as dependencies between varying time-steps. Finally, our results show that our model can improve descriptive performance without sacrificing predictive performance.},
  archive      = {J_ARTMED},
  author       = {Seyedmostafa Sheikhalishahi and Anirban Bhattacharyya and Leo Anthony Celi and Venet Osmani},
  doi          = {10.1016/j.artmed.2023.102659},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102659},
  shortjournal = {Artif. Intell. Med.},
  title        = {An interpretable deep learning model for time-series electronic health records: Case study of delirium prediction in critical care},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair and equitable AI in biomedical research and healthcare:
Social science perspectives. <em>ARTMED</em>, <em>144</em>, 102658. (<a
href="https://doi.org/10.1016/j.artmed.2023.102658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) offers opportunities but also challenges for biomedical research and healthcare. This position paper shares the results of the international conference “Fair medicine and AI” (online 3–5 March 2021). Scholars from science and technology studies (STS), gender studies , and ethics of science and technology formulated opportunities, challenges, and research and development desiderata for AI in healthcare. AI systems and solutions, which are being rapidly developed and applied, may have undesirable and unintended consequences including the risk of perpetuating health inequalities for marginalized groups. Socially robust development and implications of AI in healthcare require urgent investigation. There is a particular dearth of studies in human-AI interaction and how this may best be configured to dependably deliver safe, effective and equitable healthcare. To address these challenges, we need to establish diverse and interdisciplinary teams equipped to develop and apply medical AI in a fair, accountable and transparent manner. We formulate the importance of including social science perspectives in the development of intersectionally beneficent and equitable AI for biomedical research and healthcare, in part by strengthening AI health evaluation.},
  archive      = {J_ARTMED},
  author       = {Renate Baumgartner and Payal Arora and Corinna Bath and Darja Burljaev and Kinga Ciereszko and Bart Custers and Jin Ding and Waltraud Ernst and Eduard Fosch-Villaronga and Vassilis Galanos and Thomas Gremsl and Tereza Hendl and Cordula Kropp and Christian Lenk and Paul Martin and Somto Mbelu and Sara Morais dos Santos Bruss and Karolina Napiwodzka and Ewa Nowak and Tiara Roxanne and Silja Samerski and David Schneeberger and Karolin Tampe-Mai and Katerina Vlantoni and Kevin Wiggert and Robin Williams},
  doi          = {10.1016/j.artmed.2023.102658},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102658},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fair and equitable AI in biomedical research and healthcare: Social science perspectives},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Walking path images from real-time location data predict
degree of cognitive impairment. <em>ARTMED</em>, <em>144</em>, 102657.
(<a href="https://doi.org/10.1016/j.artmed.2023.102657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel approach that uses spatial walking patterns produced by real-time location systems to classify the severity of cognitive impairment (CI) among residents of a memory care unit. Each participant was classified as “No-CI”, “Mild-Moderate CI” or “Severe CI” based on their Mini-Mental State Examination scores. The location data was distributed into windows of various durations (5, 10, 15 and 30 min) and transformed into images used to train a custom convolutional neural network (CNN) at each window size. Class Activation Mapping was applied to the top-performing models to determine the features of images associated with each class. The best performing model achieved an accuracy of 87.38 % (30-min window length) with an overall pattern that larger window sizes perform better. The class activation maps were effectively consolidated into a Cognitive Impairment Classification Value (CICV) score that distinguishes between No-CI, Mild-Moderate CI, and Severe CI. The class activation maps show that the CNN made relevant and intuitive distinctions for paths corresponding to each class. Future work should validate the proposed techniques with participants who are well-characterized clinically, over larger and diversified settings, and towards classification of neuropsychiatric symptoms such as motor agitation, mood, or apathy.},
  archive      = {J_ARTMED},
  author       = {Tamim Faruk and Leia C. Shum and Andrea Iaboni and Shehroz S. Khan},
  doi          = {10.1016/j.artmed.2023.102657},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102657},
  shortjournal = {Artif. Intell. Med.},
  title        = {Walking path images from real-time location data predict degree of cognitive impairment},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-world prediction of preclinical alzheimer’s disease
with a deep generative model. <em>ARTMED</em>, <em>144</em>, 102654. (<a
href="https://doi.org/10.1016/j.artmed.2023.102654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amyloid positivity is an early indicator of Alzheimer’s disease and is necessary to determine the disease. In this study, a deep generative model is utilized to predict the amyloid positivity of cognitively normal individuals using proxy measures, such as structural MRI scans, demographic variables, and cognitive scores, instead of invasive direct measurements. Through its remarkable efficacy in handling imperfect datasets caused by missing data or labels, and imbalanced classes, the model outperforms previous studies and widely used machine learning approaches with an AUROC of 0.8609. Furthermore, this study illuminates the model’s adaptability to diverse clinical scenarios, even when feature sets or diagnostic criteria differ from the training data. We identify the brain regions and variables that contribute most to classification, including the lateral occipital lobes , posterior temporal lobe , and APOE ϵ ϵ 4 allele. Taking advantage of deep generative models, our approach can not only provide inexpensive, non-invasive, and accurate diagnostics for preclinical Alzheimer’s disease, but also meet real-world requirements for clinical translation of a deep learning model, including transferability and interpretability.},
  archive      = {J_ARTMED},
  author       = {Uiwon Hwang and Sung-Woo Kim and Dahuin Jung and SeungWook Kim and Hyejoo Lee and Sang Won Seo and Joon-Kyung Seong and Sungroh Yoon and Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.artmed.2023.102654},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102654},
  shortjournal = {Artif. Intell. Med.},
  title        = {Real-world prediction of preclinical alzheimer’s disease with a deep generative model},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated estimation of mitral annular plane systolic
excursion by artificial intelligence from 3D ultrasound recordings.
<em>ARTMED</em>, <em>144</em>, 102646. (<a
href="https://doi.org/10.1016/j.artmed.2023.102646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perioperative monitoring of cardiac function is beneficial for early detection of cardiovascular complications. The standard of care for cardiac monitoring performed by trained cardiologists and anesthesiologists involves a manual and qualitative evaluation of ultrasound imaging, which is a time-demanding and resource-intensive process with intraobserver- and interobserver variability. In practice, such measures can only be performed a limited number of times during the intervention. To overcome these difficulties, this study presents a robust method for automatic and quantitative monitoring of cardiac function based on 3D transesophageal echocardiography (TEE) B-mode ultrasound recordings of the left ventricle (LV). Such an assessment obtains consistent measurements and can produce a near real-time evaluation of ultrasound imagery. Hence, the presented method is time-saving and results in increased accessibility. The mitral annular plane systolic excursion (MAPSE), characterizing global LV function, is estimated by landmark detection and cardiac view classification of two-dimensional images extracted along the long-axis of the ultrasound volume. MAPSE estimation directly from 3D TEE recordings is beneficial since it removes the need for manual acquisition of cardiac views, hence decreasing the need for interference by physicians. Two convolutional neural networks (CNNs) were trained and tested on acquired ultrasound data of 107 patients, and MAPSE estimates were compared to clinically obtained references in a blinded study including 31 patients. The proposed method for automatic MAPSE estimation had low bias and low variability in comparison to clinical reference measures. The method accomplished a mean difference for MAPSE estimates of ( − 0 . 16 ± 1 . 06 −0.16±1.06 ) mm. Thus, the results did not show significant systematic errors. The obtained bias and variance of the method were comparable to inter-observer variability of clinically obtained MAPSE measures on 2D TTE echocardiography. The novel pipeline proposed in this study has the potential to enhance cardiac monitoring in perioperative- and intensive care settings.},
  archive      = {J_ARTMED},
  author       = {Anders Austlid Taskén and Erik Andreas Rye Berg and Bjørnar Grenne and Espen Holte and Håvard Dalen and Stian Stølen and Frank Lindseth and Svend Aakhus and Gabriel Kiss},
  doi          = {10.1016/j.artmed.2023.102646},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102646},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated estimation of mitral annular plane systolic excursion by artificial intelligence from 3D ultrasound recordings},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Process mining and data mining applications in the domain of
chronic diseases: A systematic review. <em>ARTMED</em>, <em>144</em>,
102645. (<a href="https://doi.org/10.1016/j.artmed.2023.102645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of information technology in healthcare leads to extensive data collection, which can be utilised to enhance patient care and manage chronic illnesses . Our objective is to summarise previous studies that have used data mining or process mining methods in the context of chronic diseases in order to identify research trends and future opportunities. The review covers articles that pertain to the application of data mining or process mining methods on chronic diseases that were published between 2000 and 2022. Articles were sourced from PubMed, Web of Science, EMBASE, and Google Scholar based on predetermined inclusion and exclusion criteria. A total of 71 articles met the inclusion criteria and were included in the review. Based on the literature review results, we detected a growing trend in the application of data mining methods in diabetes research. Additionally, a distinct increase in the use of process mining methods to model clinical pathways in cancer research was observed. Frequently, this takes the form of a collaborative integration of process mining, data mining, and traditional statistical methods. In light of this collaborative approach, the meticulous selection of statistical methods based on their underlying assumptions is essential when integrating these traditional methods with process mining and data mining methods. Another notable challenge is the lack of standardised guidelines for reporting process mining studies in the medical field. Furthermore, there is a pressing need to enhance the clinical interpretation of data mining and process mining results.},
  archive      = {J_ARTMED},
  author       = {Kaile Chen and Farhad Abtahi and Juan-Jesus Carrero and Carlos Fernandez-Llatas and Fernando Seoane},
  doi          = {10.1016/j.artmed.2023.102645},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102645},
  shortjournal = {Artif. Intell. Med.},
  title        = {Process mining and data mining applications in the domain of chronic diseases: A systematic review},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot transfer learning for personalized atrial
fibrillation detection using patient-based siamese network with
single-lead ECG records. <em>ARTMED</em>, <em>144</em>, 102644. (<a
href="https://doi.org/10.1016/j.artmed.2023.102644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of wearable devices has allowed the collection of electrocardiogram (ECG) recordings daily to monitor heart rhythm and rate . For example, 24-hour Holter monitors, cardiac patches, and smartwatches are widely used for ECG gathering and application. An automatic atrial fibrillation (AF) detector is required for timely ECG interpretation. Deep learning models can accurately identify AFs if large amounts of annotated data are available for model training. However, it is impractical to request sufficient labels for ECG recordings for an individual patient to train a personalized model. We propose a Siamese-network-based approach for transfer learning to address this issue. A pre-trained Siamese convolutional neural network is created by comparing two labeled ECG segments from the same patient. We sampled 30-second ECG segments with a 50% overlapping window from the ECG recordings of patients in the MIT-BIH Atrial Fibrillation Database. Subsequently, we independently detected the occurrence of AF in each patient in the Long-Term AF Database. By fine-tuning the model with the 1, 3, 5, 7, 9, or 11 ECG segments ranging from 30 to 180 s, our method achieved macro-F1 scores of 96.84%, 96.91%, 96.97%, 97.02%, 97.05%, and 97.07%, respectively.},
  archive      = {J_ARTMED},
  author       = {Yiuwai Ng and Min-Tsun Liao and Ting-Li Chen and Chih-Kuo Lee and Cheng-Ying Chou and Weichung Wang},
  doi          = {10.1016/j.artmed.2023.102644},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102644},
  shortjournal = {Artif. Intell. Med.},
  title        = {Few-shot transfer learning for personalized atrial fibrillation detection using patient-based siamese network with single-lead ECG records},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated precision localization of peripherally inserted
central catheter tip through model-agnostic multi-stage networks.
<em>ARTMED</em>, <em>144</em>, 102643. (<a
href="https://doi.org/10.1016/j.artmed.2023.102643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peripherally inserted central catheters (PICCs) have been widely used as one of the representative central venous lines (CVCs) due to their long-term intravascular access with low infectivity. However, PICCs have a fatal drawback of a high frequency of tip mispositions, increasing the risk of puncture, embolism, and complications such as cardiac arrhythmias . To automatically and precisely detect it, various attempts have been made by using the latest deep learning (DL) technologies. However, even with these approaches, it is still practically difficult to determine the tip location because the multiple fragments phenomenon (MFP) occurs in the process of predicting and extracting the PICC line required before predicting the tip. This study aimed to develop a system generally applied to existing models and to restore the PICC line more exactly by removing the MFs of the model output, thereby precisely localizing the actual tip position for detecting its misposition. To achieve this, we proposed a multi-stage DL-based framework post-processing the PICC line extraction result of the existing technology. Our method consists of the following three stages: 1. Existing PICC line segmentation network for a baseline, 2. Patch-based PICC line refinement network, 3. PICC line reconnection network. The proposed second and third-stage models address MFs caused by the sparseness of the PICC line and the line disconnection due to confusion with anatomical structures respectively, thereby enhancing tip detection. To verify the objective performance of the proposed MFCN, internal validation and external validation were conducted. For internal validation, learning (130 samples) and verification (150 samples) were performed with 280 data, including PICC among Chest X-ray (CXR) images taken at our institution. External validation was conducted using a public dataset called the Royal Australian and New Zealand College of Radiologists (RANZCR), and training (130 samples) and validation (150 samples) were performed with 280 data of CXR images, including PICC, which has the same number as that for internal validation. The performance was compared by root mean squared error (RMSE) and the ratio of single fragment images (Ratio S F I SFI ) (i.e., the rate at which model predicts PICC as multiple sub-lines) according to whether or not MFCN is applied to seven conventional models (i.e., FCDN , UNET, AUNET , TUNET, FCDN-HT, UNET-ELL, and UNET-RPN). In internal validation, when MFCN was applied to the existing single model, MFP was improved by an average of 45 %. The RMSE improved over 63% from an average of 27.54 mm (17.16 to 35.80 mm) to 9.77 mm (9.11 to 10.98 mm). In external validation, when MFCN was applied, the MFP incidence rate decreased by an average of 32% and the RMSE decreased by an average of 65%. Therefore, by applying the proposed MFCN, we observed the consistent detection performance improvement of PICC tip location compared to the existing model. In this study, we applied the proposed technique to the existing technique and demonstrated that it provides high tip detection performance, proving its high versatility and superiority. Therefore, we believe, in countries and regions where radiologists are scarce, that the proposed DL approach will be able to effectively detect PICC misposition on behalf of radiologists.},
  archive      = {J_ARTMED},
  author       = {Subin Park and Yoon Ki Cha and Soyoung Park and Myung Jin Chung and Kyungsu Kim},
  doi          = {10.1016/j.artmed.2023.102643},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102643},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated precision localization of peripherally inserted central catheter tip through model-agnostic multi-stage networks},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning for administrative health records: A
systematic review of techniques and applications. <em>ARTMED</em>,
<em>144</em>, 102642. (<a
href="https://doi.org/10.1016/j.artmed.2023.102642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning provides many powerful and effective techniques for analysing heterogeneous electronic health records (EHR). Administrative Health Records (AHR) are a subset of EHR collected for administrative purposes, and the use of machine learning on AHRs is a growing subfield of EHR analytics. Existing reviews of EHR analytics emphasise that the data-modality of the EHR limits the breadth of suitable machine learning techniques , and pursuable healthcare applications. Despite emphasising the importance of data modality, the literature fails to analyse which techniques and applications are relevant to AHRs. AHRs contain uniquely well-structured, categorically encoded records which are distinct from other data-modalities captured by EHRs, and they can provide valuable information pertaining to how patients interact with the healthcare system. This paper systematically reviews AHR-based research, analysing 70 relevant studies and spanning multiple databases. We identify and analyse which machine learning techniques are applied to AHRs and which health informatics applications are pursued in AHR-based research. We also analyse how these techniques are applied in pursuit of each application, and identify the limitations of these approaches. We find that while AHR-based studies are disconnected from each other, the use of AHRs in health informatics research is substantial and accelerating. Our synthesis of these studies highlights the utility of AHRs for pursuing increasingly complex and diverse research objectives despite a number of pervading data- and technique-based limitations. Finally, through our findings, we propose a set of future research directions that can enhance the utility of AHR data and machine learning techniques for health informatics research.},
  archive      = {J_ARTMED},
  author       = {Adrian Caruana and Madhushi Bandara and Katarzyna Musial and Daniel Catchpoole and Paul J. Kennedy},
  doi          = {10.1016/j.artmed.2023.102642},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102642},
  shortjournal = {Artif. Intell. Med.},
  title        = {Machine learning for administrative health records: A systematic review of techniques and applications},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic breach detection during spine pedicle drilling
based on vibroacoustic sensing. <em>ARTMED</em>, <em>144</em>, 102641.
(<a href="https://doi.org/10.1016/j.artmed.2023.102641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedicle drilling is a complex and critical spinal surgery task. Detecting breach or penetration of the surgical tool to the cortical wall during pilot-hole drilling is essential to avoid damage to vital anatomical structures adjacent to the pedicle, such as the spinal cord, blood vessels, and nerves. Currently, the guidance of pedicle drilling is done using image-guided methods that are radiation intensive and limited to the preoperative information. This work proposes a new radiation-free breach detection algorithm leveraging a non-visual sensor setup in combination with deep learning approach. Multiple vibroacoustic sensors, such as a contact microphone, a free-field microphone, a tri-axial accelerometer , a uni-axial accelerometer, and an optical tracking system were integrated into the setup. Data were collected on four cadaveric human spines, ranging from L5 to T10. An experienced spine surgeon drilled the pedicles relying on optical navigation . A new automatic labeling method based on the tracking data was introduced. Labeled data was subsequently fed to the network in mel-spectrograms, classifying the data into breach and non-breach. Different sensor types, sensor positioning, and their combinations were evaluated. The best results in breach recall for individual sensors could be achieved using contact microphones attached to the dorsal skin (85.8%) and uni-axial accelerometers clamped to the spinous process of the drilled vertebra (81.0%). The best-performing data fusion model combined the latter two sensors with a breach recall of 98%. The proposed method shows the great potential of non-visual sensor fusion for avoiding screw misplacement and accidental bone breaches during pedicle drilling and could be extended to further surgical applications.},
  archive      = {J_ARTMED},
  author       = {Aidana Massalimova and Maikel Timmermans and Nicola Cavalcanti and Daniel Suter and Matthias Seibold and Fabio Carrillo and Christoph J. Laux and Reto Sutter and Mazda Farshad and Kathleen Denis and Philipp Fürnstahl},
  doi          = {10.1016/j.artmed.2023.102641},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102641},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic breach detection during spine pedicle drilling based on vibroacoustic sensing},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DDI-GCN: Drug-drug interaction prediction via explainable
graph convolutional networks. <em>ARTMED</em>, <em>144</em>, 102640. (<a
href="https://doi.org/10.1016/j.artmed.2023.102640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-drug interactions (DDI) may lead to unexpected side effects , which is a growing concern in both academia and industry. Many DDIs have been reported, but the underlying mechanisms are not well understood. Predicting and understanding DDIs can help researchers to improve drug safety and protect patient health. Here, we introduce DDI-GCN, a method that utilizes graph convolutional networks (GCN) to predict DDIs based on chemical structures. We demonstrate that this method achieves state-of-the-art prediction performance on the independent hold-out set. It can also provide visualization of structural features associated with DDIs, which can help us to study the underlying mechanisms. To make it easy and accessible to use, we developed a web server for DDI-GCN, which is freely available at http://wengzq-lab.cn/ddi/ .},
  archive      = {J_ARTMED},
  author       = {Yi Zhong and Houbing Zheng and Xiaoming Chen and Yu Zhao and Tingfang Gao and Huiqun Dong and Heng Luo and Zuquan Weng},
  doi          = {10.1016/j.artmed.2023.102640},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102640},
  shortjournal = {Artif. Intell. Med.},
  title        = {DDI-GCN: Drug-drug interaction prediction via explainable graph convolutional networks},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A holistic AI-based approach for pharmacovigilance
optimization from patients behavior on social media. <em>ARTMED</em>,
<em>144</em>, 102638. (<a
href="https://doi.org/10.1016/j.artmed.2023.102638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a holistic AI-based pharmacovigilance optimization approach using patient’s social media data. Instead of focusing on the detection and identification of Adverse Drug Events (ADE) in social media posts in single time points, we propose a holistic approach that looks at the evolution of different user behavior indicators in time. We examine various NLP-based indicators such as word frequency, semantic similarity, Adverse Drug Reactions mentions, and sentiment analysis. We introduce a classification approach to identify normal vs. abnormal time periods based on patient comments. This approach, along with user behavior indicators, can optimize the pharmacovigilance process by flagging the need for immediate attention and further investigation. We specifically focus on the Levothyrox® case in France, which sparked media attention due to changes in the medication formula and affected patient behavior on medical forums. For classification, we propose a deep learning architecture called Word Cloud Convolutional Neural Network (WC-CNN), trained on word clouds from patient comments. We evaluate different temporal resolutions and NLP pre-processing techniques, finding that monthly resolution and the proposed indicators can effectively detect new safety signals, with an accuracy of 75%. We have made the code open source, available via github .},
  archive      = {J_ARTMED},
  author       = {Valentin Roche and Jean-Philippe Robert and Hanan Salam},
  doi          = {10.1016/j.artmed.2023.102638},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102638},
  shortjournal = {Artif. Intell. Med.},
  title        = {A holistic AI-based approach for pharmacovigilance optimization from patients behavior on social media},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep grading for MRI-based differential diagnosis of
alzheimer’s disease and frontotemporal dementia. <em>ARTMED</em>,
<em>144</em>, 102636. (<a
href="https://doi.org/10.1016/j.artmed.2023.102636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease and Frontotemporal dementia are common forms of neurodegenerative dementia. Behavioral alterations and cognitive impairments are found in the clinical courses of both diseases, and their differential diagnosis can sometimes pose challenges for physicians. Therefore, an accurate tool dedicated to this diagnostic challenge can be valuable in clinical practice. However, current structural imaging methods mainly focus on the detection of each disease but rarely on their differential diagnosis. In this paper, we propose a deep learning-based approach for both disease detection and differential diagnosis. We suggest utilizing two types of biomarkers for this application: structure grading and structure atrophy. First, we propose to train a large ensemble of 3D U-Nets to locally determine the anatomical patterns of healthy people , patients with Alzheimer’s disease and patients with Frontotemporal dementia using structural MRI as input. The output of the ensemble is a 2-channel disease’s coordinate map, which can be transformed into a 3D grading map that is easily interpretable for clinicians. This 2-channel disease’s coordinate map is coupled with a multi-layer perceptron classifier for different classification tasks. Second, we propose to combine our deep learning framework with a traditional machine learning strategy based on volume to improve the model discriminative capacity and robustness. After both cross-validation and external validation, our experiments, based on 3319 MRIs, demonstrated that our method produces competitive results compared to state-of-the-art methods for both disease detection and differential diagnosis.},
  archive      = {J_ARTMED},
  author       = {Huy-Dung Nguyen and Michaël Clément and Vincent Planche and Boris Mansencal and Pierrick Coupé},
  doi          = {10.1016/j.artmed.2023.102636},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102636},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep grading for MRI-based differential diagnosis of alzheimer’s disease and frontotemporal dementia},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Case scenario generators for trauma surgery simulation
utilizing autoregressive language models. <em>ARTMED</em>, <em>144</em>,
102635. (<a href="https://doi.org/10.1016/j.artmed.2023.102635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trauma is the leading cause of death in adults under the age of 45 and the fourth leading cause of death in the United States. Effective delivery of trauma care centers on being well versed in the Advanced Trauma Life Support (ATLS) protocol, which requires high levels of clinical experience. Often this comes from having been exposed to the many permutations of common types of injuries as well as exposed to rarer scenarios, but with potential harm to patients. Case scenarios, which are sequential representations of clinical events, can help trainees receive clinical exposure without harming patients. However authoring case scenarios requires domain expertise, wide experience, and the ability to intelligently respond to inputs, and as such is currently an arduous task. Autoregressive generative models trained on large amounts of clinical data , such as the National Trauma Data Bank (NTDB), pose a possible solution to overcome the cost of authorship while providing broad and accessible clinical experience to trainees. We have developed a Trauma AI model composed of an autoregressive generative model based on the transformer architecture for generating potential case scenario combined with an out-of-domain detection for filtering out less plausible scenarios. The GPT2 model is trained on 1.1 million case scenarios derived from the NTDB data. We demonstrate that Trauma AI is capable of generating realistic case scenarios that encode the ATLS protocol as a latent feature of the sequence of provider interventions, including scenarios that do not have any parallels in the original dataset. We also present an unsupervised means of filtering out unrealistic sequences by identifying out-of-domain sequences, and demonstrate that this improves the realism of the generated case scenarios.},
  archive      = {J_ARTMED},
  author       = {Paul Chung and Michael Boodoo and Simona Doboli},
  doi          = {10.1016/j.artmed.2023.102635},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102635},
  shortjournal = {Artif. Intell. Med.},
  title        = {Case scenario generators for trauma surgery simulation utilizing autoregressive language models},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving chest x-ray report generation by leveraging warm
starting. <em>ARTMED</em>, <em>144</em>, 102633. (<a
href="https://doi.org/10.1016/j.artmed.2023.102633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically generating a report from a patient’s Chest X-rays (CXRs) is a promising solution to reducing clinical workload and improving patient care. However, current CXR report generators—which are predominantly encoder-to-decoder models—lack the diagnostic accuracy to be deployed in a clinical setting. To improve CXR report generation, we investigate warm starting the encoder and decoder with recent open-source computer vision and natural language processing checkpoints, such as the Vision Transformer (ViT) and PubMedBERT. To this end, each checkpoint is evaluated on the MIMIC-CXR and IU X-ray datasets. Our experimental investigation demonstrates that the Convolutional vision Transformer (CvT) ImageNet-21K and the Distilled Generative Pre-trained Transformer 2 (DistilGPT2) checkpoints are best for warm starting the encoder and decoder, respectively. Compared to the state-of-the-art ( M 2 M2 Transformer Progressive), CvT2DistilGPT2 attained an improvement of 8.3% for CE F-1, 1.8% for BLEU-4, 1.6% for ROUGE-L, and 1.0% for METEOR. The reports generated by CvT2DistilGPT2 have a higher similarity to radiologist reports than previous approaches. This indicates that leveraging warm starting improves CXR report generation. Code and checkpoints for CvT2DistilGPT2 are available at https://github.com/aehrc/cvt2distilgpt2 .},
  archive      = {J_ARTMED},
  author       = {Aaron Nicolson and Jason Dowling and Bevan Koopman},
  doi          = {10.1016/j.artmed.2023.102633},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102633},
  shortjournal = {Artif. Intell. Med.},
  title        = {Improving chest X-ray report generation by leveraging warm starting},
  volume       = {144},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Osteoporosis prediction in lumbar spine x-ray images using
the multi-scale weighted fusion contextual transformer network.
<em>ARTMED</em>, <em>143</em>, 102639. (<a
href="https://doi.org/10.1016/j.artmed.2023.102639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoporosis is a bone-related disease characterized by decreased bone density and mass, leading to brittle fractures . Osteoporosis assessment from radiographs using a deep learning algorithm has proven a low-cost alternative to the golden standard DXA . Due to the considerable noise and low contrast, automated diagnosis of osteoporosis in X-ray images still poses a significant challenge for traditional diagnostic methods. In this paper, an end-to-end transformer-style network was proposed, termed FCoTNet, to overcome the shortcoming of insufficient fusion of texture information and local features in the traditional CoTNet. To extract complementary geometric representations at each scale of the transformer module, we integrated parallel multi-scale feature extraction architectures in each unit layer of FCoTNet to utilize convolution to aggregate features from different receptive fields. Moreover, in order to extract small-scale texture features which were more critical to the diagnosis of osteoporosis in radiographs, larger fusion weights were assigned to the feature maps with small-size receptive fields. Afterward, the multi-scale global modeling was conducted by self-attention mechanism. The proposed model was first investigated on a private lumbar spine X-ray dataset with the 5-fold cross-validation strategy, obtaining an average accuracy of 78.29 ± 0.93 %, an average sensitivity of 69.72 ± 2.35 %, and an average specificity of 88.92 ± 0.67 % for the multi-classification of normal, osteopenia , and osteoporosis categories. We then conducted a controlled trial with five orthopedic clinicians to evaluate the clinical value of the model. The average clinician&#39;s accuracy improved from 61.50 ± 10.79 % unaided to 80.00 ± 5.92 % aided (18.50 % improvement), sensitivity improved from 64.38 ± 8.07 % unaided to 83.31 ± 5.43 % aided (18.93 % improvement), and specificity improved from 80.11 ± 4.72 % unaided to 89.94 ± 3.82 % aided (9.83 % improvement). Meanwhile, the prediction consistency among clinicians significantly improved with the assistance of FCoTNet. Furthermore, the proposed model showed good robustness on an external test dataset . These investigations indicate that the proposed deep learning model achieves state-of-the-art performance for osteoporosis prediction, which substantially improves osteoporosis screening and reduced osteoporosis fractures.},
  archive      = {J_ARTMED},
  author       = {Linyan Xue and Geng Qin and Shilong Chang and Cheng Luo and Ya Hou and Zhiyin Xia and Jiacheng Yuan and Yucheng Wang and Shuang Liu and Kun Liu and Xiaoting Li and Sibei Wu and Qingliang Zhao and Wenshan Gao and Kun Yang},
  doi          = {10.1016/j.artmed.2023.102639},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102639},
  shortjournal = {Artif. Intell. Med.},
  title        = {Osteoporosis prediction in lumbar spine X-ray images using the multi-scale weighted fusion contextual transformer network},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-stage contextual transformer-based convolutional neural
network for airway extraction from CT images. <em>ARTMED</em>,
<em>143</em>, 102637. (<a
href="https://doi.org/10.1016/j.artmed.2023.102637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate airway segmentation from computed tomography (CT) images is critical for planning navigation bronchoscopy and realizing a quantitative assessment of airway-related chronic obstructive pulmonary disease (COPD). Existing methods face difficulty in airway segmentation, particularly for the small branches of the airway. These difficulties arise due to the constraints of limited labeling and failure to meet clinical use requirements in COPD. We propose a two-stage framework with a novel 3D contextual transformer for segmenting the overall airway and small airway branches using CT images. The method consists of two training stages sharing the same modified 3D U-Net network. The novel 3D contextual transformer block is integrated into both the encoder and decoder path of the network to effectively capture contextual and long-range information. In the first training stage, the proposed network segments the overall airway with the overall airway mask. To improve the performance of the segmentation result, we generate the intrapulmonary airway branch label, and train the network to focus on producing small airway branches in the second training stage. Extensive experiments were performed on in-house and multiple public datasets. Quantitative and qualitative analyses demonstrate that our proposed method extracts significantly more branches and longer lengths of the airway tree while accomplishing state-of-the-art airway segmentation performance. The code is available at https://github.com/zhaozsq/airway_segmentation .},
  archive      = {J_ARTMED},
  author       = {Yanan Wu and Shuiqing Zhao and Shouliang Qi and Jie Feng and Haowen Pang and Runsheng Chang and Long Bai and Mengqi Li and Shuyue Xia and Wei Qian and Hongliang Ren},
  doi          = {10.1016/j.artmed.2023.102637},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102637},
  shortjournal = {Artif. Intell. Med.},
  title        = {Two-stage contextual transformer-based convolutional neural network for airway extraction from CT images},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive bayesian learning for making risk-aware decisions:
A case of trauma survival prediction. <em>ARTMED</em>, <em>143</em>,
102634. (<a href="https://doi.org/10.1016/j.artmed.2023.102634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision tree (DT) models provide a transparent approach to prediction of patient’s outcomes within a probabilistic framework . Averaging over DT models under certain conditions can deliver reliable estimates of predictive posterior probability distributions, which is of critical importance in the case of predicting an individual patient’s outcome. Reliable estimations of the distribution can be achieved within the Bayesian framework using Markov chain Monte Carlo (MCMC) and its Reversible Jump extension enabling DT models to grow to a reasonable size. Existing MCMC strategies however have limited ability to control DT structures and tend to sample overgrown DT models, making unreasonably small partitions, thus deteriorating the uncertainty calibration. This happens because the MCMC explores a DT model parameter space within a limited knowledge of the distribution of data partitions. We propose a new adaptive strategy which overcomes this limitation, and show that in the case of predicting trauma outcomes the number of data partitions can be significantly reduced, so that the unnecessary uncertainty of estimating the predictive posterior density is avoided. The proposed and existing strategies are compared in terms of entropy which, being calculated for predicted posterior distributions , represents the uncertainty in decisions. In this framework, the proposed method has outperformed the existing sampling strategies, so that the unnecessary uncertainty in decisions is efficiently avoided.},
  archive      = {J_ARTMED},
  author       = {Livija Jakaite and Vitaly Schetinin},
  doi          = {10.1016/j.artmed.2023.102634},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102634},
  shortjournal = {Artif. Intell. Med.},
  title        = {Adaptive bayesian learning for making risk-aware decisions: A case of trauma survival prediction},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative adversarial networks in electrocardiogram
synthesis: Recent developments and challenges. <em>ARTMED</em>,
<em>143</em>, 102632. (<a
href="https://doi.org/10.1016/j.artmed.2023.102632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training deep neural network classifiers for electrocardiograms (ECGs) requires sufficient data. However, imbalanced datasets pose a major problem for the training process and hence data augmentation is commonly performed. Generative adversarial networks (GANs) can create synthetic ECG data to augment such imbalanced datasets. This review aims at identifying the present literature concerning synthetic ECG signal generation using GANs to provide a comprehensive overview of architectures, quality evaluation metrics , and classification performances. Thirty publications from the years 2019 to 2022 were selected from three separate databases. Nine publications used a quality evaluation metric neglecting classification, eleven performed a classification but omitted a quality evaluation metric, and ten publications performed both. Twenty different quality evaluation metrics were observed. Overall, the classification performance of databases augmented with synthetically created ECG signals increased by 7 % to 98 % in accuracy and 6 % to 97 % in sensitivity. In conclusion, synthetic ECG signal generation using GANs represents a promising tool for data augmentation of imbalanced datasets. Consistent quality evaluation of generated signals remains challenging. Hence, future work should focus on the establishment of a gold standard for quality evaluation metrics for GANs.},
  archive      = {J_ARTMED},
  author       = {Laurenz Berger and Max Haberbusch and Francesco Moscato},
  doi          = {10.1016/j.artmed.2023.102632},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102632},
  shortjournal = {Artif. Intell. Med.},
  title        = {Generative adversarial networks in electrocardiogram synthesis: Recent developments and challenges},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preface: Special issue on knowledge representation and
reasoning for healthcare processes. <em>ARTMED</em>, <em>143</em>,
102631. (<a href="https://doi.org/10.1016/j.artmed.2023.102631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {Francesca Zerbato and Luise Pufahl and Annette Ten Teije},
  doi          = {10.1016/j.artmed.2023.102631},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102631},
  shortjournal = {Artif. Intell. Med.},
  title        = {Preface: Special issue on knowledge representation and reasoning for healthcare processes},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Insight into ADHD diagnosis with deep learning on actimetry:
Quantitative interpretation of occlusion maps in age and gender
subgroups. <em>ARTMED</em>, <em>143</em>, 102630. (<a
href="https://doi.org/10.1016/j.artmed.2023.102630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention Deficit/Hyperactivity Disorder (ADHD) is a prevalent neurodevelopmental disorder in childhood that often persists into adulthood. Objectively diagnosing ADHD can be challenging due to the reliance on subjective questionnaires in clinical assessment. Fortunately, recent advancements in artificial intelligence (AI) have shown promise in providing objective diagnoses through the analysis of medical images or activity recordings. These AI-based techniques have demonstrated accurate ADHD diagnosis; however, the growing complexity of deep learning models has introduced a lack of interpretability. These models often function as black boxes, unable to offer meaningful insights into the data patterns that characterize ADHD. This paper proposes a methodology to interpret the output of an AI-based diagnosis system for combined ADHD in age and gender-stratified populations. Our system is based on the analysis of 24 hour-long activity records using Convolutional Neural Networks (CNNs) to classify spectrograms of activity windows. These windows are interpreted using occlusion maps to highlight the time–frequency patterns explaining ADHD activity. Significant differences in the frequency patterns between ADHD and controls both in diurnal and nocturnal activity were found for all the populations. Temporal dispersion also presented differences in the male population. The proposed interpretation techniques for CNNs highlighted gender- and age-related differences between ADHD patients and controls. Leveraging these differences could potentially lead to improved diagnostic accuracy, especially if a larger and more balanced dataset is utilized. Our findings pave the way for the development of an AI-based diagnosis system for ADHD that offers interpretability, thereby providing valuable insights into the underlying etiology of the disease.},
  archive      = {J_ARTMED},
  author       = {Patricia Amado-Caballero and Pablo Casaseca-de-la-Higuera and Susana Alberola-López and Jesús María Andrés-de-Llano and José Antonio López-Villalobos and Carlos Alberola-López},
  doi          = {10.1016/j.artmed.2023.102630},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102630},
  shortjournal = {Artif. Intell. Med.},
  title        = {Insight into ADHD diagnosis with deep learning on actimetry: Quantitative interpretation of occlusion maps in age and gender subgroups},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learnable DoG convolutional filters for microcalcification
detection. <em>ARTMED</em>, <em>143</em>, 102629. (<a
href="https://doi.org/10.1016/j.artmed.2023.102629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Difference of Gaussians (DoG) convolutional filters are one of the earliest image processing methods employed for detecting microcalcifications on mammogram images before machine and deep learning methods became widespread. DoG is a blob enhancement filter that consists in subtracting one Gaussian-smoothed version of an image from another less Gaussian-smoothed version of the same image. Smoothing with a Gaussian kernel suppresses high-frequency spatial information, thus DoG can be regarded as a band-pass filter. However, due to their small size and overimposed breast tissue, microcalcifications vary greatly in contrast-to-noise ratio and sharpness. This makes it difficult to find a single DoG configuration that enhances all microcalcifications. In this work, we propose a convolutional network, named DoG-MCNet, where the first layer automatically learns a bank of DoG filters parameterized by their associated standard deviations. We experimentally show that when employed for microcalcification detection, our DoG layer acts as a learnable bank of band-pass preprocessing filters and improves detection performance by 4.86% AUFROC over baseline MCNet and 1.53% AUFROC over state-of-the-art multicontext ensemble of CNNs .},
  archive      = {J_ARTMED},
  author       = {Marco Cantone and Claudio Marrocco and Francesco Tortorella and Alessandro Bria},
  doi          = {10.1016/j.artmed.2023.102629},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102629},
  shortjournal = {Artif. Intell. Med.},
  title        = {Learnable DoG convolutional filters for microcalcification detection},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Malignant mesothelioma subtyping via sampling driven
multiple instance prediction on tissue image and cell morphology data.
<em>ARTMED</em>, <em>143</em>, 102628. (<a
href="https://doi.org/10.1016/j.artmed.2023.102628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malignant Mesothelioma is a difficult to diagnose and highly lethal cancer usually associated with asbestos exposure. It can be broadly classified into three subtypes: Epithelioid, Sarcomatoid, and a hybrid Biphasic subtype in which significant components of both of the previous subtypes are present. Early diagnosis and identification of the subtype informs treatment and can help improve patient outcome. However, the subtyping of malignant mesothelioma, and specifically the recognition of transitional features from routine histology slides has a high level of inter-observer variability. In this work, we propose an end-to-end multiple instance learning (MIL) approach for malignant mesothelioma subtyping. This uses an adaptive instance-based sampling scheme for training deep convolutional neural networks on bags of image patches that allows learning on a wider range of relevant instances compared to max or top-N based MIL approaches. We also investigate augmenting the instance representation to include aggregate cellular morphology features from cell segmentation. The proposed MIL approach enables identification of malignant mesothelial subtypes of specific tissue regions. From this a continuous characterisation of a sample according to predominance of sarcomatoid vs epithelioid regions is possible, thus avoiding the arbitrary and highly subjective categorisation by currently used subtypes. Instance scoring also enables studying tumor heterogeneity and identifying patterns associated with different subtypes. We have evaluated the proposed method on a dataset of 234 tissue micro-array cores with an AUROC of 0 . 89 ± 0 . 05 0.89±0.05 for this task. The dataset and developed methodology is available for the community at: https://github.com/measty/PINS .},
  archive      = {J_ARTMED},
  author       = {Mark Eastwood and Silviu Tudor Marc and Xiaohong Gao and Heba Sailem and Judith Offman and Emmanouil Karteris and Angeles Montero Fernandez and Danny Jonigk and William Cookson and Miriam Moffatt and Sanjay Popat and Fayyaz Minhas and Jan Lukas Robertus},
  doi          = {10.1016/j.artmed.2023.102628},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102628},
  shortjournal = {Artif. Intell. Med.},
  title        = {Malignant mesothelioma subtyping via sampling driven multiple instance prediction on tissue image and cell morphology data},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel fuzzy deep learning approach for automated detection
of useful COVID-19 tweets. <em>ARTMED</em>, <em>143</em>, 102627. (<a
href="https://doi.org/10.1016/j.artmed.2023.102627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus (COVID-19) is a newly discovered viral disease from the SARS-CoV-2 family. This has caused a moral panic resulting in the spread of informative and uninformative information about COVID-19 and its effects. Twitter is a popular social media platform used extensively during the current outbreak. This paper aims to predict informative tweets related to COVID-19 on Twitter using a novel set of fuzzy rules involving deep learning techniques. This study focuses on identifying informative tweets during the pandemic to provide the public with trustworthy information and forecast how quickly diseases could spread. In this case, we have implemented RoBERTa and CT-BERT models using the fuzzy methodology to identify COVID-19 patient tweets. The proposed architecture combines deep learning transformer models RoBERTa and CT-BERT with the fuzzy technique to categorize posts as INFORMATIVE or UNINFORMATIVE. We performed a comparative analysis of our method with machine learning models and deep learning approaches. The results show that our proposed model can classify informative and uninformative tweets with an accuracy of 91.40% and an F1-score of 91.94% using the COVID-19 English tweet dataset. The proposed model is accurate and ready for real-world application.},
  archive      = {J_ARTMED},
  author       = {SreeJagadeesh Malla and Lella Kranthi Kumar and P.J.A. Alphonse},
  doi          = {10.1016/j.artmed.2023.102627},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102627},
  shortjournal = {Artif. Intell. Med.},
  title        = {Novel fuzzy deep learning approach for automated detection of useful COVID-19 tweets},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Applying dual models on optimized LSTM with u-net
segmentation for breast cancer diagnosis using mammogram images.
<em>ARTMED</em>, <em>143</em>, 102626. (<a
href="https://doi.org/10.1016/j.artmed.2023.102626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the most fatal disease that widely affects women. When the cancerous lumps grow from the cells of the breast, it causes breast cancer. Self-analysis and regular medical check-ups help for detecting the disease earlier and enhance the survival rate . Hence, an automated breast cancer detection system in mammograms can assist clinicians in the patient&#39;s treatment. In medical techniques, the categorization of breast cancer becomes challenging for investigators and researchers. The advancement in deep learning approaches has established more attention to their advantages to medical imaging issues, especially for breast cancer detection. The research work plans to develop a novel hybrid model for breast cancer diagnosis with the support of optimized deep-learning architecture. The required images are gathered from the benchmark datasets. These collected datasets are used in three pre-processing approaches like “Median Filtering, Histogram Equalization, and morphological operation”, which helps to remove unwanted regions from the images. Then, the pre-processed images are applied to the Optimized U-net-based tumor segmentation phase for obtaining accurate segmented results along with the optimization of certain parameters in U-Net by employing “Adapted-Black Widow Optimization (A-BWO)”. Further, the detection is performed in two different ways that is given as model 1 and model 2. In model 1, the segmented tumors are used to extract the significant patterns with the help of the “Gray-Level Co-occurrence Matrix (GLCM) and Local Gradient pattern (LGP)”. Further, these extracted patterns are utilized in the “Dual Model accessed Optimized Long Short-Term Memory (DM-OLSTM)” for performing breast cancer detection and the detected score 1 is obtained. In model 2, the same segmented tumors are given into the different variants of CNN , such as “VGG19, Resnet150, and Inception”. The extracted deep features from three CNN-based approaches are fused to form a single set of deep features. These fused deep features are inserted into the developed DM-OLSTM for getting the detected score 2 for breast cancer diagnosis. In the final phase of the hybrid model, the score 1 and score 2 obtained from model 1 and model 2 are averaged to get the final detection output. The accuracy and F1-score of the offered DM-OLSTM model are achieved at 96 % and 95 %. Experimental analysis proves that the recommended methodology achieves better performance by analyzing with the benchmark dataset. Hence, the designed model is helpful for detecting breast cancer in real-time applications.},
  archive      = {J_ARTMED},
  author       = {J. Sivamurugan and G. Sureshkumar},
  doi          = {10.1016/j.artmed.2023.102626},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102626},
  shortjournal = {Artif. Intell. Med.},
  title        = {Applying dual models on optimized LSTM with U-net segmentation for breast cancer diagnosis using mammogram images},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformers for extracting breast cancer information from
spanish clinical narratives. <em>ARTMED</em>, <em>143</em>, 102625. (<a
href="https://doi.org/10.1016/j.artmed.2023.102625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide adoption of electronic health records (EHRs) offers immense potential as a source of support for clinical research . However, previous studies focused on extracting only a limited set of medical concepts to support information extraction in the cancer domain for the Spanish language . Building on the success of deep learning for processing natural language texts, this paper proposes a transformer-based approach to extract named entities from breast cancer clinical notes written in Spanish and compares several language models . To facilitate this approach, a schema for annotating clinical notes with breast cancer concepts is presented, and a corpus for breast cancer is developed. Results indicate that both BERT-based and RoBERTa-based language models demonstrate competitive performance in clinical Named Entity Recognition (NER). Specifically, BETO and multilingual BERT achieve F-scores of 93.71% and 94.63%, respectively. Additionally, RoBERTa Biomedical attains an F-score of 95.01%, while RoBERTa BNE achieves an F-score of 94.54%. The findings suggest that transformers can feasibly extract information in the clinical domain in the Spanish language, with the use of models trained on biomedical texts contributing to enhanced results. The proposed approach takes advantage of transfer learning techniques by fine-tuning language models to automatically represent text features and avoiding the time-consuming feature engineering process.},
  archive      = {J_ARTMED},
  author       = {Oswaldo Solarte-Pabón and Orlando Montenegro and Alvaro García-Barragán and Maria Torrente and Mariano Provencio and Ernestina Menasalvas and Víctor Robles},
  doi          = {10.1016/j.artmed.2023.102625},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102625},
  shortjournal = {Artif. Intell. Med.},
  title        = {Transformers for extracting breast cancer information from spanish clinical narratives},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ADscreen: A speech processing-based screening system for
automatic identification of patients with alzheimer’s disease and
related dementia. <em>ARTMED</em>, <em>143</em>, 102624. (<a
href="https://doi.org/10.1016/j.artmed.2023.102624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s disease and related dementias (ADRD) present a looming public health crisis, affecting roughly 5 million people and 11 % of older adults in the United States. Despite nationwide efforts for timely diagnosis of patients with ADRD, &gt;50 % of them are not diagnosed and unaware of their disease. To address this challenge, we developed ADscreen, an innovative speech-processing based ADRD screening algorithm for the protective identification of patients with ADRD. ADscreen consists of five major components: (i) noise reduction for reducing background noises from the audio-recorded patient speech, (ii) modeling the patient&#39;s ability in phonetic motor planning using acoustic parameters of the patient&#39;s voice, (iii) modeling the patient&#39;s ability in semantic and syntactic levels of language organization using linguistic parameters of the patient speech, (iv) extracting vocal and semantic psycholinguistic cues from the patient speech, and (v) building and evaluating the screening algorithm. To identify important speech parameters (features) associated with ADRD, we used the Joint Mutual Information Maximization (JMIM), an effective feature selection method for high dimensional, small sample size datasets. Modeling the relationship between speech parameters and the outcome variable (presence/absence of ADRD) was conducted using three different machine learning (ML) architectures with the capability of joining informative acoustic and linguistic with contextual word embedding vectors obtained from the DistilBERT (Bidirectional Encoder Representations from Transformers). We evaluated the performance of the ADscreen on an audio-recorded patients&#39; speech (verbal description) for the Cookie-Theft picture description task, which is publicly available in the dementia databank. The joint fusion of acoustic and linguistic parameters with contextual word embedding vectors of DistilBERT achieved F1-score = 84.64 (standard deviation [std] = ±3.58) and AUC-ROC = 92.53 (std = ±3.34) for training dataset, and F1-score = 89.55 and AUC-ROC = 93.89 for the test dataset. In summary, ADscreen has a strong potential to be integrated with clinical workflow to address the need for an ADRD screening tool so that patients with cognitive impairment can receive appropriate and timely care.},
  archive      = {J_ARTMED},
  author       = {Maryam Zolnoori and Ali Zolnour and Maxim Topaz},
  doi          = {10.1016/j.artmed.2023.102624},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102624},
  shortjournal = {Artif. Intell. Med.},
  title        = {ADscreen: A speech processing-based screening system for automatic identification of patients with alzheimer&#39;s disease and related dementia},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). In memoriam david riaño, 1968–2022. <em>ARTMED</em>,
<em>143</em>, 102623. (<a
href="https://doi.org/10.1016/j.artmed.2023.102623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {Annette ten Teije and Mar Marcos and Jose M. Juarez},
  doi          = {10.1016/j.artmed.2023.102623},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102623},
  shortjournal = {Artif. Intell. Med.},
  title        = {In memoriam david riaño, 1968–2022},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cause of death estimation from verbal autopsies: Is the open
response redundant or synergistic? <em>ARTMED</em>, <em>143</em>,
102622. (<a href="https://doi.org/10.1016/j.artmed.2023.102622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Civil registration and vital statistics systems capture birth and death events to compile vital statistics and to provide legal rights to citizens. Vital statistics are a key factor in promoting public health policies and the health of the population. Medical certification of cause of death is the preferred source of cause of death information. However, two thirds of all deaths worldwide are not captured in routine mortality information systems and their cause of death is unknown. Verbal autopsy is an interim solution for estimating the cause of death distribution at the population level in the absence of medical certification. A Verbal Autopsy (VA) consists of an interview with the relative or the caregiver of the deceased. The VA includes both Closed Questions (CQs) with structured answer options, and an Open Response (OR) consisting of a free narrative of the events expressed in natural language and without any pre-determined structure. There are a number of automated systems to analyze the CQs to obtain cause specific mortality fractions with limited performance. We hypothesize that the incorporation of the text provided by the OR might convey relevant information to discern the CoD. The experimental layout compares existing Computer Coding Verbal Autopsy methods such as Tariff 2.0 with other approaches well suited to the processing of structured inputs as is the case of the CQs. Next, alternative approaches based on language models are employed to analyze the OR. Finally, we propose a new method with a bi-modal input that combines the CQs and the OR. Empirical results corroborated that the CoD prediction capability of the Tariff 2.0 algorithm is outperformed by our method taking into account the valuable information conveyed by the OR. As an added value , with this work we made available the software to enable the reproducibility of the results attained with a version implemented in R to make the comparison with Tariff 2.0 evident.},
  archive      = {J_ARTMED},
  author       = {Ander Cejudo and Arantza Casillas and Alicia Pérez and Maite Oronoz and Daniel Cobos},
  doi          = {10.1016/j.artmed.2023.102622},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102622},
  shortjournal = {Artif. Intell. Med.},
  title        = {Cause of death estimation from verbal autopsies: Is the open response redundant or synergistic?},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An idiosyncratic MIMBO-NBRF based automated system for child
birth mode prediction. <em>ARTMED</em>, <em>143</em>, 102621. (<a
href="https://doi.org/10.1016/j.artmed.2023.102621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the mode of child birth is still remains one of the most complex and challenging tasks in ancient times. Also, there is no such strong methodologies are developed in the conventional works for birth mode prediction. Therefore, the proposed work objects to develop a novel and distinct optimization based machine learning technique for creating the child birth mode prediction system. This framework includes the modules of data imputation, feature selection, classification, and prediction. Initially, the data imputation process is performed to improve the quality of dataset by normalizing the attributes and filling the missed fields. Then, the Multivariate Intensified Mine Blast Optimization (MIMBO) technique is implemented to choose the best set of features by estimating the optimal function. After that, an integrated Naïve Bayes – Random Forest (NBRF) technique is developed by incorporating the functions of conventional NB and RF techniques. The novel contribution of this technique, a Bird Mating (BM) optimization technique is used in NBRF classifier for estimating the likelihood parameter to generate the Bayesian rules. The main idea of this paper is to develop a simple as well as efficient automated system with the use of hybrid machine learning model for predicting the mode of child birth. For this purpose, advanced algorithms such as MIMBO based feature selection, and NBRF based classification are implemented in this work. Due to the inclusion of MIMBO and BM optimization techniques, the performance of classifier is greatly improved with low computational burden and increased prediction accuracy. Moreover, the combination of proposed MIMBO-NBRF technique outperforms the existing child birth prediction methods with superior results in terms of average accuracy up to 99 %. In addition, some other parameters are also estimated and compared with the existing techniques for proving the overall superiority of the proposed framework.},
  archive      = {J_ARTMED},
  author       = {Hemalatha S. and Maria Anu V.},
  doi          = {10.1016/j.artmed.2023.102621},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102621},
  shortjournal = {Artif. Intell. Med.},
  title        = {An idiosyncratic MIMBO-NBRF based automated system for child birth mode prediction},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Personalized event prediction for electronic health records.
<em>ARTMED</em>, <em>143</em>, 102620. (<a
href="https://doi.org/10.1016/j.artmed.2023.102620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical event sequences consist of hundreds of clinical events that represent records of patient care in time. Developing accurate predictive models of such sequences is of a great importance for supporting a variety of models for interpreting/classifying the current patient condition, or predicting adverse clinical events and outcomes, all aimed to improve patient care. One important challenge of learning predictive models of clinical sequences is their patient-specific variability. Based on underlying clinical conditions, each patient’s sequence may consist of different sets of clinical events (observations, lab results, medications, procedures). Hence, simple population-wide models learned from event sequences for many different patients may not accurately predict patient-specific dynamics of event sequences and their differences. To address the problem, we propose and investigate multiple new event sequence prediction models and methods that let us better adjust the prediction for individual patients and their specific conditions. The methods developed in this work pursue refinement of population-wide models to subpopulations, self-adaptation, and a meta-level model switching that is able to adaptively select the model with the best chance to support the immediate prediction. We analyze and test the performance of these models on clinical event sequences of patients in MIMIC-III database.},
  archive      = {J_ARTMED},
  author       = {Jeong Min Lee and Milos Hauskrecht},
  doi          = {10.1016/j.artmed.2023.102620},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102620},
  shortjournal = {Artif. Intell. Med.},
  title        = {Personalized event prediction for electronic health records},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-invasive localization of the ventricular excitation
origin without patient-specific geometries using deep learning.
<em>ARTMED</em>, <em>143</em>, 102619. (<a
href="https://doi.org/10.1016/j.artmed.2023.102619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases account for 17 million deaths per year worldwide. Of these, 25% are categorized as sudden cardiac death , which can be related to ventricular tachycardia (VT). This type of arrhythmia can be caused by focal activation sources outside the sinus node . Catheter ablation of these foci is a curative treatment in order to inactivate the abnormal triggering activity. However, the localization procedure is usually time-consuming and requires an invasive procedure in the catheter lab. To facilitate and expedite the treatment, we present two novel localization support techniques based on convolutional neural networks (CNNs) that address these clinical needs. In contrast to existing methods, our approaches were designed to be independent of the patient-specific geometry and directly applicable to surface ECG signals, while also delivering a binary transmural position. Moreover, one of the method’s outputs can be interpreted as several ranked solutions. The CNNs were trained on a dataset containing only simulated data and evaluated both on simulated test data and clinical data. On a novel large and open simulated dataset, the median test error was below 3 mm. The median localization error on the unseen clinical data ranged from 32 mm to 41 mm without optimizing the pre-processing and CNN to the clinical data. Interpreting the output of one of the approaches as ranked solutions, the best median error of the top-3 solutions decreased to 20 mm on the clinical data. The transmural position was correctly detected in up to 82% of all clinical cases. These results demonstrate a proof of principle to utilize CNNs to localize the activation source without the intrinsic need for patient-specific geometrical information. Furthermore, providing multiple solutions can assist physicians in identifying the true activation source amongst more than one possible location. With further optimization to clinical data, these methods have high potential to accelerate clinical interventions, replace certain steps within these procedures and consequently reduce procedural risk and improve VT patient outcomes.},
  archive      = {J_ARTMED},
  author       = {Nicolas Pilia and Steffen Schuler and Maike Rees and Gerald Moik and Danila Potyagaylo and Olaf Dössel and Axel Loewe},
  doi          = {10.1016/j.artmed.2023.102619},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102619},
  shortjournal = {Artif. Intell. Med.},
  title        = {Non-invasive localization of the ventricular excitation origin without patient-specific geometries using deep learning},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monkeypox diagnosis using ensemble classification.
<em>ARTMED</em>, <em>143</em>, 102618. (<a
href="https://doi.org/10.1016/j.artmed.2023.102618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world has recently been exposed to a fierce attack from many viral diseases , such as Covid-19, that exhausted medical systems around the world. Such attack had a negative impact not only on the health status of people or the high death rate , but also had a bad impact on the economic situation, which affected all countries of the world especially the poor and the developing ones. Monkeypox is one of the latest viral diseases that may cause a pandemic in the near future if not dealt and diagnosed with appropriately. This paper provides a new strategy for diagnosing monkeypox, which is called; Accurate Monkeypox Diagnosing Strategy (AMDS). The proposed AMDS consists of two phases, which are; (i) pre-processing and (ii) classification. During the pre-processing phase, the most effective feature are selected using Binary Tiki-Taka Algorithm (BTTA). On the other hand, in the classification phase , ensemble classification is used for diagnosing new cases, which combines evidence from three different new classifiers, namely; (a) Layered K-Nearest Neighbors (LKNN), (b) Statistical Naïve Bayes (SNB), and (c) Deep Learning Classifier (DLC). Moreover, the decisions of the proposed classifiers are merged in a new voting scheme called Fuzzified Voting Scheme (FVS). AMDS has been compared against recent diagnostic strategies. Experimental results have proven that AMDS outperforms other monkeypox diagnostic strategies as it introduces the most accurate diagnosis according to two different datasets.},
  archive      = {J_ARTMED},
  author       = {Asmaa H. Rabie and Ahmed I. Saleh},
  doi          = {10.1016/j.artmed.2023.102618},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102618},
  shortjournal = {Artif. Intell. Med.},
  title        = {Monkeypox diagnosis using ensemble classification},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic literature review of machine learning based
risk prediction models for diabetic retinopathy progression.
<em>ARTMED</em>, <em>143</em>, 102617. (<a
href="https://doi.org/10.1016/j.artmed.2023.102617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Retinopathy (DR) is the most popular debilitating impairment of diabetes and it progresses symptom-free until a sudden loss of vision occurs. Understanding the progression of DR is a pressing issue in clinical research and practice. In this systematic review of articles on Machine Learning (ML) based risk prediction models for DR progression, ever since the use of Artificial Intelligence (AI) for DR detection, there have been more cross-sectional studies with different algorithms of use of AI, there haven&#39;t been many longitudinal studies for the AI based risk prediction models. This paper proposes a novel review to fill in the gaps identified in current reviews and facilitate other researchers with current research solutions for developing AI-based risk prediction models for DR progression and closely related problems; synthesize the current results from these studies and identify research challenges, limitations and gaps to inform the selection of machine learning techniques and predictors to build novel prediction models. Additionally, this paper suggested six (6) deep AI-related technical and critical discussion of the adopted strategies and approaches. The Systematic Literature Review (SLR) methodology was employed to gather relevant studies. We searched IEEE Xplore, PubMed , Springer Link , Google Scholar, and Science Direct electronic databases for papers published from January 2017 to 30th April 2023. Thirteen (13) studies were chosen on the basis of their relevance to the review questions and satisfying the selection criteria. However, findings from the literature review exposed some critical research gaps that need to be addressed in future research to improve on the performance of risk prediction models for DR progression.},
  archive      = {J_ARTMED},
  author       = {Tiwalade Modupe Usman and Yakub Kayode Saheed PhD and Augustine Nsang PhD and Abel Ajibesin PhD and Sandip Rakshit PhD},
  doi          = {10.1016/j.artmed.2023.102617},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102617},
  shortjournal = {Artif. Intell. Med.},
  title        = {A systematic literature review of machine learning based risk prediction models for diabetic retinopathy progression},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How does the model make predictions? A systematic literature
review on the explainability power of machine learning in healthcare.
<em>ARTMED</em>, <em>143</em>, 102616. (<a
href="https://doi.org/10.1016/j.artmed.2023.102616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical use cases for machine learning (ML) are growing exponentially. The first hospitals are already using ML systems as decision support systems in their daily routine. At the same time, most ML systems are still opaque and it is not clear how these systems arrive at their predictions. In this paper, we provide a brief overview of the taxonomy of explainability methods and review popular methods. In addition, we conduct a systematic literature search on PubMed to investigate which explainable artificial intelligence (XAI) methods are used in 450 specific medical supervised ML use cases, how the use of XAI methods has emerged recently, and how the precision of describing ML pipelines has evolved over the past 20 years. A large fraction of publications with ML use cases do not use XAI methods at all to explain ML predictions. However, when XAI methods are used, open-source and model-agnostic explanation methods are more commonly used, with SHapley Additive exPlanations (SHAP) and Gradient Class Activation Mapping (Grad-CAM) for tabular and image data leading the way. ML pipelines have been described in increasing detail and uniformity in recent years. However, the willingness to share data and code has stagnated at about one-quarter. XAI methods are mainly used when their application requires little effort. The homogenization of reports in ML use cases facilitates the comparability of work and should be advanced in the coming years. Experts who can mediate between the worlds of informatics and medicine will become more and more in demand when using ML systems due to the high complexity of the domain.},
  archive      = {J_ARTMED},
  author       = {Johannes Allgaier and Lena Mulansky and Rachel Lea Draelos and Rüdiger Pryss},
  doi          = {10.1016/j.artmed.2023.102616},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102616},
  shortjournal = {Artif. Intell. Med.},
  title        = {How does the model make predictions? a systematic literature review on the explainability power of machine learning in healthcare},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CEHMR: Curriculum learning enhanced hierarchical multi-label
classification for medication recommendation. <em>ARTMED</em>,
<em>143</em>, 102613. (<a
href="https://doi.org/10.1016/j.artmed.2023.102613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The medication recommendation (MR) or medication combination prediction task aims to predict effective prescriptions given accurate patient representations derived from electronic health records (EHRs), which contributes to improving the quality of clinical decision-making, especially for patients with multi-morbidity. Although in recent years deep learning technology has achieved great success in MR, the performance of current multi-label based MR solutions is unsatisfactory. They mainly focus on improving the patient representation module and modeling the medication label dependencies such as drug–drug interaction (DDI) correlation and co-occurrence relationship. However, the hierarchical dependency among medication labels and diversity of difficulty among MR training examples lack sufficient consideration. In this paper, we propose a framework of Curriculum learning Enhanced Hierarchical multi-label classification for MR (CEHMR). Motivated by the category hierarchy of medications which organizes standard medication codes in a hierarchical structure, we utilize it to provide more trustworthy prior knowledge for modeling label dependency. Specifically, we design a hierarchical multi-label classifier with a learnable gate fusion layer, to simultaneously capture the level-independent (local) and level-dependent (global) hierarchical information in the medication hierarchy. In addition, to overcome the diversity of training example difficulties, and progressively achieve a smoother training process, we introduce a bootstrap-based curriculum learning strategy. Hence, the example difficulty can be measured based on the predictive performance of the MR model, and then all training examples would be retrained from easy to hard under the guidance of a predefined training scheduler. Experiments on the real-world medical MIMIC-III database demonstrate that the proposed framework can achieve state-of-the-art performance compared with seven representative baselines, and extensive ablation studies validate the effectiveness of each component of CEHMR.},
  archive      = {J_ARTMED},
  author       = {Mengxuan Sun and Jinghao Niu and Xuebing Yang and Yifan Gu and Wensheng Zhang},
  doi          = {10.1016/j.artmed.2023.102613},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102613},
  shortjournal = {Artif. Intell. Med.},
  title        = {CEHMR: Curriculum learning enhanced hierarchical multi-label classification for medication recommendation},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A diagnostic room for lower limb amputee based on virtual
reality and an intelligent space. <em>ARTMED</em>, <em>143</em>, 102612.
(<a href="https://doi.org/10.1016/j.artmed.2023.102612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a virtual reality (VR) system for diagnosing and rehabilitating lower limb amputees. A virtual environment and an intelligent space are the basis of the proposed solution. The target audiences are physiotherapists and doctors, and the aim is to provide a VR-based system to allow visualization and analysis of gait parameters and conformity. The multi-camera system from the intelligent space acquires images from patients during gait. This way, it is possible to generate tridimensional information for the VR-based system. Among the provided functionalities, the user can explore the virtual environment and manage several features, such as gait reproduction and parameters displayed, using a head-mounted display and hand controllers . Besides, the system presents an automatic classifier that can assist physiotherapists and doctors in assessing abnormalities from conventional human gait. We evaluate the system through two quantitative experiments. The first one addresses the performance evaluation of the automatic classifier. The second analysis is through a Likert scale questionnaire submitted to a group of physiotherapists. In this case, the specialists evaluate the existing features of the proposed framework. The results from the questionnaire showed that the virtual environment is suitable for helping track patients’ rehabilitation. Also, the neural network-based classifier results are promising, averaging higher than 91% for all evaluation metrics . Finally, a comparison with related works in the literature highlights the contributions of the proposed solution to the field.},
  archive      = {J_ARTMED},
  author       = {Pablo P. e Silva and Wyctor F. da Rocha and Luiza E.V.N. Mazzoni and Rafhael M. de Andrade and Antônio Bento and Mariana Rampinelli and Douglas Almonfrey},
  doi          = {10.1016/j.artmed.2023.102612},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102612},
  shortjournal = {Artif. Intell. Med.},
  title        = {A diagnostic room for lower limb amputee based on virtual reality and an intelligent space},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Medical visual question answering: A survey.
<em>ARTMED</em>, <em>143</em>, 102611. (<a
href="https://doi.org/10.1016/j.artmed.2023.102611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical Visual Question Answering (VQA) is a combination of medical artificial intelligence and popular VQA challenges. Given a medical image and a clinically relevant question in natural language, the medical VQA system is expected to predict a plausible and convincing answer. Although the general-domain VQA has been extensively studied, the medical VQA still needs specific investigation and exploration due to its task features. In the first part of this survey, we collect and discuss the publicly available medical VQA datasets up-to-date about the data source , data quantity, and task feature. In the second part, we review the approaches used in medical VQA tasks. We summarize and discuss their techniques, innovations, and potential improvements. In the last part, we analyze some medical-specific challenges for the field and discuss future research directions. Our goal is to provide comprehensive and helpful information for researchers interested in the medical visual question answering field and encourage them to conduct further research in this field.},
  archive      = {J_ARTMED},
  author       = {Zhihong Lin and Donghao Zhang and Qingyi Tao and Danli Shi and Gholamreza Haffari and Qi Wu and Mingguang He and Zongyuan Ge},
  doi          = {10.1016/j.artmed.2023.102611},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102611},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical visual question answering: A survey},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence framework with traditional computer
vision and deep learning approaches for optimal automatic segmentation
of left ventricle with scar. <em>ARTMED</em>, <em>143</em>, 102610. (<a
href="https://doi.org/10.1016/j.artmed.2023.102610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation of the cardiac left ventricle with scars remains a challenging and clinically significant task, as it is essential for patient diagnosis and treatment pathways. This study aimed to develop a novel framework and cost function to achieve optimal automatic segmentation of the left ventricle with scars using LGE-MRI images. To ensure the generalization of the framework, an unbiased validation protocol was established using out-of-distribution (OOD) internal and external validation cohorts, and intra-observation and inter-observer variability ground truths. The framework employs a combination of traditional computer vision techniques and deep learning , to achieve optimal segmentation results. The traditional approach uses multi-atlas techniques, active contours , and k-means methods, while the deep learning approach utilizes various deep learning techniques and networks. The study found that the traditional computer vision technique delivered more accurate results than deep learning, except in cases where there was breath misalignment error. The optimal solution of the framework achieved robust and generalized results with Dice scores of 82.8 ± 6.4% and 72.1 ± 4.6% in the internal and external OOD cohorts, respectively. The developed framework offers a high-performance solution for automatic segmentation of the left ventricle with scars using LGE-MRI. Unlike existing state-of-the-art approaches, it achieves unbiased results across different hospitals and vendors without the need for training or tuning in hospital cohorts. This framework offers a valuable tool for experts to accomplish the task of fully automatic segmentation of the left ventricle with scars based on a single-modality cardiac scan.},
  archive      = {J_ARTMED},
  author       = {Michail Mamalakis and Pankaj Garg and Tom Nelson and Justin Lee and Andrew J. Swift and James M. Wild and Richard H. Clayton},
  doi          = {10.1016/j.artmed.2023.102610},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102610},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence framework with traditional computer vision and deep learning approaches for optimal automatic segmentation of left ventricle with scar},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MLNAN: Multi-level noise-aware network for low-dose CT
imaging implemented with constrained cycle wasserstein generative
adversarial networks. <em>ARTMED</em>, <em>143</em>, 102609. (<a
href="https://doi.org/10.1016/j.artmed.2023.102609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-dose CT techniques attempt to minimize the radiation exposure of patients by estimating the high-resolution normal-dose CT images to reduce the risk of radiation-induced cancer. In recent years, many deep learning methods have been proposed to solve this problem by building a mapping function between low-dose CT images and their high-dose counterparts. However, most of these methods ignore the effect of different radiation doses on the final CT images, which results in large differences in the intensity of the noise observable in CT images. What’more, the noise intensity of low-dose CT images exists significantly differences under different medical devices manufacturers . In this paper, we propose a multi-level noise-aware network (MLNAN) implemented with constrained cycle Wasserstein generative adversarial networks to recovery the low-dose CT images under uncertain noise levels. Particularly, the noise-level classification is predicted and reused as a prior pattern in generator networks. Moreover, the discriminator network introduces noise-level determination. Under two dose-reduction strategies, experiments to evaluate the performance of proposed method are conducted on two datasets, including the simulated clinical AAPM challenge datasets and commercial CT datasets from United Imaging Healthcare (UIH). The experimental results illustrate the effectiveness of our proposed method in terms of noise suppression and structural detail preservation compared with several other deep-learning based methods. Ablation studies validate the effectiveness of the individual components regarding the afforded performance improvement. Further research for practical clinical applications and other medical modalities is required in future works.},
  archive      = {J_ARTMED},
  author       = {Zhenxing Huang and Wenbo Li and Yunling Wang and Zhou Liu and Qiyang Zhang and Yuxi Jin and Ruodai Wu and Guotao Quan and Dong Liang and Zhanli Hu and Na Zhang},
  doi          = {10.1016/j.artmed.2023.102609},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102609},
  shortjournal = {Artif. Intell. Med.},
  title        = {MLNAN: Multi-level noise-aware network for low-dose CT imaging implemented with constrained cycle wasserstein generative adversarial networks},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review on deep learning fetal brain segmentation from
magnetic resonance images. <em>ARTMED</em>, <em>143</em>, 102608. (<a
href="https://doi.org/10.1016/j.artmed.2023.102608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain segmentation is often the first and most critical step in quantitative analysis of the brain for many clinical applications, including fetal imaging. Different aspects challenge the segmentation of the fetal brain in magnetic resonance imaging (MRI), such as the non-standard position of the fetus owing to his/her movements during the examination, rapid brain development, and the limited availability of imaging data. In recent years, several segmentation methods have been proposed for automatically partitioning the fetal brain from MR images. These algorithms aim to define regions of interest with different shapes and intensities, encompassing the entire brain, or isolating specific structures. Deep learning techniques, particularly convolutional neural networks (CNNs), have become a state-of-the-art approach in the field because they can provide reliable segmentation results over heterogeneous datasets. Here, we review the deep learning algorithms developed in the field of fetal brain segmentation and categorize them according to their target structures. Finally, we discuss the perceived research gaps in the literature of the fetal domain, suggesting possible future research directions that could impact the management of fetal MR images.},
  archive      = {J_ARTMED},
  author       = {Tommaso Ciceri and Letizia Squarcina and Alice Giubergia and Alessandra Bertoldo and Paolo Brambilla and Denis Peruzzo},
  doi          = {10.1016/j.artmed.2023.102608},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102608},
  shortjournal = {Artif. Intell. Med.},
  title        = {Review on deep learning fetal brain segmentation from magnetic resonance images},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FDA-approved machine learning algorithms in neuroradiology:
A systematic review of the current evidence for approval.
<em>ARTMED</em>, <em>143</em>, 102607. (<a
href="https://doi.org/10.1016/j.artmed.2023.102607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, machine learning (ML) and artificial intelligence (AI) have become increasingly prevalent in the medical field. In the United States, the Food and Drug Administration (FDA) is responsible for regulating AI algorithms as “medical devices” to ensure patient safety . However, recent work has shown that the FDA approval process may be deficient. In this study, we evaluate the evidence supporting FDA-approved neuroalgorithms, the subset of machine learning algorithms with applications in the central nervous system (CNS), through a systematic review of the primary literature. Articles covering the 53 FDA-approved algorithms with applications in the CNS published in PubMed, EMBASE, Google Scholar and Scopus between database inception and January 25, 2022 were queried. Initial searches identified 1505 studies, of which 92 articles met the criteria for extraction and inclusion. Studies were identified for 26 of the 53 neuroalgorithms, of which 10 algorithms had only a single peer-reviewed publication. Performance metrics were available for 15 algorithms, external validation studies were available for 24 algorithms, and studies exploring the use of algorithms in clinical practice were available for 7 algorithms. Papers studying the clinical utility of these algorithms focused on three domains: workflow efficiency, cost savings, and clinical outcomes. Our analysis suggests that there is a meaningful gap between the FDA approval of machine learning algorithms and their clinical utilization. There appears to be room for process improvement by implementation of the following recommendations: the provision of compelling evidence that algorithms perform as intended, mandating minimum sample sizes, reporting of a predefined set of performance metrics for all algorithms and clinical application of algorithms prior to widespread use. This work will serve as a baseline for future research into the ideal regulatory framework for AI applications worldwide.},
  archive      = {J_ARTMED},
  author       = {Alexander G. Yearley and Caroline M.W. Goedmakers and Armon Panahi and Joanne Doucette and Aakanksha Rana and Kavitha Ranganathan and Timothy R. Smith},
  doi          = {10.1016/j.artmed.2023.102607},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102607},
  shortjournal = {Artif. Intell. Med.},
  title        = {FDA-approved machine learning algorithms in neuroradiology: A systematic review of the current evidence for approval},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised out-of-distribution detection in wireless
capsule endoscopy images. <em>ARTMED</em>, <em>143</em>, 102606. (<a
href="https://doi.org/10.1016/j.artmed.2023.102606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep learning has displayed excellent performance in a broad spectrum of application areas , neural networks still struggle to recognize what they have not seen, i.e., out-of-distribution (OOD) inputs. In the medical field, building robust models that are able to detect OOD images is highly critical, as these rare images could show diseases or anomalies that should be detected. In this study, we use wireless capsule endoscopy (WCE) images to present a novel patch-based self-supervised approach comprising three stages. First, we train a triplet network to learn vector representations of WCE image patches. Second, we cluster the patch embeddings to group patches in terms of visual similarity. Third, we use the cluster assignments as pseudolabels to train a patch classifier and use the Out-of-Distribution Detector for Neural Networks (ODIN) for OOD detection. The system has been tested on the Kvasir-capsule, a publicly released WCE dataset. Empirical results show an OOD detection improvement compared to baseline methods . Our method can detect unseen pathologies and anomalies such as lymphangiectasia , foreign bodies and blood with A U R O C &gt; 0 . 6 AUROC&amp;gt;0.6 . This work presents an effective solution for OOD detection models without needing labeled images.},
  archive      = {J_ARTMED},
  author       = {Arnau Quindós and Pablo Laiz and Jordi Vitrià and Santi Seguí},
  doi          = {10.1016/j.artmed.2023.102606},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102606},
  shortjournal = {Artif. Intell. Med.},
  title        = {Self-supervised out-of-distribution detection in wireless capsule endoscopy images},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A feature selection framework for anxiety disorder analysis
using a novel multiview harris hawk optimization algorithm.
<em>ARTMED</em>, <em>143</em>, 102605. (<a
href="https://doi.org/10.1016/j.artmed.2023.102605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) has demonstrated its ability to exploit important relationships within data collection, which can be used in the diagnosis, treatment, and prediction of outcomes in a variety of clinical contexts. Anxiety mental disorder analysis is one of the pending difficulties that ML can help with. A thorough study is demanded to gain a better understanding of this illness. Since the anxiety data is generally multidimensional, which complicates processing and as a result of technology improvements, medical data from several perspectives, known as multiview data (MVD), is being collected. Each view has its own data type and feature values, so there is a lot of diversity. This work introduces a novel preprocessing feature selection (FS) approach, multiview harris hawk optimization (MHHO), which has the potential to reduce the dimensionality of anxiety data, hence reducing analytical effort. The uniqueness of MHHO originates from combining a multiview linking methodology with the power of the harris hawk optimization (HHO) method. The HHO is used to identify the lowest optimal MVD feature subset, while multiview linking is utilized to find a promising fitness function to direct the HHO FS while accounting for all data views’ heterogeneity. The complexity of MHHO is O ( T H L 2 ) O(THL2) , where T T is the number of iterations, H H is the number of involved harris hawks, and L L is the number of objects. Using two publicly available anxiety MVDs, MHHO is validated against ten recent rivals in its category. The experimental findings show that MHHO has a considerable advantage in terms of convergence speed (converging in less than ten iterations), subset size (removing 75% of the views; reducing feature size by 66%), and classification accuracy (approaching 100%). Furthermore, statistical analyses reveal that MHHO is statistically different from its competitors, bolstering its applicability. Finally, feature importance is evaluated, shedding light on the most anxiety-inducing characteristics. The likelihood of developing additional disorders (such as depression or stress) is also investigated.},
  archive      = {J_ARTMED},
  author       = {Ahmed Hamed and Marwa F. Mohamed},
  doi          = {10.1016/j.artmed.2023.102605},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102605},
  shortjournal = {Artif. Intell. Med.},
  title        = {A feature selection framework for anxiety disorder analysis using a novel multiview harris hawk optimization algorithm},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Do japanese word-embedded representations obtained in the
academic corpus retain the medical concepts of “infarction”?
<em>ARTMED</em>, <em>143</em>, 102604. (<a
href="https://doi.org/10.1016/j.artmed.2023.102604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pathophysiological concepts of diseases are encapsulated in patients&#39; medical histories . Whether information on the pathophysiology or anatomy of “infarction” can be preserved and objectively expressed in the distributed representation obtained from a corpus of scientific Japanese medical texts in the “infarction” domain is currently unknown. Word2Vec was used to obtain distributed representations, meanings, and word analogies of word vectors, and this process was verified mathematically. The texts were abstracts that were obtained by searching for “infarction,” “abstract,” and “case report” in the Japan Medical Journal Association&#39;s Ichushi Data Base . The abstracted text was morphologically analyzed to produce word sequences converted into their standard form. MeCab was used for morphological analysis and mecab-ipadic-NEologd and ComeJisyo were used as dictionaries. The accuracy of the known tasks for medical terms was evaluated using a word analogy task specific to the “infarction” domain. Only 33 % of the word analogy tasks for medical terminology were correct. However, 52 % of the new original tasks, which were specific to the “infarction” domain, were correct, especially those regarding anatomical differences. Documents related to “infarction” were collected from a corpus of Japanese medical documents and word-embedded expressions were obtained using Word2Vec. Terminology that had similar meanings to “infarction” included words such as “cavity” and “ischemia,” which suggest the pathology of an infarction. The pathophysiological and anatomical features of an “infarction” may be retained in a distributed representation.},
  archive      = {J_ARTMED},
  author       = {Daiki Yokokawa and Kazutaka Noda and Takanori Uehara and Yasutaka Yanagita and Yoshiyuki Ohira and Masatomi Ikusaka},
  doi          = {10.1016/j.artmed.2023.102604},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102604},
  shortjournal = {Artif. Intell. Med.},
  title        = {Do japanese word-embedded representations obtained in the academic corpus retain the medical concepts of “infarction”?},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A contrast set mining based approach for cancer subtype
analysis. <em>ARTMED</em>, <em>143</em>, 102590. (<a
href="https://doi.org/10.1016/j.artmed.2023.102590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of detecting common and unique characteristics among different cancer subtypes is an important focus of research that aims to improve personalized therapies. Unlike current approaches mainly based on predictive techniques, our study aims to improve the knowledge about the molecular mechanisms that descriptively led to cancer, thus not requiring previous knowledge to be validated. Here, we propose an approach based on contrast set mining to capture high-order relationships in cancer transcriptomic data. In this way, we were able to extract valuable insights from several cancer subtypes in the form of highly specific genetic relationships related to functional pathways affected by the disease. To this end, we have divided several cancer gene expression databases by the subtype associated with each sample to detect which gene groups are related to each cancer subtype. To demonstrate the potential and usefulness of the proposed approach we have extensively analysed RNA-Seq gene expression data from breast, kidney, and colon cancer subtypes. The possible role of the obtained genetic relationships was further evaluated through extensive literature research, while its prognosis was assessed via survival analysis, finding gene expression patterns related to survival in various cancer subtypes. Some gene associations were described in the literature as potential cancer biomarkers while other results have been not described yet and could be a starting point for future research.},
  archive      = {J_ARTMED},
  author       = {A.M. Trasierras and J.M. Luna and S. Ventura},
  doi          = {10.1016/j.artmed.2023.102590},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102590},
  shortjournal = {Artif. Intell. Med.},
  title        = {A contrast set mining based approach for cancer subtype analysis},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning in the identification of prognostic DNA
methylation biomarkers among patients with cancer: A systematic review
of epigenome-wide studies. <em>ARTMED</em>, <em>143</em>, 102589. (<a
href="https://doi.org/10.1016/j.artmed.2023.102589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DNA methylation biomarkers have great potential in improving prognostic classification systems for patients with cancer. Machine learning (ML)-based analytic techniques might help overcome the challenges of analyzing high-dimensional data in relatively small sample sizes . This systematic review summarizes the current use of ML-based methods in epigenome-wide studies for the identification of DNA methylation signatures associated with cancer prognosis . We searched three electronic databases including PubMed , EMBASE, and Web of Science for articles published until 2 January 2023. ML-based methods and workflows used to identify DNA methylation signatures associated with cancer prognosis were extracted and summarized. Two authors independently assessed the methodological quality of included studies by a seven-item checklist adapted from &#39;A Tool to Assess Risk of Bias and Applicability of Prediction Model Studies (PROBAST)&#39; and from the &#39;Reporting Recommendations for Tumor Marker Prognostic Studies (REMARK). Different ML methods and workflows used in included studies were summarized and visualized by a sunburst chart, a bubble chart, and Sankey diagrams, respectively. Eighty-three studies were included in this review. Three major types of ML-based workflows were identified. 1) unsupervised clustering, 2) supervised feature selection, and 3) deep learning-based feature transformation. For the three workflows, the most frequently used ML techniques were consensus clustering , least absolute shrinkage and selection operator (LASSO), and autoencoder, respectively. The systematic review revealed that the performance of these approaches has not been adequately evaluated yet and that methodological and reporting flaws were common in the identified studies using ML techniques. There is great heterogeneity in ML-based methodological strategies used by epigenome-wide studies to identify DNA methylation markers associated with cancer prognosis. In theory, most existing workflows could not handle the high multi-collinearity and potentially non-linearity interactions in epigenome-wide DNA methylation data. Benchmarking studies are needed to compare the relative performance of various approaches for specific cancer types . Adherence to relevant methodological and reporting guidelines are urgently needed.},
  archive      = {J_ARTMED},
  author       = {Tanwei Yuan and Dominic Edelmann and Ziwen Fan and Elizabeth Alwers and Jakob Nikolas Kather and Hermann Brenner and Michael Hoffmeister},
  doi          = {10.1016/j.artmed.2023.102589},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102589},
  shortjournal = {Artif. Intell. Med.},
  title        = {Machine learning in the identification of prognostic DNA methylation biomarkers among patients with cancer: A systematic review of epigenome-wide studies},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A general text mining method to extract echocardiography
measurement results from echocardiography documents. <em>ARTMED</em>,
<em>143</em>, 102584. (<a
href="https://doi.org/10.1016/j.artmed.2023.102584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In everyday medical practice , the results of cardiac ultrasound examinations are generally recorded in unstructured text, from which extracting relevant information is an important and challenging task. This paper presents a generally applicable language and corpus-independent text mining method for extracting and structuring numerical measurement results and their descriptions from echocardiography reports. The developed method is based on generally applicable text mining preprocessing activities, it automatically identifies and standardizes the descriptions of the cardiac ultrasound measures, and it stores the extracted and standardized measurement descriptions with their measurement results in a structured form for later usage. The method does not contain any regular expression-based search and does not rely on information about the structure of the document. The method has been tested on a document set containing more than 20,000 echocardiographic reports by examining the efficiency of extracting 12 echocardiography parameters considered important by experts. The method extracted and structured the echocardiography parameters under the study with good sensitivity (lowest value: 0.775, highest value: 1.0, average: 0.904) and excellent specificity (for all cases 1.0). The F1 score ranged between 0.873 and 1.0, and its average value was 0.948. The presented case study has shown that the proposed method can extract measurement results from echocardiography documents with high confidence without performing a direct search or having detailed information about the data recording habits. Furthermore, it effectively handles spelling errors, abbreviations and the highly varied terminology used in descriptions. As it does not rely on any information related to the structure or the language of the documents or data recording habits, it can be applied for processing any free-text written medical texts.},
  archive      = {J_ARTMED},
  author       = {Szabolcs Szekér and György Fogarassy and Ágnes Vathy-Fogarassy},
  doi          = {10.1016/j.artmed.2023.102584},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102584},
  shortjournal = {Artif. Intell. Med.},
  title        = {A general text mining method to extract echocardiography measurement results from echocardiography documents},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain randomization using synthetic electrocardiograms for
training neural networks. <em>ARTMED</em>, <em>143</em>, 102583. (<a
href="https://doi.org/10.1016/j.artmed.2023.102583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for training neural networks with synthetic electrocardiograms that mimic signals produced by a wearable single lead electrocardiogram monitor. We use domain randomization where the synthetic signal properties such as the waveform shape, RR-intervals and noise are varied for every training example. Models trained with synthetic data are compared to their counterparts trained with real data. Detection of r-waves in electrocardiograms recorded during different physical activities and in atrial fibrillation is used to assess the performance. By allowing the randomization of the synthetic signals to increase beyond what is typically observed in the real-world data the performance is on par or superseding the performance of networks trained with real data. Experiments show robust model performance using different seeds and on different unseen test sets that were fully separated from the training phase. The ability of the model to generalize well to hidden test sets without any specific tuning provides a simple and explainable alternative to more complex adversarial domain adaptation methods for model generalization. This method opens up the possibility of extending the use of synthetic data towards domain insensitive cardiac disease classification when disease specific a priori information is used in the electrocardiogram generation. Additionally, the method provides training with free-to-collect data with accurate labels, control of the data distribution eliminating class imbalances that are typically observed in health-related data, and the generated data is inherently private.},
  archive      = {J_ARTMED},
  author       = {Matti Kaisti and Juho Laitala and David Wong and Antti Airola},
  doi          = {10.1016/j.artmed.2023.102583},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102583},
  shortjournal = {Artif. Intell. Med.},
  title        = {Domain randomization using synthetic electrocardiograms for training neural networks},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequent temporal patterns of physiological and biological
biomarkers and their evolution in sepsis. <em>ARTMED</em>, <em>143</em>,
102576. (<a href="https://doi.org/10.1016/j.artmed.2023.102576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is one of the most challenging health conditions worldwide, with relatively high incidence and mortality rates . It is shown that preventing sepsis is the key to avoid potentially irreversible organ dysfunction. However, data-driven early identification of sepsis is challenging as sepsis shares signs and symptoms with other health conditions. This paper adopts a temporal pattern mining approach to identify frequent temporal and evolving patterns of physiological and biological biomarkers in sepsis patients. We show that using these frequent patterns as features for classifying sepsis and non-sepsis patients can improve the prediction accuracy and performance up to 7%. Most of the temporal modeling approaches adopted in the sepsis literature are based on deep learning methods. Although these approaches produce high accuracy, they generally have limited model explainability and interpretability. Using the adopted methods in this study, we could identify the most important features contributing to the patients’ sepsis incidence, such as fluctuations in platelet, lactate, and creatinine, or evolution of patterns including renal and metabolic organ systems, and consequently, enhance the findings’ clinical interpretability.},
  archive      = {J_ARTMED},
  author       = {Ali Jazayeri and Christopher C. Yang and Muge Capan},
  doi          = {10.1016/j.artmed.2023.102576},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102576},
  shortjournal = {Artif. Intell. Med.},
  title        = {Frequent temporal patterns of physiological and biological biomarkers and their evolution in sepsis},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a bispectral index score prediction model
based on an interpretable deep learning algorithm. <em>ARTMED</em>,
<em>143</em>, 102569. (<a
href="https://doi.org/10.1016/j.artmed.2023.102569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proper maintenance of hypnosis is crucial for ensuring the safety of patients undergoing surgery. Accordingly, indicators, such as the Bispectral index (BIS), have been developed to monitor hypnotic levels. However, the black-box nature of the algorithm coupled with the hardware makes it challenging to understand the underlying mechanisms of the algorithms and integrate them with other monitoring systems , thereby limiting their use. We propose an interpretable deep learning model that forecasts BIS values 25 s in advance using 30 s electroencephalogram (EEG) data. The proposed model utilized EEG data as a predictor, which is then decomposed into amplitude and phase components using fast Fourier Transform . An attention mechanism was applied to interpret the importance of these components in predicting BIS. The predictability of the model was evaluated on both regression and binary classification tasks , where the former involved predicting a continuous BIS value, and the latter involved classifying a dichotomous status at a BIS value of 60. To evaluate the interpretability of the model, we analyzed the attention values expressed in the amplitude and phase components according to five ranges of BIS values. The proposed model was trained and evaluated using datasets collected from two separate medical institutions. The proposed model achieved excellent performance on both the internal and external validation datasets. The model achieved a root-mean-square error of 6.614 for the regression task, and an area under the receiver operating characteristic curve of 0.937 for the binary classification task. Interpretability analysis provided insight into the relationship between EEG frequency components and BIS values. Specifically, the attention mechanism revealed that higher BIS values were associated with increased amplitude attention values in high-frequency bands and increased phase attention values in various frequency bands. This finding is expected to facilitate a more profound understanding of the BIS prediction mechanism, thereby contributing to the advancement of anesthesia technologies.},
  archive      = {J_ARTMED},
  author       = {Eugene Hwang and Hee-Sun Park and Hyun-Seok Kim and Jin-Young Kim and Hanseok Jeong and Junetae Kim and Sung-Hoon Kim},
  doi          = {10.1016/j.artmed.2023.102569},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102569},
  shortjournal = {Artif. Intell. Med.},
  title        = {Development of a bispectral index score prediction model based on an interpretable deep learning algorithm},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of interpretability for deep learning algorithms
in EEG emotion recognition: A case study in autism. <em>ARTMED</em>,
<em>143</em>, 102545. (<a
href="https://doi.org/10.1016/j.artmed.2023.102545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current models on Explainable Artificial Intelligence (XAI) have shown a lack of reliability when evaluating feature-relevance for deep neural biomarker classifiers. The inclusion of reliable saliency-maps for obtaining trustworthy and interpretable neural activity is still insufficiently mature for practical applications. These limitations impede the development of clinical applications of Deep Learning . To address, these limitations we propose the RemOve-And-Retrain (ROAR) algorithm which supports the recovery of highly relevant features from any pre-trained deep neural network . In this study we evaluated the ROAR methodology and algorithm for the Face Emotion Recognition (FER) task, which is clinically applicable in the study of Autism Spectrum Disorder (ASD). We trained a Convolutional Neural Network (CNN) from electroencephalography (EEG) signals and assessed the relevance of FER-elicited EEG features from individuals diagnosed with and without ASD. Specifically, we compared the ROAR reliability from well-known relevance maps such as Layer-Wise Relevance Propagation, PatternNet, Pattern-Attribution, and Smooth-Grad Squared. This study is the first to bridge previous neuroscience and ASD research findings to feature-relevance calculation for EEG-based emotion recognition with CNN in typically-development (TD) and in ASD individuals.},
  archive      = {J_ARTMED},
  author       = {Juan Manuel Mayor Torres and Sara Medina-DeVilliers and Tessa Clarkson and Matthew D. Lerner and Giuseppe Riccardi},
  doi          = {10.1016/j.artmed.2023.102545},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102545},
  shortjournal = {Artif. Intell. Med.},
  title        = {Evaluation of interpretability for deep learning algorithms in EEG emotion recognition: A case study in autism},
  volume       = {143},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence and statistical methods for
stratification and prediction of progression in amyotrophic lateral
sclerosis: A systematic review. <em>ARTMED</em>, <em>142</em>, 102588.
(<a href="https://doi.org/10.1016/j.artmed.2023.102588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amyotrophic Lateral Sclerosis (ALS) is a fatal neurodegenerative disorder characterised by the progressive loss of motor neurons in the brain and spinal cord. The fact that ALS’s disease course is highly heterogeneous, and its determinants not fully known, combined with ALS’s relatively low prevalence, renders the successful application of artificial intelligence (AI) techniques particularly arduous. This systematic review aims at identifying areas of agreement and unanswered questions regarding two notable applications of AI in ALS, namely the automatic, data-driven stratification of patients according to their phenotype, and the prediction of ALS progression. Differently from previous works, this review is focused on the methodological landscape of AI in ALS. We conducted a systematic search of the Scopus and PubMed databases, looking for studies on data-driven stratification methods based on unsupervised techniques resulting in (A) automatic group discovery or (B) a transformation of the feature space allowing patient subgroups to be identified; and for studies on internally or externally validated methods for the prediction of ALS progression. We described the selected studies according to the following characteristics, when applicable: variables used, methodology, splitting criteria and number of groups, prediction outcomes , validation schemes, and metrics. Of the starting 1604 unique reports (2837 combined hits between Scopus and PubMed), 239 were selected for thorough screening, leading to the inclusion of 15 studies on patient stratification, 28 on prediction of ALS progression, and 6 on both stratification and prediction. In terms of variables used, most stratification and prediction studies included demographics and features derived from the ALSFRS or ALSFRS-R scores, which were also the main prediction targets. The most represented stratification methods were K-means, and hierarchical and expectation-maximisation clustering; while random forests, logistic regression , the Cox proportional hazard model , and various flavours of deep learning were the most widely used prediction methods. Predictive model validation was, albeit unexpectedly, quite rarely performed in absolute terms (leading to the exclusion of 78 eligible studies), with the overwhelming majority of included studies resorting to internal validation only. This systematic review highlighted a general agreement in terms of input variable selection for both stratification and prediction of ALS progression, and in terms of prediction targets. A striking lack of validated models emerged, as well as a general difficulty in reproducing many published studies, mainly due to the absence of the corresponding parameter lists. While deep learning seems promising for prediction applications, its superiority with respect to traditional methods has not been established; there is, instead, ample room for its application in the subfield of patient stratification. Finally, an open question remains on the role of new environmental and behavioural variables collected via novel, real-time sensors.},
  archive      = {J_ARTMED},
  author       = {Erica Tavazzi and Enrico Longato and Martina Vettoretti and Helena Aidos and Isotta Trescato and Chiara Roversi and Andreia S. Martins and Eduardo N. Castanho and Ruben Branco and Diogo F. Soares and Alessandro Guazzo and Giovanni Birolo and Daniele Pala and Pietro Bosoni and Adriano Chiò and Umberto Manera and Mamede de Carvalho and Bruno Miranda and Marta Gromicho and Inês Alves and Riccardo Bellazzi and Arianna Dagliati and Piero Fariselli and Sara C. Madeira and Barbara Di Camillo},
  doi          = {10.1016/j.artmed.2023.102588},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102588},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence and statistical methods for stratification and prediction of progression in amyotrophic lateral sclerosis: A systematic review},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Handling missing values in healthcare data: A systematic
review of deep learning-based imputation techniques. <em>ARTMED</em>,
<em>142</em>, 102587. (<a
href="https://doi.org/10.1016/j.artmed.2023.102587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proper handling of missing values is critical to delivering reliable estimates and decisions, especially in high-stakes fields such as clinical research . In response to the increasing diversity and complexity of data, many researchers have developed deep learning (DL)-based imputation techniques. We conducted a systematic review to evaluate the use of these techniques, with a particular focus on the types of data, intending to assist healthcare researchers from various disciplines in dealing with missing data. We searched five databases (MEDLINE, Web of Science, Embase , CINAHL, and Scopus) for articles published prior to February 8, 2023 that described the use of DL-based models for imputation. We examined selected articles from four perspectives: data types , model backbones (i.e., main architectures), imputation strategies, and comparisons with non-DL-based methods. Based on data types, we created an evidence map to illustrate the adoption of DL models. Out of 1822 articles, a total of 111 were included, of which tabular static data (29%, 32/111) and temporal data (40%, 44/111) were the most frequently investigated. Our findings revealed a discernible pattern in the choice of model backbones and data types, for example, the dominance of autoencoder and recurrent neural networks for tabular temporal data. The discrepancy in imputation strategy usage among data types was also observed. The “integrated” imputation strategy, which solves the imputation task simultaneously with downstream tasks, was most popular for tabular temporal data (52%, 23/44) and multi-modal data (56%, 5/9). Moreover, DL-based imputation methods yielded a higher level of imputation accuracy than non-DL methods in most studies. The DL-based imputation models are a family of techniques, with diverse network structures. Their designation in healthcare is usually tailored to data types with different characteristics. Although DL-based imputation models may not be superior to conventional approaches across all datasets, it is highly possible for them to achieve satisfactory results for a particular data type or dataset. There are, however, still issues with regard to portability, interpretability , and fairness associated with current DL-based imputation models.},
  archive      = {J_ARTMED},
  author       = {Mingxuan Liu and Siqi Li and Han Yuan and Marcus Eng Hock Ong and Yilin Ning and Feng Xie and Seyed Ehsan Saffari and Yuqing Shang and Victor Volovici and Bibhas Chakraborty and Nan Liu},
  doi          = {10.1016/j.artmed.2023.102587},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102587},
  shortjournal = {Artif. Intell. Med.},
  title        = {Handling missing values in healthcare data: A systematic review of deep learning-based imputation techniques},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FooDis: A food-disease relation mining pipeline.
<em>ARTMED</em>, <em>142</em>, 102586. (<a
href="https://doi.org/10.1016/j.artmed.2023.102586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it is really important and crucial to follow the new biomedical knowledge that is presented in scientific literature. To this end, Information Extraction pipelines can help to automatically extract meaningful relations from textual data that further require additional checks by domain experts. In the last two decades, a lot of work has been performed for extracting relations between phenotype and health concepts, however, the relations with food entities which are one of the most important environmental concepts have never been explored. In this study, we propose FooDis, a novel Information Extraction pipeline that employs state-of-the-art approaches in Natural Language Processing to mine abstracts of biomedical scientific papers and automatically suggests potential cause or treat relations between food and disease entities in different existing semantic resources. A comparison with already known relations indicates that the relations predicted by our pipeline match for 90% of the food-disease pairs that are common in our results and the NutriChem database, and 93% of the common pairs in the DietRx platform. The comparison also shows that the FooDis pipeline can suggest relations with high precision. The FooDis pipeline can be further used to dynamically discover new relations between food and diseases that should be checked by domain experts and further used to populate some of the existing resources used by NutriChem and DietRx.},
  archive      = {J_ARTMED},
  author       = {Gjorgjina Cenikj and Tome Eftimov and Barbara Koroušić Seljak},
  doi          = {10.1016/j.artmed.2023.102586},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102586},
  shortjournal = {Artif. Intell. Med.},
  title        = {FooDis: A food-disease relation mining pipeline},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence predicts lung cancer radiotherapy
response: A meta-analysis. <em>ARTMED</em>, <em>142</em>, 102585. (<a
href="https://doi.org/10.1016/j.artmed.2023.102585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) technology has clustered patients based on clinical features into sub-clusters to stratify high-risk and low-risk groups to predict outcomes in lung cancer after radiotherapy and has gained much more attention in recent years. Given that the conclusions vary considerably, this meta-analysis was conducted to investigate the combined predictive effect of AI models on lung cancer. This study was performed according to PRISMA guidelines. PubMed, ISI Web of Science, and Embase databases were searched for relevant literature. Outcomes, including overall survival (OS), disease-free survival (DFS), progression-free survival (PFS), and local control (LC), were predicted using AI models in patients with lung cancer after radiotherapy, and were used to calculate the pooled effect. Quality, heterogeneity, and publication bias of the included studies were also evaluated. Eighteen articles with 4719 patients were eligible for this meta-analysis. The combined hazard ratios (HRs) of the included studies for OS, LC, PFS, and DFS of lung cancer patients were 2.55 (95 % confidence interval (CI) = 1.73–3.76), 2.45 (95 % CI = 0.78–7.64), 3.84 (95 % CI = 2.20–6.68), and 2.66 (95 % CI = 0.96–7.34), respectively. The combined area under the receiver operating characteristics curve (AUC) of the included articles on OS and LC in patients with lung cancer was 0.75 (95 % CI = 0.67–0.84), and 0.80 (95%CI = 0.0.68–0.95), respectively. The clinical feasibility of predicting outcomes using AI models after radiotherapy in patients with lung cancer was demonstrated. Large-scale, prospective, multicenter studies should be conducted to more accurately predict the outcomes in patients with lung cancer.},
  archive      = {J_ARTMED},
  author       = {Wenmin Xing and Wenyan Gao and Xiaoling Lv and Zhenlei Zhao and Xiaogang Xu and Zhibing Wu and Genxiang Mao and Jun Chen},
  doi          = {10.1016/j.artmed.2023.102585},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102585},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence predicts lung cancer radiotherapy response: A meta-analysis},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction meets time series with gaps: User clusters with
specific usage behavior patterns. <em>ARTMED</em>, <em>142</em>, 102575.
(<a href="https://doi.org/10.1016/j.artmed.2023.102575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With mHealth apps, data can be recorded in real life, which makes them useful, for example, as an accompanying tool in treatments. However, such datasets, especially those based on apps with usage on a voluntary basis, are often affected by fluctuating engagement and by high user dropout rates. This makes it difficult to exploit the data using machine learning techniques and raises the question of whether users have stopped using the app. In this extended paper, we present a method to identify phases with varying dropout rates in a dataset and predict for each. We also present an approach to predict what period of inactivity can be expected for a user in the current state. We use change point detection to identify the phases, show how to deal with uneven misaligned time series and predict the user’s phase using time series classification. In addition, we examine how the evolution of adherence develops in individual clusters of individuals. We evaluated our method on the data of an mHealth app for tinnitus, and show that our approach is appropriate for the study of adherence in datasets with uneven, unaligned time series of different lengths and with missing values.},
  archive      = {J_ARTMED},
  author       = {Miro Schleicher and Vishnu Unnikrishnan and Rüdiger Pryss and Johannes Schobel and Winfried Schlee and Myra Spiliopoulou},
  doi          = {10.1016/j.artmed.2023.102575},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102575},
  shortjournal = {Artif. Intell. Med.},
  title        = {Prediction meets time series with gaps: User clusters with specific usage behavior patterns},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust protein language model for SARS-CoV-2
protein–protein interaction network prediction. <em>ARTMED</em>,
<em>142</em>, 102574. (<a
href="https://doi.org/10.1016/j.artmed.2023.102574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein-protein interaction is one of the ways viruses interact with their hosts. Therefore, identifying protein interactions between viruses and hosts helps explain how virus proteins work, how they replicate, and how they cause disease. SARS-CoV-2 is a new type of virus that emerged from the coronavirus family in 2019 and caused a worldwide pandemic. Detection of human proteins interacting with this novel virus strain plays an important role in monitoring the cellular process of virus-associated infection. Within the scope of the study, a natural language processing-based collective learning method is proposed for the prediction of potential SARS-CoV-2-human PPIs. Protein language models were obtained with the prediction-based word2Vec and doc2Vec embedding methods and the frequency-based tf-idf method. Known interactions were represented by proposed language models and traditional feature extraction methods (conjoint triad and repeat pattern), and their performances were compared. The interaction data were trained with support vector machine , artificial neural network (ANN), k-nearest neighbor (KNN), naive Bayes (NB), decision tree (DT), and ensemble algorithms. Experimental results show that protein language models are a promising protein representation method for protein-protein interaction prediction. The term frequency-inverse document frequency-based language model performed the SARS-CoV-2 protein-protein interaction estimation with an error of 1.4%. Additionally, the decisions of high-performing learning models for different feature extraction methods were combined with a collective voting approach to make new interaction predictions. For 10,000 human proteins, 285 new potential interactions were predicted, with models combining decisions.},
  archive      = {J_ARTMED},
  author       = {Zeynep Banu Ozger},
  doi          = {10.1016/j.artmed.2023.102574},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102574},
  shortjournal = {Artif. Intell. Med.},
  title        = {A robust protein language model for SARS-CoV-2 protein–protein interaction network prediction},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified framework of medical information annotation and
extraction for chinese clinical text. <em>ARTMED</em>, <em>142</em>,
102573. (<a href="https://doi.org/10.1016/j.artmed.2023.102573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical information extraction consists of a group of natural language processing (NLP) tasks, which collaboratively convert clinical text to pre-defined structured formats. This is a critical step to exploit electronic medical records (EMRs). Given the recent thriving NLP technologies, model implementation and performance seem no longer an obstacle, whereas the bottleneck locates on a high-quality annotated corpus and the whole engineering workflow. This study presents an engineering framework consisting of three tasks, i.e., medical entity recognition, relation extraction and attribute extraction. Within this framework, the whole workflow is demonstrated from EMR data collection through model performance evaluation. Our annotation scheme is designed to be comprehensive and compatible between the multiple tasks. With the EMRs from a general hospital in Ningbo, China, and the manual annotation by experienced physicians, our corpus is of large scale and high quality. Built upon this Chinese clinical corpus, the medical information extraction system show performance that approaches human annotation. The annotation scheme, (a subset of) the annotated corpus, and the code are all publicly released, to facilitate further research.},
  archive      = {J_ARTMED},
  author       = {Enwei Zhu and Qilin Sheng and Huanwan Yang and Yiyang Liu and Ting Cai and Jinpeng Li},
  doi          = {10.1016/j.artmed.2023.102573},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102573},
  shortjournal = {Artif. Intell. Med.},
  title        = {A unified framework of medical information annotation and extraction for chinese clinical text},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A genetic programming-based convolutional deep learning
algorithm for identifying COVID-19 cases via x-ray images.
<em>ARTMED</em>, <em>142</em>, 102571. (<a
href="https://doi.org/10.1016/j.artmed.2023.102571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms have been successfully employed to find the best structure for many learning algorithms including neural networks . Due to their flexibility and promising results, Convolutional Neural Networks (CNNs) have found their application in many image processing applications. The structure of CNNs greatly affects the performance of these algorithms both in terms of accuracy and computational cost, thus, finding the best architecture for these networks is a crucial task before they are employed. In this paper, we develop a genetic programming approach for the optimization of CNN structure in diagnosing COVID-19 cases via X-ray images. A graph representation for CNN architecture is proposed and evolutionary operators including crossover and mutation are specifically designed for the proposed representation. The proposed architecture of CNNs is defined by two sets of parameters, one is the skeleton which determines the arrangement of the convolutional and pooling operators and their connections and one is the numerical parameters of the operators which determine the properties of these operators like filter size and kernel size. The proposed algorithm in this paper optimizes the skeleton and the numerical parameters of the CNN architectures in a co-evolutionary scheme. The proposed algorithm is used to identify covid-19 cases via X-ray images.},
  archive      = {J_ARTMED},
  author       = {Mohammad Hassan Tayarani Najaran},
  doi          = {10.1016/j.artmed.2023.102571},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102571},
  shortjournal = {Artif. Intell. Med.},
  title        = {A genetic programming-based convolutional deep learning algorithm for identifying COVID-19 cases via X-ray images},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-attention LSTM-FCN model for arrhythmia classification
and uncertainty assessment. <em>ARTMED</em>, <em>142</em>, 102570. (<a
href="https://doi.org/10.1016/j.artmed.2023.102570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents ArrhyMon , a self-attention-based LSTM-FCN model for arrhythmia classification from ECG signal inputs. ArrhyMon targets to detect and classify six different types of arrhythmia apart from normal ECG patterns . To the best of our knowledge, ArrhyMon is the first end-to-end classification model that successfully targets the classification of six detailed arrhythmia types and compared to previous work does not require additional preprocessing and/or feature extraction operations separate from the classification model. ArrhyMon ’s deep learning model is designed to capture and exploit both global and local features embedded in ECG sequences by integrating fully convolutional network (FCN) layers and a self-attention-based long and short-term memory (LSTM) architecture. Moreover, to enhance its practicality, ArrhyMon incorporates a deep ensemble-based uncertainty model that generates a confidence-level measure for each classification result . We evaluate ArrhyMon ’s effectiveness using three publicly available arrhythmia datasets (i.e., MIT-BIH, Physionet Cardiology Challenge 2017 and 2020/2021) to show that ArrhyMon achieves state-of-the-art classification performance (average accuracy 99.63%), and that confidence measures show close correlation with subjective diagnosis made from practitioners.},
  archive      = {J_ARTMED},
  author       = {JaeYeon Park and Kichang Lee and Noseong Park and Seng Chan You and JeongGil Ko},
  doi          = {10.1016/j.artmed.2023.102570},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102570},
  shortjournal = {Artif. Intell. Med.},
  title        = {Self-attention LSTM-FCN model for arrhythmia classification and uncertainty assessment},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Impact of loss functions on the performance of a deep neural
network designed to restore low-dose digital mammography.
<em>ARTMED</em>, <em>142</em>, 102555. (<a
href="https://doi.org/10.1016/j.artmed.2023.102555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital mammography is currently the most common imaging tool for breast cancer screening. Although the benefits of using digital mammography for cancer screening outweigh the risks associated with the x-ray exposure, the radiation dose must be kept as low as possible while maintaining the diagnostic utility of the generated images, thus minimizing patient risks. Many studies investigated the feasibility of dose reduction by restoring low-dose images using deep neural networks. In these cases, choosing the appropriate training database and loss function is crucial and impacts the quality of the results. In this work, we used a standard residual network (ResNet) to restore low-dose digital mammography images and evaluated the performance of several loss functions. For training purposes, we extracted 256,000 image patches from a dataset of 400 images of retrospective clinical mammography exams, where dose reduction factors of 75% and 50% were simulated to generate low and standard-dose pairs. We validated the network in a real scenario by using a physical anthropomorphic breast phantom to acquire real low-dose and standard full-dose images in a commercially available mammography system, which were then processed through our trained model. We benchmarked our results against an analytical restoration model for low-dose digital mammography. Objective assessment was performed through the signal-to-noise ratio (SNR) and the mean normalized squared error (MNSE), decomposed into residual noise and bias. Statistical tests revealed that the use of the perceptual loss (PL4) resulted in statistically significant differences when compared to all other loss functions. Additionally, images restored using the PL4 achieved the closest residual noise to the standard dose. On the other hand, perceptual loss PL3, structural similarity index (SSIM) and one of the adversarial losses achieved the lowest bias for both dose reduction factors. The source code of our deep neural network is available at https://github.com/WANG-AXIS/LdDMDenoising .},
  archive      = {J_ARTMED},
  author       = {Hongming Shan and Rodrigo B. Vimieiro and Lucas R. Borges and Marcelo A.C. Vieira and Ge Wang},
  doi          = {10.1016/j.artmed.2023.102555},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102555},
  shortjournal = {Artif. Intell. Med.},
  title        = {Impact of loss functions on the performance of a deep neural network designed to restore low-dose digital mammography},
  volume       = {142},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new lung cancer detection method based on the chest CT
images using federated learning and blockchain systems. <em>ARTMED</em>,
<em>141</em>, 102572. (<a
href="https://doi.org/10.1016/j.artmed.2023.102572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With an estimated five million fatal cases each year, lung cancer is one of the significant causes of death worldwide. Lung diseases can be diagnosed with a Computed Tomography (CT) scan. The scarcity and trustworthiness of human eyes is the fundamental issue in diagnosing lung cancer patients . The main goal of this study is to detect malignant lung nodules in a CT scan of the lungs and categorize lung cancer according to severity. In this work, cutting-edge Deep Learning (DL) algorithms were used to detect the location of cancerous nodules. Also, the real-life issue is sharing data with hospitals around the world while bearing in mind the organizations&#39; privacy issues. Besides, the main problems for training a global DL model are creating a collaborative model and maintaining privacy. This study presented an approach that takes a modest amount of data from multiple hospitals and uses blockchain-based Federated Learning (FL) to train a global DL model. The data were authenticated using blockchain technology, and FL trained the model internationally while maintaining the organization&#39;s anonymity . First, we presented a data normalization approach that addresses the variability of data obtained from various institutions using various CT scanners. Furthermore, using a CapsNets method, we classified lung cancer patients in local mode. Finally, we devised a way to train a global model cooperatively utilizing blockchain technology and FL while maintaining anonymity. We also gathered data from real-life lung cancer patients for testing purposes. The suggested method was trained and tested on the Cancer Imaging Archive (CIA) dataset, Kaggle Data Science Bowl (KDSB), LUNA 16, and the local dataset. Finally, we performed extensive experiments with Python and its well-known libraries, such as Scikit-Learn and TensorFlow, to evaluate the suggested method. The findings showed that the method effectively detects lung cancer patients. The technique delivered 99.69 % accuracy with the smallest possible categorization error.},
  archive      = {J_ARTMED},
  author       = {Arash Heidari and Danial Javaheri and Shiva Toumaj and Nima Jafari Navimipour and Mahsa Rezaei and Mehmet Unal},
  doi          = {10.1016/j.artmed.2023.102572},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102572},
  shortjournal = {Artif. Intell. Med.},
  title        = {A new lung cancer detection method based on the chest CT images using federated learning and blockchain systems},
  volume       = {141},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of ERBB2 and CEN17 signals in fluorescent in situ
hybridization and dual in situ hybridization for guiding breast cancer
HER2 target therapy. <em>ARTMED</em>, <em>141</em>, 102568. (<a
href="https://doi.org/10.1016/j.artmed.2023.102568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The overexpression of the human epidermal growth factor receptor 2 (HER2) is a predictive biomarker in therapeutic effects for metastatic breast cancer. Accurate HER2 testing is critical for determining the most suitable treatment for patients. Fluorescent in situ hybridization (FISH) and dual in situ hybridization (DISH) have been recognized as FDA-approved methods to determine HER2 overexpression. However, analysis of HER2 overexpression is challenging. Firstly, the boundaries of cells are often unclear and blurry, with large variations in cell shapes and signals, making it challenging to identify the precise areas of HER2-related cells. Secondly, the use of sparsely labeled data, where some unlabeled HER2-related cells are classified as background, can significantly confuse fully supervised AI learning and result in unsatisfactory model outcomes. In this study, we present a weakly supervised Cascade R-CNN (W-CRCNN) model to automatically detect HER2 overexpression in HER2 DISH and FISH images acquired from clinical breast cancer samples. The experimental results demonstrate that the proposed W-CRCNN achieves excellent results in identification of HER2 amplification in three datasets, including two DISH datasets and a FISH dataset. For the FISH dataset, the proposed W-CRCNN achieves an accuracy of 0.970±0.022, precision of 0.974±0.028, recall of 0.917±0.065, F1-score of 0.943±0.042 and Jaccard Index of 0.899±0.073. For DISH datasets, the proposed W-CRCNN achieves an accuracy of 0.971±0.024, precision of 0.969±0.015, recall of 0.925±0.020, F1-score of 0.947±0.036 and Jaccard Index of 0.884±0.103 for dataset 1, and an accuracy of 0.978±0.011, precision of 0.975±0.011, recall of 0.918±0.038, F1-score of 0.946±0.030 and Jaccard Index of 0.884±0.052 for dataset 2, respectively. In comparison with the benchmark methods, the proposed W-CRCNN significantly outperforms all the benchmark approaches in identification of HER2 overexpression in FISH and DISH datasets ( p &lt; 0 . 05 ). With the high degree of accuracy, precision and recall , the results show that the proposed method in DISH analysis for assessment of HER2 overexpression in breast cancer patients has significant potential to assist precision medicine.},
  archive      = {J_ARTMED},
  author       = {Ching-Wei Wang and Muhammad-Adil Khalil and Yi-Jia Lin and Yu-Ching Lee and Tai-Kuang Chao},
  doi          = {10.1016/j.artmed.2023.102568},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102568},
  shortjournal = {Artif. Intell. Med.},
  title        = {Detection of ERBB2 and CEN17 signals in fluorescent in situ hybridization and dual in situ hybridization for guiding breast cancer HER2 target therapy},
  volume       = {141},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging artificial intelligence and decision support
systems in hospital-acquired pressure injuries prediction: A
comprehensive review. <em>ARTMED</em>, <em>141</em>, 102560. (<a
href="https://doi.org/10.1016/j.artmed.2023.102560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospital-acquired pressure injuries (HAPIs) constitute a significant challenge harming thousands of people worldwide yearly. While various tools and methods are used to identify pressure injuries , artificial intelligence (AI) and decision support systems (DSS) can help to reduce HAPIs risks by proactively identifying patients at risk and preventing them before harming patients. This paper comprehensively reviews AI and DSS applications for HAPIs prediction using Electronic Health Records (EHR), including a systematic literature review and bibliometric analysis. A systematic literature review was conducted through PRISMA and bibliometric analysis. In February 2023, the search was performed using four electronic databases: SCOPIS, PubMed, EBSCO, and PMCID. Articles on using AI and DSS in the management of PIs were included. The search approach yielded 319 articles, 39 of which have been included and classified into 27 AI-related and 12 DSS-related categories. The years of publication varied from 2006 to 2023, with 40% of the studies taking place in the US. Most studies focused on using AI algorithms or DSS for HAPIs prediction in inpatient units using various types of data such as electronic health records, PI assessment scales, and expert knowledge-based and environmental data to identify the risk factors associated with HAPIs development. There is insufficient evidence in the existing literature concerning the real impact of AI or DSS on making decisions for HAPIs treatment or prevention. Most studies reviewed are solely hypothetical and retrospective prediction models, with no actual application in healthcare settings. The accuracy rates, prediction results, and intervention procedures suggested based on the prediction, on the other hand, should inspire researchers to combine both approaches with larger-scale data to bring a new venue for HAPIs prevention and to investigate and adopt the suggested solutions to the existing gaps in AI and DSS prediction methods.},
  archive      = {J_ARTMED},
  author       = {Khaled M. Toffaha and Mecit Can Emre Simsekler and Mohammed Atif Omar},
  doi          = {10.1016/j.artmed.2023.102560},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102560},
  shortjournal = {Artif. Intell. Med.},
  title        = {Leveraging artificial intelligence and decision support systems in hospital-acquired pressure injuries prediction: A comprehensive review},
  volume       = {141},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic double hierarchy linguistic maclaurin
symmetric mean-MultiCriteria border approximation area comparison method
for multi-criteria group decision making and its application in a
selection of traditional chinese medicine prescriptions.
<em>ARTMED</em>, <em>141</em>, 102558. (<a
href="https://doi.org/10.1016/j.artmed.2023.102558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Chinese medicine (TCM) has gradually played an indispensable role in people’s health maintenance, especially in the treatment of chronic diseases . However, there is always uncertainty and hesitation in the judgment and understanding of diseases by doctors, which affects the status recognition and optimal diagnosis and treatment decision-making of patients. In order to overcome the above problems, we lead into probabilistic double hierarchy linguistic term set (PDHLTS) to accurately describe language information in traditional Chinese medicine and make decisions. In this paper, a multi-criteria group decision making (MCGDM) model is constructed based on the MSM-MCBAC (Maclaurin symmetric mean-MultiCriteria Border Approximation area Comparison) method in the PDHL environment. Firstly, a PDHL weighted Maclaurin symmetric mean (PDHLWMSM) operator is proposed to aggregate the evaluation matrices of multiple experts. Then, combined with the BWM and maximizing deviation method, a comprehensive weight determination method is put forward to calculate the weights of criteria. Furthermore, we propose PDHL MSM-MCBAC method based on the Multi-Attributive Border Approximation area Comparison (MABAC) method and the PDHLWMSM operator. Finally, an example of a selection of TCM prescriptions is used and some comparative analyses are made to verify the effectiveness and superiority of this paper.},
  archive      = {J_ARTMED},
  author       = {Sidong Xian and Ke Qing and Chaozhen Li and Miao Luo and Renping Liu},
  doi          = {10.1016/j.artmed.2023.102558},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102558},
  shortjournal = {Artif. Intell. Med.},
  title        = {Probabilistic double hierarchy linguistic maclaurin symmetric mean-MultiCriteria border approximation area comparison method for multi-criteria group decision making and its application in a selection of traditional chinese medicine prescriptions},
  volume       = {141},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning techniques in liver tumour diagnosis using CT
and MR imaging - a systematic review. <em>ARTMED</em>, <em>141</em>,
102557. (<a href="https://doi.org/10.1016/j.artmed.2023.102557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has become a thriving force in the computer aided diagnosis of liver cancer, as it solves extremely complicated challenges with high accuracy over time and facilitates medical experts in their diagnostic and treatment procedures. This paper presents a comprehensive systematic review on deep learning techniques applied for various applications pertaining to liver images, challenges faced by the clinicians in liver tumour diagnosis and how deep learning bridges the gap between clinical practice and technological solutions with an in-depth summary of 113 articles. Since, deep learning is an emerging revolutionary technology, recent state-of-the-art research implemented on liver images are reviewed with more focus on classification, segmentation and clinical applications in the management of liver diseases. Additionally, similar review articles in literature are reviewed and compared. The review is concluded by presenting the contemporary trends and unaddressed research issues in the field of liver tumour diagnosis, offering directions for future research in this field.},
  archive      = {J_ARTMED},
  author       = {B. Lakshmipriya and Biju Pottakkat and G. Ramkumar},
  doi          = {10.1016/j.artmed.2023.102557},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102557},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning techniques in liver tumour diagnosis using CT and MR imaging - a systematic review},
  volume       = {141},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Progressive growing of generative adversarial networks for
improving data augmentation and skin cancer diagnosis. <em>ARTMED</em>,
<em>141</em>, 102556. (<a
href="https://doi.org/10.1016/j.artmed.2023.102556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early melanoma diagnosis is the most important factor in the treatment of skin cancer and can effectively reduce mortality rates . Recently, Generative Adversarial Networks have been used to augment data, prevent overfitting and improve the diagnostic capacity of models. However, its application remains a challenging task due to the high levels of inter and intra-class variance seen in skin images, limited amounts of data, and model instability. We present a more robust Progressive Growing of Adversarial Networks based on residual learning, which is highly recommended to ease the training of deep networks. The stability of the training process was increased by receiving additional inputs from preceding blocks. The architecture is able to produce plausible photorealistic synthetic 512 × 512 skin images, even with small dermoscopic and non-dermoscopic skin image datasets as problem domains. In this manner, we tackle the lack of data and the imbalance problems. Additionally, the proposed approach leverages a skin lesion boundary segmentation algorithm and transfer learning to enhance the diagnosis of melanoma. Inception score and Matthews Correlation Coefficient were used to measure the performance of the models. The architecture was evaluated qualitatively and quantitatively through the use of an extensive experimental study on sixteen datasets, illustrating its effectiveness in the diagnosis of melanoma. Finally, four state-of-the-art data augmentation techniques applied in five convolutional neural network models were significantly outperformed. The results indicated that a bigger number of trainable parameters will not necessarily obtain a better performance in melanoma diagnosis.},
  archive      = {J_ARTMED},
  author       = {Eduardo Pérez and Sebastián Ventura},
  doi          = {10.1016/j.artmed.2023.102556},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102556},
  shortjournal = {Artif. Intell. Med.},
  title        = {Progressive growing of generative adversarial networks for improving data augmentation and skin cancer diagnosis},
  volume       = {141},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differential diagnosis of secondary hypertension based on
deep learning. <em>ARTMED</em>, <em>141</em>, 102554. (<a
href="https://doi.org/10.1016/j.artmed.2023.102554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secondary hypertension is associated with higher risks of target organ damage and cardiovascular and cerebrovascular disease events. Early aetiology identification can eliminate aetiologies and control blood pressure. However, inexperienced doctors often fail to diagnose secondary hypertension, and comprehensively screening for all causes of high blood pressure increases health care costs. To date, deep learning has rarely been involved in the differential diagnosis of secondary hypertension. Relevant machine learning methods cannot combine textual information such as chief complaints with numerical information such as the laboratory examination results in electronic health records (EHRs), and the use of all features increases health care costs. To reduce redundant examinations and accurately identify secondary hypertension, we propose a two-stage framework that follows clinical procedures. The framework carries out an initial diagnosis process in the first stage, on which basis patients are recommended for disease-related examinations, followed by differential diagnoses of different diseases based on the different characteristics observed in the second stage. We convert the numerical examination results into descriptive sentences, thus blending textual and numerical characteristics. Medical guidelines are introduced through label embedding and attention mechanisms to obtain interactive features. Our model was trained and evaluated using a cross-sectional dataset containing 11,961 patients with hypertension from January 2013 to December 2019. The F1 scores of our model were 0.912, 0.921, 0.869 and 0.894 for primary aldosteronism , thyroid disease, nephritis and nephrotic syndrome and chronic kidney disease , respectively, which are four kinds of secondary hypertension with high incidence rates. The experimental results show that our model can powerfully use the textual and numerical data contained in EHRs to provide effective decision support for the differential diagnosis of secondary hypertension.},
  archive      = {J_ARTMED},
  author       = {Lin Wu and Liying Huang and Mei Li and Zhaojun Xiong and Dinghui Liu and Yong Liu and Suzhen Liang and Hua Liang and Zifeng Liu and Xiaoxian Qian and Jiangtao Ren and Yanming Chen},
  doi          = {10.1016/j.artmed.2023.102554},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102554},
  shortjournal = {Artif. Intell. Med.},
  title        = {Differential diagnosis of secondary hypertension based on deep learning},
  volume       = {141},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multistep automated data labelling procedure (MADLaP) for
thyroid nodules on ultrasound: An artificial intelligence approach for
automating image annotation. <em>ARTMED</em>, <em>141</em>, 102553. (<a
href="https://doi.org/10.1016/j.artmed.2023.102553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) for diagnosis of thyroid nodules on ultrasound is an active area of research. However, ML tools require large, well-labeled datasets, the curation of which is time-consuming and labor-intensive. The purpose of our study was to develop and test a deep-learning-based tool to facilitate and automate the data annotation process for thyroid nodules; we named our tool Multistep Automated Data Labelling Procedure (MADLaP). MADLaP was designed to take multiple inputs including pathology reports, ultrasound images, and radiology reports. Using multiple step-wise ‘modules’ including rule-based natural language processing , deep-learning-based imaging segmentation, and optical character recognition , MADLaP automatically identified images of a specific thyroid nodule and correctly assigned a pathology label. The model was developed using a training set of 378 patients across our health system and tested on a separate set of 93 patients. Ground truths for both sets were selected by an experienced radiologist. Performance metrics including yield (how many labeled images the model produced) and accuracy (percentage correct) were measured using the test set. MADLaP achieved a yield of 63 % and an accuracy of 83 %. The yield progressively increased as the input data moved through each module, while accuracy peaked part way through. Error analysis showed that inputs from certain examination sites had lower accuracy (40 %) than the other sites (90 %, 100 %). MADLaP successfully created curated datasets of labeled ultrasound images of thyroid nodules . While accurate, the relatively suboptimal yield of MADLaP exposed some challenges when trying to automatically label radiology images from heterogeneous sources. The complex task of image curation and annotation could be automated, allowing for enrichment of larger datasets for use in machine learning development.},
  archive      = {J_ARTMED},
  author       = {Jikai Zhang and Maciej A. Mazurowski and Brian C. Allen and Benjamin Wildman-Tobriner},
  doi          = {10.1016/j.artmed.2023.102553},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102553},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multistep automated data labelling procedure (MADLaP) for thyroid nodules on ultrasound: An artificial intelligence approach for automating image annotation},
  volume       = {141},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic semantic segmentation of the lumbar spine:
Clinical applicability in a multi-parametric and multi-center study on
magnetic resonance images. <em>ARTMED</em>, <em>140</em>, 102559. (<a
href="https://doi.org/10.1016/j.artmed.2023.102559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant difficulties in medical image segmentation include the high variability of images caused by their origin (multi-center), the acquisition protocols (multi-parametric), the variability of human anatomy, illness severity, the effect of age and gender, and notable other factors. This work addresses problems associated with the automatic semantic segmentation of lumbar spine magnetic resonance images using convolutional neural networks . We aimed to assign a class label to each pixel of an image, with classes defined by radiologists corresponding to structural elements such as vertebrae , intervertebral discs , nerves, blood vessels, and other tissues. The proposed network topologies represent variants of the U-Net architecture, and we used several complementary blocks to define the variants: three types of convolutional blocks, spatial attention models, deep supervision, and multilevel feature extractor. Here, we describe the topologies and analyze the results of the neural network designs that obtained the most accurate segmentation. Several proposed designs outperform the standard U-Net used as a baseline, primarily when used in ensembles, where the outputs of multiple neural networks are combined according to different strategies.},
  archive      = {J_ARTMED},
  author       = {Jhon Jairo Sáenz-Gamboa and Julio Domenech and Antonio Alonso-Manjarrés and Jon A. Gómez and Maria de la Iglesia-Vayá},
  doi          = {10.1016/j.artmed.2023.102559},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102559},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic semantic segmentation of the lumbar spine: Clinical applicability in a multi-parametric and multi-center study on magnetic resonance images},
  volume       = {140},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying stroke-related quantified evidence from
electronic health records in real-world studies. <em>ARTMED</em>,
<em>140</em>, 102552. (<a
href="https://doi.org/10.1016/j.artmed.2023.102552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke is one of the leading causes of death and disability worldwide. The National Institutes of Health Stroke Scale (NIHSS) scores in electronic health records (EHRs), which quantitatively describe patients&#39; neurological deficits in evidence-based treatment, are crucial in stroke-related clinical investigations. However, the free-text format and lack of standardization inhibit their effective use. Automatically extracting the scale scores from the clinical free text so that its potential value in real-world studies is realized has become an important goal. This study aims to develop an automated method to extract scale scores from the free text of EHRs. We propose a two-step pipeline method to identify NIHSS items and numerical scores and validate its feasibility using a freely accessible critical care database: MIMIC-III (Medical Information Mart for Intensive Care III). First, we utilize MIMIC-III to create an annotated corpus. Then, we investigate possible machine learning methods for two subtasks, NIHSS item and score recognition and item-score relation extraction. In the evaluation, we conduct both task-specific and end-to-end evaluations and compare our method with the rule-based method using precision, recall and F1 scores as evaluation metrics . We use all available discharge summaries of stroke cases in MIMIC-III. The annotated NIHSS corpus contains 312 cases, 2929 scale items, 2774 scores and 2733 relations. The results show that the best F1-score of our method was 0.9006, which was attained by combining BERT-BiLSTM-CRF and Random Forest , and it outperformed the rule-based method (F1-score = 0.8098). In the end-to-end task, our method could successfully recognize the item “1b level of consciousness questions”, the score “1” and their relation “(‘1b level of consciousness questions’, ‘1’, ‘has value’)” from the sentence “1b level of consciousness questions: said name = 1”, while the rule-based method could not. The two-step pipeline method we propose is an effective approach to identify NIHSS items, scores and their relations. With its help, clinical investigators can easily retrieve and access structured scale data, thereby supporting stroke-related real-world studies.},
  archive      = {J_ARTMED},
  author       = {Lin Yang and Xiaoshuo Huang and Jiayang Wang and Xin Yang and Lingling Ding and Zixiao Li and Jiao Li},
  doi          = {10.1016/j.artmed.2023.102552},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102552},
  shortjournal = {Artif. Intell. Med.},
  title        = {Identifying stroke-related quantified evidence from electronic health records in real-world studies},
  volume       = {140},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Term dependency extraction using rule-based bayesian network
for medical image retrieval. <em>ARTMED</em>, <em>140</em>, 102551. (<a
href="https://doi.org/10.1016/j.artmed.2023.102551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-Based Medical Image Retrieval (TBMIR) has been known to be successful in retrieving medical images with textual descriptions. Usually, these descriptions are very brief and cannot express the whole visual content of the image in words, hence negatively affect the retrieval performance . One of the solutions offered in the literature is to form a Bayesian Network thesaurus taking advantage of some medical terms extracted from the image datasets. Despite the interestingness of this solution, it is not efficient as it is highly related to the co-occurrence measure, the layer arrangement and the arc directions. A significant drawback of the co-occurrence measure is the generation of a lot of uninteresting co-occurring terms. Several studies applied the association rules mining and its measures to discover the correlation between the terms. In this paper, we propose a new efficient association Rule Based Bayesian Network (R2BN) model for TBMIR using updated medically-dependent features (MDF) based on Unified Medical Language System (UMLS). The MDF are a set of medical terms that refers to the imaging modalities , the image color, the searched object dimension, etc. The proposed model presents the association rules mined from MDF in the form of Bayesian Network model . Then, it exploits the association rule measures (support, confidence, and lift) to prune the Bayesian Network model for efficient computation. The proposed R2BN model is combined with a literature probabilistic model to predict the relevance of an image to a given query. Experiments are carried out with ImageCLEF medical retrieval task collections from 2009 to 2013. Results show that our proposed model enhances significantly the image retrieval accuracy compared to the state-of-the-art retrieval models .},
  archive      = {J_ARTMED},
  author       = {Hajer Ayadi and Mouna Torjmen-Khemakhem and Jimmy X. Huang},
  doi          = {10.1016/j.artmed.2023.102551},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102551},
  shortjournal = {Artif. Intell. Med.},
  title        = {Term dependency extraction using rule-based bayesian network for medical image retrieval},
  volume       = {140},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using graph rewriting to operationalize medical knowledge
for the revision of concurrently applied clinical practice guidelines.
<em>ARTMED</em>, <em>140</em>, 102550. (<a
href="https://doi.org/10.1016/j.artmed.2023.102550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical practice guidelines (CPGs) are patient management tools that synthesize medical knowledge into an actionable format. CPGs are disease specific with limited applicability to the management of complex patients suffering from multimorbidity . For the management of these patients, CPGs need to be augmented with secondary medical knowledge coming from a variety of knowledge repositories . The operationalization of this knowledge is key to increasing CPGs’ uptake in clinical practice. In this work, we propose an approach to operationalizing secondary medical knowledge inspired by graph rewriting. We assume that the CPGs can be represented as task network models, and provide an approach for representing and applying codified medical knowledge to a specific patient encounter. We formally define revisions that model and mitigate adverse interactions between CPGs and we use a vocabulary of terms to instantiate these revisions. We demonstrate the application of our approach using synthetic and clinical examples. We conclude by identifying areas for future work with the vision of developing a theory of mitigation that will facilitate the development of comprehensive decision support for the management of multimorbid patients.},
  archive      = {J_ARTMED},
  author       = {Martin Michalowski and Malvika Rao and Szymon Wilk and Wojtek Michalowski and Marc Carrier},
  doi          = {10.1016/j.artmed.2023.102550},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102550},
  shortjournal = {Artif. Intell. Med.},
  title        = {Using graph rewriting to operationalize medical knowledge for the revision of concurrently applied clinical practice guidelines},
  volume       = {140},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep cross-modal feature learning applied to predict acutely
decompensated heart failure using in-home collected electrocardiography
and transthoracic bioimpedance. <em>ARTMED</em>, <em>140</em>, 102548.
(<a href="https://doi.org/10.1016/j.artmed.2023.102548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been successfully applied to ECG data to aid in the accurate and more rapid diagnosis of acutely decompensated heart failure (ADHF). Previous applications focused primarily on classifying known ECG patterns in well-controlled clinical settings. However, this approach does not fully capitalize on the potential of deep learning, which directly learns important features without relying on a priori knowledge. In addition, deep learning applications to ECG data obtained from wearable devices have not been well studied, especially in the field of ADHF prediction. We used ECG and transthoracic bioimpedance data from the SENTINEL-HF study, which enrolled patients (≥21 years) who were hospitalized with a primary diagnosis of heart failure or with ADHF symptoms. To build an ECG-based prediction model of ADHF, we developed a deep cross-modal feature learning pipeline, termed ECGX-Net, that utilizes raw ECG time series and transthoracic bioimpedance data from wearable devices. To extract rich features from ECG time series data, we first adopted a transfer learning approach in which ECG time series were transformed into 2D images, followed by feature extraction using ImageNet-pretrained DenseNet121/VGG19 models. After data filtering, we applied cross-modal feature learning in which a regressor was trained with ECG and transthoracic bioimpedance. Then, we concatenated the DenseNet121/VGG19 features with the regression features and used them to train a support vector machine (SVM) without bioimpedance information. The high-precision classifier using ECGX-Net predicted ADHF with a precision of 94 %, a recall of 79 %, and an F1-score of 0.85. The high-recall classifier with only DenseNet121 had a precision of 80 %, a recall of 98 %, and an F1-score of 0.88. We found that ECGX-Net was effective for high-precision classification, while DenseNet121 was effective for high-recall classification. We show the potential for predicting ADHF from single-channel ECG recordings obtained from outpatients, enabling timely warning signs of heart failure. Our cross-modal feature learning pipeline is expected to improve ECG-based heart failure prediction by handling the unique requirements of medical scenarios and resource limitations.},
  archive      = {J_ARTMED},
  author       = {Xiang Pan and Chuangqi Wang and Yudong Yu and Natasa Reljin and David D. McManus and Chad E. Darling and Ki H. Chon and Yitzhak Mendelson and Kwonmoo Lee},
  doi          = {10.1016/j.artmed.2023.102548},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102548},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep cross-modal feature learning applied to predict acutely decompensated heart failure using in-home collected electrocardiography and transthoracic bioimpedance},
  volume       = {140},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Are current clinical studies on artificial
intelligence-based medical devices comprehensive enough to support a
full health technology assessment? A systematic review. <em>ARTMED</em>,
<em>140</em>, 102547. (<a
href="https://doi.org/10.1016/j.artmed.2023.102547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence-based Medical Devices (AI-based MDs) are experiencing exponential growth in healthcare. This study aimed to investigate whether current studies assessing AI contain the information required for health technology assessment (HTA) by HTA bodies. We conducted a systematic literature review based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses methodology to extract articles published between 2016 and 2021 related to the assessment of AI-based MDs. Data extraction focused on study characteristics, technology, algorithms, comparators, and results. AI quality assessment and HTA scores were calculated to evaluate whether the items present in the included studies were concordant with the HTA requirements. We performed a linear regression for the HTA and AI scores with the explanatory variables of the impact factor, publication date, and medical specialty. We conducted a univariate analysis of the HTA score and a multivariate analysis of the AI score with an alpha risk of 5 %. Of 5578 retrieved records, 56 were included. The mean AI quality assessment score was 67 %; 32 % of articles had an AI quality score ≥ 70 %, 50 % had a score between 50 % and 70 %, and 18 % had a score under 50 %. The highest quality scores were observed for the study design (82 %) and optimisation (69 %) categories, whereas the scores were lowest in the clinical practice category (23 %). The mean HTA score was 52 % for all seven domains. 100 % of the studies assessed clinical effectiveness, whereas only 9 % evaluated safety, and 20 % evaluated economic issues. There was a statistically significant relationship between the impact factor and the HTA and AI scores (both p = 0.046). Clinical studies on AI-based MDs have limitations and often lack adapted, robust, and complete evidence. High-quality datasets are also required because the output data can only be trusted if the inputs are reliable. The existing assessment frameworks are not specifically designed to assess AI-based MDs. From the perspective of regulatory authorities, we suggest that these frameworks should be adapted to assess the interpretability, explainability, cybersecurity, and safety of ongoing updates. From the perspective of HTA agencies, we highlight that transparency, professional and patient acceptance, ethical issues, and organizational changes are required for the implementation of these devices. Economic assessments of AI should rely on a robust methodology (business impact or health economic models) to provide decision-makers with more reliable evidence. Currently, AI studies are insufficient to cover HTA prerequisites. HTA processes also need to be adapted because they do not consider the important specificities of AI-based MDs. Specific HTA workflows and accurate assessment tools should be designed to standardise evaluations, generate reliable evidence, and create confidence.},
  archive      = {J_ARTMED},
  author       = {Line Farah and Julie Davaze-Schneider and Tess Martin and Pierre Nguyen and Isabelle Borget and Nicolas Martelli},
  doi          = {10.1016/j.artmed.2023.102547},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102547},
  shortjournal = {Artif. Intell. Med.},
  title        = {Are current clinical studies on artificial intelligence-based medical devices comprehensive enough to support a full health technology assessment? a systematic review},
  volume       = {140},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unique color-coded visualization system with multimodal
information fusion and deep learning in a longitudinal study of
alzheimer’s disease. <em>ARTMED</em>, <em>140</em>, 102543. (<a
href="https://doi.org/10.1016/j.artmed.2023.102543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated diagnosis and prognosis of Alzheimer&#39;s Disease remain a challenging problem that machine learning (ML) techniques have attempted to resolve in the last decade. This study introduces a first-of-its-kind color-coded visualization mechanism driven by an integrated ML model to predict disease trajectory in a 2-year longitudinal study. The main aim of this study is to help capture visually in 2D and 3D renderings the diagnosis and prognosis of AD, therefore augmenting our understanding of the processes of multiclass classification and regression analysis. The proposed method, Machine Learning for Visualizing AD (ML4VisAD), is designed to predict disease progression through a visual output. This newly developed model takes baseline measurements as input to generate a color-coded visual image that reflects disease progression at different time points. The architecture of the network relies on convolutional neural networks . With 1123 subjects selected from the ADNI QT-PAD dataset, we use a 10-fold cross-validation process to evaluate the method. Multimodal inputs* include neuroimaging data (MRI, PET), neuropsychological test scores (excluding MMSE , CDR-SB, and ADAS to avoid bias), cerebrospinal fluid (CSF) biomarkers with measures of amyloid beta (ABETA), phosphorylated tau protein (PTAU), total tau protein (TAU), and risk factors that include age, gender, years of education, and ApoE4 gene. Based on subjective scores reached by three raters, the results showed an accuracy of 0.82 ± 0.03 for a 3-way classification and 0.68 ± 0.05 for a 5-way classification. The visual renderings were generated in 0.08 msec for a 23 × 23 output image and in 0.17 ms for a 45 × 45 output image. Through visualization, this study (1) demonstrates that the ML visual output augments the prospects for a more accurate diagnosis and (2) highlights why multiclass classification and regression analysis are incredibly challenging. An online survey was conducted to gauge this visualization platform&#39;s merits and obtain valuable feedback from users. All implementation codes are shared online on GitHub. This approach makes it possible to visualize the many nuances that lead to a specific classification or prediction in the disease trajectory, all in context to multimodal measurements taken at baseline. This ML model can serve as a multiclass classification and prediction model while reinforcing the diagnosis and prognosis capabilities by including a visualization platform.},
  archive      = {J_ARTMED},
  author       = {Mohammad Eslami and Solale Tabarestani and Malek Adjouadi},
  doi          = {10.1016/j.artmed.2023.102543},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102543},
  shortjournal = {Artif. Intell. Med.},
  title        = {A unique color-coded visualization system with multimodal information fusion and deep learning in a longitudinal study of alzheimer&#39;s disease},
  volume       = {140},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RIMD: A novel method for clinical prediction.
<em>ARTMED</em>, <em>140</em>, 102526. (<a
href="https://doi.org/10.1016/j.artmed.2023.102526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic health records (EHR) are sparse, noisy, and private, with variable vital measurements and stay lengths. Deep learning models are the current state of the art in many machine learning domain; however, the EHR data is not a suitable training input for most of them. In this paper, we introduce RIMD, a novel deep learning model that consists of a decay mechanism, modular recurrent networks , and a custom loss function that learns minor classes. The decay mechanism learns from patterns in sparse data. The modular network allows multiple recurrent networks to pick only relevant input based on the attention score at a given timestamp. Finally, the custom class balance loss function is responsible for learning minor classes based on samples provided in training. This novel model is used to evaluate predictions for early mortality identification, length of stay, and acute respiratory failure on MIMIC-III dataset. Experiment results indicate that the proposed models outperform similar models in F1-Score, AUROC, and PRAUC scores.},
  archive      = {J_ARTMED},
  author       = {Saroj Basnet and Sirvan Parasteh and Alireza Manashty and Brandon Sasyniuk},
  doi          = {10.1016/j.artmed.2023.102526},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102526},
  shortjournal = {Artif. Intell. Med.},
  title        = {RIMD: A novel method for clinical prediction},
  volume       = {140},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Systematic review and meta-analysis of prediction models
used in cervical cancer. <em>ARTMED</em>, <em>139</em>, 102549. (<a
href="https://doi.org/10.1016/j.artmed.2023.102549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer is one of the most common cancers in women with an incidence of around 6.5 % of all the cancer in women worldwide. Early detection and adequate treatment according to staging improve the patient&#39;s life expectancy. Outcome prediction models might aid treatment decisions, but a systematic review on prediction models for cervical cancer patients is not available. We performed a systematic review for prediction models in cervical cancer following PRISMA guidelines. Key features that were used for model training and validation, the endpoints were extracted from the article and data were analyzed. Selected articles were grouped based on prediction endpoints i.e. Group1: Overall survival , Group2: progression-free survival; Group3: recurrence or distant metastasis ; Group4: treatment response; Group5: toxicity or quality of life . We developed a scoring system to evaluate the manuscript. As per our criteria, studies were divided into four groups based on scores obtained in our scoring system, the Most significant study (Score &gt; 60 %); Significant study (60 % &gt; Score &gt; 50 %); Moderately Significant study (50 % &gt; Score &gt; 40 %); least significant study (score &lt; 40 %). A meta-analysis was performed for all the groups separately. The first line of search selected 1358 articles and finally 39 articles were selected as eligible for inclusion in the review. As per our assessment criteria, 16, 13 and 10 studies were found to be the most significant, significant and moderately significant respectively. The intra-group pooled correlation coefficient for Group1, Group2, Group3, Group4, and Group5 were 0.76 [0.72, 0.79], 0.80 [0.73, 0.86], 0.87 [0.83, 0.90], 0.85 [0.77, 0.90], 0.88 [0.85, 0.90] respectively. All the models were found to be good (prediction accuracy [c-index/AUC/R 2 ] &gt;0.7) in endpoint prediction. Prediction models of cervical cancer toxicity, local or distant recurrence and survival prediction show promising results with reasonable prediction accuracy [c-index/AUC/R 2 &gt; 0.7]. These models should also be validated on external data and evaluated in prospective clinical studies.},
  archive      = {J_ARTMED},
  author       = {Ashish Kumar Jha and Sneha Mithun and Umeshkumar B. Sherkhane and Vinay Jaiswar and Biche Osong and Nilendu Purandare and Sadhana Kannan and Kumar Prabhash and Sudeep Gupta and Ben Vanneste and Venkatesh Rangarajan and Andre Dekker and Leonard Wee},
  doi          = {10.1016/j.artmed.2023.102549},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102549},
  shortjournal = {Artif. Intell. Med.},
  title        = {Systematic review and meta-analysis of prediction models used in cervical cancer},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new method for estimating the probability of causal
relationships from observational data: Application to the study of the
short-term effects of air pollution on cardiovascular and respiratory
disease. <em>ARTMED</em>, <em>139</em>, 102546. (<a
href="https://doi.org/10.1016/j.artmed.2023.102546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate which airborne pollutants have a short-term causal effect on cardiovascular and respiratory disease using the Ancestral Probabilities (AP) procedure, a novel Bayesian approach for deriving the probabilities of causal relationships from observational data. The results are largely consistent with EPA assessments of causality, however, in a few cases AP suggests that some pollutants thought to cause cardiovascular or respiratory disease are associated due purely to confounding. The AP procedure utilizes maximal ancestral graph (MAG) models to represent and assign probabilities to causal relationships while accounting for latent confounding. The algorithm does so locally by marginalizing over models with and without causal features of interest. Before applying AP to real data, we evaluate it in a simulation study and investigate the benefits of providing background knowledge. Overall, the results suggest that AP is an effective tool for causal discovery.},
  archive      = {J_ARTMED},
  author       = {Bryan Andrews and Chirayu Wongchokprasitti and Shyam Visweswaran and Chirag M. Lakhani and Chirag J. Patel and Gregory F. Cooper},
  doi          = {10.1016/j.artmed.2023.102546},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102546},
  shortjournal = {Artif. Intell. Med.},
  title        = {A new method for estimating the probability of causal relationships from observational data: Application to the study of the short-term effects of air pollution on cardiovascular and respiratory disease},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoSumNet: A video summarization-based framework for COVID-19
monitoring in crowded scenes. <em>ARTMED</em>, <em>139</em>, 102544. (<a
href="https://doi.org/10.1016/j.artmed.2023.102544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of COVID-19 pandemic poses new challenges to research community to investigate novel mechanisms for monitoring as well as controlling its further spread via crowded scenes. Moreover, the contemporary methods of COVID-19 preventions are enforcing strict protocols in the public places. The emergence of robust computer vision-enabled applications leverages intelligent frameworks for monitoring of the pandemic deterrence in public places. The employment of COVID-19 protocols via wearing face masks by human is an effective procedure that is implemented in several countries across the world. It is a challenging task for authorities to manually monitor these protocols particularly in densely crowded public gatherings such as, shopping malls, railway stations , airports , religious places etc. Thus, to overcome these issues, the proposed research aims to design an operative method that automatically detects the violation of face mask regulation for COVID-19 pandemic. In this research work , we expound a novel technique for COVID-19 protocol desecration via video summarization in the crowded scenes (CoSumNet). Our approach automatically yields short summaries from crowded video scenes (i.e., with and without mask human). Besides, the CoSumNet can be deployed in crowded places that may assist the controlling agencies to take appropriate actions to enforce the penalty to the protocol violators. To evaluate the efficacy of the approach, the CoSumNet is trained on a benchmark “Face Mask Detection ∼12K Images Dataset” and validated through various real-time CCTV videos. The CoSumNet demonstrates superior performance of 99.98 % and 99.92 % detection accuracy in the seen and unseen scenarios respectively. Our method offers promising performance in cross-datasets environments as well as on a variety of face masks. Furthermore, the model can convert the longer videos to short summaries in nearly 5–20 s approximately.},
  archive      = {J_ARTMED},
  author       = {Ambreen Sabha and Arvind Selwal},
  doi          = {10.1016/j.artmed.2023.102544},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102544},
  shortjournal = {Artif. Intell. Med.},
  title        = {CoSumNet: A video summarization-based framework for COVID-19 monitoring in crowded scenes},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of focal and non-focal EEG signals using
optimal geometrical features derived from a second-order difference plot
of FBSE-EWT rhythms. <em>ARTMED</em>, <em>139</em>, 102542. (<a
href="https://doi.org/10.1016/j.artmed.2023.102542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual detection and localization of the brain’s epileptogenic areas using electroencephalogram (EEG) signals is time-intensive and error-prone. An automated detection system is, thus, highly desirable for support in clinical diagnosis. A set of relevant and significant non-linear features plays a major role in developing a reliable, automated focal detection system. A new feature extraction method is designed to classify focal EEG signals using eleven non-linear geometrical attributes derived from the Fourier–Bessel series expansion-based empirical wavelet transform (FBSE-EWT) segmented rhythm’s second-order difference plot (SODP). A total of 132 features (2 channels × × 6 rhythms × × 11 geometrical attributes) were computed. However, some of the obtained features might be non-significant and redundant features. Hence, to acquire an optimal set of relevant non-linear features, a new hybridization of ‘Kruskal–Wallis statistical test (KWS)’ with ‘VlseKriterijuska Optimizacija I Komoromisno Resenje’ termed as the KWS-VIKOR approach was adopted. The KWS-VIKOR has a two-fold operational feature. First, the significant features are selected using the KWS test with a p p -value lesser than 0.05. Next, the multi-attribute decision-making (MADM) based VIKOR method ranks the selected features. Several classification methods further validate the efficacy of the features of the selected top n n %. The proposed framework has been evaluated using the Bern-Barcelona dataset. The highest classification accuracy of 98.7% was achieved using the top 35% ranked features in classifying the focal and non-focal EEG signals with the least-squares support vector machine (LS-SVM) classifier. The achieved results exceeded those reported through other methods. Hence, the proposed framework will more effectively assist the clinician in localizing the epileptogenic areas.},
  archive      = {J_ARTMED},
  author       = {Arti Anuragi and Dilip Singh Sisodia and Ram Bilas Pachori},
  doi          = {10.1016/j.artmed.2023.102542},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102542},
  shortjournal = {Artif. Intell. Med.},
  title        = {Classification of focal and non-focal EEG signals using optimal geometrical features derived from a second-order difference plot of FBSE-EWT rhythms},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aggregated micropatch-based deep learning neural network for
ultrasonic diagnosis of cirrhosis. <em>ARTMED</em>, <em>139</em>,
102541. (<a href="https://doi.org/10.1016/j.artmed.2023.102541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the advancements in the diagnosis of early-stage cirrhosis , the accuracy in the diagnosis using ultrasound is still challenging owing to the presence of various image artifacts, which results in poor visual quality of the textural and lower-frequency components. In this study, we propose an end-to-end multistep network called CirrhosisNet that includes two transfer-learned convolutional neural networks for semantic segmentation and classification tasks . It uses a uniquely designed image, called an aggregated micropatch (AMP), as an input image to the classification network, thereby assessing whether the liver is in a cirrhotic stage. With a prototype AMP image, we synthesized a bunch of AMP images while retaining the textural features. This synthesis significantly increases the number of insufficient cirrhosis-labeled images, thereby circumventing overfitting issues and optimizing network performance. Furthermore, the synthesized AMP images contained unique textural patterns, mostly generated on the boundaries between adjacent micropatches (μ-patches) during their aggregation. These newly created boundary patterns provide rich information regarding the texture features of the ultrasound image, thereby making cirrhosis diagnosis more accurate and sensitive. The experimental results demonstrated that our proposed AMP image synthesis is extremely effective in expanding the dataset of cirrhosis images, thus diagnosing liver cirrhosis with considerably high accuracy. We achieved an accuracy of 99.95 %, a sensitivity of 100 %, and a specificity of 99.9 % on the Samsung Medical Center dataset using 8 × 8 pixels-sized μ-patches. The proposed approach provides an effective solution to deep-learning models with limited-training data, such as medical imaging tasks.},
  archive      = {J_ARTMED},
  author       = {Se-Yeol Rhyou and Jae-Chern Yoo},
  doi          = {10.1016/j.artmed.2023.102541},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102541},
  shortjournal = {Artif. Intell. Med.},
  title        = {Aggregated micropatch-based deep learning neural network for ultrasonic diagnosis of cirrhosis},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantifying the impact of data characteristics on the
transferability of sleep stage scoring models. <em>ARTMED</em>,
<em>139</em>, 102540. (<a
href="https://doi.org/10.1016/j.artmed.2023.102540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models for scoring sleep stages based on single-channel EEG have been proposed as a promising method for remote sleep monitoring. However, applying these models to new datasets, particularly from wearable devices , raises two questions. First, when annotations on a target dataset are unavailable, which different data characteristics affect the sleep stage scoring performance the most and by how much? Second, when annotations are available, which dataset should be used as the source of transfer learning to optimize performance? In this paper, we propose a novel method for computationally quantifying the impact of different data characteristics on the transferability of deep learning models. Quantification is accomplished by training and evaluating two models with significant architectural differences, TinySleepNet and U-Time, under various transfer configurations in which the source and target datasets have different recording channels, recording environments, and subject conditions. For the first question, the environment had the highest impact on sleep stage scoring performance, with performance degrading by over 14% when sleep annotations were unavailable. For the second question, the most useful transfer sources for TinySleepNet and the U-Time models were MASS-SS1 and ISRUC-SG1, containing a high percentage of N1 (the rarest sleep stage) relative to the others. The frontal and central EEGs were preferred for TinySleepNet. The proposed approach enables full utilization of existing sleep datasets for training and planning model transfer to maximize the sleep stage scoring performance on a target problem when sleep annotations are limited or unavailable, supporting the realization of remote sleep monitoring.},
  archive      = {J_ARTMED},
  author       = {Akara Supratak and Peter Haddawy},
  doi          = {10.1016/j.artmed.2023.102540},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102540},
  shortjournal = {Artif. Intell. Med.},
  title        = {Quantifying the impact of data characteristics on the transferability of sleep stage scoring models},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BiTNet: Hybrid deep convolutional model for ultrasound image
analysis of human biliary tract and its applications. <em>ARTMED</em>,
<em>139</em>, 102539. (<a
href="https://doi.org/10.1016/j.artmed.2023.102539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Certain life-threatening abnormalities, such as cholangiocarcinoma , in the human biliary tract are curable if detected at an early stage, and ultrasonography has been proven to be an effective tool for identifying them. However, the diagnosis often requires a second opinion from experienced radiologists , who are usually overwhelmed by many cases. Therefore, we propose a deep convolutional neural network model , named biliary tract network (BiTNet), developed to solve problems in the current screening system and to avoid overconfidence issues of traditional deep convolutional neural networks. Additionally, we present an ultrasound image dataset for the human biliary tract and demonstrate two artificial intelligence (AI) applications: auto-prescreening and assisting tools. The proposed model is the first AI model to automatically screen and diagnose upper-abdominal abnormalities from ultrasound images in real-world healthcare scenarios. Our experiments suggest that prediction probability has an impact on both applications, and our modifications to EfficientNet solve the overconfidence problem, thereby improving the performance of both applications and of healthcare professionals. The proposed BiTNet can reduce the workload of radiologists by 35% while keeping the false negatives to as low as 1 out of every 455 images. Our experiments involving 11 healthcare professionals with four different levels of experience reveal that BiTNet improves the diagnostic performance of participants of all levels. The mean accuracy and precision of the participants with BiTNet as an assisting tool (0.74 and 0.61, respectively) are statistically higher than those of participants without the assisting tool (0.50 and 0.46, respectively ( p &lt; 0 . 001 p&amp;lt;0.001 )). These experimental results demonstrate the high potential of BiTNet for use in clinical settings.},
  archive      = {J_ARTMED},
  author       = {Thanapong Intharah and Kannika Wiratchawa and Yupaporn Wanna and Prem Junsawang and Attapol Titapun and Anchalee Techasen and Arunnit Boonrod and Vallop Laopaiboon and Nittaya Chamadol and Narong Khuntikeo},
  doi          = {10.1016/j.artmed.2023.102539},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102539},
  shortjournal = {Artif. Intell. Med.},
  title        = {BiTNet: Hybrid deep convolutional model for ultrasound image analysis of human biliary tract and its applications},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gynecological cancer prognosis using machine learning
techniques: A systematic review of the last three decades (1990–2022).
<em>ARTMED</em>, <em>139</em>, 102536. (<a
href="https://doi.org/10.1016/j.artmed.2023.102536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many Computer Aided Prognostic (CAP) systems based on machine learning techniques have been proposed in the field of oncology . The objective of this systematic review was to assess and critically appraise the methodologies and approaches used in predicting the prognosis of gynecological cancers using CAPs. Electronic databases were used to systematically search for studies utilizing machine learning methods in gynecological cancers . Study risk of bias (ROB) and applicability were assessed using the PROBAST tool. 139 studies met the inclusion criteria, of which 71 predicted outcomes for ovarian cancer patients, 41 predicted outcomes for cervical cancer patients, 28 predicted outcomes for uterine cancer patients, and 2 predicted outcomes for gynecological malignancies broadly. Random forest (22.30 %) and support vector machine (21.58 %) classifiers were used most commonly. Use of clinicopathological, genomic and radiomic data as predictors was observed in 48.20 %, 51.08 % and 17.27 % of studies, respectively, with some studies using multiple modalities. 21.58 % of studies were externally validated. Twenty-three individual studies compared ML and non-ML methods. Study quality was highly variable and methodologies, statistical reporting and outcome measures were inconsistent, preventing generalized commentary or meta-analysis of performance outcomes. There is significant variability in model development when prognosticating gynecological malignancies with respect to variable selection, machine learning (ML) methods and endpoint selection. This heterogeneity prevents meta-analysis and conclusions regarding the superiority of ML methods. Furthermore, PROBAST-mediated ROB and applicability analysis demonstrates concern for the translatability of existing models. This review identifies ways that this can be improved upon in future works to develop robust, clinically translatable models within this promising field.},
  archive      = {J_ARTMED},
  author       = {Joshua Sheehy and Hamish Rutledge and U. Rajendra Acharya and Hui Wen Loh and Raj Gururajan and Xiaohui Tao and Xujuan Zhou and Yuefeng Li and Tiana Gurney and Srinivas Kondalsamy-Chennakesavan},
  doi          = {10.1016/j.artmed.2023.102536},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102536},
  shortjournal = {Artif. Intell. Med.},
  title        = {Gynecological cancer prognosis using machine learning techniques: A systematic review of the last three decades (1990–2022)},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge graph assisted end-to-end medical dialog
generation. <em>ARTMED</em>, <em>139</em>, 102535. (<a
href="https://doi.org/10.1016/j.artmed.2023.102535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical dialog systems have the potential to assist e-medicine in improving access to healthcare services , improving patient treatment quality, and lowering medical expenses. In this research, we describe a knowledge-grounded conversation generation model that demonstrates how large-scale medical information in the form of knowledge graphs can aid in language comprehension and generation in medical dialog systems. Generic responses are often produced by existing generative dialog systems, resulting in monotonous and uninteresting conversations. To solve this problem, we combine various pre-trained language models with a medical knowledge base (UMLS) to generate clinically correct and human-like medical conversations using the recently released MedDialog-EN dataset. The medical-specific knowledge graph contains broadly 3 types of medical-related information, including disease, symptom and laboratory test . We perform reasoning over the retrieved knowledge graph by reading the triples in each graph using MedFact attention, which allows us to use semantic information from the graphs for better response generation . In order to preserve medical information, we employ a policy network, which effectively injects relevant entities associated with each dialog into the response. We also study how transfer learning can significantly improve the performance by utilizing a relatively small corpus, created by extending the recently released CovidDialog dataset, containing the dialogs for diseases that are symptoms of Covid-19. Empirical results on the MedDialog corpus and the extended CovidDialog dataset demonstrate that our proposed model significantly outperforms the state-of-the-art methods in terms of both automatic evaluation and human judgment .},
  archive      = {J_ARTMED},
  author       = {Deeksha Varshney and Aizan Zafar and Niranshu Kumar Behera and Asif Ekbal},
  doi          = {10.1016/j.artmed.2023.102535},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102535},
  shortjournal = {Artif. Intell. Med.},
  title        = {Knowledge graph assisted end-to-end medical dialog generation},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence and prediction of cardiometabolic
disease: Systematic review of model performance and potential benefits
in indigenous populations. <em>ARTMED</em>, <em>139</em>, 102534. (<a
href="https://doi.org/10.1016/j.artmed.2023.102534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indigenous peoples often have higher rates of morbidity and mortality associated with cardiometabolic disease (CMD) than non-Indigenous people and this may be even more so in urban areas. The use of electronic health records and expansion of computing power has led to mainstream use of artificial intelligence (AI) to predict the onset of disease in primary health care (PHC) settings. However, it is unknown if AI and in particular machine learning is used for risk prediction of CMD in Indigenous peoples. We searched peer-reviewed literature using terms associated with AI machine learning, PHC, CMD, and Indigenous peoples. We identified 13 suitable studies for inclusion in this review. Median total number of participants was 19,270 (range 911–2,994,837). The most common algorithms used in machine learning in this setting were support vector machine, random forest, and decision tree learning. Twelve studies used the area under the receiver operating characteristic curve (AUC) to measure performance. Two studies reported an AUC of &gt;0.9. Six studies had an AUC score between 0.9 and 0.8, 4 studies had an AUC score between 0.8 and 0.7. 1 study reported an AUC score between 0.7 and 0.6. Risk of bias was observed in 10 (77 %) studies. AI machine learning and risk prediction models show moderate to excellent discriminatory ability over traditional statistical models in predicting CMD. This technology could help address the needs of urban Indigenous peoples by predicting CMD early and more rapidly than conventional methods.},
  archive      = {J_ARTMED},
  author       = {Keunwoo Jeong and Alistair R. Mallard and Leanne Coombe and James Ward},
  doi          = {10.1016/j.artmed.2023.102534},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102534},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence and prediction of cardiometabolic disease: Systematic review of model performance and potential benefits in indigenous populations},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of acute hypertensive episodes in critically ill
patients. <em>ARTMED</em>, <em>139</em>, 102525. (<a
href="https://doi.org/10.1016/j.artmed.2023.102525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prevention and treatment of complications are the backbone of medical care, particularly in critical care settings. Early detection and prompt intervention can potentially prevent complications from occurring and improve outcomes. In this study, we use four longitudinal vital signs variables of intensive care unit patients, focusing on predicting acute hypertensive episodes (AHEs). These episodes represent elevations in blood pressure and may result in clinical damage or indicate a change in a patient’s clinical situation, such as an elevation in intracranial pressure or kidney failure. Prediction of AHEs may allow clinicians to anticipate changes in the patient’s condition and respond early on to prevent these from occurring. Temporal abstraction was employed to transform the multivariate temporal data into a uniform representation of symbolic time intervals , from which frequent time-intervals-related patterns (TIRPs) are mined and used as features for AHE prediction. A novel TIRP metric for classification, called coverage , is introduced that measures the coverage of a TIRP’s instances in a time window. For comparison, several baseline models were applied on the raw time series data , including logistic regression and sequential deep learning models, are used. Our results show that using frequent TIRPs as features outperforms the baseline models, and the use of the coverage , metric outperforms other TIRP metrics. Two approaches to predicting AHEs in real-life application conditions are evaluated: using a sliding window to continuously predict whether a patient would experience an AHE within a specific prediction time period ahead, our models produced an AUC-ROC of 82%, but with low AUPRC. Alternatively, predicting whether an AHE would generally occur during the entire admission resulted in an AUC-ROC of 74%.},
  archive      = {J_ARTMED},
  author       = {Nevo Itzhak and Itai M. Pessach and Robert Moskovitch},
  doi          = {10.1016/j.artmed.2023.102525},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102525},
  shortjournal = {Artif. Intell. Med.},
  title        = {Prediction of acute hypertensive episodes in critically ill patients},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Has machine learning over-promised in healthcare?: A
critical analysis and a proposal for improved evaluation, with evidence
from parkinson’s disease. <em>ARTMED</em>, <em>139</em>, 102524. (<a
href="https://doi.org/10.1016/j.artmed.2023.102524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adoption of artificial intelligence (AI) by the medical community has long been anticipated, endorsed by a stream of machine learning literature showcasing AI systems that yield extraordinary performance. However, many of these systems are likely over-promising and will under-deliver in practice. One key reason is the community’s failure to acknowledge and address the presence of inflationary effects in the data. These simultaneously inflate evaluation performance and prevent a model from learning the underlying task, thus severely misrepresenting how that model would perform in the real world. This paper investigated the impact of these inflationary effects on healthcare tasks, as well as how these effects can be addressed. Specifically, we defined three inflationary effects that occur in medical data sets and allow models to easily reach small training losses and prevent skillful learning. We investigated two data sets of sustained vowel phonation from participants with and without Parkinson’s disease, and revealed that published models which have achieved high classification performances on these were artificially enhanced due to the inflationary effects. Our experiments showed that removing each inflationary effect corresponded with a decrease in classification accuracy, and that removing all inflationary effects reduced the evaluated performance by up to 30%. Additionally, the performance on a more realistic test set increased, suggesting that the removal of these inflationary effects enabled the model to better learn the underlying task and generalize. Source code is available at https://github.com/Wenbo-G/pd-phonation-analysis under the MIT license.},
  archive      = {J_ARTMED},
  author       = {Wenbo Ge and Christian Lueck and Hanna Suominen and Deborah Apthorp},
  doi          = {10.1016/j.artmed.2023.102524},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102524},
  shortjournal = {Artif. Intell. Med.},
  title        = {Has machine learning over-promised in healthcare?: A critical analysis and a proposal for improved evaluation, with evidence from parkinson’s disease},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enriching representation learning using 53 million patient
notes through human phenotype ontology embedding. <em>ARTMED</em>,
<em>139</em>, 102523. (<a
href="https://doi.org/10.1016/j.artmed.2023.102523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Human Phenotype Ontology (HPO) is a dictionary of &gt;15,000 clinical phenotypic terms with defined semantic relationships , developed to standardize phenotypic analysis. Over the last decade, the HPO has been used to accelerate the implementation of precision medicine into clinical practice. In addition, recent research in representation learning , specifically in graph embedding, has led to notable progress in automated prediction via learned features. Here, we present a novel approach to phenotype representation by incorporating phenotypic frequencies based on 53 million full-text health care notes from &gt;1.5 million individuals. We demonstrate the efficacy of our proposed phenotype embedding technique by comparing our work to existing phenotypic similarity-measuring methods. Using phenotype frequencies in our embedding technique, we are able to identify phenotypic similarities that surpass current computational models . Furthermore, our embedding technique exhibits a high degree of agreement with domain experts&#39; judgment . By transforming complex and multidimensional phenotypes from the HPO format into vectors, our proposed method enables efficient representation of these phenotypes for downstream tasks that require deep phenotyping. This is demonstrated in a patient similarity analysis and can further be applied to disease trajectory and risk prediction.},
  archive      = {J_ARTMED},
  author       = {Maryam Daniali and Peter D. Galer and David Lewis-Smith and Shridhar Parthasarathy and Edward Kim and Dario D. Salvucci and Jeffrey M. Miller and Scott Haag and Ingo Helbig},
  doi          = {10.1016/j.artmed.2023.102523},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102523},
  shortjournal = {Artif. Intell. Med.},
  title        = {Enriching representation learning using 53 million patient notes through human phenotype ontology embedding},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monitoring hybrid process specifications with conflict
management: An automata-theoretic approach. <em>ARTMED</em>,
<em>139</em>, 102512. (<a
href="https://doi.org/10.1016/j.artmed.2023.102512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complexity of medical treatments can vary from prescribing medicine for a specific ailment to managing a complex set of simultaneous medical issues. In the latter case, doctors are assisted by clinical guidelines which outline standard medical procedures, tests, treatments, etc. To facilitate the use of such guidelines, they can be digitized as processes and adopted in complex process engines offering additional help to health providers such as decision support while monitoring active treatments so as to detect flaws in treatment procedures and suggest possible reactions on them. For example, a patient may present symptoms of multiple diseases simultaneously (requiring multiple clinical guidelines to be followed), while also being allergic to some often-used drugs (requiring additional constraints to be respected). This can easily lead to treating a patient based on a set of process specifications which are not fully compatible with each other. While a scenario like that commonly occurs in practice, research in that direction has thus far given little consideration to how to specify multiple clinical guidelines and how to automatically combine their specifications in the context of the monitoring task. In our previous work [2] , we presented a conceptual framework for handling the above cases in the context of monitoring. In this paper, we present the algorithms necessary for implementing key components of this conceptual framework. More specifically, we provide formal languages for representing clinical guideline specifications and formalize a solution for monitoring the interplay of such specifications expressed as a combination of (data-aware) Petri nets and temporal logic rules. The proposed solution seamlessly handles combination of the input process specifications and provides both early conflict detection and decision support during process execution. We also discuss a proof-of-concept implementation of our approach and present the results of extensive scalability experiments.},
  archive      = {J_ARTMED},
  author       = {Anti Alman and Fabrizio Maria Maggi and Marco Montali and Fabio Patrizi and Andrey Rivkin},
  doi          = {10.1016/j.artmed.2023.102512},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102512},
  shortjournal = {Artif. Intell. Med.},
  title        = {Monitoring hybrid process specifications with conflict management: An automata-theoretic approach},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel discrete learning-based intelligent methodology for
breast cancer classification purposes. <em>ARTMED</em>, <em>139</em>,
102492. (<a href="https://doi.org/10.1016/j.artmed.2023.102492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is one of the most significant subfields of data mining that has been successfully applied to various applications. The literature has expended substantial effort to present more efficient and accurate classification models . Despite the diversity of the proposed models, they were all created using the same methodology, and their learning processes ignored a fundamental issue. In all existing classification model learning processes, a continuous distance-based cost function is optimized to estimate the unknown parameters. The classification problem&#39;s objective function is discrete. Consequently, applying a continuous cost function to a classification problem with a discrete objective function is illogical or inefficient. This paper proposes a novel classification methodology utilizing a discrete cost function in the learning process. To this end, one of the most popular intelligent classification models, the multilayer perceptron (MLP), is used to implement the proposed methodology. Theoretically, the classification performance of the proposed discrete learning-based MLP (DIMLP) model is not dissimilar to that of its continuous learning-based counterpart. Nevertheless, in this study, to demonstrate the efficacy of the DIMLP model, it was applied to several breast cancer classification datasets, and its classification rate was compared to that of the conventional continuous learning-based MLP model. The empirical results indicate that the proposed DIMLP model outperforms the MLP model across all datasets. The results demonstrate that the presented DIMLP classification model achieves an average classification rate of 94.70 %, a 6.95 % improvement over the classification rate of the traditional MLP model, which was 88.54 %. Therefore, the classification approach proposed in this study can be utilized as an alternative learning process in intelligent classification methods for medical decision-making and other classification applications, particularly when more accurate results are required.},
  archive      = {J_ARTMED},
  author       = {Mehdi Khashei and Negar Bakhtiarvand},
  doi          = {10.1016/j.artmed.2023.102492},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102492},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel discrete learning-based intelligent methodology for breast cancer classification purposes},
  volume       = {139},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable domain transfer of distant supervised cancer
subtyping model via imaging-based rules extraction. <em>ARTMED</em>,
<em>138</em>, 102522. (<a
href="https://doi.org/10.1016/j.artmed.2023.102522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image texture analysis has for decades represented a promising opportunity for cancer assessment and disease progression evaluation, evolving in a discipline, i.e., radiomics . However, the road to a complete translation into clinical practice is still hampered by intrinsic limitations. As purely supervised classification models fail in devising robust imaging-based biomarkers for prognosis, cancer subtyping approaches would benefit from the employment of distant supervision, for instance exploiting survival/recurrence information. In this work, we assessed, tested, and validated the domain-generality of our previously proposed Distant Supervised Cancer Subtyping model on Hodgkin Lymphoma . We evaluate the model performance on two independent datasets coming from two hospitals, comparing and analyzing the results. Although successful and consistent, the comparison confirmed the instability of radiomics due to an across-center lack of reproducibility, leading to explainable results in one center and poor interpretability in the other. We thus propose a Random Forest-based Explainable Transfer Model for testing the domain-invariance of imaging biomarkers extracted from retrospective cancer subtyping. In doing so, we tested the predictive ability of cancer subtyping in a validation and perspective setting, which led to successful results and supported the domain-generality of the proposed approach. On the other hand, the extraction of decision rules enables to draw of risk factors and robust biomarkers to inform clinical decisions. This work shows the potentialities of the Distant Supervised Cancer Subtyping model to be further evaluated in larger multi-center datasets, to reliably translate radiomics into medical practice. The code is available at this GitHub repository.},
  archive      = {J_ARTMED},
  author       = {Lara Cavinato and Noemi Gozzi and Martina Sollini and Margarita Kirienko and Carmelo Carlo-Stella and Chiara Rusconi and Arturo Chiti and Francesca Ieva},
  doi          = {10.1016/j.artmed.2023.102522},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102522},
  shortjournal = {Artif. Intell. Med.},
  title        = {Explainable domain transfer of distant supervised cancer subtyping model via imaging-based rules extraction},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supporting patients and clinicians during the breast cancer
care path with AI: The arianna solution. <em>ARTMED</em>, <em>138</em>,
102514. (<a href="https://doi.org/10.1016/j.artmed.2023.102514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The onset of cancer disease is a traumatic experience for both patients and their families that suddenly change the patient’s life and is accompanied by important physical, emotional, and psycho-social problems. The complexity of this scenario has been exacerbated by the COVID-19 pandemic which dramatically affected the continuity of the provision of optimal care to chronic patients. Telemedicine can support the management of oncology care paths by furnishing a suite of effective and efficient tools to monitor the therapies of cancer patients. In particular, this is a suitable setting for therapies that are administered at home. In this paper, we present an AI-based system, called Arianna , designed and implemented to support and monitor patients treated by the professionals belonging to the Breast Cancer Unit Network ( BCU-Net ) along the entire clinical path of breast cancer treatment. We describe in this work the three modules composing the Arianna system (the tools for patients and clinicians, and the symbolic AI-based module). The system has been validated in a qualitative way and we demonstrated how the Arianna solution reached a high level of acceptability by all types of end-users by making it suitable for a concrete integration into the daily practice of the BCU-Net .},
  archive      = {J_ARTMED},
  author       = {Mauro Dragoni and Claudio Eccher and Antonella Ferro and Tania Bailoni and Rosa Maimone and Andrea Zorzi and Alessandro Bacchiega and Gabriele Stulzer and Chiara Ghidini},
  doi          = {10.1016/j.artmed.2023.102514},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102514},
  shortjournal = {Artif. Intell. Med.},
  title        = {Supporting patients and clinicians during the breast cancer care path with AI: The arianna solution},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cognitive computing technological trends and future research
directions in healthcare — a systematic literature review.
<em>ARTMED</em>, <em>138</em>, 102513. (<a
href="https://doi.org/10.1016/j.artmed.2023.102513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive Computing systems are the intelligent systems that thinks, understands and augments the capabilities of human brain by blending the technologies of Artificial Intelligence , Machine Learning and Natural Language Processing . In recent days, maintenance or enhancement of health by preclusion, prognosis, and analysis of diseases has become a challenging task. The increasing diseases and its causes becomes a big question before humanity. Limited risk analysis , meticulous training process, and automated critical decision-making are some of the issues of cognitive computing. To overcome this issue, cognitive computing in healthcare works like a medical prodigy which anticipates the disease or illness of the human being and helps the doctors with technological facts to take the timely action. The main aim of this survey article is to explore the present and futuristic technological trends of cognitive computing in healthcare. In this work, different cognitive computing applications are reviewed, and the best application is recommended to the clinicians. Based on this recommendation, the clinicians are able to monitor and analyze the physical health of patients. This article presents the systematic literature on the different aspects of cognitive computing in healthcare. Nearly seven online databases such as SCOPUS, IEEE Xplore, Google Scholar, DBLP, Web of Science, Springer and PubMed were screened and the published articles related to cognitive computing in healthcare is collected from 2014 to 2021. In total, 75 articles were selected, examined and their pros and cons are analyzed. The analysis is done with respect to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The basic findings of this review article and their significance for theory and practice are mindmaps portraying the cognitive computing platforms, cognitive applications in healthcare, and use cases of cognitive computing in healthcare. A detailed discussion section highlighting the present issues, future research directions and recent applications of cognitive computing in healthcare. Accuracy analysis of different cognitive systems conclude that the Medical Sieve achieves 0.95 and Watson For Oncology (WFO) achieves 0.93 and hence proves to be the prominent computing systems for healthcare. Cognitive computing, an evolving technology in healthcare augments the clinical thought process and enable the doctors to make the right diagnosis and preserve the patient’s health in good condition. These systems provides timely care, optimal and cost-effective treatment. This article provides an extensive survey of the importance of cognitive computing in the health sector by highlighting the platforms, techniques, tools, algorithms, applications, and use cases. This survey also explores about the works in the literature on present issues and proposes the future research directions of applying cognitive systems in healthcare.},
  archive      = {J_ARTMED},
  author       = {Srivani M. and Abirami Murugappan and Mala T.},
  doi          = {10.1016/j.artmed.2023.102513},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102513},
  shortjournal = {Artif. Intell. Med.},
  title        = {Cognitive computing technological trends and future research directions in healthcare — a systematic literature review},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Midwifery learning and forecasting: Predicting content
demand with user-generated logs. <em>ARTMED</em>, <em>138</em>, 102511.
(<a href="https://doi.org/10.1016/j.artmed.2023.102511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, 800 women and 6700 newborns die from complications related to pregnancy or childbirth . A well-trained midwife can prevent most of these maternal and newborn deaths . Data science models together with logs generated by users of online learning applications for midwives can help improve their learning competencies. In this work, we evaluate various forecasting methods to determine the future interest of users for the different types of content available in the Safe Delivery App, a digital training tool for skilled birth attendants, broken down by profession and region. This first attempt at health content demand forecasting for midwifery learning shows that DeepAR can accurately anticipate content demand in operational settings, and could therefore be used to offer users personalized content and to provide an adaptive learning journey.},
  archive      = {J_ARTMED},
  author       = {Anna Guitart and Ana Fernández del Río and África Periáñez and Lauren Bellhouse},
  doi          = {10.1016/j.artmed.2023.102511},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102511},
  shortjournal = {Artif. Intell. Med.},
  title        = {Midwifery learning and forecasting: Predicting content demand with user-generated logs},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting mild cognitive impairment and dementia in older
adults using naturalistic driving data and interaction-based
classification from influence score. <em>ARTMED</em>, <em>138</em>,
102510. (<a href="https://doi.org/10.1016/j.artmed.2023.102510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several recent studies indicate that atypical changes in driving behaviors appear to be early signs of mild cognitive impairment (MCI) and dementia. These studies, however, are limited by small sample sizes and short follow-up duration. This study aims to develop an interaction-based classification method building on a statistic named Influence Score (i.e., I-score) for prediction of MCI and dementia using naturalistic driving data collected from the Longitudinal Research on Aging Drivers (LongROAD) project. Naturalistic driving trajectories were collected through in-vehicle recording devices for up to 44 months from 2977 participants who were cognitively intact at the time of enrollment. These data were further processed and aggregated to generate 31 time-series driving variables. Because of high dimensional time-series features for driving variables, we used I-score for variable selection. I-score is a measure to evaluate variables’ ability to predict and is proven to be effective in differentiating between noisy and predictive variables in big data . It is introduced here to select influential variable modules or groups that account for compound interactions among explanatory variables. It is explainable regarding to what extent variables and their interactions contribute to the predictiveness of a classifier. In addition, I-score boosts the performance of classifiers over imbalanced datasets due to its association with the F1 score. Using predictive variables selected by I-score, interaction-based residual blocks are constructed over top I-score modules to generate predictors and ensemble learning aggregates these predictors to boost the prediction of the overall classifier. Experiments using naturalistic driving data show that our proposed classification method achieves the best accuracy (96%) for predicting MCI and dementia, followed by random forest (93%) and logistic regression (88%). In terms of F1 score and AUC, our proposed classifier achieves 98% and 87%, respectively, followed by random forest (with an F1 score of 96% and an AUC of 79%) and logistic regression (with an F1 score of 92% and an AUC of 77%). The results indicate that incorporating I-score into machine learning algorithms could considerably improve the model performance for predicting MCI and dementia in older drivers. We also performed the feature importance analysis and found that the right to left turn ratio and the number of hard braking events are the most important driving variables to predict MCI and dementia.},
  archive      = {J_ARTMED},
  author       = {Xuan Di and Yiqiao Yin and Yongjie Fu and Zhaobin Mo and Shaw-Hwa Lo and Carolyn DiGuiseppi and David W. Eby and Linda Hill and Thelma J. Mielenz and David Strogatz and Minjae Kim and Guohua Li},
  doi          = {10.1016/j.artmed.2023.102510},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102510},
  shortjournal = {Artif. Intell. Med.},
  title        = {Detecting mild cognitive impairment and dementia in older adults using naturalistic driving data and interaction-based classification from influence score},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiments prediction and thematic analysis for diabetes
mobile apps using embedded deep neural networks and latent dirichlet
allocation. <em>ARTMED</em>, <em>138</em>, 102509. (<a
href="https://doi.org/10.1016/j.artmed.2023.102509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing reliance on mobile health for managing disease conditions has opened a new frontier in digital health , thus, the need for understanding what constitutes positive and negative sentiments of the various apps. This paper relies on Embedded Deep Neural Networks (E-DNN), Kmeans, and Latent Dirichlet Allocation (LDA) for predicting the sentiments of diabetes mobile apps users and identifying the themes and sub-themes of positive and negative sentimental users. A total of 38,640 comments from 39 diabetes mobile apps obtained from the google play store are analyzed and accuracy of 87.67 % ± 2.57 % was obtained from a 10-fold leave-one-out cross-validation. This accuracy is 2.95 % - 18.71 % better than other predominant algorithms used for sentiment analysis and 3.47 % - 20.17 % better than the results obtained by previous researchers. The study also identified the challenges of diabetes mobile apps usage to include safety and security issues, outdated information for diabetes management, clumsy user interface, and difficulty controlling operations. The positives of the apps are ease of operation, lifestyle management, effectiveness in communication and control, and data management capabilities.},
  archive      = {J_ARTMED},
  author       = {Chinedu I. Ossai and Nilmini Wickramasinghe},
  doi          = {10.1016/j.artmed.2023.102509},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102509},
  shortjournal = {Artif. Intell. Med.},
  title        = {Sentiments prediction and thematic analysis for diabetes mobile apps using embedded deep neural networks and latent dirichlet allocation},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dimensionality reduction and ensemble of LSTMs for
antimicrobial resistance prediction. <em>ARTMED</em>, <em>138</em>,
102508. (<a href="https://doi.org/10.1016/j.artmed.2023.102508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bacterial resistance to antibiotics has been rapidly increasing, resulting in low antibiotic effectiveness even treating common infections. The presence of resistant pathogens in environments such as a hospital Intensive Care Unit (ICU) exacerbates the critical admission-acquired infections. This work focuses on the prediction of antibiotic resistance in Pseudomonas aeruginosa nosocomial infections at the ICU, using Long Short-Term Memory (LSTM) artificial neural networks as the predictive method . The analyzed data were extracted from the Electronic Health Records (EHR) of patients admitted to the University Hospital of Fuenlabrada from 2004 to 2019 and were modeled as Multivariate Time Series . A data-driven dimensionality reduction method is built by adapting three feature importance techniques from the literature to the considered data and proposing an algorithm for selecting the most appropriate number of features. This is done using LSTM sequential capabilities so that the temporal aspect of features is taken into account. Furthermore, an ensemble of LSTMs is used to reduce the variance in performance. Our results indicate that the patient’s admission information, the antibiotics administered during the ICU stay, and the previous antimicrobial resistance are the most important risk factors . Compared to other conventional dimensionality reduction schemes, our approach is able to improve performance while reducing the number of features for most of the experiments. In essence, the proposed framework achieve, in a computationally cost-efficient manner, promising results for supporting decisions in this clinical task, characterized by high dimensionality , data scarcity, and concept drift .},
  archive      = {J_ARTMED},
  author       = {Àlvar Hernàndez-Carnerero and Miquel Sànchez-Marrè and Inmaculada Mora-Jiménez and Cristina Soguero-Ruiz and Sergio Martínez-Agüero and Joaquín Álvarez-Rodríguez},
  doi          = {10.1016/j.artmed.2023.102508},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102508},
  shortjournal = {Artif. Intell. Med.},
  title        = {Dimensionality reduction and ensemble of LSTMs for antimicrobial resistance prediction},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clinical-GAN: Trajectory forecasting of clinical events
using transformer and generative adversarial networks. <em>ARTMED</em>,
<em>138</em>, 102507. (<a
href="https://doi.org/10.1016/j.artmed.2023.102507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the trajectory of a disease at an early stage can aid physicians in offering effective treatment, prompt care to patients, and also avoid misdiagnosis. However, forecasting patient trajectories is challenging due to long-range dependencies, irregular intervals between consecutive admissions, and non-stationarity data. To address these challenges, we propose a novel method called Clinical-GAN, a Transformer-based Generative Adversarial Networks (GAN) to forecast the patients’ medical codes for subsequent visits. First, we represent the patients’ medical codes as a time-ordered sequence of tokens akin to language models . Then, a Transformer mechanism is used as a Generator to learn from existing patients’ medical history and is trained adversarially against a Transformer-based Discriminator . We address the above mentioned challenges based on our data modeling and Transformer-based GAN architecture. Additionally, we enable the local interpretation of the model’s prediction using a multi-head attention mechanism. We evaluated our method using a publicly available dataset, Medical Information Mart for Intensive Care IV v1.0 (MIMIC-IV), with more than 500,000 visits completed by around 196,000 adult patients over an 11-year period from 2008–2019. Clinical-GAN significantly outperforms baseline methods and existing works, as demonstrated through various experiments. Source code is at https://github.com/vigi30/Clinical-GAN .},
  archive      = {J_ARTMED},
  author       = {Vignesh Shankar and Elnaz Yousefi and Alireza Manashty and Dayne Blair and Deepika Teegapuram},
  doi          = {10.1016/j.artmed.2023.102507},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102507},
  shortjournal = {Artif. Intell. Med.},
  title        = {Clinical-GAN: Trajectory forecasting of clinical events using transformer and generative adversarial networks},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rams, hounds and white boxes: Investigating human–AI
collaboration protocols in medical diagnosis. <em>ARTMED</em>,
<em>138</em>, 102506. (<a
href="https://doi.org/10.1016/j.artmed.2023.102506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study human–AI collaboration protocols, a design-oriented construct aimed at establishing and evaluating how humans and AI can collaborate in cognitive tasks. We applied this construct in two user studies involving 12 specialist radiologists (the knee MRI study) and 44 ECG readers of varying expertise (the ECG study), who evaluated 240 and 20 cases, respectively, in different collaboration configurations. We confirm the utility of AI support but find that XAI can be associated with a “white-box paradox”, producing a null or detrimental effect. We also find that the order of presentation matters: AI-first protocols are associated with higher diagnostic accuracy than human-first protocols, and with higher accuracy than both humans and AI alone. Our findings identify the best conditions for AI to augment human diagnostic skills, rather than trigger dysfunctional responses and cognitive biases that can undermine decision effectiveness.},
  archive      = {J_ARTMED},
  author       = {Federico Cabitza and Andrea Campagner and Luca Ronzio and Matteo Cameli and Giulia Elena Mandoli and Maria Concetta Pastore and Luca Maria Sconfienza and Duarte Folgado and Marília Barandas and Hugo Gamboa},
  doi          = {10.1016/j.artmed.2023.102506},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102506},
  shortjournal = {Artif. Intell. Med.},
  title        = {Rams, hounds and white boxes: Investigating human–AI collaboration protocols in medical diagnosis},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty-guided mutual consistency learning for
semi-supervised medical image segmentation. <em>ARTMED</em>,
<em>138</em>, 102476. (<a
href="https://doi.org/10.1016/j.artmed.2022.102476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is a fundamental and critical step in many clinical approaches . Semi-supervised learning has been widely applied to medical image segmentation tasks since it alleviates the heavy burden of acquiring expert-examined annotations and takes the advantage of unlabeled data which is much easier to acquire. Although consistency learning has been proven to be an effective approach by enforcing an invariance of predictions under different distributions, existing approaches cannot make full use of region-level shape constraint and boundary-level distance information from unlabeled data. In this paper, we propose a novel uncertainty-guided mutual consistency learning framework to effectively exploit unlabeled data by integrating intra-task consistency learning from up-to-date predictions for self-ensembling and cross-task consistency learning from task-level regularization to exploit geometric shape information. The framework is guided by the estimated segmentation uncertainty of models to select out relatively certain predictions for consistency learning, so as to effectively exploit more reliable information from unlabeled data. Experiments on two publicly available benchmark datasets showed that: (1) Our proposed method can achieve significant performance improvement by leveraging unlabeled data, with up to 4.13% and 9.82% in Dice coefficient compared to supervised baseline on left atrium segmentation and brain tumor segmentation, respectively. (2) Compared with other semi-supervised segmentation methods , our proposed method achieve better segmentation performance under the same backbone network and task settings on both datasets, demonstrating the effectiveness and robustness of our method and potential transferability for other medical image segmentation tasks.},
  archive      = {J_ARTMED},
  author       = {Yichi Zhang and Rushi Jiao and Qingcheng Liao and Dongyang Li and Jicong Zhang},
  doi          = {10.1016/j.artmed.2022.102476},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102476},
  shortjournal = {Artif. Intell. Med.},
  title        = {Uncertainty-guided mutual consistency learning for semi-supervised medical image segmentation},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DECAF: An interpretable deep cascading framework for ICU
mortality prediction. <em>ARTMED</em>, <em>138</em>, 102437. (<a
href="https://doi.org/10.1016/j.artmed.2022.102437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical risk detection is an important topic and a challenging task to improve the performance of clinical practices in Intensive Care Units (ICU). Although many bio-statistical learning and deep learning approaches have provided patient-specific mortality predictions, these existing methods lack interpretability that is crucial to gain adequate insight on why such predictions would work. In this paper, we introduce cascading theory to model the physiological domino effect and provide a novel approach to dynamically simulate the deterioration of patients&#39; conditions. We propose a general DEep CAscading Framework (DECAF) to predict the potential risks of all physiological functions at each clinical stage. Compared with other feature-based and/or score-based models, our approach has a range of desirable properties , such as being interpretable, applicable with multi prediction tasks, and learnable from medical common sense and/or clinical experience knowledge. Experiments on a medical dataset (MIMIC-III) of 21,828 ICU patients show that DECAF reaches up to 89.30 % on AUROC, which surpasses the best competing methods for mortality prediction.},
  archive      = {J_ARTMED},
  author       = {Jingchi Jiang and Xuehui Yu and Boran Wang and Linjiang Ma and Yi Guan},
  doi          = {10.1016/j.artmed.2022.102437},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102437},
  shortjournal = {Artif. Intell. Med.},
  title        = {DECAF: An interpretable deep cascading framework for ICU mortality prediction},
  volume       = {138},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WeakMeSH: Leveraging provenance information for weakly
supervised classification of biomedical articles with emerging MeSH
descriptors. <em>ARTMED</em>, <em>137</em>, 102505. (<a
href="https://doi.org/10.1016/j.artmed.2023.102505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical Subject Headings (MeSH) is a hierarchically structured thesaurus created by the National Library of Medicine of USA. Each year the vocabulary gets revised, bringing forth different types of changes. Those of particular interest are the ones that introduce new descriptors in the vocabulary either brand new or those who come up as a product of a complex change. These new descriptors often lack ground truth articles and rendering learning models that require supervision not applicable. Furthermore, this problem is characterized by its multi label nature and the fine-grained character of the descriptors that play the role of classes, requiring expert supervision and a lot of human resources. In this work, we alleviate these issues through retrieving insights from provenance information about those descriptors present in MeSH to create a weakly labeled train set for them. At the same time, we make use of a similarity mechanism to further filter the weak labels obtained through the descriptor information mentioned earlier. Our method, called WeakMeSH, was applied on a large-scale subset of the BioASQ 2018 data set consisting of 900 thousand biomedical articles. The performance of our method was evaluated on BioASQ 2020 against several other approaches that had given competitive results in similar problems in the past, or apply alternative transformations against the proposed one, as well as some variants that showcase the importance of each different component of our proposed approach. Finally, an analysis was performed on the different MeSH descriptors each year to assess the applicability of our method on the thesaurus.},
  archive      = {J_ARTMED},
  author       = {Nikolaos Mylonas and Stamatis Karlos and Grigorios Tsoumakas},
  doi          = {10.1016/j.artmed.2023.102505},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102505},
  shortjournal = {Artif. Intell. Med.},
  title        = {WeakMeSH: Leveraging provenance information for weakly supervised classification of biomedical articles with emerging MeSH descriptors},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Informing clinical assessment by contextualizing post-hoc
explanations of risk prediction models in type-2 diabetes.
<em>ARTMED</em>, <em>137</em>, 102498. (<a
href="https://doi.org/10.1016/j.artmed.2023.102498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical experts may use Artificial Intelligence (AI) systems with greater trust if these are supported by ‘contextual explanations’ that let the practitioner connect system inferences to their context of use. However, their importance in improving model usage and understanding has not been extensively studied. Hence, we consider a comorbidity risk prediction scenario and focus on contexts regarding the patients’ clinical state, AI predictions about their risk of complications, and algorithmic explanations supporting the predictions . We explore how relevant information for such dimensions can be extracted from Medical guidelines to answer typical questions from clinical practitioners. We identify this as a question answering (QA) task and employ several state-of-the-art Large Language Models (LLM) to present contexts around risk prediction model inferences and evaluate their acceptability. Finally, we study the benefits of contextual explanations by building an end-to-end AI pipeline including data cohorting, AI risk modeling, post-hoc model explanations, and prototyped a visual dashboard to present the combined insights from different context dimensions and data sources, while predicting and identifying the drivers of risk of Chronic Kidney Disease ( CKD ) - a common type-2 diabetes ( T2DM ) comorbidity. All of these steps were performed in deep engagement with medical experts, including a final evaluation of the dashboard results by an expert medical panel. We show that LLMs, in particular BERT and SciBERT, can be readily deployed to extract some relevant explanations to support clinical usage. To understand the value-add of the contextual explanations, the expert panel evaluated these regarding actionable insights in the relevant clinical setting. Overall, our paper is one of the first end-to-end analyses identifying the feasibility and benefits of contextual explanations in a real-world clinical use case. Our findings can help improve clinicians’ usage of AI models .},
  archive      = {J_ARTMED},
  author       = {Shruthi Chari and Prasant Acharya and Daniel M. Gruen and Olivia Zhang and Elif K. Eyigoz and Mohamed Ghalwash and Oshani Seneviratne and Fernando Suarez Saiz and Pablo Meyer and Prithwish Chakraborty and Deborah L. McGuinness},
  doi          = {10.1016/j.artmed.2023.102498},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102498},
  shortjournal = {Artif. Intell. Med.},
  title        = {Informing clinical assessment by contextualizing post-hoc explanations of risk prediction models in type-2 diabetes},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of deep learning algorithms in automatic
sonographic localization and segmentation of the median nerve: A
systematic review and meta-analysis. <em>ARTMED</em>, <em>137</em>,
102496. (<a href="https://doi.org/10.1016/j.artmed.2023.102496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution ultrasound is an emerging tool for diagnosing carpal tunnel syndrome caused by the compression of the median nerve at the wrist. This systematic review and meta-analysis aimed to explore and summarize the performance of deep learning algorithms in the automatic sonographic assessment of the median nerve at the carpal tunnel level. PubMed , Medline, Embase , and Web of Science were searched from the earliest records to May 2022 for studies investigating the utility of deep neural networks in the evaluation of the median nerve in carpal tunnel syndrome . The quality of the included studies was evaluated using the Quality Assessment Tool for Diagnostic Accuracy Studies. The outcome variables included precision, recall, accuracy, F-score, and Dice coefficient. In total, seven articles were included, comprising 373 participants. The deep learning and related algorithms comprised U-Net, phase-based probabilistic active contour, MaskTrack, ConvLSTM, DeepNerve, DeepSL, ResNet, Feature Pyramid Network, DeepLab, Mask R-CNN, region proposal network, and ROI Align. The pooled values of precision and recall were 0.917 (95 % confidence interval [CI], 0.873–0.961) and 0.940 (95 % CI, 0.892–0.988), respectively. The pooled accuracy and Dice coefficient were 0.924 (95 % CI, 0.840–1.008) and 0.898 (95 % CI, 0.872–0.923), respectively, whereas the summarized F-score was 0.904 (95 % CI, 0.871–0.937). The deep learning algorithm enables automated localization and segmentation of the median nerve at the carpal tunnel level in ultrasound imaging with acceptable accuracy and precision. Future research is expected to validate the performance of deep learning algorithms in detecting and segmenting the median nerve along its entire length as well as across datasets obtained from various ultrasound manufacturers.},
  archive      = {J_ARTMED},
  author       = {Jia-Chi Wang and Yi-Chung Shu and Che-Yu Lin and Wei-Ting Wu and Lan-Rong Chen and Yu-Cheng Lo and Hsiao-Chi Chiu and Levent Özçakar and Ke-Vin Chang},
  doi          = {10.1016/j.artmed.2023.102496},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102496},
  shortjournal = {Artif. Intell. Med.},
  title        = {Application of deep learning algorithms in automatic sonographic localization and segmentation of the median nerve: A systematic review and meta-analysis},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A model-driven transformation approach for the modelling of
processes in clinical practice guidelines. <em>ARTMED</em>,
<em>137</em>, 102495. (<a
href="https://doi.org/10.1016/j.artmed.2023.102495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical Practice Guidelines (CPGs) include recommendations aimed at optimising patient care, informed by a review of the available clinical evidence. To achieve their potential benefits , CPG should be readily available at the point of care. This can be done by translating CPG recommendations into one of the languages for Computer-Interpretable Guidelines (CIGs). This is a difficult task for which the collaboration of clinical and technical staff is crucial. However, in general CIG languages are not accessible to non-technical staff. We propose to support the modelling of CPG processes (and hence the authoring of CIGs) based on a transformation, from a preliminary specification in a more accessible language into an implementation in a CIG language. In this paper, we approach this transformation following the Model-Driven Development (MDD) paradigm, in which models and transformations are key elements for software development. To demonstrate the approach, we implemented and tested an algorithm for the transformation from the BPMN language for business processes to the PROforma CIG language. This implementation uses transformations defined in the ATLAS Transformation Language. Additionally, we conducted a small experiment to assess the hypothesis that a language such as BPMN can facilitate the modelling of CPG processes by clinical and technical staff.},
  archive      = {J_ARTMED},
  author       = {Begoña Martínez-Salvador and Mar Marcos and Patricia Palau and Eloy Domínguez Mafé},
  doi          = {10.1016/j.artmed.2023.102495},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102495},
  shortjournal = {Artif. Intell. Med.},
  title        = {A model-driven transformation approach for the modelling of processes in clinical practice guidelines},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). XAIRE: An ensemble-based methodology for determining the
relative importance of variables in regression tasks. Application to a
hospital emergency department. <em>ARTMED</em>, <em>137</em>, 102494.
(<a href="https://doi.org/10.1016/j.artmed.2023.102494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays it is increasingly important in many applications to understand how different factors influence a variable of interest in a predictive modeling process. This task becomes particularly important in the context of Explainable Artificial Intelligence. Knowing the relative impact of each variable on the output allows us to acquire more information about the problem and about the output provided by a model. This paper proposes a new methodology, XAIRE, that determines the relative importance of input variables in a prediction environment, considering multiple prediction models in order to increase generality and avoid bias inherent in a particular learning algorithm. Concretely, we present an ensemble-based methodology that promotes the aggregation of results from several prediction methods to obtain a relative importance ranking. Also, statistical tests are considered in the methodology in order to reveal significant differences between the relative importance of the predictor variables . As a case study , XAIRE is applied to the arrival of patients in a Hospital Emergency Department, which has resulted in one of the largest sets of different predictor variables in the literature. Results show the extracted knowledge related to the relative importance of the predictors involved in the case study.},
  archive      = {J_ARTMED},
  author       = {A.J. Rivera and J. Cobo Muñoz and M.D. Pérez-Goody and B. Sáenz de San Pedro and F. Charte and D. Elizondo and C. Rodríguez and M.L. Abolafia and A. Perea and M.J. del Jesus},
  doi          = {10.1016/j.artmed.2023.102494},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102494},
  shortjournal = {Artif. Intell. Med.},
  title        = {XAIRE: An ensemble-based methodology for determining the relative importance of variables in regression tasks. application to a hospital emergency department},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structural causal model with expert augmented knowledge to
estimate the effect of oxygen therapy on mortality in the ICU.
<em>ARTMED</em>, <em>137</em>, 102493. (<a
href="https://doi.org/10.1016/j.artmed.2023.102493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in causal inference techniques, more specifically, in the theory of structural causal models, provide the framework for identifying causal effects from observational data in cases where the causal graph is identifiable, i.e., the data generation mechanism can be recovered from the joint distribution. However, no such studies have been performed to demonstrate this concept with a clinical example. We present a complete framework to estimate the causal effects from observational data by augmenting expert knowledge in the model development phase and with a practical clinical application. Our clinical application entails a timely and essential research question, the effect of oxygen therapy intervention in the intensive care unit (ICU). The result of this project is helpful in a variety of disease conditions, including severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) patients in the ICU. We used data from the MIMIC-III database, a widely used health care database in the machine learning community with 58,976 admissions from an ICU in Boston, MA, to estimate the oxygen therapy effect on morality. We also identified the model’s covariate-specific effect on oxygen therapy for more personalized intervention.},
  archive      = {J_ARTMED},
  author       = {Md Osman Gani and Shravan Kethireddy and Riddhiman Adib and Uzma Hasan and Paul Griffin and Mohammad Adibuzzaman},
  doi          = {10.1016/j.artmed.2023.102493},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102493},
  shortjournal = {Artif. Intell. Med.},
  title        = {Structural causal model with expert augmented knowledge to estimate the effect of oxygen therapy on mortality in the ICU},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic knowledge graph population with model-complete
text comprehension for pre-clinical outcomes in the field of spinal cord
injury. <em>ARTMED</em>, <em>137</em>, 102491. (<a
href="https://doi.org/10.1016/j.artmed.2023.102491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paradigm of evidence-based medicine requires that medical decisions are made on the basis of the best available knowledge published in the literature. Existing evidence is often summarized in the form of systematic reviews and/or meta-reviews and is rarely available in a structured form. Manual compilation and aggregation is costly, and conducting a systematic review represents a high effort. The need to aggregate evidence arises not only in the context of clinical trials , but is also important in the context of pre-clinical animal studies. In this context, evidence extraction is important to support translation of the most promising pre-clinical therapies into clinical trials or to optimize clinical trial design . Aiming at developing methods that facilitate the task of aggregating evidence published in pre-clinical studies, in this paper a new system is presented that automatically extracts structured knowledge from such publications and stores it in a so-called domain knowledge graph . The approach follows the paradigm of model-complete text comprehension by relying on guidance from a domain ontology creating a deep relational data-structure that reflects the main concepts, protocol, and key findings of studies. Focusing on the domain of spinal cord injuries , a single outcome of a pre-clinical study is described by up to 103 outcome parameters. Since the problem of extracting all these variables together is intractable, we propose a hierarchical architecture that incrementally predicts semantic sub-structures according to a given data model in a bottom-up fashion. At the heart of our approach is a statistical inference method that relies on conditional random fields to infer the most likely instance of the domain model given the text of a scientific publication as input. This approach allows modeling dependencies between the different variables describing a study in a semi-joint fashion. We present a comprehensive evaluation of our system to understand the extent to which our system can capture a study in the depth required to enable the generation of new knowledge. We conclude the article with a brief description of some applications of the populated knowledge graph and show the potential implications of our work for supporting evidence-based medicine.},
  archive      = {J_ARTMED},
  author       = {Hendrik ter Horst and Nicole Brazda and Jessica Schira-Heinen and Julia Krebbers and Hans-Werner Müller and Philipp Cimiano},
  doi          = {10.1016/j.artmed.2023.102491},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102491},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic knowledge graph population with model-complete text comprehension for pre-clinical outcomes in the field of spinal cord injury},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benchmarking of machine learning classifiers on plasma
proteomic for COVID-19 severity prediction through interpretable
artificial intelligence. <em>ARTMED</em>, <em>137</em>, 102490. (<a
href="https://doi.org/10.1016/j.artmed.2023.102490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The SARS-CoV-2 pandemic highlighted the need for software tools that could facilitate patient triage regarding potential disease severity or even death. In this article, an ensemble of Machine Learning (ML) algorithms is evaluated in terms of predicting the severity of their condition using plasma proteomics and clinical data as input. An overview of AI-based technical developments to support COVID-19 patient management is presented outlining the landscape of relevant technical developments. Based on this review, the use of an ensemble of ML algorithms that analyze clinical and biological data (i.e., plasma proteomics) of COVID-19 patients is designed and deployed to evaluate the potential use of AI for early COVID-19 patient triage. The proposed pipeline is evaluated using three publicly available datasets for training and testing. Three ML “tasks” are defined, and several algorithms are tested through a hyperparameter tuning method to identify the highest-performance models. As overfitting is one of the typical pitfalls for such approaches (mainly due to the size of the training/validation datasets), a variety of evaluation metrics are used to mitigate this risk. In the evaluation procedure, recall scores ranged from 0.6 to 0.74 and F1-score from 0.62 to 0.75. The best performance is observed via Multi-Layer Perceptron (MLP) and Support Vector Machines (SVM) algorithms. Additionally, input data (proteomics and clinical data) were ranked based on corresponding Shapley additive explanation (SHAP) values and evaluated for their prognosticated capacity and immuno-biological credence. This “interpretable” approach revealed that our ML models could discern critical COVID-19 cases predominantly based on patient&#39;s age and plasma proteins on B cell dysfunction, hyper-activation of inflammatory pathways like Toll-like receptors, and hypo-activation of developmental and immune pathways like SCF/c-Kit signaling. Finally, the herein computational workflow is corroborated in an independent dataset and MLP superiority along with the implication of the abovementioned predictive biological pathways are corroborated. Regarding limitations of the presented ML pipeline, the datasets used in this study contain less than 1000 observations and a significant number of input features hence constituting a high-dimensional low-sample (HDLS) dataset which could be sensitive to overfitting. An advantage of the proposed pipeline is that it combines biological data (plasma proteomics) with clinical-phenotypic data. Thus, in principle, the presented approach could enable patient triage in a timely fashion if used on already trained models. However, larger datasets and further systematic validation are needed to confirm the potential clinical value of this approach. The code is available on Github: https://github.com/inab-certh/Predicting-COVID-19-severity-through-interpretable-AI-analysis-of-plasma-proteomics .},
  archive      = {J_ARTMED},
  author       = {Stella Dimitsaki and George I. Gavriilidis and Vlasios K. Dimitriadis and Pantelis Natsiavas},
  doi          = {10.1016/j.artmed.2023.102490},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102490},
  shortjournal = {Artif. Intell. Med.},
  title        = {Benchmarking of machine learning classifiers on plasma proteomic for COVID-19 severity prediction through interpretable artificial intelligence},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic documentation of professional health interactions:
A systematic review. <em>ARTMED</em>, <em>137</em>, 102487. (<a
href="https://doi.org/10.1016/j.artmed.2023.102487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic systems are increasingly present in the healthcare system and are often related to improved medical care. However, the widespread use of these technologies ended up building a relationship of dependence that can disrupt the doctor–patient relationship. In this context, digital scribes are automated clinical documentation systems that capture the physician–patient conversation and then generate the documentation for the appointment, enabling the physician to engage with the patient entirely. We have performed a systematic literature review on intelligent solutions for automatic speech recognition (ASR) with automatic documentation during a medical interview . The scope included only original research on systems that could detect speech and transcribe it in a natural and structured fashion simultaneously with the doctor–patient interaction, excluding speech-to-text-only technologies. The search resulted in a total of 1995 titles, with eight articles remaining after filtering for the inclusion and exclusion criteria. The intelligent models mainly consisted of an ASR system with natural language processing capability, a medical lexicon, and structured text output. None of the articles had a commercially available product at the time of the publication and reported limited real-life experience. So far, none of the applications has been prospectively validated and tested in large-scale clinical studies. Nonetheless, these first reports suggest that automatic speech recognition may be a valuable tool in the future to facilitate medical registration in a faster and more reliable manner. Improving transparency, accuracy, and empathy could drastically change how patients and doctors experience a medical visit. Unfortunately, clinical data on the usability and benefits of such applications is almost non-existent. We believe that future work in this area is necessary and needed.},
  archive      = {J_ARTMED},
  author       = {Frederico Soares Falcetta and Fernando Kude de Almeida and Janaína Conceição Sutil Lemos and José Roberto Goldim and Cristiano André da Costa},
  doi          = {10.1016/j.artmed.2023.102487},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102487},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic documentation of professional health interactions: A systematic review},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The voice of COVID-19: Breath and cough recording
classification with temporal decision trees and random forests.
<em>ARTMED</em>, <em>137</em>, 102486. (<a
href="https://doi.org/10.1016/j.artmed.2022.102486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic learning is the logic-based approach to machine learning, and its mission is to provide algorithms and methodologies to extract logical information from data and express it in an interpretable way. Interval temporal logic has been recently proposed as a suitable tool for symbolic learning, specifically via the design of an interval temporal logic decision tree extraction algorithm. In order to improve their performances, interval temporal decision trees can be embedded into interval temporal random forests, mimicking the corresponding schema at the propositional level. In this article we consider a dataset of cough and breath sample recordings of volunteer subjects, labeled with their COVID-19 status, originally collected by the University of Cambridge. By interpreting such recordings as multivariate time series , we study the problem of their automated classification using interval temporal decision trees and forests. While this problem has been approached with the same dataset as well as with other datasets, in all cases, non-symbolic learning methods (usually, deep learning-based) have been applied to solve it; in this article we apply a symbolic approach, and show that it does not only outperform the state-of-the-art obtained with the same dataset, but its results are also superior to those of most non-symbolic techniques applied on other datasets. As an added bonus, thanks to the symbolic nature of our approach, we are also able to extract explicit knowledge to help physicians characterize typical COVID-positive cough and breath.},
  archive      = {J_ARTMED},
  author       = {F. Manzella and G. Pagliarini and G. Sciavicco and I.E. Stan},
  doi          = {10.1016/j.artmed.2022.102486},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102486},
  shortjournal = {Artif. Intell. Med.},
  title        = {The voice of COVID-19: Breath and cough recording classification with temporal decision trees and random forests},
  volume       = {137},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Least squares support vector regression for complex censored
data. <em>ARTMED</em>, <em>136</em>, 102497. (<a
href="https://doi.org/10.1016/j.artmed.2023.102497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Least squares support vector regression (LS-SVR) is a robust machine learning algorithm for small sample data. Its solution is derived from solving a set of linear equations , making the calculation process straightforward. In order to overcome the difficulties of the regression estimations when the responses are subject to interval censoring or left truncation and right censoring, two LS-SVR methods are proposed. For interval-censored data, one can easily estimate the regression functions by combining the imputation techniques and LS-SVR for right-censored data. For left-truncated and right-censored data, a weight is used to reduce the effects of truncation and censoring on the LS-SVR procedure. Simulation results show that the proposed methods can reduce regression error and yield high accuracy and stability.},
  archive      = {J_ARTMED},
  author       = {Xinrui Liu and Xiaogang Dong and Le Zhang and Jia Chen and Chunjie Wang},
  doi          = {10.1016/j.artmed.2023.102497},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102497},
  shortjournal = {Artif. Intell. Med.},
  title        = {Least squares support vector regression for complex censored data},
  volume       = {136},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel temporal generative adversarial network for
electrocardiography anomaly detection. <em>ARTMED</em>, <em>136</em>,
102489. (<a href="https://doi.org/10.1016/j.artmed.2023.102489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac abnormality detection from Electrocardiogram (ECG) signals is a common task for cardiologists. To facilitate efficient and objective detection, automated ECG classification by using deep learning based methods have been developed in recent years. Despite their impressive performance, these methods perform poorly when presented with cardiac abnormalities that are not well represented, or absent, in the training data . To this end, we propose a novel one-class classification based ECG anomaly detection generative adversarial network (GAN). Specifically, we embedded a Bi-directional Long-Short Term Memory (Bi-LSTM) layer into a GAN architecture and used a mini-batch discrimination training strategy in the discriminator to synthesis ECG signals. Our method generates samples to match the data distribution from normal signals of healthy group so that a generalised anomaly detector can be built reliably. The experimental results demonstrate our method outperforms several state-of-the-art semi-supervised learning based ECG anomaly detection algorithms and robustly detects the unknown anomaly class in the MIT-BIH arrhythmia database. Experiments show that our method achieves the accuracy of 95.5% and AUC of 95.9% which outperforms the most competitive baseline by 0.7% and 1.7% respectively. Our method may prove to be a helpful diagnostic method for helping cardiologists identify arrhythmias.},
  archive      = {J_ARTMED},
  author       = {Jing Qin and Fujie Gao and Zumin Wang and David C. Wong and Zhibin Zhao and Samuel D. Relton and Hui Fang},
  doi          = {10.1016/j.artmed.2023.102489},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102489},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel temporal generative adversarial network for electrocardiography anomaly detection},
  volume       = {136},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Augmenting DSM-5 diagnostic criteria with
self-attention-based BiLSTM models for psychiatric diagnosis.
<em>ARTMED</em>, <em>136</em>, 102488. (<a
href="https://doi.org/10.1016/j.artmed.2023.102488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most previous studies make psychiatric diagnoses based on diagnostic terms. In this study we sought to augment Diagnostic and Statistical Manual of Mental Disorders , 5th Edition (DSM-5) diagnostic criteria with deep neural network models to make psychiatric diagnoses based on psychiatric notes. We augmented DSM-5 diagnostic criteria with self-attention-based bidirectional long short-term memory (BiLSTM) models to identify schizophrenia , bipolar, and unipolar depressive disorders. Given that the diagnostic criteria for psychiatric diagnosis include a certain symptom profile and functional impairment, we first extracted psychiatric symptoms and functional features with two approaches, including a lexicon-based approach and a dependency parsing approach. Then, we incorporated free-text discharge notes and extracted features for psychiatric diagnoses with the proposed models. The micro-averaged F1 scores of the two automatic annotation approaches were greater than 0.8. BiLSTM models with self-attention outperformed the rule-based models with DSM-5 criteria in the prediction of schizophrenia and bipolar disorder , while the latter outperformed the former in predicting unipolar depressive disorder . Approaches for augmenting DSM-5 criteria with a self-attention-based BiLSTM outperformed both pure rule-based and pure deep neural network models . In terms of classification of psychiatric diagnoses, we observed that the performance for schizophrenia and bipolar disorder was acceptable. This DSM-5-augmented deep neural network models showed good performance in identifying psychiatric diagnoses from psychiatric notes. We conclude that it is possible to establish a model that consults clinical notes to make psychiatric diagnoses comparably to physicians. Further research will be extended to outpatient notes and other psychiatric disorders.},
  archive      = {J_ARTMED},
  author       = {Chi-Shin Wu and Chien-Hung Chen and Chu-Hsien Su and Yi-Ling Chien and Hong-Jie Dai and Hsin-Hsi Chen},
  doi          = {10.1016/j.artmed.2023.102488},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102488},
  shortjournal = {Artif. Intell. Med.},
  title        = {Augmenting DSM-5 diagnostic criteria with self-attention-based BiLSTM models for psychiatric diagnosis},
  volume       = {136},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new approach to predicting mortality in dialysis patients
using sociodemographic features based on artificial intelligence.
<em>ARTMED</em>, <em>136</em>, 102478. (<a
href="https://doi.org/10.1016/j.artmed.2022.102478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main problems that affect patients in dialysis therapy who are on the waiting list to receive a kidney transplant is predicting their survival time if they do not receive a transplant. This paper proposes a new approach to survival prediction based on artificial intelligence techniques combined with statistical methods to study the association between sociodemographic factors and patient survival on the waiting list if they do not receive a kidney transplant. This new approach consists of a first stage that uses the clustering techniques that are best suited to the data structure (K-Means, Mini Batch K-Means, Agglomerative Clustering and K-Modes) used to identify the risk profile of dialysis patients. Later, a new method called False Clustering Discovery Reduction is performed to determine the minimum number of populations to be studied, and whose mortality risk is statistically differentiable. This approach was applied to the OPTN medical dataset ( n = 44,663). The procedure started from 11 initial clusters obtained with the Agglomerative technique, and was reduced to eight final risk populations , for which their Kaplan-Meier survival curves were provided. With this result, it is possible to make predictions regarding the survival time of a new patient who enters the waiting list if the sociodemographic profile of the patient is known. To do so, the predictive algorithm XGBoost is used, which allows the cluster to which it belongs to be predicted and the corresponding Kaplan-Meier curve to be associated with it. This prediction process is achieved with an overall Multi-class AUC of 99.08 %.},
  archive      = {J_ARTMED},
  author       = {Covadonga Díez-Sanmartín and Antonio Sarasa Cabezuelo and Amado Andrés Belmonte},
  doi          = {10.1016/j.artmed.2022.102478},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102478},
  shortjournal = {Artif. Intell. Med.},
  title        = {A new approach to predicting mortality in dialysis patients using sociodemographic features based on artificial intelligence},
  volume       = {136},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent non-invasive system for automated diagnosis
of anemia exploiting a novel dataset. <em>ARTMED</em>, <em>136</em>,
102477. (<a href="https://doi.org/10.1016/j.artmed.2022.102477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anemia is a condition in which the oxygen-carrying capacity of red blood cells is insufficient to meet the body&#39;s physiological needs. It affects billions of people worldwide. An early diagnosis of this disease could prevent the advancement of other disorders. Traditional methods used to detect anemia consist of venipuncture, which requires a patient to frequently undergo laboratory tests. Therefore, anemia diagnosis using noninvasive and cost-effective methods is an open challenge. The pallor of the fingertips, palms, nail beds, and eye conjunctiva can be observed to establish whether a patient suffers from anemia. This article addresses the above challenges by presenting a novel intelligent system, based on machine learning, that supports the automated diagnosis of anemia. This system is innovative from different points of view. Specifically, it has been trained on a dataset that contains eye conjunctiva photos of Indian and Italian patients. This dataset, which was created using a very strict experimental set, is now made available to the Scientific Community. Moreover, compared to previous systems in the literature, the proposed system uses a low-cost device, which makes it suitable for widespread use. The performance of the learning algorithms utilizing two different areas of the mucous membrane of the eye is discussed. In particular, the RUSBoost algorithm, when appropriately trained on palpebral conjunctiva images, shows good performance in classifying anemic and nonanemic patients. The results are very robust, even when considering different ethnicities.},
  archive      = {J_ARTMED},
  author       = {Giovanni Dimauro and Maria Elena Griseta and Mauro Giuseppe Camporeale and Felice Clemente and Attilio Guarini and Rosalia Maglietta},
  doi          = {10.1016/j.artmed.2022.102477},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102477},
  shortjournal = {Artif. Intell. Med.},
  title        = {An intelligent non-invasive system for automated diagnosis of anemia exploiting a novel dataset},
  volume       = {136},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepMNF: Deep multimodal neuroimaging framework for
diagnosing autism spectrum disorder. <em>ARTMED</em>, <em>136</em>,
102475. (<a href="https://doi.org/10.1016/j.artmed.2022.102475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing prevalence of neurological disorders , e.g., Autism Spectrum Disorder (ASD), demands robust computer-aided diagnosis (CAD) due to the diverse symptoms which require early intervention, particularly in young children . The absence of a benchmark neuroimaging diagnostics paves the way to study transitions in the brain&#39;s anatomical structure and neurological patterns associated with ASD. The existing CADs take advantage of the large-scale baseline dataset from the Autism Brain Imaging Data Exchange (ABIDE) repository to improve diagnostic performance, but the involvement of multisite data also amplifies the variabilities and heterogeneities that hinder satisfactory results. To resolve this problem, we propose a Deep Multimodal Neuroimaging Framework (DeepMNF) that employs Functional Magnetic Resonance Imaging (fMRI) and Structural Magnetic Resonance Imaging (sMRI) to integrate cross-modality spatiotemporal information by exploiting 2-dimensional time-series data along with 3-dimensional images. The purpose is to fuse complementary information that increases group differences and homogeneities. To the best of our knowledge, our DeepMNF achieves superior validation performance than the best reported result on the ABIDE-1 repository involving datasets from all available screening sites. In this work, we also demonstrate the performance of the studied modalities in a single model as well as their possible combinations to develop the multimodal framework.},
  archive      = {J_ARTMED},
  author       = {S. Qasim Abbas and Lianhua Chi and Yi-Ping Phoebe Chen},
  doi          = {10.1016/j.artmed.2022.102475},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102475},
  shortjournal = {Artif. Intell. Med.},
  title        = {DeepMNF: Deep multimodal neuroimaging framework for diagnosing autism spectrum disorder},
  volume       = {136},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hand motion capture method based on infrared thermography
for measuring fine motor skills in biomedicine. <em>ARTMED</em>,
<em>135</em>, 102474. (<a
href="https://doi.org/10.1016/j.artmed.2022.102474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many biomedical applications require fine motor skill assessments; however, real-time and contactless fine motor skill assessments are not typically implemented. In this study, we followed the 2D-to-3D pipeline principle and proposed a transformer-based spatial–temporal network to accurately regress 3D hand joint locations by inputting infrared thermal video for eliminating need of multiple cameras or RGB-D devices. We also developed a dataset composed of infrared thermal videos and ground truth annotations for training. The label represents a set of 3D joint locations from infrared optical trackers, which is considered the gold standard for clinical applications. To demonstrate their potential, the proposed method was used to measure the finger motion angle, and we investigated its accuracy by comparing the proposal with the Azure Kinect system and Leap Motion system. On the proposed dataset, the proposed method achieved a 3D hand pose mean error of less than 14 mm and outperforms the other deep learning methods. When the error thresholds were larger than approximately 35 mm, our method first to achieved excellent performance ( &gt; &amp;gt; 80%) in terms of the fraction of good frames. For the finger motion angle calculation task, the proposed and commercial systems had comparable inter-system reliability (ICC 2 , 1 2,1 ranging from 0.81 to 0.83) and excellent validity (Pearson’s r r -values ranging from 0.82 to 0.86). We believe that the proposed approaches can capture hand motion and measure finger motion angles and can be used in different biomedicine scenarios as an effective evaluation tool for fine motor skills.},
  archive      = {J_ARTMED},
  author       = {Yean Zhu and Chonglun Guo},
  doi          = {10.1016/j.artmed.2022.102474},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102474},
  shortjournal = {Artif. Intell. Med.},
  title        = {A hand motion capture method based on infrared thermography for measuring fine motor skills in biomedicine},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Process mining for healthcare decision analytics with
micro-costing estimations. <em>ARTMED</em>, <em>135</em>, 102473. (<a
href="https://doi.org/10.1016/j.artmed.2022.102473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing constrained healthcare resources is an important and inescapable role of healthcare decision makers . Allocative decisions are based on downstream consequences of changes to care processes: judging whether the costs involved are offset by the magnitude of the consequences, and therefore whether the change represents value for money. Process mining techniques can inform such decisions by quantitatively discovering, comparing and detailing care processes using recorded data, however the scope of techniques typically excludes anything ‘after-the-process’ i.e., their accumulated costs and resulting consequences. Cost considerations are increasingly incorporated into process mining techniques, but the majority of healthcare costs for service and overhead components are commonly apportioned and recorded at the patient (trace) level, hiding event level detail. Within decision-analysis, event-driven and individual-level simulation models are sometimes used to forecast the expected downstream consequences of process changes, but are expensive to manually operationalise. In this paper, we address both of these gaps within and between process mining and decision analytics, by better linking them together. In particular, we introduce a new type of process model containing trace data that can be used in individual-level or cohort-level decision-analytical model building. Furthermore, we enhance these models with process-based micro-costing estimations. The approach was evaluated with health economics and decision modelling experts, with discussion centred on how the outputs could be used, and how similar information would otherwise be compiled.},
  archive      = {J_ARTMED},
  author       = {Sander J.J. Leemans and Andrew Partington and Jonathan Karnon and Moe T. Wynn},
  doi          = {10.1016/j.artmed.2022.102473},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102473},
  shortjournal = {Artif. Intell. Med.},
  title        = {Process mining for healthcare decision analytics with micro-costing estimations},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supporting physicians in the coordination of distributed
execution of CIGs to treat comorbid patients. <em>ARTMED</em>,
<em>135</em>, 102472. (<a
href="https://doi.org/10.1016/j.artmed.2022.102472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical Practice Guidelines (CPGs) encode the “best” medical practices to treat patients affected by a specific disease and are widely used in the medical practice. Starting from the ‘90s&#39;, several Computer-Interpretable Guideline (CIG) systems have been devised to provide physicians with CPG-based decision support. CPGs (and CIGs) are devoted to provide evidence-based recommendations for one specific disease. In order to support the treatment of patients affected by multiple diseases (i.e., comorbid patients), challenging additional tasks have to be addressed, such as (i) the detection of the interactions between CIG actions, (ii) their management, and, finally, (iii) the “merge” or conciliation of the CIGs. Several CIG approaches have been recently extended in order to face (at least one of) such challenging problems, and one of them is GLARE. However, besides the solutions to tasks (i)-(iii) above, the “run-time” support to physicians treating a comorbid patient requires additional capabilities, to support the distribution of the management of interactions and of the execution of CIGs among different physicians. In this paper, we propose a general framework, based on GLARE and GLARE-SSCPM, to provide such additional capabilities.},
  archive      = {J_ARTMED},
  author       = {Alessio Bottrighi and Luca Piovesan and Paolo Terenziani},
  doi          = {10.1016/j.artmed.2022.102472},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102472},
  shortjournal = {Artif. Intell. Med.},
  title        = {Supporting physicians in the coordination of distributed execution of CIGs to treat comorbid patients},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Why did AI get this one wrong? — tree-based explanations of
machine learning model predictions. <em>ARTMED</em>, <em>135</em>,
102471. (<a href="https://doi.org/10.1016/j.artmed.2022.102471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasingly complex learning methods such as boosting, bagging and deep learning have made ML models more accurate, but harder to interpret and explain, culminating in black-box machine learning models. Model developers and users alike are often presented with a trade-off between performance and intelligibility, especially in high-stakes applications like medicine. In the present article we propose a novel methodological approach for generating explanations for the predictions of a generic machine learning model, given a specific instance for which the prediction has been made. The method, named AraucanaXAI, is based on surrogate, locally-fitted classification and regression trees that are used to provide post-hoc explanations of the prediction of a generic machine learning model. Advantages of the proposed XAI approach include superior fidelity to the original model, ability to deal with non-linear decision boundaries, and native support to both classification and regression problems . We provide a packaged, open-source implementation of the AraucanaXAI method and evaluate its behaviour in a number of different settings that are commonly encountered in medical applications of AI . These include potential disagreement between the model prediction and physician’s expert opinion and low reliability of the prediction due to data scarcity.},
  archive      = {J_ARTMED},
  author       = {Enea Parimbelli and Tommaso Mario Buonocore and Giovanna Nicora and Wojtek Michalowski and Szymon Wilk and Riccardo Bellazzi},
  doi          = {10.1016/j.artmed.2022.102471},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102471},
  shortjournal = {Artif. Intell. Med.},
  title        = {Why did AI get this one wrong? — tree-based explanations of machine learning model predictions},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ReCasNet: Improving consistency within the two-stage mitosis
detection framework. <em>ARTMED</em>, <em>135</em>, 102462. (<a
href="https://doi.org/10.1016/j.artmed.2022.102462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitotic count (MC) is an important histological parameter for cancer diagnosis and grading, but the manual process for obtaining MC from whole-slide histopathological images is very time-consuming and prone to error. Therefore, deep learning models have been proposed to facilitate this process. Existing approaches utilize a two-stage pipeline: the detection stage for identifying the locations of potential mitotic cells and the classification stage for refining prediction confidences. However, this pipeline formulation can lead to inconsistencies in the classification stage due to the poor prediction quality of the detection stage and the mismatches in training data distributions between the two stages. In this study, we propose a Refine Cascade Network (ReCasNet), an enhanced deep learning pipeline that mitigates the aforementioned problems with three improvements. First, window relocation was used to reduce the number of poor quality false positives generated during the detection stage. Second, object re-cropping was performed with another deep learning model to adjust poorly centered objects. Third, improved data selection strategies were introduced during the classification stage to reduce the mismatches in training data distributions . ReCasNet was evaluated on two large-scale mitotic figure recognition datasets, canine cutaneous mast cell tumor (CCMCT) and canine mammary carcinoma (CMC), which resulted in up to 4.8% percentage point improvements in the F1 scores for mitotic cell detection and 44.1% reductions in mean absolute percentage error (MAPE) for MC prediction. Techniques that underlie ReCasNet can be generalized to other two-stage object detection pipeline and should contribute to improving the performances of deep learning models in broad digital pathology applications.},
  archive      = {J_ARTMED},
  author       = {Chawan Piansaddhayanaon and Sakun Santisukwongchote and Shanop Shuangshoti and Qingyi Tao and Sira Sriswasdi and Ekapol Chuangsuwanich},
  doi          = {10.1016/j.artmed.2022.102462},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102462},
  shortjournal = {Artif. Intell. Med.},
  title        = {ReCasNet: Improving consistency within the two-stage mitosis detection framework},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Environmental exposures in machine learning and data mining
approaches to diabetes etiology: A scoping review. <em>ARTMED</em>,
<em>135</em>, 102461. (<a
href="https://doi.org/10.1016/j.artmed.2022.102461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental exposures are implicated in diabetes etiology, but are poorly understood due to disease heterogeneity, complexity of exposures, and analytical challenges. Machine learning and data mining are artificial intelligence methods that can address these limitations. Despite their increasing adoption in etiology and prediction of diabetes research, the types of methods and exposures analyzed have not been thoroughly reviewed. We aimed to review articles that implemented machine learning and data mining methods to understand environmental exposures in diabetes etiology and disease prediction. We queried PubMed and Scopus databases for machine learning and data mining studies that used environmental exposures to understand diabetes etiology on September 19th, 2022. Exposures were classified into specific external, general external, or internal exposures. We reviewed machine learning and data mining methods and characterized the scope of environmental exposures studied in the etiology of general diabetes, type 1 diabetes, type 2 diabetes, and other types of diabetes. We identified 44 articles for inclusion. Specific external exposures were the most common exposures studied, and supervised models were the most common methods used. Well-established specific external exposures of low physical activity , high cholesterol , and high triglycerides were predictive of general diabetes, type 2 diabetes, and prediabetes , while novel metabolic and gut microbiome biomarkers were implicated in type 1 diabetes. The use of machine learning and data mining methods to elucidate environmental triggers of diabetes was largely limited to well-established risk factors identified using easily explainable and interpretable models. Future studies should seek to leverage machine learning and data mining to explore the temporality and co-occurrence of multiple exposures and further evaluate the role of general external and internal exposures in diabetes etiology.},
  archive      = {J_ARTMED},
  author       = {Sejal Mistry and Naomi O. Riches and Ramkiran Gouripeddi and Julio C. Facelli},
  doi          = {10.1016/j.artmed.2022.102461},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102461},
  shortjournal = {Artif. Intell. Med.},
  title        = {Environmental exposures in machine learning and data mining approaches to diabetes etiology: A scoping review},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clipped DeepControl: Deep neural network two-dimensional
pulse design with an amplitude constraint layer. <em>ARTMED</em>,
<em>135</em>, 102460. (<a
href="https://doi.org/10.1016/j.artmed.2022.102460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced radio-frequency pulse design used in magnetic resonance imaging has recently been demonstrated with deep learning of (convolutional) neural networks and reinforcement learning. For two-dimensionally selective radio-frequency pulses, the (convolutional) neural network pulse prediction time (a few milliseconds) was in comparison more than three orders of magnitude faster than the conventional optimal control computation. The network pulses were from the supervised training capable of compensating scan-subject dependent inhomogeneities of B 0 and B 1 + fields. Unfortunately, the network presented with a small percentage of pulse amplitude overshoots in the test subset, despite the optimal control pulses used in training were fully constrained. Here, we have extended the convolutional neural network with a custom-made clipping layer that completely eliminates the risk of pulse amplitude overshoots, while preserving the ability to compensate for the inhomogeneous field conditions.},
  archive      = {J_ARTMED},
  author       = {Mads Sloth Vinding and Torben Ellegaard Lund},
  doi          = {10.1016/j.artmed.2022.102460},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102460},
  shortjournal = {Artif. Intell. Med.},
  title        = {Clipped DeepControl: Deep neural network two-dimensional pulse design with an amplitude constraint layer},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time detection of freezing of gait in parkinson’s
disease using multi-head convolutional neural networks and a single
inertial sensor. <em>ARTMED</em>, <em>135</em>, 102459. (<a
href="https://doi.org/10.1016/j.artmed.2022.102459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freezing of gait (FOG) is one of the most disabling symptoms of Parkinson’s disease (PD), contributing to poor quality of life and increased risk of falls. Wearable sensors represent a valuable means for detecting FOG in the home environment. Moreover, real-time feedback has proven to help reduce the duration of FOG episodes. This work proposes a robust real-time FOG detection algorithm , which is easy to implement in stand-alone devices working in non-supervised conditions. Data from three different data sets were used in this study, with two employed as independent test sets. Acceleration recordings from 118 PD patients and 21 healthy elderly subjects were collected while they performed simulated daily living activities. A single inertial sensor was attached to the waist of each subject. More than 17 h of valid data and a total number of 1110 FOG episodes were analyzed in this study. The implemented algorithm consisted of a multi-head convolutional neural network , which exploited different spatial resolutions in the analysis of inertial data. The architecture and the model parameters were designed to provide optimal performance while reducing computational complexity and testing time. The developed algorithm demonstrated good to excellent classification performance, with more than 50% (30%) of FOG episodes predicted on average 3.1 s (1.3 s) before the actual onset in the main (independent) data set. Around 50% of FOG was detected with an average delay of 0.8 s (1.1 s) in the main (independent) data set. Moreover, a specificity above 88% (93%) was obtained when testing the algorithm on the main (independent) test set, while 100% specificity was obtained on healthy elderly subjects. The algorithm proved robust, with low computational complexity and processing time, thus paving the way to a real-time implementation in a stand-alone device that can be used in non-supervised environments.},
  archive      = {J_ARTMED},
  author       = {Luigi Borzì and Luis Sigcha and Daniel Rodríguez-Martín and Gabriella Olmo},
  doi          = {10.1016/j.artmed.2022.102459},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102459},
  shortjournal = {Artif. Intell. Med.},
  title        = {Real-time detection of freezing of gait in parkinson’s disease using multi-head convolutional neural networks and a single inertial sensor},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A smarter perspective: Learning with and from AI-cases.
<em>ARTMED</em>, <em>135</em>, 102458. (<a
href="https://doi.org/10.1016/j.artmed.2022.102458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has only partially (or not at all) been integrated into medical education , leading to growing concerns regarding how to train healthcare practitioners to handle the changes brought about by the introduction of AI. Programming lessons and other technical information into healthcare curricula has been proposed as a solution to support healthcare personnel in using AI or other future technology. However, integrating these core elements of computer science knowledge might not meet the observed need that students will benefit from gaining practical experience with AI in the direct application area. Therefore, this paper proposes a dynamic approach to case-based learning that utilizes the scenarios where AI is currently used in clinical practice as examples. This approach will support students&#39; understanding of technical aspects. Case-based learning with AI as an example provides additional benefits: (1) it allows doctors to compare their thought processes to the AI suggestions and critically reflect on the assumptions and biases of AI and clinical practice; (2) it incentivizes doctors to discuss and address ethical issues inherent to technology and those already existing in current clinical practice; (3) it serves as a foundation for fostering interdisciplinary collaboration via discussion of different views between technologists, multidisciplinary experts, and healthcare professionals. The proposed knowledge shift from AI as a technical focus to AI as an example for case-based learning aims to encourage a different perspective on educational needs. Technical education does not need to compete with other essential clinical skills as it could serve as a basis for supporting them, which leads to better medical education and practice, ultimately benefiting patients.},
  archive      = {J_ARTMED},
  author       = {Laura Arbelaez Ossa and Michael Rost and Giorgia Lorenzini and David M. Shaw and Bernice Simone Elger},
  doi          = {10.1016/j.artmed.2022.102458},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102458},
  shortjournal = {Artif. Intell. Med.},
  title        = {A smarter perspective: Learning with and from AI-cases},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Style-transfer counterfactual explanations: An application
to mortality prevention of ICU patients. <em>ARTMED</em>, <em>135</em>,
102457. (<a href="https://doi.org/10.1016/j.artmed.2022.102457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, machine learning methods have been rapidly adopted in the medical domain. However, current state-of-the-art medical mining methods usually produce opaque, black-box models. To address the lack of model transparency, substantial attention has been given to developing interpretable machine learning models. In the medical domain, counterfactuals can provide example-based explanations for predictions, and show practitioners the modifications required to change a prediction from an undesired to a desired state. In this paper, we propose a counterfactual solution MedSeqCF for preventing the mortality of three cohorts of ICU patients, by representing their electronic health records as medical event sequences, and generating counterfactuals by adopting and employing a text style-transfer technique. We propose three model augmentations for MedSeqCF to integrate additional medical knowledge for generating more trustworthy counterfactuals. Experimental results on the MIMIC-III dataset strongly suggest that augmented style-transfer methods can be effectively adapted for the problem of counterfactual explanations in healthcare applications and can further improve the model performance in terms of validity, BLEU-4, local outlier factor , and edit distance. In addition, our qualitative analysis of the results by consultation with medical experts suggests that our style-transfer solutions can generate clinically relevant and actionable counterfactual explanations.},
  archive      = {J_ARTMED},
  author       = {Zhendong Wang and Isak Samsten and Vasiliki Kougia and Panagiotis Papapetrou},
  doi          = {10.1016/j.artmed.2022.102457},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102457},
  shortjournal = {Artif. Intell. Med.},
  title        = {Style-transfer counterfactual explanations: An application to mortality prevention of ICU patients},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A PROMETHEE based outranking approach for the construction
of fangcang shelter hospital using spherical fuzzy sets.
<em>ARTMED</em>, <em>135</em>, 102456. (<a
href="https://doi.org/10.1016/j.artmed.2022.102456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study mainly aims to develop two effective and practical multi-criteria group decision-making approaches by taking advantage of the ground-breaking theory of PROMETHEE family of outranking methods. The presented variants of Preference Ranking Organization Method for Enrichment Evaluation (PROMETHEE) method are acknowledged to address the complex decision-making problems carrying the ambiguous information, expressible in terms of yes, no, abstinence and refusal, owing to the preeminent condition and wider structure of spherical fuzzy sets. Both of the proposed approaches seek help from the Shannon’s entropy formula to evaluate the object weights of the decision criteria. The proposed techniques operate by taking into account the deviation between each pair of potential alternatives in accordance to different types of preference functions to determine the preference indices. The proposed technique of spherical fuzzy PROMETHEE I method carefully compares the positive and negative outranking flows of the alternative to get partial rankings. In contrast, the spherical fuzzy PROMETHEE II method has the edge to eliminate the incomparable pair by employing the net outranking flow to derive the final ranking. The application of proposed approaches is explained via a case study in the field of medical concerning the selection of appropriate site to establish Fangcang shelter hospital in Wuhan to treat COVID-19 patients. The convincing comparisons of the proposed methodologies with q -rung orthopair fuzzy PROMETHEE and spherical fuzzy TOPSIS methods are also included to verify the aptitude of the proposed methodology.},
  archive      = {J_ARTMED},
  author       = {Muhammad Akram and Kiran Zahid and Cengiz Kahraman},
  doi          = {10.1016/j.artmed.2022.102456},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102456},
  shortjournal = {Artif. Intell. Med.},
  title        = {A PROMETHEE based outranking approach for the construction of fangcang shelter hospital using spherical fuzzy sets},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph-based association rule learning for context-based
health monitoring to enable user-centered assistance. <em>ARTMED</em>,
<em>135</em>, 102455. (<a
href="https://doi.org/10.1016/j.artmed.2022.102455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the demographic change and the accompanying challenges for effective healthcare, approaches to enable using advancements of digitalization and IoT infrastructures as well as AI methods to deliver results in the field of personalized health assistance are necessary. In our research, we aim at enabling user-centered assistance with the help of networked sensors and Health Assistance Systems as well as learning methods based on connected graph data that model the shared system, user, and environmental context. In particular, this paper demonstrates a graph-based dynamic context model for a medication assistance system and presents an association rule learning method using Apriori algorithm to learn correlations between user vitals, activities as well as medication intake behavior. An application scenario for context-based heart rate monitoring is consequently presented as proof of concept, where associated contextual elements from the modeled context relating surges in monitored heart rate to environmental and user activity are shown.},
  archive      = {J_ARTMED},
  author       = {Nada Sahlab and Iman Sonji and Michael Weyrich},
  doi          = {10.1016/j.artmed.2022.102455},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102455},
  shortjournal = {Artif. Intell. Med.},
  title        = {Graph-based association rule learning for context-based health monitoring to enable user-centered assistance},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A self-supervised algorithm to detect signs of social
isolation in the elderly from daily activity sequences. <em>ARTMED</em>,
<em>135</em>, 102454. (<a
href="https://doi.org/10.1016/j.artmed.2022.102454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the increasing aging of the population, multi-device monitoring of the activities of daily living (ADL) of older people becomes crucial to support independent living and early detection of symptoms of mental illnesses, such as depression and Alzheimer’s disease. Anomalies can anticipate the diagnosis of these pathologies in the patient’s normal behavior, such as reduced hygiene, changes in sleep habits, and fewer social interactions. These abnormalities are often subtle and hard to detect. Especially using non-intrusive monitoring devices might cause anomaly detectors to generate false alarms or ignore relevant clues. This limitation may hinder their usage by caregivers. Furthermore, the notion of abnormality here is context and patient-dependent, thus requiring untrained approaches. To reduce these problems, we propose a self-supervised model for multi-sensor time series signals based on Hyperbolic uncertainty for Anomaly Detection , which we dub HypAD. HypAD estimates uncertainty end-to-end, thanks to hyperbolic neural networks , and integrates it into the ”classic” notion of reconstruction loss in anomaly detection. Based on hyperbolic uncertainty, HypAD introduces the principle of a detectable anomaly. HypAD assesses whether it is sure about the input signal and fails to reconstruct it because it is anomalous or whether the high reconstruction loss is due to the model uncertainty, e.g., a complex but regular signal (cf. this parallels the residual model error upon training). The proposed solution has been incorporated into an end-to-end ADL monitoring system for elderly patients in retirement homes, developed within a funded project leveraging an interdisciplinary consortium of computer scientists, engineers, and geriatricians. Healthcare professionals were involved in the design and verification process to foster trust in the system. In addition, the system has been equipped with explainability features.},
  archive      = {J_ARTMED},
  author       = {Bardh Prenkaj and Dario Aragona and Alessandro Flaborea and Fabio Galasso and Saverio Gravina and Luca Podo and Emilia Reda and Paola Velardi},
  doi          = {10.1016/j.artmed.2022.102454},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102454},
  shortjournal = {Artif. Intell. Med.},
  title        = {A self-supervised algorithm to detect signs of social isolation in the elderly from daily activity sequences},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepGA for automatically estimating fetal gestational age
through ultrasound imaging. <em>ARTMED</em>, <em>135</em>, 102453. (<a
href="https://doi.org/10.1016/j.artmed.2022.102453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimation of gestational age (GA) is vital for identifying fetal abnormalities . Conventionally, GA is estimated by measuring the morphology of the cranium, abdomen, and femur manually and inputting them into the classic Hadlock formula to assess fetal growth . However, this procedure incurs considerable overhead and suffers from bias caused by the operators, yielding suboptimal estimations. To address this challenge, we develop an automatic DeepGA model to achieve fully automatic GA prediction in an end-to-end manner. Our model uses a deep segmentation model (DeepSeg) to accurately identify and segment three critical tissues, including the cranium, abdomen, and femur, in which their morphology is automatically extracted. After that, we are able to directly estimate the GA via a deep regression model (DeepReg). We evaluate DeepGA on a large dataset, including 10,413 ultrasound images from 7113 subjects. It achieves superior performance over the traditional measurement approach, with a mean absolute estimation error (MAE) of 5 days. Our DeepGA model is a novel automatic solution on the basis of artificial intelligence learning that can help radiologists improve the performance of GA estimation in various clinical scenarios, thereby enhancing the efficiency of prenatal examinations.},
  archive      = {J_ARTMED},
  author       = {Tingting Dan and Xijie Chen and Miao He and Hongmei Guo and Xiaoqin He and Jiazhou Chen and Jianbo Xian and Yu Hu and Bin Zhang and Nan Wang and Hongning Xie and Hongmin Cai},
  doi          = {10.1016/j.artmed.2022.102453},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102453},
  shortjournal = {Artif. Intell. Med.},
  title        = {DeepGA for automatically estimating fetal gestational age through ultrasound imaging},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using type-2 fuzzy ontology to improve semantic
interoperability for healthcare and diagnosis of depression.
<em>ARTMED</em>, <em>135</em>, 102452. (<a
href="https://doi.org/10.1016/j.artmed.2022.102452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology enhances semantic interoperability through integrating health data from heterogeneous sources and sharing information in a meaningful way. In the field of smart health services, semantic interoperability means the exchange and interpretation of data without ambiguity and uncertainty. However, existing classical ontologies are not able to represent vague and uncertain knowledge, especially in contexts of mental health disorders which are associated with varying degrees of uncertainty and inaccuracy of diagnosis, and in this case, the treatment is a complex and common mental process necessitating to share information accurately and unambiguously. Type-2 fuzzy set theory can offer a fruitful solution in order to control uncertainty or express ambiguous concepts in a dynamic and complex environment such as healthcare systems. Herein, a semantic framework for healthcare, and also monitoring mental health disorders using type-2 fuzzy set theory based on the Internet of Thing (IoT) is suggested, in which all depression-related concepts are semantically annotated to share detailed information with the treatment staff. This framework not only paved the way to increasing the accuracy of medical diagnosis and decision-making but also provides the possibility of inference and semantic reasoning using the languages of SPARQL query and DL query.},
  archive      = {J_ARTMED},
  author       = {Abolfazl Ghorbani and Fatemeh Davoodi and Kamran Zamanifar},
  doi          = {10.1016/j.artmed.2022.102452},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102452},
  shortjournal = {Artif. Intell. Med.},
  title        = {Using type-2 fuzzy ontology to improve semantic interoperability for healthcare and diagnosis of depression},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Open-set recognition of breast cancer treatments.
<em>ARTMED</em>, <em>135</em>, 102451. (<a
href="https://doi.org/10.1016/j.artmed.2022.102451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-set recognition generalizes a classification task by classifying test samples as one of the known classes from training or “unknown.” As novel cancer drug cocktails with improved treatment are continually discovered, classifying patients by treatments can naturally be formulated in terms of an open-set recognition problem. Drawbacks, due to modeling unknown samples during training, arise from straightforward implementations of prior work in healthcare open-set learning. Accordingly, we reframe the problem methodology and apply a recent Gaussian mixture variational autoencoder model, which achieves state-of-the-art results for image datasets, to breast cancer patient data. Not only do we obtain more accurate and robust classification results (14% average F1 increase compared to recent methods), but we also reexamine open-set recognition in terms of deployability to a clinical setting.},
  archive      = {J_ARTMED},
  author       = {Alexander Cao and Diego Klabjan and Yuan Luo},
  doi          = {10.1016/j.artmed.2022.102451},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102451},
  shortjournal = {Artif. Intell. Med.},
  title        = {Open-set recognition of breast cancer treatments},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Virtual trials: Causally-validated treatment effects
efficiently learned from an observational cancer registry.
<em>ARTMED</em>, <em>135</em>, 102450. (<a
href="https://doi.org/10.1016/j.artmed.2022.102450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized controlled trials (RCTs) offer a clear causal interpretation of treatment effects, but are inefficient in terms of information gain per patient. Moreover, because they are intended to test cohort-level effects, RCTs rarely provide information to support precision medicine, which strives to choose the best treatment for an individual patient . If causal information could be efficiently extracted from widely available real-world data, the rapidity of treatment validation could be increased, and its costs reduced. Moreover, inferences could be made across larger, more diverse patient populations. We created a “virtual trial” by fitting a multilevel Bayesian survival model to treatment and outcome records self-reported by 451 brain cancer patients . The model recovers group-level treatment effects comparable to RCTs representing over 3200 patients. The model additionally discovers the feature-treatment interactions needed to make individual-level predictions for precision medicine. By learning from heterogeneous real-world data, virtual trials can generate more causal estimates with fewer patients than RCTs, and they can do so without artificially limiting the patient population. This demonstrates the value of virtual trials as a complement to large randomized controlled trials, especially in highly heterogeneous or rare diseases .},
  archive      = {J_ARTMED},
  author       = {Asher Wasserman and Al Musella and Mark Shapiro and Jeff Shrager},
  doi          = {10.1016/j.artmed.2022.102450},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102450},
  shortjournal = {Artif. Intell. Med.},
  title        = {Virtual trials: Causally-validated treatment effects efficiently learned from an observational cancer registry},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated ELECTRE method for selection of rehabilitation
center with m-polar fuzzy n-soft information. <em>ARTMED</em>,
<em>135</em>, 102449. (<a
href="https://doi.org/10.1016/j.artmed.2022.102449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary goal of this research article is to apply ELECTRE I, a fundamental multi-criteria group decision-making technique, in an m m -polar fuzzy N N -soft environment. This new methodology helps us to pinpoint the best alternative(s) in the presence of multi-polar options with N N -graded qualities. Its basic operational idea entails the comparison between any two alternatives by the assessment of score degrees. Concordance and discordance indices are then calculated to evaluate the alternatives’ superiority and inferiority. We may disqualify the incompetent alternatives using concordance and discordance levels. An m m -polar fuzzy N N -soft dominance matrix can represent the combined effect of concordance and discordance dominance matrices. The steps of this new multi-criteria group decision making technique are summarized in a flowchart. In order to demonstrate its authenticity and applicability, we employ a case study involving the establishment of a rehabilitation facility for drug abusers. A comparison with the m m -polar fuzzy PROMETHEE and m m -polar fuzzy ELECTRE I methodologies establishes its validity. Finally, we conclude our study of the methodology proposed in this paper with a critical analysis of its benefits and drawbacks.},
  archive      = {J_ARTMED},
  author       = {Muhammad Akram and Maheen Sultan and José Carlos R. Alcantud},
  doi          = {10.1016/j.artmed.2022.102449},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102449},
  shortjournal = {Artif. Intell. Med.},
  title        = {An integrated ELECTRE method for selection of rehabilitation center with m-polar fuzzy N-soft information},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated LSTM-HeteroRGNN model for interpretable opioid
overdose risk prediction. <em>ARTMED</em>, <em>135</em>, 102439. (<a
href="https://doi.org/10.1016/j.artmed.2022.102439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opioid overdose (OD) has become a leading cause of accidental death in the United States, and overdose deaths reached a record high during the COVID-19 pandemic. Combating the opioid crisis requires targeting high-need populations by identifying individuals at risk of OD. While deep learning emerges as a powerful method for building predictive models using large scale electronic health records (EHR), it is challenged by the complex intrinsic relationships among EHR data. Further, its utility is limited by the lack of clinically meaningful explainability, which is necessary for making informed clinical or policy decisions using such models. In this paper, we present LIGHTED, an integrated deep learning model combining long short term memory (LSTM) and graph neural networks (GNN) to predict patients&#39; OD risk. The LIGHTED model can incorporate the temporal effects of disease progression and the knowledge learned from interactions among clinical features . We evaluated the model using Cerner&#39;s Health Facts database with over 5 million patients. Our experiments demonstrated that the model outperforms traditional machine learning methods and other deep learning models. We also proposed a novel interpretability method by exploiting embeddings provided by GNNs to cluster patients and EHR features respectively, and conducted qualitative feature cluster analysis for clinical interpretations. Our study shows that LIGHTED can take advantage of longitudinal EHR data and the intrinsic graph structure of EHRs among patients to provide effective and interpretable OD risk predictions that may potentially improve clinical decision support.},
  archive      = {J_ARTMED},
  author       = {Xinyu Dong and Rachel Wong and Weimin Lyu and Kayley Abell-Hart and Jianyuan Deng and Yinan Liu and Janos G. Hajagos and Richard N. Rosenthal and Chao Chen and Fusheng Wang},
  doi          = {10.1016/j.artmed.2022.102439},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102439},
  shortjournal = {Artif. Intell. Med.},
  title        = {An integrated LSTM-HeteroRGNN model for interpretable opioid overdose risk prediction},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ProDeM: A process-oriented delphi method for systematic
asynchronous and consensual surgical process modelling. <em>ARTMED</em>,
<em>135</em>, 102426. (<a
href="https://doi.org/10.1016/j.artmed.2022.102426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical process models support improving healthcare provision by facilitating communication and reasoning about processes in the medical domain. Modelling surgical processes is challenging as it requires integrating information that might be fragmented, scattered, and not process-oriented. These challenges can be faced by involving healthcare domain experts during process modelling. This paper presents ProDeM: a novel Process-Oriented Delphi Method for the systematic, asynchronous, and consensual modelling of surgical processes. ProDeM is an adaptable and flexible method that acknowledges that: (i) domain experts have busy calendars and might be geographically dispersed, and (ii) various elements of the process model need to be assessed to ensure model quality . The contribution of the paper is twofold as it outlines ProDeM, but also demonstrates its operationalisation in the context of a well-known surgical process. Besides showing the method’s feasibility in practice, we also present an evaluation of the method by the experts involved in the demonstration.},
  archive      = {J_ARTMED},
  author       = {Fernanda Gonzalez-Lopez and Niels Martin and Rene de la Fuente and Victor Galvez-Yanjari and Javiera Guzmán and Eduardo Kattan and Marcos Sepúlveda and Jorge Munoz-Gama},
  doi          = {10.1016/j.artmed.2022.102426},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102426},
  shortjournal = {Artif. Intell. Med.},
  title        = {ProDeM: A process-oriented delphi method for systematic asynchronous and consensual surgical process modelling},
  volume       = {135},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
