<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>RAS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ras---171">RAS - 171</h2>
<ul>
<li><details>
<summary>
(2023). Pyramidal 3D feature fusion on polar grids for fast and
robust traversability analysis on CPU. <em>RAS</em>, <em>170</em>,
104524. (<a href="https://doi.org/10.1016/j.robot.2023.104524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-driving vehicles and autonomous ground robots require a reliable and accurate method to analyze the traversability of the surrounding environment for safe navigation . This paper proposes and evaluates a real-time machine learning-based traversability analysis method that combines geometric features with a pyramid-polar space representation based on SVM classifiers. In particular, we show that by fusing geometric features with information stemming from coarser pyramid levels that account for a broader space portion, as well as integrating important implementation details, allows for a noticeable boost in performance and reliability. The main goal of this work is to demonstrate that traversability analysis is possible with effective results and in real-time even on cheaper hardware than expensive GPUs , e.g. CPU-only PCs. The proposed approach has been compared with state-of-the-art deep learning approaches on publicly available datasets of outdoor driving scenarios, running such algorithms both on GPU and CPU to compare runtimes. Our method can be fully executed on CPU and achieves results close to the best-in-class methods, runs faster, and requires fewer and less expensive hardware resources, consuming less than 30\% electrical power with respect to deep learning models on embedded processing units. We release with this paper the open-source implementation of our method.},
  archive      = {J_RAS},
  author       = {Daniel Fusaro and Emilio Olivastri and Ivano Donadi and Daniele Evangelista and Emanuele Menegatti and Alberto Pretto},
  doi          = {10.1016/j.robot.2023.104524},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104524},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Pyramidal 3D feature fusion on polar grids for fast and robust traversability analysis on CPU},
  volume       = {170},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A study of robotic search strategy for multi-radiation
sources in unknown environments. <em>RAS</em>, <em>169</em>, 104529. (<a
href="https://doi.org/10.1016/j.robot.2023.104529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the multiple radiation source search problems, where the mobile robot identifies the number and parameters of sources online while exploring an unknown environment. The radiation superposition and the limited observations improve the difficulty of estimation, and the exploration trajectory is also associated with estimation. A novel search strategy based on receding horizon planning is proposed, which includes the observation, estimation, and exploration modules. The observation module filters and records the radiation intensity for estimation. In the estimation module, an adaptive differential evolution algorithm is integrated into the peak suppression particle filter to avoid the local optimum. The multi-source radiation gain model is conceived to determine the observation position in the exploration module. The strategy trades off exploration of unknown areas and exploitation of known radiation fields. The results of simulations and experiments demonstrate that the proposed strategy can identify the parameters and quantities of all sources in multi-modal radiation fields. Furthermore, our strategy exhibits superior performance in searching for multi-radiation sources in unknown environments compared with the boustrophedon path and the Next-Best-View planner.},
  archive      = {J_RAS},
  author       = {Hua Bai and Wenrui Gao and Haofei Ma and Pengchao Ding and Gongcheng Wang and Wenda Xu and Weidong Wang and Zhijiang Du},
  doi          = {10.1016/j.robot.2023.104529},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104529},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A study of robotic search strategy for multi-radiation sources in unknown environments},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel collaborative path planning algorithm for 3-wheel
omnidirectional autonomous mobile robot. <em>RAS</em>, <em>169</em>,
104527. (<a href="https://doi.org/10.1016/j.robot.2023.104527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaboration of multiple mobile robots becomes important in situations where collaborative tasks are required. For this purpose, a method including obstacle detection based on collaborative path planning of multiple Autonomous Mobile Robots (AMRs) has been developed. This study ensures the usability of collaborative omnidirectional AMRs technologies in various fields. In the study, novel path planning and obstacle avoidance algorithms are developed for collaborative mobile robots with omnidirectional mobility. Essentially, these algorithms include motion planning performed by obstacle avoidance with two identical 3-wheel omnidirectional mobile robots (TWOMR). Numerical calculations of the collaborative algorithm have been performed after the kinematic calculations, and tested algorithms developed for the proposed model. As a result, it has been observed that the path planning and obstacle avoidance algorithms developed for collaborative omnidirectional AMRs successfully follow the Master robot in the most efficient trajectory without collision and it has been observed that the developed method works with high accuracy.},
  archive      = {J_RAS},
  author       = {Meltem Eyuboglu and Gokhan Atali},
  doi          = {10.1016/j.robot.2023.104527},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104527},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A novel collaborative path planning algorithm for 3-wheel omnidirectional autonomous mobile robot},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A framework to integrate mobile manipulators as
cyber–physical systems into existing production systems in the context
of industry 4.0. <em>RAS</em>, <em>169</em>, 104526. (<a
href="https://doi.org/10.1016/j.robot.2023.104526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of the Cyber–Physical Systems (CPSs) along with the fourth industrial revolution, the discussion of distributed architecture and coordination and extensive communication between all components of a system was raised. On the other hand, Modern industrial manufacturing relies heavily on flexible production. Autonomous mobile manipulators (MMs) have the potential to improve the flexibility of existing manufacturing environments . With the advantages associated with this technology, there is an upsurge in the demand for MMs. Thus, adding a new MM as a new CPS into a system following industry 4.0 requires a framework to help taking all the advantages from it. In this article, we proposed a framework to integrating MMs as CPSs into an existing production system. This integration requires comprehensive knowledge of the existing production process and control, which is a view to improve the performance of the existing production systems via new functionalities due to MMs. The next step of the framework is to make new MM operations compatible with the existing production control system. For this purpose, we define different parametric blocks to perform new operations and thus contribute to making the production line more autonomous. Considering all of these issues simultaneously is necessary for an efficient integration in smart production context. For a successful integration, we presented four principal dimensions of integration: Physical integration, communicational integration, functional and operational integration, and digital integration. Furthermore, the framework has been applied to a research production line called Platform 4.0 at Arts et Métiers. An MM from OMRON Company (called MoMa) has been integrated into the existing production system. Results from this real-world demonstration show that MoMa is capable of successfully increasing flexibility, autonomy, and efficiency of a production system using command signals from Manufacturing Execution System (MES).},
  archive      = {J_RAS},
  author       = {Nooshin Ghodsian and Khaled Benfriha and Adel Olabi and Varun Gopinath and Esma Talhi and Lucas A. Hof and Aurélien Arnou},
  doi          = {10.1016/j.robot.2023.104526},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104526},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A framework to integrate mobile manipulators as cyber–physical systems into existing production systems in the context of industry 4.0},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual-RRT: Integrating IBVS as a steering method in an RRT
planner. <em>RAS</em>, <em>169</em>, 104525. (<a
href="https://doi.org/10.1016/j.robot.2023.104525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new approach to robot motion planning that anticipates the use of vision-based feedback control during task execution. We accomplish this by incorporating an image-based visual servo (IBVS) controller directly into the steering function used by a Rapidly Exploring Random Tree (RRT) planner. Our approach requires a number of extensions to traditional RRT-style planning. First, we derive a new sampling strategy that augments the usual state information by including image features that will be used by the IBVS control law. These augmented samples are then used by our new IBVS steering function, which simulates an IBVS control law to generate local trajectories that extend the current tree. These trajectories must be validated to ensure that they are collision-free and that all image features remain unoccluded and within the camera field of view throughout the local trajectory. We also provide a formal proof showing that the proposed approach is probabilistically complete . We have applied our approach to the problem of planning trajectories for three different systems: a robotic arm , an unmanned aerial vehicle (UAV) and a car-like robot, which are equipped with an IBVS control law. We explore performance trade-offs in the control design via simulation studies and demonstrate real-world effectiveness via experiments in which a small-scale car-like robot uses IBVS to navigate a track that includes a number of obstacles and potential occlusions. By exploring performance trade-offs, we mean that several elements, such as the metric used to identify nearest neighbors in the RRT and the steering method used to generate nodes, are tested and compared.},
  archive      = {J_RAS},
  author       = {Ramses Reyes and Israel Becerra and Rafael Murrieta-Cid and Seth Hutchinson},
  doi          = {10.1016/j.robot.2023.104525},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104525},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Visual-RRT: Integrating IBVS as a steering method in an RRT planner},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance analysis of buck converter with fractional PID
controller using hybrid technique. <em>RAS</em>, <em>169</em>, 104515.
(<a href="https://doi.org/10.1016/j.robot.2023.104515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid technique is proposed for analyzing the performance of buck converters with fractional-order proportional integral derivative (FOPID) controllers. The hybrid approach is a combination of Capuchin Search Algorithm (CapSA) and Golden Jackal Optimization (GJO). The update behavior of Golden Jackal Optimization2 is enhanced with Capuchin Search Algorithm (CapSA) therefore it is called the improved GJO (IGJO) technique. The power converters are hard to manage based on their nonlinear nature and therefore the search for smart and effectual controllers is ongoing and continual. In current years, fractional order controllers have shown greater efficiency in power electronic systems. The IGJO technique is used to establish the optimum design of a fractional-order proportional integral derivative (PID) controller for the buck converter. The FOPID controller parameters are considered to diminish several performance metrics, with a particular focus on the Integral Squared Error (ISE). The proposed method is performed in the MATLAB, and its execution is analyzed by using the existing methods. From the simulation result, the proposed method reduces the error more effectively than existing methods.},
  archive      = {J_RAS},
  author       = {S. Sangeetha and B. Sri Revathi and K. Balamurugan and Suresh G.},
  doi          = {10.1016/j.robot.2023.104515},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104515},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Performance analysis of buck converter with fractional PID controller using hybrid technique},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards autonomous mapping in agriculture: A review of
supportive technologies for ground robotics. <em>RAS</em>, <em>169</em>,
104514. (<a href="https://doi.org/10.1016/j.robot.2023.104514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper surveys the supportive technologies currently available for ground mobile robots used for autonomous mapping in agriculture. Unlike previous reviews, we describe state-of-the-art approaches and technologies aimed at extracting information from agricultural environments, not only for navigation purposes but especially for mapping and monitoring. The state-of-the-art platforms and sensors, the modern localization techniques, the navigation and path planning approaches, as well as the potentialities of artificial intelligence towards autonomous mapping in agriculture are analyzed. According to the findings of this review, many examples of recent mobile robots provide full navigation and autonomous mapping capability. Significant resources are currently devoted to this research area, in order to further improve mobile robot capabilities in this complex and challenging field.},
  archive      = {J_RAS},
  author       = {Diego Tiozzo Fasiolo and Lorenzo Scalera and Eleonora Maset and Alessandro Gasparetto},
  doi          = {10.1016/j.robot.2023.104514},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104514},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Towards autonomous mapping in agriculture: A review of supportive technologies for ground robotics},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time terrain anomaly perception for safe robot
locomotion using a digital double framework. <em>RAS</em>, <em>169</em>,
104512. (<a href="https://doi.org/10.1016/j.robot.2023.104512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital twinning systems are effective tools to test and develop new robotic capabilities before applying them in the real world. This work presents a real-time digital double framework that improves and facilitates robot perception of the environment. Soft or non-rigid terrains can cause locomotion failures, while visual perception alone is often insufficient to assess the physical properties of such surfaces. To tackle this problem we employ the proposed framework to estimate ground collapsibility through physical interactions while the robot is dynamically walking on challenging terrains. We extract discrepancy information between the two systems, a simulated digital double that is synchronized with a real robot , both using exactly the same physical model and locomotion controller. The discrepancy in sensor measurements between the real robot and its digital double serves as a critical indicator of anomalies between expected and actual motion and is utilized as input to a learning-based model for terrain collapsibility analysis. The performance of the collapsibility estimation was evaluated in a variety of real-world scenarios involving flat, inclined, elevated, and outdoor terrains. Our results demonstrate the generality and efficacy of our real-time digital double architecture for estimating terrain collapsibility.},
  archive      = {J_RAS},
  author       = {Garen Haddeler and Hari P. Palanivelu and Fabien Colonnier and Yung Chuen Ng and Albertus H. Adiwahono and Zhibin Li and Chee-Meng Chew and Meng Yee Michael Chuah},
  doi          = {10.1016/j.robot.2023.104512},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104512},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Real-time terrain anomaly perception for safe robot locomotion using a digital double framework},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autonomous agent-based simulation modelling—a case study on
a flexible GPU-card final assembly line. <em>RAS</em>, <em>169</em>,
104511. (<a href="https://doi.org/10.1016/j.robot.2023.104511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Market demands for high-tech products constantly evolve by product specification. To be competitive, a production system must be flexible and reconfigurable when facing mass customization . Flexible assembly line (FAL) enables mixed production with high efficiency. One example is graphic processing unit (GPU) cards. FAL requires comprehensive system design and scheduling to fully utilize the resources. This study adopts agent-based simulation (ABS) modelling for a FAL because of the abilities of ABS in flexibility and scalability. The proposed framework consists of three parts: real environment, virtual environment, and evaluation and analysis. This study uses agent-based simulation modelling to elaborate on sequencing and scheduling performances in the GPU-card assembly line. The Pareto frontier analysis is conducted to resolve conflicts between part tardiness and throughput.},
  archive      = {J_RAS},
  author       = {Kung-Jeng Wang and Agustina Eunike and Ivan Kurniawan and Romadhani Ardi and Jing-Ming Chiu},
  doi          = {10.1016/j.robot.2023.104511},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104511},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Autonomous agent-based simulation modelling—A case study on a flexible GPU-card final assembly line},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning stable robotic skills on riemannian manifolds.
<em>RAS</em>, <em>169</em>, 104510. (<a
href="https://doi.org/10.1016/j.robot.2023.104510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an approach to learn stable dynamical systems that evolve on Riemannian manifolds. Our approach leverages a data-efficient procedure to learn a diffeomorphic transformation, enabling the mapping of simple stable dynamical systems onto complex robotic skills. By harnessing mathematical techniques derived from differential geometry, our method guarantees that the learned skills fulfill the geometric constraints imposed by the underlying manifolds, such as unit quaternions (UQ) for orientation and symmetric positive definite (SPD) matrices for impedance. Additionally, the method preserves convergence towards a given target. Initially, the proposed methodology is evaluated through simulation on a widely recognized benchmark, which involves projecting Cartesian data onto UQ and SPD manifolds. The performance of our proposed approach is then compared with existing methodologies. Apart from that, a series of experiments were performed to evaluate the proposed approach in real-world scenarios. These experiments involved a physical robot tasked with bottle stacking under various conditions and a drilling task performed in collaboration with a human operator. The evaluation results demonstrate encouraging outcomes in terms of learning accuracy and the ability to adapt to different situations.},
  archive      = {J_RAS},
  author       = {Matteo Saveriano and Fares J. Abu-Dakka and Ville Kyrki},
  doi          = {10.1016/j.robot.2023.104510},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104510},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Learning stable robotic skills on riemannian manifolds},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed strategy for communication between multiple
robots during formation navigation task. <em>RAS</em>, <em>169</em>,
104509. (<a href="https://doi.org/10.1016/j.robot.2023.104509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm robotics involves the study of the behavior of a set of robots in carrying out collective tasks, such as alignment, navigation and formation. During cooperative tasks execution, the communication among robots can contribute to successfully performing tasks through an efficient messages exchange. This paper proposes a communication strategy for swarm robots, the so-called Double-Wave Swarm, aiming at alignment and navigation tasks . The Double-Wave Swarm is an improvement of a prior Wave Swarm communication approach that uses the concept of wave propagation for message exchange between neighbors. Double-Wave Swarm provides better communication network connectivity when compared to the former approach. Experiments with the robot simulator CoppeliaSim (V-REP) validate the proposed communication and highlight its efficiency and robustness while running alignment and navigation tasks . Also, the Double-Wave Swarm proved to be superior during swarm formation navigation into environments with obstacles in different scenarios if compared with Wave Swarm.},
  archive      = {J_RAS},
  author       = {Rubisson Duarte Lamperti and Lucia Valéria Ramos de Arruda},
  doi          = {10.1016/j.robot.2023.104509},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104509},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Distributed strategy for communication between multiple robots during formation navigation task},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Perception-aware online trajectory generation for a
prescribed manoeuvre of unmanned surface vehicle in cluttered
unstructured environment. <em>RAS</em>, <em>169</em>, 104508. (<a
href="https://doi.org/10.1016/j.robot.2023.104508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a perception-aware online trajectory generation system that facilitates prescribed manoeuvres of an unmanned surface vehicle (USV) in a dynamic unstructured environment. The proposed system is developed based on the principles of the inverse dynamics in the virtual domain (IDVD) method and an event-triggered receding horizon control (ETRHC) mechanism. This approach transforms the underlying nonconvex constrained optimization problem into a virtual space with a differentially flat dynamics and uses relatively few decision variables to prototype feasible quasi-optimal trajectories. The closed-loop configuration is provided by a computationally efficient ETRHC mechanism that uses situational awareness of operating environment to trigger trajectory replanning if/when required. This addresses the challenge of continuously updating a closed-loop trajectory which imposes unnecessary computational burden on a system with the limited onboard resources. To investigate the performance of the proposed trajectory generating system, a dynamic unstructured environment including variable and uncertain no-fly zone areas as well as variable current vector fields are modeled. Further, different operating conditions incorporating the uncertainties of environment and sudden failure on the USV propulsion system are introduced to examine the effectiveness, agility, and robustness of the proposed trajectory generating system. A comparative study with benchmark solutions generated by the hp-adaptive Radau pseudo-spectral method is conducted to provide a detailed statistical analysis of the proposed approach robustness, computational complexity , and effectiveness. The simulation results confirm the effectiveness of the proposed trajectory generator and ability to produce a solution for online realization.},
  archive      = {J_RAS},
  author       = {Amirmehdi Yazdani and Somaiyeh MahmoudZadeh and Oleg Yakimenko and Hai Wang},
  doi          = {10.1016/j.robot.2023.104508},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104508},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Perception-aware online trajectory generation for a prescribed manoeuvre of unmanned surface vehicle in cluttered unstructured environment},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flattening and folding towels with a single-arm robot based
on reinforcement learning. <em>RAS</em>, <em>169</em>, 104506. (<a
href="https://doi.org/10.1016/j.robot.2023.104506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots can learn how to complete a variety of tasks without explicit instructions thanks to reinforcement learning . In this work, a piece of cloth is placed on a table and manipulated using a single-arm robot. We consider 2 forms of manipulation: flattening a crumpled towel and folding a flat one. To learn a policy that will allow the robot to select the optimum course of action based on observations of the environment, we construct a simulation environment using a gripper and a piece of cloth. After that, the policy is applied to a real robot and put to the test. Additionally, we present our method for identifying the corners of a garment using computer vision , which includes a comparison between a traditional computer vision approach with a deep learning one. We use an ABB robot and a 2D camera for the experiments and PyBullet software for the simulation.},
  archive      = {J_RAS},
  author       = {Hassan Shehawy and Daniele Pareyson and Virginia Caruso and Stefano De Bernardi and Andrea Maria Zanchettin and Paolo Rocco},
  doi          = {10.1016/j.robot.2023.104506},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104506},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Flattening and folding towels with a single-arm robot based on reinforcement learning},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Driving line-based two-stage path planning in the AGV
sorting system. <em>RAS</em>, <em>169</em>, 104505. (<a
href="https://doi.org/10.1016/j.robot.2023.104505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The path planning problem is the core issue in the automatic guided vehicle (AGV) sorting system. The current AGV sorting system has the following characteristics: (1) a great number of AGVs; (2) dynamic sorting of tasks; and (3) two-stage tasks involving transporting express packages and then leaving the sorting area. Therefore, existing path planning methods face challenges in terms of achieving timeliness and optimality . In this paper, the path planning problem of the AGV sorting system in a mesh topology area is modeled. A Driving Line-based Two-Stage (DLTS) path planning algorithm is proposed. First, to avoid conflicts among AGVs with different driving directions, time–space resources are divided according to the driving line mechanism, which specifies the driving direction, possible planned locations and specific driving rules. Second, we propose an incremental search method to plan continuous paths for two-stage tasks while simultaneously avoiding conflicts among AGVs moving in the same direction. Finally, we verify the effectiveness of our method in terms of real-time and optimal performance through simulation experiments.},
  archive      = {J_RAS},
  author       = {Ke Wang and Wei Liang and Huaguang Shi and Jialin Zhang and Qi Wang},
  doi          = {10.1016/j.robot.2023.104505},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104505},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Driving line-based two-stage path planning in the AGV sorting system},
  volume       = {169},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RGB-d-based categorical object pose and shape estimation:
Methods, datasets, and evaluation. <em>RAS</em>, <em>168</em>, 104507.
(<a href="https://doi.org/10.1016/j.robot.2023.104507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, various methods for 6D pose and shape estimation of objects at a per-category level have been proposed. This work provides an overview of the field in terms of methods, datasets, and evaluation protocols. First, an overview of existing works and their commonalities and differences is provided. Second, we take a critical look at the predominant evaluation protocol, including metrics and datasets. Based on the findings, we propose a new set of metrics, contribute new annotations for the Redwood dataset, and evaluate state-of-the-art methods in a fair comparison. The results indicate that existing methods do not generalize well to unconstrained orientations and are actually heavily biased towards objects being upright. We provide an easy-to-use evaluation toolbox with well-defined metrics, methods, and dataset interfaces, which allows evaluation and comparison with various state-of-the-art approaches ( https://github.com/roym899/pose_and_shape_evaluation ).},
  archive      = {J_RAS},
  author       = {Leonard Bruns and Patric Jensfelt},
  doi          = {10.1016/j.robot.2023.104507},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104507},
  shortjournal = {Robot. Auton. Syst.},
  title        = {RGB-D-based categorical object pose and shape estimation: Methods, datasets, and evaluation},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-locomotion clustered tensegrity mobile robot with
fewer actuators. <em>RAS</em>, <em>168</em>, 104504. (<a
href="https://doi.org/10.1016/j.robot.2023.104504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots with multi locomotion modes have excellent terrain adaptability. However, traditional multi-locomotion mobile robots are usually actuated by a large number of motors, making their structures heavy and bulky. As a result, the controls become complex, the load-to-mass ratio is low, and the energy consumption is high. Inspired by the bio-mechanism of worms, a novel tensegrity-based multi-locomotion mobile robot, named TJUBot, has been designed. It is actuated by only two motors, yet it has the potential to realize three locomotion modes: earthworm-like, inchworm-like, and tumbling locomotion. The design of these three locomotion modes has been implemented based on kinematic and dynamic models, and the driving law of the two motors under each locomotion mode has been established. Notably, the robot’s locomotion has been analyzed under five different terrains. A laboratory prototype of TJUBot has been developed, and experiments demonstrate that the robot can adjust to five types of terrains using the three locomotion modes. For instance, on flat ground, it achieves a maximum velocity of 2.34 BL/min, and it can pass through confined spaces with a minimum height of 1.26 BH. Moreover, the robot can climb slopes with a maximum angle of 7°, overcome obstacles with a maximum height of 0.52 BH, and traverse gaps with a maximum width as 0.35 BL. Herein, BL and BH represent the body length and body height of the robot, respectively. In addition, TJUBot exhibits outstanding performance in terms of its load-to-mass ratio, which is measured at 5.56, and its low energy consumption of 0.69J/m, as observed in experiments. The promising results obtained from these experiments indicate that TJUBot holds significant potential for applications in multi-terrain environments.},
  archive      = {J_RAS},
  author       = {Qi Yang and Xinyu Liu and Panfeng Wang and Yimin Song and Tao Sun},
  doi          = {10.1016/j.robot.2023.104504},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104504},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A multi-locomotion clustered tensegrity mobile robot with fewer actuators},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LSVL: Large-scale season-invariant visual localization for
UAVs. <em>RAS</em>, <em>168</em>, 104497. (<a
href="https://doi.org/10.1016/j.robot.2023.104497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization of autonomous unmanned aerial vehicles (UAVs) relies heavily on Global Navigation Satellite Systems (GNSS), which are susceptible to interference. Especially in security applications, robust localization algorithms independent of GNSS are needed to provide dependable operations of autonomous UAVs also in interfered conditions. Typical non-GNSS visual localization approaches rely on known starting pose, work only on a small-sized map, or require known flight paths before a mission starts. We consider the problem of localization with no information on initial pose or planned flight path. We propose a solution for global visual localization on large maps, based on matching orthoprojected UAV images to satellite imagery using learned season-invariant descriptors, and test with environment sizes up to 100 km 2 2 . We show that the method is able to determine heading, latitude and longitude of the UAV at 12.6–18.7 m lateral translation error in as few as 23.2–44.4 updates from an uninformed initialization, also in situations of significant seasonal appearance difference (winter–summer) between the UAV image and the map. We evaluate the characteristics of multiple neural network architectures for generating the descriptors, and likelihood estimation methods that are able to provide fast convergence and low localization error . We also evaluate the operation of the algorithm using real UAV data and evaluate running time on a real-time embedded platform. We believe this is the first work that is able to recover the pose of an UAV at this scale and rate of convergence , while allowing significant seasonal difference between camera observations and map.},
  archive      = {J_RAS},
  author       = {Jouko Kinnari and Riccardo Renzulli and Francesco Verdoja and Ville Kyrki},
  doi          = {10.1016/j.robot.2023.104497},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104497},
  shortjournal = {Robot. Auton. Syst.},
  title        = {LSVL: Large-scale season-invariant visual localization for UAVs},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feedback control of millimeter scale pivot walkers using
magnetic actuation. <em>RAS</em>, <em>168</em>, 104496. (<a
href="https://doi.org/10.1016/j.robot.2023.104496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An external magnetic field can be used to remotely control small-scaled robots, making them promising candidates for diverse biomedical and engineering applications. In a previous study, we showed that our magnetically actuated millirobot is highly agile and can perform a variety of locomotive tasks such as pivot walking, tumbling, and tapping in a horizontal plane. In this study, we focus on controlling the locomotion outcomes of this millirobot in the pivot walking mode. A mathematical model of the system is developed and the kinematic model is derived. The role of the sweep and tilt angles in the robot’s motion is also investigated. We study two controllers to regulate the gait of the pivot walker. The first one is a proportional-geometric-based controller, which determines the correct pivot point that the millirobot should use. Then, it regulates the angular velocity proportionally based on the error between the center of the millirobot and the reference trajectory . The second controller is based on a gradient descent optimization technique, which expresses the control action as an optimization problem . These control algorithms enable the millirobot to generate a stable gait while tracking the desired trajectory . A low-cost high-performance magnetic actuator is built to validate the proposed controllers. We conduct a set of different experiments and simulation runs to establish the effectiveness of proposed controllers for different sweep and tilt angles in terms of tracking error. The two controllers exhibit an appropriate performance, but it is observed that the gradient descent-based controller yields faster convergence time, smaller tracking error, and fewer number of steps. Finally, we perform an extensive experimentally parametric analysis of the effect of sweep and tilt angles and step time on the tracking error. As we expect, the optimization-based controller outperforms the geometric-based one.},
  archive      = {J_RAS},
  author       = {Ehab Al Khatib and Pouria Razzaghi and Yildirim Hurmuzlu},
  doi          = {10.1016/j.robot.2023.104496},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104496},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Feedback control of millimeter scale pivot walkers using magnetic actuation},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Humanoid motion generation in a world of stairs.
<em>RAS</em>, <em>168</em>, 104495. (<a
href="https://doi.org/10.1016/j.robot.2023.104495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the problem of generating humanoid motions in an environment consisting of horizontal patches located at different heights ( world of stairs ). To this end, the paper proposes an integrated scheme which combines footstep planning and gait generation. In particular, footsteps are produced by a randomized algorithm that guarantees both feasibility and quality of the plan according to a chosen criterion; whereas for 3D gait generation we devise an ad hoc extension of the Intrinsically Stable MPC scheme. In its basic form, the proposed scheme addresses the off-line case (known environments), but a sensor-based adaptation is developed for the on-line case (unknown environments) based on an anytime version of the footstep planner. In order to validate the proposed approach, we present simulations in CoppeliaSim for the HRP-4 humanoid robot navigating scenarios of different complexity, both in the on-line and off-line case.},
  archive      = {J_RAS},
  author       = {Michele Cipriano and Paolo Ferrari and Nicola Scianca and Leonardo Lanari and Giuseppe Oriolo},
  doi          = {10.1016/j.robot.2023.104495},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104495},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Humanoid motion generation in a world of stairs},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traversability analysis for off-road environments using
locomotion experiments and earth observation data. <em>RAS</em>,
<em>168</em>, 104494. (<a
href="https://doi.org/10.1016/j.robot.2023.104494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the navigation capabilities of mobile robots in off-road environments have increased significantly, opening up new potential applications in a variety of settings. By accurately identifying different types of terrain in unstructured environments, safe automated navigation can be supported. However, to enable safe path planning and execution, the traversability costs of the terrain types need to be accurately estimated. Such estimations are often performed manually by experts who possess information about the environment and are familiar with the capabilities of the robotic system or using simplified experiments. In this paper, we present an automated pipeline for generating traversability costs that use recorded locomotion data from a realistic experiment and descriptive information on the terrain obtained from earth observation data. The main contribution is that the cost estimation for different terrain types is based on locomotion data obtained in realistic standardized experiments. Moreover, by repeating the experiments with different robot systems we are easily able to reflect the actual capabilities of the systems. Experiments were conducted in an alpine off-road environment to record locomotion data of four different robot systems and to investigate the performance and validity of the proposed pipeline. The recorded locomotion data for the different robots are publicly available at https://robonav.ist.tugraz.at/data/},
  archive      = {J_RAS},
  author       = {Matthias Eder and Raphael Prinz and Florian Schöggl and Gerald Steinbauer-Wagner},
  doi          = {10.1016/j.robot.2023.104494},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104494},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Traversability analysis for off-road environments using locomotion experiments and earth observation data},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From the desks of ROS maintainers: A survey of modern &amp;
capable mobile robotics algorithms in the robot operating system 2.
<em>RAS</em>, <em>168</em>, 104493. (<a
href="https://doi.org/10.1016/j.robot.2023.104493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Robot Operating System 2 (ROS 2) is rapidly impacting the intelligent machines sector — on space missions, large agriculture equipment, multi-robot fleets, and more. Its success derives from its focused design and improved capabilities targeting product-grade and modern robotic systems . Following ROS 2’s example, the mobile robotics ecosystem has been fully redesigned based on the transformed needs of modern robots and is experiencing active development not seen since its inception. This paper comes from the desks of the key ROS Navigation maintainers to review and analyze the state of the art of robotics navigation in ROS 2. This includes new systems without parallel in ROS 1 or other similar mobile robotics frameworks. We discuss current research products and historically robust methods that provide differing behaviors and support for most every robot type. This survey consists of overviews, comparisons, and expert insights organized by the fundamental problems in the field. Some of these implementations have yet to be described in literature and many have not been benchmarked relative to others. We end by providing a glimpse into the future of the ROS 2 mobile robotics ecosystem.},
  archive      = {J_RAS},
  author       = {Steve Macenski and Tom Moore and David V. Lu and Alexey Merzlyakov and Michael Ferguson},
  doi          = {10.1016/j.robot.2023.104493},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104493},
  shortjournal = {Robot. Auton. Syst.},
  title        = {From the desks of ROS maintainers: A survey of modern &amp; capable mobile robotics algorithms in the robot operating system 2},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization techniques for multi-robot task allocation
problems: Review on the state-of-the-art. <em>RAS</em>, <em>168</em>,
104492. (<a href="https://doi.org/10.1016/j.robot.2023.104492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last years, Multi-Robot Systems (MRS) have experienced considerable recognition due to various possible real-world applications. Multi-Robot Task Allocation (MRTA) is among the most interesting MRS problems. This problem concerns the situation when a set of given tasks must be performed by a team of mobile robots with the intention of optimizing an objective function (e.g., minimizing the mission time). This paper aims to present MRTA applications and categorizes methods into market-based, behavior-based, and optimization-based approaches. The paper focus on the latter and review several works in order to point out their advantages and limitations and to identify possible future research opportunities. Furthermore, a statistical analysis is provided to identify the most used methods and the evolution of the topic over the years.},
  archive      = {J_RAS},
  author       = {Hamza Chakraa and François Guérin and Edouard Leclercq and Dimitri Lefebvre},
  doi          = {10.1016/j.robot.2023.104492},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104492},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Optimization techniques for multi-robot task allocation problems: Review on the state-of-the-art},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). YOLOPose v2: Understanding and improving transformer-based
6D pose estimation. <em>RAS</em>, <em>168</em>, 104490. (<a
href="https://doi.org/10.1016/j.robot.2023.104490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {6D object pose estimation is a crucial prerequisite for autonomous robot manipulation applications. The state-of-the-art models for pose estimation are convolutional neural network (CNN)-based. Lately, Transformers, an architecture originally proposed for natural language processing , is achieving state-of-the-art results in many computer vision tasks as well. Equipped with the multi-head self-attention mechanism, Transformers enable simple single-stage end-to-end architectures for learning object detection and 6D object pose estimation jointly. In this work, we propose YOLOPose (short form for You Only Look Once Pose estimation), a Transformer-based multi-object 6D pose estimation method based on keypoint regression and an improved variant of the YOLOPose model. In contrast to the standard heatmaps for predicting keypoints in an image, we directly regress the keypoints. Additionally, we employ a learnable orientation estimation module to predict the orientation from the keypoints. Along with a separate translation estimation module, our model is end-to-end differentiable. Our method is suitable for real-time applications and achieves results comparable to state-of-the-art methods. We analyze the role of object queries in our architecture and reveal that the object queries specialize in detecting objects in specific image regions. Furthermore, we quantify the accuracy trade-off of using datasets of smaller sizes to train our model.},
  archive      = {J_RAS},
  author       = {Arul Selvam Periyasamy and Arash Amini and Vladimir Tsaturyan and Sven Behnke},
  doi          = {10.1016/j.robot.2023.104490},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104490},
  shortjournal = {Robot. Auton. Syst.},
  title        = {YOLOPose v2: Understanding and improving transformer-based 6D pose estimation},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic motion planning for non-euclidean and
multi-vehicle problems. <em>RAS</em>, <em>168</em>, 104487. (<a
href="https://doi.org/10.1016/j.robot.2023.104487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory planning tasks for non-holonomic or collaborative systems are naturally modeled by state spaces with non-Euclidean metrics. However, existing proofs of convergence for sample-based motion planners only consider the setting of Euclidean state spaces. We resolve this issue by formulating a flexible framework and set of assumptions for which the widely-used PRM*, RRT, and RRT* algorithms remain asymptotically optimal in the non-Euclidean setting. The framework is compatible with collaborative trajectory planning: given a fleet of robotic systems that individually satisfy our assumptions, we show that the corresponding collaborative system again satisfies the assumptions and therefore has guaranteed convergence for the trajectory-finding methods. Our joint state space construction builds in a coupling parameter 1 ≤ p ≤ ∞ 1≤p≤∞ , which interpolates between a preference for minimizing total energy at one extreme and a preference for minimizing the travel time at the opposite extreme. We illustrate our theory with trajectory planning for simple coupled systems, fleets of Reeds–Shepp vehicles, and a highly non-Euclidean fractal space.},
  archive      = {J_RAS},
  author       = {Anton Lukyanenko and Damoon Soudbakhsh},
  doi          = {10.1016/j.robot.2023.104487},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104487},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Probabilistic motion planning for non-euclidean and multi-vehicle problems},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards one shot &amp; pick all: 3D-OAS, an end-to-end
framework for vision guided top-down parcel bin-picking using
3D-overlapping-aware instance segmentation and GNN. <em>RAS</em>,
<em>167</em>, 104491. (<a
href="https://doi.org/10.1016/j.robot.2023.104491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic Grasping and sorting is acknowledged as the most fundamental and significant manipulation task in industry. An ultimate goal of a Vision guided Robotic grasping system is to precisely and efficiently sort maximum objects with minimum inference time of vision system. So far, applicable end-to-end perception and autonomously picking of hierarchically stacked objects has not been intensively reported in previous works. Especially, in the scenario of top-down parcel bin-picking where robots are required to perceive and pick up parcels from random stacks. In this work, we focus on this challenging task by putting forward a novel end-to-end parcel bin-picking model termed 3D-OAS. Our proposal combines a 3D overlapping-aware instance segmentation and directed graph to describe the hierarchical structure of stacked objects from a top-down angle and a graph-neural-network is introduced to solve the optimal sorting orders. The experiment was conducted via a set of Vision guided Delta-Parallel robotic grasping system with a top-down RGB-D camera. Experimental Results proved the feasibility of our proposal, it could hierarchically segment stacked objects and solve sorting sequence with minimum one shot.},
  archive      = {J_RAS},
  author       = {Yi Zhao and Jiacheng Yang and Shaocong Wang and Xiaohui Li},
  doi          = {10.1016/j.robot.2023.104491},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104491},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Towards one shot &amp; pick all: 3D-OAS, an end-to-end framework for vision guided top-down parcel bin-picking using 3D-overlapping-aware instance segmentation and GNN},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep multi-agent reinforcement learning framework for
autonomous aerial navigation to grasping points on loads. <em>RAS</em>,
<em>167</em>, 104489. (<a
href="https://doi.org/10.1016/j.robot.2023.104489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning, by taking advantage of neural networks, has made great strides in the continuous control of robots. However, in scenarios where multiple robots are required to collaborate with each other to accomplish a task, it is still challenging to build an efficient and scalable multi-agent control system due to increasing complexity. In this paper, we regard each unmanned aerial vehicle (UAV) with its manipulator as one agent, and leverage the power of multi-agent deep deterministic policy gradient (MADDPG) for the cooperative navigation and manipulation of a load. We propose solutions for addressing navigation to grasping point problem in targeted and flexible scenarios, and mainly focus on how to develop model-free policies for the UAVs without relying on a trajectory planner. To overcome the challenges of learning in scenarios with an increasing number of grasping points, we incorporate the demonstrations from an Optimal Reciprocal Collision Avoidance (ORCA) algorithm into our framework to guide the policy training and adapt two novel techniques into the architecture of MADDPG. Furthermore, curriculum learning with the attention mechanism is utilized by reusing knowledge from fewer grasping points to facilitate the training of a load with more points. Our experiments were validated by a load with three, four and six grasping points respectively in Coppeliasim simulator and then transferred into the real world with Crazyflie quadrotors. Our results show that the average tracking deviations from the desirable grasping point to the final position of the UAV can be less than 10 cm in some real-world experiments. Compared with state-of-the-art model-free reinforcement learning and swarm optimization algorithms, results show that our proposed methods outperform other baselines with a reasonable success rate especially in the scenarios with more grasping points. Furthermore, the learned optimal policies enable UAVs to reach and hover over all the grasping points before manipulation without any collision. We conducted a comprehensive analysis of both targeted and flexible navigation, highlighting their respective advantages and disadvantages.},
  archive      = {J_RAS},
  author       = {Jingyu Chen and Ruidong Ma and John Oyekan},
  doi          = {10.1016/j.robot.2023.104489},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104489},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A deep multi-agent reinforcement learning framework for autonomous aerial navigation to grasping points on loads},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model checking embedded adaptive cruise controllers.
<em>RAS</em>, <em>167</em>, 104488. (<a
href="https://doi.org/10.1016/j.robot.2023.104488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While checking functional correctness for automated driving is often achieved through vast amounts of automated and manual field testing, automating specification verification is essential for developing and releasing fully self-driving vehicles. This paper presents an automatic bounded model checking approach for functional specifications over longitudinal vehicle controller implementations. The proposed method checks the actual embedded program, rather than an extracted abstract model. The specification is converted into a monitor that is interleaved with the execution of the program over a finite time horizon in closed-loop simulation. A decomposition is proposed to tackle the verification complexity. This allows verifying the program for whole parameter sets using a software model checker as opposed to testing only individual samples. The approach is capable of identifying functional flaws in several exemplary longitudinal controllers with variable complexity.},
  archive      = {J_RAS},
  author       = {Vladislav Nenchev},
  doi          = {10.1016/j.robot.2023.104488},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104488},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Model checking embedded adaptive cruise controllers},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed safe formation maneuver control of
euler–lagrange multi-agent systems in a partially unknown environment by
safe reinforcement learning. <em>RAS</em>, <em>167</em>, 104486. (<a
href="https://doi.org/10.1016/j.robot.2023.104486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a multi-layer approach to the problem of safe formation control . The agents’ and the leader’s dynamics are considered unknown Euler–Lagrange (E-L) systems. In addition, the environment is partially unknown. We propose a novel layered approach to reach the predefined target while preserving a designed, safe, optimal formation pattern along a planned optimal path. By satisfying the safety constraints, safe reinforcement learning (RL) is introduced to ensure the leader reaches the desired destination without collision. Maintaining a constant formation pattern is unsafe for followers since they are not familiar with the surroundings. Thus, we define the formation maneuver control problem, which can adjust formation geomatical patterns dynamically depending on the environment. A proposed algorithm based on the leader’s designed path is defined to solve the problem. Using off-policy RL, the model-free distributed control law is presented to generate a designed formation pattern in a determined optimal path. Finally, we demonstrate that the proposed approach can be applied to the safe formation maneuver problem in an environment with convex obstacles. This paper presents a safe formation control strategy that addresses practical issues, such as model uncertainty, without requiring sensor measurements in an unknown, static environment without uncertainty. Simulation demonstrates the effectiveness of the suggested approaches for a group of Uncrewed Surface Vehicles (USVs).},
  archive      = {J_RAS},
  author       = {Fatemeh Mahdavi Golmisheh and Saeed Shamaghdari},
  doi          = {10.1016/j.robot.2023.104486},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104486},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Distributed safe formation maneuver control of Euler–Lagrange multi-agent systems in a partially unknown environment by safe reinforcement learning},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Map point selection for visual SLAM. <em>RAS</em>,
<em>167</em>, 104485. (<a
href="https://doi.org/10.1016/j.robot.2023.104485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous localisation and mapping (SLAM) play a vital role in autonomous robotics. Robotic platforms are often resource-constrained, and this limitation motivates resource-efficient SLAM implementations. While sparse visual SLAM algorithms offer good accuracy for modest hardware requirements, even these more scalable sparse approaches face limitations when applied to large-scale and long-term scenarios. A contributing factor is that the point clouds resulting from SLAM are inefficient to use and contain significant redundancy. This paper proposes the use of subset selection algorithms to reduce the map produced by sparse visual SLAM algorithms. Information-theoretic techniques have been applied to simpler related problems before, but they do not scale if applied to the full visual SLAM problem. This paper proposes a number of novel information-theoretic utility functions for map point selection and optimises these functions using greedy algorithms . The reduced maps are evaluated using practical data alongside an existing visual SLAM implementation (ORB-SLAM 2). Approximate selection techniques proposed in this paper achieve trajectory accuracy comparable to an offline baseline while being suitable for online use. These techniques enable the practical reduction of maps for visual SLAM with competitive trajectory accuracy. Results also demonstrate that SLAM front-end performance can significantly impact the performance of map point selection. This shows the importance of testing map point selection with a front-end implementation. To exploit this, this paper proposes an approach that includes a model of the front-end in the utility function when additional information is available. This approach outperforms alternatives on applicable datasets and highlights future research directions.},
  archive      = {J_RAS},
  author       = {Christiaan J. Müller and Corné E. van Daalen},
  doi          = {10.1016/j.robot.2023.104485},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104485},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Map point selection for visual SLAM},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast and accurate compound collision detector for RRT
motion planning. <em>RAS</em>, <em>167</em>, 104484. (<a
href="https://doi.org/10.1016/j.robot.2023.104484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of artificial intelligence tools has led to newly developed collision detectors which have better computational efficiency than the kinematics-and-geometry based collision detectors (KCD) to improve robot motion planning strategies. However, new detectors are not very accurate in some cases. To improve the accuracy, a trade-off between efficiency and accuracy is required. We propose a novel compound collision detector (CCD) for collision queries that modifies the planners of rapidly-exploring random tree (RRT) to improve the classical probabilistic collision detector (PCD). It is composed of an exact collision detector (ECD), an inference collision detector (ICD) and a strategy to determine ECD or ICD based on some conditions. In our CCD, we use a sphere-ellipsoidal pseudo distance (SEPD) in the determination strategy to alleviate the problem of highly-frequent outputs of false-positive in narrow passages of PCD, and a node based bounding method (NBB) to increase the speed of data storage and loading for the sub-algorithm ICD. Experiments on a Kinova Jaco assistive robotic arm are taken to evaluate the performance of our CCD, which show an improved accuracy with a small reduction of speed in comparison with PCD. So, it is a promising tool in robot motion planning.},
  archive      = {J_RAS},
  author       = {Shangliang Wu and Guangyu Liu and Yanxin Zhang and Anke Xue},
  doi          = {10.1016/j.robot.2023.104484},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104484},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A fast and accurate compound collision detector for RRT motion planning},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Near-optimal 3D trajectory design in presence of obstacles:
A convolutional neural network approach. <em>RAS</em>, <em>167</em>,
104483. (<a href="https://doi.org/10.1016/j.robot.2023.104483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an approach based on neural networks for designing near-optimal 3D trajectories connecting two points separated by obstacles. A reference path is first built with a novel Theta* algorithm implementation, upgraded to reduce the number of waypoints and the angular variations. Starting from the path, a trajectory based on piecewise Bézier curves is designed with an algorithm relying on two design parameters. The optimal value of these parameters is estimated with a Convolutional Neural Network (CNN) architecture receiving as inputs an image of the path and its properties. The CNN training is performed on a synthetic dataset of optimal parameters built with Differential Evolution optimization for a variety of randomly generated paths. The parameters from CNN are refined with an algorithm capable of providing with high success rate near-optimal trajectories within minimum computation time.},
  archive      = {J_RAS},
  author       = {Daniele Sartori and Danping Zou and Ling Pei and Wenxian Yu},
  doi          = {10.1016/j.robot.2023.104483},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104483},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Near-optimal 3D trajectory design in presence of obstacles: A convolutional neural network approach},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autonomous cooperative wall building by a team of unmanned
aerial vehicles in the MBZIRC 2020 competition. <em>RAS</em>,
<em>167</em>, 104482. (<a
href="https://doi.org/10.1016/j.robot.2023.104482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a system for autonomous cooperative wall building with a team of Unmanned Aerial Vehicles (UAVs). The system was developed for Challenge 2 of the Mohamed Bin Zayed International Robotics Challenge (MBZIRC) 2020. The wall-building scenario of Challenge 2 featured an initial stack of bricks and wall structure where the individual bricks had to be placed by a team of three UAVs. The objective of the task was to maximize collected points for placing the bricks within the restricted construction time while following the prescribed wall pattern. The proposed approach uses initial scanning to find a priori unknown locations of the bricks and the wall structure. Each UAV is then assigned to individual bricks and wall placing locations and further performs grasping and placement using onboard resources only. The developed system consists of methods for scanning a given area, RGB-D detection of bricks and wall placement locations, precise grasping and placing of bricks, and coordination of multiple UAVs. The paper describes the overall system, individual components, experimental verification in demanding outdoor conditions, the achieved results in the competition, and lessons learned. The presented CTU-UPenn-NYU approach achieved the overall best performance among all participants to win the MBZIRC competition by collecting the highest number of points by correct placement of a high number of bricks.},
  archive      = {J_RAS},
  author       = {Tomas Baca and Robert Penicka and Petr Stepan and Matej Petrlik and Vojtech Spurny and Daniel Hert and Martin Saska},
  doi          = {10.1016/j.robot.2023.104482},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104482},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Autonomous cooperative wall building by a team of unmanned aerial vehicles in the MBZIRC 2020 competition},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bimanual dynamic grabbing and tossing of objects onto a
moving target. <em>RAS</em>, <em>167</em>, 104481. (<a
href="https://doi.org/10.1016/j.robot.2023.104481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bimanual grabbing and tossing of packages onto trays or conveyor belts remains a human activity in the industry. For robots, such a dynamic task requires coordination between two arms and fast adaptation abilities when the tossing target is moving and subject to perturbations. Thus, this paper proposes a control framework that enables a bimanual robotic system to grab and toss objects onto a moving target. We develop a mixed learning-optimization method that computes the tossing parameters necessary to achieve accurate tossing tasks. Hence, we learn an inverse throwing map (a closed-form solution of the inverse non-linear throwing problem) that provides minimum release velocities of the object for given relative release positions. This map is embedded into a kinematics-based bi-level optimization that determines the associated feasible release states (positions and velocities) of the dual-arm robot. Additionally, we propose a closed-form modeling approach of the robot’s tossable workspace (set of all positions reachable by an object if tossed by the robot) and use the model to predict intercept or landing locations that yield high probabilities of task success. Furthermore, we employ dynamical systems to generate the coordinated motion of the dual-arm system and design an adaptation strategy to ensure robustness of the interception in the face of target’s perturbations in speed or location. Finally, we validate experimentally the framework on two 7-DoF robotic arms . We demonstrate the accuracy and robustness of the proposed approach. We also show its speed and energy advantages when compared to the traditional pick-and-place strategy.},
  archive      = {J_RAS},
  author       = {Michael Bombile and Aude Billard},
  doi          = {10.1016/j.robot.2023.104481},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104481},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Bimanual dynamic grabbing and tossing of objects onto a moving target},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent planning and coordination for automated aircraft
ground handling. <em>RAS</em>, <em>167</em>, 104480. (<a
href="https://doi.org/10.1016/j.robot.2023.104480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the vision of fully autonomous airside operations at Schiphol airport , this study aims to contribute to the short-term goal of automated aircraft ground handling. In this research, we design and evaluate a multi-agent system for planning of automated ground handling. There are two main components in the system: task allocation optimization and multi-agent path planning . To allocate tasks to ground support equipment (GSE) vehicles, an auction mechanism inspired by temporal sequential single item (TeSSI) auction is proposed. Ground handling tasks scheduling for GSE vehicles is modeled as several single-vehicle pickup and delivery optimization problems (SPDP), and the values of the objective functions are used to generate bids for GSE vehicle agents in the auction. Prioritized safe interval path planning for large agents (LA-SIPP) is used to plan collision-free paths for GSE vehicle agents in the model to execute tasks. The aim is to increase the success rates of allocating tasks and finding collision free paths without causing flight delays, given the limited resources such as a small number of available GSE vehicles, time windows constraints and conflicting interests of different agents. Due to the results, even for the instances with frequent flights and the most limited resources, the success rates of allocation and path planning were higher than 81\% and 98\%, respectively. Furthermore, periodic task allocation and path planning of the ground handling tasks for flights in three aircraft stands during a planning time window of the day, as well as replanning in case of disruptions were performed in a short CPU time. There is a lack of research dealing with the complete process of ground handling, since existing studies concerning the automation of ground handling operations involve fleet assignment or task scheduling models without an integration of detailed path planning. Our main contribution is to present a framework that combines task allocation and path planning for automation of ground handling operations and provides solutions using a multi-agent perspective.},
  archive      = {J_RAS},
  author       = {Szu-Tung Chen and Gülçin Ermiş and Alexei Sharpanskykh},
  doi          = {10.1016/j.robot.2023.104480},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104480},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multi-agent planning and coordination for automated aircraft ground handling},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fuzzy logic-based stabilization system for a flying robot,
with an embedded energy harvester and a visual decision-making system.
<em>RAS</em>, <em>167</em>, 104471. (<a
href="https://doi.org/10.1016/j.robot.2023.104471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Smart cities” is a popular concept in modern urban development that demands innovative solutions to enhance various aspects of our lives. This paper introduces a novel application that aims to improve public road maintenance by utilizing a flying robot to repaint partially erased sections of the sidewalks’ edges that are typically marked with black and white colors. The first contribution of this paper is the development of a fuzzy-logic-based stabilization system for an octocopter, which can serve as a liquids transporter and be equipped with a robot arm. The second contribution is the design of an embedded energy harvester for the flying robot, which optimizes the management of available power sources. Additionally, this project includes a complementary heuristic study that clarifies fundamental concepts related to a computer vision-based decision-making system.},
  archive      = {J_RAS},
  author       = {Abdullatif Baba and Basil Alothman},
  doi          = {10.1016/j.robot.2023.104471},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104471},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A fuzzy logic-based stabilization system for a flying robot, with an embedded energy harvester and a visual decision-making system},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling variability in self-adapting robotic systems.
<em>RAS</em>, <em>167</em>, 104470. (<a
href="https://doi.org/10.1016/j.robot.2023.104470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robots operating in everyday environments, such as hospitals, private houses, and public roads, are context-aware self-adaptive systems, i.e. they exploit knowledge about their resources and the environment to trigger runtime adaptation, so that they exhibit a behavior adequate to the current context. For these systems, context-aware self-adaptation requires to design the robot control application as a dynamically reconfigurable software architecture and to specify the adaptation logic for reconfiguring its variable aspects (e.g. the modules that implement various obstacle detection algorithms or control different distance sensors) according to specific criteria (e.g. enhancing robustness against variable illumination conditions). Despite self-adaptation is an intrinsic capability of autonomous robots, ad-hoc approaches are used in practice to design reconfigurable robot architectures. In order to enhance system maintainability , the control logic and the adaptation logic should be loosely coupled. For this purpose, the adaptation logic should be defined against an explicit representation of software variability in the robot control architecture. In this paper we propose a modeling approach, which consists in explicitly representing robot software variability with the MARTE ::ARM-Variability metamodel, which has been designed as an extension of the UML MARTE profile. We evaluate the applicability of the proposed approach by exemplifying the software architecture design of a robot navigation framework and by analyzing the support provided by the ROS infrastructure for runtime reconfiguration of its variable aspects.},
  archive      = {J_RAS},
  author       = {Davide Brugali},
  doi          = {10.1016/j.robot.2023.104470},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104470},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Modeling variability in self-adapting robotic systems},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online learning of MPC for autonomous racing. <em>RAS</em>,
<em>167</em>, 104469. (<a
href="https://doi.org/10.1016/j.robot.2023.104469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Learning-based Model Predictive Control (LMPC) algorithm is proposed for a Formula Student (FS) autonomous vehicle. The online learning algorithm has two distinct roles: to improve the dynamic model accuracy of the vehicle used in the MPC, while performing online tuning of the model predictive controller parameters . The developed controller is shown to reduce the total lap time through an iterative learning process as the vehicle progresses on track. To capture the full complexity of the nonlinear higher order dynamics, an Artificial Neural Network (ANN) complements the vehicle’s nominal model. The ANN is trained using an online supervised learning scheme based on past model prediction errors. Additionally, a Genetic Algorithm (GA) is used to iteratively find the optimal set of controller parameters that maximizes a reward function. Several simulation tests performed on real examples of competition tracks demonstrate the effectiveness of the approach. Moreover, it is shown that the combination of both online learning methods is able to significantly improve tracking performance of the FS vehicle, eventually reducing the total lap time by over 16\%.},
  archive      = {J_RAS},
  author       = {Gabriel Costa and João Pinho and Miguel Ayala Botto and Pedro U. Lima},
  doi          = {10.1016/j.robot.2023.104469},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104469},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Online learning of MPC for autonomous racing},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive legged manipulation: Versatile disturbance
predictive control for quadruped robots with robotic arms. <em>RAS</em>,
<em>167</em>, 104468. (<a
href="https://doi.org/10.1016/j.robot.2023.104468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equipping a legged robot with a manipulator enables versatile mobile manipulation, significantly improving its performance in various tasks. However, developing a unified framework for diverse robotic arms and legged robots presents a challenge. This study proposes a disturbance predictive control framework where a high-level estimator cooperates with a disturbance-based low-level controller. Further, a transportable latent dynamic adapter is introduced to enable the model to migrate rapidly to different robotic arms . Our method can adapt well to other manipulators with a few samples. Further, the effectiveness of our method was demonstrated via simulation and real experiments.},
  archive      = {J_RAS},
  author       = {Qingfeng Yao and Cong Wang and Jilong Wang and Linghan Meng and Shuyu Yang and Qifeng Zhang and Donglin Wang},
  doi          = {10.1016/j.robot.2023.104468},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104468},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Adaptive legged manipulation: Versatile disturbance predictive control for quadruped robots with robotic arms},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward best practices in embedded ethics: Suggestions for
interdisciplinary technology development. <em>RAS</em>, <em>167</em>,
104467. (<a href="https://doi.org/10.1016/j.robot.2023.104467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With current developments in robotics and artificial intelligence (AI) comes an increased focus on the ethical production and use of such novel technologies. Accordingly, a trend toward “embedded ethics” is seen in recent research, reflecting an increase in efforts to integrate social and ethical considerations in computer science education and early in the development phases of AI and robotics. What remains to be established, however, is a more concrete understanding of the best working modalities for such interdisciplinary collaborations. In this brief discussion paper, we provide reflections derived from our interdisciplinary Responsible Robotics project which integrates ethicists and social scientists at early stages of development. We put forward several suggestions on how to integrate ethics and social science within technological development. We believe these suggestions can serve as a working taxonomy of best practices for embedded ethics.},
  archive      = {J_RAS},
  author       = {Daniel W. Tigard and Maximilian Braun and Svenja Breuer and Konstantin Ritt and Amelia Fiske and Stuart McLennan and Alena Buyx},
  doi          = {10.1016/j.robot.2023.104467},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104467},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Toward best practices in embedded ethics: Suggestions for interdisciplinary technology development},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robot learning from human demonstrations with inconsistent
contexts. <em>RAS</em>, <em>166</em>, 104466. (<a
href="https://doi.org/10.1016/j.robot.2023.104466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual imitation learning is a promising approach that promotes robots to learn skills from visual demonstrations. However, current visual imitation learning approaches introduce unreasonable assumptions that the contexts of the visual demonstrations and the robot observations are consistent, which affects the flexibility and scalability of the approaches. It is a key challenge for robots to learn from visual demonstrations with inconsistent contexts. Inconsistent contexts may cause a serious difference in the pixel distribution of the operator and the environment, which makes vision-based control policies hardly effective. In this paper, we propose a novel imitation learning framework to enable robots to reproduce behavior by watching human demonstrations with inconsistent contexts, such as different viewpoints, operators, backgrounds, object appearances and positions. Specifically, our framework consists of three networks: flow-based viewpoint transformation network (FVTrans), robot2human alignment network (RANet) and inverse dynamics network (IDNet). First, FVTrans transforms various third-person demonstrations into the fixed robot execution view. With a meta learning strategy, FVTrans can quickly adapt to novel contexts with few samples. Then, RANet aligns the human and the robot at the feature level. Therefore, the demonstration feature can be used as a subgoal of the current moment. Finally, IDNet predicts the joint angles of the robot. We collect a multi-context dataset on the real robot (UR5) for three tasks, including grasping cups, sweeping garbage and placing objects. We empirically demonstrate that our framework can perform three tasks with a high success rate and be effectively generalized to different contexts.},
  archive      = {J_RAS},
  author       = {Zhifeng Qian and Mingyu You and Hongjun Zhou and Xuanhui Xu and Bin He},
  doi          = {10.1016/j.robot.2023.104466},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104466},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robot learning from human demonstrations with inconsistent contexts},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultrasound-guide prostate biopsy robot and calibration based
on dynamic kinematic error model with POE formula. <em>RAS</em>,
<em>166</em>, 104465. (<a
href="https://doi.org/10.1016/j.robot.2023.104465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the transrectal ultrasound-guided transperineal prostate biopsy, the application of robots can effectively reduce the interference of low-quality ultrasound images on the physician to determine the biopsy route and improve the positive detection rate. In this paper, an 8-degree-of-freedom (DOF) prostate biopsy robot for clinical is developed to realize the operation of ultrasonic probe scanning, the inserting point and target lesion point positioning, and the needle insertion. Considering the dynamic errors caused by different motions of robot joints , a dynamic product-of-exponentials (POE) based kinematic model that can reflect non-geometric errors is proposed by integrating the errors into each joint. Moreover, the parameters in the model are identified by linearizing the dynamic POE-based kinematic model . Finally, the experiment shows the maximum errors can be limited to 0.60 and 1.16 mm for inserting point and needle endpoint after compensation, and the maximum inserting angle error is limited to 1.381°. It proves the feasibility of the kinematic model proposed in this paper and indicates that the robot system can meet the requirements of clinical biopsy.},
  archive      = {J_RAS},
  author       = {Weirong Wang and Bo Pan and Yue Ai and Yili Fu and Gonghui Li and Yanjie Liu},
  doi          = {10.1016/j.robot.2023.104465},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104465},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Ultrasound-guide prostate biopsy robot and calibration based on dynamic kinematic error model with POE formula},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable modular synthetic data generation for advancing
aerial autonomy. <em>RAS</em>, <em>166</em>, 104464. (<a
href="https://doi.org/10.1016/j.robot.2023.104464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One major barrier to advancing aerial autonomy has been collecting large-scale aerial datasets for training machine learning models. Due to costly and time-consuming real-world data collection through deploying drones, there has been an increasing shift towards using synthetic data for training models in drone applications. However, to increase widespread generalization and transferring models to real-world, increasing the diversity of simulation environments to train a model over all the varieties and augmenting the training data, has been proved to be essential. Current synthetic aerial data generation tools either lack data augmentation or rely heavily on manual workload or real samples for configuring and generating diverse realistic simulation scenes for data collection. These dependencies limit scalability of the data generation workflow. Accordingly, there is a major challenge in balancing generalizability and scalability in synthetic data generation. To address these gaps, we introduce a scalable Aerial Synthetic Data Augmentation (ASDA) framework tailored to aerial autonomy applications. ASDA extends a central data collection engine with two scriptable pipelines that automatically perform scene and data augmentations to generate diverse aerial datasets for different training tasks. ASDA improves data generation workflow efficiency by providing a unified prompt-based interface over integrated pipelines for flexible control. The procedural generative approach of our data augmentation is performant and adaptable to different simulation environments, training tasks and data collection needs. We demonstrate the effectiveness of our method in automatically generating diverse datasets and show its potential for downstream performance optimization . Our work contributes to generating enhanced benchmark datasets for training models that can generalize better to real-world situations. Video: youtube.com/watch?v=eKpOh-K-NfQ},
  archive      = {J_RAS},
  author       = {Mehrnaz Sabet and Praveen Palanisamy and Sakshi Mishra},
  doi          = {10.1016/j.robot.2023.104464},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104464},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Scalable modular synthetic data generation for advancing aerial autonomy},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online active and dynamic object shape exploration with a
multi-fingered robotic hand. <em>RAS</em>, <em>166</em>, 104461. (<a
href="https://doi.org/10.1016/j.robot.2023.104461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sense of touch can provide a robot with a wealth of information about the contact region when interacting with an unknown environment. Nevertheless, utilizing touch information to plan exploration paths and adjust robot posture to improve task efficiency remains challenging. This paper presents a novel approach for the online tactile surface exploration of unknown objects with a multi-degree of freedom robotic hand . We propose an exploration strategy that actively maximizes the entropy of the acquired data while dynamically balancing the exploration’s global knowledge and local complexity. We demonstrate that our method can efficiently control a multi-fingered robotic hand to explore objects of arbitrary shapes (e.g., with a handle, hole, or sharp edges). To facilitate efficient multi-contact exploration with a robotic hand, we offer an optimization-based planning algorithm that adapts the hand pose to the local surface geometry online and increases the kinematic configuration of each finger during exploration. Ultimately, we compared our approach to state of the art in a simulated environment. Experimental results indicate that our proposed methods can guide a multi-finger robotic hand to explore efficiently and smoothly, thereby reconstructing the unknown geometry of a variety of everyday objects, with significant improvements in data efficiency and finger compliance when compared to state-of-the-art approaches.},
  archive      = {J_RAS},
  author       = {Farshad Khadivar and Kunpeng Yao and Xiao Gao and Aude Billard},
  doi          = {10.1016/j.robot.2023.104461},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104461},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Online active and dynamic object shape exploration with a multi-fingered robotic hand},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LWDNet-a lightweight water-obstacles detection network for
unmanned surface vehicles. <em>RAS</em>, <em>166</em>, 104453. (<a
href="https://doi.org/10.1016/j.robot.2023.104453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water-obstacles detection based on semantic segmentation is an essential part of autonomous navigation of unmanned surface vehicles (USV). However, it is difficult for existing methods to ensure the real-time of water-obstacles recognition and high detection accuracy. To address this issue, we proposed novel network architecture , a lightweight water-obstacles detection network (LWDNet). In LWDNet, we adopt a novel backbone, bottleneck structure with attention block, the former decrease the model size, the latter obtain more semantic information, and then the dilated convolution has been used in depthwise separable (DW) convolution to enforce the extraction of feature information. Additionally, by using improved focal loss (weight the main and auxiliary focal loss), the water-obstacles detection accuracy increased. In order to test the real-time performance and detection accuracy of LWDNet, we use the most challenging dataset, Multi-modal Marine Obstacle Detection Dataset 2 (MODD2) dataset, for experimental validation. The experimental results show that, compared with the state-of-the-art detection methods, such as WasR and ShorelineNet, the LWDNet maintains a much faster speed of images inference (62 frames-per-second on an NVIDIA RTX 2080Ti), and at the same time, the obstacles detection performance is equally high (87.5\% F-measure, 77.8\% IOU). Therefore, the LWDNet is an efficient network in water-obstacles detection, making the autonomous navigation of USV more reliable.},
  archive      = {J_RAS},
  author       = {Qilie Cai and Qiang Wang and Yulong Zhang and Zhibo He and Yuhong Zhang},
  doi          = {10.1016/j.robot.2023.104453},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104453},
  shortjournal = {Robot. Auton. Syst.},
  title        = {LWDNet-A lightweight water-obstacles detection network for unmanned surface vehicles},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symbolic representation of what robots are taught in one
demonstration. <em>RAS</em>, <em>166</em>, 104452. (<a
href="https://doi.org/10.1016/j.robot.2023.104452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To facilitate the use of robots in small and medium-sized enterprises (SMEs), they have to be easily and quickly deployed by non-expert users. Programming by Demonstration (PbD) is considered a fast and intuitive approach to handle this requirement. However, one of the major drawbacks of pure PbD is that it may suffer from poor generalisation capabilities, as it is mainly capable of motion-level representations. This work proposes a method to semantically represent a demonstrated skill, so as to identify the elements of the workspace that are relevant for the characterisation of the skill itself, as well as its preconditions and effects. This way, the robot can automatically abstract from the demonstration and memorise the skill in a more general way. An experimental case study consisting in a manipulation task is reported to validate the approach.},
  archive      = {J_RAS},
  author       = {Andrea Maria Zanchettin},
  doi          = {10.1016/j.robot.2023.104452},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104452},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Symbolic representation of what robots are taught in one demonstration},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning 6-DoF grasping with dual-agent deep reinforcement
learning. <em>RAS</em>, <em>166</em>, 104451. (<a
href="https://doi.org/10.1016/j.robot.2023.104451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised grasp learning (SGL) is one of the most promising approaches to challenging robotic grasping. However, most existing SGL-based methods are restricted to in 4-DoF planar grasps due to limited grasp representations and inadequate learning rewards. This paper proposes 6-DoF grasp learning (6DGL). It represents a 6-DoF grasp by exploiting both planar and spherical grasp affordance in the image space. Its underlying network is called Q Mixing Network with Planar and Spherical Affordances (QMIX-PSA). In QMIX-PSA, two agent networks, i.e., a planar affordance network (PA-Net) and a spherical affordance network (SA-Net), are used to predict grasp position and orientation. Then, the two networks’ joint action value is estimated by a QMIX to reconstruct their connection. Again, an augmented reward is presented to evaluate the quality of a 6-DoF grasp by measuring the incurred disturbance to the surroundings with scene images. Finally, extensive experiments are conducted on grasping metal workpieces and daily items. The results show that 6DGL outperforms its peers regarding grasp success rate and quality, especially in clutter where existing SGL methods are incompetent.},
  archive      = {J_RAS},
  author       = {Yanxu Hou and Jun Li},
  doi          = {10.1016/j.robot.2023.104451},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104451},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Learning 6-DoF grasping with dual-agent deep reinforcement learning},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Motion planning in dynamic environments using context-aware
human trajectory prediction. <em>RAS</em>, <em>166</em>, 104450. (<a
href="https://doi.org/10.1016/j.robot.2023.104450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, the separate fields of motion planning, mapping, and human trajectory prediction have advanced considerably. However, the literature is still sparse in providing practical frameworks that enable mobile manipulators to perform whole-body movements and account for the predicted motion of moving obstacles. Previous optimisation-based motion planning approaches that use distance fields have suffered from the high computational cost required to update the environment representation. We demonstrate that GPU-accelerated predicted composite distance fields significantly reduce the computation time compared to calculating distance fields from scratch. We integrate this technique with a complete motion planning and perception framework that accounts for the predicted motion of humans in dynamic environments, enabling reactive and pre-emptive motion planning that incorporates predicted motions. To achieve this, we propose and implement a novel human trajectory prediction method that combines intention recognition with trajectory optimisation-based motion planning. We validate our resultant framework on a real-world Toyota Human Support Robot (HSR) using live RGB-D sensor data from the onboard camera. In addition to providing analysis on a publicly available dataset, we release the Oxford Indoor Human Motion (Oxford-IHM) dataset and demonstrate state-of-the-art performance in human trajectory prediction. The Oxford-IHM dataset is a human trajectory prediction dataset in which people walk between regions of interest in an indoor environment. Both static and robot-mounted RGB-D cameras observe the people while tracked with a motion-capture system.},
  archive      = {J_RAS},
  author       = {Mark Nicholas Finean and Luka Petrović and Wolfgang Merkt and Ivan Marković and Ioannis Havoutis},
  doi          = {10.1016/j.robot.2023.104450},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104450},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Motion planning in dynamic environments using context-aware human trajectory prediction},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Informed expansion for informative path planning via online
distribution learning. <em>RAS</em>, <em>166</em>, 104449. (<a
href="https://doi.org/10.1016/j.robot.2023.104449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots are essential tools for gathering knowledge of the environment and monitoring areas of interest as well as industrial assets. Informative Path Planning methodologies have been successfully applied making robots able to autonomously acquire information and explore unknown surroundings. Rapidly-exploring Information Gathering approaches have been validated in real-world applications, proving they are the way to go when aiming for Information Gathering tasks. In fact, RIG can plan paths for robots with several degrees of freedom and rapidly explore complex workspaces by using the state-of-the-art Voronoi-biased expansion. Nevertheless, it is an efficient solution when most of the area is unknown but its effectiveness decreases as the exploration/gathering evolves. This paper introduces an innovative informed expansion for IG tasks that combines the Kernel Density Estimation technique and a rejection sampling algorithm . By learning online the distribution of the acquired information (i.e., the discovered map), the proposed methodology generates samples in the unexplored regions of the workspace, and thus steers the tree toward the most promising areas. Realistic simulations and an experimental campaign, conducted in the underwater robotics domain, provide a proof-of-concept validation for the developed informed expansion methodology and demonstrate that it enhances the performance of the RIG algorithm.},
  archive      = {J_RAS},
  author       = {Leonardo Zacchini and Alessandro Ridolfi and Benedetto Allotta},
  doi          = {10.1016/j.robot.2023.104449},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104449},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Informed expansion for informative path planning via online distribution learning},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-contact planning and control for humanoid robots:
Design and validation of a complete framework. <em>RAS</em>,
<em>166</em>, 104448. (<a
href="https://doi.org/10.1016/j.robot.2023.104448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of generating appropriate motions for a torque-controlled humanoid robot that is assigned a multi-contact loco-manipulation task, i.e., a task that requires the robot to move within the environment by repeatedly establishing and breaking multiple, non-coplanar contacts. To this end, we present a complete multi-contact planning and control framework for multi-limbed robotic systems , such as humanoids. The planning layer works offline and consists of two sequential modules: first, a stance planner computes a sequence of feasible contact combinations; then, a whole-body planner finds the sequence of collision-free humanoid motions that realize them while respecting the physical limitations of the robot. For the challenging problem posed by the first stage, we propose a novel randomized approach that does not require the specification of pre-designed potential contacts or any kind of pre-computation. The control layer produces online torque commands that enable the humanoid to execute the planned motions while guaranteeing closed-loop balance. It relies on two modules, i.e., the stance switching and reactive balancing module; their combined action allows it to withstand possible execution inaccuracies, external disturbances , and modeling uncertainties. Numerical and experimental results obtained on COMAN+, a torque-controlled humanoid robot designed at Istituto Italiano di Tecnologia, validate our framework for loco-manipulation tasks of different complexity.},
  archive      = {J_RAS},
  author       = {Paolo Ferrari and Luca Rossini and Francesco Ruscelli and Arturo Laurenzi and Giuseppe Oriolo and Nikos G. Tsagarakis and Enrico Mingo Hoffman},
  doi          = {10.1016/j.robot.2023.104448},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104448},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multi-contact planning and control for humanoid robots: Design and validation of a complete framework},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of 9-DOF humanoid arms inspired by the human’s inner
shoulder to enhance versatility and workspace. <em>RAS</em>,
<em>166</em>, 104447. (<a
href="https://doi.org/10.1016/j.robot.2023.104447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many humanoid arms have six degrees-of-freedom (DOFs), similar to the human joint configuration. Moreover, humanoid arms with 7-DOF or 8-DOF have been designed to enhance the range of motion or structural versatility. Notably, these arms exhibit structural limitations and thus cannot effectively implement versatile and complex motions such as valve closing motion. To address this problem, this paper proposes a novel 9-DOF humanoid arm, named RoK-Arm9, inspired by the human inner shoulder. Two additional joints are introduced inside the shoulder to increase the versatility and workspace. To demonstrate the superiority of RoK-Arm9 over the existing robots for complex dual-arm manipulation, we analyzed the corresponding manipulability measure, bimanual task areas, and dual-arm manipulability measure. Finally, we confirmed that the actual RoK-Arm9 can conduct the same motion as the simulation.},
  archive      = {J_RAS},
  author       = {Jaesoon Lee and Baek-Kyu Cho},
  doi          = {10.1016/j.robot.2023.104447},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104447},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design of 9-DOF humanoid arms inspired by the human’s inner shoulder to enhance versatility and workspace},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TMG: A topology-based motion generalization method with
spatial relationship preservation. <em>RAS</em>, <em>166</em>, 104445.
(<a href="https://doi.org/10.1016/j.robot.2023.104445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important requirement, human-friendly motion in human–robot interaction (HRI) is increasingly attracting attention. In many scenarios, the ability to generalize a similar motion from demonstration is essential for a robot, and the similarity is generally captured by the spatial relationship between the different joints of the robot. Though a lot of investigation for motion generalization has been conducted and good progress achieved, they share limitations in leaving the relationship out of consideration and being difficult to apply the generalization between different robots. In this paper, we propose a novel topology-based motion generalization (TMG) method that abstracts the motion generalization problem to a mesh deformation optimization, and the spatial relationship between different parts of the robot is captured with a topology-based representation. Instead of only taking into account a single joint position, the relationship semantic with Laplacian coordinates is modeled, and the motion generalization from demonstration to reproduction is realized by preserving the semantic as a Laplacian deformation, and even the robot or target position is changed. Furthermore, motion generalization between single or multiple different robots can be achieved with spatial relationship preservation and transfer. Our experimental results show that the reproduction based on topology-based representation outperforms the mapping methods by training with end-effector pose or joint angles, and ensures robust motion with spatial relationship preservation.},
  archive      = {J_RAS},
  author       = {Yihui Li and Jiajun Wu and Xiaohan Chen and Yisheng Guan and Haifei Zhu},
  doi          = {10.1016/j.robot.2023.104445},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104445},
  shortjournal = {Robot. Auton. Syst.},
  title        = {TMG: A topology-based motion generalization method with spatial relationship preservation},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on control of humanoid fall over. <em>RAS</em>,
<em>166</em>, 104443. (<a
href="https://doi.org/10.1016/j.robot.2023.104443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robot operation requires balancing to prevent failures, such as fall over. This is a crucial task in legged robots and thus several researchers are working on this topic. Fall prediction, controlled fall, and fall recovery become important topics in understanding robot control and allow legged robots to function in challenging real-world environments. This paper aims at setting up methodically the problem definition of humanoid falling and further identifying and surveying working techniques in the literature. The focus is to categorize all methods that were used in the community, identify the solved and open questions, as well as propose directions of research in the field. The paper is based on experimental research that has been done on a full-size humanoid robot.},
  archive      = {J_RAS},
  author       = {Rajesh Subburaman and Dimitrios Kanoulas and Nikos Tsagarakis and Jinoh Lee},
  doi          = {10.1016/j.robot.2023.104443},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104443},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A survey on control of humanoid fall over},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An agent-based modeling framework for the multi-UAV
rendezvous recharging problem. <em>RAS</em>, <em>166</em>, 104442. (<a
href="https://doi.org/10.1016/j.robot.2023.104442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we aim to model the multi-UAV rendezvous recharging problem , which consists of energy-limited aerial vehicles that rendezvous with a mobile or fixed charging station. The motivation for such a problem is to tackle persistent surveillance missions, where the modeling of related problems often rely on heavy mathematical formulations, such as mixed integer linear programming (MILP). The major drawback of such approaches is great difficulty in capturing constraints and adjusting the model for changes. Additionally, MILP solvers are not guaranteed to yield a feasible solution in a timely manner. As a result, we chose to create an agent-based model (ABM). To the best of our knowledge, the presented problem has not been modeled before using ABM. Additionally, we sought to use a custom framework incorporating Behavior Trees (BTs) and Hierarchical Finite State Machines (HFSMs), two commonly used tools in the video game and robotics industry. We verify the model’s correctness through numerical simulations and show that it is highly modular and extensible.},
  archive      = {J_RAS},
  author       = {Kenny Chour and Jean-Paul Reddinger and James Dotterweich and Marshal Childers and James Humann and Sivakumar Rathinam and Swaroop Darbha},
  doi          = {10.1016/j.robot.2023.104442},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104442},
  shortjournal = {Robot. Auton. Syst.},
  title        = {An agent-based modeling framework for the multi-UAV rendezvous recharging problem},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DROPO: Sim-to-real transfer with offline domain
randomization. <em>RAS</em>, <em>166</em>, 104432. (<a
href="https://doi.org/10.1016/j.robot.2023.104432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, domain randomization over dynamics parameters has gained a lot of traction as a method for sim-to-real transfer of reinforcement learning policies in robotic manipulation; however, finding optimal randomization distributions can be difficult. In this paper, we introduce DROPO, a novel method for estimating domain randomization distributions for safe sim-to-real transfer. Unlike prior work, DROPO only requires a limited, precollected offline dataset of trajectories, and explicitly models parameter uncertainty to match real data using a likelihood-based approach. We demonstrate that DROPO is capable of recovering dynamic parameter distributions in simulation and finding a distribution capable of compensating for an unmodeled phenomenon. We also evaluate the method in two zero-shot sim-to-real transfer scenarios, showing successful domain transfer and improved performance over prior methods.},
  archive      = {J_RAS},
  author       = {Gabriele Tiboni and Karol Arndt and Ville Kyrki},
  doi          = {10.1016/j.robot.2023.104432},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104432},
  shortjournal = {Robot. Auton. Syst.},
  title        = {DROPO: Sim-to-real transfer with offline domain randomization},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SAR optimization and convolutional neural network based
fault estimations and for auto-landing control model. <em>RAS</em>,
<em>166</em>, 104409. (<a
href="https://doi.org/10.1016/j.robot.2023.104409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During auto landing, the aircraft flies at a significantly low altitude and low speed. So the consequent accidents and flight crashes are highly possible. Several constrained space and foremost external interruption while landing is considered as one of the most complex phases of the aircraft. Therefore it is necessary to recover the aircraft from various major disturbances and to estimate the rate of fault during aircraft landing. In addition to this, for the effective design of an aircraft, it is essential in determining the fault that affects the aircraft. To overcome the issues, this article aim to propose a novel CNNLSTM-SAR-based fault estimation approach to estimate the fault rate from various state trajectories of the aircraft. Here we employed a Convolution Neural Network (CNN) and Long Short-Term Memory (LSTM) model integrated with the Search and Rescue (SAR) optimization algorithm to react instantaneously to the broad range of failures such as actuator failure and failure due to the wind. Then the performances of the proposed CNNLSTM-SAR based fault estimation approach are compared and the results demonstrated that the proposed approach provide a smooth landing with minimum fault and error.},
  archive      = {J_RAS},
  author       = {T. Ayyasamy and S. Nirmala and A. Saravanakumar},
  doi          = {10.1016/j.robot.2023.104409},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104409},
  shortjournal = {Robot. Auton. Syst.},
  title        = {SAR optimization and convolutional neural network based fault estimations and for auto-landing control model},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A telerobotic system enabling online switching among various
architectures and controllers. <em>RAS</em>, <em>166</em>, 104402. (<a
href="https://doi.org/10.1016/j.robot.2023.104402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of teleoperation tasks, various teleoperation architectures, including the Single-Leader/Single-Follower (SLSF), Multiple-Leader/Multiple-Follower (MLMF), Single-Leader/Multiple-Follower (SLMF), and Multiple-Leader/Single-Follower (MLSF) systems, are emerging. Although numerous works have focused on the control strategies or a specific architecture, the study on online switching among different architectures is not equally prolific. However, the online switching among different architectures/controllers is required in a wide spectrum of robotic applications to perform complex tasks. This feature can also promote the development of shared autonomy robotic systems , including the seamless adaption of the autonomy level, the better co-adaption between human and robot, and so on. Here a generic, flexible, and expandable telerobotic system is developed. Instead of focusing on the control strategy of a specific architecture, the physical topology , the software design , and the switching strategy during transitions are all considered to enable the online switching among various architectures and/or controllers. The experimental results of several scenarios validate the main features of the proposed system and demonstrate the benefits of these features.},
  archive      = {J_RAS},
  author       = {Gaofeng Li and Fernando Caponetto and Vasiliki Katsageorgiou and Nikos G. Tsagarakis and Ioannis Sagakoglou},
  doi          = {10.1016/j.robot.2023.104402},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104402},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A telerobotic system enabling online switching among various architectures and controllers},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Super intendo: Semantic robot programming from multiple
demonstrations for taskable robots. <em>RAS</em>, <em>166</em>, 104397.
(<a href="https://doi.org/10.1016/j.robot.2023.104397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When an end-user instructs a taskable robot on a new task, it is important for the robot to learn the user’s intention for the task. Knowing the user’s intention, represented as desired goal conditions, allows the robot to generalize across variations of the learned task seen at execution time. However, it has proven challenging to learn goal conditions due to the large, noisy, and complex space of goal conditions expressed by human users. This paper introduces Semantic Robot Programming with Multiple Demonstrations ( SRP-MD ) to learn a generative model of latent end-user task goal conditions from multiple end-user demonstrations in a shared workspace . By learning a generative model of the goal conditions, SRP-MD generalizes to task instances even when the quantity of objects to be arranged is not in the training set or novel object instances are included. At test time, a new goal is pulled from the learned generative model given the objects present in the initial scene. The efficacy of SRP-MD as a step toward taskable robots is shown on a Fetch robot learning and executing bin packing tasks in a simulated environment with grocery items.},
  archive      = {J_RAS},
  author       = {Kevin David French and Ji Hwang Kim and Yidong Du and Elizabeth Mamantov Goeddel and Zhen Zeng and Odest Chadwicke Jenkins},
  doi          = {10.1016/j.robot.2023.104397},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104397},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Super intendo: Semantic robot programming from multiple demonstrations for taskable robots},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multimodal loop closure fusion for autonomous vehicles
SLAM. <em>RAS</em>, <em>165</em>, 104446. (<a
href="https://doi.org/10.1016/j.robot.2023.104446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Place recognition and loop closure detection are critical steps in the process of Simultaneous Localization and Mapping (SLAM). Indeed, the ability to determine whether an Autonomous Ground Vehicle (AGV) has returned to a previously visited place is highly important in the context of building a reliable SLAM system. In order to build a consistent global map and to localize the AGV with high confidence in an unknown environment, it is crucial to reduce the cumulative error generated by pose estimation. Although multiple approaches using various data sources have been proposed in order to provide an accurate pose estimation, fewer studies have focused on the integration of a multimodal process to detect loop closure. In this work, we present a novel approach to leverage multiple modalities for a robust and reliable loop closure detection. Our method is based on Similarity-Guided Particle Filtering (SGPF) for the search and validation of Loop Closure Candidates (LCCs). We validate the proposed Multimodal Loop Closure (MMLC) by using two perception modalities based on Bag-of-Words and Scan Context techniques for camera-based and LiDAR-based place recognition, respectively. The efficiency of our method has been evaluated on both KITTI and a self-collected dataset. Compared to the classical loop closure used in ORB-SLAM2, the suggested approach reduces the Absolute Trajectory Error (ATE) by up to 54\% and the cumulative error during run-time by up to 62.63\%. Finally, 100\% of the loops are accurately detected and the ground truth distance between the current pose and the LC is less than 3 m in 98\% of the cases.},
  archive      = {J_RAS},
  author       = {Mohammed Chghaf and Sergio Rodríguez Flórez and Abdelhafid El Ouardi},
  doi          = {10.1016/j.robot.2023.104446},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104446},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A multimodal loop closure fusion for autonomous vehicles SLAM},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A lumen-adapted navigation scheme with spatial awareness
from monocular vision for autonomous robotic endoscopy. <em>RAS</em>,
<em>165</em>, 104444. (<a
href="https://doi.org/10.1016/j.robot.2023.104444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lumen is a common anatomical condition in endoscopic therapy or diagnostics. The navigation of autonomous robotic endoscopy usually involves vision techniques such as detection of lumen center or anatomically specific contour features. However, these methods may fail to achieve smooth interventions and result in large conveying force without spatial awareness of the tissue state. In this paper, a novel navigation pipeline based on a spatial-aware monocular vision is proposed. The spatial awareness pipeline starts with a data-driven depth estimation technique for reconstructing real-time approximate tissue surface. The spatial shape of the lumen described by the skeleton is then extracted using digital topology. We modify the skeleton to get a smooth pathway, and design an adaptive autonomous control strategy using geometric information from the pathway. We conduct experiments on a colon phantom and ex vivo pig intestines. We test turning performance of several bending segments with different angles in phantom, as well as the overall performance of a long-range intervention task in the phantom and pig intestines. The results show our navigation scheme achieve smoother intervention with lower conveying force. The proposed navigation method with spatial awareness can effectively improve the fluency of autonomous robotic endoscopy.},
  archive      = {J_RAS},
  author       = {Tao Yang and Yongming Yang and Peng Wang and Yang Cao and Zhuo Yang and Hao Liu},
  doi          = {10.1016/j.robot.2023.104444},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104444},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A lumen-adapted navigation scheme with spatial awareness from monocular vision for autonomous robotic endoscopy},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smooth collision avoidance for the formation control of
first order multi-agent systems. <em>RAS</em>, <em>165</em>, 104433. (<a
href="https://doi.org/10.1016/j.robot.2023.104433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses collision avoidance in the formation control of a group of mobile robots with first-order dynamics perturbed by lateral and longitudinal slipping parameters. A Generalized Proportional–Integral Observer (GPIO) is designed to estimate these perturbations. Then, an Active Disturbance Rejection Control (ADRC) is proposed to solve the well-known formation control avoiding collisions among the agents. The control strategy only depends on the agents’ position measurements. On the other hand, Continuous Repulsive Vector Fields (C-RVFs) are developed to avoid collisions among the agents. For this purpose, a parameter depending on the inter-robot distance is developed to scale the RVFs properly. By proposing C-RVFs, the chattering is eliminated when using Discontinuous RVFs (D-RVFs). Numerical simulations and real-time experiments illustrate the agents’ performance when they are at risk of collision.},
  archive      = {J_RAS},
  author       = {Jaime González-Sierra and E.G. Hernandez-Martinez and Mario Ramírez-Neria and Guillermo Fernandez-Anaya},
  doi          = {10.1016/j.robot.2023.104433},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104433},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Smooth collision avoidance for the formation control of first order multi-agent systems},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model predictive impedance control with gaussian processes
for human and environment interaction. <em>RAS</em>, <em>165</em>,
104431. (<a href="https://doi.org/10.1016/j.robot.2023.104431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic tasks which involve uncertainty – due to variation in goal, environment configuration , or confidence in task model – may require human input to instruct or adapt the robot. In tasks with physical contact, several existing methods for adapting robot trajectory or impedance according to individual uncertainties have been proposed, e.g., realizing intention detection or uncertainty-aware learning from demonstration. However, isolated methods cannot address the wide range of uncertainties jointly present in many tasks. To improve generality, this paper proposes a model predictive control (MPC) framework which plans both trajectory and impedance online, can consider discrete and continuous uncertainties, includes safety constraints, and can be efficiently applied to a new task. This framework can consider uncertainty from: contact constraint variation, uncertainty in human goals, or task disturbances. An uncertainty-aware task model is learned from a few ( ≤ 3 ≤3 ) demonstrations using Gaussian Processes . This task model is used in a nonlinear MPC problem to optimize robot trajectory and impedance according to belief in discrete human goals, human kinematics, safety constraints, contact stability, and frequency-domain disturbance rejection. This MPC formulation is introduced, analyzed with respect to convexity, and validated in co-manipulation with multiple goals, a collaborative polishing task, and a collaborative assembly task.},
  archive      = {J_RAS},
  author       = {Kevin Haninger and Christian Hegeler and Luka Peternel},
  doi          = {10.1016/j.robot.2023.104431},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104431},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Model predictive impedance control with gaussian processes for human and environment interaction},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Direction constraints adaptive extended bidirectional a*
algorithm based on random two-dimensional map environments.
<em>RAS</em>, <em>165</em>, 104430. (<a
href="https://doi.org/10.1016/j.robot.2023.104430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the mobile robot path planning problem of optimizing the performance metrics of bidirectional A* algorithm in randomized two-dimensional map environments. An algorithm called direction constraints adaptive extended bidirectional A* (DCAE-BA*), which is an improvement of the traditional target dynamic bidirectional A* algorithm (TTD-BA*), is proposed to improve the performance metrics of the algorithm. Regarding the improvement, we propose the adaptive extension method and the direction-constrained optimal node extension method (DCONE). Simulation experiments were conducted for DCAE-BA*, TTD-BA* and traditional A* algorithm (A*) in a large number of random two-dimensional map environments. The simulation experimental scenarios consider four types of start and end point relative directions and three obstacle proportions to objectively and comprehensively evaluate the performance of the proposed algorithms. The results show that different scenarios have a significant impact on the algorithm performance metrics. Finally, the overall performance of the proposed algorithm is evaluated with a large number of experiments in “random” scenarios, and the results show that DCAE-BA* obtains significantly better search time for all three obstacle proportions, and better path length and number of expanded nodes for 10\% and 25\% obstacle proportions. The effectiveness of the proposed DCAE-BA* algorithm is demonstrated, which provides an essential reference for the path planning of mobile robots in a random 2D map environment.},
  archive      = {J_RAS},
  author       = {Jiqing Chen and Mingyu Li and Yousheng Su and Wenqu Li and Yizhong Lin},
  doi          = {10.1016/j.robot.2023.104430},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104430},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Direction constraints adaptive extended bidirectional a* algorithm based on random two-dimensional map environments},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quasi-static balancing for biped robot to perform extreme
postures using ducted-fan propulsion system. <em>RAS</em>, <em>165</em>,
104429. (<a href="https://doi.org/10.1016/j.robot.2023.104429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quasi-static balancing is important for enabling humanoid robots to move through extremely rugged terrain, e.g., stepping over a ditch whose width exceeds the robot’s leg length. In this study, to overcome such challenges, an innovative solution was developed, in which external thrust is utilized to maintain the robot’s balance. Initially, a model of the robot’s balance was established for analyzing the factors affecting the balance and the means to maintain it. Subsequently, a new controller combining a thrust controller and a center-of-mass controller was developed to compensate for errors in the thrust output and mass distribution. Finally, a new motion-planning method based on line search regression (LSR) and grid search optimization (GSO) was developed. A series of experiments were conducted using a prototype robot (Jet-HR3), including an error compensation test, an external force disturbance test, a comprehensive motion test, and an active sliding steering test. The results indicated the effectiveness and efficiency of the proposed method. The robot successfully crossed a ditch 695 mm wide, i.e., 147\% of the robot’s leg length.},
  archive      = {J_RAS},
  author       = {Zhifeng Huang and Zijun Wang and Jinglun Zhou and Kairong Wu and Shunjie Zhu and Lei Nie and Yuwei Liang and Liang Yang and Yun Zhang},
  doi          = {10.1016/j.robot.2023.104429},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104429},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Quasi-static balancing for biped robot to perform extreme postures using ducted-fan propulsion system},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic extension of a symbolic mobile manipulation skill
set. <em>RAS</em>, <em>165</em>, 104428. (<a
href="https://doi.org/10.1016/j.robot.2023.104428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic planning can provide an intuitive interface for non-expert users to operate autonomous robots by abstracting away much of the low-level programming. However, symbolic planners assume that the initially provided abstract domain and problem descriptions are closed and complete. This means that they are fundamentally unable to adapt to changes in the environment or tasks that are not captured by the initial description. We propose a method that allows an agent to automatically extend the abstract description of its skill set upon encountering such a situation. We introduce strategies for generalizing from previous experience, completing sequences of key actions and discovering preconditions to ensure computational efficiency. The resulting system is evaluated on a symbolic planning benchmark task and on object rearrangement tasks in simulation. Compared to a Monte Carlo Tree Search baseline, our strategies for efficient search have on average a 25\% higher success rate at a 67\% faster runtime. Code is available at https://github.com/ethz-asl/high_level_planning .},
  archive      = {J_RAS},
  author       = {Julian Förster and Lionel Ott and Juan Nieto and Nicholas Lawrance and Roland Siegwart and Jen Jen Chung},
  doi          = {10.1016/j.robot.2023.104428},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104428},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Automatic extension of a symbolic mobile manipulation skill set},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual learning from demonstration of robotics skills.
<em>RAS</em>, <em>165</em>, 104427. (<a
href="https://doi.org/10.1016/j.robot.2023.104427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods for teaching motion skills to robots focus on training for a single skill at a time. Robots capable of learning from demonstration can considerably benefit from the added ability to learn new movement skills without forgetting what was learned in the past. To this end, we propose an approach for continual learning from demonstration using hypernetworks and neural ordinary differential equation solvers. We empirically demonstrate the effectiveness of this approach in remembering long sequences of trajectory learning tasks without the need to store any data from past demonstrations. Our results show that hypernetworks outperform other state-of-the-art continual learning approaches for learning from demonstration. In our experiments, we use the popular LASA benchmark, and two new datasets of kinesthetic demonstrations collected with a real robot that we introduce in this paper called the HelloWorld and RoboTasks datasets. We evaluate our approach on a physical robot and demonstrate its effectiveness in learning real-world robotic tasks involving changing positions as well as orientations. We report both trajectory error metrics and continual learning metrics, and we propose two new continual learning metrics. Our code, along with the newly collected datasets, is available at https://github.com/sayantanauddy/clfd .},
  archive      = {J_RAS},
  author       = {Sayantan Auddy and Jakob Hollenstein and Matteo Saveriano and Antonio Rodríguez-Sánchez and Justus Piater},
  doi          = {10.1016/j.robot.2023.104427},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104427},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Continual learning from demonstration of robotics skills},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implementation relations and testing for cyclic systems:
Adding probabilities. <em>RAS</em>, <em>165</em>, 104426. (<a
href="https://doi.org/10.1016/j.robot.2023.104426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the systematic testing of robotic control software based on state-based models. We focus on cyclic systems that typically receive inputs (values from sensors), perform computations, produce outputs (sent to actuators) and possibly change state. We provide a testing theory for such cyclic systems where time can be represented and probabilities are used to quantify non-deterministic choices, making it possible to model probabilistic algorithms. In addition, refusals , the inability of a system to perform a set of actions, are taken into account. We consider several possible testing scenarios. For example, a tester might only be able to passively observe a sequence of events and so cannot check probabilities, while in another scenario a tester might be able to repeatedly apply a test case and so estimate the probabilities of sequences of events. These different testing scenarios lead to a range of implementation relations (notions of correctness). As a consequence, this paper provides formal definitions of implementation relations that can form the basis of sound automated testing in a range of testing scenarios. We also validate the implementation relations by showing how observers can be used to provide an alternative but equivalent characterisation.},
  archive      = {J_RAS},
  author       = {Manuel Núñez and Robert M. Hierons and Raluca Lefticaru},
  doi          = {10.1016/j.robot.2023.104426},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104426},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Implementation relations and testing for cyclic systems: Adding probabilities},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cyclic policy distillation: Sample-efficient sim-to-real
reinforcement learning with domain randomization. <em>RAS</em>,
<em>165</em>, 104425. (<a
href="https://doi.org/10.1016/j.robot.2023.104425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning with domain randomization learns a control policy in various simulations with randomized physical and sensor model parameters to become transferable to the real world in a zero-shot setting. However, a huge number of samples are often required to learn an effective policy when the range of randomized parameters is extensive due to the instability of policy updates. To alleviate this problem, we propose a sample-efficient method named cyclic policy distillation (CPD). CPD divides the range of randomized parameters into several small sub-domains and assigns a local policy to each one. Then local policies are learned while cyclically transitioning to sub-domains. CPD accelerates learning through knowledge transfer based on expected performance improvements. Finally, all of the learned local policies are distilled into a global policy for sim-to-real transfers. CPD’s effectiveness and sample efficiency are demonstrated through simulations with four tasks (Pendulum from OpenAIGym and Pusher, Swimmer, and HalfCheetah from Mujoco), and a real-robot, ball-dispersal task. We published code and videos from our experiments at https://github.com/yuki-kadokawa/cyclic-policy-distillation .},
  archive      = {J_RAS},
  author       = {Yuki Kadokawa and Lingwei Zhu and Yoshihisa Tsurumine and Takamitsu Matsubara},
  doi          = {10.1016/j.robot.2023.104425},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104425},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Cyclic policy distillation: Sample-efficient sim-to-real reinforcement learning with domain randomization},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An exploratory study of software engineering in heavy-duty
mobile machine automation. <em>RAS</em>, <em>165</em>, 104424. (<a
href="https://doi.org/10.1016/j.robot.2023.104424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the amount and complexity of software for automating heavy-duty mobile machinery is increasing, software engineering in this domain is becoming more important. To characterize the industry’s current state of software engineering and its issues to guide future research, we performed an empirical exploratory study . We interviewed 16 software engineering professionals from 13 different companies conducting business in heavy-duty mobile machines and their automation. The interviews were analyzed qualitatively, and quantification of the analysis results is presented. We first create an overview of software engineering in the heavy-duty mobile machinery industry. We then identify problem areas affecting software development and discuss some of the possible solutions found in literature. Our findings indicate that the major problem areas faced in the industry that require more research are its digital transformation, autonomous machine functional safety , low availability of workforce for developing software for robotic mobile machines and the lack of established software standards.},
  archive      = {J_RAS},
  author       = {Andrei Ahonen and Marea de Koning and Tyrone Machado and Reza Ghabcheloo and Outi Sievi-Korte},
  doi          = {10.1016/j.robot.2023.104424},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104424},
  shortjournal = {Robot. Auton. Syst.},
  title        = {An exploratory study of software engineering in heavy-duty mobile machine automation},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-reconfiguration of PARTS: A parallel reconfiguration
algorithm based on surface flow. <em>RAS</em>, <em>164</em>, 104417. (<a
href="https://doi.org/10.1016/j.robot.2023.104417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a parallel reconfiguration algorithm for shape-shifting modular robots with a triangular structure. The reconfiguration planning is based on partitioning the robot’s surface into source and sink sections for modules, using the largest common topology as a reference. Reconfiguration is realized by a synchronous surface flow of modules guided by the prior determination of module sources and sinks. Individual reconfiguration steps are carried out by a multi-step optimization framework, ensuring that intermediate configurations required for topology changes are valid and collision-free. With a configuration containing n n modules, the algorithm completes the reconfiguration in O ( n ) O(n) reconfiguration steps and allows for a distributed and asynchronous hardware implementation. We demonstrate the performance of the proposed algorithm on multiple example configurations and compare the results to other reconfiguration approaches.},
  archive      = {J_RAS},
  author       = {Michael Gerbl and Johannes Gerstmayr},
  doi          = {10.1016/j.robot.2023.104417},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104417},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Self-reconfiguration of PARTS: A parallel reconfiguration algorithm based on surface flow},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pose accuracy improvement in robotic machining by
visually-guided method and experimental investigation. <em>RAS</em>,
<em>164</em>, 104416. (<a
href="https://doi.org/10.1016/j.robot.2023.104416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial robots have been widely used in the industries of automotive, machining, electrical and electronic, rubber and plastics, aerospace, food, etc., owing to their high efficiency and flexibility in contrast to large scaled machining centers . However, the poor accuracy resulted from the serial configuration of industrial robots has restricted their applications to high-precision machining for several decades. In this paper, an error compensation technique is proposed using the visual guidance to effectively improve the pose accuracy of industrial robots. Firstly, the effect of the establishment method of tracking coordinate system for a visual sensor on the pose measurement error is analyzed and the establishment method is optimized. Next, a fuzzy PID controller is designed and integrated with a KUKA robot controller KRC via the KUKA robot sensor interface to guide the robot to the desired pose in real-time. Finally, experimental tests are implemented to validate the effectiveness of the proposed approach.},
  archive      = {J_RAS},
  author       = {Bo Li and Yufei Li and Wei Tian and Wenhe Liao},
  doi          = {10.1016/j.robot.2023.104416},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104416},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Pose accuracy improvement in robotic machining by visually-guided method and experimental investigation},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A memory system of a robot cognitive architecture and its
implementation in ArmarX. <em>RAS</em>, <em>164</em>, 104415. (<a
href="https://doi.org/10.1016/j.robot.2023.104415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive agents such as humans and robots perceive their environment through an abundance of sensors producing streams of data that need to be processed to generate intelligent behavior. A key question of cognition-enabled and AI-driven robotics is how to organize and manage such data and knowledge efficiently in a cognitive robot control architecture. We argue, that memory is a central active component of such architectures that mediates between semantic and sensorimotor representations, orchestrates the flow of data streams and events between different processes and provides the components of a cognitive architecture with data-driven services for learning semantics from sensorimotor data, the parametrization of symbolic plans for execution and prediction of action effects. Based on related work, and the experience gained in developing our ARMAR humanoid robot systems, we identified conceptual and technical requirements of a memory system as central component of cognitive robot control architecture that facilitate the realization of high-level cognitive abilities such as explaining, reasoning, prospection, simulation and augmentation. Conceptually, a memory should be active, support multi-modal data representations, associate knowledge, be introspective, and have an inherently episodic structure. Technically, the memory should support a distributed design, be access-efficient and capable of long-term data storage. We introduce the memory system for our cognitive robot control architecture and its implementation in the robot software framework ArmarX. We evaluate the efficiency of the memory system with respect to transfer speeds, compression, reproduction and prediction capabilities.},
  archive      = {J_RAS},
  author       = {Fabian Peller-Konrad and Rainer Kartmann and Christian R.G. Dreher and Andre Meixner and Fabian Reister and Markus Grotz and Tamim Asfour},
  doi          = {10.1016/j.robot.2023.104415},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104415},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A memory system of a robot cognitive architecture and its implementation in ArmarX},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A vision-based virtual fixture with robot learning for
teleoperation. <em>RAS</em>, <em>164</em>, 104414. (<a
href="https://doi.org/10.1016/j.robot.2023.104414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teleoperation plays a key role for semi-automated tasks with high complexity in remote working environment. By integrating the interaction information and control strategy, the control performance can be guaranteed by the skilled operator manipulation in terms of stability and precision. However, due to a lack of prolonged specialized training, the manipulation characteristics, such as operation habits and tremor for green hands, the control performance of teleoperation cannot be guaranteed, especially for complicated and refined tasks. To this end, a vision-based virtual fixture with robot learning approach is proposed for teleoperation. In the proposed method, a dynamic movement primitives method is utilized to learn the human tutor or skilled operator manipulation skill and then generates the expert trajectories for training of green hands. Additionally, considering the instantaneity of manipulation, a vision-based virtual fixture is utilized to generate a force selector based on position error and provides a force guidance to the green hands in order to enhance the precision of control with expert level and reduce the operation pressure. Comparative experimental results demonstrated the performance of the developed approach for teleoperation.},
  archive      = {J_RAS},
  author       = {Jing Luo and Weibin Liu and Wen Qi and Jianwen Hu and Junming Chen and Chenguang Yang},
  doi          = {10.1016/j.robot.2023.104414},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104414},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A vision-based virtual fixture with robot learning for teleoperation},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A geometric optimal control approach for imitation and
generalization of manipulation skills. <em>RAS</em>, <em>164</em>,
104413. (<a href="https://doi.org/10.1016/j.robot.2023.104413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Daily manipulation tasks are characterized by regular features associated with the task structure, which can be described by multiple geometric primitives related to actions and object shapes. Only using Cartesian coordinate systems cannot fully represent such geometric descriptors. In this article, we consider other candidate coordinate systems and propose a learning approach to extract the optimal representation of an observed movement/behavior from these coordinates. This is achieved by using an extension of Gaussian distributions on Riemannian manifolds, which is used to analyze a small set of user demonstrations statistically represented in different coordinate systems. We formulate the skill generalization as a general optimal control problem based on the (iterative) linear quadratic regulator ((i)LQR), where the Gaussian distribution in the proper coordinate systems is used to define the cost function. We apply our approach to object grasping and box-opening tasks in simulation and on a 7-axis Franka Emika robot using open-loop and feedback control , where precision matrices result in the automatic determination of feedback gains for the controller from very few demonstrations represented in multiple coordinate systems. The results show that the robot can exploit several geometries to execute the manipulation task and generalize it to new situations. The results show high variation along the do-not-matter direction, while maintaining the invariant characteristics of the task in the coordinate system(s) of interest. We then tested the approach in a human–robot shared control task. Results show that the robot can modify its grasping strategy based on the geometry of the object that the user decides to grasp.},
  archive      = {J_RAS},
  author       = {Boyang Ti and Amirreza Razmjoo and Yongsheng Gao and Jie Zhao and Sylvain Calinon},
  doi          = {10.1016/j.robot.2023.104413},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104413},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A geometric optimal control approach for imitation and generalization of manipulation skills},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and analysis of an e-puck2 robot plug-in for the
ARGoS simulator. <em>RAS</em>, <em>164</em>, 104412. (<a
href="https://doi.org/10.1016/j.robot.2023.104412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we present a new plug-in for the ARGoS swarm robotic simulator to implement the E-Puck2 robot model, including its graphical representation , sensors and actuators. We have based our development on the former E-Puck robot model (version 1) by upgrading the existing sensors (proximity, light, ground, camera, and battery) and adding new ones (time of flight and simulated encoders) implemented from scratch. We have adapted the values produced by the proximity, light and ground sensors, including the E-Puck2’s onboard camera according to its resolution, and proposed four new discharge models for the battery. We have evaluated this new plug-in in terms of accuracy and efficiency through comparisons with real robots and extensive simulations. In all our experiments the proposed plug-in has worked well showing high levels of accuracy. The observed increment of execution times when using the studied sensors varies according to the number of robots and types of sensors included in the simulation, ranging from a negligible impact to 53\% longer simulations in the most demanding cases.},
  archive      = {J_RAS},
  author       = {Daniel H. Stolfi and Grégoire Danoy},
  doi          = {10.1016/j.robot.2023.104412},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104412},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design and analysis of an E-puck2 robot plug-in for the ARGoS simulator},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust and compliant framework for legged mobile
manipulators using virtual model control and whole-body control.
<em>RAS</em>, <em>164</em>, 104411. (<a
href="https://doi.org/10.1016/j.robot.2023.104411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadruped robots can mimic animal locomotion mode and have great potential usage in unstructured environments. However, as mobile platforms, quadruped robots often lack manipulation capabilities. In this project, we equipped the quadruped robot SDU-ADog with a torque-controlled 6-DOF arm. A novel control framework which combines virtual model control (VMC) and prioritized whole-body control (WBC) for the whole system is proposed in this paper. VMC finds optimal target ground reaction forces while compensating the arm’s inertia, and then makes the robot compliant to external disturbance . Prioritized WBC deals with multiple tasks in an optimal fashion and achieves efficiency and robustness of robot’s locomotion and manipulation. The effectiveness of our framework has been evaluated through a set of robot dynamic simulations conducted in Webots. The robot can finish balance maintaining with moving arm, fixed point tracking while trotting, and locomotion over different obstacles with an end-point task.},
  archive      = {J_RAS},
  author       = {Aizhen Xie and Teng Chen and Xuewen Rong and Guoteng Zhang and Yibin Li and Yong Fan},
  doi          = {10.1016/j.robot.2023.104411},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104411},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A robust and compliant framework for legged mobile manipulators using virtual model control and whole-body control},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative artificial intelligence for underwater robotic
swarm. <em>RAS</em>, <em>164</em>, 104410. (<a
href="https://doi.org/10.1016/j.robot.2023.104410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater Robots such as Autonomous Underwater Vehicles (AUVs) and Remotely Operated Vehicles (ROVs) has played an important role in many tasks, such as marine environmental monitoring, underwater resource exploration, oil and gas industries , hydrographic surveys, military missions, etc. Underwater robotic swarm is a team of cooperative underwater robots which focuses on controlling multiple underwater robots to work in an organic group. In contrast to a single underwater robot, underwater robotic swarm represents higher operation efficiency and better stability while executing complex tasks. However, it needs higher intelligence to realize complementary cooperation than a single robot. It is beneficial to researchers to present a comprehensive survey of the state of the art of cooperative research for underwater robotic swarm. We observe that the research of Artificial Intelligence (AI) for multiple underwater robots is still in an early stage. In this paper, we study different collaborative operation mode in detail, such as formation control , task allocation, path planning , obstacle avoidance, flocking control etc. We propose different classification frameworks for these research topics and it also can be used to compare different methods and help engineers choose suitable methods for various applications. To achieve better cooperative performance of underwater robots, there are several key factors, including multi-source heterogeneous sensing, cooperative communication and navigation, information fusion and decision. Moreover, cooperative AI for underwater robotic swarm has different kinds of interesting and helpful applications. Finally, several possible applied AI methods including meta-heuristic algorithms, deep learning method and distributed learning method are accomplishing to cooperation of underwater robotic swarm.},
  archive      = {J_RAS},
  author       = {Wenyu Cai and Ziqiang Liu and Meiyan Zhang and Chengcai Wang},
  doi          = {10.1016/j.robot.2023.104410},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104410},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Cooperative artificial intelligence for underwater robotic swarm},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TRUSTS: A novel treadmill-based multifunctional testing
system for performance evaluation of wheeled planetary exploration
rover. <em>RAS</em>, <em>164</em>, 104408. (<a
href="https://doi.org/10.1016/j.robot.2023.104408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel treadmill-based multifunctional testing system (TRUSTS) to execute ground testing for wheeled planetary exploration rover (WPER) in both regular and extreme physical conditions before launching. The TRUSTS with specially-made components featuring compact structure and multifunctional testing items comprises a traction loading subsystem (TLS) and a treadmill-based resistance torque loading subsystem (TRTLS). The former offers the working modes including traction loading, position holding, and range limiting. The latter offers working modes including resistance torque loading and leader–follower tracking. By appropriately allocating the working modes of two subsystems, the TRUSTS is capable of conducting diverse testing items. The customized controllers for the TLS and the TRTLS are proposed to guarantee the operation performance of the TRUSTS in all testing items. Extensive experimental results on a Mars rover prototype in both regular and extreme physical conditions demonstrate that the devised TRUSTS could effectively executing trafficability and maneuverability as well as adaptability tests with reliable scenarios and satisfactory precisions of motion tracking and traction/torque loading, which makes the TRUSTS a favorable choice for comprehensive performance assessment of rover in simulant extraterrestrial environment.},
  archive      = {J_RAS},
  author       = {Haitao Yu and Jian Chen and Dong Pan and Haibo Gao},
  doi          = {10.1016/j.robot.2023.104408},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104408},
  shortjournal = {Robot. Auton. Syst.},
  title        = {TRUSTS: A novel treadmill-based multifunctional testing system for performance evaluation of wheeled planetary exploration rover},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Force control of lightweight series elastic systems using
enhanced disturbance observers. <em>RAS</em>, <em>164</em>, 104407. (<a
href="https://doi.org/10.1016/j.robot.2023.104407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the control challenges associated to lightweight series elastic systems in force control applications, showing that a low end-point inertia can lead to high sensitivity to environment uncertainties. Where mainstream force control methods fail, this paper proposes a control methodology to enhance the performance robustness of existing disturbance observers (DOBs). The approach is validated experimentally and successfully compared to basic control solutions and state of the art DOB approaches.},
  archive      = {J_RAS},
  author       = {Andrea Calanca and Enrico Sartori and Bogdan Maris},
  doi          = {10.1016/j.robot.2023.104407},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104407},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Force control of lightweight series elastic systems using enhanced disturbance observers},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy dynamical system for robot learning motion skills from
human demonstration. <em>RAS</em>, <em>164</em>, 104406. (<a
href="https://doi.org/10.1016/j.robot.2023.104406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from demonstration (LfD) is an intuitive strategy for transferring human motion skills to robots in an agile and adaptable manner. The major goal of LfD is to identify significant movement primitives (MPs) from human demonstrations and then recompose those intrinsic primitives to adapt to a variety of new situations. However, maintaining the simplicity of MPs representation while guaranteeing their adaptability is not an easy undertaking. To achieve these two goals, two approaches are possible: (1) learning models that can capture and utilize the inherent patterns and main characteristics of the human demonstrations, and (2) dynamical systems that can respond to perturbations online without requiring to re-plan the entire trajectory. In this paper, we present a novel and efficient model that combines these two benefits to formulate MPs using a fuzzy dynamical system (Fuzzy-DS), which enables robots to adaptively alter the learned motion skills to meet various additional constraints in the process of performing tasks. Due to the joint use of a fuzzy inference system and a dynamic system, Fuzzy-DS is well-suited to human inputs and intuitive fuzzy rules, resulting in a computationally efficient model. To verify the effectiveness of the proposed method, experiments have been designed where the robot learned a plant pruning task and a pick-and-place task, subsequently, it can replicate and generalize these tasks to novel situations.},
  archive      = {J_RAS},
  author       = {Tao Teng and Matteo Gatti and Stefano Poni and Darwin Caldwell and Fei Chen},
  doi          = {10.1016/j.robot.2023.104406},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104406},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Fuzzy dynamical system for robot learning motion skills from human demonstration},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Teleoperation by seamless transitions in real and virtual
world environments. <em>RAS</em>, <em>164</em>, 104405. (<a
href="https://doi.org/10.1016/j.robot.2023.104405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates operability and acceptability issues in the teleoperation of robots. Prior studies have proposed efficient approaches to increase human perceptual ability and robot autonomy but with reduced operability and acceptance. We propose a novel teleoperation method that overcomes the weaknesses of existing approaches while inheriting their strengths. The key feature of our method is switching the teleoperated robot world from real to virtual. The user study results showed that the proposed method offered an improved user experience compared to the conventional methods, while task efficiency was equivalent in all methods. The contributions of this paper include the proposal of the teleoperation method by seamless switching between real and virtual space , the proposal of an image transformation method and visual effect to achieve seamless switching, and verification of the practicality of the proposed system through experiments on actual mobile robots.},
  archive      = {J_RAS},
  author       = {Junki Aoki and Fumihiro Sasaki and Ryota Yamashina and Ryo Kurazume},
  doi          = {10.1016/j.robot.2023.104405},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104405},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Teleoperation by seamless transitions in real and virtual world environments},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correct and efficient UAV missions based on temporal
planning and in-flight hybrid simulations. <em>RAS</em>, <em>164</em>,
104404. (<a href="https://doi.org/10.1016/j.robot.2023.104404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controller synthesis has been successfully applied in UAV applications, to construct a mission plan that is guaranteed to be correct with respect to a user-provided specification. Albeit being correct, these plans may not be optimal in the vehicle’s trajectory, battery consumption, or other criteria which the user may consider relevant. A possibility would be to apply a quantitative synthesis approach where the target is to compute efficient plans before the mission, at a higher cost of complexity and potential limitations in the optimization goals to achieve. As an alternative, in this paper we propose doing the plan optimization in-flight. For this, we use available tools that synthesize controllers with multiple controllable choices and later select among these choices in-flight using hybrid simulations ranking them according to the optimization objective . We present the advantages of our approach and validate them using software-in-the-loop simulation with typical UAV mission scenarios .},
  archive      = {J_RAS},
  author       = {Ezequiel Pecker-Marcosig and Sebastián Zudaire and Rodrigo Castro and Sebastián Uchitel},
  doi          = {10.1016/j.robot.2023.104404},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104404},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Correct and efficient UAV missions based on temporal planning and in-flight hybrid simulations},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifelong mapping in the wild: Novel strategies for ensuring
map stability and accuracy over time evaluated on thousands of robots.
<em>RAS</em>, <em>164</em>, 104403. (<a
href="https://doi.org/10.1016/j.robot.2023.104403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong mapping presents unique challenges to household robots which operate in the same environment over long durations. One is the growth of redundant information in the map as it evolves over time, which can easily overwhelm the limited computation resources of a household robot. Another is the possibility of mapping errors. An error in robot pose estimate, which if not corrected fast enough, will result in incorrect occupancy and semantic representation , rendering the map unusable. Finally, for a lifelong mapping system where the map is updated continuously, avoiding these errors altogether is infeasible. In this paper, we present a comprehensive overview of novel strategies for eliminating redundant information from the map and preventing and correcting mapping errors. We also present a detailed evaluation of these novel strategies on 10,000 robots running in indoor environments across different geographic locations of the world to demonstrate map stability and accuracy over time.},
  archive      = {J_RAS},
  author       = {Nandan Banerjee and Dimitri Lisin and Scott R. Lenser and Jimmy Briggs and Rodrigo Baravalle and Victoria Albanese and Yao Chen and Arman Karimian and Tyagaraja Ramaswamy and Pablo Pilotti and Martin Llofriu Alonso and Lucio Nardelli and Veronica Lane and Renaud Moser and Andrea Okerholm Huttlin and Justin Shriver and Phil Fong},
  doi          = {10.1016/j.robot.2023.104403},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104403},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Lifelong mapping in the wild: Novel strategies for ensuring map stability and accuracy over time evaluated on thousands of robots},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Whole body motion generation with centroidal dynamics of
legged robots using sequential bounds tightening of McCormick envelopes.
<em>RAS</em>, <em>164</em>, 104401. (<a
href="https://doi.org/10.1016/j.robot.2023.104401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce a Sequential Convex Programming (SCP) algorithm for the motion generation with the centroidal dynamics of legged robots using a sequential bounds tightening of McCormick envelopes strategy to cope with the nonconvexity of the problem (related to bilinear terms). Therefore, the proposed SCP algorithm is initialized with relaxed McCormick envelopes and then their bounds are sequentially tightened around the current estimate of the solution enforcing this way convergence to a feasible point. The SCP algorithm solves a quadratic program at each iteration by an interior point method . Additionally, the proposed SCP algorithm is alternated with an inverse kinematics algorithm to achieve the whole body motion generation. Finally, extensive numerical experiments show the effectiveness of the proposed algorithm in generating highly agile motions such as trotting, bounding, stotting and running for humanoid and quadruped robots .},
  archive      = {J_RAS},
  author       = {Jose C. Rojas-Rodriguez and Ana Y. Aguilar-Bustos and Eusebio Bugarin},
  doi          = {10.1016/j.robot.2023.104401},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104401},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Whole body motion generation with centroidal dynamics of legged robots using sequential bounds tightening of McCormick envelopes},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Roboception and adaptation in a cognitive robot.
<em>RAS</em>, <em>164</em>, 104400. (<a
href="https://doi.org/10.1016/j.robot.2023.104400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotics, perception is usually oriented at understanding what is happening in the external world, while few works pay attention to what is occurring in the robot’s body. In this work, we propose an artificial somatosensory system, embedded in a cognitive architecture, that enables a robot to perceive the sensations from its embodiment while executing a task. We called these perceptions roboceptions , and they let the robot act according to its own physical needs in addition to the task demands. Physical information is processed by the robot to behave in a balanced way, determining the most appropriate trade-off between the achievement of the task and its well being. The experiments show the integration of information from the somatosensory system and the choices that lead to the accomplishment of the task.},
  archive      = {J_RAS},
  author       = {Agnese Augello and Salvatore Gaglio and Ignazio Infantino and Umberto Maniscalco and Giovanni Pilato and Filippo Vella},
  doi          = {10.1016/j.robot.2023.104400},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104400},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Roboception and adaptation in a cognitive robot},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robotic assembly strategy via reinforcement learning based
on force and visual information. <em>RAS</em>, <em>164</em>, 104399. (<a
href="https://doi.org/10.1016/j.robot.2023.104399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since assembly tasks are frequently performed in a wide range of industries, there have been many efforts to develop robotic assembly strategies. However, robotic assembly is only applicable in structured environments wherein a target object is placed in a fixed position, because the occurrence of a large error substantially degrades performance. Thus, there is still a need for a generalized assembly strategy that can cope with a large position/orientation error regardless of the shape. To this end, this study presents an assembly strategy based on both the force and visual information. Specifically, the trajectory of the robot is obtained by combining the output of two neural-network-based trajectory generators that receive the force and image information, respectively, and then a deep reinforcement learning algorithm is applied to obtain the optimal strategy . In this process, imitation learning is applied to train the force-based network using the demonstration data collected with the suggested hand-guiding method, and the probability distribution of the feature is introduced in the image-based network to enable a robot to quickly adapt to assembly parts with different shapes. The performance of the proposed assembly strategy is experimentally verified using various peg-in-hole tasks, and the results confirm that the robot can successfully accomplish an assembly task regardless of the shapes of the assembly parts, even when the initial position/orientation error is large.},
  archive      = {J_RAS},
  author       = {Kuk-Hyun Ahn and Minwoo Na and Jae-Bok Song},
  doi          = {10.1016/j.robot.2023.104399},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104399},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robotic assembly strategy via reinforcement learning based on force and visual information},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient reinforcement learning with least-squares soft
bellman residual for robotic grasping. <em>RAS</em>, <em>164</em>,
104385. (<a href="https://doi.org/10.1016/j.robot.2023.104385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping control of intelligent robots has to deal with the difficulties of model uncertainties and nonlinearities. In this paper, we propose the Kernel-based Least-Squares Soft Bellman residual Actor–Critic (KLSAC) algorithm for robotic grasping. In the proposed approach, a novel linear temporal-difference learning algorithm using the least-squares soft Bellman residual (LS 2 2 BR) method is designed for policy evaluation. In addition, KLSAC adopts a sparse-kernel feature representation method based on approximate linear dependency (ALD) analysis to construct features for continuous state–action space. Compared with typical deep reinforcement learning algorithms, KLSAC has two main advantages: firstly, the critic module has the capacity for rapid convergence by computing the fixed point of the linear soft Bellman equation via the least-squares optimization method. Secondly, the kernel-based features construction approach only requires predefining the basic kernel function and can improve the generalization ability of KLSAC. The simulation studies on robotic grasping control were conducted in the V-REP simulator. The results demonstrate that compared with other typical RL algorithms (e.g., SAC and BMPO), the proposed KLSAC algorithm can achieve better performance in terms of sample efficiency and asymptotic convergence property . Furthermore, experimental results on a real UR5 robot validated that KLSAC performed well in the real world.},
  archive      = {J_RAS},
  author       = {Yixing Lan and Junkai Ren and Tao Tang and Xin Xu and Yifei Shi and Zixin Tang},
  doi          = {10.1016/j.robot.2023.104385},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104385},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Efficient reinforcement learning with least-squares soft bellman residual for robotic grasping},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Practical whole-body elasto-geometric calibration of a
humanoid robot: Application to the TALOS robot. <em>RAS</em>,
<em>164</em>, 104365. (<a
href="https://doi.org/10.1016/j.robot.2023.104365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The whole-body elasto-geometrical calibration of humanoid robots is critical particularly for their control and accurate simulation. However, it is often not considered probably since it is a nontrivial task due to the mechanical complexity and inherent constraints of anthropomorphic structures. Also, humanoid robots have to sustain great efforts on their support legs, leading to link and joint being deformed, and are prone to auto-collision. Thus, elastic parameters have to be factored in addition to the geometric ones and to improve the precision of the pose of all robot segments. This is much more cumbersome and time consuming than the classical calibration of serial manipulators that deals solely with the estimation of the pose of the end-effector. Finally, due to the complexity of the task, a manual intervention in several steps of the calibration is no longer possible and a thorough automation of the approach is needed. Therefore, we propose to use a stereophotogrammetric system along with embedded joint torque sensors to calibrate the pose of all robot links with a fully automatic procedure. The generation of the minimal set of optimal calibration postures is based on a new iterative optimization process that leads to a stable maximum of an observability index. Then full set of geometrical parameters but also joint and base elastic parameters were calibrated using a single least-square optimization program. The proposed method was validated on a TALOS humanoid robot allowing to obtain an accurate whole-body calibration in less than 10 min. The proposed approach was cross-validated experimentally and showed an average RMS error of the tracked markers of 2.2 mm.},
  archive      = {J_RAS},
  author       = {Vincent Bonnet and Joseph Mirabel and David Daney and Florent Lamiraux and Maxime Gautier and Olivier Stasse},
  doi          = {10.1016/j.robot.2023.104365},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104365},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Practical whole-body elasto-geometric calibration of a humanoid robot: Application to the TALOS robot},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ArTuga: A novel multimodal fiducial marker for aerial
robotics. <em>RAS</em>, <em>163</em>, 104398. (<a
href="https://doi.org/10.1016/j.robot.2023.104398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For Vertical Take-Off and Landing Unmanned Aerial Vehicles (VTOL UAVs) to operate autonomously and effectively, it is mandatory to endow them with precise landing abilities. The UAV has to be able to detect the landing target and to perform the landing maneuver without compromising its own safety and the integrity of its surroundings. However, current UAVs do not present the required robustness and reliability for precise landing in highly demanding scenarios, particularly due to their inadequacy to perform accordingly under challenging lighting and weather conditions, including in day and night operations. This work proposes a multimodal fiducial marker , named ArTuga (Augmented Reality Tag for Unmanned vision-Guided Aircraft), capable of being detected by an heterogeneous perception system for accurate and precise landing in challenging environments and daylight conditions. This research combines photometric and radiometric information by proposing a real-time multimodal fusion technique that ensures a robust and reliable detection of the landing target in severe environments. Experimental results using a real multicopter UAV show that the system was able to detect the proposed marker in adverse conditions (such as at different heights, with intense sunlight and in dark environments). The obtained average accuracy for position estimation at 1 m height was of 0.0060 m with a standard deviation of 0.0003 m. Precise landing tests obtained an average deviation of 0.027 m from the proposed marker, with a standard deviation of 0.026 m. These results demonstrate the relevance of the proposed system for the precise landing in adverse conditions, such as in day and night operations with harsh weather conditions.},
  archive      = {J_RAS},
  author       = {Rafael Marques Claro and Diogo Brandão Silva and Andry Maykol Pinto},
  doi          = {10.1016/j.robot.2023.104398},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104398},
  shortjournal = {Robot. Auton. Syst.},
  title        = {ArTuga: A novel multimodal fiducial marker for aerial robotics},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heel-strike and toe-off walking of humanoid robot using
quadratic programming considering the foot contact states. <em>RAS</em>,
<em>163</em>, 104396. (<a
href="https://doi.org/10.1016/j.robot.2023.104396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heel-strike and toe-off (heel-toe) walking has been studied to increase step length, reduce the torque of the leg joints , or make robots walk similarly to humans. To realize heel-toe walking, it is necessary to determine the foot angle and ensure contact between the ground and the heel and toe. The foot angle for heel-toe walking can be analytically calculated considering the position of the center of mass (CoM) before the foot lands or rises. Therefore, the trajectory of the CoM of one cycle of walking must be known in advance. However, this method cannot be easily incorporated with model predictive control (MPC) to generate the trajectory of CoM in real time. This paper proposes a heel-toe walking method that can be used with the CoM trajectory generated using the MPC scheme. The CoM trajectory generation method that reduced the velocity fluctuation using MPC, which was proposed in a previous study, was used. The stability of the MPC scheme is proved in this paper. The quadratic programming is used to generate the heel-toe walking by considering the foot contact states as the constraints. The increase in step length and the decrease in singularity occurrence due to heel-toe walking were compared and analyzed in the simulation. The experiment verified the proposed heel-toe method.},
  archive      = {J_RAS},
  author       = {Beomyeong Park and Jaeheung Park},
  doi          = {10.1016/j.robot.2023.104396},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104396},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Heel-strike and toe-off walking of humanoid robot using quadratic programming considering the foot contact states},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Specification, stochastic modeling and analysis of
interactive service robotic applications. <em>RAS</em>, <em>163</em>,
104387. (<a href="https://doi.org/10.1016/j.robot.2023.104387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assistive robotic systems are quickly becoming a core technology for the service sector as they are understood capable of supporting people in need of assistance in a wide variety of tasks. This step poses a number of ethical and technological questions. The research community is wondering how service robotics can be a step forward in human care and aid, and how robotics applications can be realized in order to put the human role at the forefront. Therefore, there is a growing demand for frameworks supporting robotic application designers in a “human-aware” development process. This paper presents a model-driven framework for analyzing and developing human–robot interactive scenarios in non-industrial settings with significant sources of uncertainty. The framework’s core is a formal model of the agents at play – the humans and the robot – and the robot’s mission, which is then put through verification to estimate the probability of completing the mission. The model captures non-trivial features related to human behavior, specifically the unpredictability of human choices and physiological aspects tied to their state of health. To foster the framework’s accessibility, we present a verification tool-agnostic Domain-Specific Language that allows designers lacking expertise in formal modeling to configure the interactive scenarios in a user-friendly manner. We compare the formal analysis outputs with results obtained by deploying benchmark scenarios in the physical environment with a real mobile robot to assess whether the formal model adheres to reality and whether the verification results are accurate. The entire development pipeline is then tested on several scenarios from the healthcare setting to assess its flexibility and effectiveness in the application design process.},
  archive      = {J_RAS},
  author       = {Livia Lestingi and Davide Zerla and Marcello M. Bersani and Matteo Rossi},
  doi          = {10.1016/j.robot.2023.104387},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104387},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Specification, stochastic modeling and analysis of interactive service robotic applications},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mission specification and decomposition for multi-robot
systems. <em>RAS</em>, <em>163</em>, 104386. (<a
href="https://doi.org/10.1016/j.robot.2023.104386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service robots are increasingly being used to perform missions comprising dangerous or tedious tasks previously executed by humans. However, their users—who know the environment and requirements for these missions—have limited or no robotics experience. As such, they often find the process of allocating concrete tasks to each robot within a multi-robot system (MRS) very challenging. Our paper introduces a framework for Mu l t i- Ro bot mission S pecification and d e composition (MutRoSe) that simplifies and automates key activities of this process. To that end, MutRoSe allows an MRS mission designer to define all relevant aspects of a mission and its environment in a high-level specification language that accounts for the variability of real-world scenarios, the dependencies between task instances, and the reusability of task libraries. Additionally, MutRoSe automates the decomposition of MRS missions defined in this language into task instances, which can then be allocated to specific robots for execution—with all task dependencies appropriately taken into account. We illustrate the application of MutRoSe and show its effectiveness for four missions taken from a recently published repository of MRS applications.},
  archive      = {J_RAS},
  author       = {Eric Bernd Gil and Genaína Nunes Rodrigues and Patrizio Pelliccione and Radu Calinescu},
  doi          = {10.1016/j.robot.2023.104386},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104386},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Mission specification and decomposition for multi-robot systems},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe deep learning-based global path planning using a fast
collision-free path generator. <em>RAS</em>, <em>163</em>, 104384. (<a
href="https://doi.org/10.1016/j.robot.2023.104384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, a global path planning method based on recurrent neural networks by means of a new Loss function is presented, which regardless of the complexity of the configuration space , generates the path in a relatively constant time. The new Loss function is defined in such a way that in addition to learning the input data of the network, it creates an adjustable safety margin around the obstacles and ultimately creates a safe path. Moreover, a new global path planning method is also introduced, which is used to create the dataset required to train the proposed neural network . The convergence of this method is mathematically proven and it is shown that this method can also produce a suboptimal path in a much shorter time than the common methods of global path planning reported in the literature. In short, the main purpose of this research consists in providing a method which can create a suboptimal, fast and safe path for a mobile robot from any random starting point to any random destination in a known environment. First, the proposed methods will be implemented for different two-dimensional environments consisting of convex and non-convex obstacles, considering the robot as a point-mass, and then it will be implemented in a simulation environment, AI2THOR. Compared to classical global path planning algorithms, such as RRT and A*, the proposed approach demonstrates better performance in complex and challenging environments.},
  archive      = {J_RAS},
  author       = {Shirin Chehelgami and Erfan Ashtari and Mohammad Amin Basiri and Mehdi Tale Masouleh and Ahmad Kalhor},
  doi          = {10.1016/j.robot.2023.104384},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104384},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Safe deep learning-based global path planning using a fast collision-free path generator},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iterative reward shaping for non-overshooting altitude
control of a wing-in-ground craft based on deep reinforcement learning.
<em>RAS</em>, <em>163</em>, 104383. (<a
href="https://doi.org/10.1016/j.robot.2023.104383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a wing-in-ground craft (WIG) adjusts its flying altitude, overshooting behavior may occur, which weakens the safety and stealth ability. In previous studies on path following, cross-track error was used in company with other indicators to indirectly suppress overshoot. This paper proposes a method for direct and gradual suppression of the overshoot via deep reinforcement learning (DRL), which iterates the reward function by introducing a partial one based on the current overshoot magnitude. Each time the overshoot is obtained by DRL, a function about this overshoot is added to the reward function for retraining. The function is defined as a type of cross-track error within a range of the current overshoot magnitude to the target altitude, and it counts the partial reward before the WIG gets the worse overshoot during training. The methodological feasibility is proved by mathematical reasoning , and an example of a virtual WIG changing the altitude is taken to validate the method. Assuming that the added partial function is in a basic 1-order fractional form of cross-track error and multiplied by a factor, the implementation of iterative reward shaping decreases overshoot to a minimal level, with the overshoot down to over 99.8\% when compared to the initial one. Moreover, when introducing the partial reward function in the first iteration, influence of the factor on overshoot is analyzed. For a WIG’s adjustment of altitude, the method can monotonically reduce overshoot within tolerance.},
  archive      = {J_RAS},
  author       = {Huan Hu and Guiyong Zhang and Lichao Ding and Kuikui Jiao and Zhifan Zhang and Ji Zhang},
  doi          = {10.1016/j.robot.2023.104383},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104383},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Iterative reward shaping for non-overshooting altitude control of a wing-in-ground craft based on deep reinforcement learning},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parallel multi-speed pursuit-evasion game algorithms.
<em>RAS</em>, <em>163</em>, 104382. (<a
href="https://doi.org/10.1016/j.robot.2023.104382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pursuit-Evasion Game (PEG) consists of a team of pursuers trying to capture one or more evaders. PEG is important due to its application in surveillance, search and rescue, disaster robotics, boundary defense and so on. In general, PEG requires exponential time to compute the minimum number of pursuers to capture an evader. To mitigate this, we have designed a parallel optimal algorithm to minimize the capture time in PEG. Given a discrete topology , this algorithm also outputs the minimum number of pursuers to capture an evader. We also extended parallel algorithm to consider other versions as: heterogeneous/multi-speed players; the pac-dot technique to increase evader lifetime in a game; and a pruning strategy for pac-dot technique to increase the scalability. The parallel algorithm performance was evaluated by speedup metric and this algorithm and its extensions were simulated and evaluated on many different topologies to validate the viability of our algorithms by discussing and evaluating a set of simulation results. The parallel algorithm enables us to scale up to 8.13 times with 8 cores compared to state-of-the-art. Considering the complexity of the state space growing up, pruning technique to pac-dot algorithm minimizes the state space and generated transition, and can handle a large number of states ( ≈ ≈ 830 M M ) and transitions ( ≈ ≈ 11 G G ) generated. In general, our algorithms increase the scalability and make it feasible to compute the PEG optimal strategy for more realistic cases.},
  archive      = {J_RAS},
  author       = {Renato F. dos Santos and Ragesh K. Ramachandran and Marcos A.M. Vieira and Gaurav S. Sukhatme},
  doi          = {10.1016/j.robot.2023.104382},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104382},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Parallel multi-speed pursuit-evasion game algorithms},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model predictive optimization for imitation learning from
demonstrations. <em>RAS</em>, <em>163</em>, 104381. (<a
href="https://doi.org/10.1016/j.robot.2023.104381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Motion generation by imitating” enables a robot to generate its trajectory in a new environment. Research works on dynamic movement primitives (DMP) has reported promising results, with good imitation effect and convergence to the target. However, DMP still has issues such as learning from multiple demonstrations for different initial conditions and achieving obstacle avoidance considering the distribution and motion of obstacles. One of the effective solutions is combining DMP and model predictive control (MPC). The imitation process was transformed into a receding horizon planning procedure, letting the robot to learn more from nearer demonstrations. It is solved as an optimization problem with obstacles modeled as constraints. However, its drawback includes the heavy computation burden, which can be even aggravated in a multi-obstacle scenario where complicated constraints occur. Thus, in this paper, we propose an enhanced MPDMP+ method that combines the advantages of MPC with potential function for both multi-demonstration imitation and multi-obstacle avoidance effect. A proximal augmented Lagrangian method is proposed to solve the optimization problem . This proposed method has a faster convergence rate and small errors. We conducted the simulation and robot experiments for imitation learning for obstacle avoidance scenarios. Our results illustrate the superior performance of the proposed method.},
  archive      = {J_RAS},
  author       = {Yingbai Hu and Mingyang Cui and Jianghua Duan and Wenjun Liu and Dianye Huang and Alois Knoll and Guang Chen},
  doi          = {10.1016/j.robot.2023.104381},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104381},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Model predictive optimization for imitation learning from demonstrations},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on the 10th european conference on mobile
robots (ECMR 2021). <em>RAS</em>, <em>163</em>, 104380. (<a
href="https://doi.org/10.1016/j.robot.2023.104380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_RAS},
  author       = {Chris McCool and Emanuele Menegatti and Sven Behnke},
  doi          = {10.1016/j.robot.2023.104380},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104380},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Special issue on the 10th european conference on mobile robots (ECMR 2021)},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The XBot2 real-time middleware for robotics. <em>RAS</em>,
<em>163</em>, 104379. (<a
href="https://doi.org/10.1016/j.robot.2023.104379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces XBot2 , a novel real-time middleware for robotic applications with a strong focus on modularity and reusability of components, and seamless support for multi-threaded, mixed real-time (RT) and non-RT architectures. Compared to previous works, XBot2 focuses on providing a dynamic, ready-to-use hardware abstraction layer that allows users to make run-time queries about the robot topology, and act consequently, by leveraging an easy-to-use API that is fully RT-compatible. We provide an extensive description about implementation challenges and design decisions, and finally validate our architecture with multiple use-cases. These range from the integration of three popular simulation tools (i.e. Gazebo, PyBullet, and MuJoCo), to real-world tests involving complex, hybrid robotic platforms such as IIT’s CENTAURO and MoCA robots.},
  archive      = {J_RAS},
  author       = {Arturo Laurenzi and Davide Antonucci and Nikos G. Tsagarakis and Luca Muratore},
  doi          = {10.1016/j.robot.2023.104379},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104379},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The XBot2 real-time middleware for robotics},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using model checking to formally verify rendezvous
algorithms for robots with lights in euclidean space. <em>RAS</em>,
<em>163</em>, 104378. (<a
href="https://doi.org/10.1016/j.robot.2023.104378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper details the first successful attempt at using model checking techniques to verify the correctness of distributed algorithms for robots evolving in a continuous environment. The study focuses on the problem of rendezvous of two robots with lights. There exist many different rendezvous algorithms that aim at finding the minimal number of colors needed to solve rendezvous in various synchrony models ( e.g. , FSYNC, SSYNC, ASYNC). While these rendezvous algorithms are typically very simple, their analysis and proof of correctness tend to be extremely complex, tedious, and error-prone as impossibility results are based on subtle interactions between the activation schedules of the robots. The paper presents a generic verification model that can be concretely expressed in available software model-checkers. In particular, we explain the subtle design decisions that allow to keep the search space finite and tractable, as well as prove several important theorems that support them. As a sanity check, we use the model to verify several known rendezvous algorithms in six different models of synchrony. In each case, we find that the results obtained from the model checker are consistent with the results known in the literature. The model checker outputs a counter-example execution in every case that is known to fail. In the course of developing and proving the validity of the model, we identified several fundamental theorems , including the ability for a well chosen algorithm and ASYNC scheduler to produce an emerging property of memory in a system of oblivious mobile robots, and why it is not a problem when robots executing the gathering algorithms are equipped with lights.},
  archive      = {J_RAS},
  author       = {Xavier Défago and Adam Heriban and Sébastien Tixeuil and Koichi Wada},
  doi          = {10.1016/j.robot.2023.104378},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104378},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Using model checking to formally verify rendezvous algorithms for robots with lights in euclidean space},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kinematics optimization of a novel 7-DOF redundant
manipulator. <em>RAS</em>, <em>163</em>, 104377. (<a
href="https://doi.org/10.1016/j.robot.2023.104377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Redundant manipulators can accomplish complex tasks due to the redundant degree of freedom (DOF). At the same time, their kinematics calculations are complicated. In this study, the kinematics solution for a self-designed 7-DOF redundant anthropomorphic manipulator is obtained, and an optimization method is provided to optimize the motion time of the manipulator in the same trajectory. Kinematics analysis of the spherical parallel shoulder joint was performed by using a geometric method and coordinate transformation. Kinematics analysis of the redundant manipulator was performed by a geometric method with an optimizing arm angle. Linearly decreasing weight particle swarm optimization (LDWPSO) was used to optimize the arm angle to minimize the motion time of the manipulator. The kinematics calculation of the shoulder joint was verified by a combination of SOLIDWORKS T M TM and MATLAB T M TM software. The kinematics calculation of the redundant manipulator was verified by MATLAB T M TM . The linear, circular and 8-shaped motion trajectories were used to evaluate the proposed method in the simulation. The simulation results showed that the motion time with optimization of the arm angle was only 16\%–30\% of that without optimization. Furthermore, the proposed method was evaluated through real manipulator experiments, and the experimental results were similar to those in the simulation.},
  archive      = {J_RAS},
  author       = {Yanlin Chen and Xianmin Zhang and Yanjiang Huang and Yanbin Wu and Jun Ota},
  doi          = {10.1016/j.robot.2023.104377},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104377},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Kinematics optimization of a novel 7-DOF redundant manipulator},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A causal-based approach to explain, predict and prevent
failures in robotic tasks. <em>RAS</em>, <em>162</em>, 104376. (<a
href="https://doi.org/10.1016/j.robot.2023.104376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots working in human environments need to adapt to unexpected changes to avoid failures. This is an open and complex challenge that requires robots to timely predict and identify the causes of failures in order to prevent them. In this paper, we present a causal-based method that will enable robots to predict when errors are likely to occur and prevent them from happening by executing a corrective action. Our proposed method is able to predict immediate failures and also failures that will occur in the future. The latter type of failure is very challenging, and we call them timely-shifted action failures (e.g., the current action was successful but will negatively affect the success of future actions). First, our method detects the cause–effect relationships between task executions and their consequences by learning a causal Bayesian network (BN). The obtained model is transferred from simulated data to real scenarios to demonstrate the robustness and generalization of the obtained models. Based on the causal BN, the robot can predict if and why the executed action will succeed or not in its current state. Then, we introduce a novel method that finds the closest success state through a contrastive Breadth-First-Search if the current action was predicted to fail. We evaluate our approach for the problem of stacking cubes in two cases; (a) single stacks (stacking one cube) and; (b) multiple stacks (stacking three cubes). In the single-stack case, our method was able to reduce the error rate by 97\%. We also show that our approach can scale to capture various actions in one model, allowing us to measure the impact of an imprecise stack of the first cube on the stacking success of the third cube. For these complex situations, our model was able to prevent around 95\% of the stacking errors. Thus, demonstrating that our method is able to explain, predict, and prevent execution failures, which even scales to complex scenarios that require an understanding of how the action history impacts future actions.},
  archive      = {J_RAS},
  author       = {Maximilian Diehl and Karinne Ramirez-Amaro},
  doi          = {10.1016/j.robot.2023.104376},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104376},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A causal-based approach to explain, predict and prevent failures in robotic tasks},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical mixture of experts for autonomous unmanned
aerial vehicles utilizing thrust models and acoustics. <em>RAS</em>,
<em>162</em>, 104369. (<a
href="https://doi.org/10.1016/j.robot.2023.104369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate position, velocity, attitude, and angular velocity state estimation is crucial for unmanned aerial vehicles , especially in enabling them with autonomous capabilities. It is necessary to adequately model and account for all the environmental and dynamic flight parameters . A hierarchical mixture of experts (HME) framework has been viable in improving state estimation accuracy in interplanetary orbit determination problems, and this paper proposes an extension for quadcopters. It is shown that the state and motor angular velocity estimation accuracy can be significantly improved by processing different thrust models, and acoustic parameters have an important, previously unreported, role in this improvement. Higher motor angular velocities produce higher noise levels, and thus, the relationships of the onboard acoustic measurements to the vehicle state parameters play an essential part in estimation. The motor angular velocities’ estimations depend on the extended Kalman filter solutions or an acoustic curve fit. The experts in the HME framework utilize the state estimation solutions from the extended Kalman filters and the motor angular velocity estimations to compare against the telemetry data as truth. The overall HME solution is compared against a non-acoustic static thrust model. Illustrative examples and analysis presented in this paper reveal that the proposed estimation solutions can also apply to other flight vehicles for onboard real-time implementation to leverage autonomy.},
  archive      = {J_RAS},
  author       = {Evan Kawamura and Dilmurat Azimov and John S. Allen and Corey Ippolito},
  doi          = {10.1016/j.robot.2023.104369},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104369},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Hierarchical mixture of experts for autonomous unmanned aerial vehicles utilizing thrust models and acoustics},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed control for a robotic swarm to pass through a
curve virtual tube. <em>RAS</em>, <em>162</em>, 104368. (<a
href="https://doi.org/10.1016/j.robot.2023.104368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To guide a robotic swarm in a cluttered environment, a curve virtual tube is designed in this paper. There is no obstacle within the curve virtual tube, and the area inside can be seen as a safety zone. Then, a distributed swarm controller is proposed with three elaborate control terms. Formal analyses and proofs show that the curve virtual tube passing-through control problem can be solved in a finite time. For convenience in practical use, a modified controller with an approximate control performance is put forward. Some control laws for different types of robots to track their vector fields are also presented. The effectiveness of the proposed method is validated by numerical simulations and real experiments. To show the advantages of the proposed method, the comparisons between our method and other methods are also presented.},
  archive      = {J_RAS},
  author       = {Quan Quan and Yan Gao and Chenggang Bai},
  doi          = {10.1016/j.robot.2023.104368},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104368},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Distributed control for a robotic swarm to pass through a curve virtual tube},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online task segmentation by merging symbolic and data-driven
skill recognition during kinesthetic teaching. <em>RAS</em>,
<em>162</em>, 104367. (<a
href="https://doi.org/10.1016/j.robot.2023.104367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming by Demonstration (PbD) is used to transfer a task from a human teacher to a robot, where it is of high interest to understand the underlying structure of what has been demonstrated. Such a demonstrated task can be represented as a sequence of so-called actions or skills. This work focuses on the recognition part of the task transfer. We propose a framework that recognizes skills online during a kinesthetic demonstration by means of position and force–torque (wrench) sensing. Therefore, our framework works independently of visual perception. The recognized skill sequence constitutes a task representation that lets the user intuitively understand what the robot has learned. The skill recognition algorithm combines symbolic skill segmentation, which makes use of pre- and post-conditions, and data-driven prediction, which uses support vector machines for skill classification. This combines the advantages of both techniques, which is inexpensive evaluation of symbols and usage of data-driven classification of complex observations. The framework is thus able to detect a larger variety of skills, such as manipulation and force-based skills that can be used in assembly tasks. The applicability of our framework is proven in a user study that achieves a 96\% accuracy in the online skill recognition capabilities and highlights the benefits of the generated task representation in comparison to a baseline representation. The results show that the task load could be reduced, trust and explainability could be increased, and, that the users were able to debug the robot program using the generated task representation.},
  archive      = {J_RAS},
  author       = {Thomas Eiband and Johanna Liebl and Christoph Willibald and Dongheui Lee},
  doi          = {10.1016/j.robot.2023.104367},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104367},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Online task segmentation by merging symbolic and data-driven skill recognition during kinesthetic teaching},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy efficient path planning for autonomous ground
vehicles with ackermann steering. <em>RAS</em>, <em>162</em>, 104366.
(<a href="https://doi.org/10.1016/j.robot.2023.104366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The autonomous ground vehicles have attracted a great deal of attention as viable solutions to a wide variety of military and civilian applications. However, the energy consumption plays a major role in the navigation of autonomous ground vehicles in challenging environments, especially if they are left to operate unattended under limited on-board power, such as planetary exploration, border patrol, etc. The autonomous ground vehicles are expected to perform more tasks more efficiently with limited power in these scenarios. Although plenty of research has developed an effective methodology for generating dynamically feasible and energy efficient trajectories for skid steering or differential steering vehicles, few studies on path planning for ackermann steering autonomous ground vehicles are available. In this study, an energy efficient path planning method with guarantee on completeness is proposed for autonomous ground vehicle with ackermann steering which is based on A ∗ A∗ search algorithm. Firstly, the energy cost model is established for the autonomous ground vehicle using its kinematic constraints. Then, given the start and goal states, the energy-aware motion primitives are generated offline using the energy cost model to calculate the cost of each primary trajectory. Lastly, the energy efficient path planner is proposed and the analysis for completeness properties is given. The effectiveness of the proposed energy efficient path planner is verified by simulation over 150 randomly generated maps and real vehicle tests. The results show that a small increase in the distance of a path over the distance optimal path can result in a reduction of energy cost by nearly 26.9\% in simulation and 21.09\% in real test scenario for autonomous ground vehicles with ackermann steering.},
  archive      = {J_RAS},
  author       = {Haojie Zhang and Yudong Zhang and Chuankai Liu and Zuoyu Zhang},
  doi          = {10.1016/j.robot.2023.104366},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104366},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Energy efficient path planning for autonomous ground vehicles with ackermann steering},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart agriculture: Development of a skid-steer autonomous
robot with advanced model predictive controllers. <em>RAS</em>,
<em>162</em>, 104364. (<a
href="https://doi.org/10.1016/j.robot.2023.104364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The agricultural domain has been experiencing extensive automation interest over the past decade. The established process for measuring physiological and morphological traits (phenotypes) of crops is labour-intensive and error-prone. In this paper, a mobile robotic platform , namely The Autonomous Robot for Orchard Surveying (AROS), was developed to automate the process of collecting spatial and visual data autonomously. Furthermore, six different control frameworks are presented to evaluate the feasibility of using a kinematic model in agricultural environments. The kinematic model does not consider wheel slippage or any forces associated with dynamic motion. Thus, the following six controllers are evaluated: Proportional-Derivative (PD) controller, Sliding Mode Controller (SMC), Control-Lyapunov Function (CLF), Nonlinear Model Predictive Controller (NMPC), Tube-Based Nonlinear Model Predictive Controller (TBNMPC), and Model Predictive Sliding Mode Control (MPSMC). This paper provides insight into the degree of disturbance rejection that the mentioned control architectures can achieve in outdoor environments. Experimental results validate that all control architectures are capable of rejecting the present disturbances associated with unmodelled dynamics and wheel slip on soft ground conditions. Additionally, the optimal-based controllers managed to perform better than the non-optimal controllers. Performance improvements of the TBNMPC of up to 209.72\% are realized when compared to non-optimal methods. Results also show that the non-optimal controllers had low performance due to the underactuated constraint present in the kinematic model.},
  archive      = {J_RAS},
  author       = {Cesar Wen Zhu and Elyse Hill and Mohammad Biglarbegian and S. Andrew Gadsden and John A. Cline},
  doi          = {10.1016/j.robot.2023.104364},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104364},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Smart agriculture: Development of a skid-steer autonomous robot with advanced model predictive controllers},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Precision fingertip grasp: A human-inspired grasp planning
and inverse kinematics approach for integrated arm–hand systems.
<em>RAS</em>, <em>162</em>, 104348. (<a
href="https://doi.org/10.1016/j.robot.2022.104348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a human-inspired approach to solve grasp planning and inverse kinematics (IK) problems, simultaneously. Our proposed solution is for integrated arm–hand systems. Conventional approaches consider the robot manipulator (arm) and the robotic hand separately and solve the problems of grasp planning and IK in sequence. Such separate considerations of the arm and hand often introduce errors in the IK solution. The sequential approaches waste significant computational power in searching for infeasible grasps. To address these issues, we propose to consider the robotic arm and the hand as a kinematically integrated system . We then introduce a coarse-to-fine strategy to solve grasp planning and IK problems simultaneously. The proposed approach achieves force-closure fingertip grasping without using reachability information a priori. Instead, through an integrated grasp planning and IK solution, the reachability information is obtained from the IK solution and is used to filter out infeasible grasps. This strategy will dramatically reduce the search space and save significant computational power. Numerical examples will be used to demonstrate the efficiency of the proposed approach, in comparison to a sequential solution of the grasp planning and IK for integrated arm–hand systems.},
  archive      = {J_RAS},
  author       = {Shuwei Qiu and Mehrdad R. Kermani},
  doi          = {10.1016/j.robot.2022.104348},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104348},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Precision fingertip grasp: A human-inspired grasp planning and inverse kinematics approach for integrated arm–hand systems},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rendering the directional TSDF for tracking and multi-sensor
registration with point-to-plane scale ICP. <em>RAS</em>, <em>162</em>,
104337. (<a href="https://doi.org/10.1016/j.robot.2022.104337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense real-time tracking and mapping from RGB-D images is an important tool for many robotic applications , such as navigation and manipulation. The recently presented Directional Truncated Signed Distance Function (DTSDF) is an augmentation of the regular TSDF that shows potential for more coherent maps and improved tracking performance. In this work, we present methods for rendering depth- and color images from the DTSDF, making it a true drop-in replacement for the regular TSDF in established trackers. We evaluate the algorithm on well-established datasets and observe that our method improves tracking performance and increases re-usability of mapped scenes. Furthermore, we add color integration which notably improves color-correctness at adjacent surfaces. Our novel formulation of combined ICP with frame-to-keyframe photometric error minimization further improves tracking results. Lastly, we introduce Sim Sim (3) point-to-plane ICP for refining pose priors in a multi-sensor scenario with different scale factors.},
  archive      = {J_RAS},
  author       = {Malte Splietker and Sven Behnke},
  doi          = {10.1016/j.robot.2022.104337},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104337},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Rendering the directional TSDF for tracking and multi-sensor registration with point-to-plane scale ICP},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Object-wise comparison of LiDAR occupancy grid scan
rendering methods. <em>RAS</em>, <em>161</em>, 104363. (<a
href="https://doi.org/10.1016/j.robot.2023.104363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing Occupancy grids with LiDAR data, is a popular strategy for environment representation. In the last two decades, several authors have proposed different methods to render the sensed information into the grids, seeking to obtain computational efficiency or accurate environment modeling. However, no comparison regarding their performance under object detection in autonomous driving applications has been found in the literature. As a result, this work compares six representative LiDAR scan rendering strategies in a quantitative manner. To that end, a novel quantitative evaluation framework for occupancy grids is proposed. It addresses the two main steps of object detection: object segmentation and features estimation, proposing a meaningful procedure, repeatable with other OG approaches. The code of this evaluation framework is available in https://git-autopia.car.upm-csic.es/open_source/occupancy_grid_object_detection_evaluation.git .},
  archive      = {J_RAS},
  author       = {Víctor Jiménez and Jorge Godoy and Antonio Artuñedo and Jorge Villagra},
  doi          = {10.1016/j.robot.2023.104363},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104363},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Object-wise comparison of LiDAR occupancy grid scan rendering methods},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum planning for swarm robotics. <em>RAS</em>,
<em>161</em>, 104362. (<a
href="https://doi.org/10.1016/j.robot.2023.104362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational resources of quantum computing can enhance robotic motion, decision making, and path planning . While the quantum paradigm is being applied to individual robots, its approach to swarms of simple and interacting robots remains largely unexplored. In this paper, we attempt to bridge the gap between swarm robotics and quantum computing, in the framework of a search and rescue mission. We focus on a decision-making and path-planning collective task. Thus, we present a quantum-based path-planning algorithm for a swarm of robots. Quantization enters position and reward information (measured as a robot’s proximity to the target) and path-planning decisions. Pairwise information-exchange is modeled through a logic gate , implemented with a quantum circuit . Path planning draws upon Grover’s search algorithm, implemented with another quantum circuit. Our case study involves a search and rescue scenario, inspired by ant-foraging behavior in nature, as an example of swarm intelligence . We show that our method outperforms two ant-behavior simulations, in NetLogo and Java, respectively, presenting a faster convergence to the target, represented here by the source of food. This study can shed light on future applications of quantum computing to swarm robotics.},
  archive      = {J_RAS},
  author       = {Antonio Chella and Salvatore Gaglio and Maria Mannone and Giovanni Pilato and Valeria Seidita and Filippo Vella and Salvatore Zammuto},
  doi          = {10.1016/j.robot.2023.104362},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104362},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Quantum planning for swarm robotics},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Message flow analysis with complex causal links for
distributed ROS 2 systems. <em>RAS</em>, <em>161</em>, 104361. (<a
href="https://doi.org/10.1016/j.robot.2022.104361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed robotic systems rely heavily on the publish–subscribe communication paradigm and middleware frameworks that support it, such as the Robot Operating System (ROS), to efficiently implement modular computation graphs . The ROS 2 executor, a high-level task scheduler which handles ROS 2 messages, is a performance bottleneck . We extend ros2_tracing , a framework with instrumentation and tools for real-time tracing of ROS 2, with the analysis and visualization of the flow of messages across distributed ROS 2 systems. Our method detects one-to-many and many-to-many causal links between input and output messages, including indirect causal links through simple user-level annotations. We validate our method on both synthetic and real robotic systems , and demonstrate its low runtime overhead. Moreover, the underlying intermediate execution representation database can be further leveraged to extract additional metrics and high-level results. This can provide valuable timing and scheduling information to further study and improve the ROS 2 executor as well as optimize any ROS 2 system. The source code is available at: github.com/christophebedard/ros2-message-flow-analysis .},
  archive      = {J_RAS},
  author       = {Christophe Bédard and Pierre-Yves Lajoie and Giovanni Beltrame and Michel Dagenais},
  doi          = {10.1016/j.robot.2022.104361},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104361},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Message flow analysis with complex causal links for distributed ROS 2 systems},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal strategies of a pursuit-evasion game with three
pursuers and one superior evader. <em>RAS</em>, <em>161</em>, 104360.
(<a href="https://doi.org/10.1016/j.robot.2022.104360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We attempt to solve the pursuit-evasion game of a faster evader being surrounded by three pursuers. The complexity of the game under study stems from the holonomic motion of the agents. This game has not been solved either in the sense of presenting optimal trajectories or in the sense of feedback strategies. There exist heuristic strategies, and solutions to similar but simpler games which will be of use. We present a solution for the optimal trajectories of the game, but we do not prove optimality . Then, we synthesize feedback strategies for both parties based on the proposed trajectories.},
  archive      = {J_RAS},
  author       = {János Szőts and István Harmati},
  doi          = {10.1016/j.robot.2022.104360},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104360},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Optimal strategies of a pursuit-evasion game with three pursuers and one superior evader},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-in-the-loop layered architecture for control of a
wearable ankle–foot robot. <em>RAS</em>, <em>161</em>, 104353. (<a
href="https://doi.org/10.1016/j.robot.2022.104353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent wearable robotics is a promising approach for the development of devices that can interact with people and assist them in daily activities. This work presents a novel human-in-the-loop layered architecture to control a wearable robot while interacting with the human body. The proposed control architecture is composed of high-, mid- and low-level computational and control layers, together with wearable sensors , for the control of a wearable ankle–foot robot. The high-level layer uses Bayesian formulation and a competing accumulator model to estimate the human posture during the gait cycle . The mid-level layer implements a Finite State Machine (FSM) to prepare the control parameters for the wearable robot based on the decisions from the high-level layer. The low-level layer is responsible for the precise control of the wearable robot over time using a cascade proportional–integral–derivative (PID) control approach. The human-in-the-loop layered architecture is systematically validated with the control of a 3D printed wearable ankle–foot robot to assist the human foot while walking. The assistance is applied lifting up the human foot when the toe-off event is detected in the walking cycle, and the assistance is removed allowing the human foot to move down and contact the ground when the heel-contact event is detected. Overall, the experiments in offline and real-time modes, undertaken for the validation process, show the potential of the human-in-the-loop layered architecture to develop intelligent wearable robots capable of making decisions and responding fast and accurately based on the interaction with the human body.},
  archive      = {J_RAS},
  author       = {Uriel Martinez-Hernandez and Sina Firouzy and Pouyan Mehryar and Lin Meng and Craig Childs and Arjan Buis and Abbas A. Dehghani-Sanij},
  doi          = {10.1016/j.robot.2022.104353},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104353},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Human-in-the-loop layered architecture for control of a wearable ankle–foot robot},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social interaction model enhanced with speculation stage for
human trajectory prediction. <em>RAS</em>, <em>161</em>, 104352. (<a
href="https://doi.org/10.1016/j.robot.2022.104352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate human trajectory prediction is still challenging due to the complicated interactions with surroundings. A Spatio-Temporal Graph Convolution Neural Network based Social Interaction Model ( STGCNN-SIM ) is proposed to address this challenge. In addition to historical trajectory information, the presented method employs the speculated trajectories in the future to extract social interactive features and model interaction behaviors. Three social interactive features are extracted explicitly from the observed and speculated trajectories: (1) the relative distance, (2) the angle between the velocity vectors of two interacting partners, and (3) the angles between the velocity vectors of interacting partners and the distance vector. STGCNN-SIM utilizes these social interactive features to model interactions with surroundings in the historical and speculated stages. Then an attention mechanism is adopted to improve the model by focusing on more relevant features. Experimental results on three public datasets demonstrate that STGCNN-SIM achieves higher accuracy and stability than the state-of-the-art methods.},
  archive      = {J_RAS},
  author       = {Lei Pi and Qiang Zhang and Lingfang Yang and Zhi Huang},
  doi          = {10.1016/j.robot.2022.104352},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104352},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Social interaction model enhanced with speculation stage for human trajectory prediction},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning under temporal logic constraints as a
sequence modeling problem. <em>RAS</em>, <em>161</em>, 104351. (<a
href="https://doi.org/10.1016/j.robot.2022.104351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) under temporal logic typically suffers from slow propagation for credit assignment. Inspired by recent advancements called trajectory transformer in machine learning , the reinforcement learning under Temporal Logic (TL) is modeled as a sequence modeling problem in this paper, where an agent utilizes the transformer to fit the optimal policy satisfying the Finite Linear Temporal Logic ( LTL f LTLf ) tasks. To combat the sparse reward issue, dense reward functions for LTL f LTLf are designed. For the sake of reducing the computational complexity , a sparse transformer with local and global attention is constructed to automatically conduct credit assignment, which removes the time-consuming value iteration process . The optimal action is found by the beam search performed in transformers. The proposed method generates a series of policies fitted by sparse transformers, which has sustainably high accuracy in fitting the demonstrations. At last, the effectiveness of the proposed method is demonstrated by simulations in Mini-Grid environments.},
  archive      = {J_RAS},
  author       = {Daiying Tian and Hao Fang and Qingkai Yang and Haoyong Yu and Wenyu Liang and Yan Wu},
  doi          = {10.1016/j.robot.2022.104351},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104351},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Reinforcement learning under temporal logic constraints as a sequence modeling problem},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid skill parameterisation model combining symbolic and
subsymbolic elements for introspective robots. <em>RAS</em>,
<em>161</em>, 104350. (<a
href="https://doi.org/10.1016/j.robot.2022.104350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the design of robot skills, the focus generally lies on increasing the flexibility and reliability of the robot execution process; however, typical skill representations are not designed for analysing execution failures if they occur or for explicitly learning from failures. In this paper, we describe a learning-based hybrid representation for skill parameterisation called an execution model, which considers execution failures to be a natural part of the execution process. We then (i) demonstrate how execution contexts can be included in execution models, (ii) introduce a technique for generalising models between object categories by combining generalisation attempts performed by a robot with knowledge about object similarities represented in an ontology, and (iii) describe a procedure that uses an execution model for identifying a likely hypothesis of a parameterisation failure. The feasibility of the proposed methods is evaluated in multiple experiments performed with a physical robot in the context of handle grasping, object grasping, and object pulling. The experimental results suggest that execution models contribute towards avoiding execution failures, but also represent a first step towards more introspective robots that are able to analyse some of their execution failures in an explicit manner.},
  archive      = {J_RAS},
  author       = {Alex Mitrevski and Paul G. Plöger and Gerhard Lakemeyer},
  doi          = {10.1016/j.robot.2022.104350},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104350},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A hybrid skill parameterisation model combining symbolic and subsymbolic elements for introspective robots},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-assisted robotic detection of foreign object debris
inside confined spaces of marine vessels using probabilistic mapping.
<em>RAS</em>, <em>161</em>, 104349. (<a
href="https://doi.org/10.1016/j.robot.2022.104349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many complex vehicular systems, such as large marine vessels, contain confined spaces like water tanks, which are critical for the safe functioning of the vehicles. It is particularly hazardous for humans to inspect such spaces due to limited accessibility, poor visibility, and unstructured configuration. While robots provide a viable alternative, they encounter the same set of challenges in realizing robust autonomy. In this work, we specifically address the problem of detecting foreign object debris (FODs) left inside the confined spaces using a visual mapping-based system that relies on Mahalanobis distance-driven comparisons between the nominal and online maps for local outlier identification. The identified outliers, corresponding to candidate FODs, are used to generate waypoints that are fed to a mobile ground robot to take camera photos. The photos are subsequently labeled by humans for final identification of the presence and types of FODs, leading to high detection accuracy while mitigating the effect of recall–precision tradeoff. Preliminary simulation studies, followed by extensive physical trials on a prototype tank, demonstrate the capability and potential of our FOD detection system.},
  archive      = {J_RAS},
  author       = {Benjamin Wong and Wade Marquette and Nikolay Bykov and Tyler M. Paine and Ashis G. Banerjee},
  doi          = {10.1016/j.robot.2022.104349},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104349},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Human-assisted robotic detection of foreign object debris inside confined spaces of marine vessels using probabilistic mapping},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Addressing time discrepancy between digital and physical
twins. <em>RAS</em>, <em>161</em>, 104347. (<a
href="https://doi.org/10.1016/j.robot.2022.104347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital twins (DTs) represent a key technology in the development, real-time monitoring and optimisation of cyber–physical systems (CPSs). Such potential emerges as a result of the real-time coupling between DTs and their physical counterparts, where it is possible to make use of operational data as it is being generated in order to aid decision-making. Harnessing this potential presents several design challenges, such as the parallel operation of the DT and its physical twin (PT), and the necessary synchronisation thereof, to ensure coherent execution of the system in ensemble. In this paper we present an approach that handles situations where a DT and its PT get out of sync as a result of disturbances in the normal operational conditions of the DT–PT system, e.g. , due to network degradation or temporary network drop. The purpose is to provide a best-effort functionality covering: user notification, degradation of DT to digital shadow (DS), with recovery mechanisms to re-establish the synchronisation between DT and PT.},
  archive      = {J_RAS},
  author       = {Mirgita Frasheri and Henrik Ejersbo and Casper Thule and Cláudio Gomes and Jakob Levisen Kvistgaard and Peter Gorm Larsen and Lukas Esterle},
  doi          = {10.1016/j.robot.2022.104347},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104347},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Addressing time discrepancy between digital and physical twins},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seeking at-home long-term autonomy of assistive mobile
robots through the integration with an IoT-based monitoring system.
<em>RAS</em>, <em>161</em>, 104346. (<a
href="https://doi.org/10.1016/j.robot.2022.104346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a system that stems from the integration of an autonomous mobile robot with an IoT-based monitoring system to provide monitoring, assistance, and stimulation to older adults living alone in their own houses. The creation of an Internet of Robotics Things (IoRT) based on the interplay between pervasive smart objects and autonomous robotic systems is claimed to enable the creation of innovative services conceived for assisting the final user, especially in elderly care. The synergy between IoT and a Socially Assistive Robot (SAR) was conceived to offer robustness, reconfiguration, heterogeneity, and scalability, by bringing a strong added value to both the current SAR and IoT technologies. First, we propose a method to achieve the synergy and integration between the IoT system and the robot; then, we show how our method increases the performance and effectiveness of both to provide long-term support to the older adults. To do so, we present a case-study, where we focus on the detection of signs of the frailty syndrome , a set of vulnerabilities typically conveyed by a cognitive and physical decline in older people that concur in amplifying the risks of major diseases hindering the capabilities of independent living. Experimental evaluation is performed in both controlled settings and in a long-term real-world pilot study with 9 older adults in their own apartments, where the system was deployed autonomously for, on average, 12 weeks.},
  archive      = {J_RAS},
  author       = {Matteo Luperto and Javier Monroy and Francisco-Angel Moreno and Francesca Lunardini and Jennifer Renoux and Andrej Krpic and Cipriano Galindo and Simona Ferrante and Nicola Basilico and Javier Gonzalez-Jimenez and N. Alberto Borghese},
  doi          = {10.1016/j.robot.2022.104346},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104346},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Seeking at-home long-term autonomy of assistive mobile robots through the integration with an IoT-based monitoring system},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contact-based object inspection with mobile manipulators at
near-optimal base locations. <em>RAS</em>, <em>161</em>, 104345. (<a
href="https://doi.org/10.1016/j.robot.2022.104345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a control and motion planning algorithm for a mobile vehicle-manipulator system such that the mobile vehicle and the manipulator mounted on it work in harmony to inspect unknown objects. Forward Dynamic Control method is used for the manipulator to accomplish a stable interaction with the environment and constrained particle swarm optimization is applied so that the vehicle can be localized at the estimated points maximizing the dexterity of the manipulator. Quartic splines are implemented to generate a smooth path for the vehicle in between the optimal locations. The proposed architecture is validated via an experimental setup consisting of a robotic arm with a force sensor at its end-effector mounted on a parallel manipulator . These experiments emulate an underwater vehicle-manipulator system, where the mobile base is subject to disturbances due to the physical interaction of the end-effector with the environment, typically a pipe. The advantage of the proposed approach is that it allows continuous and smooth movement of the base in harmony with the robotic manipulator while executing a task on a large surface (larger than the manipulator workspace can cover from a fixed position) and maintains a high level of dexterity index for the manipulator.},
  archive      = {J_RAS},
  author       = {Harun Tugal and Kamil Cetin and Yvan Petillot and Matthew Dunnigan and Mustafa Suphi Erden},
  doi          = {10.1016/j.robot.2022.104345},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104345},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Contact-based object inspection with mobile manipulators at near-optimal base locations},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and control of an aerial-ground tethered
tendon-driven continuum robot with hybrid routing. <em>RAS</em>,
<em>161</em>, 104344. (<a
href="https://doi.org/10.1016/j.robot.2022.104344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining aerial and continuum robots harnesses both their flexibility and manoeuvrability to potentially perform dangerous maintenance tasks. However, such systems require heavy payloads to interact with its environment. An aerial-ground tethered tendon-driven continuum robot is thus proposed to tackle the limitations of on-board payload aerial systems and the underactuation of multirotors. Due to the natural limitation on the tendons used in the implementation of aerial ground tethered continuum robots, we explore the use of hybrid polynomial and parallel routes to achieve desired workspace profiles, while providing intuition on choosing suitable tendon routes. In this work, we leverage on geometrically exact methods to derive the differential kinematics of the aerial continuum robot using actuation sensors particularly for polynomial tendon routes. We demonstrate that both position and orientation can be controlled using a single stage continuum robot with hybrid tendon routing. Finally, a simple manoeuvre is executed by the aerial continuum robot prototype to validate the proposed proof of concept .},
  archive      = {J_RAS},
  author       = {Jer Luen Chien and Clarissa Leong and Jingmin Liu and Shaohui Foong},
  doi          = {10.1016/j.robot.2022.104344},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104344},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design and control of an aerial-ground tethered tendon-driven continuum robot with hybrid routing},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fault-tolerant sensor fusion in mobile robots using
multiple model kalman filters. <em>RAS</em>, <em>161</em>, 104343. (<a
href="https://doi.org/10.1016/j.robot.2022.104343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate localization is crucial in the navigation of mobile robots. However, in other circumstances, single-sensor localization faces different challenges, including software and hardware problems or data outages. Sensor fusion is used in most autonomous vehicles (including aerial and ground vehicles) to overcome such challenges. In this paper, the localization of a mobile robot is studied in the presence of sensor faults. The mobile robot has two sensors: two Inertial Measurement Units (IMU) and wheel encoders. Regarding the fault-tolerant scheme, measurements of both sets of sensors are fused using an Interacting Multiple Model (IMM) Kalman filter based on both unscented and extended Kalman filters (UKF and EKF). UKF and EKF-based IMM are chosen for this study since the dynamic model of the localization is highly nonlinear. Regarding contributions, it should be noted that this scheme eliminates the need to model every single fault scenario and use an additional sensor to oversee the performance of the sensing system. Also, comparing this method with similar approaches adopted by other studies shows better performance regarding the cost of computations and RMSE. To evaluate performance, the outputs of the proposed filters are simulated and compared for different trajectories where the data of each sensor is intentionally corrupted to observe the fault detection capability. Simulations are performed for different trajectories and noises to demonstrate this method’s efficiency in different situations. In addition, the results of unscented and extended Kalman filter-based IMM are compared in terms of error and computational costs to evaluate their performance. Overall, simulation and experiments indicate accurate 3D estimations in all cases. Moreover, designated weights vividly show that sensor fault detection is achieved by both unscented and extended IMM Kalman filters, which enable complete fault isolation consequently. This approach provides mobile robots with a reliable and straightforward sensor fault detection and localization solution.},
  archive      = {J_RAS},
  author       = {M. Kheirandish and E. Azadi Yazdi and H. Mohammadi and M. Mohammadi},
  doi          = {10.1016/j.robot.2022.104343},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104343},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A fault-tolerant sensor fusion in mobile robots using multiple model kalman filters},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of quadrotor UAV: Control and SLAM methodologies
ranging from conventional to innovative approaches. <em>RAS</em>,
<em>161</em>, 104342. (<a
href="https://doi.org/10.1016/j.robot.2022.104342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two indispensable methodologies for autonomous flights performed by unmanned aerial vehicles (UAV). The first is flight control, and the other is simultaneous localization and mapping (SLAM). In the literature, these two issues are generally considered separately. However, they have very close relationships with each other. In this study, both methods were extensively examined in the literature, especially for quadrotors. Quadrotors, also known as quadrotors, are rotary-wing UAVs capable of vertical take-off and landing. As their use becomes widespread worldwide, the number of studies conducted to enable autonomous tasks is growing. The study was prepared under three subtitles. First, a fast and simple introduction of quadrotors was made, and the advances in this area were discussed. In the next section, studies on the position, attitude, and altitude control methods required for the autonomous use of such aircraft are analyzed based on linear, nonlinear, and intelligent methods. As the third subheading, research on SLAM techniques was widely discussed. Frequently used performance metrics, application environments, and results were presented in detailed tables for studies in both areas. Comparative studies were particularly emphasized, and the best results obtained were expressed in tables. The hardware implementations of the mentioned applications were also reviewed. Thus, hardware and method-based quick reference resource were created for researchers. As a consequence, the objective of this research is to provide a comprehensive resource for researchers working on quadrotor navigation systems to effectively select the flight control and SLAM methods they will employ.},
  archive      = {J_RAS},
  author       = {Güray SONUGÜR},
  doi          = {10.1016/j.robot.2022.104342},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104342},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A review of quadrotor UAV: Control and SLAM methodologies ranging from conventional to innovative approaches},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disturbance-aware reinforcement learning for rejecting
excessive disturbances. <em>RAS</em>, <em>161</em>, 104341. (<a
href="https://doi.org/10.1016/j.robot.2022.104341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a disturbance-aware Reinforcement Learning (RL) approach for stabilizing a free-floating platform under excessive external disturbances . In particular, we consider the scenarios where disturbances frequently exceed actuator limits and largely affect the dynamics characterizing the disturbed platform. This stabilization problem is better described by a set of Unknown Partially Observable Markovian Decision Processes (POMDPs), as opposed to a single-POMDP formulation, making online disturbance awareness necessary. This paper proposes a new Disturbance-Observer network (DO-net) that mimics prediction procedures through an auxiliary Gated Recurrent Unit (GRU), for the purpose of estimating and encoding the disturbance states and the disturbance transition functions, respectively. Then the controller subnetwork is trained with joint optimization of the observer subnetwork in an RL manner for mutual robustness and runtime efficiency. Numerical simulations on position regulation tasks have demonstrated that the DO-net outperforms the DOB-net and reduces the gap with an ideal performance estimate, the latter of which is obtained by a commercial solver given precise disturbance knowledge.},
  archive      = {J_RAS},
  author       = {Wenjie Lu and Manman Hu},
  doi          = {10.1016/j.robot.2022.104341},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104341},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Disturbance-aware reinforcement learning for rejecting excessive disturbances},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and development of software stack of an autonomous
vehicle using robot operating system. <em>RAS</em>, <em>161</em>,
104340. (<a href="https://doi.org/10.1016/j.robot.2022.104340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent research activities, autonomous vehicles and self-driving technology have gained lot of attention among scientists. The idea of autonomous vehicles can be anticipated in the 1920 s when the design of the first radio-controlled vehicles was in progress. Autonomous vehicles are going to be the trend of the future in this modern era of automation and technology. In this paper various autonomous driving aspects, highlighting the software stack and hardware components are discussed. The software architecture covers mainly robot operating system (ROS), machine learning (ML), deep learning (DL), and OpenCV frameworks, along with the calibration of sensors and cameras. The paper also discussed about simultaneous localization and mapping (SLAM) based-path tracking, computer vision-based controller, and intelligent object avoidance. Further, point cloud, ground, radius, and raycast filters was implemented to distinguish between the real-time objects, ground, and its own parts or obstacle shadows. The paper highlights the overall hardware modules responsible for controlling the car.},
  archive      = {J_RAS},
  author       = {Abhisek Omkar Prasad and Pradumn Mishra and Urja Jain and Anish Pandey and Anushka Sinha and Anil Singh Yadav and Rajan Kumar and Abhishek Sharma and Gaurav Kumar and Karrar Hazim Salem and Avdhesh Sharma and Anil Kumar Dixit},
  doi          = {10.1016/j.robot.2022.104340},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104340},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design and development of software stack of an autonomous vehicle using robot operating system},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient surface detection for assisting collaborative
robots. <em>RAS</em>, <em>161</em>, 104339. (<a
href="https://doi.org/10.1016/j.robot.2022.104339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative Robots need to read the surfaces they are walking on to keep their dynamic equilibrium, regardless of whether the ground is flat or uneven. Although accelerometers are frequently employed for this task, previous efforts have centered on retrofitting the quadruped robots with new sensors. The second technique is to collect lots of samples for machine learning algorithms , which are not widely implemented. Learning-based approaches altered the traditional way of data analytics . The advanced deep learning algorithms provide better accuracy and prove more efficient when the data size is large. This paper introduced a novel architecture of Convolutional Neural Network , a deep learning-based approach for efficiently classifying the surface on which the robots are walking. The dataset contains reading captured by Inertia Measurement Unit sensors. The proposed model achieved an overall classification accuracy of 88\%. The proposed architecture is compared with the existing deep and machine learning techniques to show its effectiveness. The proposed model can be installed on collaborative robots’ onboard processors to identify the surfaces effectively.},
  archive      = {J_RAS},
  author       = {Simranjit Singh and Mohit Sajwan and Gurbhej Singh and Anil Kumar Dixit and Amrinder Mehta},
  doi          = {10.1016/j.robot.2022.104339},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104339},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Efficient surface detection for assisting collaborative robots},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bimanual telemanipulation with force and haptic feedback
through an anthropomorphic avatar system. <em>RAS</em>, <em>161</em>,
104338. (<a href="https://doi.org/10.1016/j.robot.2022.104338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic teleoperation is a key technology for a wide variety of applications. It allows sending robots instead of humans in remote, possibly dangerous locations while still using the human brain with its enormous knowledge and creativity, especially for solving unexpected problems. A main challenge in teleoperation consists of providing enough feedback to the human operator for situation awareness and thus create full immersion, as well as offering the operator suitable control interfaces to achieve efficient and robust task fulfillment. We present a bimanual telemanipulation system consisting of an anthropomorphic avatar robot and an operator station providing force and haptic feedback to the human operator. The avatar arms are controlled in Cartesian space with a direct mapping of the operator movements. The measured forces and torques on the avatar side are haptically displayed to the operator. We developed a predictive avatar model for limit avoidance which runs on the operator side, ensuring low latency. The system was successfully evaluated during the ANA Avatar XPRIZE competition semifinals. In addition, we performed in lab experiments and carried out a small user study with mostly untrained operators.},
  archive      = {J_RAS},
  author       = {Christian Lenz and Sven Behnke},
  doi          = {10.1016/j.robot.2022.104338},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104338},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Bimanual telemanipulation with force and haptic feedback through an anthropomorphic avatar system},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). External six-bar mechanism rehabilitation device for index
finger: Development and shape synthesis. <em>RAS</em>, <em>161</em>,
104336. (<a href="https://doi.org/10.1016/j.robot.2022.104336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel external Stephenson-III six-bar mechanism-based rehabilitation device. This device has been designed to rehabilitate the patient’s finger for the action of grabbing, also known as flexion and extension. A predefined trajectory is used to synthesize the mechanism using TeachingLearning-Optimization algorithm (TLBO) and Particle swarm optimization algorithm (PSO). The trajectory data was obtained after image processing by grabbing a particular object 30 times to record the flexion and extension motion of the index finger. An optimization problem was formulated and results of TLBO and PSO were compared. The mechanism obtained from TLBO algorithm was deemed better in terms of precision and feasible configuration. Using clinical biomechanical data for flexion/extension of index finger, position and static force analysis are performed. The CAD model of the mechanism was then tested for feasibility in a CAD/Software. Excess mass was removed using topology optimization and a 20\% mean reduction for every link was achieved. An index finger rehabilitation device employing an external six-bar mechanism was obtained, that would help a patient with motor control loss to rehabilitate and bring normalcy to life. The design of exoskeleton was able to match the trajectory of the index. Shape synthesis ensured a 20\% reduction in overall mass of the linkages.},
  archive      = {J_RAS},
  author       = {Debaditya Chakraborty and Ayush Rathi and Ramanpreet Singh and Vimal Kumar Pathak and Ashish Kumar Srivastava and Abhishek Sharma and Kuldeep K. Saxena and Gaurav Kumar and Sandeep Kumar},
  doi          = {10.1016/j.robot.2022.104336},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104336},
  shortjournal = {Robot. Auton. Syst.},
  title        = {External six-bar mechanism rehabilitation device for index finger: Development and shape synthesis},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of multi-agent human–robot interaction systems.
<em>RAS</em>, <em>161</em>, 104335. (<a
href="https://doi.org/10.1016/j.robot.2022.104335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a survey of literature in the area of Human–Robot Interaction (HRI), specifically on systems containing more than two agents (i.e., having multiple humans and/or multiple robots). We identify three core aspects of “Multi-agent” HRI systems that are useful for understanding how these systems differ from dyadic systems and from one another. These are the Team structure, Interaction style among agents, and the system’s Computational characteristics. Under these core aspects, we present five attributes of HRI systems, namely Team size, Team composition, Interaction model, Communication modalities, and Robot control. These attributes are used to characterize and distinguish one system from another. We populate resulting categories with examples from the recent literature along with a brief discussion of their applications. We also analyze how these attributes in multi-agent systems differ from the case of dyadic human–robot systems. Through this survey, we summarize key observations from the current literature, and identify challenges and promising areas for future research in this domain. In order to realize the vision of robots being part of the society and interacting seamlessly with humans, there is a need to expand research on multi-human–multi-robot systems. Not only do these systems require coordination among several agents, they also involve multi-agent and indirect interactions which are absent from dyadic HRI systems. Including multiple agents in HRI systems requires more advanced interaction schemes, behavior understanding and control methods to allow natural interactions among humans and robots. In addition, research on human behavioral understanding in mixed human–robot teams also requires more attention. This will help formulate and implement effective robot control policies in HRI systems with large numbers of heterogeneous robots and humans; a team composition reflecting many real-world scenarios.},
  archive      = {J_RAS},
  author       = {Abhinav Dahiya and Alexander M. Aroyo and Kerstin Dautenhahn and Stephen L. Smith},
  doi          = {10.1016/j.robot.2022.104335},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104335},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A survey of multi-agent Human–Robot interaction systems},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UV disinfection robots: A review. <em>RAS</em>,
<em>161</em>, 104332. (<a
href="https://doi.org/10.1016/j.robot.2022.104332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel coronavirus (COVID-19) pandemic has completely changed our lives and how we interact with the world. The pandemic has brought about a pressing need to have effective disinfection practices that can be incorporated into daily life. They are needed to limit the spread of infections through surfaces and air, particularly in public settings. Most of the current methods utilize chemical disinfectants, which can be laborious and time-consuming. Ultraviolet (UV) irradiation is a proven and powerful means of disinfection. There has been a rising interest in the implementation of UV disinfection robots by various public institutions, such as hospitals, long-term care homes, airports , and shopping malls. The use of UV-based disinfection robots could make the disinfection process faster and more efficient. The objective of this review is to equip readers with the necessary background on UV disinfection and provide relevant discussion on various aspects of UV robots.},
  archive      = {J_RAS},
  author       = {Ishaan Mehta and Hao-Ya Hsueh and Sharareh Taghipour and Wenbin Li and Sajad Saeedi},
  doi          = {10.1016/j.robot.2022.104332},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104332},
  shortjournal = {Robot. Auton. Syst.},
  title        = {UV disinfection robots: A review},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OGATE: A framework for autonomous controllers assessment.
<em>RAS</em>, <em>161</em>, 104325. (<a
href="https://doi.org/10.1016/j.robot.2022.104325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robots can face a variety of applications integrating Artificial Intelligence (AI) techniques, for instance Planning &amp; Scheduling (P&amp;S). While robotics and planning systems are commonly well assessed through test benchs and metrics, in autonomous robots literature it is usual to present isolated case studies for evaluating such works. For instance, experiments are presented in very specific circumstances and often the data provided is not enough to enable a characterization of the autonomous features performance, providing only a demonstration of effectiveness. The main issue is the absence of a framework to assess autonomous controllers from a general perspective. We propose a research focused on a set of general applicable metrics to enable assessment of autonomous controllers. In this way, our objective is to analyse the deliberation and reaction capabilities of an autonomous robot in real operative scenarios. Such metrics are implemented in OGATE, a domain independent tool that automatically carries on with controllers’ testing, generating objective and reproducible performance assessments. To test this framework we have used two autonomous controllers that rely on different technologies for P&amp;S. Results show that we are able to obtain relevant data, enabling the characterization of different P&amp;S integration in robotics.},
  archive      = {J_RAS},
  author       = {Pablo Muñoz and Amedeo Cesta and Andrea Orlandini and María D. R-Moreno},
  doi          = {10.1016/j.robot.2022.104325},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104325},
  shortjournal = {Robot. Auton. Syst.},
  title        = {OGATE: A framework for autonomous controllers assessment},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-robot task allocation clustering based on game theory.
<em>RAS</em>, <em>161</em>, 104314. (<a
href="https://doi.org/10.1016/j.robot.2022.104314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cooperative game theory framework is proposed to solve multi-robot task allocation (MRTA) problems. In particular, a cooperative game is built to assess the performance of sets of robots and tasks so that the Shapley value of the game can be used to compute their average marginal contribution. This fact allows us to partition the initial MRTA problem into a set of smaller and simpler MRTA subproblems , which are formed by ranking and clustering robots and tasks according to their Shapley value. A large-scale simulation case study illustrates the benefits of the proposed scheme, which is assessed using a genetic algorithm (GA) as a baseline method . The results show that the game theoretical approach outperforms GA both in performance and computation time for a range of problem instances.},
  archive      = {J_RAS},
  author       = {Javier G. Martin and Francisco Javier Muros and José María Maestre and Eduardo F. Camacho},
  doi          = {10.1016/j.robot.2022.104314},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104314},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multi-robot task allocation clustering based on game theory},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A resilient solution to range-only SLAM based on a decoupled
landmark range and bearing reconstruction. <em>RAS</em>, <em>160</em>,
104324. (<a href="https://doi.org/10.1016/j.robot.2022.104324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Range Only Simultaneous Localization and Mapping (RO-SLAM) problem is considered in this paper. The robot is a unicycle like vehicle equipped with encoders on the actuated wheels, which measures the distance to a set of UWB landmarks located in unknown position in the surrounding. A Multi Hypotheses Extended Kalman Filter (MHEKF), one for each landmark, is designed to dynamically estimate the range and the bearing of the observed landmark. These estimates, regarded as measurements with a proper covariance matrix , are used in an EKF SLAM algorithm, endowed with a resilient module to discern and possibly to temporarily discard landmarks with an unreliable range and bearing estimate. This allows to cope with the initial uncertainty characterizing the bearing reconstruction, but also to resist the effects of outliers and to detect possible abnormal situations. Simulation and experimental results illustrate the effectiveness of the proposed approach compared to other methods available in the literature, especially in case of significant perturbations, like the sudden and unmodeled shift of the landmarks.},
  archive      = {J_RAS},
  author       = {Francesco Martinelli and Simone Mattogno and Fabrizio Romanelli},
  doi          = {10.1016/j.robot.2022.104324},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104324},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A resilient solution to range-only SLAM based on a decoupled landmark range and bearing reconstruction},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robotic learning and generalization framework for curved
surface based on modified DMP. <em>RAS</em>, <em>160</em>, 104323. (<a
href="https://doi.org/10.1016/j.robot.2022.104323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to reproduce and generalize the skills acquired by demonstrating is a hot topic for researchers. (1) A compliant continuous drag demonstration system based on discrete admittance model was designed to continuously and smoothly drag or demonstrate. (2) The modified DMP including the scaling factor and the force coupling term was used to improve the poor generalization ability of the classical DMP. (3) Curve drawing experiments were carried out to show the effectiveness of our proposed learning and generalization framework.},
  archive      = {J_RAS},
  author       = {Xianfa Xue and Jiale Dong and Zhenyu Lu and Ning Wang},
  doi          = {10.1016/j.robot.2022.104323},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104323},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A robotic learning and generalization framework for curved surface based on modified DMP},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A BPMN-driven framework for multi-robot system development.
<em>RAS</em>, <em>160</em>, 104322. (<a
href="https://doi.org/10.1016/j.robot.2022.104322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming robotic systems is often a challenging task requiring advanced skills, especially when the goal is to ensure loosely-coupled coordination in heterogeneous Multi-Robot Systems (MRSs). Model-driven approaches for robotic system engineering have shown their benefits in facilitating the development of robots’ behavior, controllers, and system components. However, the state of the art still lacks contributions addressing crucial aspects of the model-driven approach applied to MRSs, such as developing robots’ distributed cooperation through models supporting the communication among robots. In this paper, we present a novel framework for modeling, configuring and enacting the cooperative behaviors of MRSs through collaboration diagrams as provided by the BPMN 2.0 standard. The advantages of our solution lie, indeed, in the use of BPMN , which provides easily understandable and highly expressive diagrams for representing the cooperation among distributed robots, and benefits from a wide list of supporting tools. Starting from the selection of BPMNelements, we define a set of guidelines for driving the developer in modeling an MRS mission using BPMN. The developer configures the resulting collaboration diagram to link elements in the model to the robotic middleware, ROS2 in the toolchain we implemented. Finally, the configured model is enacted by BPMN engines integrated into the ROS2 middleware run by each robot involved in the MRS, thus obtaining a fully distributed cooperation. We assess our framework’s effectiveness through experiments in simulated and real environments.},
  archive      = {J_RAS},
  author       = {Flavio Corradini and Sara Pettinari and Barbara Re and Lorenzo Rossi and Francesco Tiezzi},
  doi          = {10.1016/j.robot.2022.104322},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104322},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A BPMN-driven framework for multi-robot system development},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Skill generalization of tubular object manipulation with
tactile sensing and Sim2Real learning. <em>RAS</em>, <em>160</em>,
104321. (<a href="https://doi.org/10.1016/j.robot.2022.104321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tubular objects such as test tubes are common in chemistry and life sciences research laboratories , and robots that can handle them have the potential to accelerate experiments. Moreover, it is expected to train a robot to manipulate tubular objects in a simulator and then deploy it in a real-world environment. However, it is still challenging for a robot to learn to handle tubular objects through single sensing and bridge the gap between simulation and reality. In this paper, we propose a novel tactile–motor policy learning method to generalize tubular object manipulation skills from simulation to reality. In particular, we propose a Sim-to-Real transferable in-hand pose estimation network that generalizes to unseen tubular objects. The network utilizes a novel adversarial domain adaptation network to narrow the pixel-level domain gap for tactile tasks by introducing the attention mechanism and a task-related constraint. The in-hand pose estimation network is further implemented in a Reinforcement Learning-based policy learning framework for robotic insert-and-pullout manipulation tasks. The proposed method is applied to a human–robot collaborative tube placing scenario and a robotic pipetting scenario. The experimental results demonstrate the generalization capability of the learned tactile–motor policy toward tubular object manipulation in research laboratories .},
  archive      = {J_RAS},
  author       = {Yongqiang Zhao and Xingshuo Jing and Kun Qian and Daniel Fernandes Gomes and Shan Luo},
  doi          = {10.1016/j.robot.2022.104321},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104321},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Skill generalization of tubular object manipulation with tactile sensing and Sim2Real learning},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic obstacle avoidance for multi-rotor UAV using
chance-constraints based on obstacle velocity. <em>RAS</em>,
<em>160</em>, 104320. (<a
href="https://doi.org/10.1016/j.robot.2022.104320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure the safety of autonomous Multi-rotor UAVs flying in urban airspace, they should be capable of avoiding collisions with unpredictable dynamic obstacles, such as birds. UAVs must consider both relative position and relative velocity to avoid moving obstacles. Model predictive control (MPC) can consider the multiple collision avoidance constraints in a constrained optimisation framework. This study proposes a chance-constraints based on obstacle velocity (CCOV) method, which can be combined with previous positional chance constraint methods to account for uncertainty in both position and velocity. This effectively prevents collision with high-velocity obstacles, even in a noisy environment . The proposed method has been performed on a numerical simulation built in MATLAB.},
  archive      = {J_RAS},
  author       = {Takumi Wakabayashi and Yukimasa Suzuki and Satoshi Suzuki},
  doi          = {10.1016/j.robot.2022.104320},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104320},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Dynamic obstacle avoidance for multi-rotor UAV using chance-constraints based on obstacle velocity},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online gait generator for lower limb exoskeleton robots:
Suitable for level ground, slopes, stairs, and obstacle avoidance.
<em>RAS</em>, <em>160</em>, 104319. (<a
href="https://doi.org/10.1016/j.robot.2022.104319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of lower limb exoskeletons has seen significant interest in recent times. Two types of them are more used that cover two types of needs: gait rehabilitation and human locomotion assistance. An essential subject in controlling the latter kind is trajectory generation , in which there are still challenges. For online controlling of the exoskeleton, gait parameters must have the ability to change at any moment during walking, taking into account human intention and particular conditions. In this paper, an online gait generation method is provided that is suitable for different walking modes. For this purpose, three trajectory generator blocks are proposed. The first block is for the center of mass (CoM) in the double support phase, where the trajectory is generated to make the patient feel more comfortable. The second block is for the support leg in the single support phase. The trajectory is generated using the center of pressure (CoP) criterion to secure backward balance and reduce the forces applied to the arms. The last block is for the swing leg in the single support phase, where a cost function is proposed to minimize the torques of the motors. The performance analysis of the proposed trajectory generator blocks was evaluated, and walking patterns were examined via simulations. Finally, three experimental tests were implemented with a healthy subject wearing Exoped® exoskeleton on level-ground with an obstacle, and stairs.},
  archive      = {J_RAS},
  author       = {Habib Mohamad and Sadjaad Ozgoli},
  doi          = {10.1016/j.robot.2022.104319},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104319},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Online gait generator for lower limb exoskeleton robots: Suitable for level ground, slopes, stairs, and obstacle avoidance},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Skill-based design of dependable robotic architectures.
<em>RAS</em>, <em>160</em>, 104318. (<a
href="https://doi.org/10.1016/j.robot.2022.104318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software architectures for autonomous systems are generally structured with 3 layers: a decisional layer managing autonomous reasoning, a functional layer managing reactive tasks and processing, and an executive layer bridging the gap between both. The executive layer plays a central role, as it links high-level tasks with low-level processing, and is generally responsible for the robustness or the fault-tolerance of the overall system. In this paper, we propose a development process for such an executive layer that emphasizes on the dependability of this layer. To do so, we structure the executive layer using skills , that are formally defined using a specific language, and we then provide some tools to verify these models, generate some code, and a methodology to assess the fault-tolerance of the resulting architecture.},
  archive      = {J_RAS},
  author       = {Alexandre Albore and David Doose and Christophe Grand and Jérémie Guiochet and Charles Lesire and Augustin Manecy},
  doi          = {10.1016/j.robot.2022.104318},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104318},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Skill-based design of dependable robotic architectures},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The human-following strategy for mobile robots in mixed
environments. <em>RAS</em>, <em>160</em>, 104317. (<a
href="https://doi.org/10.1016/j.robot.2022.104317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robot behavior strategy is considered as a crucial part in the human-following task to help the robot maintain an appropriate distance and orientation to the selected target person (STP) with a smooth and safe manner. As usual, the robot is uniquely considered to follow the STP in a specific class of environments, such as unknown environments (non-mapped environments) or known environments (mapped environments). However, in real-life applications, the robot is sometimes requested to follow the STP in various types of environments, both in known and unknown ones. This observation raises the need to propose an alternative method to challenge the mentioned issue, as well as to break the current limit of the human-following function. In this paper, a new approach for the human-following strategy is proposed in which the mobile robot is enabled to follow the STP in mixed environments (non-mapped and mapped). In non-mapped environments, only the STP and the obstacle information with respect to the robot local coordinates are considered, whose purpose is to make the robot work without any prior understandings about its working environment. However, after the robot entered mapped environments, its prior knowledge of the working environment is leveraged to fulfill some additional requirements during the cooperation, such as the mobile robot in factories is not allowed to enter some specific areas even when the STP is executing technical tasks inside. Additionally, in this paper, a human-like inference mechanism is also introduced for the human-following strategy by using an extended hedge algebras. The proposed method is experimentally verified both in factories and laboratories. Demo Video Link : https://www.youtube.com/watch?v=YGrWU6ldKuw Since real videos in the factory are not allowed to publish, only visualization (in Rviz) is presented for demos in such kinds of environments. The visualization is synchronous with the real executions of the human–robot interactions . The robot used in the factory is an autonomous mobile robot (dimension 0.5 (m) ×1.0 (m), weight 120 (kg), carrying a tool cabinet around 300(kg))). The mobile robot is following the worker to support them during the technical processes in the car production line. In the video, the robot is represented by a green rectangular, and the STP is represented by a cylinder (with a sphere on its head) The events in the demo video are described more clearly in Appendix A .},
  archive      = {J_RAS},
  author       = {Nguyen Van Toan and Minh Do Hoang and Phan Bui Khoi and Soo-Yeong Yi},
  doi          = {10.1016/j.robot.2022.104317},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104317},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The human-following strategy for mobile robots in mixed environments},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Best axes composition extended: Multiple gyroscopes and
accelerometers data fusion to reduce systematic error. <em>RAS</em>,
<em>160</em>, 104316. (<a
href="https://doi.org/10.1016/j.robot.2022.104316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple rigidly attached Inertial Measurement Unit (IMU) sensors provide a richer flow of data compared to a single IMU. State-of-the-art methods follow a probabilistic model of IMU measurements based on the random nature of errors combined under a Bayesian framework . However, affordable low-grade IMUs, in addition, suffer from systematic errors due to their imperfections not covered by their corresponding probabilistic model. In this paper, we propose a method, the Best Axes Composition (BAC) of combining Multiple IMU (MIMU) sensors data for accurate 3D-pose estimation that takes into account both random and systematic errors by dynamically choosing the best IMU axes from the set of all available axes. We evaluate our approach on our MIMU visual–inertial sensor and compare the performance of the method with a purely probabilistic state-of-the-art approach of MIMU data fusion. We show that BAC outperforms the latter and achieves up to 20\% accuracy improvement for both orientation and position estimation in open loop, but needs proper treatment to keep the obtained gain.},
  archive      = {J_RAS},
  author       = {Marsel Faizullin and Gonzalo Ferrer},
  doi          = {10.1016/j.robot.2022.104316},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104316},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Best axes composition extended: Multiple gyroscopes and accelerometers data fusion to reduce systematic error},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive estimation of UAV altitude in complex indoor
environments using degraded and time-delayed measurements with
time-varying uncertainties. <em>RAS</em>, <em>160</em>, 104315. (<a
href="https://doi.org/10.1016/j.robot.2022.104315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel approach for robust Unmanned Aerial Vehicle (UAV) altitude estimation relying on laser measurements that is designed for use in complex indoor environments is proposed in this paper. Specifically, we aim to design a system with general usability inside multi-floor buildings. The multi-floor buildings are characterized by areas lacking distinct vertical geometric features to be used as reference by 3D Light Detection and Ranging (LiDAR) localization algorithms, and by areas with either flat floors or limited areas with inconsistent ground elevation. The proposed approach solves the problem of adaptive fusion of data from multiple sources with apriori-unknown confidence dependent on the current environmental properties. Whenever the environment contains enough geometric structure, altitude data from a 3D LiDAR-based Simultaneous Localization and Mapping (SLAM) algorithm are utilized. In environments that are too symmetrical for reliable SLAM operation, the approach relies mostly on measurements from a downward-facing 1D laser rangefinder, while simultaneously detecting inconsistent ground elevation areas. These measurements are fused with barometer data, Inertial Measurement Unit (IMU) data, and information from the UAV position controllers. Furthermore, our approach correctly handles the measurement delay caused by 3D LiDAR data processing that significantly differs from other sensor delays. The performance of the proposed approach has been validated in complex simulations and real-world experiments with the produced altitude estimate utilized in the control loop of the UAV. The proposed approach is released as open-source as part of the MRS UAV System.},
  archive      = {J_RAS},
  author       = {Václav Pritzl and Matouš Vrba and Claudio Tortorici and Reem Ashour and Martin Saska},
  doi          = {10.1016/j.robot.2022.104315},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104315},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Adaptive estimation of UAV altitude in complex indoor environments using degraded and time-delayed measurements with time-varying uncertainties},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MVGrasp: Real-time multi-view 3D object grasping in highly
cluttered environments. <em>RAS</em>, <em>160</em>, 104313. (<a
href="https://doi.org/10.1016/j.robot.2022.104313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays robots play an increasingly important role in our daily life. In human-centered environments, robots often encounter piles of objects, packed items, or isolated objects. Therefore, a robot must be able to grasp and manipulate different objects in various situations to help humans with daily tasks. In this paper, we propose a multi-view deep learning approach to handle robust object grasping in human-centric domains. In particular, our approach takes a point cloud of an arbitrary object as an input, and then, generates orthographic views of the given object. The obtained views are finally used to estimate pixel-wise grasp synthesis for each object. We train the model end-to-end using a synthetic object grasp dataset and test it on both simulation and real-world data without any further fine-tuning. To evaluate the performance of the proposed approach, we performed extensive sets of experiments in four everyday scenarios, including isolated objects, packed items, pile of objects, and highly cluttered scenes. Experimental results show that our approach performed very well in all simulation and real-robot scenarios. More specifically, the proposed approach outperforms previous state-of-the-art approaches and achieves a success rate of &gt; 90\% &amp;gt;90\% in all simulated and real scenarios, except for the pile of objects which is 82\%. Additionally, our method demonstrated reliable closed-loop grasping of novel objects in a variety of scene configurations. The video of our experiments can be found here: https://youtu.be/c-4lzjbF7fY .},
  archive      = {J_RAS},
  author       = {Hamidreza Kasaei and Mohammadreza Kasaei},
  doi          = {10.1016/j.robot.2022.104313},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104313},
  shortjournal = {Robot. Auton. Syst.},
  title        = {MVGrasp: Real-time multi-view 3D object grasping in highly cluttered environments},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A neural network based framework for variable impedance
skills learning from demonstrations. <em>RAS</em>, <em>160</em>, 104312.
(<a href="https://doi.org/10.1016/j.robot.2022.104312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are becoming standard collaborators not only in factories, hospitals, and offices, but also in people’s homes, where they can play an important role in situations where a human cannot complete a task alone or needs the help of another person (i.e., collaborative tasks). Variable impedance control with contact forces is critical for robots to successfully perform such manipulation tasks, and robots should be equipped with adaptive capabilities because conditions vary significantly for different robotic tasks in dynamic environments. This can be achieved by learning human motion capabilities and variable impedance skills. In this paper, a neural-network-based framework for learning variable impedance skills is proposed. The proposed approach builds the full stiffness function with the acquired forces and position learned from demonstrations, and then is used together with the sensed data to achieve the variable impedance control . The proposed algorithm can adapt to unknown situations that change the learned motion skill as needed (e.g., adapt to intermediate via-points or avoid obstacles). The proposed framework consists of two parts: Learning motion features and learning impedance features. The motion features learning is validated by reproducing, generalizing, and adapting to transit points and avoiding obstacles in the LASA dataset. Impedance features learning is validated based on a virtual variable stiffness system that achieves higher accuracy (approximately 90\%) compared to traditional methods in a manual dataset, and the whole framework is validated through a co-manipulation task between a person and the Franka Emika robot.},
  archive      = {J_RAS},
  author       = {Yu Zhang and Long Cheng and Ran Cao and Houcheng Li and Chenguang Yang},
  doi          = {10.1016/j.robot.2022.104312},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104312},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A neural network based framework for variable impedance skills learning from demonstrations},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the parameter identification of free-flying space
manipulator systems. <em>RAS</em>, <em>160</em>, 104310. (<a
href="https://doi.org/10.1016/j.robot.2022.104310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel parameter identification method is proposed, which identifies all the parameters required for the reconstruction of free-flying space manipulator system dynamics . Its key advantage is that it does not use acceleration measurements; thus, it is less sensitive to sensor noise than other methods. The method is based on the conservation of angular momentum and on a kinematic equation including a Jacobian . To apply the method, all manipulator joints are commanded to follow optimized exciting trajectories, while the system is in free-floating mode. The estimated parameters render the free-flying system dynamics fully identified and available to model-based control. The method applies to multi-arm systems and is validated by simulation and experiments with excellent results.},
  archive      = {J_RAS},
  author       = {Olga-Orsalia Christidi-Loumpasefski and Evangelos Papadopoulos},
  doi          = {10.1016/j.robot.2022.104310},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104310},
  shortjournal = {Robot. Auton. Syst.},
  title        = {On the parameter identification of free-flying space manipulator systems},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning and extrapolation of robotic skills using
task-parameterized equation learner networks. <em>RAS</em>,
<em>160</em>, 104309. (<a
href="https://doi.org/10.1016/j.robot.2022.104309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation learning approaches achieve good generalization within the range of the training data, but tend to generate unpredictable motions when querying outside this range. We present a novel approach to imitation learning with enhanced extrapolation capabilities that exploits the so-called Equation Learner Network (EQLN). Unlike conventional approaches, EQLNs use supervised learning to fit a set of analytical expressions that allows them to extrapolate beyond the range of the training data. We augment the task demonstrations with a set of task-dependent parameters representing spatial properties of each motion and use them to train the EQLN. At run time, the features are used to query the Task-Parameterized Equation Learner Network (TP-EQLN) and generate the corresponding robot trajectory. The set of features encodes kinematic constraints of the task such as desired height or a final point to reach. We validate the results of our approach on manipulation tasks where it is important to preserve the shape of the motion in the extrapolation domain. Our approach is also compared with existing state-of-the-art approaches, in simulation and in real setups. The experimental results show that TP-EQLN can respect the constraints of the trajectory encoded in the feature parameters, even in the extrapolation domain, while preserving the overall shape of the trajectory provided in the demonstrations.},
  archive      = {J_RAS},
  author       = {Hector Perez-Villeda and Justus Piater and Matteo Saveriano},
  doi          = {10.1016/j.robot.2022.104309},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104309},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Learning and extrapolation of robotic skills using task-parameterized equation learner networks},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of safety-related performance of wearable lower
limb exoskeleton robot (WLLER): A systematic review. <em>RAS</em>,
<em>160</em>, 104308. (<a
href="https://doi.org/10.1016/j.robot.2022.104308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable lower limb exoskeleton robots (WLLER) have broad development prospects in the military, industrial and medical fields. The intelligent device comes into intimate contact with the human body, and its safety is an essential factor that developers must consider. With the increasing research on the safety of WLLER, its safety test methods and indicators should gradually improve. By examining current test methods and indicators, this study aims to mobilize this information and summarize the most recent safety research. The safety-related studies reviewed in this paper are not limited to evaluating subjects in clinical trials but are concerned with extensive safety research. The focus of our analysis is the test performance indicators. Some functional evaluation indicators are also summarized to explore a broader and more applicable approach on the safety metrics. We found that, in general, most researchers pay attention to the power-assisting performance of WLLER, but the stability and comfort have been largely ignored. At the same time, our analysis also reveals that although there are a wide variety of existing evaluation indicators, uniform and standard test methods and indicators for safety testing of WLLER are still deficient. Based on these results, we identified and discussed several promising research directions that may help the community to attain a widely accepted test method that can objectively evaluate the safety of WLLER.},
  archive      = {J_RAS},
  author       = {Duojin Wang and Xiaoping Gu and Wenzhuo Li and Yaoxiang Jin and Maisi Yang and Hongliu Yu},
  doi          = {10.1016/j.robot.2022.104308},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104308},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Evaluation of safety-related performance of wearable lower limb exoskeleton robot (WLLER): A systematic review},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on the autonomous exploration of confined
subterranean spaces: Perspectives from real-word and industrial robotic
deployments. <em>RAS</em>, <em>160</em>, 104304. (<a
href="https://doi.org/10.1016/j.robot.2022.104304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Confined and subterranean areas are common in many civilian and industrial sites, although they are hazardous for humans given the presence of noxious gases, extreme temperatures, narrow spaces, unhealthy oxygen levels, flooding, and collapsing structures. Therefore, exploration, routine inspections, and surveillance tasks can benefit from using autonomous mobile robots to improve safety by reducing the presence of humans in those scenarios. However, despite advances in the field, there are still challenges to overcome for confined and subterranean robot operation. Real word robotic exploration requires robust and reliable map generation, precise localization , safe navigation , and efficient path planning . These requirements make exploration in complex 3D environments with rugged terrain difficult. The challenge is increased when considering multi-robot teams, as there is no guarantee of a functional network infrastructure. Despite consistent increasing interest in the area, there is a lack of research summarizing the results and best practices for exploring such environments. Therefore, in this paper, we provide a review and discuss state-of-the-art robotic exploration techniques, including single and cooperative approaches with homogeneous and heterogeneous teams, with a focus on complex subterranean and confined 3D scenarios. We also present a comprehensive list of insights on open challenges and possible directions for future investigation in the topic.},
  archive      = {J_RAS},
  author       = {Héctor Azpúrua and Maíra Saboia and Gustavo M. Freitas and Lillian Clark and Ali-akbar Agha-mohammadi and Gustavo Pessin and Mario F.M. Campos and Douglas G. Macharet},
  doi          = {10.1016/j.robot.2022.104304},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104304},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A survey on the autonomous exploration of confined subterranean spaces: Perspectives from real-word and industrial robotic deployments},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel multi objective constraints based industrial gripper
design with optimized stiffness for object grasping. <em>RAS</em>,
<em>160</em>, 104303. (<a
href="https://doi.org/10.1016/j.robot.2022.104303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft gripper design is a rising area of research due of its great possibilities in automation. One difficult problem in robot design is the ability to grasp a broader variety of items with variable stiffness, forms, and sizes in a single gripper. An ideal soft robotic gripper design with variable stiffness was designed in this research as a grasping model. Its distinctiveness is found in the methods utilized for modelling actuators and in the shifting stiffness characteristics of silicon soft gripper. When modelling the actuator in this case, multi-objective functions like gripping displacement and force transmission ratio are taken into account, and the actuator functions are controlled by the MDF (multiple degrees of freedom). The precise stiffness needed to grasp the item is then chosen using an adaptive optimization method. This enhanced weight-based horse herd (IHH) optimization method carries out the stiffness adjustment based on actuation pressure . Additionally, the suggested soft robotic gripper with variable stiffness employs the adaptive level set (ALS) technique to build the gripping force model. Additionally, several validations are offered in relation to the outcomes for item gripping by the suggested soft gripper. This shown that the results of the created soft gripper excelled those of other methods. The developed ABBIRB 1410 robot gripper type may enhance the work cycle in industrial applications and performs object grabbing with dependability and speed. The experimental validations show that the developed gripper model provides an enhanced object grasp with a range of curvatures, delivering a maximum pulling force of 121.07 kPa at 50 kpa, 119.15 kPa for patterned pulling, and 45.05 kPa for non-patterned pulling. The designed gripper type has a curve with a minimum size of 1.1 mm and a maximum size of 218 mm. Additionally, the soft gripper for industrial applications is examined with variously sized and weighted items. The suggested gripper model achieved an RMSE performance of 2.9 and a Pearson correlation of 0.993.},
  archive      = {J_RAS},
  author       = {Venkatesa Prabu Dinakaran and Meenakshi Priya Balasubramaniyan and Quynh Hoang Le and Ali Jawad Alrubaie and Ameer Al-khaykan and Suresh Muthusamy and Hitesh Panchal and Mustafa Musa Jaber and Anil Kumar Dixit and Chander Prakash},
  doi          = {10.1016/j.robot.2022.104303},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104303},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A novel multi objective constraints based industrial gripper design with optimized stiffness for object grasping},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human–robot handover with prior-to-pass soft/rigid object
classification via tactile glove. <em>RAS</em>, <em>159</em>, 104311.
(<a href="https://doi.org/10.1016/j.robot.2022.104311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human–robot handovers constitute a challenging and fundamental aspect of physical human–robot interaction. This paper describes the design and implementation of a human–robot handover pipeline in the case in which both soft and rigid objects are passed by the human to the robot. These objects require different profiles of grasping torques by the robot hand fingers, so as to avoid damaging them. As a viable solution to this problem, a tactile glove worn by the human is used to provide real-time information to a deep neural network , which classifies each object as soft or rigid in the pre-handover phase: this information is passed to the robot, which applies the grasping torque profile suitable for the specific type of object. The proposed method is designed and validated based on experiments with eight human participants and 24 objects. The outcomes of these experiments regarding classification accuracy , force and torque profiles, and evaluation of the subjective experiences via questionnaires, are described and discussed.},
  archive      = {J_RAS},
  author       = {Ayan Mazhitov and Togzhan Syrymova and Zhanat Kappassov and Matteo Rubagotti},
  doi          = {10.1016/j.robot.2022.104311},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104311},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Human–robot handover with prior-to-pass soft/rigid object classification via tactile glove},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep reinforcement learning of event-triggered communication
and consensus-based control for distributed cooperative transport.
<em>RAS</em>, <em>159</em>, 104307. (<a
href="https://doi.org/10.1016/j.robot.2022.104307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a solution to a design problem of control strategies for multi-agent cooperative transport. Although existing learning-based methods assume that the number of agents is the same as that in the training environment, the number might differ in reality considering that the robots’ batteries may completely discharge, or additional robots may be introduced to reduce the time required to complete a task. Therefore, it is crucial that the learned strategy be applicable to scenarios wherein the number of agents differs from that in the training environment. In this paper, we propose a novel multi-agent reinforcement learning framework of event-triggered communication and consensus-based control for distributed cooperative transport. The proposed policy model estimates the resultant force and torque in a consensus manner using the estimates of the resultant force and torque with the neighborhood agents. Moreover, it computes the control and communication inputs to determine when to communicate with the neighboring agents under local observations and estimates of the resultant force and torque. Therefore, the proposed framework can balance the control performance and communication savings in scenarios wherein the number of agents differs from that in the training environment. We confirm the effectiveness of our approach by using a maximum of eight and six robots in the simulations and experiments, respectively.},
  archive      = {J_RAS},
  author       = {Kazuki Shibata and Tomohiko Jimbo and Takamitsu Matsubara},
  doi          = {10.1016/j.robot.2022.104307},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104307},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Deep reinforcement learning of event-triggered communication and consensus-based control for distributed cooperative transport},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Systematic solution for optimally energy-efficient turning
radius for wheeled skid-steer rovers. <em>RAS</em>, <em>159</em>,
104306. (<a href="https://doi.org/10.1016/j.robot.2022.104306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A skid-steer rover’s power consumption is highly dependent on the turning radius of its path, with a point turn consuming much more power compared to straight line motion. As energy is the integration of instantaneous power over time, a trade-off between arcs’ turning radii and lengths should be made to minimize energy consumption. Because of the skid-steer rovers’ ability to do point turns the simplest and shortest way to traverse a distance between two points is by doing a point turn-line-point turn (PLP) maneuver. However, we show that wheeled skid-steer rovers there are scenarios where optimal Circle–Line–Circle (CLC) paths consume less energy than PLP paths. Therefore, the goal in this work is to find the best path from among CLC paths; Karush–Kuhn–Tucker (KKT) conditions are used to systematically obtain the optimally energy-efficient answer for the CLC paths. It is assumed that the rovers move forward on hard flat ground. For solving the problem, a new practical constraint constant -v c c is suggested. In this paper, comparing the KKT conditions and experimental results reveals that the lowest total energy consumption for CLC paths with or without considering constant -v c c constraint is obtained by selecting turning radii equal to R ′ R′ (the half of slip-track).},
  archive      = {J_RAS},
  author       = {Meysam Effati and Krzysztof Skonieczny},
  doi          = {10.1016/j.robot.2022.104306},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104306},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Systematic solution for optimally energy-efficient turning radius for wheeled skid-steer rovers},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improvement of strong tracking UKF-SLAM approach using
three-position ultrasonic detection. <em>RAS</em>, <em>159</em>, 104305.
(<a href="https://doi.org/10.1016/j.robot.2022.104305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As for the uncertainty problem of detection and estimation of robot localization and mapping using ultrasonic sensor , this paper proposes the improvement of Strong Tracking UKF-SLAM approach using three-position ultrasonic detection. A three-position ultrasonic detection model is first of all built for reducing these uncertainties through topological relationship screening and environmental contour estimation. Then Strong Tracking UKF-SLAM approach is improved by using multiple fade factors to fuse the ultrasonic measurement data and motion model information of robot for obtaining more accurate localization and mapping. Finally, we construct simulation and indoor experimental environments and design the mobile robot system with ultrasonic sensor for verification. The simulation represents that the improved algorithm has less error and more accurate effect than original algorithms in localization and mapping of mobile robot. The indoor environmental experiment is performed for illustrating the feasibility and effectiveness of the proposed method. The proposed method has certain reference value for research of Simultaneous Localization and Mapping.},
  archive      = {J_RAS},
  author       = {Shuai Yuan and Jian Wu and Fangjun Luan and Lili Zhang and Jiaqi Lv},
  doi          = {10.1016/j.robot.2022.104305},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104305},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Improvement of strong tracking UKF-SLAM approach using three-position ultrasonic detection},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Caster walker GAIT trainer (CGT): A robotic assistive
device. <em>RAS</em>, <em>159</em>, 104302. (<a
href="https://doi.org/10.1016/j.robot.2022.104302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke has become one of the leading causes of lower limb paresis. Costing the patients, a fortune for its diagnosis and prognosis. Clinical experimentations have proven that one can regain ambulation if the rehabilitation is started in the acute or sub-acute stage. Traditional mode of rehabilitation include manual therapies which are labor-intensive and time consuming. Therefore, robotic training are preferred over manual therapies. Nevertheless, there are some limitations such as devices are bulky and complex, some are not portable, others need body weight support system, and costly. To address such issues, this paper proposes development of a new Caster Walker Gait Trainer (CGT) for gait rehabilitation. CGT is an end-effector based passive device in which Stephenson III six-bar linkage has been implemented to mimic the kinematics of a healthy gait. The trainer device uses a belt-pulley system for providing motion to the linkage. The lower limb of the patient gets the drive as he/she pushes the cater walker forward or backward. The paper also proposed the optimal design of defect-free Stephenson III six-bar linkage using loop-by-loop approach. To design the linkage, an optimal problem is formulated, and tear drop ankle trajectory is desired. The optimization problem is solved using a nature-inspired algorithm and it is found that the trajectory generated by the synthesized mechanism is able to mimic the desired trajectory . Then using the notion of inverse kinematics , hip and knee trajectories are obtained from the generated ankle trajectory for validation.},
  archive      = {J_RAS},
  author       = {Ramanpreet Singh and Vimal Kumar Pathak and Abhishek Sharma and Debaditya Chakraborty and Kuldeep K. Saxena and C. Prakash and Dharam Buddhi and Karrar hazim Salem},
  doi          = {10.1016/j.robot.2022.104302},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104302},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Caster walker GAIT trainer (CGT): A robotic assistive device},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A formal toolchain for offline and run-time verification of
robotic systems. <em>RAS</em>, <em>159</em>, 104301. (<a
href="https://doi.org/10.1016/j.robot.2022.104301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Validation and Verification (V&amp;V) of autonomous robotic system software is becoming a critical issue. Among the V&amp;V techniques at our disposal, formal approaches are among the most rigorous and trustworthy ones. Yet, the level of skills and knowledge required to use and deploy formal methods is usually quite high and rare. In this paper, we describe an approach that starts from a regular, but rigorous, framework to specify and deploy robotic software components, which can also automatically synthesize a formal model of these components. We describe how we can execute the resulting formal model, in place of a traditional implementation, and show how this provides the opportunity to add powerful monitoring and runtime verification capabilities to a system, e.g., to prevent collisions , or trigger an emergency landing. Since the runtime used to execute formal models is specifically designed to be faithful to their semantics, every execution (in the implementation) can be mapped to a trace in the specification. As a result, we can also prove many interesting properties offline, using model-checking techniques. We give several examples, such as properties about schedulability, worst-case traversal time, or mutual exclusion . We believe that having a consistent workflow, from an initial specification of our system, down to a formal, executable specification is a major advance in robotics and opens the way for verification of functional components of autonomous robots and beyond. We illustrate this claim by describing a complete example based on a genuine drone flight controller.},
  archive      = {J_RAS},
  author       = {Silvano Dal Zilio and Pierre-Emmanuel Hladik and Félix Ingrand and Anthony Mallet},
  doi          = {10.1016/j.robot.2022.104301},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104301},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A formal toolchain for offline and run-time verification of robotic systems},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of semantic reasoning frameworks for robotic
systems. <em>RAS</em>, <em>159</em>, 104294. (<a
href="https://doi.org/10.1016/j.robot.2022.104294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are increasingly transitioning from specialized, single-task machines to general-purpose systems that operate in diverse and dynamic environments. To address the challenges associated with operation in real-world domains, robots must effectively generalize knowledge, learn, and be transparent in their decision making. This survey examines Semantic Reasoning techniques for robotic systems , which enable robots to encode and use semantic knowledge , including concepts, facts, ideas, and beliefs about the world. Continually perceiving, understanding, and generalizing semantic knowledge allows a robot to identify the meaningful patterns shared between problems and environments, and therefore more effectively perform a wide range of real-world tasks. We identify the three common components that make up a computational Semantic Reasoning Framework : knowledge sources, computational frameworks, and world representations. We analyze the existing implementations and the key characteristics of these components, highlight the many interactions that occur between them, and examine their integration for solving robotic tasks related to five aspects of the world, including objects, spaces, agents, tasks, and actions. By analyzing the computational formulation and underlying mechanisms of existing methods, we provide a unified view of the wide range of semantic reasoning techniques and identify open areas for future research.},
  archive      = {J_RAS},
  author       = {Weiyu Liu and Angel Daruna and Maithili Patel and Kartik Ramachandruni and Sonia Chernova},
  doi          = {10.1016/j.robot.2022.104294},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104294},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A survey of semantic reasoning frameworks for robotic systems},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust deflection control and analysis of a fishing rod-type
flexible robotic manipulator for collaborative robotics. <em>RAS</em>,
<em>159</em>, 104293. (<a
href="https://doi.org/10.1016/j.robot.2022.104293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to high-speed operation at low inertia, flexible manipulators are becoming more and more popular in today’s world. These manipulators produce excessive vibration, which must be reduced using an efficient control technique for the manipulator to function well. In the present study, a flexible manipulator model with a single link is built in such a manner that it can be considered as a flexible fishing rod. The free end of the flexible rod has a provision for applying a payload, which serves to give a deflection of the flexible rod. A lumped parameter method is adopted for modelling the flexible rod as well as the string using the Sim-Mechanics tool in MATLAB. Simulations were carried out for sudden and sinusoidal loading. It has been found that the flexible link produces excessive vibration under both sudden and sinusoidal loading. A proportional integral derivative (PID) controller is used to suppress the excessive vibration generated in the simulation model. Four different locations (Location 1: 15 cm; Location 2: 30 cm; Location 3: 45 cm; and Location 4: 60 cm) are selected for controller positioning. Simulation revealed that the minimum deflection was observed at location 4, i.e., at the tip for both sudden and sinusoidal loading. The developed model is validated using two loading conditions, viz., the beam’s self-weight and a point load of 30 N at the free end. It has been found that the simulation results resemble the analytical results with an error of 0.44\% and 0.36\% for both the loading conditions.},
  archive      = {J_RAS},
  author       = {Prasenjit Sarkhel and Mithilesh K. Dikshit and Vimal Kumar Pathak and Kuldeep K. Saxena and C. Prakash and Dharam Buddhi},
  doi          = {10.1016/j.robot.2022.104293},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104293},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robust deflection control and analysis of a fishing rod-type flexible robotic manipulator for collaborative robotics},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). INDI-based aggressive quadrotor flight control with position
and attitude constraints. <em>RAS</em>, <em>159</em>, 104292. (<a
href="https://doi.org/10.1016/j.robot.2022.104292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have significantly contributed to the extensive use of quadrotors for delivery, mapping, and inspection. To further increase the versatility of quadrotors under confined environments, we focus on the precise trajectory tracking problem with position and attitude constraints. In tightly constrained scenarios, any slight error will infect flight security, especially in a large attitude maneuver. We utilize the incremental nonlinear dynamic inversion (INDI) method to precisely linearize the nonlinearities in the system and generalize it to the entire rotation space to reach a globally expressed control law. Meanwhile, the thrust alignment is introduced to improve the robustness against the mismatch between actuator dynamics and rotational dynamics, guaranteeing higher tracking accuracy. Improvements over a conventional geometry tracking controller are demonstrated in experiments where the quadrotor flies through an inclined narrow gap with orientation up to 90°. Flight tests also indicate the high disturbance rejection capabilities with the thrust alignment in gap traverse flight.},
  archive      = {J_RAS},
  author       = {Jiesong Yang and Zhihao Cai and Jiang Zhao and Zexin Wang and Yongfei Ding and Yingxun Wang},
  doi          = {10.1016/j.robot.2022.104292},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104292},
  shortjournal = {Robot. Auton. Syst.},
  title        = {INDI-based aggressive quadrotor flight control with position and attitude constraints},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A non-potential orthogonal vector field method for more
efficient robot navigation and control. <em>RAS</em>, <em>159</em>,
104291. (<a href="https://doi.org/10.1016/j.robot.2022.104291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To navigate and control a single mobile robot or a robotic swarm with higher efficiency, a novel non-potential orthogonal vector field method is proposed in this paper, which is modified from the traditional artificial potential field method. The improvement strategy aims at making the overall repulsive vector field orthogonal to the attractive vector field in some conditions. And the same potential field function is still applied to the Lyapunov-based stability analysis. In short, such an improvement strategy combines the advantages of the artificial potential field method with the non-potential vector field method, namely a combination of theoretical completeness and control efficiency. Finally, the effectiveness of the proposed method is validated both by numerical simulations with statistical significance and real experiments. The comparisons between our method and other methods are also presented.},
  archive      = {J_RAS},
  author       = {Yan Gao and Chenggang Bai and Rao Fu and Quan Quan},
  doi          = {10.1016/j.robot.2022.104291},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104291},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A non-potential orthogonal vector field method for more efficient robot navigation and control},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting the confusions of semantic places to improve
service robotic tasks in indoor environments. <em>RAS</em>,
<em>159</em>, 104290. (<a
href="https://doi.org/10.1016/j.robot.2022.104290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant challenge in service robots is the semantic understanding of their surrounding areas. Traditional approaches addressed this problem by segmenting the environment into regions corresponding to full rooms that are assigned labels consistent with human perception, e.g. office or kitchen . However, different areas inside the same room can be used in different ways: Could the table and the chair in my kitchen become my office ? What is the category of that area now? office or kitchen ? To adapt to these circumstances we propose a new paradigm where we intentionally relax the resulting labeling of place classifiers by allowing confusions, and by avoiding further filtering leading to clean full room classifications. Our hypothesis is that confusions can be beneficial to a service robot and, therefore, they can be kept and better exploited. Our approach creates a subdivision of the environment into different regions by maintaining the confusions which are due to the scene appearance or to the distribution of objects. In this paper, we present a proof of concept implemented in simulated and real scenarios, that improves efficiency in the robotic task of searching for objects by exploiting the confusions in place classifications.},
  archive      = {J_RAS},
  author       = {Alejandra C. Hernandez and Clara Gomez and Ramon Barber and Oscar Martinez Mozos},
  doi          = {10.1016/j.robot.2022.104290},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104290},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Exploiting the confusions of semantic places to improve service robotic tasks in indoor environments},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balanced task allocation and collision-free scheduling of
multi-robot systems in large spacecraft structure manufacturing.
<em>RAS</em>, <em>159</em>, 104289. (<a
href="https://doi.org/10.1016/j.robot.2022.104289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of multiple cooperating industrial robots provides efficient and flexible solutions to the manufacturing of complex aerospace structures. Such applications require the workloads to be sufficiently shared between neighboring robots, this entails the collision-free scheduling of many discrete tasks, where precedence orders need to be assigned for specific tasks. In this paper, we first present a two-step task allocation method that handles workload balancing , then a scheduling algorithm combining construction heuristic with iterated local search to provide efficient schedules. Our key innovation is a collision model that encodes precedence constraints and a fast heuristic that constructs collision-free schedule under given constraints, the optimization of the schedule is then addressed by an iterated local search . The advantage in terms of minimizing makespan under different problem scales and conditions is validated by computational experiments. Finally, the use of our method is demonstrated by a physical multi-robot system.},
  archive      = {J_RAS},
  author       = {Shaorui Liu and Jianxin Shen and Wei Tian and Jiamei Lin and Pengcheng Li and Bo Li},
  doi          = {10.1016/j.robot.2022.104289},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104289},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Balanced task allocation and collision-free scheduling of multi-robot systems in large spacecraft structure manufacturing},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive path planning for UAVs for multi-resolution
semantic segmentation. <em>RAS</em>, <em>159</em>, 104288. (<a
href="https://doi.org/10.1016/j.robot.2022.104288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient data collection methods play a major role in helping us better understand the Earth and its ecosystems. In many applications, the usage of unmanned aerial vehicles (UAVs) for monitoring and remote sensing is rapidly gaining momentum due to their high mobility, low cost, and flexible deployment. A key challenge is planning missions to maximize the value of acquired data in large environments given flight time limitations. This is, for example, relevant for monitoring agricultural fields. This paper addresses the problem of adaptive path planning for accurate semantic segmentation of using UAVs. We propose an online planning algorithm which adapts the UAV paths to obtain high-resolution semantic segmentations necessary in areas with fine details as they are detected in incoming images. This enables us to perform close inspections at low altitudes only where required, without wasting energy on exhaustive mapping at maximum image resolution. A key feature of our approach is a new accuracy model for deep learning-based architectures that captures the relationship between UAV altitude and semantic segmentation accuracy. We evaluate our approach on different domains using real-world data, proving the efficacy and generability of our solution.},
  archive      = {J_RAS},
  author       = {Felix Stache and Jonas Westheider and Federico Magistri and Cyrill Stachniss and Marija Popović},
  doi          = {10.1016/j.robot.2022.104288},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104288},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Adaptive path planning for UAVs for multi-resolution semantic segmentation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Static map generation from 3D LiDAR point clouds exploiting
ground segmentation. <em>RAS</em>, <em>159</em>, 104287. (<a
href="https://doi.org/10.1016/j.robot.2022.104287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A clean and reliable map of the environment is key for a variety of robotic tasks including localization , path planning , and navigation. Dynamic objects are an inherent part of our world, but their presence often deteriorates the performance of various mapping algorithms . This not only makes it important but necessary to remove these dynamic points from the map before they can be used for other tasks such as path planning . In this paper, we address the problem of building maps of the static aspects of the world by detecting and removing dynamic points from the source point clouds. We target a map cleaning approach that removes the dynamic points and maintains a high quality map of the static part of the world. To this end, we propose a novel offline ground segmentation method and integrate it into the OctoMap to better distinguish between the moving objects and static road backgrounds. We evaluate our approach using SemanticKITTI for both, dynamic object removal and ground segmentation algorithms as well as on the Apollo dataset. The evaluation results show that our method outperforms the baseline methods in both tasks and achieves good performance in generating clean maps over different datasets without any change in the parameters.},
  archive      = {J_RAS},
  author       = {Mehul Arora and Louis Wiesmann and Xieyuanli Chen and Cyrill Stachniss},
  doi          = {10.1016/j.robot.2022.104287},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104287},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Static map generation from 3D LiDAR point clouds exploiting ground segmentation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time multi-modal semantic fusion on unmanned aerial
vehicles with label propagation for cross-domain adaptation.
<em>RAS</em>, <em>159</em>, 104286. (<a
href="https://doi.org/10.1016/j.robot.2022.104286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) equipped with multiple complementary sensors have tremendous potential for fast autonomous or remote-controlled semantic scene analysis , e.g., for disaster examination. Here, we propose a UAV system for real-time semantic inference and fusion of multiple sensor modalities. Semantic segmentation of LiDAR scans and RGB images , as well as object detection on RGB and thermal images , run online onboard the UAV computer using lightweight CNN architectures and embedded inference accelerators. We follow a late fusion approach where semantic information from multiple sensor modalities augments 3D point clouds and image segmentation masks while also generating an allocentric semantic map. Label propagation on the semantic map allows for sensor-specific adaptation with cross-modality and cross-domain supervision. Our system provides augmented semantic images and point clouds with ≈ ≈ 9 Hz. We evaluate the integrated system in real-world experiments in an urban environment and at a disaster test site.},
  archive      = {J_RAS},
  author       = {Simon Bultmann and Jan Quenzel and Sven Behnke},
  doi          = {10.1016/j.robot.2022.104286},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104286},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Real-time multi-modal semantic fusion on unmanned aerial vehicles with label propagation for cross-domain adaptation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Power solutions for autonomous mobile robots: A survey.
<em>RAS</em>, <em>159</em>, 104285. (<a
href="https://doi.org/10.1016/j.robot.2022.104285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous mobile robots are a special class of robotic systems that can move a payload from one location to the other or perform a specific task. They allow efficient, precise, and streamlined workflow that makes human work less arduous. The market and research work related to these robots is increasing in anticipation of industry 5.0 , where humans and machines are expected to co-exist and co-work. The future mobile robots are desired to have clean and cost-effective energy sources to have longer operation times and compliance with environmental requirements to allow application in diverse fields. The research on mechanical design, perception, navigation and control has carved out many commercially viable solutions for mobile robots. However, their widespread application is still limited due to the lack of efficient power systems for use in diverse and largely unknown/uncontrolled environments. The current power solutions incur high initial costs and require recharging or refuelling, which makes them unsuitable for unattended long-haul worktimes and cost-effective applications. These drawbacks are major hurdles in the wider applicability of terrain-based mobile robots to new domains and daily life scenarios, which are possible with the existing mechanical, perception, and control technologies. Keeping in view the need for advancement in this field and to gain a better understanding of the current state of the art and future directions, this work summarizes and reviews the energy solutions presented in the literature and used in notable commercially available terrain-based mobile robots. The provided solutions are categorized and discussed while the prospects and research gaps are also highlighted. A comparison of discussed power techniques is also provided, which can serve as a guideline for selecting a robot’s energy source according to the desired requirements.},
  archive      = {J_RAS},
  author       = {Muhammad Umar Farooq and Amre Eizad and Hyun-Ki Bae},
  doi          = {10.1016/j.robot.2022.104285},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104285},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Power solutions for autonomous mobile robots: A survey},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Congestion control algorithms for robotic swarms with a
common target based on the throughput of the target area. <em>RAS</em>,
<em>159</em>, 104284. (<a
href="https://doi.org/10.1016/j.robot.2022.104284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a large number of robots try to reach a common area, congestions happen, causing severe delays. To minimise congestion in a robotic swarm system, traffic control algorithms must be employed in a decentralised manner. Based on strategies aimed to maximise the throughput of the common target area, we developed two novel algorithms for robots using artificial potential fields for obstacle avoidance and navigation. One algorithm is inspired by creating a queue to get to the target area (Single Queue Former — SQF), while the other makes the robots touch the boundary of the circular area by using vector fields (Touch and Run Vector Fields — TRVF). We performed simulation experiments to show that the proposed algorithms are bounded by the throughput of their inspired theoretical strategies and compare the two novel algorithms with state-of-art algorithms for the same problem (PCC, EE and PCC–EE). The SQF algorithm significantly outperforms all other algorithms for a large number of robots or when the circular target region radius is small. TRVF, on the other hand, is better than SQF only for a limited number of robots and outperforms only PCC for numerous robots. However, it allows us to analyse the potential impacts on the throughput when transferring an idea from a theoretical strategy to a concrete algorithm that considers changing linear speeds and distances between robots.},
  archive      = {J_RAS},
  author       = {Yuri Tavares dos Passos and Xavier Duquesne and Leandro Soriano Marcolino},
  doi          = {10.1016/j.robot.2022.104284},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104284},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Congestion control algorithms for robotic swarms with a common target based on the throughput of the target area},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online pole segmentation on range images for long-term LiDAR
localization in urban environments. <em>RAS</em>, <em>159</em>, 104283.
(<a href="https://doi.org/10.1016/j.robot.2022.104283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust and accurate localization is a basic requirement for mobile autonomous systems . Pole-like objects, such as traffic signs, poles, and lamps are frequently used landmarks for localization in urban environments due to their local distinctiveness and long-term stability. In this paper, we present a novel, accurate, and fast pole extraction approach based on geometric features that runs online and has little computational demands. Our method performs all computations directly on range images generated from 3D LiDAR scans, which avoids processing 3D point clouds explicitly and enables fast pole extraction for each scan. We further use the extracted poles as pseudo labels to train a deep neural network for online range image-based pole segmentation. We test both our geometric and learning-based pole extraction methods for localization on different datasets with different LiDAR scanners, routes, and seasonal changes. The experimental results show that our methods outperform other state-of-the-art approaches. Moreover, boosted with pseudo pole labels extracted from multiple datasets, our learning-based method can run across different datasets and achieve even better localization results compared to our geometry-based method. We released our pole datasets to the public for evaluating the performance of pole extractors, as well as the implementation of our approach.},
  archive      = {J_RAS},
  author       = {Hao Dong and Xieyuanli Chen and Simo Särkkä and Cyrill Stachniss},
  doi          = {10.1016/j.robot.2022.104283},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104283},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Online pole segmentation on range images for long-term LiDAR localization in urban environments},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mapping beyond what you can see: Predicting the layout of
rooms behind closed doors. <em>RAS</em>, <em>159</em>, 104282. (<a
href="https://doi.org/10.1016/j.robot.2022.104282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of maps of indoor environments is often fundamental for autonomous mobile robots to efficiently operate in industrial, office, and domestic applications. When robots build such maps, some areas of interest could be inaccessible, for instance, due to closed doors. As a consequence, these areas are not represented in the maps, possibly causing limitations in robot localization and navigation. In this paper, we provide a method that completes 2D grid maps by adding the predicted layout of the rooms behind closed doors. The main idea of our approach is to exploit the underlying geometrical structure of indoor environments to estimate the shape of unobserved rooms. Results show that our method is accurate in completing maps also when large portions of environments cannot be accessed by the robot during map building. We experimentally validate the quality of the completed maps by using them to perform path planning tasks.},
  archive      = {J_RAS},
  author       = {Matteo Luperto and Federico Amadelli and Moreno Di Berardino and Francesco Amigoni},
  doi          = {10.1016/j.robot.2022.104282},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104282},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Mapping beyond what you can see: Predicting the layout of rooms behind closed doors},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consistency optimal coordination control of underground
heavy-load robot in nonstructural environment. <em>RAS</em>,
<em>159</em>, 104281. (<a
href="https://doi.org/10.1016/j.robot.2022.104281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to guarantee the dynamic stability of robots in nonstructural environment, this paper proposes a new consistency optimal coordination (COC) control strategy. Firstly, by analyzing the topological structure , motion correlation and control coupling relationship among subsystems, the general expression of multi-body coupling system (MCS) for underground heavy-load robot is realized. Then, the transient spatial output deviations are proposed as the characterization of dynamic stability for the underground heavy-load robot. Afterwards, in order to reduce the strong coupling relationship among subsystems, the underground heavy-load robot is decoupled into fixed-point and non-fixed-point operation modes, the Nyquist stability and Lyapunov stability are applied to discriminate the dynamic stability of two working modes respectively. Finally, based on the idea of minimum loop gain compensation of mechanism, the COC control strategy is proposed, which can coordinate the subsystems to be consistent, so as to realize the dynamic stability of overall system in nonstructural environment. Both the experimental and situational results verify that the COC control strategy proposed in this paper not only realizes stable output of robot, but also effectively reduces the lag caused by instability. The work of this paper improves the dynamic stability analysis theory for robots, and promotes adaptability and dynamic response capability of moving robots as well.},
  archive      = {J_RAS},
  author       = {Lixia Fang and Tong Wang and Weixiong Zheng and Zhigang Liu and Liu Ming and Xiaowen Zheng and Miao Wu},
  doi          = {10.1016/j.robot.2022.104281},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104281},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Consistency optimal coordination control of underground heavy-load robot in nonstructural environment},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Audio–visual language instruction understanding for robotic
sorting. <em>RAS</em>, <em>159</em>, 104271. (<a
href="https://doi.org/10.1016/j.robot.2022.104271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For robot in human environment, it has always been expected that the robot can execute specified tasks following language instructions. Most current methods only rely on visual perception to understand the language instruction, while it may be not sufficient to fully interpret some language instructions when visually identical objects exist. In this paper, we propose a task of audio–visual language instruction understanding for robotic sorting, in which the robot is able to use both the visual and audio information to fully understand and execute the given instruction. To solve the proposed task, an audio–visual fusion framework is developed, which combines the visual localization and audio recognition models together for the robotic sorting task following language instruction. We have also collected a multimodal dataset for evaluation, and extensive experiments are conducted within the dataset and generalized to new scenarios in physical world demonstrating the effectiveness of the proposed framework.},
  archive      = {J_RAS},
  author       = {Di Guo and Huaping Liu and Fuchun Sun},
  doi          = {10.1016/j.robot.2022.104271},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104271},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Audio–visual language instruction understanding for robotic sorting},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consensus-based fast and energy-efficient multi-robot task
allocation. <em>RAS</em>, <em>159</em>, 104270. (<a
href="https://doi.org/10.1016/j.robot.2022.104270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a multi-robot system, the appropriate allocation of the tasks to the individual robots is a very significant component. The availability of a centralized infrastructure can guarantee an optimal allocation of the tasks. However, in many important scenarios such as search and rescue, exploration, disaster-management, war-field, etc., on-the-fly allocation of the dynamic tasks to the robots in a decentralized fashion is the only possible option. Efficient communication among the robots plays a crucial role in any such decentralized setting. Existing works on distributed Multi-Robot Task Allocation (MRTA) either assume that the network is available or a naive communication paradigm is used. On the contrary, in most of these scenarios, the network infrastructure is either unstable or unavailable and ad-hoc networking is the only resort. Recent developments in synchronous-transmission (ST) based wireless communication protocols are shown to be more efficient than the traditional asynchronous transmission-based protocols in ad hoc networks such as Wireless Sensor Network (WSN)/ Internet of Things (IoT) applications. The current work is the first effort that utilizes ST for MRTA. Specifically, we propose an algorithm that efficiently adapts ST-based many-to-many interaction and minimizes the information exchange to reach a consensus for task allocation. We showcase the efficacy of the proposed algorithm through an extensive simulation-based study of its latency and energy-efficiency under different settings.},
  archive      = {J_RAS},
  author       = {Prabhat Mahato and Sudipta Saha and Chayan Sarkar and Md. Shaghil},
  doi          = {10.1016/j.robot.2022.104270},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104270},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Consensus-based fast and energy-efficient multi-robot task allocation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to control highly accelerated ballistic movements
on muscular robots. <em>RAS</em>, <em>159</em>, 104230. (<a
href="https://doi.org/10.1016/j.robot.2022.104230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed and high-acceleration movements are inherently hard to control. Applying learning to the control of such motions on anthropomorphic robot arms can improve the control’s accuracy but might damage the system. The inherent exploration of learning approaches can lead to instabilities and the robot reaching joint limits at high speeds. Having hardware that enables safe exploration of high-speed and high-acceleration movements is therefore desirable. To address this issue, we propose to use robots actuated by pneumatic artificial muscles (PAMs). In this paper, we present a four degrees of freedom (DoFs) robot arm that reaches high joint angle accelerations of up to 28 000° s -2 while avoiding dangerous joint limits thanks to the antagonistic actuation and limits on the air pressure ranges. With this robot arm, we can tune control parameters using Bayesian optimization directly on the hardware without additional safety considerations. The achieved tracking performance on a fast trajectory exceeds previous results on comparable PAM-driven robots. We also show that our system can be controlled well on slow trajectories with PID controllers due to careful construction considerations such as minimal bending of cables, lightweight kinematics, and minimal contact between PAMs and PAMs with the links. Finally, we propose a novel technique to control the co-contraction of antagonistic muscle pairs. Experimental results illustrate that choosing the optimal co-contraction level is vital to reach better tracking performance. Using PAM-driven robots and learning, we do a small step towards the future development of robots capable of more human-like motions.},
  archive      = {J_RAS},
  author       = {Dieter Büchler and Roberto Calandra and Jan Peters},
  doi          = {10.1016/j.robot.2022.104230},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104230},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Learning to control highly accelerated ballistic movements on muscular robots},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
