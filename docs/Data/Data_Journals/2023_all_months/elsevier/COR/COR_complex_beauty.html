<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cor---283">COR - 283</h2>
<ul>
<li><details>
<summary>
(2023). Exact approaches for the unconstrained two-dimensional
cutting problem with defects. <em>COR</em>, <em>160</em>, 106407. (<a
href="https://doi.org/10.1016/j.cor.2023.106407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the unconstrained two-dimensional cutting problem with defects, which requires cutting a set of rectangular item types from a rectangular sheet with defects. The available number of each type is not limited. Two versions of the problem are studied, based on whether the guillotine cut constraint is required. Due to equipment limitations, the guillotine cutting restrictions are essential in specific industries , requiring cutting from one side to the other with each cut and splitting the sheet into two separate sheets. An integer model is proposed for the non-guillotine cut version, and an exact dynamic programming (DP) approach is proposed for the guillotine cut version. To reduce the number of vertical and horizontal positions, we extend the normal patterns, raster points, and meet-in-the-middle patterns to consider the effect of defects. The experimental results on standard benchmarks show that the proposed model can solve most of the instances in literature in a short time. For the guillotine cut version, our approach can significantly reduce the number of cut positions and improve the efficiency of the DP approach compared to the previous exact approach that considers all possible positions. Our approach solves the large instances with more than 300 item types in a relatively short time.},
  archive      = {J_COR},
  author       = {Hao Zhang and Shaowen Yao and Qiang Liu and Jiewu Leng and Lijun Wei},
  doi          = {10.1016/j.cor.2023.106407},
  journal      = {Computers &amp; Operations Research},
  pages        = {106407},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exact approaches for the unconstrained two-dimensional cutting problem with defects},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A spatial pyramid pooling-based deep reinforcement learning
model for dynamic job-shop scheduling problem. <em>COR</em>,
<em>160</em>, 106401. (<a
href="https://doi.org/10.1016/j.cor.2023.106401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic job-shop scheduling problem (DJSP) is a typical of scheduling tasks where rescheduling is performed when encountering unexpected events such as random job arrivals and rush order. However, the current rescheduling approaches cannot reuse the trained scheduling policies or the experiences due to the variant size of scheduling problems. In this paper, we propose a deep reinforcement learning (DRL) scheduling model for DJSP based on spatial pyramid pooling networks (SPP-Net). A new state representation is proposed based on the machine matrix and remaining time matrix which is decomposed from the scheduling instance matrix. And a new reward function is derived from the area of total scheduling time where the accumulated reward is negatively linearly dependent with the make-span of a scheduling task. Moreover, a size-agnostic scheduling policy is designed based on the SPP-Net and SoftMax function , which is trained by the proximal policy optimization (PPO). Besides, various paired priority dispatching rules (PDR) are used as available actions. Static experiments on classic benchmark instances show that our scheduling model achieves better results on average than existing DRL methods. In addition, dynamic scheduling experiments are tested and our model obtains better results than the PDR scheduling methods in reasonable time when encountering unexpected events such as random job arrivals and rush order.},
  archive      = {J_COR},
  author       = {Xinquan Wu and Xuefeng Yan},
  doi          = {10.1016/j.cor.2023.106401},
  journal      = {Computers &amp; Operations Research},
  pages        = {106401},
  shortjournal = {Comput. Oper. Res.},
  title        = {A spatial pyramid pooling-based deep reinforcement learning model for dynamic job-shop scheduling problem},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ambulance location routing problem considering all sources
of uncertainty: Progressive estimating algorithm. <em>COR</em>,
<em>160</em>, 106400. (<a
href="https://doi.org/10.1016/j.cor.2023.106400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main concern of any emergency medical services (EMS) in the world is to provide quality services to emergency calls in the shortest possible time. In this paper, the Ambulance Location Routing problem (ALRP) is proposed that is a mathematical attempt to obtain optimal cost-oriented strategic decisions (locating EMS centers and allocating ambulance fleet) in a way that guarantees service quality factors like response time, service level, and definite treatment time through optimal ambulance routing. In response to the concerns that emergency medical services deal with, in this research, a novel mixed-integer two-stage stochastic programming model is developed that can consider the uncertain nature of parameters like emergency calls, travel times, and pathways, simultaneously. Considering a heterogeneous fleet of ambulances to provide specialized out-of-hospital services and to use the treatment golden time, and considering different types of patients in terms of the need to be transferred to the hospital, are among the most vital innovations of the proposed ALRP. To tackle the computational complexity, a new decomposition-based heuristic method called the Progressive Estimating Algorithm (PEA) is developed. PEA is a modified version of the classic PHA and solves its drawbacks, like the possibility of being placed in a loop or prolonging the solution time by changing the method of calculating the first stage variables in each iteration. Therefore, by considering a large number of scenarios, PEA can reach feasible near-optimal solutions more efficiently. We have employed the actual data of a city with nearly 800.000 population, as a case study to validate the proposed ALRP model and the PEA method. The obtained results demonstrate that the proposed ALRP solution is valid, and the PEA can reach the near-optimal solution, in a very reasonable time, and with no exception, outperform the PHA. The results also show that the ALRP model reduces costs on average by 30\% compared to a benchmark model. In addition, it is found that the solution obtained for the case study can reduce costs by 58\% compared to the current state of the EMS in this city while guaranteeing the quality of services. Furthermore, the need to use a heterogeneous fleet of ambulances and scattered stations in the region is recommended to improve the performance of EM services. Finally, the unique way of looking at the integrated problem of location, allocation, and routing in the proposed ALRP and the idea of PEA are attractive for further studies in the field of EMS planning and other optimization problems, and several suggestions for future studies are mentioned in Conclusion Section.},
  archive      = {J_COR},
  author       = {Farnaz Khoshgehbari and S. Mohammad J. Mirzapour Al-e-Hashem},
  doi          = {10.1016/j.cor.2023.106400},
  journal      = {Computers &amp; Operations Research},
  pages        = {106400},
  shortjournal = {Comput. Oper. Res.},
  title        = {Ambulance location routing problem considering all sources of uncertainty: Progressive estimating algorithm},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving the 1-median problem on a network with continuous
demand and demand surplus. <em>COR</em>, <em>160</em>, 106399. (<a
href="https://doi.org/10.1016/j.cor.2023.106399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we address the problem of locating a delivery business with a production capacity. It is a variant of the 1-median location problem on a network, in which demand is assumed to be distributed along the edges and nodes of the network. However, instead of assuming that all the demand must be served, the location for a facility is sought minimizing the expected distance to a fraction of the demand. The problem is expressed as a Mixed Integer Nonlinear Optimization problem , solved by means of a geometric Branch and Bound algorithm .},
  archive      = {J_COR},
  author       = {Rafael Blanquero and Emilio Carrizosa and Boglárka G.-Tóth and Kristóf Kovács},
  doi          = {10.1016/j.cor.2023.106399},
  journal      = {Computers &amp; Operations Research},
  pages        = {106399},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving the 1-median problem on a network with continuous demand and demand surplus},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heuristics for the two-dimensional irregular bin packing
problem with limited rotations. <em>COR</em>, <em>160</em>, 106398. (<a
href="https://doi.org/10.1016/j.cor.2023.106398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a two-dimensional irregular bin packing problem with some specific degrees of rotations. Despite a large number of studies on the two-dimensional irregular strip packing problem , much less attention has been paid to the two-dimensional irregular bin packing problem (2DIBPP), and most of the current research on 2DIBPP is about free rotations. However, limited by the texture of the material, sometimes only some specific degrees of rotations are allowed. To pack a set of irregular pieces with some specific degrees into multi-stock sheets and maximize the utilization, we propose a heuristic algorithm that combines some pieces into one block for packing and uses residual spaces with reference lines to help select the next piece to be packed. In order to further increase the utilization of bins, we adopt fine-tuning, movement, filling, replacement and swap operations, as well as partial and full repack strategies. The computational results show that the proposed algorithm can obtain superior results on the instances with small number of pieces, relatively large number of types of pieces, large bins and more specific degrees of rotations.},
  archive      = {J_COR},
  author       = {Sifan Cai and Jie Deng and Loo Hay Lee and Ek Peng Chew and Haobin Li},
  doi          = {10.1016/j.cor.2023.106398},
  journal      = {Computers &amp; Operations Research},
  pages        = {106398},
  shortjournal = {Comput. Oper. Res.},
  title        = {Heuristics for the two-dimensional irregular bin packing problem with limited rotations},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-neighborhood iterated local search for routing and
wavelength assignment. <em>COR</em>, <em>160</em>, 106396. (<a
href="https://doi.org/10.1016/j.cor.2023.106396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum routing and wavelength assignment (min-RWA) problem is a classic and challenging NP-hard combinatorial optimization problem which aims to reduce the required wavelengths in wavelength-division multiplexing optical networks. In order to tackle this problem, we present a dual-neighborhood iterated local search (DN-ILS) by alternately evaluating a shift-shaking and a swap-shaking neighborhood to improve the current solution. Both neighborhoods are based on an ejection chain-based shaking (ECS) procedure, while the high-level procedures are shift moves and swap moves, respectively. These two move operators change the wavelengths of certain lightpaths , while the ECS refines routing for the related lightpaths . Experimental results on commonly used benchmark instances demonstrate that our proposed DN-ILS algorithm outperforms the best methods in the literature by improving the best known results for 35 out of 113 instances while matching the best known results for the remaining ones. The success of the shift-shaking and swap-shaking neighborhoods inspires us to apply them to other challenging optimization problems with multi-level decisions and strong constraints.},
  archive      = {J_COR},
  author       = {Zhipeng Lü and Yuan Fang and Zhouxing Su and Yang Wang and Xinyun Wu and Fred Glover},
  doi          = {10.1016/j.cor.2023.106396},
  journal      = {Computers &amp; Operations Research},
  pages        = {106396},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dual-neighborhood iterated local search for routing and wavelength assignment},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic community partitioning for e-commerce last mile
delivery with time window constraints. <em>COR</em>, <em>160</em>,
106394. (<a href="https://doi.org/10.1016/j.cor.2023.106394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community logistics (CL) is a recently proposed delivery strategy designed to deal with e-commerce last-mile delivery scheduling by dynamically assigning vehicles to designated delivery regions partitioned into “communities”. Since optimizing vehicle routes is not mandatory in the CL spectrum, the delivery solution format and optimization process can be greatly simplified. Nevertheless, abandoning vehicle routes means vehicle arrival time at each customer specified delivery destination is unknown, resulting in the inability of handling time window constraints of e-commerce orders. To expand the application scope of CL, this study introduces community time window, an aggregation of identical or adjacent order time windows. Once the community time window for a delivery community is satisfied, all orders in this community can be received within designated time windows without determining vehicle routes. With this new concept, the application range of the CL is extended to e-commerce last mile delivery contexts where order time window constraints are considered. A dynamic community partitioning problem with the time window is presented based on the Markov decision process (MDP). An efficient heuristic solution framework based on policy function approximation is proposed to solve the MDP model. Numerical results show that the CL is very effective in dealing with the time window constraints of e-commerce orders.},
  archive      = {J_COR},
  author       = {Zhiyuan Ouyang and Eric K.H. Leung and Yiji Cai and George Q. Huang},
  doi          = {10.1016/j.cor.2023.106394},
  journal      = {Computers &amp; Operations Research},
  pages        = {106394},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic community partitioning for e-commerce last mile delivery with time window constraints},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A logic-based benders decomposition solution approach for
two covering problems that consider the underlying transportation.
<em>COR</em>, <em>160</em>, 106393. (<a
href="https://doi.org/10.1016/j.cor.2023.106393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate two maximal covering location problems with capacity restrictions, minimum workload, and transportation. The problems are inspired by a waste collection problem in which large waste containers are scattered throughout the municipality, and the residents bring their waste to these containers. We take the residents’ preferences into account when allocating them to locations. When a container is full, a vehicle transports an empty container from the disposal facility (depot) to that location and replaces it. We propose a mixed-integer linear programming formulation for the problems in which vehicles can carry one or two containers, and apply a logic-based Benders decomposition approach for the latter. Here, the sub problem is a multi-period minimum weight perfect matching problem . We show that our logic-based Benders decomposition approach outperforms the direct formulation in terms of solution quality and speed. We further show that transportation of two containers at a time reduces the distance to be driven by 29.5\% on average, without compromising the covering level. Furthermore, we analyze the effect of imposing a minimum workload as well as the effect of changing the focus between transportation and covering.},
  archive      = {J_COR},
  author       = {Vera Fischer and Sanne Wøhlk},
  doi          = {10.1016/j.cor.2023.106393},
  journal      = {Computers &amp; Operations Research},
  pages        = {106393},
  shortjournal = {Comput. Oper. Res.},
  title        = {A logic-based benders decomposition solution approach for two covering problems that consider the underlying transportation},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logic-based benders decomposition for wildfire suppression.
<em>COR</em>, <em>160</em>, 106392. (<a
href="https://doi.org/10.1016/j.cor.2023.106392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider a network interdiction problem where the follower is characterised by a spreading phenomenon. As a case study we consider in detail a wildfire suppression problem. The landscape is modelled as a directed graph , with nodes representing regions of the landscape, and arcs representing adjacency relationships. The fire spread is modelled using the minimum travel time principle. The goal is to locate fire suppression resources in a landscape in order to minimise the total area burned. As previous exact algorithms in this space are intractable on reasonable instances, the literature focuses on heuristics. In this paper we propose a new exact algorithm utilising logic-based Benders decomposition . We benchmark the new approach against mixed-integer programming and metaheuristic approaches. Our approach is able to quickly solve instances from the literature. We are also able to solve larger instances to optimality in a reasonable amount of time.},
  archive      = {J_COR},
  author       = {Mitchell G. Harris and Michael A. Forbes and Thomas Taimre},
  doi          = {10.1016/j.cor.2023.106392},
  journal      = {Computers &amp; Operations Research},
  pages        = {106392},
  shortjournal = {Comput. Oper. Res.},
  title        = {Logic-based benders decomposition for wildfire suppression},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data mining transmission switching heuristic for
post-contingency AC power flow violation reduction in real-world,
large-scale systems. <em>COR</em>, <em>160</em>, 106391. (<a
href="https://doi.org/10.1016/j.cor.2023.106391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transmission switching has proven to be a highly useful post-contingency recovery technique by allowing power system operators increased levels of control through leveraging the topology of the power system. However, transmission switching remains only implemented in limited capacity because of concerns over computational complexity , uncertainty of performance in AC systems, and scalability to real-world, large-scale systems. We propose a heuristic which uses a sophisticated guided undersampling procedure combined with logistic regression to accurately identify transmission switching actions to reduce post-contingency AC power flow violations. The proposed heuristic was tested on real-world, large-scale AC power system data and consistently identified optimal or near optimal transmission switching actions. Because the proposed heuristic is computationally inexpensive, addresses an AC system, and is validated on real-world large-scale data, it directly addresses the aforementioned issues regarding transmission switching implementation.},
  archive      = {J_COR},
  author       = {W. Eric Brown and Erick Moreno-Centeno},
  doi          = {10.1016/j.cor.2023.106391},
  journal      = {Computers &amp; Operations Research},
  pages        = {106391},
  shortjournal = {Comput. Oper. Res.},
  title        = {A data mining transmission switching heuristic for post-contingency AC power flow violation reduction in real-world, large-scale systems},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple traveling salesperson problem with drones: General
variable neighborhood search approach. <em>COR</em>, <em>160</em>,
106390. (<a href="https://doi.org/10.1016/j.cor.2023.106390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key factor to consider in the development of new technologies in a number of fields is the use of unmanned aerial vehicles . This rapidly developing technology is used in military, communication, health, mapping, agriculture and transportation fields. The importance of cargo transportation has grown due to the growth of e-commerce. Currently, with advancing technology, and the effect of the pandemic, purchases are increasingly made over the internet. For cargo transporters, this situation leads to an increase in the number of destination points, in distances traveled, and in the delivery frequency, and a decrease in the package sizes. As a result, the planning of transportation has become increasingly complex. One solution is to make greater use of unmanned aerial vehicles in this sector, and to reduce reliance on trucks through appropriate planning. This involves two aspects: the unmanned aerial vehicle delivering to a point, while the cargo truck delivers to a separate point. In this study, we consider a multiple traveling salesperson problem simultaneously using multiple trucks and unmanned aerial vehicles for package delivery. We develop a general variable neighborhood search algorithm, and compare the results with the existing studies in the literature. Computational experiments show that our approach is able to find highly satisfactory solutions in reasonable time, and outperforms the existing methods in terms of best solution, average solution and solution time in majority of the instances.},
  archive      = {J_COR},
  author       = {Baybars İbroşka and Selin Özpeynirci and Özgür Özpeynirci},
  doi          = {10.1016/j.cor.2023.106390},
  journal      = {Computers &amp; Operations Research},
  pages        = {106390},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multiple traveling salesperson problem with drones: General variable neighborhood search approach},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-echelon collaborative routing problem with heterogeneous
crowd-shippers. <em>COR</em>, <em>160</em>, 106389. (<a
href="https://doi.org/10.1016/j.cor.2023.106389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider a setting in which a retail store uses occasional couriers (OCs), which are not regular couriers but work as couriers on occasion, and in-store customers, which make a single delivery on the way back to their origin locations from the retail store, to perform the last-mile delivery along with its own fleet of couriers. To represent this setting, we design a two-echelon hetero-collaborative routing problem (2E-HCRP) that facilitates parcel transfers between couriers and OCs at customer nodes, in addition to in-store customer deliveries for optimizing last-mile services. We develop a mixed-integer linear programming (MILP) model and an adaptive large neighborhood search (ALNS) heuristic algorithm to devise cost-effective delivery plans that incorporate couriers, OCs, and in-store customers simultaneously. Furthermore, we introduce novel neighborhood search algorithms specifically tailored for parcel transfers and a scheduling algorithm designed for enhancing OC utilization and timely delivery to customers. We evaluate the performance of the proposed algorithms with the genetic algorithm, Monte Carlo method, and neighborhood search. The results indicate that our proposed algorithms outperform the others in minimizing travel costs and time window violations. Moreover, we provide valuable managerial implications through sensitivity analysis.},
  archive      = {J_COR},
  author       = {Byeongmok Kim and Ho Young Jeong and Seokcheon Lee},
  doi          = {10.1016/j.cor.2023.106389},
  journal      = {Computers &amp; Operations Research},
  pages        = {106389},
  shortjournal = {Comput. Oper. Res.},
  title        = {Two-echelon collaborative routing problem with heterogeneous crowd-shippers},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving dynamic satellite image data downlink scheduling
problem via an adaptive bi-objective optimization algorithm.
<em>COR</em>, <em>160</em>, 106388. (<a
href="https://doi.org/10.1016/j.cor.2023.106388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The satellite image data downlink scheduling problem (SIDSP) plays a critical role in the mission planning operation of earth observation satellites. However, with recent developments in satellite technology, the traditional SIDSP is poorly effective for modern satellites. To offer additional modeling flexibility and renewed capabilities, a dynamic SIDSP (DSIDSP), which combines two interlinked operations of image data segmentation and image data downlink dynamically, was introduced. We have formulated the DSIDSP as a bi-objective problem of optimizing the image data transmission rate and the service-balance degree. Harnessing the power of an adaptive large neighborhood search (ALNS) algorithm with a nondominated sorting genetic algorithm II (NSGA-II), an adaptive bi-objective memetic algorithm , NSGA2ALNS, is developed to solve DSIDSP. Results of extensive computational experiments carried out using benchmark instances are also presented. Our experimental results reveal that the NSGA2ALNS algorithm is an effective and efficient method of solving DSIDSP based on various performance metrics. In addition, new benchmark instances are also provided for DSIDSP that could be used in future research.},
  archive      = {J_COR},
  author       = {Zhongxiang Chang and Abraham P. Punnen and Zhongbao Zhou and Shi Cheng},
  doi          = {10.1016/j.cor.2023.106388},
  journal      = {Computers &amp; Operations Research},
  pages        = {106388},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving dynamic satellite image data downlink scheduling problem via an adaptive bi-objective optimization algorithm},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scheduling multi-staged jobs on parallel identical machines
and a central server with sequence-dependent setup times: An application
to an automated kitchen. <em>COR</em>, <em>160</em>, 106387. (<a
href="https://doi.org/10.1016/j.cor.2023.106387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of scheduling multi-staged jobs in a production environment with parallel identical machines and a central server with sequence-dependent setup times motivated by a real-life application in a robotic automated kitchen. The proposed model addresses a makespan minimization offline optimization problem that arises in the context of mise-en-place preparation. We present two mathematical formulations, one with a machine index and one without, as well as lower bounds. We also propose an effective general variable neighborhood search algorithm based on heuristics which aims to improve the incumbent by eliminating idle times. Through a series of experiments on random instances, we demonstrate the effectiveness of the proposed method under various combinations of instance parameters. On instances with known optimal solutions, the metaheuristic produces solutions with an average gap of 0.31\% in very short computation times. On large-size instances, the metaheuristic produces solutions with an average gap of 6.04\% when measured against a known lower bound. We also present a real-life case study provided by our industrial partner and we investigate how to maximise the output of the studied automated production system.},
  archive      = {J_COR},
  author       = {Simon Belieres and Yossiri Adulyasak and Jean-François Cordeau},
  doi          = {10.1016/j.cor.2023.106387},
  journal      = {Computers &amp; Operations Research},
  pages        = {106387},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling multi-staged jobs on parallel identical machines and a central server with sequence-dependent setup times: An application to an automated kitchen},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A constraint programming-based iterated greedy algorithm for
the open shop with sequence-dependent processing times and makespan
minimization. <em>COR</em>, <em>160</em>, 106386. (<a
href="https://doi.org/10.1016/j.cor.2023.106386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel variant of the open shop scheduling problem where the jobs have sequence-dependent processing times is addressed. The performance measure considered is the minimization of the length of the schedule (makespan). This problem arises in several real-life settings and, particularly, our work is inspired in scheduling samples in a quality control laboratory where a series of tests have to be performed in different equipment – being irrelevant the order in which these tests are performed –, and the time required to perform the tests depends on the previous sample tested. For this problem, we compare the results of a Mixed-Integer Linear Programming (MILP) model with those from a Constraint Programming (CP) model specifically proposed for the problem, showing that the latter yields better results. Given the NP-hard nature of the problem, in order to obtain good – but not necessarily optimal – solutions within reasonable computational effort, we propose a matheuristic consisting of an Iterated Greedy Algorithm hybridized with a reconstruction phase based in executing the CP model with a partial solution. The results of the computational experiments carried out on 160 instances based on established datasets show the ability of the matheuristic to solve large-sized instances, in contrast with exact (i.e. MILP and CP) models. Our proposal outperforms the most efficient approximate procedures from related problems that have been adapted to the problem under consideration. A subsequent statistical analysis is carried out to prove the statistical significance of these results.},
  archive      = {J_COR},
  author       = {Levi R. Abreu and Bruno A. Prata and Marcelo S. Nagano and Jose M. Framinan},
  doi          = {10.1016/j.cor.2023.106386},
  journal      = {Computers &amp; Operations Research},
  pages        = {106386},
  shortjournal = {Comput. Oper. Res.},
  title        = {A constraint programming-based iterated greedy algorithm for the open shop with sequence-dependent processing times and makespan minimization},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced iterated local search for the technician routing
and scheduling problem. <em>COR</em>, <em>160</em>, 106385. (<a
href="https://doi.org/10.1016/j.cor.2023.106385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most public facilities in the European countries , including France, Germany, and the United Kingdom, were built during the reconstruction projects between 1950 and 1980. Owing to the deteriorating state of such vital infrastructure, its maintenance has become relatively expensive in the recent decades. A significant part of the maintenance operation costs is spent on the technical staff. Therefore, the optimal use of the available workforce is essential to minimize the overall costs. This includes planning technical interventions, workload balancing , productivity improvement, etc. In this paper, we focus on the routing of technicians and the scheduling of their tasks. We address for this purpose a variant of the workforce scheduling problem called the Technician Routing and Scheduling Problem. This problem has applications in different fields, such as maintenance of transportation infrastructure (rail and road networks), telecommunications, and sewage facilities. To solve the problem, we propose an enhanced iterated local search approach. The enhancement of the iterated local search firstly includes an intensification procedure that incorporates a set of local search operators and removal-repair heuristics adapted for the studied problem. Next, four different mechanisms are used in the perturbation phase. Finally, an elite set of solutions is used to extensively explore the neighborhood of local optima as well as to enhance diversification during search space exploration. To measure the performance of the proposed method, experiments were conducted based on benchmark instances from the literature, and the results obtained were compared with those of an existing method. Our method achieved very good results, since it reached the best overall gap, which is almost three times lower than that of the literature. Furthermore, eILS improved the best-known solution for 31 instances among a total of 56 while maintaining reasonable computational times.},
  archive      = {J_COR},
  author       = {Ala-Eddine Yahiaoui and Sohaib Afifi and Hamid Allaoui},
  doi          = {10.1016/j.cor.2023.106385},
  journal      = {Computers &amp; Operations Research},
  pages        = {106385},
  shortjournal = {Comput. Oper. Res.},
  title        = {Enhanced iterated local search for the technician routing and scheduling problem},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A sample approximation solution procedure for
chance-constrained districting problems. <em>COR</em>, <em>160</em>,
106376. (<a href="https://doi.org/10.1016/j.cor.2023.106376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a Districting Problem with chance-constraints balancing requirements is investigated. The goal is to partition a set of basic Territorial Units into p p contiguous and compact districts such that their probability of being balanced is above a minimum threshold. For such a problem, an approximate counterpart is considered, in which deterministic inequalities are used to express the need for the districting plan to be balanced across a large set of randomly drawn scenarios. This leads to a sample approximation problem. In order to solve the latter, a new heuristic algorithm is devised. The proposed procedure exploits a location–allocation scheme coupled with a so-called “balancing constraints-generation” procedure. In practice, the sample approximation problem is iteratively solved by adding demand scenarios (and, hence, the corresponding balancing constraints) on the fly. Several measures to drive the selection of such scenarios and embed them into the problem during the solution process are introduced and discussed. Extensive computational experiments on testbed instances from the literature prove the validity of the devised procedure, showing that it outperforms existing heuristics in the number of solved instances and/or computing times while assuring comparable solutions’ quality, especially for larger-sized test cases.},
  archive      = {J_COR},
  author       = {Silvia Baldassarre and Giuseppe Bruno and Antonio Diglio and Carmela Piccolo},
  doi          = {10.1016/j.cor.2023.106376},
  journal      = {Computers &amp; Operations Research},
  pages        = {106376},
  shortjournal = {Comput. Oper. Res.},
  title        = {A sample approximation solution procedure for chance-constrained districting problems},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new mixed integer programming approach for inverse
correspondence analysis. <em>COR</em>, <em>160</em>, 106375. (<a
href="https://doi.org/10.1016/j.cor.2023.106375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correspondence analysis (CA) is a dimension reduction technique for categorical data in a two-way contingency table. The low-dimensional CA solution optimally depicts the relationship between the categorical variables . We consider the inverse correspondence analysis (ICA) problem, where we use the low-dimensional representation in order to retrieve the original data table. We propose a mixed integer programming formulation for the ICA problem based on transition formulas, which link the row and column coordinates in a CA solution. We show that our formulation has better theoretical characteristics than the existing formulation in the literature and is able to model a generalised ICA problem, which requires less input. In addition, we introduce an iterative method, which uses the fit of individual points in the low-dimensional CA solution. By incorporating statistical information on the quality of CA solutions into our methodology, we are able to retrieve the original data for larger ICA instances.},
  archive      = {J_COR},
  author       = {Rick S.H. Willemsen and Wilco van den Heuvel and Michel van de Velden},
  doi          = {10.1016/j.cor.2023.106375},
  journal      = {Computers &amp; Operations Research},
  pages        = {106375},
  shortjournal = {Comput. Oper. Res.},
  title        = {A new mixed integer programming approach for inverse correspondence analysis},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using submodularity in solving the robust bandwidth packing
problem with queuing delay guarantees. <em>COR</em>, <em>160</em>,
106374. (<a href="https://doi.org/10.1016/j.cor.2023.106374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the robust bandwidth packing problem with queuing delay guarantees. The queuing delays are approximated using the M / G / 1 M/G/1 model. The problem involves nonlinear constraints that aim to limit the total queuing delays and satisfy edge capacities. We present two types of reformulations for this intractable problem. The first type consists of conic quadratically constrained or linear programs with integer variables, which can be implemented using commercial solvers. The second type is mixed-integer linear programs with an exponential number of constraints. To address the nonlinear constraints, we reformulate them into multiple linear constraints by combining polymatroid or submodular inequalities with the supporting hyperplanes of a concave function . The computational results demonstrate the effectiveness of the proposed formulations.},
  archive      = {J_COR},
  author       = {Seulgi Joung},
  doi          = {10.1016/j.cor.2023.106374},
  journal      = {Computers &amp; Operations Research},
  pages        = {106374},
  shortjournal = {Comput. Oper. Res.},
  title        = {Using submodularity in solving the robust bandwidth packing problem with queuing delay guarantees},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A vertex weighting-based double-tabu search algorithm for
the classical p-center problem. <em>COR</em>, <em>160</em>, 106373. (<a
href="https://doi.org/10.1016/j.cor.2023.106373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The p p -center problem, which is NP-hard, aims to select p p centers from a set of candidates to serve all clients while minimizing the maximum distance between each client and its assigned center. To solve this challenging optimization problem , we transform the p p -center problem into a series of decision subproblems , and propose a vertex weighting-based double-tabu search (VWDT) algorithm. It integrates a vertex weighting strategy and a double-tabu search which combines both solution-based and attribute-based tabu strategies to help the search to escape from the local optima trap. Computational experiments on totally 510 public instances in the literature show that VWDT is highly competitive comparing to the state-of-the-art algorithms. Specifically, VWDT improves the previous best known results for 84 large instances and matches the best results for all the remaining ones. Apart from the improvements in solution quality, VWDT is much faster than other state-of-the-art algorithms in the literature, especially on some large instances. Furthermore, we perform additional experiments to analyze the impact of the key components to VWDT, such as the vertex weighting and the double-tabu search strategy.},
  archive      = {J_COR},
  author       = {Qingyun Zhang and Zhipeng Lü and Zhouxing Su and Chumin Li},
  doi          = {10.1016/j.cor.2023.106373},
  journal      = {Computers &amp; Operations Research},
  pages        = {106373},
  shortjournal = {Comput. Oper. Res.},
  title        = {A vertex weighting-based double-tabu search algorithm for the classical p-center problem},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comprehensive quantity discount model for dynamic green
supplier selection and order allocation. <em>COR</em>, <em>160</em>,
106372. (<a href="https://doi.org/10.1016/j.cor.2023.106372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model and solve a deterministic multi-period single-product green supplier selection and order allocation problem in which the considered suppliers’ availability, cost, and green performance change from one period to another in the planning horizon. Moreover, the available suppliers may offer an all-unit or an incremental quantity discount (QD) scheme, resulting in three problem configurations. In one configuration, all suppliers offer all-unit QD. In the second, all suppliers offer incremental QD. In the third, some suppliers offer all-unit QD, and others offer incremental QD. The problem is modeled using a bi-objective integer linear programming formulation that maximizes the total green value of the purchased items from all the suppliers and minimizes their total corresponding cost, including the fixed cost, variable cost, inventory holding cost, and shortage cost. The proposed bi-objective model is scalarized and solved using the branch-and-cut algorithm and a population-based heuristic. A numerical analysis is conducted, which allows first to validate the heuristic approach using small-size instances by comparing its results with those of the exact approach. Moreover, an extensive comparison between the exact and heuristic solution approaches is carried out. The results reveal different findings. First, the economic and environmental solutions of an instance are different, and the environmental solution is independent of the suppliers’ pricing schemes. Second, the maximum difference between the heuristic approach and the exact approach in terms of the bi-objective function value is 4.72\%, which makes the proposed heuristic recommended for large-size instances due to its short computation time and good accuracy. Third, there is no difference in terms of the heuristic performance between the combined model and the models with a single type of discount. Fourth, the all-unit discount scheme seems to be generally better in terms of the trade-off between the green value of purchasing and cost.},
  archive      = {J_COR},
  author       = {Sadeque Hamdan and Ali Cheaitou and Amir Shikhli and Imad Alsyouf},
  doi          = {10.1016/j.cor.2023.106372},
  journal      = {Computers &amp; Operations Research},
  pages        = {106372},
  shortjournal = {Comput. Oper. Res.},
  title        = {Comprehensive quantity discount model for dynamic green supplier selection and order allocation},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multistage stochastic fractionated intensity modulated
radiation therapy planning. <em>COR</em>, <em>160</em>, 106371. (<a
href="https://doi.org/10.1016/j.cor.2023.106371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intensity modulated radiation therapy (IMRT) is a widely used cancer treatment technique designed to target malignant cells. To enhance its effectiveness on tumors and reduce side effects, radiotherapy plans are usually divided into consecutive treatments, or fractions, that are delivered over multiple weeks. However, typical planning approaches have focused on finding the full sequence of radiation intensities prior to the treatment, or were restricted to a single treatment session. In this work, we investigate the fractionated IMRT planning problem that accounts for geometric motion-related uncertainty during treatment. We propose a novel multistage stochastic programming (MSP) modeling framework that incorporates the sequential decision-making nature of the problem and prevailing stochasticity in cancer treatment. We model the uncertainty in the form of a scenario tree following the multiple instance of geometry approximation , and solve the MSP model using stochastic dual dynamic programming considering a variety of risk measures. We conduct computational experiments on five test cases that are generated based on clinical data. Through extensive simulations, we show that our MSP model generates higher quality treatment plans compared to deterministic and two-stage program counterparts based on multiple performance measures. In particular, our model leads to a higher rate of tumor coverage and a lower rate of radiation exposure for healthy tissues. Accordingly, the proposed MSP framework can greatly contribute to the clinical practice in fractionated IMRT.},
  archive      = {J_COR},
  author       = {Merve Bodur and Mucahit Cevik and Andre A. Cire and Mark Ruschin and Juyoung Wang},
  doi          = {10.1016/j.cor.2023.106371},
  journal      = {Computers &amp; Operations Research},
  pages        = {106371},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multistage stochastic fractionated intensity modulated radiation therapy planning},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Newton-based approach to solving k-SVCR and twin-KSVC
multi-class classification in the primal space. <em>COR</em>,
<em>160</em>, 106370. (<a
href="https://doi.org/10.1016/j.cor.2023.106370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-class classification is an important problem in machine learning , which often occurs in the real world and is an ongoing research issue. Support vector classification-regression machine for k k -class classification (K-SVCR) and twin k k -class support vector classification (Twin-KSVC) are two novel machine learning methods for multi-class classification problems. This paper presents novel methods to solve the primal problems of K-SVCR and Twin-KSVC, known as NK-SVCR and NTW-KSVC, respectively. The proposed methods evaluate all training data into a “1-versus-1-versus-rest” structure, so it generates ternary outputs { − 1 , 0 , + 1 } {−1,0,+1} . The primal problems are reformulated as unconstrained optimization problems so that the objective functions are only once differentiable, not twice, therefore an extension of the Newton-Armijo algorithm is adopted for finding their solution. To test the efficiency and validity of the proposed methods, we compare the classification accuracy and learning time of these methods with K-SVCR and Twin-KSVC on the United States Postal Service (USPS) handwriting digital data sets and several University of California Irvine (UCI) benchmark data sets. To analyze more in aspect of training time, we also compared all methods on the multi-class version of the Normally Distributed Clustered (NDC) database. To further analyze classification accuracy and learning time differences between the classifiers, the statistical Friedman’s test is used.},
  archive      = {J_COR},
  author       = {Hossein Moosaei and Milan Hladík and Mohamad Razzaghi and Saeed Ketabchi},
  doi          = {10.1016/j.cor.2023.106370},
  journal      = {Computers &amp; Operations Research},
  pages        = {106370},
  shortjournal = {Comput. Oper. Res.},
  title        = {Newton-based approach to solving K-SVCR and twin-KSVC multi-class classification in the primal space},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Redistricting optimization with recombination: A local
search case study. <em>COR</em>, <em>160</em>, 106369. (<a
href="https://doi.org/10.1016/j.cor.2023.106369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the U.S., states redraw electoral district boundaries every ten years. Given that redistricting affects political representation at both the state and national levels, it is crucial to prevent the manipulation of district boundaries for political gain. Optimization methods can be valuable tools for promoting transparency and fairness in redistricting. Here we examine a novel local search approach for redistricting that transitions between feasible solutions using Recombination (a recently introduced spanning tree iteration). We compare the performance of multiple local search heuristics using both Recombination and more traditional Flip iterations by optimizing congressional plans for Illinois, Missouri, and Tennessee with respect to several common fairness objectives. We evaluate which heuristic produces the best objective value within limited time periods and generate collections of optimized plans. The Recombination heuristics produced excellent objective values, often far superior to the Flip heuristics; they also maintained more compact district shapes when the objective was not compactness. However, the Flip heuristics converged to a local optimum more quickly and occasionally achieved better solutions than the ReCom heuristics within short time periods. Hence, while the use of Recombination within local search frequently improves solution quality, there are some scenarios for which Flip may be preferable.},
  archive      = {J_COR},
  author       = {Kiera W. Dobbs and Douglas M. King and Sheldon H. Jacobson},
  doi          = {10.1016/j.cor.2023.106369},
  journal      = {Computers &amp; Operations Research},
  pages        = {106369},
  shortjournal = {Comput. Oper. Res.},
  title        = {Redistricting optimization with recombination: A local search case study},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms for a risk-averse stackelberg game with multiple
adversaries. <em>COR</em>, <em>160</em>, 106367. (<a
href="https://doi.org/10.1016/j.cor.2023.106367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a Stackelberg game that arises in a security domain (SSG), where a defender can simultaneously protect m m out of n n targets from an adversary that observes the defense strategy before deciding on an utility maximizing attack. Given the high stakes in security settings, it is reasonable that the defender in this game is risk averse with respect to the attacker’s decisions. Here we focus on developing efficient solution algorithms for a specific SSG, where the defender uses an entropic risk measure to model risk aversion to the attacker’s strategies, and where multiple attackers select targets following logit quantal response equilibrium models. This problem can be formulated as a nonconvex nonlinear optimization problem . We propose two solution methods: (1) approximate the problem through convex mixed integer nonlinear programs (MINR) and (2) a general purpose methodology (CELL) to optimize nonconvex and nonseparable fractional problems through mixed integer linear programming approximations . Both methods provide arbitrarily good incumbents and lower bounds on SSG. We present cutting plane methods to solve these problems for large instances. Our computational experiments illustrate the advantages of introducing risk aversion into the defender’s behavior and show that MINR dominates CELL, producing in 2 h solutions that are within 2\% of optimal on average.},
  archive      = {J_COR},
  author       = {Renaud Chicoisne and Fernando Ordóñez},
  doi          = {10.1016/j.cor.2023.106367},
  journal      = {Computers &amp; Operations Research},
  pages        = {106367},
  shortjournal = {Comput. Oper. Res.},
  title        = {Algorithms for a risk-averse stackelberg game with multiple adversaries},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A non-clustered approach to platelet collection routing
problem. <em>COR</em>, <em>160</em>, 106366. (<a
href="https://doi.org/10.1016/j.cor.2023.106366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the blood components that can be extracted from whole blood is the platelet, which has a wide range of uses in medical fields. Due to the perishable nature of platelets, it is recommended that the separation occurs within six hours after the donation. Moreover, platelets constitute less than one percent of the whole blood volume, yet they are highly demanded. Given the importance of platelets in healthcare, their perishability, and their limited supply, an effective platelet supply chain leans on well-managed whole blood collection operations. In this study, we consider a blood collection problem (BCP) focusing on the collection of whole blood donations from the blood donation sites (BDSs). Different from the basic form of BCP, we consider the processing time limit (PTL) of blood and arbitrary donation patterns of donors as well as relaxing the assumption of assigning each blood collection vehicle (BCV) to a set of BDSs. Therefore, we define the non-clustered maximum blood collection problem (NCMBCP) as a variant of BCP. In this study, we examine routing decisions for platelet collections while relaxing the clustering requirement from the BDSs, which results in a significant increase in the complexity of the problem. In order to solve the problem, we propose a hybrid genetic algorithm (HGA) and an invasive weed optimization (IWO) algorithm that provide considerable improvements over the best solution in the literature for the clustered variant of the problem and outperform it (on average) by 8.68\% and 8.16\%, respectively.},
  archive      = {J_COR},
  author       = {Ramin Talebi Khameneh and Milad Elyasi and O. Örsan Özener and Ali Ekici},
  doi          = {10.1016/j.cor.2023.106366},
  journal      = {Computers &amp; Operations Research},
  pages        = {106366},
  shortjournal = {Comput. Oper. Res.},
  title        = {A non-clustered approach to platelet collection routing problem},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scheduling wagons to unload in bulk cargo ports with
uncertain processing times. <em>COR</em>, <em>160</em>, 106364. (<a
href="https://doi.org/10.1016/j.cor.2023.106364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimising operations in bulk cargo ports is of great relevance due to their major participation in international trade. In inbound operations, which are critical to meet due dates, the product typically arrives by train and must be transferred to the stockyard. This process requires several machines and is subject to frequent disruptions leading to uncertain processing times. This work focuses on the scheduling problem of unloading the wagons to the stockyard, approaching both the deterministic and the stochastic versions. For the deterministic problem, we compare three solution approaches: a Mixed Integer Programming model, a Constraint Programming model and a Greedy Randomised algorithm . The selection rule of the latter is evolved by Genetic Programming . The stochastic version is tackled by dispatching rules , also evolved via Genetic Programming . The proposed approaches are validated using real data from a leading company in the mining sector. Results show that the new heuristic presents similar results to the company’s algorithm in a considerably shorter computational time. Moreover, we perform extensive computational experiments to validate the methods on a wide spectrum of randomly generated instances . Finally, as managing uncertainty is fundamental for the effectiveness of these operations, distinct strategies are compared, ranging from purely predictive to completely reactive scheduling. We conclude that re-scheduling with high frequency is the best approach to avoid performance deterioration under schedule disruptions, and using the evolved dispatching rules incur fewer deviations from the original schedule.},
  archive      = {J_COR},
  author       = {Cristiane Ferreira and Gonçalo Figueira and Pedro Amorim and Alexandre Pigatti},
  doi          = {10.1016/j.cor.2023.106364},
  journal      = {Computers &amp; Operations Research},
  pages        = {106364},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling wagons to unload in bulk cargo ports with uncertain processing times},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid modified-NSGA-II VNS algorithm for the
multi-objective critical disruption path problem. <em>COR</em>,
<em>160</em>, 106363. (<a
href="https://doi.org/10.1016/j.cor.2023.106363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a Multiple Objective variant of the Critical Disruption Path problem to extend its suitability in a range of security operations relying on path-based network interdiction, including flight pattern optimisation for surveillance. Given a pair of nodes s s and t t from the network to be monitored, the problem seeks for loopless s − t s−t paths such that, within the induced subgraph obtained via deletion of the path, the size of the largest connected component is minimised, the number of connected components is maximised, while concurrently reducing as much as possible the cost of such disruption path. These three objectives are possibly in conflict with each other, and the scope of this work is to allow for an efficient and insightful approximation of the Pareto front, looking for a trade-off between costs and effectiveness to secure the most convenient paths for security and surveillance operations. We first introduce and formulate the Multi-Objective Critical Disruption Path Problem (Multi-Objs-CDP) as a mixed integer programming formulation (MO-CDP), then we propose an original evolutionary metaheuristic algorithm hybridising modified-NSGA-II and VNS for finding an approximation of the Pareto front, as well as a procedure securing the efficient generation of a high quality pool of initial solutions. The experimental performance of the proposed algorithm, as compared with a variety of competing approaches, proves to be fully satisfactory in terms of time efficiency and quality of the solutions obtained on a set of medium to large benchmark instances.},
  archive      = {J_COR},
  author       = {Donatella Granata and Antonino Sgalambro},
  doi          = {10.1016/j.cor.2023.106363},
  journal      = {Computers &amp; Operations Research},
  pages        = {106363},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid modified-NSGA-II VNS algorithm for the multi-objective critical disruption path problem},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Making opportunity sales in attended home delivery.
<em>COR</em>, <em>160</em>, 106362. (<a
href="https://doi.org/10.1016/j.cor.2023.106362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on time window management in attended home delivery mainly focuses on influencing customers’ delivery time choices to reduce monetary and environmental costs. In this study, we adopt a different perspective and propose exploiting otherwise idle time and vehicle capacities to generate extra profits through opportunity sales for e-groceries. We consider nudging potential target customers (residing in locations that are ”easy” to insert into the delivery tours) with push notifications to generate new sales. These customers are incentivized for purchases by dropping the terms imposed on standard e-grocery sales such as service fees or minimum purchase quantities. Managing the delivery operations for this innovative business model requires concurrently choosing the target customers and planning the vehicle routes under the offer acceptance and response time uncertainties. To solve this challenging problem, we propose an integer linear programming model that enables a decomposition of the problem into a routing problem and several customer selection problems. For the solution to the customer selection problems, we propose mathematical models with varying risk-taking levels. We also investigate the benefits of dynamic policies to take advantage of the information revealed during the delivery operations in order to adjust customer selection and vehicle routing decisions. Our extensive numerical experiments show that these models, equipped with dynamic decision making, can compete with the risk-ignorant models for the total profit while generating more sales per offer, as well as ensuring timely execution of the delivery operations.},
  archive      = {J_COR},
  author       = {Çelen Naz Ötken and Barış Yıldız and Okan Arslan and Gilbert Laporte},
  doi          = {10.1016/j.cor.2023.106362},
  journal      = {Computers &amp; Operations Research},
  pages        = {106362},
  shortjournal = {Comput. Oper. Res.},
  title        = {Making opportunity sales in attended home delivery},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised parallel machines scheduling with tool
switches. <em>COR</em>, <em>160</em>, 106361. (<a
href="https://doi.org/10.1016/j.cor.2023.106361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of scheduling jobs on identical parallel machines with tool switches in a high-mix, low-volume manufacturing environment. Inspired by the initiatives on “lights-out factory” at our industry partner, our problem setting involves several complex features. For example, we consider unsupervised production hours (e.g., night shifts where operators are not available) in which tool switches cannot occur. Moreover, motivated by current practice, tool switches in our problem setting cause costs instead of delays. Also, a subset of jobs is prioritized to be completed within a scheduling horizon, and a job may consist of ordered operations due to reentry to machines. The objective is to maximize the profit generated by the manufacturing system, which is composed of revenue generated by the finished operations minus tool switching costs and penalty costs of unfinished priority jobs. The decisions involve assigning operations to machines, sequencing these operations, and determining a tool-switching plan. A mix-integer linear programming model is first formulated. We then propose a genetic algorithm to solve industry-size problem instances, in which tailored crossover and mutation mechanisms are introduced. We illustrate the performance of the proposed GA with industry case studies using real-world data. We also make the anonymized data set publicly available. Computational experiments reveal that approximately 26\% profit improvement can be achieved by using the proposed GA instead of the current way of scheduling at our industry partner. Moreover, we find that the proposed GA brings higher benefits when the duration of the unsupervised shifts gets longer, and there is high pressure on prioritizing jobs in the schedule.},
  archive      = {J_COR},
  author       = {Quang-Vinh Dang and Koen Herps and Tugce Martagan and Ivo Adan and Jasper Heinrich},
  doi          = {10.1016/j.cor.2023.106361},
  journal      = {Computers &amp; Operations Research},
  pages        = {106361},
  shortjournal = {Comput. Oper. Res.},
  title        = {Unsupervised parallel machines scheduling with tool switches},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Loads scheduling for demand response in energy communities.
<em>COR</em>, <em>160</em>, 106358. (<a
href="https://doi.org/10.1016/j.cor.2023.106358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on optimizing the collective self-consumption rate in energy communities by scheduling members’ loads. The community remains connected to the public grid and comprises prosumers, traditional consumers, and distributed storage units. Prosumers can exchange their energy with the public grid or other members. The proposed strategy aims at implementing a Demand Side Management program taking advantage of controllable loads’ characteristics. A MILP formulation of the problem allows, on the one hand, to give the optimal planning for electrical devices’ operations. On the other hand, it provides optimal solutions for managing the storage units, peer-to-peer exchanges, and interactions with the public grid to minimize the energy flows from the public grid over time. However, this MILP only allows for solving small problem instances. Thus, we develop a column generation-based heuristic for large problem instances. Our numerical experiments based on real data collected in the south of France show that joining an energy community saves money on energy bills and reduces the total energy drawn from the primary grid by at least 15\%.},
  archive      = {J_COR},
  author       = {Mariam Sangaré and Eric Bourreau and Bernard Fortz and Amaury Pachurka and Michael Poss},
  doi          = {10.1016/j.cor.2023.106358},
  journal      = {Computers &amp; Operations Research},
  pages        = {106358},
  shortjournal = {Comput. Oper. Res.},
  title        = {Loads scheduling for demand response in energy communities},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reducing tardy batches by seru production: Model, exact
solution, cooperative coevolution solution, and insights. <em>COR</em>,
<em>160</em>, 106048. (<a
href="https://doi.org/10.1016/j.cor.2022.106048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seru production, as an innovative production mode, has the advantages of quick response, good flexibility, and high efficiency. We investigate how to reduce tardy batches using seru production. The model of seru production, which minimizes the number of tardy batches, is formulated and decomposed into seru formation and seru scheduling. To obtain the optimal solution, we formulate a linear model of seru scheduling to maximize the number of on-time batches for a given seru formation. In the case of small-scale instances, the optimal solution for seru production is obtained by solving the linear model exactly for all seru formations. However, this method is extremely time-consuming. Therefore, for medium-scale instances, we develop an exact method based on surrogate-relaxation and branch-and-bound. Surrogate relaxation is developed to rapidly eliminate unpromising seru formations, where an upper bound of a given seru formation is quickly produced. If the upper bound is worse than the current lower bound of seru production, the seru formation is unpromising and eliminated in advance. Otherwise, it remains, and its feasible solution is obtained by surrogate relaxation to update the current lower bound. By the proposed method, 97.29\% of unpromising seru formations are eliminated on average and 76.21\% of computational time is saved. Subsequently, for each remaining seru formation, we develop a branch-and-bound algorithm to obtain an optimal solution. In the branch-and-bound method, the lower bound is used not only to prune branches but also to eliminate the remaining seru formations. For large-scale instances, we propose a cooperative coevolution algorithm combined with simulated annealing that can generate nearly optimal solutions for large-scale problems in seconds. Extensive experiments demonstrate the superiority of the proposed algorithms, and tardy batches are reduced by 62.06\% on average. Based on the experimental results, several managerial insights are provided to reduce tardy batches.},
  archive      = {J_COR},
  author       = {Xiaolong Li and Yang Yu and Wei Sun and Jiafu Tang},
  doi          = {10.1016/j.cor.2022.106048},
  journal      = {Computers &amp; Operations Research},
  pages        = {106048},
  shortjournal = {Comput. Oper. Res.},
  title        = {Reducing tardy batches by seru production: Model, exact solution, cooperative coevolution solution, and insights},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Factors affecting the final solution of the bike-sharing
rebalancing problem under heuristic algorithms. <em>COR</em>,
<em>159</em>, 106368. (<a
href="https://doi.org/10.1016/j.cor.2023.106368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bike-sharing rebalancing problem (BRP) belongs to a class of one-commodity pickup and delivery vehicle route problems (1-PDVRPs) which often must be solved using heuristic algorithms due to the large problem size. However, an open question is which factors affect the quality of the final solutions for the BRP with heuristic algorithms , and how they affect the solution quality. This study proposed six initial solution construction methods and two heuristic algorithms, and applied 32 instances to explore this question in greater depth. The results showed that problem size and the algorithms&#39; searching capacity are the most important factors affecting the quality of final solutions. Furthermore, the influence of the quality and diversity of initial solutions cannot be ignored. The quality of final solutions is negatively correlated with problem size, and positively correlated with the algorithms&#39; searching capacity, and the quality and diversity of initial solutions. The influence of the quality and diversity of initial solutions on the quality of final solutions is positively correlated with problem size. For algorithms with insufficient (powerful) searching capacity, the influence of the quality (diversity) of initial solutions is more significant than that of their diversity (quality). High-quality and rich-diversity initial solutions are very helpful for algorithms to find high-quality final solutions. In addition, the CPU time of heuristic algorithms is generally positively correlated with their searching capacity. These findings have certain universal applicability and reference value for solving the 1-PDVRPs with similar solution structures using heuristic algorithms.},
  archive      = {J_COR},
  author       = {Jian Qiao and Mengying He and Niannian Sun and Pengfei Sun and Ying Fan},
  doi          = {10.1016/j.cor.2023.106368},
  journal      = {Computers &amp; Operations Research},
  pages        = {106368},
  shortjournal = {Comput. Oper. Res.},
  title        = {Factors affecting the final solution of the bike-sharing rebalancing problem under heuristic algorithms},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-agent system for integrated scheduling and
maintenance planning of the flexible job shop. <em>COR</em>,
<em>159</em>, 106365. (<a
href="https://doi.org/10.1016/j.cor.2023.106365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of scheduling and maintenance planning of the Flexible Job Shop (FJS). Preventive maintenance is often being followed in the industry , which, if not considered while scheduling, may lead to unrealistic/sub-optimal schedules. Despite the importance of maintenance planning while scheduling, the problem has attracted very little attention in the literature. Further, the existing approaches assume centralized decision-making which not only suffers from low scalability but is not amenable to futuristic manufacturing systems such as industry 4.0. However, to the best of the authors’ knowledge, no decentralized system has been reported for integrated scheduling and maintenance planning of the FJS. This paper proposes a multi-agent system, a popular approach for decentralized decision-making, for integrated scheduling and maintenance planning of FJSP . The efficacy of our approach is compared with the existing approaches by solving 11 problem instances with fixed (to be performed at the predefined time) and flexible (to be performed any time within a time window) maintenance.},
  archive      = {J_COR},
  author       = {Manojkumar Pal and Murari lal Mittal and Gunjan Soni and Satyendra S. Chouhan},
  doi          = {10.1016/j.cor.2023.106365},
  journal      = {Computers &amp; Operations Research},
  pages        = {106365},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multi-agent system for integrated scheduling and maintenance planning of the flexible job shop},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective energy-efficient hybrid flow shop scheduling
using q-learning and GVNS driven NSGA-II. <em>COR</em>, <em>159</em>,
106360. (<a href="https://doi.org/10.1016/j.cor.2023.106360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The urgent mission for carbon peak and carbon neutrality is demanding greater industrial sustainability. Energy-efficient hybrid flow shop scheduling problem (EEHFSP) has been raising increasing attention in recent years. This paper studies a new EEHFSP with uniform machines to minimize total tardiness, total energy cost, and carbon trading cost. Time-of-use tariffs and power down strategies are simultaneously adopted. A novel multi-objective mixed-integer nonlinear programming model for the problem is proposed. To solve the model, we propose a Q-learning and general variable neighborhood search (GVNS) driven non-dominated sorting genetic algorithm II (QVNS-NSGA-II). The novelty of the algorithm is that we incorporate Q-learning into GVNS to guide premium adaptive operator selection throughout the shaking and local search processes. A distinguishing feature is that the states and actions of Q-learning are set as neighborhood structures and local search operators. The Q-learning-driven GVNS is embedded into NSGA-II to promote the exploration and exploitation capability. Experimental results show that the proposed QVNS-NSGA-II outperforms NSGA-II, improved Jaya, and modified MOEA/D in terms of the quantity, quality of Pareto solutions, and computational efficiency. Sensitivity analysis also derives several managerial implications. The proposed approach can be applied to improve sustainability and productivity for hybrid flow shop manufacturers.},
  archive      = {J_COR},
  author       = {Peize Li and Qiang Xue and Ziteng Zhang and Jian Chen and Dequn Zhou},
  doi          = {10.1016/j.cor.2023.106360},
  journal      = {Computers &amp; Operations Research},
  pages        = {106360},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-objective energy-efficient hybrid flow shop scheduling using Q-learning and GVNS driven NSGA-II},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balancing u-type assembly lines with human–robot
collaboration. <em>COR</em>, <em>159</em>, 106359. (<a
href="https://doi.org/10.1016/j.cor.2023.106359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a U-type assembly line balancing problem with human–robot collaboration (UALBP-HRC), in which the collaborative robot (cobot) can either parallelly process different tasks or collaboratively process the same task with workers. A mixed-integer programming (MIP) model is formulated and the objective is to minimize the cycle time for a given number of stations. We further propose an enhanced MIP (EMIP) model by incorporating enhancement strategies, including tight lower bound, upper bound and initial solution. To the best of our knowledge, this study is among the first attempts to address the UALBP-HRC in which both parallel and collaborative tasks are allowed. Due to the NP-hardness of the problem, a simulated annealing algorithm with enhanced search procedure (ESA) is developed to effectively solve the problem. The model functionalities and algorithm effectiveness are evaluated by adapted standard datasets and real case studies. The experimental results show that EMIP outperforms MIP and ESA finds promising solutions compared to MIP, EMIP, simulated annealing algorithm (SA) and genetic algorithm (GA). The comparisons between UALBP-HRC and straight assembly line balancing problem with human–robot collaboration (ALBP-HRC) are also conducted and the managerial insights are concluded.},
  archive      = {J_COR},
  author       = {Zhaofang Mao and Jiaxin Zhang and Kan Fang and Dian Huang and Yiting Sun},
  doi          = {10.1016/j.cor.2023.106359},
  journal      = {Computers &amp; Operations Research},
  pages        = {106359},
  shortjournal = {Comput. Oper. Res.},
  title        = {Balancing U-type assembly lines with human–robot collaboration},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-period hub location problem considering polynomial
time-dependent demand. <em>COR</em>, <em>159</em>, 106357. (<a
href="https://doi.org/10.1016/j.cor.2023.106357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a bi-objective, nonlinear mathematical model for designing a multi-period hub network, considering a polynomial function for time-dependent transportation demand. The proposed demand function can be used for various applications of the hub network design problem. Hubs’ capacity in the proposed model is considered to be modular. Each module corresponds to a number of servers at hubs. Objectives of the problem include minimizing network costs and maximizing responsiveness by minimizing the sum of the maximum travel times in all time periods. The proposed model provides the best timing for implementing decisions during the planning horizon. To solve the model, NSGA-II, NRGA, PESA-II, and SPEA-II meta-heuristics are used. To compare the performance of the solution algorithms, some multi-objective metrics and statistical tests on the CAB, AP, and TR datasets are applied. We also perform sensitivity analysis on some critical parameters. The sensitivity analysis results show that the network design with economic and responsiveness considerations simultaneously has a higher cost than the network design with only economic considerations.},
  archive      = {J_COR},
  author       = {Amir Khaleghi and Alireza Eydi},
  doi          = {10.1016/j.cor.2023.106357},
  journal      = {Computers &amp; Operations Research},
  pages        = {106357},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-period hub location problem considering polynomial time-dependent demand},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Facility location problems on graphs with non-convex
neighborhoods. <em>COR</em>, <em>159</em>, 106356. (<a
href="https://doi.org/10.1016/j.cor.2023.106356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we deal with some variants of classical facility location problems on graphs in which both the customers and the facilities belong to a non-necessarily convex neighborhood . Therefore, a point in each neighborhood representing the customer/facility has to be determined, and the customers have to be assigned to the facilities depending on a criterion. In particular, the p p -median, the p p -center, and the p p -maximal covering versions of this problem on graphs are analyzed. An important difference with respect to their classical versions is that the lengths of the arcs depend on the location of the points chosen in the neighborhoods. Therefore, the lengths are not part of the input but part of the decision process. Assuming that the neighborhoods are Mixed-Integer Second Order Cone representable, different mixed-integer non-linear programming formulations are proposed for each one of the considered problems. Moreover, solution procedures providing bounds and a preprocessing phase are developed to reduce the number of variables and constraints of the proposed formulations. The results of an extensive computational experience are reported.},
  archive      = {J_COR},
  author       = {I. Espejo and R. Páez and J. Puerto and A.M. Rodríguez-Chía},
  doi          = {10.1016/j.cor.2023.106356},
  journal      = {Computers &amp; Operations Research},
  pages        = {106356},
  shortjournal = {Comput. Oper. Res.},
  title        = {Facility location problems on graphs with non-convex neighborhoods},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive variable neighbourhood search approach for
time-dependent joint location and dispatching problem in a multi-tier
ambulance system. <em>COR</em>, <em>159</em>, 106355. (<a
href="https://doi.org/10.1016/j.cor.2023.106355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-allocation of ambulances is a critical planning problem in the efficient operation of an emergency medical services system. This work considers a joint ambulance location and dispatch problem for a multi-tier ambulance system. The proposed problem addresses three key decisions: the location of ambulance stations, allocation of ambulances to these stations, and the preference order of stations for dispatching ambulances. We consider various other important factors, such as temporal variation in demand and travel time, station-specific ambulance busy probabilities and possible relocation of ambulances over the day. A mixed-integer non-linear programming model is formulated with a survival probability-based objective function to represent the problem. A queueing-based iterative approximation approach is presented to estimate the station-level dispatch probability of ambulances. We propose an adaptive variable neighbourhood search approach to solve the problem that utilises the approximation approach to obtain the objective function. A relaxed station location problem combined with a particle swarm approach for ambulance allocation is solved to obtain an initial solution. The effectiveness of the proposed approach is validated using a dataset generated based on the city of Kolkata in India.},
  archive      = {J_COR},
  author       = {Raviarun A. Nadar and J.K. Jha and Jitesh J. Thakkar},
  doi          = {10.1016/j.cor.2023.106355},
  journal      = {Computers &amp; Operations Research},
  pages        = {106355},
  shortjournal = {Comput. Oper. Res.},
  title        = {Adaptive variable neighbourhood search approach for time-dependent joint location and dispatching problem in a multi-tier ambulance system},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The p-median problem with upgrading of transportation costs
and minimum travel time allocation. <em>COR</em>, <em>159</em>, 106354.
(<a href="https://doi.org/10.1016/j.cor.2023.106354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyse the upgrading of arcs in the p p -median problem on a bi-network. Both travel times and transportation costs are associated with each arc. Our goal consists of simultaneously finding p p medians, allocating each node to the median of minimum travel time and distributing a known budget among the arcs of the network to reduce their transportation cost, in order to minimise the total transportation cost of the system. The problem is motivated by the warehouse-to-locker structure of the distribution networks of many ecommerce businesses. We formulate it in two different ways as an integer programming problem, derive some properties of any optimal solution, develop valid inequalities and present computational results.},
  archive      = {J_COR},
  author       = {Inmaculada Espejo and Alfredo Marín},
  doi          = {10.1016/j.cor.2023.106354},
  journal      = {Computers &amp; Operations Research},
  pages        = {106354},
  shortjournal = {Comput. Oper. Res.},
  title        = {The p-median problem with upgrading of transportation costs and minimum travel time allocation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A branch-and-cut embedded matheuristic for the inventory
routing problem. <em>COR</em>, <em>159</em>, 106353. (<a
href="https://doi.org/10.1016/j.cor.2023.106353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an improved version of the solution method that won the inventory routing problem track of the 1 2 th 12th DIMACS Implementation Challenge. The solution method is a branch-and-cut embedded matheuristic where a matheuristic is called every time a new primal solution is found in a branch-and-cut method. The matheuristic consists of a construction heuristic and an improvement heuristic. The construction heuristic uses a giant tour method and a shifting assignments method to generate a set of promising routes which, in turn, are combined into a feasible solution to the problem by solving a route-based mathematical program . The improvement heuristic then solves a series of extended route-based mathematical programs where clusters of customers may be inserted and/or removed from the routes of the initial feasible solution. We have, to the best of our knowledge, gathered all detailed results from previously published methods for the inventory routing problem and made this overview available online. Compared with these results, the proposed method found the best-known solution for 741 out of 878 multi-vehicle inventory routing instances, where 247 of them are strictly better than the previously best-known solutions. Furthermore, we prove optimality for 458 of these solutions. The proposed method is also able to find the best-known solution for 116 out of 226 benchmark instances for the split delivery vehicle routing problem, and improve three best-known solutions from the CVRPlib for the capacitated vehicle routing problem.},
  archive      = {J_COR},
  author       = {Jørgen Skålnes and Simen T. Vadseth and Henrik Andersson and Magnus Stålhane},
  doi          = {10.1016/j.cor.2023.106353},
  journal      = {Computers &amp; Operations Research},
  pages        = {106353},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-cut embedded matheuristic for the inventory routing problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Managing interruptions in appointment schedules via patient
notification. <em>COR</em>, <em>159</em>, 106352. (<a
href="https://doi.org/10.1016/j.cor.2023.106352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interruptions in appointment schedules are common in practice, yet many clinics use generic appointment scheduling templates and sub-optimal interruption management strategies that fail to address dynamics aspects of daily healthcare operations. In this study, we consider patient no-shows, patient punctuality, service time variability, random walk-in patient arrivals and other common appointment interruptions to determine optimal single-server, intra-day appointment schedules. Using a modified depth first search (DFS) algorithm that relies on a sample average approximation (SAA) technique for objective function evaluation, we minimize a weighted sum of expected waiting times for scheduled and walk-in patients, physician idle time, and physician overtime. Extensive experimentation shows the proposed algorithm solves realistic problems in reasonable time. Furthermore, we propose a sequential notification procedure (SNP) that serves as a dynamic correcting mechanism to address infrequent and unexpected interruptions with a relatively long duration. Considering possible patient responses to notification, SNP notifies scheduled patients in advance to prevent excessive patient waiting and physician overtime. Furthermore, we propose an easy-to-use patient notification heuristic (NH) that can be adopted by clinics using traditional appointment systems. Experimentation shows that both SNP and NH provide significant value, improving operational outcomes. We demonstrate the value of patient notification increases as interruption levels increase and when patients are responsive to notifications.},
  archive      = {J_COR},
  author       = {Ali K. Dogru and Sharif H. Melouk and İbrahim Çapar and Thomas J. Weida},
  doi          = {10.1016/j.cor.2023.106352},
  journal      = {Computers &amp; Operations Research},
  pages        = {106352},
  shortjournal = {Comput. Oper. Res.},
  title        = {Managing interruptions in appointment schedules via patient notification},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive large neighbourhood search algorithm for a
real-world home care scheduling problem with time windows and dynamic
breaks. <em>COR</em>, <em>159</em>, 106351. (<a
href="https://doi.org/10.1016/j.cor.2023.106351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a Home Care Scheduling Problem (from now on HCSP) based on a real case of a care company for elderly and dependent people located in the North of Spain. The problem incorporates many of the common features addressed in the HCSP literature, such as soft and hard time windows for the services, available working time of the caregivers or affinity levels between users and caregivers. However, it also includes other novel characteristics that increase the difficulty of the problem significantly, since the breaks between services will play a key role in the quality of the solutions. To evaluate the solutions, the users welfare will be prioritized over the cost associated with the schedule. The problem has been formulated as a Mixed Integer Linear Programming (MILP) one but, due to the complexity of the model, it is not possible to solve it for real size instances. Therefore, we have designed a method that combines the Adaptive Large Neighbourhood Search (ALNS) methodology with a heuristic approach necessary to evaluate the objective functions. To analyse the behaviour of the algorithm, a set of computational experiments are carried out under different configurations. First, the MILP formulation and the algorithm have been compared over some standard instances from the literature. Finally, the performance of the algorithm is evaluated over a real case study based on the timetables of the company during some weeks from 2016 to 2017.},
  archive      = {J_COR},
  author       = {Isabel Méndez-Fernández and Silvia Lorenzo-Freire and Ángel Manuel González-Rueda},
  doi          = {10.1016/j.cor.2023.106351},
  journal      = {Computers &amp; Operations Research},
  pages        = {106351},
  shortjournal = {Comput. Oper. Res.},
  title        = {An adaptive large neighbourhood search algorithm for a real-world home care scheduling problem with time windows and dynamic breaks},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A GVNS algorithm applied to the single allocation hub
location problem with heterogeneous economies of scale. <em>COR</em>,
<em>159</em>, 106350. (<a
href="https://doi.org/10.1016/j.cor.2023.106350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the single allocation hub location problem with heterogeneous economies of scale . This problem consists of selecting the nodes to establish the hubs in order to minimize the total cost of installing the hubs and routing demand flows, assuming that there is an economy of scale that depends on the amount of flow routed in each arc. We proposed a formulation to model the problem and an algorithm based on the General Variable Neighborhood Search (GVNS) meta-heuristic to handle the problem. Computational experiments were performed using instances from the literature with up to 500 nodes. The results show that the GVNS algorithm is effective for solving the instances in terms of runtime and solution quality. The results also show that the proposed formulation outperforms the literature formulation when activating the Benders decomposition method available in the CPLEX solver.},
  archive      = {J_COR},
  author       = {Nayane Carvalho Freitas and Elisangela Martins de Sá and Sérgio Ricardo de Souza},
  doi          = {10.1016/j.cor.2023.106350},
  journal      = {Computers &amp; Operations Research},
  pages        = {106350},
  shortjournal = {Comput. Oper. Res.},
  title        = {A GVNS algorithm applied to the single allocation hub location problem with heterogeneous economies of scale},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to schedule heuristics for the simultaneous
stochastic optimization of mining complexes. <em>COR</em>, <em>159</em>,
106349. (<a href="https://doi.org/10.1016/j.cor.2023.106349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simultaneous stochastic optimization of mining complexes is a large-scale stochastic combinatorial optimization problem that simultaneously manages the extraction of materials from multiple mines and their processing through interconnected facilities to generate a set of final products, while taking into account geological (material supply) uncertainty to manage the associated risk. Existing methods do not offer solutions to such a complex problem in a reasonable time. This work proposes a data-driven framework for heuristic scheduling in a fully self-managed hyper-heuristic to solve the simultaneous stochastic optimization of mining complexes. The proposed learn-to-perturb hyper-heuristic is a multi-neighborhood simulated annealing algorithm that selects the heuristic (perturbation) to be applied in a self-adaptive manner using reinforcement learning to efficiently explore the local search that is best suited to a particular search point. By learning from data that describes the performance of the heuristics, a problem-specific ordering of heuristics that collectively find better solutions faster is obtained. To the best of our knowledge, this research proposes the first data-driven heuristic search tree for mine planning. Results from several instances of two types of large-scale industrial mining complexes show a reduction of up to 80\% in execution time and an order of magnitude reduction in primal suboptimality compared to state-of-the-art methods.},
  archive      = {J_COR},
  author       = {Yassine Yaakoubi and Roussos Dimitrakopoulos},
  doi          = {10.1016/j.cor.2023.106349},
  journal      = {Computers &amp; Operations Research},
  pages        = {106349},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learning to schedule heuristics for the simultaneous stochastic optimization of mining complexes},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven integrated home service staffing and capacity
planning: Stochastic optimization approaches. <em>COR</em>,
<em>159</em>, 106348. (<a
href="https://doi.org/10.1016/j.cor.2023.106348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a h ome service s taffing and c apacity p lanning (HSCP) problem under uncertainty. Specifically, given sets of providers, service types, and days in the planning horizon, we aim to determine the number of providers to hire ( staffing ) and the allocation of hired providers to different types of services ( capacity planning ). Data from a collaborating home services provider in Beijing demonstrate significant variability in customer demand within and across service types. Service duration is also random. The objective is to minimize the total cost associated with staffing, capacity allocation, over-staffing, and under-staffing. We propose two-stage stochastic programming (SP) and data-driven distributionally robust optimization (DRO) approaches to address demand and service time uncertainty considering two types of decision-makers, namely an everything-in-advance decision-maker (EA) and a flexible adjustment decision-maker (FA). In the EA models, we determine the staffing and capacity allocation decisions in the first stage before observing the demand. In the FA models, we make staffing decisions in the first stage and then determine the allocations based on demand realizations in the second stage. We derive equivalent mixed-integer linear programming (MILP) reformulations of the proposed DRO models for the EA decision-maker that can be implemented and efficiently solved using off-the-shelf optimization software. We propose a computationally efficient column-and-constraint generation algorithm with valid inequalities to solve the proposed DRO models for the FA decision-maker. Numerical experiments based on data from a home services provider in Beijing are used to compare the proposed approaches and illustrate the potential for impact in practice.},
  archive      = {J_COR},
  author       = {Ridong Wang and Karmel S. Shehadeh and Xiaolei Xie and Lefei Li},
  doi          = {10.1016/j.cor.2023.106348},
  journal      = {Computers &amp; Operations Research},
  pages        = {106348},
  shortjournal = {Comput. Oper. Res.},
  title        = {Data-driven integrated home service staffing and capacity planning: Stochastic optimization approaches},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rankability and linear ordering problem: Probabilistic
insight and algorithms. <em>COR</em>, <em>159</em>, 106347. (<a
href="https://doi.org/10.1016/j.cor.2023.106347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The linear ordering problem (LOP), which consists in ordering M M objects from their pairwise comparisons , is commonly applied in many areas of research. While efforts have been made to devise efficient LOP algorithms, verification of whether the data is rankable , that is, if the LOP solutions have a meaningful interpretation, received much less attention. To address this problem, we adopt a probabilistic perspective where the results of pairwise comparisons are modeled as Bernoulli variables with a common parameter, and we estimate the latter from the observed data. The enumeration over the space of permutations , required to solve the problem, has a prohibitive complexity of O ( M ! ) O(M!) if implemented explicitly. We thus reformulate the problem and introduce a concept of the Slater spectrum that generalizes the Slater index, and then devise an algorithm to find the spectrum with complexity O ( M 3 2 M ) O(M32M) that is manageable for moderate values of M M . Furthermore, with a minor modification of the algorithm, we are able to find all solutions of the LOP with the complexity O ( M 2 M ) O(M2M) . Numerical examples are shown on synthetic and real-world data, and the algorithms are publicly available.},
  archive      = {J_COR},
  author       = {Leszek Szczecinski and Harsh Sukheja},
  doi          = {10.1016/j.cor.2023.106347},
  journal      = {Computers &amp; Operations Research},
  pages        = {106347},
  shortjournal = {Comput. Oper. Res.},
  title        = {Rankability and linear ordering problem: Probabilistic insight and algorithms},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid collaborative framework for integrated production
scheduling and vehicle routing problem with batch manufacturing and soft
time windows. <em>COR</em>, <em>159</em>, 106346. (<a
href="https://doi.org/10.1016/j.cor.2023.106346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a new integrated production scheduling and vehicle routing problem where the production of customer orders is performed under a batch manufacturing environment and order deliveries are made by multi-trip heterogeneous vehicles in soft time windows. A bi-objective mixed-integer programming model with maximizing total profits and minimizing total weighted earliness and tardiness has been established. We develop a hybrid collaborative framework to solve this problem, which nests the collaborative mechanism in an optimization mode based on the hybrid algorithm. In the collaborative mechanism, a property on the ideal optimal departure time of the tour is first proposed, based on which an exact strategy is developed to simultaneously coordinate batch manufacturing and tour departure schedules. High-quality integrated solutions are provided by simultaneously making both production scheduling and vehicle routing decisions. Then, in order to get the best integrated solution, we adopt a multi-objective evolutionary algorithm improved by an adaptive large neighborhood search strategy based on the specific problem and coding form to realize the optimization mode. Computational experiments are performed on a dataset containing 30 instances of various scales. The results show that the proposed hybrid collaborative framework performs well in cardinality, convergence, distribution and spread, which is a very competitive method to solve this problem.},
  archive      = {J_COR},
  author       = {Ming Huang and Baigang Du and Jun Guo},
  doi          = {10.1016/j.cor.2023.106346},
  journal      = {Computers &amp; Operations Research},
  pages        = {106346},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid collaborative framework for integrated production scheduling and vehicle routing problem with batch manufacturing and soft time windows},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved multi-objective framework for the rich arc
routing problem. <em>COR</em>, <em>159</em>, 106345. (<a
href="https://doi.org/10.1016/j.cor.2023.106345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a Rich Arc Routing Problem (RARP). Required arcs are partitioned into given clusters, and each cluster shall be serviced for prescribed times during the planning horizon. There is a time limit that restricts the visits that can be performed in a single day. Each vehicle has to stop at one of intermediate facilities before the end of the specific hours per day. Accordingly, several days may be necessary to complete all tasks, and paths traveled by different vehicles on the same day shall not overlap. The RARP consists of finding a set of routes with (i) the minimum total distance, (ii) the minimum number of vehicles, (iii) the minimum pure working days, and (iv ) the temporal service time interval consistency of each cluster. Recently, a Local-Ideal-Points based Autonomous Space Decomposition (LIP-ASD) algorithm has been demonstrated to be a competitive multi-objective framework. However, randomly generating an initial population in each decomposed space decreases the convergence speed of LIP-ASD. In addition, retaining only one individual preserved in each sub-space limits population diversity. In response to these issues, an Improved LIP-ASD (I-LIP-ASD) for RARP is developed. The two improvements of the proposed algorithm are as follows: (i) the initial population in the current sub-space is generated by combining existing nondominated individuals, and (ii) all nondominated solutions will be output from the evolved population in each decomposed sub-space. Finally, we conduct a series of experiments over converted capacitated arc routing problem instances, as well as analyze them under a real-world case to evaluate and demonstrate the effectiveness of the proposed solution algorithm.},
  archive      = {J_COR},
  author       = {Long Chen and Peng Xu and Reginald R. Souleyrette},
  doi          = {10.1016/j.cor.2023.106345},
  journal      = {Computers &amp; Operations Research},
  pages        = {106345},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved multi-objective framework for the rich arc routing problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MPILS: An automatic tuner for MILP solvers. <em>COR</em>,
<em>159</em>, 106344. (<a
href="https://doi.org/10.1016/j.cor.2023.106344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The parameter configuration problem consists of finding a parameter configuration that gives a particular algorithm the best performance. This paper introduces a new multi-phase tuner based on the iterated local search meta-heuristic. This tuner addresses the parameter configuration problem for deterministic MILP solvers that are used to solve challenging industrial optimization problems . Further, the proposed tuner offers a new search strategy based on three ideas. First, instead of tuning in the entire configuration space induced by the parameter set, the multi-phase tuner focuses on a small parameter pool that is dynamically enriched with new promising parameters. Second, it leverages the gathered knowledge during the search using statistical learning to forbid less promising parameter combinations. Third, it tunes on a single instance provided by earlier clustering of MILP instances. A computational study on the widely-used commercial solver CPLEX with instances from the MIPLIB library and a real large-scale optimization problem highlights the promising potential of the tuner.},
  archive      = {J_COR},
  author       = {Ilyas Himmich and El Mehdi Er Raqabi and Nizar El Hachemi and Issmaïl El Hallaoui and Abdelmoutalib Metrane and François Soumis},
  doi          = {10.1016/j.cor.2023.106344},
  journal      = {Computers &amp; Operations Research},
  pages        = {106344},
  shortjournal = {Comput. Oper. Res.},
  title        = {MPILS: An automatic tuner for MILP solvers},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solution techniques for bi-level knapsack problems.
<em>COR</em>, <em>159</em>, 106343. (<a
href="https://doi.org/10.1016/j.cor.2023.106343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional funding mechanisms for healthcare projects involve ranking the projects and awarding funds based on their cost to benefit ratio. An alternative funding mechanism based on Bi-level programming was proposed in the literature. We refer to this as Donor-Recipient Bi-level Knapsack Problem ( DR-BKP ), which we explore further in this work. There are two participants, a leader (a donor agency) and a follower (recipient country) in this problem. Both the participants have their individual budgets. There is a set of projects, each having a certain cost and profit associated. The cost of projects are common to both the participants however the profits can be different for them. There is an external project that is of exclusive interest to the follower. The leader decides on cost subsidies to provide for the projects that is within her budget, while the follower solves a knapsack problem with the cost subsidised projects and the external project. Two enumerative algorithms were proposed in the literature for Bi-level problems with discrete upper level variables. We adapt them for DR-BKP that has continuous upper level variables having non-linear interaction with lower level variables. We first show the existence of a solution for DR-BKP and show the convergence of these algorithms. We provide evidence for Σ 2 P Σ2P -hardness by showing that the problem is both NP-hard and Co-NP hard. Finally, we have implemented these two enumerative algorithms and shared the results and analyses of the computational experiments. A set of fifteen differing data sets each having randomly generated 10 instances have been solved to evaluate the performance of the proposed algorithms.},
  archive      = {J_COR},
  author       = {Shraddha Ghatkar and Ashwin Arulselvan and Alec Morton},
  doi          = {10.1016/j.cor.2023.106343},
  journal      = {Computers &amp; Operations Research},
  pages        = {106343},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solution techniques for bi-level knapsack problems},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adopting a hierarchical diagnosis and treatment system to
optimize elective surgery scheduling. <em>COR</em>, <em>159</em>,
106342. (<a href="https://doi.org/10.1016/j.cor.2023.106342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 outbreak has changed the hospital demand dynamics by increasing the ICU/ward demand and uncertainty. While traditional standalone hospitals have struggled to manage their elective surgery scheduling during the pandemic, hierarchical diagnosis and treatment systems (HDTS) with the high- and low-level hospitals have had some advantages as the high-level hospitals can transfer postoperative recovery patients to their low-level hospital in the network to mitigate the resource shortages. However, in practice, this task is challenging as patient transfers could be costly depending on the patient’s condition, transfer time, and transfer hospital. Thus, there exists an interesting tradeoff between the costs and benefits associated with the patient transfer process within an HDTS. Since data is usually not available in this context, we develop a fuzzy (based on executive opinion) scheduling model for elective surgeries considering the tradeoffs in the patient transfer process. An efficient hybrid algorithm based on the genetic algorithm, variable neighborhood search, and heuristic rules is proposed to cope with the computational complexity of the problem, and the adaptability of the fuzzy model in an uncertain environment is validated. Our paper highlights how hospitals can maximize their profits by transferring patients in an HDTS when the demand for ICUs/wards is uncertain, and thus, this framework also applies to elective patient scheduling during epidemic outbreaks such as COVID-19.},
  archive      = {J_COR},
  author       = {Zongli Dai and Sandun C. Perera and Jian-Jun Wang},
  doi          = {10.1016/j.cor.2023.106342},
  journal      = {Computers &amp; Operations Research},
  pages        = {106342},
  shortjournal = {Comput. Oper. Res.},
  title        = {Adopting a hierarchical diagnosis and treatment system to optimize elective surgery scheduling},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A family of hybrid conjugate gradient method with restart
procedure for unconstrained optimizations and image restorations.
<em>COR</em>, <em>159</em>, 106341. (<a
href="https://doi.org/10.1016/j.cor.2023.106341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conjugate gradient method is one of the most effective methods for solving large-scale optimization problems . Based on the CD conjugate parameter and an improved PRP conjugate parameter, a hybrid conjugate parameter with a single-parameter is designed by using two hybrid techniques, and then a restart procedure is set in its search direction to improve its descent property and computational efficiency. Accordingly, a family of hybrid conjugate gradient method with restart procedure is established, which is sufficient descent at each iteration without depending on any selection of line search criterions. Under usual assumptions and using the weak Wolfe line search criterion to generate the steplengths, the global convergence of the proposed family is proved. Finally, choosing a specific algorithm from this family to solve large-scale unconstrained optimization problems and image restorations, all the numerical results show that the proposed algorithm is effective.},
  archive      = {J_COR},
  author       = {Xianzhen Jiang and Xiaomin Ye and Zefeng Huang and Meixing Liu},
  doi          = {10.1016/j.cor.2023.106341},
  journal      = {Computers &amp; Operations Research},
  pages        = {106341},
  shortjournal = {Comput. Oper. Res.},
  title        = {A family of hybrid conjugate gradient method with restart procedure for unconstrained optimizations and image restorations},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving multiplicative programs by binary-encoding the
multiplication operation. <em>COR</em>, <em>159</em>, 106340. (<a
href="https://doi.org/10.1016/j.cor.2023.106340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplicative programs in the form of maximization and/or minimization have numerous applications in conservation planning, game theory, and multi-objective optimization settings. In practice, multiplicative programs are challenging to solve because of their multiplicative objective function (a product of continuous or integer variables). These challenges are twofold: 1. As the number of factors in the objective increases, so does the solution time, and the problems become computationally expensive to solve. 2. If all factors are in ( 0 , 1 ) (0,1) or in ( 1 , ∞ ) (1,∞) , the objective may cause ill-conditioning and numerical instability . The solution methods proposed in this paper help overcome both of these challenges. The main idea is to binary-encode the multiplication operation analogously to how a computer conducts it internally. This not only solves the aforementioned numerical issues but also allows us to develop a new family of solution methods for multiplicative programs. One such method is to solve the multiplicative programs bit-by-bit, i.e., iteratively computing the optimal value of each bit of the objective function. In an extensive computational study, we explore a number of solution methods that solve multiplicative programs faster and more accurately.},
  archive      = {J_COR},
  author       = {Payman Ghasemi Saghand and Fabian Rigterink and Vahid Mahmoodian and Hadi Charkhgard},
  doi          = {10.1016/j.cor.2023.106340},
  journal      = {Computers &amp; Operations Research},
  pages        = {106340},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving multiplicative programs by binary-encoding the multiplication operation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Set covering heuristics in a benders decomposition for
railway timetabling. <em>COR</em>, <em>159</em>, 106339. (<a
href="https://doi.org/10.1016/j.cor.2023.106339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway timetabling is a major challenge in the operation of railway. The timetable of a railway determines times, orders and routes of trains on the network and thereby defines the performance of the entire railway system . Railway operators are keen to maximize the economic performance of their railway system, such that timetables should be designed taking into account service requirements that result in a performant railway system In this work, we address a specific subdomain of timetabling, focusing on short-term tactical changes for already existing timetables, modeled with microscopic detail. With a Benders decomposition we propose an approach on this specific microscopic timetabling problem. In the decomposition, we consider quality and optimality of a timetable separately from the feasibility of a timetable. Quality is determined in a set covering problem and feasibility in a mixed-integer scheduling problem. With efficient heuristics on the problem of set covering in our decomposition, high quality solution for the resulting timetables are provided in short time, which enables an interactive design of adapted timetables. The novel approach provides heuristic solutions up to ∼ 20 ∼20 times faster than standard approaches by commercial solvers, with an average gap of ∼ 7 . 5\% ∼7.5\% in the optimality of solutions. Extensive experiments empirically confirm the benefits of the new approach.},
  archive      = {J_COR},
  author       = {Florin Leutwiler and Francesco Corman},
  doi          = {10.1016/j.cor.2023.106339},
  journal      = {Computers &amp; Operations Research},
  pages        = {106339},
  shortjournal = {Comput. Oper. Res.},
  title        = {Set covering heuristics in a benders decomposition for railway timetabling},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Off-line approximate dynamic programming for the vehicle
routing problem with a highly variable customer basis and stochastic
demands. <em>COR</em>, <em>159</em>, 106338. (<a
href="https://doi.org/10.1016/j.cor.2023.106338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a stochastic variant of the vehicle routing problem (VRP) arising in the context of domestic donor collection services. The problem we consider combines the following attributes. Customers requesting services are variable , in the sense that they are stochastic, but are not restricted to a predefined set. Furthermore, demand volumes are also stochastic and are observed upon visiting customers. The objective is to maximize the expected served demands while meeting vehicle capacity and time restrictions. We call this problem the VRP with a highly Variable Customer basis and Stochastic Demands (VRP-VCSD). We first propose a classical Markov Decision Process (MDP) formulation for the VRP-VCSD. The resulting model is, however, unusable due to the explosion in the dimension of the state and action spaces. To solve the VRP-VCSD, we propose a number of methodological contributions aimed at reducing the state and action spaces. We first reformulate the MDP as an MDP with a consecutive action selection procedure. In this formulation, we enforce the treatment of a single vehicle (as opposed to multiple vehicles) at each decision epoch. We then introduce an observation function that selects a subset of the available information, which is deemed relevant for the considered vehicle in each epoch. We develop a Q-learning algorithm called QN-CO. In particular, we use a continuous state representation and incorporate a two-layer artificial neural network to approximate the Q values. Furthermore, we propose an aggregation strategy yielding a fixed-size output. Finally, we enhance our algorithm with Replay Memory and a Double Q Network. We conduct a thorough computational analysis. Results show that QN-CO considerably outperforms five benchmark policies. Moreover, we show that QN-CO can compete with specialized methods developed for the particular case of the VRP-VCSD where customer locations and expected demands are known in advance.},
  archive      = {J_COR},
  author       = {Mohsen Dastpak and Fausto Errico and Ola Jabali},
  doi          = {10.1016/j.cor.2023.106338},
  journal      = {Computers &amp; Operations Research},
  pages        = {106338},
  shortjournal = {Comput. Oper. Res.},
  title        = {Off-line approximate dynamic programming for the vehicle routing problem with a highly variable customer basis and stochastic demands},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disruption recovery for the pickup and delivery problem with
time windows—a scenario-based approach for online food delivery.
<em>COR</em>, <em>159</em>, 106337. (<a
href="https://doi.org/10.1016/j.cor.2023.106337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the pickup and delivery problem has attracted increasing attention due to its applications in online food delivery services. At the same time, unforeseen events, such as vehicle breakdowns, traffic jam, and service time changes, often lead to the delay of delivery services. This paper defines the disruption recovery problem for the pickup and delivery problem with time windows (DR-PDPTW) and presents a scenario-based approach to solve the problem in a computationally efficient way. The approach starts with pre-disruption preparation that generates disruption scenarios and corresponding candidate recovery solutions. Once a disruption occurs, the approach will first check if recovery efforts are necessary based on the magnitude of delays caused by the disruption. If such delays are not acceptable, the approach will move to the post-disruption response stage to match the disruption with an already generated disruption scenario. Then corresponding candidate recovery solutions will be adjusted based on the actual disruption and executed. Computation experiments demonstrate the quality and efficiency of the proposed approach. This study can help to provide real-time decision support for disruption management in online food delivery services.},
  archive      = {J_COR},
  author       = {Yuzhen Hu and Pu Zhang and Kang Zhao and Song Zhang and Bo Fan},
  doi          = {10.1016/j.cor.2023.106337},
  journal      = {Computers &amp; Operations Research},
  pages        = {106337},
  shortjournal = {Comput. Oper. Res.},
  title        = {Disruption recovery for the pickup and delivery problem with time windows—A scenario-based approach for online food delivery},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint location and cost planning in maximum capture facility
location under random utilities. <em>COR</em>, <em>159</em>, 106336. (<a
href="https://doi.org/10.1016/j.cor.2023.106336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a joint facility location and cost planning problem in a competitive market under random utility maximization (RUM) models. The objective is to locate new facilities and make decisions on the costs (or budgets) to spend on the new facilities, aiming to maximize an expected captured customer demand, assuming that customers choose a facility among all available facilities according to a RUM model. We examine two RUM frameworks in the discrete choice literature, namely, the additive and multiplicative RUM. While the former has been widely used in facility location problems, we are the first to explore the latter in the context. We numerically show that the two RUM frameworks can well approximate each other in the context of the cost optimization problem . In addition, we show that, under the additive RUM framework, the resultant cost optimization problem becomes highly non-convex and may have several local optima. In contrast, the use of the multiplicative RUM brings several advantages to the competitive facility location problem. For instance, the cost optimization problem under the multiplicative RUM can be solved efficiently by a general convex optimization solver, or can be reformulated as a conic quadratic program and handled by a conic solver available in some off-the-shelf solvers such as CPLEX or GUROBI. Furthermore, we consider a joint location and cost optimization problem under the multiplicative RUM and propose three approaches to solve the problem, namely, an equivalent conic reformulation, a multi-cut outer-approximation algorithm, and a local search heuristic . We provide numerical experiments based on synthetic instances of various sizes to evaluate the performances of the proposed algorithms in solving the cost optimization and the joint location and cost optimization problems.},
  archive      = {J_COR},
  author       = {Ngan Ha Duong and Tien Thanh Dam and Thuy Anh Ta and Tien Mai},
  doi          = {10.1016/j.cor.2023.106336},
  journal      = {Computers &amp; Operations Research},
  pages        = {106336},
  shortjournal = {Comput. Oper. Res.},
  title        = {Joint location and cost planning in maximum capture facility location under random utilities},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The profit-oriented hub line location problem with elastic
demand. <em>COR</em>, <em>159</em>, 106335. (<a
href="https://doi.org/10.1016/j.cor.2023.106335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with an extension of the hub line location problem considering demand elasticity with respect to travel times. The proposed model aims to capture the impact the hub network topology has on demand. The objective is to maximize the total revenue generated by each unit of demand using the hub line. We propose mixed-integer nonlinear formulations to model this problem. We study some properties of the nonlinear objective function associated with these formulations. Due to the inherent complexity involved in solving these nonlinear formulations with state-of-the-art solvers, we also present alternative mixed-integer linear programming formulations. Computational results compare the proposed formulations and the benefits of the presented model using benchmark instances commonly used in hub location. Moreover, a sensitivity analysis study is carried out with real data from the city of Montreal, Canada, to demonstrate the added value of incorporating demand elasticity when using the proposed model for public transportation planning.},
  archive      = {J_COR},
  author       = {Brenda Cobeña and Ivan Contreras and Luisa I. Martínez-Merino and Antonio M. Rodríguez-Chía},
  doi          = {10.1016/j.cor.2023.106335},
  journal      = {Computers &amp; Operations Research},
  pages        = {106335},
  shortjournal = {Comput. Oper. Res.},
  title        = {The profit-oriented hub line location problem with elastic demand},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust MILP formulations for the two-stage weighted vertex
p-center problem. <em>COR</em>, <em>159</em>, 106334. (<a
href="https://doi.org/10.1016/j.cor.2023.106334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The weighted vertex p p -center problem ( P C P ) (PCP) consists of locating p p facilities among a set of available sites such that the maximum weighted distance (or travel time) from any demand node to its closest located facility is minimized. This paper studies the exact solution of the two-stage robust weighted vertex p p -center problem ( R P C P 2 ) (RPCP2) . In this problem, the location of the facilities is fixed in the first stage while the demand node allocations are recourse decisions fixed once the uncertainty is revealed. The problem is modeled by box uncertainty sets on both the demands and the distances. We introduce five different robust reformulations based on MILP formulations of ( P C P ) (PCP) from the literature. We prove that considering a finite subset of scenarios is sufficient to obtain an optimal solution of ( R P C P 2 ) (RPCP2) . We leverage this result to introduce a column-and-constraint generation algorithm and a branch-and-cut algorithm to efficiently solve this problem optimally. We highlight how these algorithms can also be adapted to solve the single-stage problem ( R P C P 1 ) (RPCP1) which is obtained when no recourse is considered. We present a numerical study to compare the performances of these formulations on randomly generated instances and on a case study from the literature.},
  archive      = {J_COR},
  author       = {Cristian Duran-Mateluna and Zacharie Ales and Sourour Elloumi and Natalia Jorquera-Bravo},
  doi          = {10.1016/j.cor.2023.106334},
  journal      = {Computers &amp; Operations Research},
  pages        = {106334},
  shortjournal = {Comput. Oper. Res.},
  title        = {Robust MILP formulations for the two-stage weighted vertex p-center problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast 1-flip neighborhood evaluations for large-scale
pseudo-boolean optimization using posiform representation. <em>COR</em>,
<em>159</em>, 106324. (<a
href="https://doi.org/10.1016/j.cor.2023.106324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the general case of pseudo-Boolean optimization ( PBO ). This problem belongs to the NP-hard class of computational complexity and generalizes the well-known quadratic unconstrained binary optimization ( QUBO ) problem, which is able to model a wide range of combinatorial optimization problems and also has applications in quantum computing . Several state-of-the-art methods in the literature for solving specific classes of PBO problems rely on the ability to quickly evaluate changes in objective function value upon a flip move, i.e., after changing the value of a Boolean variable in a given solution from 0 to 1 or from 1 to 0. In this work, we propose closed-form formulae, and develop algorithms and auxiliary data structures for quickly evaluating 1-flip move neighborhoods in PBO problems. We work with the objective function represented as a posiform, i.e., a sum of terms that may contain Boolean variables or negations thereof. This representation is interesting for solving large-scale instances, since converting a posiform to an expression containing no variable negations may take exponential time and space in the number of variables. We also provide implementations of our algorithms and data structures as a library written in C programming language. This library can be used to implement methods with fast flip move evaluations for solving PBO problem instances. We conducted computational experiments with implementations of a Iterated Tabu Search (ITS) metaheuristic , when solving randomly-generated instances, and also instances of the Hypergraph Maximum Cut problem, which can be easily recast as a PBO problem. The results showed that our best evaluation algorithms provided relatively large speedups as instance sizes increased, and became more competitive as a consequence of speedup.},
  archive      = {J_COR},
  author       = {Ricardo N. Liang and Eduardo A.J. Anacleto and Cláudio N. Meneses},
  doi          = {10.1016/j.cor.2023.106324},
  journal      = {Computers &amp; Operations Research},
  pages        = {106324},
  shortjournal = {Comput. Oper. Res.},
  title        = {Fast 1-flip neighborhood evaluations for large-scale pseudo-boolean optimization using posiform representation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of the simple assembly line balancing problem
complexity. <em>COR</em>, <em>159</em>, 106323. (<a
href="https://doi.org/10.1016/j.cor.2023.106323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simple assembly line balancing problem (SALBP) involves the determination of the assignment of elementary assembly operations to the workstations of the assembly line for the manufacture of a final product, with the objective of maximising assembly efficiency. In addition to its practicality, the SALBP can be considered as an extension of the bin packing problem (BPP) to account for the precedence relations between items. These constraints introduce an ordering component to the problem, which increases the complexity of SALBP resolution. However, previous studies indicated that precedence constraints do not play an important role in the capacity of state-of-the-art procedures to solve benchmark instances to optimality . In this study, we analysed the influences of different features of an SALBP instance on the performance of state-of-the-art solution methods for the abovementioned problem. First, we provide an alternative proof of complexity for the SALBP that uses precedence constraints to demonstrate its non-deterministic polynomial time (NP)-complete status, followed by a new set of benchmark instances directed towards an empirical analysis of the different features of SALBP instances. The experimental results revealed that the packing features of the SALBP are a major source of the perceived difficulty for any instance; however, precedence constraints play a role in the performance of these solution procedures. Specifically, the number of precedence constraints plays an important role in the results obtained from state-of-the-art methods. In addition to the analysis, certain issues that were identified in the publicly available implementations of the state-of-the-art method for resolving this problem were addressed in this study.},
  archive      = {J_COR},
  author       = {Eduardo Álvarez-Miranda and Jordi Pereira and Mariona Vilà},
  doi          = {10.1016/j.cor.2023.106323},
  journal      = {Computers &amp; Operations Research},
  pages        = {106323},
  shortjournal = {Comput. Oper. Res.},
  title        = {Analysis of the simple assembly line balancing problem complexity},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multiple-drone arc routing and mothership coordination
problem. <em>COR</em>, <em>159</em>, 106322. (<a
href="https://doi.org/10.1016/j.cor.2023.106322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the optimisation problems that arise in coordinating a tandem between a mothership vehicle and a fleet of drones. Each drone can be launched from the mothership to perform a task. After completing their tasks, the drones return to the mothership to recharge their batteries and be ready for a new task. Tasks consist of (partially) visiting graphs of a given length to provide some services or to carry out a surveillance/inspection activity. The goal is to minimise the overall time of travelling carried out by the mothership (makespan) while satisfying some requirements in terms of fractions of visits to the target graphs. In all cases, we develop exact formulations resorting to mixed-integer second-order cone programmes that are compared on a testbed of instances to assess their performance. We also develop a matheuristic algorithm that provides reasonable solutions. Computational experiments show the usefulness of our methodology in different scenarios.},
  archive      = {J_COR},
  author       = {Lavinia Amorosi and Justo Puerto and Carlos Valverde},
  doi          = {10.1016/j.cor.2023.106322},
  journal      = {Computers &amp; Operations Research},
  pages        = {106322},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multiple-drone arc routing and mothership coordination problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Upgrading edges in the graphical TSP. <em>COR</em>,
<em>159</em>, 106321. (<a
href="https://doi.org/10.1016/j.cor.2023.106321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a generalization of the Graphical Traveling Salesman Problem (GTSP). Given a communication graph in which not all direct connections are necessarily possible, the Graphical Traveling Salesman Problem consists of finding the shortest tour that visits each node at least once. In this work, we assume the availability of a budget that allows to upgrade, i.e. reduce their traversal cost, some of the current connections and we propose the problem of designing the minimum cost tour using this budget. We propose and study a formulation for the problem, verifying that the polyhedron associated with the set of feasible solutions of a relaxed version of the problem is a full-dimensional polytope. We present families of valid inequalities that reinforce the model and pre-processing techniques to reduce the number of variables of the formulation. To solve the problem, we propose a branch-and-cut algorithm that uses the introduced valid inequalities, as well as a heuristic to obtain good upper bounds and a tailor-made branching strategy. Comprehensive computational experiments on a new set of benchmark instances are presented to assess the performance of this exact method.},
  archive      = {J_COR},
  author       = {Mercedes Landete and Isaac Plana and José Luis Sainz-Pardo and José María Sanchis},
  doi          = {10.1016/j.cor.2023.106321},
  journal      = {Computers &amp; Operations Research},
  pages        = {106321},
  shortjournal = {Comput. Oper. Res.},
  title        = {Upgrading edges in the graphical TSP},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On some lower bounds for the permutation flowshop problem.
<em>COR</em>, <em>159</em>, 106320. (<a
href="https://doi.org/10.1016/j.cor.2023.106320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The permutation flowshop problem with makespan objective is a classic machine scheduling problem , known to be NP NP -hard in the strong sense. We analyse some of the existing lower bounds for the problem, including the “job-based” and “machine-based” bounds, a bound from linear programming (LP), and a recent bound of Kumar and co-authors. We show that the Kumar et al. bound dominates the machine-based bound, but the LP bound is stronger still. On the other hand, the LP bound does not, in general, dominate the job-based bound. Based on this, we devise simple iterative procedures for strengthening the Kumar et al. and LP bounds. Computational results are encouraging. In particular, we are able to obtain improved lower bounds for the “hard, small” instances of Vallada, Ruiz and Framinan.},
  archive      = {J_COR},
  author       = {Sebastian Cáceres Gelvez and Thu Huong Dang and Adam N. Letchford},
  doi          = {10.1016/j.cor.2023.106320},
  journal      = {Computers &amp; Operations Research},
  pages        = {106320},
  shortjournal = {Comput. Oper. Res.},
  title        = {On some lower bounds for the permutation flowshop problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A variable neighborhood search for parcel delivery by
vehicle with drone cycles. <em>COR</em>, <em>159</em>, 106319. (<a
href="https://doi.org/10.1016/j.cor.2023.106319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spite of the growing literature on and relevance of vehicle-drone parcel delivery, the logistical impact of cyclic drone flights, in which a drone launches and lands at the same node (as opposed to distinct sites) while delivering to a customer in between, remains unclear. To assess the pertinence and logistical impact of drone cycles, we propose a variable neighborhood search (VNS) heuristic for the Traveling Salesman Problem with Drone (TSP-D), whereby a vehicle and its companion aerial drone are synchronously routed to deliver customer orders with the objective of minimizing the return time of both carriers to the depot. The key to the success of the proposed VNS is a two-phase intensification scheme. In the first phase, the VNS broadly explores the feasible space by temporarily limiting the scope of drone flights and rendezvous locations. In the second phase, two features are introduced to ensure a deeper exploration of the feasible space: (i) intervening visits to customers are allowed for the vehicle between the drone rendezvous (launch and re-collect) nodes and (ii) drone operations may include no cycles, single cycles, or multiple cycles. The VNS is powered by optimization models that may accommodate the diverse operational settings proposed in the TSP-D literature. Over a set of benchmark instances, the VNS improves upon the best-known results for 113/120 instances having up to 100 nodes with comparable computational effort to existing approaches. The VNS also reveals improvements of up to 1\%–8\% in delivery times when drone multi-cycles are permitted, over a test-bed of diverse customer topographies and instance sizes.},
  archive      = {J_COR},
  author       = {Amro M. El-Adle and Ahmed Ghoniem and Mohamed Haouari},
  doi          = {10.1016/j.cor.2023.106319},
  journal      = {Computers &amp; Operations Research},
  pages        = {106319},
  shortjournal = {Comput. Oper. Res.},
  title        = {A variable neighborhood search for parcel delivery by vehicle with drone cycles},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Green split multiple-commodity pickup and delivery vehicle
routing problem. <em>COR</em>, <em>159</em>, 106318. (<a
href="https://doi.org/10.1016/j.cor.2023.106318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a new version of the green split multiple-commodity pickup and delivery vehicle routing problem , in which the multiple commodity demands of each retail store could be split and each retail store could be visited multiple times. In addition, the reallocation of items collected from other retail stores, traffic congestion and time-windows for convenient pickup and delivery were considered when formulating the model. To solve this complex model, a two-stage search quantum particle swarm optimization (TSQPSO) algorithm is proposed. The two-stage search strategy of TSQPSO helps to find the optimization direction quickly. Meanwhile, the three designed neighbourhood structures help to prevent the algorithm from falling into local optimal solutions. We compared the results obtained by the GAMS optimization solver and our algorithm. The average gap between the results is 0.86\%, but our algorithm can obtain the optimal solution much faster. The computational results show that the model is capable of offering more reasonable and economical solutions. Furthermore, we found that with the lower unit operating commodity cost at the depot, the total cost is lower when the commodities are allowed to distribute from the depot. Conversely, when it is higher, the total cost is lower when the commodities collected from the supply retail stores are reallocated.},
  archive      = {J_COR},
  author       = {Jiao Zhao and Hongxia Dong and Ning Wang},
  doi          = {10.1016/j.cor.2023.106318},
  journal      = {Computers &amp; Operations Research},
  pages        = {106318},
  shortjournal = {Comput. Oper. Res.},
  title        = {Green split multiple-commodity pickup and delivery vehicle routing problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated ride-matching and vehicle-rebalancing model
for shared mobility on-demand services. <em>COR</em>, <em>159</em>,
106317. (<a href="https://doi.org/10.1016/j.cor.2023.106317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shared mobility on demand (MoD) services are receiving increased attention as many high-volume ride-hailing companies are offering shared services (e.g. UberPool, LyftLine) at an increasing rate. Also, the advent of autonomous vehicles (AVs) promises further operational opportunities to benefit from these developments as AVs enable a centrally operated and fully connected fleet. There are two fundamental tasks for a shared MoD service: ride-matching and vehicle-rebalancing. Traditionally, these two tasks are optimized sequentially and independently. The paper formulates an integrated ride-matching and vehicle-rebalancing problem for shared MoD services which simultaneously optimizes these two tasks. We propose a graph-based methodology to solve the integrated ride-matching and vehicle-rebalancing problem with a novel rebalancing cost term quantifying supply contributions of vehicle scheduling to zonal supply deficit balances (deviations from the desired supply level) in the network. The integrated model performance is validated using a large-scale empirical shared MoD dataset by comparing with state-of-the-art sequential models. Generally, the integrated model improves the level of service and sustainability performance compared to the sequential model. The detailed analysis shows that the vehicle rebalancing in the integrated model is replaced by a more effective ride-matching and penalizing singly served trips in the integrated model can further improve its sustainability performance.},
  archive      = {J_COR},
  author       = {Kerem Tuncel and Haris N. Koutsopoulos and Zhenliang Ma},
  doi          = {10.1016/j.cor.2023.106317},
  journal      = {Computers &amp; Operations Research},
  pages        = {106317},
  shortjournal = {Comput. Oper. Res.},
  title        = {An integrated ride-matching and vehicle-rebalancing model for shared mobility on-demand services},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving crop planning and rotation problems in a sustainable
agriculture perspective. <em>COR</em>, <em>159</em>, 106316. (<a
href="https://doi.org/10.1016/j.cor.2023.106316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of planning the allocation of crops to arable lands, taking into account crop rotations principles and diversification strategies promoted by sustainable agriculture is addressed. Optimization models for solving multi-period planning problems are proposed, able to decide how to allocate crops in each growing season in order to maximize the total expected profit. The allocation decisions are made considering the crop rotation benefits across seasons and the sustainable requirements stated by current regulations. A complexity analysis is performed, and polynomial special cases are presented. Integer Linear Programming models are proposed, for a case study related to structured professional Italian farms specialized in arable crops, following sustainability rules coming from public regulations and private initiatives, i.e., the Common Agricultural Policy by the European Union and “La Carta del Mulino” by the Barilla Group. Numerical experiments conducted on real data show the effectiveness of the proposed solution approaches.},
  archive      = {J_COR},
  author       = {Mario Benini and Emanuele Blasi and Paolo Detti and Lorenzo Fosci},
  doi          = {10.1016/j.cor.2023.106316},
  journal      = {Computers &amp; Operations Research},
  pages        = {106316},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving crop planning and rotation problems in a sustainable agriculture perspective},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An estimation approach for the influential–imitator
diffusion. <em>COR</em>, <em>159</em>, 106315. (<a
href="https://doi.org/10.1016/j.cor.2023.106315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a numerical estimation procedure for the influential–imitator diffusion, an extension to the Bass model in which a population is partitioned into two segments: influentials (who influence each other) and imitators (whose choices are affected by the ones of influentials). Focusing on the estimation of the model parameters, we propose a maximum likelihood approach and investigate its numerical solvability, building on an asymptotic approximation of the underlying differential equation. Specifically, we develop a truncated series expansion, exhibiting an increasing accuracy when the spontaneous innovation decreases. After uncovering the theoretical properties of the proposed methodology, we propose a specialized block coordinate descent method for the numerical maximization of the likelihood function. Empirical and computational tests are provided using the Michell and West dataset about the cannabis consumption of a cohort of students over their second, third and fourth year at a secondary school in Glasgow. The estimated imitation pattern confirms the well-known hypothesis on peer influences, where the choices of popular children represent the leading effects to determine the habits of others.},
  archive      = {J_COR},
  author       = {Ringo Thomas Tchouya and Stefano Nasini and Sophie Dabo-Niang},
  doi          = {10.1016/j.cor.2023.106315},
  journal      = {Computers &amp; Operations Research},
  pages        = {106315},
  shortjournal = {Comput. Oper. Res.},
  title        = {An estimation approach for the influential–imitator diffusion},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online optimisation for ambulance routing in disaster
response with partial or no information on victim conditions.
<em>COR</em>, <em>159</em>, 106314. (<a
href="https://doi.org/10.1016/j.cor.2023.106314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to mass casualty incidents, medical aid must be provided to numerous victims synchronously under challenging circumstances including uncertainty about the condition of victims. Therefore, it is essential to have decision support tools which can generate fast solutions under uncertainty and utilise the available medical resources efficiently to provide victims with the needed treatments. We introduce an online optimisation problem for routing and scheduling of the ambulances under uncertainty about the triage levels and required treatment times of the victims in mass casualty incidents. Due to the lack of information in the initial emergency response phase, we assume that the triage level and treatment time of each victim can be disclosed online only once the condition of a victim is closely assessed by the medical team on one of the ambulances at the casualty location. We investigate this problem under two different scenarios with partial and no information about the conditions of victims. We follow the theoretical competitive analysis framework for online optimisation and prove the lower bounds on the competitive ratio of deterministic and randomised online solutions for both cases of partial and no prior information. Next, we introduce three novel online heuristics to solve this problem. We verify the quality of our online solutions against the offline optimal solutions that are provided under complete information on a comprehensive set of 1296 instances from the literature. Finally, we draw our conclusions in regard to the suitability of each of our solutions in various scenarios of information availability with different numbers of victims.},
  archive      = {J_COR},
  author       = {Davood Shiri and Vahid Akbari and Hakan Tozan},
  doi          = {10.1016/j.cor.2023.106314},
  journal      = {Computers &amp; Operations Research},
  pages        = {106314},
  shortjournal = {Comput. Oper. Res.},
  title        = {Online optimisation for ambulance routing in disaster response with partial or no information on victim conditions},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A three-phase matheuristic algorithm for the multi-day task
assignment problem. <em>COR</em>, <em>159</em>, 106313. (<a
href="https://doi.org/10.1016/j.cor.2023.106313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a multi-day task assignment model that introduces several features of practical relevance into the widely-studied generalized assignment problem . This model includes a significantly increased number of variables and constraints compared to the task assignment models investigated in the literature and thus is computationally challenging. For solving this problem, we propose an innovative three-phase matheuristic algorithm that first employs a construction phase to quickly produce a reasonable quality solution and then alternates between an intensification phase to reach local optima and a diversification phase to drive the search into new regions. The construction phase decomposes the original problem into a sequence of smaller subproblems , solves each subproblem with the Gurobi optimizer, and aggregates the solutions from the subproblems to produce a feasible solution. The intensification phase executes an iterative variable fixing heuristic that divides the solution space into different neighborhoods and iteratively explores each neighborhood by solving the reduced model. The diversification phase solves a modified model that adds a distance component into the original objective function. Computational experiments demonstrate that our proposed algorithm outperforms Gurobi, LocalSolver and Tabu Search in terms of both solution quality and computational time. The best solutions found by our algorithm have percentage gaps to the upper bounds (attained by Gurobi and LocalSolver) ranging from 0.82\% to 2.79\%, indicating that they are very close to the optimal solutions. In addition, experimental analysis has been carried out to identify the impact of some of the key components of the proposed algorithm which are contributing to its superior performance. The benchmark instances generated for our study are made available to the public for future research works on this problem.},
  archive      = {J_COR},
  author       = {Yang Wang and Haichao Liu and Bo Peng and Haibo Wang and Abraham P. Punnen},
  doi          = {10.1016/j.cor.2023.106313},
  journal      = {Computers &amp; Operations Research},
  pages        = {106313},
  shortjournal = {Comput. Oper. Res.},
  title        = {A three-phase matheuristic algorithm for the multi-day task assignment problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learn global and optimize local: A data-driven methodology
for last-mile routing. <em>COR</em>, <em>159</em>, 106312. (<a
href="https://doi.org/10.1016/j.cor.2023.106312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In last-mile routing, the task of finding a route is often framed as a Traveling Salesman Problem to minimize travel time and associated cost. However, solutions stemming from this approach do not match the realized paths as drivers deviate due to navigational considerations and preferences. To prescribe routes that incorporate this tacit knowledge , a data-driven model is proposed that aligns well with the hierarchical structure of delivery data wherein each stop belongs to a zone — a geographical area. First, on the global level, a zone sequence is established as a result of a minimization over a cost matrix which is a weighted combination of historical information and distances (travel times) between zones. Subsequently, within zones, sequences of stops are determined, such that, integrated with the predetermined zone sequence, a full solution is obtained. The methodology is particularly promising as it propels itself within the top-tier of submissions to the Last-Mile Routing Research Challenge while maintaining an elegant decomposition that ensures a feasible implementation into practice. The concurrence between prescribed and realized routes underpins the adequateness of a hierarchical breakdown of the problem, and the fact that drivers make a series of locally optimal decisions when navigating. Furthermore, experimenting with the balance between historical information and distance exposes that historic information is pivotal in deciding a starting zone of a route. The experiments also reveal that at the end of a route, historical information can best be discarded, making the time it takes to return to the station the primary concern.},
  archive      = {J_COR},
  author       = {Mayukh Ghosh and Alex Kuiper and Roshan Mahes and Donato Maragno},
  doi          = {10.1016/j.cor.2023.106312},
  journal      = {Computers &amp; Operations Research},
  pages        = {106312},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learn global and optimize local: A data-driven methodology for last-mile routing},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constructive–destructive heuristics for the safe set
problem. <em>COR</em>, <em>159</em>, 106311. (<a
href="https://doi.org/10.1016/j.cor.2023.106311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Weighted Safe Set Problem aims to determine in an undirected graph a subset of vertices such that the weights of the connected components they induce exceed the weights of the adjacent components induced by the complementary subset. We tackle the problem with various approaches based on randomised constructive and destructive procedures, comparing them with each other and with the only other existing heuristic approach , that is a randomised destructive heuristic. The experiments concern all the available benchmark instances (random graphs up to 60 vertices), but also new benchmark instances with larger size and different topologies, namely random, small-world, regular, planar, grid and real-world graphs up to 300 vertices. Dense random graphs, in fact, appear to become progressively easier to solve as their size grows. On the other instances, the best performance is obtained by combining a randomised constructive procedure, a deterministic destructive procedure, and delayed termination conditions that allow a deeper exploration of the feasible region.},
  archive      = {J_COR},
  author       = {Alberto Boggio Tomasaz and Roberto Cordone and Pierre Hosteins},
  doi          = {10.1016/j.cor.2023.106311},
  journal      = {Computers &amp; Operations Research},
  pages        = {106311},
  shortjournal = {Comput. Oper. Res.},
  title        = {Constructive–destructive heuristics for the safe set problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved matheuristic for solving the electric vehicle
routing problem with time windows and synchronized mobile
charging/battery swapping. <em>COR</em>, <em>159</em>, 106310. (<a
href="https://doi.org/10.1016/j.cor.2023.106310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shift towards low-emission vehicles in transportation activities, electric vehicles (EVs) in particular, has accelerated lately due to the growing concerns in modern societies regarding greenhouse gas emissions and climate change. Delivery companies have started using EVs in their fleets to reduce their dependency on fossil fuels and improve their carbon footprints. However, range anxiety, long recharge durations and insufficient recharging infrastructure still restrain the wider adoption of EVs in the sector. As a remedy, battery swapping vans (BSVs) were proposed in the literature to supply energy to EVs at points of need and the arising problem was referred to as the Electric Vehicle Routing Problem with Time Windows and Synchronized Mobile Battery Swapping (EVRPTW-SMBS). However, the use of BSVs is limited to small commercial vehicles. In this study, we generalize the problem and present the Electric Vehicle Routing Problem with Time Windows and Mobile Charging Stations (EVRPTW-MCS). In this problem, EVs serve the customers within their time windows and electric trucks/vans are employed to recharge or swap their batteries at selected customer locations during their visits. The objective is to minimize the total operational cost with the minimum fleet size. First, we present the mathematical model of the EVRPTW-MCS. Next, we propose a matheuristic approach that combines the Variable Neighborhood Search with exact method to solve it. Then, we perform an extensive numerical study to validate the performance of the proposed approach and present new best solutions for two related problems in the literature. We also investigate the potential benefits of utilizing MCSs and provide several trade-off analyses. Finally, we provide a case study based on real data to present managerial insights.},
  archive      = {J_COR},
  author       = {Bülent Çatay and İhsan Sadati},
  doi          = {10.1016/j.cor.2023.106310},
  journal      = {Computers &amp; Operations Research},
  pages        = {106310},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved matheuristic for solving the electric vehicle routing problem with time windows and synchronized mobile charging/battery swapping},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A note on the exact solution of the minimum squared load
assignment problem. <em>COR</em>, <em>159</em>, 106309. (<a
href="https://doi.org/10.1016/j.cor.2023.106309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of finding a fair assignment of tasks to agents that minimizes the total sum of squared workloads was introduced by Karsu and Azizoglu (2019) as the Minimum Squared Load Assignment Problem (MSLAP). To solve this problem, the authors developed a tailored branch-and-bound algorithm. While this algorithm was shown to produce better results than CPLEX on a mixed binary linear programming formulation of the MSLAP, about 71\% of the 1200 benchmark instances yet remained unsolved. In this note, we test two state-of-the-art solvers on different mathematical programming formulations of the MSLAP. Our computational results show that the performance of the solvers is heavily dependent on the type of mathematical optimization model. The best results are obtained when the MSLAP is expressed as a quadratically-constrained program. Such a formulation allows one of the solvers to find and verify an optimal solution for every problem in the existing benchmark data sets within just a few seconds per problem, on average. Additional experiments on large-sized instances demonstrate that the solvers’ performances remain at a high level.},
  archive      = {J_COR},
  author       = {Philipp Schulze and Rico Walter},
  doi          = {10.1016/j.cor.2023.106309},
  journal      = {Computers &amp; Operations Research},
  pages        = {106309},
  shortjournal = {Comput. Oper. Res.},
  title        = {A note on the exact solution of the minimum squared load assignment problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advanced network connectivity features and zonal
requirements in covering location problems. <em>COR</em>, <em>159</em>,
106307. (<a href="https://doi.org/10.1016/j.cor.2023.106307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world facility planning problems often require to tackle simultaneously network connectivity and zonal requirements, in order to guarantee an equitable provision of services and an efficient flow of goods, people and information among the facilities. Nonetheless, such challenges have not been addressed jointly so far. In this paper we explore the introduction of advanced network connectivity features and spatial-related requirements within Covering Location Problems. We adopt a broad modelling perspective, accounting for structural and economic aspects of connectivity features, while allowing the choice for one or more facilities to serve the facility networks as depots, and containing the maximal distance between any active facility and such depot(s). A novel class of Multi-objective Covering Location problems are proposed, utilising Mixed Integer Linear Programming as a modelling tool. Aiming at obtaining efficiently the arising Pareto Sets and providing actionable decision-making support throughout real planning processes, we adapt to our problem the robust variant of the AUGMEnted ɛ ɛ ɛ -CONstraint method (AUGMECON-R). Furthermore, we exploit the mathematical properties of the proposed problems to design tailored Matheuristic algorithms which boost the scalability of the solution method, with particular reference to the case of multiple depots. By conducting a comprehensive computational study on benchmark instances, we provide a thorough proof of concept for the novel problems, highlighting the challenging nature of the advanced connectivity features and the scalability of the proposed Matheuristics. From a managerial standpoint, the suitability of the proposed work in responding effectively to the motivating needs is showcased.},
  archive      = {J_COR},
  author       = {Serena Fugaro and Antonino Sgalambro},
  doi          = {10.1016/j.cor.2023.106307},
  journal      = {Computers &amp; Operations Research},
  pages        = {106307},
  shortjournal = {Comput. Oper. Res.},
  title        = {Advanced network connectivity features and zonal requirements in covering location problems},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variance reduced shapley value estimation for trustworthy
data valuation. <em>COR</em>, <em>159</em>, 106305. (<a
href="https://doi.org/10.1016/j.cor.2023.106305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data valuation, especially quantifying data value in algorithmic prediction and decision-making, is a fundamental problem in data trading scenarios. The most widely used method is to define the data Shapley and approximate it by means of the permutation sampling algorithm . To make up for the large estimation variance of the permutation sampling that hinders the development of the data marketplace, we propose a more robust data valuation method using stratified sampling , named variance reduced data Shapley (VRDS for short). We theoretically show how to stratify, how many samples are taken at each stratum, and the sample complexity analysis of VRDS . Finally, the effectiveness of VRDS is illustrated in different types of datasets and data removal applications.},
  archive      = {J_COR},
  author       = {Mengmeng Wu and Ruoxi Jia and Changle Lin and Wei Huang and Xiangyu Chang},
  doi          = {10.1016/j.cor.2023.106305},
  journal      = {Computers &amp; Operations Research},
  pages        = {106305},
  shortjournal = {Comput. Oper. Res.},
  title        = {Variance reduced shapley value estimation for trustworthy data valuation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heuristic algorithm for nested markov decision process:
Solution quality and computational complexity. <em>COR</em>,
<em>159</em>, 106297. (<a
href="https://doi.org/10.1016/j.cor.2023.106297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A nested Markov decision process (NMDP) is a multi-level MDP consisting of an outer MDP and several inner MDPs. These MDPs are dependent on each other such that, each state of the outer MDP induces a unique inner MDP. We propose for the first time an algorithm to solve an infinite horizon nested Markov decision process under the average reward criterion (NMDP-HA). The algorithm incorporates the policy iteration method, which is composed of the value-determination operation and the policy improvement routine. To evaluate the solution quality and computational complexity of the NMDP-HA, we develop a specialized enumerative algorithm adapted from a completely observable MDP equivalent of the NMDP problem. The proposed NMDP-HA is illustrated with several numerical examples and our results for the problem instances evaluated indicate that the heuristic algorithm can find the same optimal solution in a fraction of the time the total enumeration algorithm uses to exhaustively search the entire solution space. For the cases, where the optimal solution is not found, the percentage deviation from the optimal solution is less than 5\%.},
  archive      = {J_COR},
  author       = {Sefakor Fianu and Lauren B. Davis},
  doi          = {10.1016/j.cor.2023.106297},
  journal      = {Computers &amp; Operations Research},
  pages        = {106297},
  shortjournal = {Comput. Oper. Res.},
  title        = {Heuristic algorithm for nested markov decision process: Solution quality and computational complexity},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synchronized truck and drone routing under disastrous
conditions (case study: Urban thoroughfares disinfection). <em>COR</em>,
<em>159</em>, 106295. (<a
href="https://doi.org/10.1016/j.cor.2023.106295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spraying unmanned aerial vehicles (UAVs) are widely utilized in the agricultural sector for various field operations including irrigation as well as fertilizing and pesticides applications. In this paper, we explore the application of spraying UAVs to neutralize environmental contamination or infections in crises such as outbreak of epidemics. Given the limitations of current UAV technologies and their operational constraints in urban areas, such crisis management operations are carried out in collaboration with ground vehicles. Consequently, a novel mixed-integer linear programming (MILP) model is proposed to facilitate the collaboration of ground vehicles with UAVs. A hybrid heuristic algorithm consisting of simulated annealing and tabu search is also developed to solve the large-size instances efficiently. Finally, the applicability of the model and its solution approach are validated using real-world data.},
  archive      = {J_COR},
  author       = {Hamed Manshadian and Mohsen Sadegh Amalnick and S. Ali Torabi},
  doi          = {10.1016/j.cor.2023.106295},
  journal      = {Computers &amp; Operations Research},
  pages        = {106295},
  shortjournal = {Comput. Oper. Res.},
  title        = {Synchronized truck and drone routing under disastrous conditions (case study: Urban thoroughfares disinfection)},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep multi-agent reinforcement learning approach to solve
dynamic job shop scheduling problem. <em>COR</em>, <em>159</em>, 106294.
(<a href="https://doi.org/10.1016/j.cor.2023.106294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturing industry is experiencing a revolution in the creation and utilization of data, the abundance of industrial data creates a need for data-driven techniques to implement real-time production scheduling. However, existing dynamic scheduling techniques have been mainly developed to solve problems of invariable size, and are incapable of addressing the increasing volatility and complexity of practical production scheduling problems. To facilitate near real-time decision-making on the shop floor, we propose a deep multi-agent reinforcement learning-based approach to solve the dynamic job shop scheduling problem. Double deep Q-network algorithm, attached to decentralized scheduling agents, is used to learn the relationships between production information and scheduling objectives, and to make near real-time scheduling decisions. Proposed framework utilizes centralized training and decentralized execution scheme and parameter-sharing technique to tackle the non-stationary problem in the multi-agent reinforcement learning task. Several enhancements are also developed, including the novel state and action representation that can handle size-agnostic dynamic scheduling problems, a chronological joint-action framework to alleviate the credit-assignment difficulty, and knowledge-based reward-shaping techniques to encourage cooperation. Simulation study shows that the proposed architecture significantly improves the learning effectiveness, and delivers superior performance compared to existing scheduling strategies and state-of-the-art deep reinforcement learning-based dynamic scheduling approaches.},
  archive      = {J_COR},
  author       = {Renke Liu and Rajesh Piplani and Carlos Toro},
  doi          = {10.1016/j.cor.2023.106294},
  journal      = {Computers &amp; Operations Research},
  pages        = {106294},
  shortjournal = {Comput. Oper. Res.},
  title        = {A deep multi-agent reinforcement learning approach to solve dynamic job shop scheduling problem},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-period location routing: An application to the
planning of mobile clinic operations in iraq. <em>COR</em>,
<em>159</em>, 106288. (<a
href="https://doi.org/10.1016/j.cor.2023.106288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health service access and delivery are hampered during humanitarian crises due to disrupted health systems, damaged infrastructure, and healthcare worker shortages, this particularly in conflict zones. Mobile clinics are a strategy used to reach populations cut off from local health services, and organizations commonly rely on them during relief and recovery humanitarian efforts to deliver primary healthcare. In this study, we present a multiperiod location-routing problem (MLRP) with benefits for the tactical planning of mobile clinic deployment. Our set-packing formulation was developed and solved as part of a collaboration with Première Urgence Internationale (PUI). The proposed model aims to select communities to be served and design routes to be performed such that health benefits, measured by means of coverage and continuity of care functions, are maximized throughout the planning horizon. Results are presented for an application based on PUI’s operations in Iraq, including sensitivity analyses on the parameters used to model the healthcare benefits. Managerial insights on the impacts of organizational strategic and tactical decisions, such as the number of mobile clinics and the relative importance given to coverage and continuity of care, are presented.},
  archive      = {J_COR},
  author       = {Rosemarie Santa González and Marilène Cherkesly and Teodor Gabriel Crainic and Marie-Ève Rancourt},
  doi          = {10.1016/j.cor.2023.106288},
  journal      = {Computers &amp; Operations Research},
  pages        = {106288},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-period location routing: An application to the planning of mobile clinic operations in iraq},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A massively parallel branch-&amp;-bound algorithm for the
balanced minimum evolution problem. <em>COR</em>, <em>158</em>, 106308.
(<a href="https://doi.org/10.1016/j.cor.2023.106308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We build upon recent theoretical advances in the Balanced Minimum Evolution Problem (BMEP) to design a new massively parallel exact solution algorithm that proves to be up to one order of magnitude faster than the current state-of-the-art under the same computing settings and environment.},
  archive      = {J_COR},
  author       = {Daniele Catanzaro and Martin Frohn and Olivier Gascuel and Raffaele Pesenti},
  doi          = {10.1016/j.cor.2023.106308},
  journal      = {Computers &amp; Operations Research},
  pages        = {106308},
  shortjournal = {Comput. Oper. Res.},
  title        = {A massively parallel branch-&amp;-bound algorithm for the balanced minimum evolution problem},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A DRL based approach for adaptive scheduling of
one-of-a-kind production. <em>COR</em>, <em>158</em>, 106306. (<a
href="https://doi.org/10.1016/j.cor.2023.106306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive scheduling is an efficient strategy for one-of-a-kind production (OKP) widespread in heavy industries to address its challenges of the high degree of customization and frequent interference. However, the scheduling procedure meets the problems of complex constraints and short decision time. To address these issues, this study aims to develop a reinforcement learning-based algorithm to solve the adaptive scheduling problem of OKP. The objective is to minimize the makespan. Firstly, the OKP adaptive scheduling problem is modeled as a Markov decision process, and a reinforcement learning algorithm is used to train the scheduling agent offline. Then, the trained agent can make scheduling decisions adaptively according to the production state in a short time. To evaluate the effectiveness of the proposed algorithm, a large number of numerical experiments are performed on the benchmark datasets and a practical engineering case. The results show that the proposed algorithm is competitive in static testing. And it can also achieve the balance between scheduling performance and computation time during adaptive scheduling.},
  archive      = {J_COR},
  author       = {Teng Wang and Xiaofeng Hu and Yahui Zhang},
  doi          = {10.1016/j.cor.2023.106306},
  journal      = {Computers &amp; Operations Research},
  pages        = {106306},
  shortjournal = {Comput. Oper. Res.},
  title        = {A DRL based approach for adaptive scheduling of one-of-a-kind production},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient multi-objective metaheuristic algorithm for
sustainable harvest planning problem. <em>COR</em>, <em>158</em>,
106304. (<a href="https://doi.org/10.1016/j.cor.2023.106304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shift towards sustainable and regenerative agriculture is being propelled by global farmers due to increasing awareness of social inequalities and climate change. To make this transition a reality, farmers should consider various sustainability factors including all economic, environmental, and social factors, and tackle the complexity of the harvest planning. This study introduces a new multi-objective optimization approach that employs fuzzy logic and multiple objectives to facilitate sustainable harvest planning in the face of various sources of uncertainties such as changes in commodity prices, weather conditions, crop ripening patterns, and productivity fluctuations. The model seeks to optimize profit while minimizing greenhouse gas emissions and wastes generated by harvesting machines as the economic and environmental dimensions. To incorporate social sustainability, we define the farmer&#39;s working days on each block as a constraint set in our model. To address the complexity of this optimization model in large-scale networks, this paper proposes a revised version of the non-dominated sorting genetic algorithm (NSGA-II) using the genetic engineering concept, called the non-dominated sorting genetic engineering algorithm (NSGEA). This article showcases the outcomes of a case study that employed the blueberry industry in Canada. The findings indicate that the NSGEA algorithm, which was proposed in the study, is effective in addressing our multi-objective optimization model in comparison to other metaheuristic algorithms and the epsilon constraint method. This paper concludes by discussing theoretical contributions and managerial insights that emphasize the advantages of the proposed multi-objective harvest planning problem for achieving sustainable blueberry agriculture in Canada.},
  archive      = {J_COR},
  author       = {Amir M. Fathollahi-Fard and Guangdong Tian and Hua Ke and Yaping Fu and Kuan Yew Wong},
  doi          = {10.1016/j.cor.2023.106304},
  journal      = {Computers &amp; Operations Research},
  pages        = {106304},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficient multi-objective metaheuristic algorithm for sustainable harvest planning problem},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A trajectory based heuristic for the planar p-median
problem. <em>COR</em>, <em>158</em>, 106296. (<a
href="https://doi.org/10.1016/j.cor.2023.106296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach for solving the planar p p -median problem. A sub-class of the distributed p p -median problem (Brimberg et al., 2021) is identified that allows a continuous trajectory of local optima to be constructed as a parameter α α decreases from 1 to 0. The trajectory converges to a local optimum of the planar p p -median problem as α α approaches 0. Computational results are very encouraging. For larger instances tested, the proposed trajectory method finds better solutions in a small fraction of the time taken by a conventional multi-start local search. The methodology is readily extended to continuous p p -median problems in higher dimensional spaces.},
  archive      = {J_COR},
  author       = {Zvi Drezner and Jack Brimberg and Anita Schöbel},
  doi          = {10.1016/j.cor.2023.106296},
  journal      = {Computers &amp; Operations Research},
  pages        = {106296},
  shortjournal = {Comput. Oper. Res.},
  title        = {A trajectory based heuristic for the planar p-median problem},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An iterated local search algorithm for latency vehicle
routing problems with multiple depots. <em>COR</em>, <em>158</em>,
106293. (<a href="https://doi.org/10.1016/j.cor.2023.106293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-depot Cumulative Capacitated Vehicle Routing Problem (MDCCVRP) extends the recently proposed Cumulative Capacitated Vehicle Routing Problem (CCVRP). The aim is to minimize the sum of the arrival times at the customers considering a fleet of N v Nv capacitated vehicles and a set of N d Nd uncapacitated depots. This paper proposes valid lower bounds and a novel metaheuristic algorithm for the solution of the MDCCVRP. The initial solution is obtained by combining different heuristic approaches , while the improving phase consists of an iterated local search algorithm (ILS). Computational experiments on 78 MDCCVRP benchmark instances show that the proposed algorithm is able to find, within reasonable computing times, solution values globally better than those obtained by the state-of-the-art heuristic algorithms . For challenging instances (having a large number of customers and a small fleet size), the algorithm can find, within short computing times, solutions globally better than those obtained by the published exact algorithms. The proposed algorithm has also been applied to the recently introduced Multi-depot k -traveling Repairman Problem (MD k -TRP) and the Latency Location Routing Problem (LLRP). The MD k -TRP is a particular case of the MDCCVRP arising when the vehicles are uncapacitated, while the LLRP is a generalization of the MDCCVRP in which, at most, p p of the N d Nd available depots can be used. The computational experiments performed on 87 MD k -TRP benchmark instances and 76 LLRP benchmark instances show that the proposed algorithm globally outperforms the state-of-the-art metaheuristic algorithms for what concerns both the solution quality and the computing time. For large-size instances, the computing time required to provide a good quality solution is considerably smaller than that required by the previously published heuristic and exact algorithms. For all the problems, the proposed algorithm is able to find better solution values than those obtained by the respective state-of-the-art metaheuristic algorithms when it is executed for the same computing time as the respective competitor.},
  archive      = {J_COR},
  author       = {Alan Osorio-Mora and John Willmer Escobar and Paolo Toth},
  doi          = {10.1016/j.cor.2023.106293},
  journal      = {Computers &amp; Operations Research},
  pages        = {106293},
  shortjournal = {Comput. Oper. Res.},
  title        = {An iterated local search algorithm for latency vehicle routing problems with multiple depots},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving energy aware nanosatellite task scheduling by a
branch-cut-and-price algorithm. <em>COR</em>, <em>158</em>, 106292. (<a
href="https://doi.org/10.1016/j.cor.2023.106292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CubeSats are small satellite platforms that have become increasingly popular for space research due to their small size, modular design, and affordability. However, their limited power and communication capabilities present significant challenges for the development and operation of these satellites. One of the main challenges is to effectively manage the limited power resources available on CubeSats for supporting the various tasks and payloads of the satellite. Addressing these challenges requires careful task scheduling that considers the power requirements and importance of different tasks and the trade-offs between power consumption and other factors such as data rate, volume, and accuracy. Decision-making in task scheduling for CubeSats often involves solving large mixed-integer programming (MIP) problems, which can be computationally intensive and time-consuming. To address this challenge, we propose a branch-cut-and-price algorithm for CubeSats that improves upon previous approaches in the literature. We apply dual stabilization to column generation and propose new valid inequalities ; resort to an effectively implemented dynamic programming (DP) algorithm to generate multiple columns in parallel; and rely on a new branching strategy based on pseudocosts to reduce the number of nodes and improve the overall performance of the method. Our results demonstrate the effectiveness of these enhancements for solving a complex task scheduling problem in the context of CubeSats compared to the state-of-the-art approach, and further highlight its potential to improve the efficiency and accuracy of mission planning and operations for these small satellite platforms.},
  archive      = {J_COR},
  author       = {Laio Oriel Seman and Cezar Antônio Rigo and Eduardo Camponogara and Pedro Munari and Eduardo Augusto Bezerra},
  doi          = {10.1016/j.cor.2023.106292},
  journal      = {Computers &amp; Operations Research},
  pages        = {106292},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improving energy aware nanosatellite task scheduling by a branch-cut-and-price algorithm},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A benders decomposition algorithm for a bid generation
problem in the procurement of three-echelon transportation services.
<em>COR</em>, <em>158</em>, 106291. (<a
href="https://doi.org/10.1016/j.cor.2023.106291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a bid generation problem in a combinatorial auction for the procurement of transportation services with time windows in a three-echelon transportation network. By considering the interconnectivity of transportation operations in different echelons, a path-based mathematical programming model is proposed for this problem. To solve the model with complicated linking constraints, a Benders decomposition algorithm in a heuristic manner is designed. The algorithm iteratively and alternatively solves a master problem that is a selective routing problem with time windows for the second echelon and two subproblems that are routing problems with time windows for the first and third echelon respectively. The basic Benders decomposition algorithm is enhanced by applying the acceleration techniques of multiple cuts, Pareto-optimal cuts and multiple cuts combined with Pareto-optimal cuts. Extensive computational experiments were performed to evaluate the effectiveness of the acceleration techniques and the efficiency of the algorithm. The computational results indicate that the enhanced algorithm significantly outperforms CPLEX in terms of solution quality and CPU time. Moreover, our sensitivity analysis on some key parameters of the model show that the lower the proportion of reserved requests, the larger of the capacity of each vehicle, and the higher the percentage of profit increase of a carrier after bidding.},
  archive      = {J_COR},
  author       = {Xiaohui Lyu and Haoxun Chen and Nengmin Wang and Zhen Yang},
  doi          = {10.1016/j.cor.2023.106291},
  journal      = {Computers &amp; Operations Research},
  pages        = {106291},
  shortjournal = {Comput. Oper. Res.},
  title        = {A benders decomposition algorithm for a bid generation problem in the procurement of three-echelon transportation services},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic dynamic programming heuristic for the (r,s,s)
policy parameters computation. <em>COR</em>, <em>158</em>, 106289. (<a
href="https://doi.org/10.1016/j.cor.2023.106289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new stochastic dynamic program (SDP) based heuristic to compute the ( R , s , S ) (R,s,S) policy parameters for the non-stationary stochastic lot-sizing problem with backlogging of the excessive demand, fixed order and review costs, and linear holding and penalty costs. Our model combines a greedy relaxation of the problem that considers replenishment cycles independent with a modified version of Scarf’s ( s , S ) (s,S) SDP. A simple model implementation requires a prohibitive computational effort to compute the parameters. However, leveraging the K-convexity property and deploying memoisation techniques strongly reduce the computational effort required. The resulting algorithm is considerably faster than the state-of-the-art, extending its applicability by practitioners. An extensive computational study shows that our approach computes the optimal policy in more than 97\% of the analysed instances, with a 0.02\% average optimality gap.},
  archive      = {J_COR},
  author       = {Andrea Visentin and Steven Prestwich and Roberto Rossi and S. Armagan Tarim},
  doi          = {10.1016/j.cor.2023.106289},
  journal      = {Computers &amp; Operations Research},
  pages        = {106289},
  shortjournal = {Comput. Oper. Res.},
  title        = {Stochastic dynamic programming heuristic for the (R,s,S) policy parameters computation},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-stage stochastic location–routing problem for electric
vehicles fast charging. <em>COR</em>, <em>158</em>, 106286. (<a
href="https://doi.org/10.1016/j.cor.2023.106286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric cars are projected to become the vehicles of the future. A major barrier for their expansion is range anxiety stemming from the limited range a typical electric vehicle can travel. Electric vehicle batteries’ performance and capacity are affected by many factors. In particular, the decrease in ambient temperature below a certain threshold will adversely affect the battery’s efficiency. This paper develops a two-stage stochastic program model for charging stations’ optimal location to facilitate the routing decisions of delivery services that use electric vehicles while considering the variability inherent in climate and customer demand. A novel solution approach based on the progressive hedging algorithm is presented to solve the resulting mathematical model and to provide high-quality solutions within reasonable running times for problems with many scenarios. To evaluate the proposed formulation and solution approach’s performance, Fargo city in North Dakota is selected as a testbed . We observe that the location–routing decisions are susceptible to the electric vehicle logistics underlying climate, signifying that decision-makers of the direct current fast charging electric vehicle logistic network for cities that suffer from high-temperature fluctuations would not overlook the effect of climate to design and manage the respective logistic network efficiently.},
  archive      = {J_COR},
  author       = {Amin Aghalari and Darweesh Salamah and Mohannad Kabli and Mohammad Marufuzzaman},
  doi          = {10.1016/j.cor.2023.106286},
  journal      = {Computers &amp; Operations Research},
  pages        = {106286},
  shortjournal = {Comput. Oper. Res.},
  title        = {A two-stage stochastic location–routing problem for electric vehicles fast charging},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A massively parallel evolutionary algorithm for the partial
latin square extension problem. <em>COR</em>, <em>158</em>, 106284. (<a
href="https://doi.org/10.1016/j.cor.2023.106284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The partial Latin square extension problem is to fill as many as possible empty cells of a partially filled Latin square. This problem is a useful model for a wide range of applications in diverse domains. This paper presents the first massively parallel evolutionary algorithm for this computationally challenging problem based on a transformation of the problem to partial graph coloring . The algorithm features the following original elements. Based on a very large population (with more than 1 0 4 104 individuals) and modern graphical processing units, the algorithm performs many local searches in parallel to ensure an intensive exploitation of the search space. The algorithm employs a dedicated crossover with a specific parent matching strategy to create a large number of diversified and information-preserving offspring at each generation. Extensive experiments on 1800 benchmark instances show a high competitiveness of the algorithm compared to the current best performing methods. Competitive results are also reported on the related Latin square completion problem. Analyses are performed to shed lights on the roles of the main algorithmic components .},
  archive      = {J_COR},
  author       = {Olivier Goudet and Jin-Kao Hao},
  doi          = {10.1016/j.cor.2023.106284},
  journal      = {Computers &amp; Operations Research},
  pages        = {106284},
  shortjournal = {Comput. Oper. Res.},
  title        = {A massively parallel evolutionary algorithm for the partial latin square extension problem},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The synchronized multi-commodity multi-service
transshipment-hub location problem with cyclic schedules. <em>COR</em>,
<em>158</em>, 106282. (<a
href="https://doi.org/10.1016/j.cor.2023.106282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synchronized multi-commodity multi-service Transshipment-Hub Location Problem is a hub location problem variant faced by a logistics service provider operating in the context of synchromodal logistics. The provider must decide where and when to locate transshipment facilities in order to manage many customers’ origin–destination shipments with release and due dates while minimizing a total cost given by location costs, transportation costs, and penalties related to unmet time constraints. The considered synchromodal network involves different transportation modes (e.g., truck, rail, river and sea navigation) to perform long-haul shipments and the freight synchronization at facilities for transshipment operations. To the best of our knowledge, this variant has never been studied before. Considering a time horizon in which both transportation services and demand follow a cyclic pattern, we propose a time–space network representation of the problem and an ad-hoc embedding of the time-dependent parameters into the network topology and the arcs’ weight. This allows to model the flow synchronization required by the problem through a Mixed-Integer Linear Programming formulation with a simplified structure, similar to well-known hub location problems and avoiding complicating constraints for managing the time dimension. Through an extensive experimental campaign conducted over a large set of realistic instances, we present a computational and an economic analysis. In particular, we want to assess the potential benefits of implementing synchromodal logistics operations into long-haul supply-chains managed by large service providers. Since flexibility is one of the main features of synchromodality, we evaluate the impact on decisions and costs of different levels of flexibility regarding terminals’ operations and customers’ requirements.},
  archive      = {J_COR},
  author       = {Riccardo Giusti and Daniele Manerba and Teodor Gabriel Crainic and Roberto Tadei},
  doi          = {10.1016/j.cor.2023.106282},
  journal      = {Computers &amp; Operations Research},
  pages        = {106282},
  shortjournal = {Comput. Oper. Res.},
  title        = {The synchronized multi-commodity multi-service transshipment-hub location problem with cyclic schedules},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pseudo-polynomial algorithms for solving the knapsack
problem with dependencies between items. <em>COR</em>, <em>158</em>,
106281. (<a href="https://doi.org/10.1016/j.cor.2023.106281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a new variant of the Knapsack Problem with dependencies between items. In this variant, the set of items is partitioned into subsets with dependencies among them, and an item can be selected from a subset only if at least one item is selected from each of its dependent subsets. We develop pseudo-polynomial algorithms to solve this new constrained version in the cases where the dependencies (between the subsets of items rather than items) are represented by out-trees, in-trees, and directed acyclic graphs. We consider both cases, when the weight and profit of each item are similar, which is the classical Subset Sum problem , and the case when they take arbitrary non-negative values. The proposed algorithms run in O ( n W ) O(nW) times and spaces for out-trees, while for in-trees and acyclic digraphs it runs in O ( n W + m W 2 ) O(nW+mW2) and O ( n W + m a x { m W 2 , m ( n W ) } ) O(nW+max{mW2,m(nW)}) , respectively, where n n is the number of items, W W is the knapsack capacity, and m m is the number of nodes. Experiments on randomly generated knapsack instances with different graphs of dependency are carried out to assess algorithm efficiency, and show the running dependency on different instance parameters.},
  archive      = {J_COR},
  author       = {Mohammed Lalou and Hamamache Kheddouci},
  doi          = {10.1016/j.cor.2023.106281},
  journal      = {Computers &amp; Operations Research},
  pages        = {106281},
  shortjournal = {Comput. Oper. Res.},
  title        = {Pseudo-polynomial algorithms for solving the knapsack problem with dependencies between items},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven meta-learning recommendation model for
multi-mode resource constrained project scheduling problem.
<em>COR</em>, <em>157</em>, 106290. (<a
href="https://doi.org/10.1016/j.cor.2023.106290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-heuristics widely proposed in addressing multi-mode resource constrained project scheduling problem (MRCPSP) are problem-dependent. This paper first proposes an adaptive data-driven meta -learning Meta-heuristic Recommendation Model (MRM) to solve MRCPSP intelligently and efficiently. By learning the association between problem meta -features and algorithm performance, MRM can identify the most appropriate algorithm for different MRCPSPs. Multiclass Support Vector Machine (MCSVM) are integrated to train the classifiers for predicting the performance of the candidate meta -heuristics. To validate the proposed MRM, the performance is evaluated and compared in terms of accuracy, precision, sensitivity, and comprehensive evaluation index. In the experiments of 4 scenarios with 2 strategies, the average optimization and prediction accuracies are higher than 90\% without increase in computational complexity. Comprehensive experiments and numerical results demonstrate the outperforming performance of the proposed MRM across various MRCPSP.},
  archive      = {J_COR},
  author       = {Xianghua Chu and Shuxiang Li and Fei Gao and Can Cui and Forest Pfeiffer and Jianshuang Cui},
  doi          = {10.1016/j.cor.2023.106290},
  journal      = {Computers &amp; Operations Research},
  pages        = {106290},
  shortjournal = {Comput. Oper. Res.},
  title        = {A data-driven meta-learning recommendation model for multi-mode resource constrained project scheduling problem},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fairness in maximal covering location problems.
<em>COR</em>, <em>157</em>, 106287. (<a
href="https://doi.org/10.1016/j.cor.2023.106287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a mathematical optimization framework to incorporate fairness measures from the facilities’ perspective to discrete and continuous maximal covering location problems. The main ingredients to construct a function measuring fairness in this problem are the use of (1) ordered weighted averaging operators , a popular family of aggregation criteria for solving multiobjective combinatorial optimization problems ; and (2) α α -fairness operators which allow generalizing most of the equity measures. A general mathematical optimization model is derived which captures the notion of fairness in maximal covering location problems. The models are first formulated as mixed integer non-linear optimization problems for both the discrete and the continuous location spaces. Suitable mixed integer second order cone optimization reformulations are derived using geometric properties of the problem. Finally, the paper concludes with the results obtained from an extensive battery of computational experiments on real datasets. The obtained results support the convenience of the proposed approach.},
  archive      = {J_COR},
  author       = {Víctor Blanco and Ricardo Gázquez},
  doi          = {10.1016/j.cor.2023.106287},
  journal      = {Computers &amp; Operations Research},
  pages        = {106287},
  shortjournal = {Comput. Oper. Res.},
  title        = {Fairness in maximal covering location problems},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heuristic and metaheuristic procedures for the buffer sizing
problem in parallel assembly lines balancing problem with multi-line
workstations and different cycle times. <em>COR</em>, <em>157</em>,
106285. (<a href="https://doi.org/10.1016/j.cor.2023.106285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the parallel assembly lines balancing problem (PALBP) there is the possibility that the operators can perform the tasks assigned to their multi-line workstation on two adjacent lines. As a result, the line efficiency can be increased. In a PALB system, the assembly lines can work with the same or different cycle times. In the latter case, the lines may produce in batches, and thus the use of buffers (existence and sizing) in multi-line workstations is needed. Exact procedures have been proposed to solve the buffer sizing problem (BSP) in a multi-line workstation, but only small-size instances can be solved in a viable computational time. The BSP is an unresolved problem for real-size instances. This paper presents the first non-exact procedures to solve real-size instances of the BSP in a multi-line workstation for a given set of tasks. The problem is detailed and described in the paper, and several heuristics and metaheuristic procedures are developed to solve it. Finally, several computational experiments are carried out to evaluate the procedures presented.},
  archive      = {J_COR},
  author       = {Harry Aguilar and Alberto García-Villoria and Rafael Pastor},
  doi          = {10.1016/j.cor.2023.106285},
  journal      = {Computers &amp; Operations Research},
  pages        = {106285},
  shortjournal = {Comput. Oper. Res.},
  title        = {Heuristic and metaheuristic procedures for the buffer sizing problem in parallel assembly lines balancing problem with multi-line workstations and different cycle times},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-dimensional stock cutting resilient against singular
random defects. <em>COR</em>, <em>157</em>, 106280. (<a
href="https://doi.org/10.1016/j.cor.2023.106280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When industrial components are obtained by cutting bars of raw material ( stocks ), production volumes and values can be affected by random defects in the stocks. To deal with this inconvenience, we propose to design reconfigurable cutting patterns that can be adjusted so that defects fall, as far as possible, in the residual area that is normally discarded. In this situation, a trade-off arises between the amount of this scrap area and the probability that there exists a reconfiguration with no loss of items. We define mathematical models for the expected economic value produced with a single stock, or with all the stocks cut to obtain the required items. We then introduce the relevant optimization problems , discuss their complexity and devise various solution algorithms, comprising dynamic programming and Integer Linear Programming . The effectiveness of our algorithms is finally illustrated by computational tests on sample problems derived from the literature.},
  archive      = {J_COR},
  author       = {Claudio Arbib and Fabrizio Marinelli and Ulrich Pferschy and Fatemeh K. Ranjbar},
  doi          = {10.1016/j.cor.2023.106280},
  journal      = {Computers &amp; Operations Research},
  pages        = {106280},
  shortjournal = {Comput. Oper. Res.},
  title        = {One-dimensional stock cutting resilient against singular random defects},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The transportation problem with packing constraints.
<em>COR</em>, <em>157</em>, 106278. (<a
href="https://doi.org/10.1016/j.cor.2023.106278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a new variant of the transportation problem, where a set of different commodities, available at several supply nodes with different prices, are distributed to demand nodes using a set of heterogeneous vehicle fleets available at each supply node. Since each commodity has a specific weight, there is a packing constraint due to the total capacity of each vehicle. The objective of this problem is to minimize the total supply cost, which includes the purchase cost of commodities and the fixed transportation cost based on the traveled distance. This novel variant of the transportation problem poses computational challenges due to its combinatorial structure . To tackle these challenges and solve large-scale instances to near-optimality in reasonable CPU times, we propose a variable neighborhood search algorithm. The proposed algorithm partitions the problem into smaller, more manageable problems to be solved. In order to initialize this methodology, we also propose a decomposition heuristic that prescribes initial feasible solutions in CPU times ranging from 0.6 s to 133.2 s on average with average optimality gaps ranging from 0.09\% to 4.62\%. Our proposed methodology provides solutions with 0.06\% to 3.78\% optimality gaps on average within average CPU times ranging from 0.2 s to 386.2 s, while the commercial solvers are unable to find integer solutions or to solve most of the instances to optimality within one CPU-hour time limit.},
  archive      = {J_COR},
  author       = {Tülay Flamand and Manuel Iori and Mohamed Haouari},
  doi          = {10.1016/j.cor.2023.106278},
  journal      = {Computers &amp; Operations Research},
  pages        = {106278},
  shortjournal = {Comput. Oper. Res.},
  title        = {The transportation problem with packing constraints},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the complexity of efficient multi-skilled team
composition. <em>COR</em>, <em>157</em>, 106277. (<a
href="https://doi.org/10.1016/j.cor.2023.106277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workers that master multiple skills increase the flexibility and the working range of teams in organizations. Efficient multi-skilled team formation or workforce composition is therefore paramount for the organization’s success. In this paper, we study various multi-skilled workforce formation problems that are complementary to problems in the scheduling literature. The goal of these problems is to design a set of multi-skilled workers (or resources) that can fulfill a certain skill demand. More specifically, we investigate the complexity of problems that minimize the skill availability or the size of the workforce. Next, we look at the impact of specific skill and worker characteristics on the complexity of these problems. We propose a set of fixed individual multi-skilled workforce problems, in which the number of available skills per skill type or the number of mastered skills per worker is defined upfront. Furthermore, we introduce and discuss the complexity of fixed total multi-skilled workforce problems in which either the total skill availability or the workforce size is fixed and the other quantity is minimized. We conclude this paper by applying the presented problems to real-life projects and by performing computational experiments that analyze the empirical hardness of the multi-skilled workforce problems.},
  archive      = {J_COR},
  author       = {Jakob Snauwaert and Rob Van Eynde and Mario Vanhoucke},
  doi          = {10.1016/j.cor.2023.106277},
  journal      = {Computers &amp; Operations Research},
  pages        = {106277},
  shortjournal = {Comput. Oper. Res.},
  title        = {On the complexity of efficient multi-skilled team composition},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulation-based inventory management of perishable products
via linear discrete choice models. <em>COR</em>, <em>157</em>, 106270.
(<a href="https://doi.org/10.1016/j.cor.2023.106270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retail inventory management of perishable items, like fresh food, is a relevant and complex problem. It is relevant in the light of trends towards the reduction of food waste, and because of potential cross-sales interaction with other item categories. It is complex, because of multiple sources of uncertainty in supply, demand, and quality, and other complicating factors like seasonality within the week, FIFO/LIFO consumer behavior, and potential substitutions between items, possibly because of a stockout. Similar items may be vertically differentiated due to intrinsic quality, which is also related with item age, or brand image, as it could be the case when a retail chain stocks both a brand item and a private label one. In the paper, we adapt a simple discrete choice model to represent consumers’ heterogeneity and different tradeoffs between price and quality, and apply simulation-based optimization to learn simple ordering rules for two vertically differentiated items, adapted to a seasonal case, in order to maximize long-term average profit under a lost sales assumption. While well-known constant and base-stock policies need not be optimal, they are simple to communicate and apply. We explore combinations of such rules for the two items, obtaining some useful managerial insights.},
  archive      = {J_COR},
  author       = {Daniele Giovanni Gioia and Leonardo Kanashiro Felizardo and Paolo Brandimarte},
  doi          = {10.1016/j.cor.2023.106270},
  journal      = {Computers &amp; Operations Research},
  pages        = {106270},
  shortjournal = {Comput. Oper. Res.},
  title        = {Simulation-based inventory management of perishable products via linear discrete choice models},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Literature reviews in operations research: A new taxonomy
and a meta review. <em>COR</em>, <em>157</em>, 106269. (<a
href="https://doi.org/10.1016/j.cor.2023.106269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Literature reviews represent a key genre for preserving and developing knowledge in many scientific fields, including the operations research (OR) discipline. Although the body of OR reviews shows a large diversity in terms of entities investigated, methodologies applied, and contributions developed, our discipline has been rather silent on the genre of literature reviews. As a consequence, the OR field misses (1) a classification of literature reviews, which would allow authors, readers, editors, and reviewers to distinguish various types of reviews, and (2) an overview of the landscape of (the types of) published reviews, which would allow identifying uncharted territories and untapped potentials of reviews. This meta review addresses both issues by suggesting a taxonomy of literature reviews in the OR field and applying the suggested taxonomy to the landscape of OR reviews. The proposed taxonomy distinguishes nine types of OR reviews ( scoping review , selective review , tutorial review , theoretical review , algorithmic review , computational review , meta-analysis , qualitative systematic review , and meta review ). In our empirical study, we apply the taxonomy to the body of 709 literature reviews published in 38 pertinent OR journals during the period 2011–2020. Our findings and implications include that reviews of all nine types have been published with a strong focus on scoping and selective reviews, and the remaining types of reviews have large, yet untapped potential to synthesize and create novel OR knowledge in different ways. These insights support scholars in specifying their different expectations of, needs for, and contributions of OR reviews.},
  archive      = {J_COR},
  author       = {Guido Schryen and Martina Sperling},
  doi          = {10.1016/j.cor.2023.106269},
  journal      = {Computers &amp; Operations Research},
  pages        = {106269},
  shortjournal = {Comput. Oper. Res.},
  title        = {Literature reviews in operations research: A new taxonomy and a meta review},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scoring from pairwise winning indices. <em>COR</em>,
<em>157</em>, 106268. (<a
href="https://doi.org/10.1016/j.cor.2023.106268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pairwise winning indices, computed in the Stochastic Multicriteria Acceptability Analysis, give the probability with which an alternative is preferred to another. They are computed taking into account all the instances of the assumed preference model compatible with the preference information provided by the Decision Maker mainly, but not exclusively, in terms of pairwise preference comparisons of reference alternatives. In this paper we present a new scoring method assigning a value to each alternative summarizing the results of the pairwise winning indices. Several procedures of this type have been provided in literature. However, our method, expressing the score in terms of a representative additive value function, permits to disaggregate the overall evaluation of each alternative in the sum of contributions of considered criteria. This permits not only to rank the alternatives but also to explain the reasons for which an alternative obtains its evaluation and, consequently, fills a certain ranking position. We also present a probabilistic model underlying our methodology. This probabilistic model is based on a simple piecewise linear approximation of the cumulative normal distribution , which allows the use of linear programming. To prove the efficiency of the method in representing the preferences of the Decision Maker, we performed an extensive set of simulations varying the number of alternatives and criteria. The results of the simulations, analyzed from a statistical point of view, prove the reliability of our procedure. The applicability of the method to decision making problems is explained by means of a case study related to the evaluation of financial funds.},
  archive      = {J_COR},
  author       = {Sally Giuseppe Arcidiacono and Salvatore Corrente and Salvatore Greco},
  doi          = {10.1016/j.cor.2023.106268},
  journal      = {Computers &amp; Operations Research},
  pages        = {106268},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scoring from pairwise winning indices},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid branch-and-price-and-cut algorithm for the
two-dimensional vector packing problem with time windows. <em>COR</em>,
<em>157</em>, 106267. (<a
href="https://doi.org/10.1016/j.cor.2023.106267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the two-dimensional vector packing problem with time windows (2DVPPTW). It packs all items into identical bins to minimize the number of used bins. Items are characterized by their weights, volumes, and time windows. Items have different time requirements for delivery in many practical settings. For example, items have their time windows for packing and delivery. The 2DVPPTW is subjected to three constraints: weight, volume, and time windows. We present an integer programming (IP) model for the proposed 2DVPPTW. The IP model is reformulated into the master problem and the subproblem (SP). A hybrid branch-and-price-and-cut (H-BPC) algorithm is developed to solve the 2DVPPTW. On the basis of extensive computational experiments, the proposed H-BPC is significantly effective in comparison with the commercial branch-and-bound/cut solvers, such as CPLEX, and two exact methods. The primary reason for the computational efficiency of the H-BPC is the development of a heuristic algorithm, namely, adaptive large neighborhood search (ALNS), to solve the SP, which is usually computationally expensive. Developing the heuristic algorithm extends the works on the solution to the SPs of bin packing problems and two-dimensional vector packing problems. Two dynamic programming (DP) algorithms are also proposed to solve the SP optimally, namely, the label-setting algorithm and the maximal clique-based DP (MC_DP) algorithm. Moreover, two cooperative schemes are proposed and compared. One is composed of the ALNS and label-setting algorithm, which has a shorter computational time, and the other is composed of the ALNS and MC_DP, which can obtain more optimal solutions. Furthermore, subset-row inequalities, rounded capacity inequalities, multidimensional dual-feasible function, and incompatibility preprocessing policy help to decrease the computational burden dramatically.},
  archive      = {J_COR},
  author       = {Mujin Gao and Yanru Chen and Junheng Li and M.I.M. Wahab},
  doi          = {10.1016/j.cor.2023.106267},
  journal      = {Computers &amp; Operations Research},
  pages        = {106267},
  shortjournal = {Comput. Oper. Res.},
  title        = {Hybrid branch-and-price-and-cut algorithm for the two-dimensional vector packing problem with time windows},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Manufacturing rescheduling after crisis or disaster-caused
supply chain disruption. <em>COR</em>, <em>157</em>, 106266. (<a
href="https://doi.org/10.1016/j.cor.2023.106266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problems a repair shop has with rescheduling after major supply disruptions. The repair shop provides repair and maintenance services to its customers. After a major disruption to production, the repair shop faces delays in production and order delivery due to shortages in materials and/or labor, which requires rescheduling of all the unfinished parts. We observe that the finished parts incur high holding costs until the entire order is completed, while any unfinished parts (in the form of raw material or work-in-progress) incur low holding costs until production starts. Moreover, the repair shop incurs a setup cost when switching between different types of parts. Considering these new features, we formulate the rescheduling problem for the repair shop under a coordinated supply chain as an integer program to minimize the total tardiness, setup cost, and holding cost. To solve the model, we propose an innovative two-stage genetic algorithm, which utilizes the estimation of distribution algorithm (EDA) to improve the search process of the optimal solution. We test the performance of this algorithm on a dataset generated from the order data of a heavy machinery maintenance provider. The numerical results show that our model generates solutions that outperform the initial schedule, which was obtained by minimizing holding and setup costs without disruption. In addition, using other closely-related genetic algorithms as benchmarks, we show that our algorithm outperforms the benchmarks without sacrificing the computational time. We also discuss an extension of the main model by considering the recovery of productivity in terms of processing time.},
  archive      = {J_COR},
  author       = {Hongguang Bo and Xiao Alison Chen and Qian Luo and Wenpeng Wang},
  doi          = {10.1016/j.cor.2023.106266},
  journal      = {Computers &amp; Operations Research},
  pages        = {106266},
  shortjournal = {Comput. Oper. Res.},
  title        = {Manufacturing rescheduling after crisis or disaster-caused supply chain disruption},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving the efficiency of patient diagnostic specimen
collection with the aid of a multi-modal routing algorithm.
<em>COR</em>, <em>157</em>, 106265. (<a
href="https://doi.org/10.1016/j.cor.2023.106265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Sustainable Specimen Collection Problem (SSCP), in which diagnostic specimens are collected from GP surgeries (doctor’s office/clinics) and subsequently transported to a hospital laboratory for analysis using more sustainable transport modes , is introduced in this paper. Using a weighted objective function, we solve a new multi-objective problem using cycle consolidation to limit driving time and the numbers of vans used whilst improving overall service quality, reducing costs and emissions. This particular heterogeneous vehicle routing problem is explored and applied to two real-world case studies in the UK, where 97 and 22 sites (respectively) are currently served, using a column generation based heuristic algorithm with some additional improvement heuristics. The results demonstrated a potential improvement in the system’s maximum delivery time between 41\% and 74\% compared to business-as-usual activity using solely road vehicles. Road vehicle (van) fleets could be reduced by up to 40\%, and the total driving time across the fleet by between 41\% and 65\%. Operational costs were estimated to increase by up to 38\%, though additional workloads for gig-economy cycle couriers and improvement in specimen quality and service reliability may make this trade-off worthwhile. Tailpipe CO 2 emissions were also reduced by up to 43\%. The proposed algorithm was effective, reducing computational time by up to 99\% whilst achieving an average of 5\% deviation from optimality .},
  archive      = {J_COR},
  author       = {Andy Oakey and Antonio Martinez-Sykora and Tom Cherrett},
  doi          = {10.1016/j.cor.2023.106265},
  journal      = {Computers &amp; Operations Research},
  pages        = {106265},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improving the efficiency of patient diagnostic specimen collection with the aid of a multi-modal routing algorithm},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Covering delivery problem with electric vehicle and parcel
lockers: Variable neighborhood search approach. <em>COR</em>,
<em>157</em>, 106263. (<a
href="https://doi.org/10.1016/j.cor.2023.106263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimizing total delivery time and carbon footprint in last mile delivery presents a real challenge in logistic field. Usage of electric vehicles in combination with parcel lockers responds to these challenges. In this paper we introduce the covering delivery problem in last mile with electric vehicle and parcel lockers. The proposed problem aims to design a tour for a given electric vehicle so that customers’ demands are met either by visiting them directly or they are covered by parcel lockers included in the tour. The overall goal is to minimize the total time needed to perform a tour which includes the total traveling time over the tour and charging time at charging stations where the charging station can also serve as parcel locker. The problem is modeled as a mixed integer programming model and small size instances are solved using commercial MIP solver, while for large scale ones we develop a Variable Neighborhood Search (VNS) heuristic. As an improvement procedure the developed VNS uses a new variable neighborhood descent (VND) variant called sequential-mixed VND. Extensive computational results have been performed to assess the performances of the proposed VNS heuristic. It turns out that the proposed heuristic is able to successfully tackle the studied problem.},
  archive      = {J_COR},
  author       = {Milena Vukićević and Mustapha Ratli and Atika Rivenq and Maria Zrikem},
  doi          = {10.1016/j.cor.2023.106263},
  journal      = {Computers &amp; Operations Research},
  pages        = {106263},
  shortjournal = {Comput. Oper. Res.},
  title        = {Covering delivery problem with electric vehicle and parcel lockers: Variable neighborhood search approach},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A machine learning optimization approach for last-mile
delivery and third-party logistics. <em>COR</em>, <em>157</em>, 106262.
(<a href="https://doi.org/10.1016/j.cor.2023.106262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Third-party logistics is now an essential component of efficient delivery systems, enabling companies to purchase carrier services instead of an expensive fleet of vehicles. However, carrier contracts have to be booked in advance without exact knowledge of what orders will be available for dispatch. The model describing this problem is the variable cost and size bin packing problem with stochastic items. Since it cannot be solved for realistic instances by means of exact solvers, in this paper, we present a new heuristic algorithm able to do so based on machine learning techniques . Several numerical experiments show that the proposed heuristics achieve good performance in a short computational time, thus enabling its real-world usage. Moreover, the comparison against a new and efficient version of progressive hedging proves that the proposed heuristic achieves better results. Finally, we present managerial insights for a case study on parcel delivery in Turin, Italy.},
  archive      = {J_COR},
  author       = {Maria Elena Bruni and Edoardo Fadda and Stanislav Fedorov and Guido Perboli},
  doi          = {10.1016/j.cor.2023.106262},
  journal      = {Computers &amp; Operations Research},
  pages        = {106262},
  shortjournal = {Comput. Oper. Res.},
  title        = {A machine learning optimization approach for last-mile delivery and third-party logistics},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A matheuristic for the electric vehicle routing problem with
time windows and a realistic energy consumption model. <em>COR</em>,
<em>157</em>, 106261. (<a
href="https://doi.org/10.1016/j.cor.2023.106261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address an Electric Vehicle Routing Problem with Time Windows (E-VRPTW) considering several real-like factors in the energy consumption model , e.g., the payload and the vehicle speed. We model E-VRPTW as a Mixed Integer Linear Program (MILP) where the speeds of vehicles are continuous variables that can vary between a minimum and a maximum value. Moreover, the proposed MILP formulation is cloneless since it allows using more than once the same recharging station without introducing dummy copies of it. To efficiently solve large-sized instances of the problem, we design a Random Kernel Search (RKS) matheuristic approach, based on the cloneless MILP formulation, that in turn exploits another matheuristic, called Random k-Degree Search (RkDS), to generate an initial feasible solution. We compare the results produced by a MILP solver using the MILP formulation with the ones obtained by the RKS on instances up to 100 customers derived from the benchmark instances of E-VRPTW. We show that the proposed matheuristic outperforms the cloneless MILP formulation on the medium/large-sized instances and also that it is robust, being not significantly sensitive to the values of the parameters used by the RkDS to generate the initial solution and to the initial time limit for the restricted MILP models.},
  archive      = {J_COR},
  author       = {M. Bruglieri and M. Paolucci and O. Pisacane},
  doi          = {10.1016/j.cor.2023.106261},
  journal      = {Computers &amp; Operations Research},
  pages        = {106261},
  shortjournal = {Comput. Oper. Res.},
  title        = {A matheuristic for the electric vehicle routing problem with time windows and a realistic energy consumption model},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ILS-based algorithms for the profit maximizing uncapacitated
hub network design problem with multiple allocation. <em>COR</em>,
<em>157</em>, 106252. (<a
href="https://doi.org/10.1016/j.cor.2023.106252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses a hub network design problem to maximize net profit. This problem considers an incomplete hub network with multiple allocation that does not impose capacity constraints, does not allow direct connections between non-hub nodes, and accepts the demand to be partially met, being satisfied only when profitable. To tackle this problem, which is NP-hard, we propose two heuristic algorithms based on the Iterated Local Search (ILS) metaheuristic , a standard ILS algorithm, and an Enhanced ILS algorithm, which increases the perturbation level only after a few unsuccessful attempts at improvement. Both algorithms use Random Variable Neighborhood Descent in the local search. Computational experiments were performed using benchmark instances for hub location problems, and statistical analyzes of the algorithms were presented. Numerical results confirm that both algorithms yield good-quality solutions with an acceptable runtime. In particular, the proposed algorithms obtain the optimal solution for most instances with up to 150 nodes, which have known optimal solutions. Furthermore, the proposed algorithms were able to handle instances with up to 500 nodes.},
  archive      = {J_COR},
  author       = {Fabricio Alves Oliveira and Elisangela Martins de Sá and Sérgio Ricardo de Souza and Marcone Jamilson Freitas Souza},
  doi          = {10.1016/j.cor.2023.106252},
  journal      = {Computers &amp; Operations Research},
  pages        = {106252},
  shortjournal = {Comput. Oper. Res.},
  title        = {ILS-based algorithms for the profit maximizing uncapacitated hub network design problem with multiple allocation},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reinforced hybrid genetic algorithm for the traveling
salesman problem. <em>COR</em>, <em>157</em>, 106249. (<a
href="https://doi.org/10.1016/j.cor.2023.106249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method called the Reinforced Hybrid Genetic Algorithm (RHGA) for solving the famous NP-hard Traveling Salesman Problem (TSP). Specifically, we combine reinforcement learning with the well-known Edge Assembly Crossover Genetic Algorithm (EAX-GA) and the Lin–Kernighan–Helsgaun (LKH) local search heuristic . In the hybrid algorithm, LKH can help EAX-GA improve the population by its effective local search, and EAX-GA can help LKH escape from local optima by providing high-quality and diverse initial solutions. We restrict that there is only one special individual among the population in EAX-GA that can be improved by LKH. Such a mechanism can prevent the population diversity, efficiency, and algorithm performance from declining due to the redundant calling of LKH upon the population. As a result, our proposed hybrid mechanism can help EAX-GA and LKH boost each other’s performance without reducing the convergence rate of the population. The reinforcement learning technique based on the Q-learning algorithm further promotes the hybrid genetic algorithm. Experimental results on 138 well-known and widely used TSP benchmarks with the number of cities ranging from 1,000 to 85,900 demonstrate the excellent performance of the proposed RHGA algorithm.},
  archive      = {J_COR},
  author       = {Jiongzhi Zheng and Jialun Zhong and Menglei Chen and Kun He},
  doi          = {10.1016/j.cor.2023.106249},
  journal      = {Computers &amp; Operations Research},
  pages        = {106249},
  shortjournal = {Comput. Oper. Res.},
  title        = {A reinforced hybrid genetic algorithm for the traveling salesman problem},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous instant delivery orders scheduling and routing
problem. <em>COR</em>, <em>157</em>, 106246. (<a
href="https://doi.org/10.1016/j.cor.2023.106246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling a large number of time-sensitive orders of multiple types in a short time period is a major challenge for instant delivery platforms. This study introduces an integrated problem of heterogeneous order assignment and routing optimization in the real-world setting of third-party instant delivery platforms. A mixed integer programming model is presented to optimize the assignment of instant delivery orders of multiple types and the scheduling of couriers with different grades. We develop a column generation model and a heuristic solution procedure to yield a solution for the integrated problem and we design an exact sub-procedure to accelerate the pricing problem. Taking Songjiang District, Shanghai as an example, numerical experiments are performed to evaluate the effectiveness of the proposed model and the efficiency of the proposed algorithm. The results show that the algorithm can obtain near-optimal solutions within a reasonable computing time. Several managerial implications are obtained from sensitivity analysis. The proposed methodology can be recommended for platform operators to improve dispatch efficiency and optimize workforce resources.},
  archive      = {J_COR},
  author       = {Lu Zhen and Jingwen Wu and Gilbert Laporte and Zheyi Tan},
  doi          = {10.1016/j.cor.2023.106246},
  journal      = {Computers &amp; Operations Research},
  pages        = {106246},
  shortjournal = {Comput. Oper. Res.},
  title        = {Heterogeneous instant delivery orders scheduling and routing problem},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximizing the service level on the makespan in the
stochastic flexible job-shop scheduling problem. <em>COR</em>,
<em>157</em>, 106237. (<a
href="https://doi.org/10.1016/j.cor.2023.106237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the flexible job-shop scheduling problem with stochastic processing times. To find a sequence insensitive to shop floor disturbances, the available probabilistic information related to the variability of processing times is taken into account by maximizing the makespan service level for a given deadline. This corresponds to the probability of the makespan to be smaller than a given threshold. After showing why this criterion makes sense compared to minimizing the average makespan, a solution approach relying on a tabu search and a Monte Carlo sampling-based approximation is presented. Then, new instances are generated by extending the deterministic benchmark instances. Extensive computational experiments are conducted to evaluate the relevance of the makespan service level and the performance of the proposed solution method. The drawbacks of a number of reference scenarios, including worst-case and best-case scenarios, in addressing effectively the problem under study are presented. A numerical analysis is also performed to compare the scope of the proposed criterion against the minimization of the expected makespan. The accuracy of the proposed solutions induced by the hyper-parameters of the Monte Carlo approximation is explicitly analyzed.},
  archive      = {J_COR},
  author       = {Mario Flores-Gómez and Valeria Borodin and Stéphane Dauzère-Pérès},
  doi          = {10.1016/j.cor.2023.106237},
  journal      = {Computers &amp; Operations Research},
  pages        = {106237},
  shortjournal = {Comput. Oper. Res.},
  title        = {Maximizing the service level on the makespan in the stochastic flexible job-shop scheduling problem},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal deep neural networks by maximization of the
approximation power. <em>COR</em>, <em>156</em>, 106264. (<a
href="https://doi.org/10.1016/j.cor.2023.106264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an optimal architecture for deep neural networks of given size. The optimal architecture obtains from maximizing the lower bound of the maximum number of linear regions approximated by a deep neural network with a ReLu activation function . The accuracy of the approximation function relies on the neural network structure characterized by the number, dependence and hierarchy between the nodes within and across layers. We show how the accuracy of the approximation improves as we optimally choose the width and depth of the network. A Monte-Carlo simulation exercise illustrates the outperformance of the optimized architecture against cross-validation methods and gridsearch for linear and nonlinear prediction models. The application of this methodology to the Boston Housing dataset confirms empirically the outperformance of our method against state-of the-art machine learning models.},
  archive      = {J_COR},
  author       = {Hector Calvo-Pardo and Tullio Mancini and Jose Olmo},
  doi          = {10.1016/j.cor.2023.106264},
  journal      = {Computers &amp; Operations Research},
  pages        = {106264},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal deep neural networks by maximization of the approximation power},
  volume       = {156},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint chance-constrained multi-objective multi-commodity
minimum cost network flow problem with copula theory. <em>COR</em>,
<em>156</em>, 106260. (<a
href="https://doi.org/10.1016/j.cor.2023.106260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on a specific problem in network optimization, namely the minimum cost multi-commodity network flow (MCNF) problem. The problem is complicated by the presence of uncertain parameters, including various types of costs associated with each arc in the network. The study presents a multi-objective approach to solving this problem, where the coefficients of the capacity constraints are modelled as random variables with a normal distribution, and the dependence between them is modelled using an Archimedean copula . The capacity constraints are presented as joint chance constraints, and a multi-objective problem is formulated to deal with the uncertainty. This uncertain multi-objective problem is then converted into a certain multi-objective problem using fuzzy programming . The resulting certain multi-objective MCNF problem is converted to a certain single objective problem using second-order cone programming (SOCP), which is solved using either piecewise tangent approximation or piecewise linear approximation methods. The proposed approaches are tested using numerical examples and experimental tests to demonstrate their effectiveness in solving large-scale network problems efficiently. The results show that the proposed approaches are a useful tool for solving uncertain multi-objective MCNF problems in real-world applications.},
  archive      = {J_COR},
  author       = {Somayeh Khezri and Salman Khodayifar},
  doi          = {10.1016/j.cor.2023.106260},
  journal      = {Computers &amp; Operations Research},
  pages        = {106260},
  shortjournal = {Comput. Oper. Res.},
  title        = {Joint chance-constrained multi-objective multi-commodity minimum cost network flow problem with copula theory},
  volume       = {156},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Berth and quay crane allocation and scheduling problem with
renewable energy uncertainty: A robust exact decomposition.
<em>COR</em>, <em>156</em>, 106251. (<a
href="https://doi.org/10.1016/j.cor.2023.106251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Container terminals are moving towards using renewable energy sources to manage their operations and cope with the traditional ones impacting the environment. However, renewable energy sources are limited, more costly, uncertain, and supplied in a non-continuous way. To improve operations’ sustainability, terminals are called to alternate between traditional and renewable energy sources. In this context, this paper proposes a multi-objective mathematical model to solve the berth and quay crane allocation and scheduling problem (BACASP), considering energy uncertainty and operations’ sustainability. The model considers two conflicting objectives: maximising renewable energy usage and minimising operational and energy costs. A robust version of the model is proposed to handle the uncertainty of renewable energy availability, whose objective is to optimize the worst-case scenario. Since many uncertain scenarios are involved, a simple commercial solver could not solve the model, even for small instances. Thus, we propose an exact decomposition algorithm that alleviates the model complexity, based on novel reinforcement procedures including novel set partitioning and valid inequalities, lower bounds, a warm-up scenario picking formula, speed up upper bounds, and a max–min MIP cutting procedure. A series of experiments show how the proposed approach helped tighten the model bounds, improve algorithm convergence, and alleviate computational time. We also conduct an economic analysis to assess the value of integration of energy parameters within BACASP. An additional investigation is made to show how Pareto optimal curves are sensitive to the price and availability of renewable energy uncertain scenarios.},
  archive      = {J_COR},
  author       = {Kaoutar Chargui and Tarik Zouadi and V. Raja Sreedharan},
  doi          = {10.1016/j.cor.2023.106251},
  journal      = {Computers &amp; Operations Research},
  pages        = {106251},
  shortjournal = {Comput. Oper. Res.},
  title        = {Berth and quay crane allocation and scheduling problem with renewable energy uncertainty: A robust exact decomposition},
  volume       = {156},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robustness evaluation of trust and reputation systems using
a deep reinforcement learning approach. <em>COR</em>, <em>156</em>,
106250. (<a href="https://doi.org/10.1016/j.cor.2023.106250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the biggest challenges facing trust and reputation systems (TRSs) is evaluating their ability to withstand various attacks, as these systems are vulnerable to multiple types of attacks. While simulation methods have been used to evaluate TRSs, they are limited because they cannot detect new attacks and do not ensure the system’s overall robustness. To address this limitation, verification methods have been proposed that can examine the entire state space and detect all possible attacks. However, these methods are not always practical for large models and real environments because they suffer from the state space explosion problem. To tackle this issue, we propose a deep reinforcement learning approach for evaluating the robustness of TRSs. In this approach, an agent can learn how to attack a system and find the best attack plan without prior knowledge . Additionally, our method avoids the state space explosion problem because it uses a deep Q-network instead of storing and examining the entire state space. We tested our proposed method on five well-known reputation models, assessing various attack goals such as selfishness, maliciousness, competition, and slandering. The results showed that our method was successful in identifying the best attack plan and executing it successfully in the system, demonstrating its effectiveness in evaluating the robustness of TRSs.},
  archive      = {J_COR},
  author       = {Amir Jalaly Bidgoly and Fereshteh Arabi},
  doi          = {10.1016/j.cor.2023.106250},
  journal      = {Computers &amp; Operations Research},
  pages        = {106250},
  shortjournal = {Comput. Oper. Res.},
  title        = {Robustness evaluation of trust and reputation systems using a deep reinforcement learning approach},
  volume       = {156},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A branch-and-bound algorithm for the precedence-constrained
minimum-cost arborescence problem. <em>COR</em>, <em>156</em>, 106248.
(<a href="https://doi.org/10.1016/j.cor.2023.106248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Precedence-Constrained Minimum-Cost Arborescence problem, in which precedence constraints are enforced on pairs of vertices, has been recently proposed. The purpose of the constraints is to prevent the formation of directed paths along the tree that violate a precedence relationship. The problem has been shown to be NP -hard, and formulations for the problem have been proposed in the literature. This work introduces a branch-and-bound algorithm based on a Lagrangian relaxation for solving the problem. The results show that the newly proposed method is 74.6\% faster, on average, compared to the state-of-the-art methods recently available in the literature.},
  archive      = {J_COR},
  author       = {Mauro Dell’Amico and Jafar Jamal and Roberto Montemanni},
  doi          = {10.1016/j.cor.2023.106248},
  journal      = {Computers &amp; Operations Research},
  pages        = {106248},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-bound algorithm for the precedence-constrained minimum-cost arborescence problem},
  volume       = {156},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A genetic algorithm for scheduling open shops with conflict
graphs to minimize the makespan. <em>COR</em>, <em>156</em>, 106247. (<a
href="https://doi.org/10.1016/j.cor.2023.106247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The open shop problem with conflict graph consists of scheduling jobs on an open shop system subject to conflict constraints given by a simple undirected graph G G , called the conflict graph . In this graph, each vertex represents a job, and jobs that are adjacent in G G are in conflict, i.e. they cannot be processed at the same time on different machines. The problem of finding a feasible schedule that minimizes the maximum completion time is known to be NP-hard even on two machines. In this paper, we present mixed integer linear programming models, lower bounds, and genetic algorithms for this problem. Extensive computational experiments are conducted on a large set of instances derived from well-known benchmarks of the basic open shop problem . The results show the effectiveness of the genetic algorithm that solves to optimality at least 93.490\% of the instances and the average deviation from the lower bounds is within 0.475\%. Furthermore, the algorithm improves the upper bounds obtained by the mathematical formulations and outperforms the existing heuristics.},
  archive      = {J_COR},
  author       = {Nour ElHouda Tellache and Laoucine Kerbache},
  doi          = {10.1016/j.cor.2023.106247},
  journal      = {Computers &amp; Operations Research},
  pages        = {106247},
  shortjournal = {Comput. Oper. Res.},
  title        = {A genetic algorithm for scheduling open shops with conflict graphs to minimize the makespan},
  volume       = {156},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating prepayment installment, pricing and
replenishment decisions for growing items with power demand pattern and
non-linear holding cost under carbon regulations. <em>COR</em>,
<em>156</em>, 106225. (<a
href="https://doi.org/10.1016/j.cor.2023.106225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasingly strict carbon regulations enforced by regulators are encouraging companies to seek better ways to manage inventories with a desire to reduce carbon emissions from their operations. This work investigates joint prepayment installment, pricing and replenishment decisions for a growing item under cap-and-price, cap-and-trade and carbon tax regulations with the goal of maximizing a livestock farming company&#39;s profit while simultaneously reducing total carbon emissions. To investigate the work in a more general perspective, the consumption structure of the slaughtered growing items is considered as a power pattern in both price and storage time, while the cumulative holding cost to hold a weight unit up to any time is a non-linear function of storage time under an imposed prepayment mechanism. This study examines, for the first time, the best prepayment installment decision for a growing item after characterizing its properties theoretically under carbon regulations. Integrating all possible cases of the optimal solutions from theoretical outcomes, an algorithm is suggested to achieve joint optimal decisions for the farm. Five different numerical examples are solved to examine the working performance of the algorithm and finally, several management insights are provided by investigating the changing pattern of the optimal strategies for variation of the system parameters. The derived outcomes highlight that the cap-and-price policy performs well both economically and environmentally for the livestock farming company when the penalty is less than or equal to the reward for each unit of carbon emissions. Furthermore, increased customer demand in the early stages of the cycle compels the farm to purchase a higher number of growing items amid a higher number of prepayment installments and set a lower selling price for the slaughtered growing items for increasing profit. The farming company should try to finish the prepayment using multiple payments in small amounts when the prepayment portion, the rate of interest charged and the authorized time period for prepayment are all high.},
  archive      = {J_COR},
  author       = {Md. Al-Amin Khan and Leopoldo Eduardo Cárdenas-Barrón and Gerardo Treviño-Garza and Armando Céspedes-Mota and Imelda de Jesús Loera-Hernández},
  doi          = {10.1016/j.cor.2023.106225},
  journal      = {Computers &amp; Operations Research},
  pages        = {106225},
  shortjournal = {Comput. Oper. Res.},
  title        = {Integrating prepayment installment, pricing and replenishment decisions for growing items with power demand pattern and non-linear holding cost under carbon regulations},
  volume       = {156},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A lexicographic optimization approach for a bi-objective
parallel-machine scheduling problem minimizing total quality loss and
total tardiness. <em>COR</em>, <em>155</em>, 106245. (<a
href="https://doi.org/10.1016/j.cor.2023.106245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wafer fabrication, production quality is a key performance index and is subject to machine condition deterioration. This paper studies a parallel-machine scheduling problem that can typically be found in the photolithography process. To solve the problem, a lexicographic optimization approach is proposed where the total quality loss is firstly minimized and the second objective is to minimize total tardiness. An optional maintenance activity is also considered to restore the machine condition to a certain level. Optimality properties are discussed, based on which an exact scheduling algorithm is developed. Experimental analyses derived from real data demonstrate the effectiveness of the proposed algorithm and support some managerial insights.},
  archive      = {J_COR},
  author       = {Lu Chen and Wenhui Yang and Kejun Qiu and Stéphane Dauzère-Pérès},
  doi          = {10.1016/j.cor.2023.106245},
  journal      = {Computers &amp; Operations Research},
  pages        = {106245},
  shortjournal = {Comput. Oper. Res.},
  title        = {A lexicographic optimization approach for a bi-objective parallel-machine scheduling problem minimizing total quality loss and total tardiness},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing a portfolio-based closed-loop supply chain network
for dairy products with a financial approach: Accelerated benders
decomposition algorithm. <em>COR</em>, <em>155</em>, 106244. (<a
href="https://doi.org/10.1016/j.cor.2023.106244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Product portfolio design is one of the important and effective factors in the financial and physical flows of various supply chains, especially dairy products. Accordingly, the financial and physical flows of the portfolio should be taken into consideration during the supply chain design. In this study, a closed-loop supply chain (CLSC) network is designed for dairy products aiming at maximizing the net cash flow from assets and maximizing the amounts paid to shareholders simultaneously. To find the optimal policy, an accelerated Benders decomposition (ABD) algorithm is implemented to tackle the complexity of the model. Moreover, three multi-objective optimization solution approaches of the weighted sum method (WSM), augmented ε-constraint (AEC), and fuzzy multi-objective programming (FMOP) are implemented to tackle the bi-objectiveness of the model. Next, a real case study in Iran is investigated to reveal the applicability of the developed methodology. Numerical results reveal that the ABD method reduces CPU time by about 10.8\%. Moreover, the results of the case study demonstrate that by integrating financial and physical flows, an improvement of 4.8478\% in the net cash flow from assets and a 2.3\% improvement in the amounts paid to shareholders compared to the current situation.},
  archive      = {J_COR},
  author       = {Alireza Goli and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.cor.2023.106244},
  journal      = {Computers &amp; Operations Research},
  pages        = {106244},
  shortjournal = {Comput. Oper. Res.},
  title        = {Designing a portfolio-based closed-loop supply chain network for dairy products with a financial approach: Accelerated benders decomposition algorithm},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A double-oracle, logic-based benders decomposition approach
to solve the k-adaptability problem. <em>COR</em>, <em>155</em>, 106243.
(<a href="https://doi.org/10.1016/j.cor.2023.106243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The K K -adaptability problem is a special case of adaptive robust optimization with discrete recourse that aims to prepare K K solutions under uncertainty, and select among them upon full knowledge of the realized scenario. We propose a novel approach to solve K K -adaptability problems with linear objective and constraints, binary first-stage decision variables, second-stage objective uncertainty, and a polyhedral uncertainty set. A logic-based Benders decomposition is applied to handle the first-stage decisions in a master problem, thus the Benders subproblem becomes a min–max–min robust combinatorial optimization problem . To solve the subproblem , a double-oracle algorithm that iteratively generates adverse scenarios and recourse decisions and assigns scenarios to K K -subsets of the decisions by solving p p -center problems is devised. Extensions of the proposed approach to handle parameter uncertainty in both the first-stage objective and the second-stage constraints, and for integer first-stage decision variables and nonlinear functions , are also provided. We show that, under mild conditions, the proposed algorithm converges to an optimal solution and terminates in a finite number of iterations. Numerical results obtained from experiments on benchmark instances of the adaptive shortest path problem , the regular knapsack problem , the asset liability-management problem, and a generic K K -adaptability problem demonstrate the performance advantage of the proposed approach when compared to state-of-the-art methods in the literature.},
  archive      = {J_COR},
  author       = {Alireza Ghahtarani and Ahmed Saif and Alireza Ghasemi and Erick Delage},
  doi          = {10.1016/j.cor.2023.106243},
  journal      = {Computers &amp; Operations Research},
  pages        = {106243},
  shortjournal = {Comput. Oper. Res.},
  title        = {A double-oracle, logic-based benders decomposition approach to solve the K-adaptability problem},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The balanced p-median problem with unitary demand.
<em>COR</em>, <em>155</em>, 106242. (<a
href="https://doi.org/10.1016/j.cor.2023.106242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a bi-objective variant of the p p -median problem where p p facilities must be located to serve a set of n n customers with unitary demand. The considered objectives are: minimizing the average traveled distance between customers and facilities, and balancing the number of allocated customers per facility. We denote the latter by customer allocation inequity and measure it as the mean absolute deviation of the number of customers assigned to each median. We formulate this new problem as a bi-objective mixed-integer linear program ,and use a weighted sum method to generate a representative set of Pareto optimal solutions. Considering the single-objective subproblem solved by the weighted sum method , we develop a primal–dual algorithm that handles large-scale instances by combining a Lagrangian relaxation heuristic within a variable neighborhood search metaheuristic . This algorithm relies on the solution of a tailored minimum cost flow problem for the case where the locations of the facilities are known. We evaluate the proposed formulation and algorithm on test instances from the literature. After demonstrating the effectiveness of the developed algorithm, we test it on a series of large instances derived from an industrial application of districting for last-mile delivery. We analyze the trade-off between the assignment cost and customer allocation inequity, and evaluate the quality of the solutions by comparing them with those attained through alternative inequity measures.},
  archive      = {J_COR},
  author       = {Davide Croci and Ola Jabali and Federico Malucelli},
  doi          = {10.1016/j.cor.2023.106242},
  journal      = {Computers &amp; Operations Research},
  pages        = {106242},
  shortjournal = {Comput. Oper. Res.},
  title        = {The balanced p-median problem with unitary demand},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new formulation and branch-and-cut method for
single-allocation hub location problems. <em>COR</em>, <em>155</em>,
106241. (<a href="https://doi.org/10.1016/j.cor.2023.106241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new compact formulation for uncapacitated single-allocation hub location problems with fewer variables than the previous Integer Linear Programming formulations in the literature is introduced. Our formulation works even with costs not based on distances and not satisfying triangle inequality . Moreover, costs can be given in aggregated or disaggregated way. Different families of valid inequalities that strengthen the formulation are developed and a branch-and-cut algorithm based on a relaxed version of the formulation is designed, whose restrictions are inserted in a cut generation procedure together with two sets of valid inequalities. The performance of the proposed methodology is tested on well-known hub location data sets and compared to the most recent and efficient exact algorithms for single-allocation hub location problems. Extensive computational results prove the efficiency of our methodology, that solves large-scale instances in very competitive times.},
  archive      = {J_COR},
  author       = {Inmaculada Espejo and Alfredo Marín and Juan M. Muñoz-Ocaña and Antonio M. Rodríguez-Chía},
  doi          = {10.1016/j.cor.2023.106241},
  journal      = {Computers &amp; Operations Research},
  pages        = {106241},
  shortjournal = {Comput. Oper. Res.},
  title        = {A new formulation and branch-and-cut method for single-allocation hub location problems},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient linear reformulations for binary polynomial
optimization problems. <em>COR</em>, <em>155</em>, 106240. (<a
href="https://doi.org/10.1016/j.cor.2023.106240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider unconstrained polynomial minimization problems with binary variables (BPO). These problems can be easily linearized, i.e., reformulated into a MILP in a higher dimensional space. Several linearizations are possible for a given BPO, depending on how each monomial is decomposed and replaced by additional variables and constraints. We focus on finding efficient linearizations that maximize the continuous relaxation bound of the resulting MILP. For this purpose, we introduce the notion of linearization patterns that allow us to model and enumerate the possible decompositions of a degree- d d monomial . The assignment of a unique pattern to each monomial of BPO results in a reformulation of BPO into a MILP. Our method, called MaxBound , amounts to searching for an optimal association between monomials and patterns in the sense that it leads to a MILP with the best continuous relaxation bound. We show that this process can be formulated as a MILP which we denote by ( M B ˜ ) (MB˜) . We further highlight domination properties among the patterns that allow us to discard the dominated patterns and to decrease the size of ( M B ˜ ) (MB˜) . Another effect of these domination properties is that it now makes sense to search for a reformulation that requires as few additional variables as possible, based only on the non-dominated patterns. We call this reformulation method ND-MinVar and again show that it can be found by solving another MILP. We make an experimental study on degree 4 polynomials that compares the results of both methods and shows the advantages and disadvantages of each.},
  archive      = {J_COR},
  author       = {Sourour Elloumi and Zoé Verchère},
  doi          = {10.1016/j.cor.2023.106240},
  journal      = {Computers &amp; Operations Research},
  pages        = {106240},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficient linear reformulations for binary polynomial optimization problems},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Metamodel-based simulation optimization considering a single
stochastic constraint. <em>COR</em>, <em>155</em>, 106239. (<a
href="https://doi.org/10.1016/j.cor.2023.106239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a simulation optimization problem with a single stochastic constraint where (i) the objective and constraint functions cannot be mathematically evaluated but they can be estimated via stochastic simulation and (ii) the number of solutions is very large (i.e., possibly infinite). To solve the problem, we propose metamodel-based frameworks which represent an extension of the metamodel approach in conjunction with the deterministic mathematical programming technique, and ranking and selection procedures. The firstly proposed framework uses ranking and selection procedures to identify the feasibility of a solution, and it selects the optimal solution among the visited promising solutions (with a prespecified statistical guarantee). In the stage of metamodel fitting, the regression metamodels are developed separately for the response values of the objective and the constraint. The other proposed frameworks adopt the penalty function approach, and fit appropriate metamodels for an aggregated objective function. Experimental results are provided to show the efficiency of the developed algorithms when compared to other existing approach.},
  archive      = {J_COR},
  author       = {Shing Chih Tsai and Chuljin Park and Min Han Chang},
  doi          = {10.1016/j.cor.2023.106239},
  journal      = {Computers &amp; Operations Research},
  pages        = {106239},
  shortjournal = {Comput. Oper. Res.},
  title        = {Metamodel-based simulation optimization considering a single stochastic constraint},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integer programming model and branch-and-cut algorithm for
the stack inbound and pre-marshalling problem. <em>COR</em>,
<em>155</em>, 106238. (<a
href="https://doi.org/10.1016/j.cor.2023.106238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The steel plate yard of shipbuilding separates the inbound and pre-processing operations, increasing the number of moves. This paper considers the mixed inbound and pre-processing operation and studies the stack inbound and pre-marshalling problem where storage and relocation moves can alternate. This problem aims to find a minimum operation to store all inbound plates while eliminating all blocking plates. We propose a novel integer programming model combining two moves in one time period. This model reduces the number of periods, thereby decreasing the model size, but requires extra constraints to avoid infeasible patterns. An exact branch-and-cut algorithm is introduced to tackle the influence of these extra constraints. This paper provides a new modeling approach for stack-related problems, and the experiments show that the proposed method outperforms other ILP-based methods in the literature.},
  archive      = {J_COR},
  author       = {Lebao Wu and Zuhua Jiang and Fuhua Wang},
  doi          = {10.1016/j.cor.2023.106238},
  journal      = {Computers &amp; Operations Research},
  pages        = {106238},
  shortjournal = {Comput. Oper. Res.},
  title        = {Integer programming model and branch-and-cut algorithm for the stack inbound and pre-marshalling problem},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An infeasible interior-point technique to generate the
nondominated set for multiobjective optimization problems. <em>COR</em>,
<em>155</em>, 106236. (<a
href="https://doi.org/10.1016/j.cor.2023.106236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an infeasible interior-point technique is proposed to generate the nondominated set of nonlinear multi-objective optimization problems with the help of the direction-based cone method. We derive the proposed method for both convex and nonconvex problems . In order to solve the parametric optimization problems of the cone method, the infeasible interior-point method starts with an initial iterate outside the feasible region, and then gradually reduces the primal and dual infeasibility measures and the objective function value across the iterations with the help of a merit function. Estimates of the reduction of primal and dual infeasibility parameters per iteration are given. The convergence analysis of the method and an estimate of the number of iterations to reach an ϵ ϵ -precise solution are also provided. We provide the performance of the proposed methods on a variety of convex and nonconvex multi-objective test problems. Performance comparison between the proposed method and popular existing solvers is provided with respect to two performance measures and the corresponding relative efficiency measures. The reduction of a combined infeasibility measure, as the iterations progress, on the test problems is also shown graphically.},
  archive      = {J_COR},
  author       = {Jauny and Debdas Ghosh and Qamrul Hasan Ansari and Matthias Ehrgott and Ashutosh Upadhayay},
  doi          = {10.1016/j.cor.2023.106236},
  journal      = {Computers &amp; Operations Research},
  pages        = {106236},
  shortjournal = {Comput. Oper. Res.},
  title        = {An infeasible interior-point technique to generate the nondominated set for multiobjective optimization problems},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal reservation control strategies in shared parking
systems considering two types of customers. <em>COR</em>, <em>155</em>,
106235. (<a href="https://doi.org/10.1016/j.cor.2023.106235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operational challenges of shared parking platforms include heterogeneous sharing time intervals and two types of customers randomly providing demand information. Thus, the operation of shared parking platforms necessitates a more intricate reservation strategy than those of the hotels and leasing industries. To address the problem, this study proposes reservation control strategies in a shared parking system with two types of customers and then allocates capacity among customers. Firstly, we propose a dynamic programming ( DP ) model with dynamic characteristics of demand information and prove that the boundary condition of the model is NP-hard. Secondly, period- and product-based decomposition models have been proposed to approach the DP model. The objective functions of the period- and product-based decomposition models are concave and supermodular, respectively. We also propose three approximation algorithms to obtain reservation strategies based on decomposition models. Finally, several numerical experiments are conducted to verify the effectiveness of the proposed models and algorithms. Extended experiments are conducted to test the robustness of the method for real-world applications. The results support reservation control in shared parking systems.},
  archive      = {J_COR},
  author       = {Lifeng Zhang and Yinping Mu and Xiangrui Chao and Fuying Jing},
  doi          = {10.1016/j.cor.2023.106235},
  journal      = {Computers &amp; Operations Research},
  pages        = {106235},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal reservation control strategies in shared parking systems considering two types of customers},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The effect of different mathematical formulations on a
matheuristic algorithm for the production routing problem. <em>COR</em>,
<em>155</em>, 106232. (<a
href="https://doi.org/10.1016/j.cor.2023.106232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We perform an experimental study to evaluate the performance of a matheuristic for the production routing problem (PRP). First, we develop a basic matheuristic that prescribes starting from a partial initial solution, completing it using a sequence of constructive heuristics, and improving it using a general-purpose mixed-integer programming heuristic. Next, we investigate the effect of three state-of-the-art mathematical formulations on the proposed matheuristic convergence. The formulations are implemented and tested with and without the use of valid inequalities. In addition, by suggesting different techniques to generate a feasible starting solution for our matheuristic, we assess the contribution of an initial solution to the matheuristic’s overall performance. We conduct extensive computational experiments on benchmark data instances for the PRP. The results show that a proper choice of an embedded mathematical formulation depends on the data instances’ features, such as the number of customers and the length of the planning horizon. The comparisons undertaken in this study indicate that having a better initial solution does not necessarily lead to finding a better final solution.},
  archive      = {J_COR},
  author       = {Mohamed Ben Ahmed and Lars Magnus Hvattum and Agostinho Agra},
  doi          = {10.1016/j.cor.2023.106232},
  journal      = {Computers &amp; Operations Research},
  pages        = {106232},
  shortjournal = {Comput. Oper. Res.},
  title        = {The effect of different mathematical formulations on a matheuristic algorithm for the production routing problem},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Population-based iterated greedy algorithm for the
s-labeling problem. <em>COR</em>, <em>155</em>, 106224. (<a
href="https://doi.org/10.1016/j.cor.2023.106224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The iterated greedy metaheuristic generates a sequence of solutions by iterating over a constructive heuristic using destruction and construction phases. In the last few years, it has been employed to solve a considerable number of optimization problems ; however, it has never been explored as a solver for graph labeling problems. Hence, in this paper, we contribute to bridging this gap by proposing a population-based iterated greedy to solve the S-labeling problem. The construction phase invokes a novel greedy algorithm for the problem and the destruction phase engages a destructive strength that is attenuated as the algorithm progresses. In addition, it incorporates a restart operator that is activated according to an innovative criterion for detecting convergence. Extensive experiments verify that the proposal can achieve better solution quality than the state-of-the-art optimizer for this optimization problem and other competing algorithms. We have completed the study about the potential of the iterated greedy metaheuristic for graph labeling problems by evaluating experimentally the performance of an extension of the proposed algorithm that solves the Antibandwidth problem. Remarkably, it provides comparable results to those of the best algorithms in the literature for this complex case of labeling problem.},
  archive      = {J_COR},
  author       = {Manuel Lozano and Eduardo Rodriguez-Tello},
  doi          = {10.1016/j.cor.2023.106224},
  journal      = {Computers &amp; Operations Research},
  pages        = {106224},
  shortjournal = {Comput. Oper. Res.},
  title        = {Population-based iterated greedy algorithm for the S-labeling problem},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid genetic search for the traveling salesman problem
with hybrid electric vehicle and time windows. <em>COR</em>,
<em>155</em>, 106223. (<a
href="https://doi.org/10.1016/j.cor.2023.106223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a hybrid genetic search for the traveling salesman problem considering a hybrid electric vehicle and time windows. The developed approach includes a specific operator based on the order crossover (OX) to obtain improved solutions, as well as a search limitation strategy and an efficient move evaluation scheme to speed up the local search phase . Extensive computational experiments were conducted on more than 200 benchmark instances, and the proposed algorithm revealed to be effective in systematically finding high-quality solutions when compared to those achieved by the best heuristic for the problem. A number of improved solutions were found, especially for the larger and more challenging cases, for which our algorithm performed, on average, 9 times faster than the quickest method available. Moreover, we also examine the frequency distribution of the battery operation mode usage associated with the best solutions found.},
  archive      = {J_COR},
  author       = {Yure Rocha and Anand Subramanian},
  doi          = {10.1016/j.cor.2023.106223},
  journal      = {Computers &amp; Operations Research},
  pages        = {106223},
  shortjournal = {Comput. Oper. Res.},
  title        = {Hybrid genetic search for the traveling salesman problem with hybrid electric vehicle and time windows},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A MIP model and a hybrid genetic algorithm for flexible
job-shop scheduling problem with job-splitting. <em>COR</em>,
<em>155</em>, 106222. (<a
href="https://doi.org/10.1016/j.cor.2023.106222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the scheduling literature, it is generally assumed that jobs are not split into sub-lots, or that the number and size of sub-lots are limited or predetermined. These assumptions make the problem more manageable. However, they may prevent more successful schedules. For many businesses, considering the splitting of jobs while scheduling them can create significant improvement opportunities. This study addresses the Flexible Job-Shop Scheduling Problem (FJSP) with job-splitting, determining how many sub-lots each job should be split into and the size of each sub-lot. A MIP model is proposed for the considered problem. In the model, the size and number of sub-lots of a job are not predefined or bounded. The objective function of the model is to minimize the makespan. Feasible solutions could not be found for large-sized problems by the mathematical model. So, a Hybrid Genetic Algorithm (HGA) is also proposed. In the proposed HGA, a Local Search Algorithm (LSA) that determines the size of sub-lots has been included in the GA to improve the efficiency. To show the success of the proposed HGA, its performance is compared with the classical GA.},
  archive      = {J_COR},
  author       = {Busra Tutumlu and Tugba Saraç},
  doi          = {10.1016/j.cor.2023.106222},
  journal      = {Computers &amp; Operations Research},
  pages        = {106222},
  shortjournal = {Comput. Oper. Res.},
  title        = {A MIP model and a hybrid genetic algorithm for flexible job-shop scheduling problem with job-splitting},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variable neighborhood search: The power of change and
simplicity. <em>COR</em>, <em>155</em>, 106221. (<a
href="https://doi.org/10.1016/j.cor.2023.106221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review discusses and analyses three main contributions championed by Professor Mladenović. These include variable neighborhood search (VNS), variable formulation space (VFS), and finally, the less-is-more approach (LIMA). These three methodologies share two important ingredients, namely, simplicity and change. Given that Professor Mladenović is widely known for VNS, we will focus mainly on this methodology and its developments as well as a sampling of successful applications. This is followed by a shorter discussion covering VFS and LIMA. We introduce several remarks throughout the text to highlight certain aspects while also suggesting challenging research areas to examine.},
  archive      = {J_COR},
  author       = {Jack Brimberg and Said Salhi and Raca Todosijević and Dragan Urošević},
  doi          = {10.1016/j.cor.2023.106221},
  journal      = {Computers &amp; Operations Research},
  pages        = {106221},
  shortjournal = {Comput. Oper. Res.},
  title        = {Variable neighborhood search: The power of change and simplicity},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive large neighborhood search method for rebalancing
free-floating electric vehicle sharing systems. <em>COR</em>,
<em>155</em>, 106220. (<a
href="https://doi.org/10.1016/j.cor.2023.106220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Free-floating electric vehicle sharing systems allow users to pick up an available electric vehicle (EV) and return it to any permissible parking location within a service area. Such service flexibility can drive a severe spatial imbalance between vehicle availability and trip demands. Hence, it is an important part of their operations to relocate the EV fleet to meet the next day’s demand with sufficient battery levels. This relocation operation involves a complicated routing problem for a fleet of shuttles to transport the staff drivers who recharge, if necessary, and relocate the EVs to proper demand locations. Characterized by unique hierarchical and interdependent decisions, the EV relocation and shuttle routing problem poses significant computational challenges for large-scale problems. We devise an efficient algorithm that adapts the Adaptive Large Neighborhood Search (ALNS) metaheuristic framework to overcome such unique challenges. The algorithm is tested on two sets of data: randomly generated data and real-world EV-sharing usage data in Amsterdam. The results validate the efficiency and effectiveness of our ALNS algorithm. In addition, the analysis of total operational cost and waiting time percentage provides practical recommendations to decision-makers on choosing the mode of staff transportation (e.g., shuttles vs. personal mobility such as scooters). Lastly, our numerical results also highlight the usefulness of our ALNS method, which is quite flexible to be applied to a dynamic environment where some EV demands are removed or added in the course of EV relocation operations.},
  archive      = {J_COR},
  author       = {Xufei Liu and Sang Won Kim and Changhyun Kwon},
  doi          = {10.1016/j.cor.2023.106220},
  journal      = {Computers &amp; Operations Research},
  pages        = {106220},
  shortjournal = {Comput. Oper. Res.},
  title        = {An adaptive large neighborhood search method for rebalancing free-floating electric vehicle sharing systems},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating energy consumption and charging duration of
electric vehicle in multigraph. <em>COR</em>, <em>155</em>, 106216. (<a
href="https://doi.org/10.1016/j.cor.2023.106216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two main features of electric vehicles are their ability to recuperate energy and their spent time in charging stations, including the waiting time in the queue and the battery charge duration. In this paper, we focus on estimating energy consumption and charging duration in an Electric Vehicles Routing Problem on a multigraph that incorporates a queuing model at charging stations. We develop a mathematical model and propose an Adaptive heuristic to solve the problem. The heuristic approach is compared with an exact solution on small-size instances and a Tabu Search algorithm. Computational results are also provided in larger and more realistic instances. Furthermore, we find that increasing the waiting time in the queue may lead to higher costs whereas the existence of alternative paths may reduce expenses. Finally, we conduct a sensitivity analysis to illustrate the impression of the model parameters on the solution.},
  archive      = {J_COR},
  author       = {Asal Karimpour and Mostafa Setak and Ahmad Hemmati},
  doi          = {10.1016/j.cor.2023.106216},
  journal      = {Computers &amp; Operations Research},
  pages        = {106216},
  shortjournal = {Comput. Oper. Res.},
  title        = {Estimating energy consumption and charging duration of electric vehicle in multigraph},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A numerical optimization approach for pricing components in
customer defined bundles in a B2B market. <em>COR</em>, <em>155</em>,
106215. (<a href="https://doi.org/10.1016/j.cor.2023.106215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research examines the problem of pricing products in multi-product, multi-quantity bundles in a business-to-business market setting in which customers’ valuation of products diminishes with the size of the bundle. The framework developed in this paper consists of three steps: (i) estimation of diminished valuation of each product based on their stand-alone valuations and bundle composition, (ii) maximization of expected profit of the firm to obtain the optimal bundle price, and (iii) maximization of customer satisfaction to obtain the optimal split of the bundle price into component prices. A Nelder–Mead optimization based method is proposed as a solution approach, which leverages an importance sampling based Monte Carlo integration method to approximate the quantities of interests in the model. The framework is also used to analyze the behavior of the model for quantity increase. Results indicate that the price per unit of each product decreases when the quantity of any of the products is increased. However, the rate of decrement is the least for the product whose quantity is incremented. Additional results show that fixing prices (and not re-optimizing), when the bundle composition changes, can significantly reduce the firm’s profit.},
  archive      = {J_COR},
  author       = {Ritwik Raj and Mark H. Karwan and Chase Murray and Lei Sun},
  doi          = {10.1016/j.cor.2023.106215},
  journal      = {Computers &amp; Operations Research},
  pages        = {106215},
  shortjournal = {Comput. Oper. Res.},
  title        = {A numerical optimization approach for pricing components in customer defined bundles in a B2B market},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deterministic bounding algorithm vs. A hybrid
meta-heuristic to deal with a bilevel mixed-integer nonlinear
optimization model for electricity dynamic pricing. <em>COR</em>,
<em>155</em>, 106195. (<a
href="https://doi.org/10.1016/j.cor.2023.106195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the electricity retail market, the retailer company aims to determine the optimal time-of-use (ToU) prices to maximize profits resulting from buying energy in organized (long-term, day-ahead, balancing) markets and selling it to consumers. Therefore, the retailer should take into account the consumer’s demand response actions to minimize the electricity bill in face of time varying prices. In this paper, this problem is formulated as a bilevel mixed-integer nonlinear programming model in which the retailer is the leader and the consumer is the follower. The consumer’s problem encompasses the integrated optimization of all home energy resources, considering re-scheduling appliance operation, charging/discharging of electric vehicle and stationary batteries, local microgeneration and (buying and selling) exchanges with the grid. The accurate physical modelling of appliance operation to generate effective load scheduling solutions imposes a high computational burden. Two algorithms are proposed to address this problem: a deterministic bounding algorithm (DBA) using an optimal-value-function approach for bilevel optimization, and a hybrid meta-heuristic using a particle swarm optimization algorithm to tackle the upper-level problem that calls an exact mixed-integer linear programming solver to deal with the lower-level problem. In the framework of the DBA, three different techniques were implemented to deal with the nonlinearities arising from the products of integer and continuous variables (bilinear terms): 1) solving the (non-convex) subproblems of DBA using a mixed-integer nonlinear solver, 2) using the McCormick envelopes to approximate the bilinear terms by linear ones, and 3) expressing the integer variables by binary ones and linearizing the bilinear terms using an exact form. Computational experiments are presented and discussed for real data settings of the problem under study considering a computational budget to compare the different algorithms and techniques employed. The results showed that the DBA with the approximate linearization technique (2) leads to the best solutions.},
  archive      = {J_COR},
  author       = {Inês Soares and Maria João Alves and Carlos Henggeler Antunes},
  doi          = {10.1016/j.cor.2023.106195},
  journal      = {Computers &amp; Operations Research},
  pages        = {106195},
  shortjournal = {Comput. Oper. Res.},
  title        = {A deterministic bounding algorithm vs. a hybrid meta-heuristic to deal with a bilevel mixed-integer nonlinear optimization model for electricity dynamic pricing},
  volume       = {155},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk-allocation-based index tracking. <em>COR</em>,
<em>154</em>, 106219. (<a
href="https://doi.org/10.1016/j.cor.2023.106219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Index tracking (IT) is a passive investment strategy where a portfolio is created to replicate the performance of a benchmark portfolio. This work reframes the IT problem to be more risk-centric, positing that matching the risk make-up of the tracking portfolio to that of the benchmark’s should be a primary importance in IT. To that end, a novel risk-allocation based index tracking (RABIT) framework is proposed where the risk profile of the benchmark is tracked by minimizing the difference between its sectors’ percentage risk contribution and tracking portfolio’s. The RABIT framework is formulated as a non-convex, quadratically-constrained, quadratic mixed integer program . The formulation is solvable to global optimality by the latest off-the-shelf solvers, which is verified in small-scale experiments. An exploration–exploitation heuristic utilizing nonlinear programming (NLP) and genetic algorithms (GA) is developed to solve larger scale problems which are computationally burdensome to the latest solvers. Computational experiments on synthetic and real-world financial data support the need of the RABIT framework, its use for both nominal and enhanced IT, and validate the use of the proposed heuristic to solve the problem. Empirical experiments show that by matching the risk contributions, the RABIT framework tilts the portfolios towards the benchmark, bringing it closer in terms of in-sample characteristics. The out-of-sample performance of the RABIT framework is also shown to be closer to the benchmark’s in terms of risk-adjusted return across all cardinality sizes and auxiliary objective functions.},
  archive      = {J_COR},
  author       = {Hassan T. Anis and Giorgio Costa and Roy H. Kwon},
  doi          = {10.1016/j.cor.2023.106219},
  journal      = {Computers &amp; Operations Research},
  pages        = {106219},
  shortjournal = {Comput. Oper. Res.},
  title        = {Risk-allocation-based index tracking},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The max-out min-in problem: A tool for data analysis.
<em>COR</em>, <em>154</em>, 106218. (<a
href="https://doi.org/10.1016/j.cor.2023.106218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a graph with vertex set V V and non-negative weights on the edges. For every subset of vertices S S , define ϕ ( S ) ϕ(S) to be the sum of the weights of edges with one vertex in S S and the other in V ∖ S V∖S , minus the sum of the weights of the edges with both vertices in S S . We consider the problem of finding S ⊆ V S⊆V for which ϕ ( S ) ϕ(S) is maximized. We call this combinatorial optimization problem the max-out min-in problem (MOMIP). In this paper we ( i i ) present a linear 0/1 formulation and a quadratic unconstrained binary optimization formulation for MOMIP; ( i i ii ) prove that the problem is NP-hard; ( i i i iii ) report results of computational experiments on simulated data to compare the performances of the two models; ( i v iv ) illustrate the applicability of MOMIP for two different topics in the context of data analysis, namely in the selection of variables in exploratory data analysis and in the identification of clusters in the context of cluster analysis; and ( v v ) introduce a generalization of MOMIP that includes, as particular cases, the well-known weighted maximum cut problem and a novel problem related to independent dominant sets in graphs.},
  archive      = {J_COR},
  author       = {Jorge Orestes Cerdeira and Maria João Martins and Marcos Raydan},
  doi          = {10.1016/j.cor.2023.106218},
  journal      = {Computers &amp; Operations Research},
  pages        = {106218},
  shortjournal = {Comput. Oper. Res.},
  title        = {The max-out min-in problem: A tool for data analysis},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An automatic method for generating multiple alignment
alternatives for a railway bypass. <em>COR</em>, <em>154</em>, 106217.
(<a href="https://doi.org/10.1016/j.cor.2023.106217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of designing a bypass on a railway line. Based on a geometrical model capable of determining automatically the need of major structures (bridges, tunnels, overpasses and underpasses), the optimal design of a railway bypass is formulated in the framework of Mixed Integer Non Linear Programming (MINLP), and it is solved with a numerical algorithm which provides different layout alternatives that are optimal solutions (local minima) from the economic point of view. The proposed method is tested on a case study with the aim of showing its practical usefulness as a support tool for engineers in order to accomplish the complex and time-consuming task to generate a set of initial alternatives for the design of a railway bypass.},
  archive      = {J_COR},
  author       = {Miguel E. Vázquez-Méndez and Gerardo Casal and Alberte Castro and Duarte Santamarina},
  doi          = {10.1016/j.cor.2023.106217},
  journal      = {Computers &amp; Operations Research},
  pages        = {106217},
  shortjournal = {Comput. Oper. Res.},
  title        = {An automatic method for generating multiple alignment alternatives for a railway bypass},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A matheuristic for the multi-product maritime inventory
routing problem. <em>COR</em>, <em>154</em>, 106214. (<a
href="https://doi.org/10.1016/j.cor.2023.106214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a multi-product maritime inventory routing problem in which the routes of the vessels are determined while inventories in the ports must remain within given bounds. Since there is more than one product, each port can be a consumption port for one product and a production port for another product. We propose a matheuristic to deal with large-size instances with a planning horizon of 60 days. The first phase of the heuristic identifies a subset of the arcs in order to use them as input parameters for the second phase. In the second phase, a mathematical model is solved with the selected arcs fixed. These two phases are iterated until a stopping criterion is satisfied. The solutions produced by the matheuristic are compared with those obtained by CPLEX. Comparing the single-product version of the problem with the multi-product version revealed that instances with multiple products require significantly more run time compared with the single-product instances.},
  archive      = {J_COR},
  author       = {Homayoun Shaabani and Arild Hoff and Lars Magnus Hvattum and Gilbert Laporte},
  doi          = {10.1016/j.cor.2023.106214},
  journal      = {Computers &amp; Operations Research},
  pages        = {106214},
  shortjournal = {Comput. Oper. Res.},
  title        = {A matheuristic for the multi-product maritime inventory routing problem},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level bottleneck assignment problems: Complexity and
sparsity-exploiting formulations. <em>COR</em>, <em>154</em>, 106213.
(<a href="https://doi.org/10.1016/j.cor.2023.106213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the multi-level bottleneck assignment problem: given a weight matrix , the task is to rearrange entries in each column such that the maximum sum of values in each row is as small as possible. We analyze the complexity of this problem in a generalized setting, where a graph models restrictions how values in columns can be permuted. We present a lower bound on its approximability by giving a non-trivial gap reduction from three-dimensional matching to the multi-level bottleneck assignment problem. We present new integer programming formulations and consider the impact of graph density on problem hardness in numerical experiments.},
  archive      = {J_COR},
  author       = {Trivikram Dokka and Marc Goerigk},
  doi          = {10.1016/j.cor.2023.106213},
  journal      = {Computers &amp; Operations Research},
  pages        = {106213},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-level bottleneck assignment problems: Complexity and sparsity-exploiting formulations},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimising makespan and energy consumption in task
scheduling for parallel systems. <em>COR</em>, <em>154</em>, 106212. (<a
href="https://doi.org/10.1016/j.cor.2023.106212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In parallel computing, the scheduling of the tasks of an application onto the processors of the parallel system is crucial. A task schedule determines both the allocation of tasks to the processors, and the order in which they are executed. Formally defined, this task scheduling problem is a challenging optimisation problem (strongly NP-hard), even for the case where there is only one objective, e.g. to minimise the total execution time, also known as makespan. Today task scheduling is often a constrained optimisation problem, where the makespan needs to be minimised, while keeping energy consumption below a threshold, or vice versa, where the energy consumption needs to be minimised, while keeping the makespan below a threshold. In a generalisation of this problem, we consider here a bi-objective version of this scheduling problem that aims to minimise both makespan and energy consumption in a Pareto-efficient manner. Based on a model of processor energy consumption, a bi-objective integer linear programming problem is formulated. Different approaches to modelling processor static (background) energy consumption are described. The task scheduling problems can be solved using bi-objective optimisation methods based on weighted sum scalarisation or ɛ ɛ ɛ -constraint scalarisation. In an extensive evaluation, the computational performance and the characteristics of sets of Pareto-efficient solutions of this bi-objective problem are studied and discussed, with interesting insights into the nature and shape of the Pareto-efficient sets.},
  archive      = {J_COR},
  author       = {Russell Stewart and Andrea Raith and Oliver Sinnen},
  doi          = {10.1016/j.cor.2023.106212},
  journal      = {Computers &amp; Operations Research},
  pages        = {106212},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimising makespan and energy consumption in task scheduling for parallel systems},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The p-hub centre routing problem with emissions budget:
Formulation and solution procedure. <em>COR</em>, <em>154</em>, 106211.
(<a href="https://doi.org/10.1016/j.cor.2023.106211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the use of fossil fuels has led to a drastic increase in the emissions of CO 2 and other greenhouse polluting gases. The transportation sector stands out as one of the main contributors to this pollution. Thus, several network design problems are being revisited to uncover cost and energy-efficient solutions. In this paper, we formulate and solve a p-hub centre routing problem under a CO 2 emissions budget. The aim is to locate hub nodes, allocate client nodes in local tours of capacitated vehicles, and decide on vehicle speeds during transportation. The objective is to minimise the maximum time of service subject to a budget constraint on the total CO 2 emissions cost of the hub network. To solve the introduced problem, we implement an efficient simulated annealing algorithm with a temperature-dependent penalty cost function, a fixed size prohibited solutions list, and a speed-based reparation heuristic. Additionally, we present a novel clustering-based construction heuristic to generate initial starting solutions for our algorithm, while hub location–allocation, vehicle routing, and speed optimisation operators are considered during the local search step. Extensive computational experiments on adapted AP data set instances show that the proposed solution approach outperforms a state-of-art solver in terms of CPU time and solution quality. Finally, we study the trade-off between the quality of service and the CO 2 emission costs and discuss the effect of the CO 2 budget on the design of hub networks.},
  archive      = {J_COR},
  author       = {El Mehdi Ibnoulouafi and Mustapha Oudani and Tarik Aouam and Mounir Ghogho},
  doi          = {10.1016/j.cor.2023.106211},
  journal      = {Computers &amp; Operations Research},
  pages        = {106211},
  shortjournal = {Comput. Oper. Res.},
  title        = {The p-hub centre routing problem with emissions budget: Formulation and solution procedure},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A planar facility location–allocation problem with fixed
and/or variable cost structures for rural electrification. <em>COR</em>,
<em>154</em>, 106202. (<a
href="https://doi.org/10.1016/j.cor.2023.106202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One major impediment to developing countries’ economic growth is the lack of access to affordable, sustainable, and reliable modern energy systems. Even today, hundreds of millions of people live in rural areas and do not have access to essential electricity services. In this study, we present a planar facility location–allocation problem for planning decentralized energy systems in rural development. We consider nano-grid and micro-grid systems to electrify rural households. While micro-grids serve multiple households with a common generation facility, nano-grids are small-scale systems serving individual consumers. The households served by micro-grids are connected to the generation facilities with low-voltage cables, for which we employ a distance limit constraint due to technical concerns, including power loss and allowable voltage levels. In this problem, we minimize the total investment cost that consists of the facility opening and the low-voltage cable costs. In order to capture the diversity of cost structures in renewable energy investments, we consider three versions of the objective function where we incorporate different combinations of fixed and variable cost components for facilities. For this problem, we provide mixed-integer quadratically constrained problem formulations and propose model-based and clustering-based heuristic approaches . Model-based approaches are multi-stage, in which we solve the discrete counterparts of the problem and employ alternative selection methods for the candidate facility locations. Clustering-based approaches utilize faster clustering techniques to identify the type and location of the facilities. We conduct computational experiments on real-life instances from villages in Sub-Saharan Africa and perform a comparative analysis of the suggested heuristic approaches .},
  archive      = {J_COR},
  author       = {Beste Akbas and Ayse Selin Kocaman},
  doi          = {10.1016/j.cor.2023.106202},
  journal      = {Computers &amp; Operations Research},
  pages        = {106202},
  shortjournal = {Comput. Oper. Res.},
  title        = {A planar facility location–allocation problem with fixed and/or variable cost structures for rural electrification},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integer l-shaped algorithm for vehicle routing problem
with simultaneous delivery and stochastic pickup. <em>COR</em>,
<em>154</em>, 106201. (<a
href="https://doi.org/10.1016/j.cor.2023.106201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses an exact algorithm for vehicle routing problem with simultaneous pickup and delivery in which customer demands to be collected are stochastic. The problem is modeled as a two-stage stochastic programming problem with recourse, in which routing decisions are made based on known delivery demand and deterministic expected pickup demand in the first stage and recourse actions are made in the second stage when stochastic pickup quantities have been revealed. However, failures happen when the load of the vehicle is insufficient to meet the observed pickup demand of a customer. Three recourse policies are proposed to help deal with the failures to proceed with the routing decisions in the first stage. The Integer L-shaped algorithmic framework is used to solve this two-stage stochastic programming problems with recourse. Furthermore, effective lower bounding of the expected recourse cost of partial routes is designed for the three recourse policies, respectively. Computational experiments on the newly generated instances compare the performance of the Integer L-shaped algorithm under the three recourse policies, and the conclusion is validated via numerous simulations. The effectiveness of the proposed lower bounding functionals is confirmed through reduced optimality gaps and lower computing times.},
  archive      = {J_COR},
  author       = {Yuxin Che and Zhenzhen Zhang},
  doi          = {10.1016/j.cor.2023.106201},
  journal      = {Computers &amp; Operations Research},
  pages        = {106201},
  shortjournal = {Comput. Oper. Res.},
  title        = {An integer L-shaped algorithm for vehicle routing problem with simultaneous delivery and stochastic pickup},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-stage international portfolio models with higher moment
risk measures. <em>COR</em>, <em>154</em>, 106200. (<a
href="https://doi.org/10.1016/j.cor.2023.106200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing an appropriate risk measure is a significant challenge for portfolio optimization. The purpose of this paper is to illustrate the advantages of higher moment coherent risk measures (HMCR) in evaluating portfolio risk in dynamic settings. Two two-stage international portfolio models considering the market risks and currency risks simultaneously are then established based on the HMCR measures. For ease of the implementation of the resulting dynamic portfolio models , we first derive the dual representation of the HMCR measures and prove that there exist critical degrees of risk aversion making the HMCR measures stable. Two decomposition methods are then designed to solve the models efficiently. Empirical results demonstrate that some advantages in the performance of international portfolios can be obtained when using higher moment risk measures as the optimization criterion . The solution time of our decomposition methods when solving large-scale portfolio models is less than that of other three commercial solvers: CPLEX, GUROBI and MOSEK.},
  archive      = {J_COR},
  author       = {Xiaolei He and Weiguo Zhang},
  doi          = {10.1016/j.cor.2023.106200},
  journal      = {Computers &amp; Operations Research},
  pages        = {106200},
  shortjournal = {Comput. Oper. Res.},
  title        = {Two-stage international portfolio models with higher moment risk measures},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A large neighbourhood search algorithm for solving container
loading problems. <em>COR</em>, <em>154</em>, 106199. (<a
href="https://doi.org/10.1016/j.cor.2023.106199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a Large Neighbourhood Search (LNS) algorithm that finds an effective packing of a set of items into containers. The aim of the LNS algorithm is to provide packing solutions that can be adopted by many logistics companies. The LNS algorithm can handle a set of side constraints such as orientation, stacking, and separation as well as weight limit, loading priorities, and stability to address the issues arising for loading the items. The packing solution is also visualised and animated using an Excel workbook to help the workers for loading of the items. Finally, the authors present a comparison between the performance of the LNS algorithm and the state-of-the-art algorithms from the literature based on benchmark data sets. The results demonstrate the quality of the solutions achieved by the LNS algorithm.},
  archive      = {J_COR},
  author       = {Özge Şafak and Güneş Erdoğan},
  doi          = {10.1016/j.cor.2023.106199},
  journal      = {Computers &amp; Operations Research},
  pages        = {106199},
  shortjournal = {Comput. Oper. Res.},
  title        = {A large neighbourhood search algorithm for solving container loading problems},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Eco-routing problem for the delivery of perishable products.
<em>COR</em>, <em>154</em>, 106198. (<a
href="https://doi.org/10.1016/j.cor.2023.106198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eco-routing problem (ERP) is concerned with selecting the optimal route for a vehicle to minimize fuel consumption. For delivery activities, the vehicle is often required to finish the trip within a given period, so we propose a time-constrained ERP for this case. Since the nonlinearities in the fuel consumption model and the time constraint make the ERP difficult to solve, this paper develops a method to linearize it into a mixed-integer linear programming (MILP) model that off-the-shelf optimizers can efficiently solve. When delivering perishables, the ERP should take the deterioration process into account. Thus, this paper further extends the time-constrained ERP to a bi-objective ERP, setting weighted normalized total deterioration value and fuel consumption as the objective function. Numerical experiments are implemented to investigate the performances of the proposed models and solution methods: The results demonstrate the computational efficiency of the proposed solution method. The sensitivity analysis confirms the existence of a trade-off between the total deterioration value (TDV) of perishable goods and the fuel consumption of the delivery vehicle. This trade-off can be efficiently balanced through the integration of speed optimization into the routing decision-making process. Furthermore, numerical results reveal that the vehicle can achieve a lower TDV with the same fuel consumption when traffic conditions are better.},
  archive      = {J_COR},
  author       = {Fuliang Wu and Ming Dong},
  doi          = {10.1016/j.cor.2023.106198},
  journal      = {Computers &amp; Operations Research},
  pages        = {106198},
  shortjournal = {Comput. Oper. Res.},
  title        = {Eco-routing problem for the delivery of perishable products},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient local search algorithm for minimum positive
influence dominating set problem. <em>COR</em>, <em>154</em>, 106197.
(<a href="https://doi.org/10.1016/j.cor.2023.106197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In graph theory, the minimum dominating set (MDS) problem is one of the most important combinatorial optimization problems . An important extension of the MDS problem is the minimum positive influence dominating set (MPIDS) problem; it has extensive applications, especially in social networks. Compared with MDS, which is used to develop many heuristic and exact algorithms and to efficiently solve massive graphs with millions of vertices, the MPIDS algorithms generally work on small-scale instances and are not applicable for massive graphs. To solve the MPIDS problems with different scale instances, this study proposes an efficient local search algorithm based on three main ideas. First, a reduction-based initialization method is used to fix portions of vertices inside or outside the candidate solution; it avoids exploring redundant search spaces. Second, by fully considering the characteristic of the MPIDS problem, a novel vertex exchange strategy is designed based on two types of scoring functions. Third, a general local search framework based on a two-level satisfaction judgment mechanism is proposed to improve the performance of the search procedure. The experimental results show that the proposed algorithm performs much better than several state-of-the-art MPIDS algorithms on both conventional benchmarks and a suite of massive graphs in terms of solution quality.},
  archive      = {J_COR},
  author       = {Rui Sun and Jieyu Wu and Chenghou Jin and Yiyuan Wang and Wenbo Zhou and Minghao Yin},
  doi          = {10.1016/j.cor.2023.106197},
  journal      = {Computers &amp; Operations Research},
  pages        = {106197},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient local search algorithm for minimum positive influence dominating set problem},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tight lower bounds for the traveling salesman problem with
draft limits. <em>COR</em>, <em>154</em>, 106196. (<a
href="https://doi.org/10.1016/j.cor.2023.106196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present paper, we consider the Traveling Salesman Problem with Draft Limits (TSPDL), which is a variant of the Traveling Salesman Problem (TSP) arising in maritime transportation. We provide compact formulations of polynomial size developed by using the Reformulation-Linearization Technique (RLT) with one and two levels. In doing so, we recover time-dependent formulations of TSP and provide their factorization into products involving the decision variables and their complements. This factorization affords further RLT-lifting to the model of TSPDL by combining time-dependent and flow variables that lead to very tight linear relaxation. Computational results conducted on benchmark instances confirm the tightness of the lower bounds.},
  archive      = {J_COR},
  author       = {Ali Balma and Mehdi Mrad and Talel Ladhari},
  doi          = {10.1016/j.cor.2023.106196},
  journal      = {Computers &amp; Operations Research},
  pages        = {106196},
  shortjournal = {Comput. Oper. Res.},
  title        = {Tight lower bounds for the traveling salesman problem with draft limits},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized nash equilibrium models for asymmetric,
non-cooperative games on line graphs: Application to water resource
systems. <em>COR</em>, <em>154</em>, 106194. (<a
href="https://doi.org/10.1016/j.cor.2023.106194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the game theory of resource-allocation situations where the “first come, first serve” heuristic creates inequitable, asymmetric benefits to the players. Specifically, this problem is formulated as a Generalized Nash Equilibrium Model where the players are arranged sequentially along a directed line graph. The goal of the model is to reduce the asymmetric benefits among the players using a policy instrument. It serves as a more realistic, alternative approach to the line-graph models considered in the cooperative game-theoretic literature. An application-oriented formulation is also developed for water resource systems. The players in this model are utilities who withdraw water and are arranged along a river basin from upstream to downstream. This model is applied to a stylized, three-node model as well as a test bed in the Duck River Basin in Tennessee, USA. Based on the results, a non-cooperative, water-release market can be an acceptable policy instrument according to metrics traditionally used in cooperative game theory .},
  archive      = {J_COR},
  author       = {Nathan T. Boyd and Steven A. Gabriel and George Rest and Tom Dumm},
  doi          = {10.1016/j.cor.2023.106194},
  journal      = {Computers &amp; Operations Research},
  pages        = {106194},
  shortjournal = {Comput. Oper. Res.},
  title        = {Generalized nash equilibrium models for asymmetric, non-cooperative games on line graphs: Application to water resource systems},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A customized two-stage parallel computing algorithm for
solving the combined modal split and traffic assignment problem.
<em>COR</em>, <em>154</em>, 106193. (<a
href="https://doi.org/10.1016/j.cor.2023.106193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently solving the traffic assignment problem (TAP) for large-scale transport networks is a critical problem for transportation studies. Most of the existing algorithms for TAP are serial ones based on single-computer mode, which has inherently limited the computational efficiency, compared with parallel computing methods. Thus, this paper aims to propose an efficient distributed multi-computer cluster resource allocation method for the parallel computing of TAP. Previous studies on the parallel computing of TAP are mainly based on a single-mode, which is extended to a more complex combined modal split and traffic assignment (CMSTA) case in this paper. In order to decompose the CMSTA problem, we proposed a block-decomposed model for solving the CMSTA problem. Then we designed an optimal parallel computing resource schedule for solving each block problem more quickly on the huge transportation network. Therefore, we implemented a customized two-stage parallel (TP) algorithm that can fully use parallel resources. The first parallel stage of the TP algorithm is used in the path generation phase, and the second parallel stage is used in the path flow adjustment phase. Besides, the parallel slowdown is uncovered in calculating each block problem of the path flow adjustment phase by using parallel resources. Numerical examples are taken to validate the efficiency and robustness of the proposed TP algorithm.},
  archive      = {J_COR},
  author       = {Kai Zhang and Honggang Zhang and Qixiu Cheng and Xinyuan Chen and Zewen Wang and Zhiyuan Liu},
  doi          = {10.1016/j.cor.2023.106193},
  journal      = {Computers &amp; Operations Research},
  pages        = {106193},
  shortjournal = {Comput. Oper. Res.},
  title        = {A customized two-stage parallel computing algorithm for solving the combined modal split and traffic assignment problem},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flowshop with additional resources during setups:
Mathematical models and a GRASP algorithm. <em>COR</em>, <em>154</em>,
106192. (<a href="https://doi.org/10.1016/j.cor.2023.106192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine scheduling problems arise in many production processes, and are something that needs to be consider when optimizing the supply chain . Among them, flowshop scheduling problems happen when a number of jobs have to be sequentially processed by a number of machines. This paper addressees, for the first time, the Permutation Flowshop Scheduling problem with additional Resources during Setups (PFSR-S). In this problem, in addition to the standard permutation flowshop constraints, each machine requires a setup between the processing of two consecutive jobs. A number of additional and scarce resources, e.g. operators, are needed to carry out each setup. Two Mixed Integer Linear Programming formulations and an exact algorithm are proposed to solve the PFSR-S. Due to its complexity, these approaches can only solve instances of small size to optimality . Therefore, a GRASP metaheuristic is also proposed which provides solutions for much larger instances. All the methods designed for the PFSR-S in this paper are computationally tested over a benchmark of instances adapted from the literature. The results obtained show that the GRASP metaheuristic finds good quality solutions in short computational times.},
  archive      = {J_COR},
  author       = {Juan C. Yepes-Borrero and Federico Perea and Fulgencia Villa and Eva Vallada},
  doi          = {10.1016/j.cor.2023.106192},
  journal      = {Computers &amp; Operations Research},
  pages        = {106192},
  shortjournal = {Comput. Oper. Res.},
  title        = {Flowshop with additional resources during setups: Mathematical models and a GRASP algorithm},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning augmented approaches for hub location
problems. <em>COR</em>, <em>154</em>, 106188. (<a
href="https://doi.org/10.1016/j.cor.2023.106188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hub location problems are widely analyzed in fields of logistic and transportation industry for cost reduction. In this paper, a novel algorithm framework based on machine learning is proposed to improve solution quality of hub location problems for large-scale instances. First, a deep-learning based probabilistic hub-ranker (DLHr) is developed to determine the priority of nodes to be selected as hubs. Next, two node-ranking based approaches DL-CBS and DL-GVNS are developed to augment the DLHr for single allocation hub location problems. DL-CBS is an augment algorithm embedding DLHr-ranking into clustering-based potential hub sets algorithm (CBS) while DL-GVNS embeds DLHr-ranking into general variable neighborhood search (GVNS). The numerical results evidence that DLHr outperforms baselines on the node-ranking task and helps to identify potential hubs. Evaluation on a wide range of experiments shows that DL-CBS and DL-GVNS improve solution quality of single allocation hub location problems compared with vanilla CBS and GVNS , revealing DLHr ranking helps to boost the performance of traditional heuristics.},
  archive      = {J_COR},
  author       = {Meng Li and Sebastian Wandelt and Kaiquan Cai and Xiaoqian Sun},
  doi          = {10.1016/j.cor.2023.106188},
  journal      = {Computers &amp; Operations Research},
  pages        = {106188},
  shortjournal = {Comput. Oper. Res.},
  title        = {Machine learning augmented approaches for hub location problems},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A three-phase heuristic for the fairness-oriented crew
rostering problem. <em>COR</em>, <em>154</em>, 106186. (<a
href="https://doi.org/10.1016/j.cor.2023.106186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fairness-Oriented Crew Rostering Problem (FCRP) considers the joint optimization of attractiveness and fairness in cyclic crew rostering. Like many problems in scheduling and logistics, the combinatorial complexity of cyclic rostering causes exact methods to fail for large-scale practical instances. In case of the FCRP, this is accentuated by the additionally imposed fairness requirements. Hence, heuristic methods are necessary. We present a three-phase heuristic for the FCRP combining column generation techniques with variable-depth neighborhood search. The heuristic exploits different mathematical formulations to find feasible solutions and to search for improvements. We apply our methodology to practical instances from Netherlands Railways (NS), the main passenger railway operator in the Netherlands Our results show the three-phase heuristic finds good solutions for most instances and outperforms a state-of-the-art commercial solver.},
  archive      = {J_COR},
  author       = {Thomas Breugem and Thomas Schlechte and Christof Schulz and Ralf Borndörfer},
  doi          = {10.1016/j.cor.2023.106186},
  journal      = {Computers &amp; Operations Research},
  pages        = {106186},
  shortjournal = {Comput. Oper. Res.},
  title        = {A three-phase heuristic for the fairness-oriented crew rostering problem},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On clustering and interpreting with rules by means of
mathematical optimization. <em>COR</em>, <em>154</em>, 106180. (<a
href="https://doi.org/10.1016/j.cor.2023.106180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we make Cluster Analysis more interpretable with a new approach that simultaneously allocates individuals to clusters and gives rule-based explanations to each cluster. The traditional homogeneity metric in clustering, namely the sum of the dissimilarities between individuals in the same cluster, is enriched by considering also, for each cluster and its associated explanation, two explainability criteria, namely, the accuracy of the explanation, i.e., how many individuals within the cluster satisfy its explanation, and the distinctiveness of the explanation, i.e., how many individuals outside the cluster satisfy its explanation. Finding the clusters and the explanations optimizing a joint measure of homogeneity, accuracy, and distinctiveness is formulated as a multi-objective Mixed Integer Linear Optimization problem , from which non-dominated solutions are generated. Our approach is tested on real-world datasets.},
  archive      = {J_COR},
  author       = {Emilio Carrizosa and Kseniia Kurishchenko and Alfredo Marín and Dolores Romero Morales},
  doi          = {10.1016/j.cor.2023.106180},
  journal      = {Computers &amp; Operations Research},
  pages        = {106180},
  shortjournal = {Comput. Oper. Res.},
  title        = {On clustering and interpreting with rules by means of mathematical optimization},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic parcel pick-up routing problem with prioritized
customers and constrained capacity via lower-bound-based rollout
approach. <em>COR</em>, <em>154</em>, 106176. (<a
href="https://doi.org/10.1016/j.cor.2023.106176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we address a parcel pick-up routing problem that involves prioritized customers and constrained capacity, in the context of dynamic vehicle routing. The number and locations of potential customers are known in advance, but the sizes of their parcels are stochastic and unknown until their requests reveal. To tackle this problem, we formulate it as a Markov decision process (MDP), where dynamic requests are handled periodically. Specifically, in each stage, if the total size of the dynamic customers’ parcels that have accumulated fits within the vehicle’s remaining capacity, all of the requests are accepted. Otherwise, requests are accepted according to customers’ priorities. Our objective is to minimize the total expected waiting time of customers. However, the multi-dimensional MDP state causes the curse of dimensionality , making the problem challenging to solve. Therefore, we propose a rollout approach to solve the problem. First, unlike traditional rollout-related methods, we derive a lower bound of the post-decision state’s value function and use it to develop a base policy. Second, we apply a post-decision rollout algorithm to determine an online rollout policy that theoretically satisfies the r o l l o u t i m p r o v i n g rolloutimproving property. In our numerical study , we compare our rollout policy with a general value function approximation-based rollout policy and a model-independent greedy method. Our results show that our rollout policy outperforms both of them with a significant advantage, while the latter two methods have ups and downs on both sides.},
  archive      = {J_COR},
  author       = {Yu Wu and Bo Zeng},
  doi          = {10.1016/j.cor.2023.106176},
  journal      = {Computers &amp; Operations Research},
  pages        = {106176},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic parcel pick-up routing problem with prioritized customers and constrained capacity via lower-bound-based rollout approach},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Refined bounds for the non-archimedean ϵ in DEA.
<em>COR</em>, <em>154</em>, 106163. (<a
href="https://doi.org/10.1016/j.cor.2023.106163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by measuring the Pareto–Koopmans efficiency of public service units, we present refined bounds for the crucial non-Archimedean infinitesimal, aka epsilon. In non-parametric efficiency modeling, epsilon plays a key role as a multiplication factor to the sum of input and output slacks in the objective function. However, selecting an appropriate value for epsilon is non-trivial. It has to be sufficiently small to guarantee the envelopment model is bounded (or multiplier model to be feasible), yet large enough to provide managerial insight and not cause computational problems. Furthermore, the appropriate value is context dependent on the input and output metrics, and sensitive to assumptions regarding constant or variable returns-to-scale. Finally, different epsilon values may lead to drastically different ordering of the relative efficiency measures. To guarantee consistent relative order of the evaluated units we provide two refined bounds. The first, positive efficiency measures , serves as a precursor to ensure the obtained Pareto–Koopmans efficiency measures are positive and well-defined. The second and main contribution, robust efficiency measures , ensures the relative efficiency measures are provably consistent. We illustrate our bounds and their implications from an evaluation study of twelve public healthcare centers.},
  archive      = {J_COR},
  author       = {Jafar Sadeghi and Mehmet A. Begen and Fredrik Ødegaard},
  doi          = {10.1016/j.cor.2023.106163},
  journal      = {Computers &amp; Operations Research},
  pages        = {106163},
  shortjournal = {Comput. Oper. Res.},
  title        = {Refined bounds for the non-archimedean ϵ in DEA},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust homecare service capacity planning. <em>COR</em>,
<em>154</em>, 106155. (<a
href="https://doi.org/10.1016/j.cor.2023.106155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a home healthcare planning problem under the demand uncertainty, where the service type (authorization) and capacity are the first-stage decision and the homecare resource allocation is the second-stage decision which adapts to the demand realizations. We model the problem using an adaptive robust optimization technique where we construct a budget uncertainty set of demand using the well-known Mahalanobis Distance . We analyze the impact of the authorization, capacity decisions as well as the budget (robustness level) of the Mahalanobis uncertainty set onto the worst-case revenue. To solve the model, we develop a Benders decomposition algorithm that solves a pair of a mixed-integer second-order cone program (MISOCP) and a mixed integer linear program (MILP) in each iteration, both can be handled by off-the-shelf MIP solvers, with finite-step convergence. We also develop an affine approximation approach that directly solves one instance of MISOCP. Finally, sufficient numerical studies demonstrate the effectiveness of our model and the solution approaches.},
  archive      = {J_COR},
  author       = {Weiping Xie and Tianqi Liu and Xiang Li and Chenyang Zheng},
  doi          = {10.1016/j.cor.2023.106155},
  journal      = {Computers &amp; Operations Research},
  pages        = {106155},
  shortjournal = {Comput. Oper. Res.},
  title        = {Robust homecare service capacity planning},
  volume       = {154},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Branch-and-price algorithms for large-scale mission-oriented
maintenance planning problems. <em>COR</em>, <em>153</em>, 106191. (<a
href="https://doi.org/10.1016/j.cor.2023.106191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel column-generation-based approach for solving large-scale instances of the joint selective maintenance and repairperson assignment problem (JSM-RAP) for mission-oriented systems in industrial settings. Such systems perform consecutive missions separated by scheduled finite-duration breaks during which some of their components are imperfectly maintained by repairpersons, aiming to maximize system reliability in subsequent missions. The resulting mathematical model is computationally expensive, even for problems of moderate size. The proposed approach decomposes the JSM-RAP into a master problem and multiple subproblems that are solved to generate maintenance patterns, i.e., columns. Two methods are developed to handle the mixed-integer nonlinear subproblems : a piecewise-linear approximation and an exact reformulation into mixed-integer exponential conic programs. Branch-and-price algorithms are developed by embedding the column-generation method into a branch-and-bound tree to restore solution integrality and guarantee its optimality . Furthermore, we use a stabilization scheme to accelerate convergence. Numerical experiments validate the proposed approach and demonstrate its added value in terms of computation time and solution quality. Problem instances of very-large size, similar to real-life industrial production plants, are solved efficiently. Results also show that increasing the number of maintenance levels grants more flexibility to the optimizer to find combinations of components and maintenance actions that better use the limited resources.},
  archive      = {J_COR},
  author       = {Hamzea Al-Jabouri and Ahmed Saif and Claver Diallo and Abdelhakim Khatab},
  doi          = {10.1016/j.cor.2023.106191},
  journal      = {Computers &amp; Operations Research},
  pages        = {106191},
  shortjournal = {Comput. Oper. Res.},
  title        = {Branch-and-price algorithms for large-scale mission-oriented maintenance planning problems},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of decentralized optimization focused on
information flows of decomposition algorithms. <em>COR</em>,
<em>153</em>, 106190. (<a
href="https://doi.org/10.1016/j.cor.2023.106190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized decision-making can be represented as a connected decision network of agents collaboratively optimizing their local objective functions over common coupling constraints. In this setting, solving large-scale mathematical programming centrally is undesirable or impossible because the data storage and decision authority are already decentralized, the communication bandwidth for information exchange is limited, and privacy concerns with information may exist. We introduce a taxonomy of mathematical programming-based decentralized optimization problems and decentralized algorithms based on the degree of information sharing, information exchange and existence of a central coordinator. We synthesize the literature and identify the shortcomings of a decentralized algorithm, the trends, and the potential research directions based on the proposed taxonomy.},
  archive      = {J_COR},
  author       = {In-Jae Jeong},
  doi          = {10.1016/j.cor.2023.106190},
  journal      = {Computers &amp; Operations Research},
  pages        = {106190},
  shortjournal = {Comput. Oper. Res.},
  title        = {A review of decentralized optimization focused on information flows of decomposition algorithms},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Metaheuristics with variable diversity control and
neighborhood search for the heterogeneous site-dependent multi-depot
multi-trip periodic vehicle routing problem. <em>COR</em>, <em>153</em>,
106189. (<a href="https://doi.org/10.1016/j.cor.2023.106189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The planning of vehicle routes is a major issue involved in supply chains . In real environment, we can find situations involving a very large number of clients or constraints which indicate that exact methods should be avoided. In this context, this paper presents two metaheuristcs which are used to solve a complex problem named the Heterogeneous Site-Dependent Multi-depot Multi-trip Periodic Vehicle Routing Problem (HSDMDMTPVRP). The HSDMDMTPVRP is a real problem found in the automotive industry and considers several well-known Vehicle Routing Problems (VRP). The first metaheuristic is an adaptation of the Unified Hybrid Genetic Search (UHGS) which considers an advanced diversity control, feasibility control and a restart mechanism. The second one is a new metaheuristic named Adaptive Variable Neighborhood Race (AVNR) which combines variable neighborhood search and adaptive mechanisms integrated with a shrinking population managed with a diversity mechanism. Both approaches are also used for solving some variants of the VRP: Heterogeneous VRP, Site dependent VRP, Periodic VRP and Multi-trip VRP. Our computational experiments used 398 available instances in the literature with generic code path and also present 20 new instances for the HSDMDMTPVRP. The metaheuristics solved all instances with only one set of parameters and the results outperform or present the same solutions found by several state-of-the-art algorithms, showing the good performance of the approaches. Out of the 398 previously tested literature instances, the proposed metaheuristics found 140 new best-known solutions and 209 of the best-known ones. For the remaining instances, both approaches found results very close to best ones known.},
  archive      = {J_COR},
  author       = {Bruno Salezze Vieira and Glaydston Mattos Ribeiro and Laura Bahiense},
  doi          = {10.1016/j.cor.2023.106189},
  journal      = {Computers &amp; Operations Research},
  pages        = {106189},
  shortjournal = {Comput. Oper. Res.},
  title        = {Metaheuristics with variable diversity control and neighborhood search for the heterogeneous site-dependent multi-depot multi-trip periodic vehicle routing problem},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On solving simplified diversified top-k s-plex problem.
<em>COR</em>, <em>153</em>, 106187. (<a
href="https://doi.org/10.1016/j.cor.2023.106187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding cohesive groups in a graph, which has been extensively studied by many researchers, is a fundamental and critical problem for various real-world applications, such as community search, motif discovery and anomaly detection . Unfortunately, the cohesive groups rarely appear as cliques and are usually highly overlapping, so few cohesive groups can be found by searching maximum or top- k k maximal cliques . In other words, maximum or top- k k maximal cliques are too strict for representing cohesive groups. To handle this problem, the DTKSP problem was introduced earlier in the literature to find k k maximal s s -plexes that cover maximum vertices with the lowest overlapping in a given graph. In this paper, we consider the Simplified Diversified Top- k k s s -Plex (S-DTKSP) problem, by aiming to find k k maximal s s -plexes that cover the maximum vertices without considering the size of overlap. We prove that the S-DTKSP problem is NP-hard and propose an integer linear programming for S-DTKSP problem. Then, we propose an iterated local search (ILS) algorithm with a tabu strategy to efficiently find a good solution. The proposed algorithms are evaluated on large real-world instances. The experimental results demonstrate that our approaches can solve the S-DTKSP problem effectively and efficiently than two baseline algorithms.},
  archive      = {J_COR},
  author       = {Jun Wu and Chu-Min Li and Luzhi Wang and Shuli Hu and Peng Zhao and Minghao Yin},
  doi          = {10.1016/j.cor.2023.106187},
  journal      = {Computers &amp; Operations Research},
  pages        = {106187},
  shortjournal = {Comput. Oper. Res.},
  title        = {On solving simplified diversified top-k s-plex problem},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tabu search for proactive project scheduling problem with
flexible resources. <em>COR</em>, <em>153</em>, 106185. (<a
href="https://doi.org/10.1016/j.cor.2023.106185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a proactive resource-constrained project scheduling problem where resources have several skills and can switch the selected skill at discrete time instants. The objective of this paper is to simultaneously determine the starting times of activities and select the skills of resources to maximize the schedule robustness, while satisfying constraints of precedence, renewable resources and a project deadline. After defining the problem, an integer linear programming model is constructed and the studied problem is proven to be NP-hard. Considering the NP-hardness of the problem, we develop a tabu search embedded with two special algorithms to solve the problem. Based on the characteristics of the problem, a resource allocation algorithm for determining the skill for resources is proposed. The two special algorithms are regarded as two improvement measures to combine with the basic tabu search, leading to three versions of the tabu search, i.e., TS, TS-IM1, and TS-IM12. A commercial mathematical programming solver, which can optimally solve the model, is used as a benchmark for comparing the developed algorithm. Through a computational experiment performed on a randomly generated dataset, the effectiveness of the designed algorithms and the two improvement measures is verified, and the results for single-skilled resources as well as the skill switching of flexible resources are discussed. In addition, the effects of the key parameters on the objective function are also analysed. From the computational results, we can draw several conclusions. First, among the three developed algorithms, TS-IM12, which is the tabu search embedded with two improvement measures, performs best, and compared with the commercial software, TS-IM12 shows a higher efficiency in solving the studied problem. Second, the increase in the resource flexibility should be moderate. Third, the robustness of the baseline schedule increases with an increase of the resource flexibility, the resource availability and the project deadline. Finally, the improvement of the schedule robustness brought by the increase of the resource flexibility or the resource availability will be further magnified as the project deadline extends, while the improvement of the schedule robustness caused by the increase of the resource flexibility will be reduced as the resource availability augments.},
  archive      = {J_COR},
  author       = {Yong Ma and Zhengwen He and Nengmin Wang and Erik Demeulemeester},
  doi          = {10.1016/j.cor.2023.106185},
  journal      = {Computers &amp; Operations Research},
  pages        = {106185},
  shortjournal = {Comput. Oper. Res.},
  title        = {Tabu search for proactive project scheduling problem with flexible resources},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The road train optimization problem with load assignment.
<em>COR</em>, <em>153</em>, 106184. (<a
href="https://doi.org/10.1016/j.cor.2023.106184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the road train optimization problem with load assignments (RTOP–LA). The RTOP–LA deals with assigning customers’ demands to trailers delivered via regular trucks or road trains and determining the routing of these trucks through final customers. Road trains leave the origin terminal to reach intermediate ones, where the trailers can later be dismantled and sent to customers by regular trucks. We formulate the problem to minimize the total cost. A commercial solver is used to solve small-size instances of the problem, and we develop a multi-start iterated local search (MS-ILS) algorithm to obtain high-quality solutions. The results of our experiments show that MS-ILS provides optimal solutions for most instances. For small size instances MS-ILS outperforms the commercial solver, but its performance becomes more evident when the number of customers increases. Moreover, MS-ILS provides excellent solutions for larger instances in short computation times. Finally, a slightly adapted version of our algorithm has been proved efficient to solve the single truck and trailer routing problem . Compared to state-of-the-art algorithms on a set of 32 instances, our adapted algorithm obtained five new best known solutions.},
  archive      = {J_COR},
  author       = {Eliseu J. Araújo and Maryam Darvish and Jacques Renaud},
  doi          = {10.1016/j.cor.2023.106184},
  journal      = {Computers &amp; Operations Research},
  pages        = {106184},
  shortjournal = {Comput. Oper. Res.},
  title        = {The road train optimization problem with load assignment},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective upper and lower bounds for a two-stage reentrant
flexible flow shop scheduling problem. <em>COR</em>, <em>153</em>,
106183. (<a href="https://doi.org/10.1016/j.cor.2023.106183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flow shop scheduling is important in modern industrial manufacturing to improve production efficiency. This paper studies a realistic two-stage reentrant flexible flow shop scheduling problem (TSRFFS) with broad applications in aircraft scheduling, manufacturing, and the medical industry, etc. Given a flow shop with a single machine in Stage 1, a set of parallel machines in Stage 2, and a set of jobs to be processed, the TSRFFS aims to determine the completion time of jobs in Stage 1 and then that in Stage 2, and finally returns to Stage 1, as well as determine the job-to-machine assignment in Stage 2 such that all jobs are served and the total processing time of jobs (makespan) is minimized. The optimal solution properties are investigated, based on which a mixed integer programming mathematical model and a greedy random constructive heuristic for near optimal solutions are proposed. By solving series of a revised parallel machine scheduling problem (P m ||C max ), a lower bound method is developed. Extensive numerical experiments on 1560 random instances with up to 1000 jobs and 50 realistic airport simulation instances were conducted to demonstrate the effectiveness of the proposed algorithms. The average gap between the proposed upper bound and the best lower bounds is approximately 1.78\%, and the average gap between the proposed lower bound and the best upper bounds is 0.91\%, which far outperforms state-of-the-art approaches in terms of solution quality and computational time.},
  archive      = {J_COR},
  author       = {Shuang Zheng and Zhengwen He and Zhen Yang and Chengbin Chu and Nengmin Wang},
  doi          = {10.1016/j.cor.2023.106183},
  journal      = {Computers &amp; Operations Research},
  pages        = {106183},
  shortjournal = {Comput. Oper. Res.},
  title        = {Effective upper and lower bounds for a two-stage reentrant flexible flow shop scheduling problem},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic forestry planning under market and growth
uncertainty. <em>COR</em>, <em>153</em>, 106182. (<a
href="https://doi.org/10.1016/j.cor.2023.106182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The forest planning problem with road construction consists of managing the timber production of a forest divided into harvest cells for a given planning horizon. Subject to uncertainty, it becomes a complex large-scale multi-stage stochastic problem expressed through scenarios. A suitable algorithm for these problems is progressive hedging (PH), which decomposes the problem by scenarios. A two-phase solving approach, in which PH is used as a heuristic method to obtain a directly optimized restricted model with fixed variables, is implemented. Multiple adjustments to improve the performance of the method are adopted and tested in a tactical case study. The performance of the proposed method is compared with those of traditional approaches. Thanks to these enhancements, we solved a real original problem including all the complexities of a practical problem not addressed in previous studies. Comprehensive computational results indicate the advantages of the method, including its ability to efficiently solve instances of up to 1000 scenarios by exploiting its parallel implementation.},
  archive      = {J_COR},
  author       = {Cristobal Pais and Andres Weintraub and Zuo-Jun Max Shen},
  doi          = {10.1016/j.cor.2023.106182},
  journal      = {Computers &amp; Operations Research},
  pages        = {106182},
  shortjournal = {Comput. Oper. Res.},
  title        = {Stochastic forestry planning under market and growth uncertainty},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bounds and convex heuristics for bi-objective optimal
experiment design in water networks. <em>COR</em>, <em>153</em>, 106181.
(<a href="https://doi.org/10.1016/j.cor.2023.106181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal Experiment Design for parameter estimation in water networks has been traditionally formulated to maximize either hydraulic model accuracy or spatial coverage. Because a unique sensor configuration that optimizes both objectives may not exist, these approaches inevitably result in sub-optimal configurations with respect to one of the objectives. This paper presents a new bi-objective optimization problem formulation to investigate the trade-offs between these conflicting objectives. We develop a convex heuristic to approximate the Pareto front, and compute guaranteed bounds to discard portions of the criterion space that do not contain non-dominated solutions. Our method relies on a Chebyshev scalarization scheme and convex optimization . We implement the proposed methods for optimal experiment design in an operational water network from the UK. For this case study, the convex heuristic computes near-optimal solutions for the individual objective minimization problems , and tight bounds on the true Pareto front of the considered bi-objective optimization problem.},
  archive      = {J_COR},
  author       = {Filippo Pecci and Ivan Stoianov},
  doi          = {10.1016/j.cor.2023.106181},
  journal      = {Computers &amp; Operations Research},
  pages        = {106181},
  shortjournal = {Comput. Oper. Res.},
  title        = {Bounds and convex heuristics for bi-objective optimal experiment design in water networks},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bi-objective overlapped links vehicle routing problem for
risk minimizing valuables transportation. <em>COR</em>, <em>153</em>,
106177. (<a href="https://doi.org/10.1016/j.cor.2023.106177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel variant of the vehicle routing problem (VRP) that considers overlapped links for the transportation of valuables. Maintaining security and minimizing route risks are crucial challenges in the planning and routing of valuable goods whose transport is threatened by risks such as armed robbery and assault. Keeping the transit process secure necessitates, therefore, special planning and routing. A more realistic examination of real-world situations reveals that network routes are not entirely independent and share sections that influence one another. In other words, changing the status of one street section simultaneously affects multiple links. Consequently, a bi-objective overlapped links vehicle routing problem (OLVRP) for valuable goods transportation is developed in this study, where the total cost and risk of routing are minimized. Moreover, a hybrid genetic algorithm is developed to optimize the problem, and its efficiency and effectiveness for small-to-medium and large-scale problems are evaluated. The results demonstrate that the proposed algorithm is superior and highly efficient compared to The non-dominated sorting genetic algorithm II (NSGA-II). Finally, the proposed model is used to conduct a real-world case study on cash distribution in Tehran province, Iran, one of the most widely used types of valuable goods transportation.},
  archive      = {J_COR},
  author       = {Fatemeh Mazdarani and Seyed Farid Ghannadpour and Fatemeh Zandieh},
  doi          = {10.1016/j.cor.2023.106177},
  journal      = {Computers &amp; Operations Research},
  pages        = {106177},
  shortjournal = {Comput. Oper. Res.},
  title        = {Bi-objective overlapped links vehicle routing problem for risk minimizing valuables transportation},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Service expansion for chained business facilities under
congestion and market competition. <em>COR</em>, <em>153</em>, 106175.
(<a href="https://doi.org/10.1016/j.cor.2023.106175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a service expansion problem for chained business facilities under endogenic facility congestion and exogenous market competition. More specifically, we consider a company that operates a chain of facilities and plans to expand service capacities with the objective of maximizing its profit, accounting for revenue and expansion costs. To estimate revenue, the company needs to anticipate customer behaviors. Due to the co-existence of competition and congestion, customer behaviors are explained as a two-stage process. In the first stage, customers make “channel” choices, i.e., they decide whether to seek services from the company. Such a choice reflects the market competition and is predicted by a discrete choice model . Subsequently, customers who select the company will choose one facility to patronize. Owing to congestion, the facility choice will induce “user equilibrium”, which in return affects the outcome of market competition. To facilitate the company’s decision-making in this complex business environment, we develop a generic modeling framework. Unfortunately, the proposed model is nonconvex. To solve it, we first design an approximate mixed-integer linear programming approach subject to adjustable approximation errors. We then propose a surrogate optimization framework for large-scale instances, which explores the hidden bilevel structure of the model and leverages a “learning-to-optimize” problem and a customer behavior estimation subroutine. Using extensive computational experiments, we demonstrate the effectiveness of the proposed approaches. Finally, we conduct sensitivity analysis and draw practical implications.},
  archive      = {J_COR},
  author       = {Yun Hui Lin and Qingyun Tian and Shaojun Liu},
  doi          = {10.1016/j.cor.2023.106175},
  journal      = {Computers &amp; Operations Research},
  pages        = {106175},
  shortjournal = {Comput. Oper. Res.},
  title        = {Service expansion for chained business facilities under congestion and market competition},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exact and metaheuristic approaches to solve the integrated
production scheduling, berth allocation and storage yard allocation
problem. <em>COR</em>, <em>153</em>, 106174. (<a
href="https://doi.org/10.1016/j.cor.2023.106174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies an industrial complex specialized in producing and exporting fertilizers. The integration of the production scheduling, berth allocation, and storage yard allocation decisions is necessary to improve the overall performance of the complex as these problems are interrelated. Exact and metaheuristic approaches are proposed to solve the problem. First, a mixed-integer linear formulation along with a branch-and-cut procedure are proposed. The numerical experiments show that these exact methods solve small-sized instances optimally but fail to provide good quality solutions for industrial-sized instances. Therefore, a multi-start GRASP-ILS is proposed where initial solutions are constructed using a greedy randomized adaptive search procedure (GRASP) and improved using an iterated local search algorithm (ILS). The metaheuristic approach is based on a disjunctive graph representation and additional conditions to respect the storage yard constraints and other operational constraints. The results show that the multi-start GRASP-ILS can be effectively used to solve larger instances of the problem.},
  archive      = {J_COR},
  author       = {Nicolas Cheimanoff and Pierre Féniès and Mohamed Nour Kitri and Nikolay Tchernev},
  doi          = {10.1016/j.cor.2023.106174},
  journal      = {Computers &amp; Operations Research},
  pages        = {106174},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exact and metaheuristic approaches to solve the integrated production scheduling, berth allocation and storage yard allocation problem},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A parallel adaptive memory algorithm for the capacitated
modular hub location problem. <em>COR</em>, <em>153</em>, 106173. (<a
href="https://doi.org/10.1016/j.cor.2023.106173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacitated modular hub location problem is a realistic variant of the popular hub location problem arising from the design of telecommunications networks . Given a set of demand nodes, the problem consists in selecting a subset of nodes to represent hubs and assigning the rest of the nodes to the hub nodes, such that the transportation cost is minimized while satisfying the capacity constraints. The adaptive memory algorithm is a hybrid evolutionary heuristic that uses a central memory to store blocks of solutions. At each iteration, the recombination operator uses these solution blocks to create an offspring solution. In this paper, we present a parallel adaptive memory algorithm for the capacitated modular hub location problem that stores both solution blocks and complete solutions in a shared memory for the creation of an offspring . Other distinguishing features of our proposed algorithm include specially designed recombination and mutation operators for search diversification, an effective tabu search procedure for search intensification, and parallel computing for global optimization. Extensive computational results on three well-known data sets of 170 benchmark instances show that the proposed algorithm competes very favorably with the state-of-the-art heuristics from the literature. In particular, it finds 115 improved best-known solutions (for more than 67\% of the cases). Furthermore, we analyze the key algorithmic components and shed lights on their impact on the proposed algorithm.},
  archive      = {J_COR},
  author       = {Qinghua Wu and Zhe Sun and Una Benlic and Yongliang Lu},
  doi          = {10.1016/j.cor.2023.106173},
  journal      = {Computers &amp; Operations Research},
  pages        = {106173},
  shortjournal = {Comput. Oper. Res.},
  title        = {A parallel adaptive memory algorithm for the capacitated modular hub location problem},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New resource-constrained project scheduling instances for
testing (meta-)heuristic scheduling algorithms. <em>COR</em>,
<em>153</em>, 106165. (<a
href="https://doi.org/10.1016/j.cor.2023.106165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resource-constrained project scheduling problem (RCPSP) is a well-known scheduling problem that has attracted attention since several decades. Despite the rapid progress of exact and (meta-)heuristic procedures, the problem can still not be solved to optimality for many problem instances of relatively small size. Due to the known complexity, many researchers have proposed fast and efficient meta-heuristic solution procedures that can solve the problem to near optimality . Despite the excellent results obtained in the last decades, little is known why some heuristics perform better than others. However, if researchers better understood why some meta-heuristic procedures generate good solutions for some project instances while still falling short for others, this could lead to insights to improve these meta-heuristics, ultimately leading to stronger algorithms and better overall solution quality. In this study, a new hardness indicator is proposed to measure the difficulty of providing near-optimal solutions for meta-heuristic procedures. The new indicator is based on a new concept that uses the σ σ distance metric to describe the solution space of the problem instance, and relies on current knowledge for lower and upper bound calculations for problem instances from five known datasets in the literature. This new indicator, which will be called the σ D σD indicator, will be used not only to measure the hardness of existing project datasets, but also to generate a new benchmark dataset that can be used for future research purposes. The new dataset contains project instances with different values for the σ D σD indicator, and it will be shown that the value of the σ σ distance metric actually describes the difficulty of the project instances through two fast and efficient meta-heuristic procedures from the literature.},
  archive      = {J_COR},
  author       = {José Coelho and Mario Vanhoucke},
  doi          = {10.1016/j.cor.2023.106165},
  journal      = {Computers &amp; Operations Research},
  pages        = {106165},
  shortjournal = {Comput. Oper. Res.},
  title        = {New resource-constrained project scheduling instances for testing (meta-)heuristic scheduling algorithms},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximate condorcet partitioning: Solving large-scale rank
aggregation problems. <em>COR</em>, <em>153</em>, 106164. (<a
href="https://doi.org/10.1016/j.cor.2023.106164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rank aggregation has ubiquitous applications in computer science, operations research , and various other fields. Most attention on this problem has focused on an NP-hard variant known as Kemeny aggregation, for which solution approaches with provable guarantees that can handle difficult high-dimensional instances remain elusive. This work introduces exact and approximate methodologies inspired by the social choice foundations of the problem, namely the Condorcet Criterion. We formalize the concept of the finest-Condorcet partition for rankings that may contain ties and specify its required conditions. We prove that this partition is unique and devise an efficient algorithm to obtain it. To deal with instances where it does not yield many subsets, we propose Approximate Condorcet Partitioning (ACP), with which larger subsets can be further broken down and more easily solved. ACP is a scalable solution technique capable of handling large instances while still providing provable guarantees. Although ACP approximation factors are instance-specific, their values were lower than those offered by all known constant-factor approximation schemes — inexact algorithms whose resulting objective values are guaranteed to be within a specified fixed percent of the optimal objective value — for all 113 instances tested herein (containing up to 2,820 items). What is more, ACP obtained solutions that deviated by at most two percent from the optimal objective function values for a large majority of these instances.},
  archive      = {J_COR},
  author       = {Sina Akbari and Adolfo R. Escobedo},
  doi          = {10.1016/j.cor.2023.106164},
  journal      = {Computers &amp; Operations Research},
  pages        = {106164},
  shortjournal = {Comput. Oper. Res.},
  title        = {Approximate condorcet partitioning: Solving large-scale rank aggregation problems},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal decision-making of mutual fund temporary borrowing
problem via approximate dynamic programming. <em>COR</em>, <em>153</em>,
106162. (<a href="https://doi.org/10.1016/j.cor.2023.106162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporary borrowing is a liquidity risk management tool for mutual fund managers to meet investor redemption demands. We develop a new Markov decision process model to describe the temporary borrowing process, considering the multiple lending channels, the validity period of loans, and the uncertainties of cost, demand, and maximum loan amount simultaneously. An approximate dynamic programming (ADP) algorithm is initiated to solve the cost-minimizing temporary borrowing problem. We construct the value function as a separable approximation and prove the convexity of its components with respect to the available funds in different channels. Moreover, a new value function updating formula, DMAX, is designed to overcome value function overestimation. The proved convexity and the proposed formula contribute to fast and reliable value function estimation. Numerical experiments based on actual business data show that the proposed algorithm can obtain near-optimal decisions in deterministic cases and maintain high robustness in stochastic cases.},
  archive      = {J_COR},
  author       = {Xuyang Luo and Chunyue Song},
  doi          = {10.1016/j.cor.2023.106162},
  journal      = {Computers &amp; Operations Research},
  pages        = {106162},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal decision-making of mutual fund temporary borrowing problem via approximate dynamic programming},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient GRASP solution approach for the prisoner
transportation problem. <em>COR</em>, <em>153</em>, 106161. (<a
href="https://doi.org/10.1016/j.cor.2023.106161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, resources are allocated to the transportation of prisoners to and from services such as hospitals and court proceedings. The optimal allocation of the resources – such as protected vehicles, drivers, and guards – is a complex task that requires significant efforts of human planners. For this reason, a recent paper described the Prisoner Transportation Problem (PTP), that aims to optimize the transportation of convicts between origin–destination pairs within pre-defined time windows. In addition to the similarities with the Vehicle Routing Problem with Time Windows, the PTP presents many additional challenges induced by the use of multi-comparted vehicles and incompatibility constraints, related to the safety of both prisoners and personnel. To efficiently solve the PTP, this paper proposes a GRASP approach, that was tested on a dataset of real-size instances, and the results show significant improvements with respect to the only competing approach proposed in the literature, both in terms of solution quality and computational times required to find them.},
  archive      = {J_COR},
  author       = {Daniele Ferone and Paola Festa and Tommaso Pastore and Mauricio G.C. Resende},
  doi          = {10.1016/j.cor.2023.106161},
  journal      = {Computers &amp; Operations Research},
  pages        = {106161},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficient GRASP solution approach for the prisoner transportation problem},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial optimization of multiple area land acquisition.
<em>COR</em>, <em>153</em>, 106160. (<a
href="https://doi.org/10.1016/j.cor.2023.106160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land acquisition was first posed as an integer programming problem by Wright et al. (1983) . They defined this problem as the selection of spatial planning units that altogether formed a contiguous area of land of desired size while optimizing one or more objectives. One of the key difficulties in solving the land acquisition as an integer program is ensuring spatial contiguity among the land units that are selected. Also recognized is that some application contexts are also concerned with compactness. Over time, a number of model formulations and solution heuristics have been proposed for the case of delineating one contiguous area, as well as extension to identify multiple independent areas. Unfortunately, existing model formulations are either too computationally complex to solve reasonably sized problems or they rely on one or more simplifying assumptions that limit their utility. We introduce a new model formulation for the multiple land acquisition problem that can be solved by exact methods using commercial mixed-integer programming software, and does so without simplifying assumptions. The key element of this new model formulation is that the contiguity constraints are self-contained and complete and can accommodate any interpretation of land unit neighbor (or adjacency) relationships. Overall, this new model can be applied to problems involving tens of thousands of spatial planning units. Application experience for this general model is detailed, addressing delineated area selection for concentrated fuels removal/reduction efforts in order to reduce wildfire risk for the U.S. Forest Service.},
  archive      = {J_COR},
  author       = {Alan T. Murray and Richard L. Church},
  doi          = {10.1016/j.cor.2023.106160},
  journal      = {Computers &amp; Operations Research},
  pages        = {106160},
  shortjournal = {Comput. Oper. Res.},
  title        = {Spatial optimization of multiple area land acquisition},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Formulations and an adaptive large neighborhood search for
just-in-time scheduling of unrelated parallel machines with a common due
window. <em>COR</em>, <em>153</em>, 106159. (<a
href="https://doi.org/10.1016/j.cor.2023.106159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address an unrelated parallel machine scheduling problem inspired by aspects of semiconductor manufacturing and other production systems. The objective is to minimize the total sum of weighted earliness and tardiness penalties when jobs are subject to a common restrictive due window. We conceptualize the problem, present two mixed-integer linear programming (MILP) formulations, and give necessary but not sufficient conditions for an optimal schedule. Since optimal schedules do not necessarily start at time zero, we derive two constructive heuristics coupled with a shift-forward procedure that determines leading idle times based on the elimination of straddling jobs. We propose a novel earliness–tardiness extension of the adaptive large neighborhood search (ET-ALNS) with several ad hoc removal/insertion operators and an embedded procedure to accelerate the calculation of the objective function. We carry out extensive computational experiments on a new set of 600 benchmark instances and compare our methods against two modern solvers with an incorporated warm-start mechanism as well as other state-of-the-art algorithms designed for closely related problems. A careful statistical analysis is conducted and results show that ET-ALNS outperforms the remaining methods by a significant margin.},
  archive      = {J_COR},
  author       = {Gustavo Alencar Rolim and Marcelo Seido Nagano and Bruno de Athayde Prata},
  doi          = {10.1016/j.cor.2023.106159},
  journal      = {Computers &amp; Operations Research},
  pages        = {106159},
  shortjournal = {Comput. Oper. Res.},
  title        = {Formulations and an adaptive large neighborhood search for just-in-time scheduling of unrelated parallel machines with a common due window},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization of the cutting process integrated to the lot
sizing in multi-plant paper production industries. <em>COR</em>,
<em>153</em>, 106157. (<a
href="https://doi.org/10.1016/j.cor.2023.106157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many industrial production and cutting processes have costs associated with setup, production of objects, waste of material in the cutting process, inventory, and transport which can vary according to each plant’s location (factory). The production lot sizing , the planning of cuts, and the transport between plants of a company are interconnected problems that, if optimized in an integrated way, can lead to reduction in total costs. In the literature, such problems are widely addressed independently. Recently, the integrated lot sizing and cutting stock problem has been the subject of several studies. However, none have addressed the integrated problem, which also considers multiple plants. This paper presents an integer linear programming formulation for the integrated lot sizing and cutting stock problem with multiple plants and a solution methodology. The formulation is inspired by a practical situation in the paper-making industry . The developed solution methodology consists of a column generation method and a relax-and-fix with a feasibility heuristic. Computational tests were performed to evaluate the performance of the proposed approach and the solution methodology. The proposed approach presented lower total costs, demonstrating the potential for reducing all considered costs. The applied solution methodology showed satisfactory performance for all the studied instances.},
  archive      = {J_COR},
  author       = {Livia Maria Pierini and Kelly Cristina Poldi},
  doi          = {10.1016/j.cor.2023.106157},
  journal      = {Computers &amp; Operations Research},
  pages        = {106157},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimization of the cutting process integrated to the lot sizing in multi-plant paper production industries},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exact and approximate determination of the pareto front
using minimal correction subsets. <em>COR</em>, <em>153</em>, 106153.
(<a href="https://doi.org/10.1016/j.cor.2023.106153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, it has been shown that the enumeration of Minimal Correction Subsets (MCS) of Boolean formulas allows solving Multi-Objective Boolean Optimization (MOBO) formulations. However, a major drawback of this approach is that most MCSs do not correspond to Pareto-optimal solutions. In fact, one can only know that a given MCS corresponds to a Pareto-optimal solution when all MCSs are enumerated. Moreover, if it is not possible to enumerate all MCSs, then there is no guarantee of the quality of the approximation of the Pareto frontier . This paper extends the state of the art for solving MOBO using MCSs. First, we show that it is possible to use MCS enumeration to solve MOBO problems such that each MCS necessarily corresponds to a Pareto-optimal solution. Additionally, we also propose two new algorithms that can find a ɛ ( 1 + ɛ ) (1+ɛ) -approximation of the Pareto frontier using MCS enumeration. Experimental results in several benchmark sets show that the newly proposed algorithms allow finding better approximations of the Pareto frontier than state-of-the-art algorithms, and with guaranteed approximation ratios.},
  archive      = {J_COR},
  author       = {A. P. Guerreiro and J. Cortes and D. Vanderpooten and C. Bazgan and I. Lynce and V. Manquinho and J.R. Figueira},
  doi          = {10.1016/j.cor.2023.106153},
  journal      = {Computers &amp; Operations Research},
  pages        = {106153},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exact and approximate determination of the pareto front using minimal correction subsets},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A vertex-separator-based integer linear programming
formulation for the partitioned steiner tree problem. <em>COR</em>,
<em>153</em>, 106151. (<a
href="https://doi.org/10.1016/j.cor.2023.106151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected graph G G with a cost function on vertices, a collection of subgraphs of G G such that in each subgraph, there are some distinguished vertices called terminals, the Partitioned Steiner Tree Problem (PSTP) asks for a minimum cost vertex set such that, in each of the given subgraph G i Gi , the graph induced by the vertex set spans the terminal set in G i Gi . The PSTP generalizes the well-known Steiner tree problem and has important applications in computational sustainability, network design, and social network analysis . However, for solving the PSTP, conventional integer programming approaches based on single-commodity flow, multi-commodity flow and subtour elimination integer linear programs , suffer from low computational efficiency due to a substantial number of variables. In this paper, we propose a compact vertex-separator-based integer linear programming formulation with much fewer variables. Enhancing inequalities are also studied for tightening the formulation. We further investigate a branch-and-cut algorithm, a local-branching heuristic algorithm , and a hybrid algorithm combining them. In experiments where both public real-world and synthetic graphs are used, our hybrid algorithm outperforms all conventional approaches, especially for large graphs with more than ten thousand vertices. Further tests also validate the effectiveness of the proposed formulation and enhancing inequalities .},
  archive      = {J_COR},
  author       = {Mengfan Ma and Ziyang Men and André Rossi and Yi Zhou and Mingyu Xiao},
  doi          = {10.1016/j.cor.2023.106151},
  journal      = {Computers &amp; Operations Research},
  pages        = {106151},
  shortjournal = {Comput. Oper. Res.},
  title        = {A vertex-separator-based integer linear programming formulation for the partitioned steiner tree problem},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scenario-dominance to multi-stage stochastic lot-sizing and
knapsack problems. <em>COR</em>, <em>153</em>, 106149. (<a
href="https://doi.org/10.1016/j.cor.2023.106149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents strong scenario dominance cuts for effectively solving the multi-stage stochastic mixed-integer programs (M-SMIPs), specifically focusing on the two most well-known M-SMIPs: stochastic capacitated multi-item lot-sizing (S-MCLSP) and the stochastic dynamic multi-dimensional knapsack (S-MKP) problems. Scenario dominance is characterized by a partial ordering of scenarios based on the pairwise comparisons of random variable realizations in a scenario tree of a stochastic program. In this paper, we study the implications of scenario-dominance relations and inferences obtained by solving scenario sub-problems to drive new strong cutting planes to solve S-MCLSP and S-MKP instances faster. Computational experiments demonstrate that our strong scenario dominance cuts can significantly reduce the solution time for such M-SMIP problems with an average of 0.06\% deviation from the optimal solution. The results with up to 81 random variables for S-MKP show that strong dominance cuts improve the state-of-the-art solver solution of two hours by 0.13\% in five minutes. The proposed framework can also be applied to other scenario-based optimization problems .},
  archive      = {J_COR},
  author       = {İ. Esra Büyüktahtakın},
  doi          = {10.1016/j.cor.2023.106149},
  journal      = {Computers &amp; Operations Research},
  pages        = {106149},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scenario-dominance to multi-stage stochastic lot-sizing and knapsack problems},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simultaneous predictive maintenance and inventory policy in
a continuously monitoring system using simulation optimization.
<em>COR</em>, <em>153</em>, 106146. (<a
href="https://doi.org/10.1016/j.cor.2023.106146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive maintenance (PdM) is a strategy which can help determine the appropriate timing for maintenance depending on the actual operational conditions of a manufacturing system. Many relevant studies have ignored the effects of resource dependency and only considered perfect maintenance to reduce the complexity and uncertainty of maintenance problems. In this study, we develop a novel and highly practical maintenance model to fill the gap. The proposed model simultaneously considers the predictive maintenance and inventory policies of spare parts. In light of the high degree of complexity in modern manufacturing systems and the profound stochasticity in component degradation, a metamodeling-based simulation optimization method is proposed to find the optimal component inventory policy and degradation level thresholds of each component. A numerical study is conducted to verify that the proposed model and solution method can find the optimal or nearly optimal maintenance cost effectively and efficiently. Furthermore, the impact of critical factors in the maintenance model on the optimal policy is analyzed and useful managerial insights are derived.},
  archive      = {J_COR},
  author       = {Yuan-Yuan Liu and Kuo-Hao Chang and You-Ying Chen},
  doi          = {10.1016/j.cor.2023.106146},
  journal      = {Computers &amp; Operations Research},
  pages        = {106146},
  shortjournal = {Comput. Oper. Res.},
  title        = {Simultaneous predictive maintenance and inventory policy in a continuously monitoring system using simulation optimization},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compromise policy for multi-stage stochastic linear
programming: Variance and bias reduction. <em>COR</em>, <em>153</em>,
106132. (<a href="https://doi.org/10.1016/j.cor.2022.106132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on algorithms for multi-stage stochastic linear programming (MSLP). We propose an ensemble method named the “compromise policy”, which not only reduces the variance of the function approximation but also reduces the bias of the estimated optimal value. It provides a tight lower bound estimate with a confidence interval. By exploiting parallel computing , the compromise policy provides demonstrable advantages in performance and stability with marginally extra computational time. We further propose a meta-algorithm to solve the MSLP problems based on in-sample and out-of-sample optimality tests. Our meta-algorithm is incorporated within an SDDP-type algorithm for MSLP and significantly improves the reliability of the decisions suggested by SDDP. These advantages are demonstrated via extensive computations, which illustrate the effectiveness of our approach.},
  archive      = {J_COR},
  author       = {Jiajun Xu and Suvrajeet Sen},
  doi          = {10.1016/j.cor.2022.106132},
  journal      = {Computers &amp; Operations Research},
  pages        = {106132},
  shortjournal = {Comput. Oper. Res.},
  title        = {Compromise policy for multi-stage stochastic linear programming: Variance and bias reduction},
  volume       = {153},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shortest paths with exclusive-disjunction arc pairs
conflicts. <em>COR</em>, <em>152</em>, 106158. (<a
href="https://doi.org/10.1016/j.cor.2023.106158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a NP -hard variant of the shortest path problem , involving exclusive-disjunction arc pairs conflicts, is introduced. In this framework, a conflict is violated and a penalty has to be paid if either both the arcs in a pair or none of them are selected. The aim is to find a path for which the overall cost, defined as the sum of the costs of the traversed arcs and the penalties of the violated conflicts, is minimized. The proposed variant is used to model web applications test planning scenarios, where a path represents a sequence of web pages and hyperlinks. A proof of the NP -hardness is provided and two mathematical programming formulations are proposed for the problem. The former is an integer linear program relying on auxiliary variables to model conflict violations, while the latter is characterized by a nonlinear objective function, that uses only the arc variables to derive the penalties associated to the violated conflicts. To solve the problem, a two-stage matheuristic algorithm is also presented and its performances are compared with those provided by the best formulation solved by CPLEX.},
  archive      = {J_COR},
  author       = {Raffaele Cerulli and Francesca Guerriero and Edoardo Scalzo and Carmine Sorgente},
  doi          = {10.1016/j.cor.2023.106158},
  journal      = {Computers &amp; Operations Research},
  pages        = {106158},
  shortjournal = {Comput. Oper. Res.},
  title        = {Shortest paths with exclusive-disjunction arc pairs conflicts},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logic-based benders decomposition for the preemptive
flexible job-shop scheduling problem. <em>COR</em>, <em>152</em>,
106156. (<a href="https://doi.org/10.1016/j.cor.2023.106156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on exact methods to solve the preemptive flexible job-shop scheduling problem with makespan minimisation objective function. Mathematical and constraint programming models enable the resolution of this problem for small instances. However, as an NP-hard problem, the cost of solving grows rapidly when considering larger instances. In this regard, we propose a logic-based Benders decomposition that relies on an efficient branch-and-bound procedure to solve the subproblem representing a pure (non-flexible) preemptive job-shop scheduling problem. Computational experiments are carried out and show the very good performance of our proposals.},
  archive      = {J_COR},
  author       = {Carla Juvin and Laurent Houssin and Pierre Lopez},
  doi          = {10.1016/j.cor.2023.106156},
  journal      = {Computers &amp; Operations Research},
  pages        = {106156},
  shortjournal = {Comput. Oper. Res.},
  title        = {Logic-based benders decomposition for the preemptive flexible job-shop scheduling problem},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic unsplittable flows with path-change penalties: New
formulations and solution schemes for large instances. <em>COR</em>,
<em>152</em>, 106154. (<a
href="https://doi.org/10.1016/j.cor.2023.106154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider the dynamic unsplittable flow problem. This variation of the unsplittable flow problem has received little attention so far. The unsplittable flow problem is an NP-hard extension of the multi-commodity flow problem where each commodity sends its flow on only one path. In its dynamic version, this problem features several time steps and a penalty is paid when a commodity changes its path from one time step to the next. We present several mixed-integer linear programming formulations for this problem and compare the strength of their linear relaxation. These formulations are embedded in several solvers which are extensively compared on small to large instances. One of these formulations must be solved through a column generation process whose pricing problem is more difficult than those used in classical flow problems. We present limitations of the pricing schemes proposed in earlier works and describe two new schemes with a better worst-case complexity. Overall, this work lays a strong algorithmic baseline for the resolution of the dynamic unsplittable flow problem, proposes original formulations, and discusses the compared advantages of each, thus hopefully contributing a step towards a better understanding of this problem for both OR researchers and practical applications.},
  archive      = {J_COR},
  author       = {François Lamothe and Emmanuel Rachelson and Alain Haït and Cédric Baudoin and Jean-Baptiste Dupé},
  doi          = {10.1016/j.cor.2023.106154},
  journal      = {Computers &amp; Operations Research},
  pages        = {106154},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic unsplittable flows with path-change penalties: New formulations and solution schemes for large instances},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On optimal regression trees to detect critical intervals for
multivariate functional data. <em>COR</em>, <em>152</em>, 106152. (<a
href="https://doi.org/10.1016/j.cor.2023.106152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we tailor optimal randomized regression trees to handle multivariate functional data. A compromise between prediction accuracy and sparsity is sought. Whilst fitting the tree model, the detection of a reduced number of intervals that are critical for prediction, as well as the control of their length, is performed. Local and global sparsities can be modeled through the inclusion of LASSO-type regularization terms over the coefficients associated to functional predictor variables . The resulting optimization problem is formulated as a nonlinear continuous and smooth model with linear constraints . The numerical experience reported shows that our approach is competitive against benchmark procedures, being also able to trade off prediction accuracy and sparsity.},
  archive      = {J_COR},
  author       = {Rafael Blanquero and Emilio Carrizosa and Cristina Molero-Río and Dolores Romero Morales},
  doi          = {10.1016/j.cor.2023.106152},
  journal      = {Computers &amp; Operations Research},
  pages        = {106152},
  shortjournal = {Comput. Oper. Res.},
  title        = {On optimal regression trees to detect critical intervals for multivariate functional data},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wasserstein distributionally robust chance-constrained
program with moment information. <em>COR</em>, <em>152</em>, 106150. (<a
href="https://doi.org/10.1016/j.cor.2023.106150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a distributionally robust joint chance-constrained program with a hybrid ambiguity set including the Wasserstein metric, and moment and bounded support information of uncertain parameters. For the considered mathematical program, the random variables are located in a given support space, so a set of random constraints with a high threshold probability for all the distributions that are within a specified Wasserstein distance from an empirical distribution, and a series of moment constraints have to be simultaneously satisfied. We first demonstrate how to transform the distributionally robust joint chance-constrained program into an equivalent reformulation, and show that such a program with binary variables can be equivalently reformulated as a mixed 0–1 integer conic program. To reduce the computational complexity, we derive a relaxed approximation of the joint DRCCP-H using McCormick envelop relaxation, and introduce linear relaxed and conservative approximations by using norm-based inequalities when the Wasserstein metric uses the l p lp -norm with p ≠ 1 p≠1 and p ≠ ∞ p≠∞ . Finally, we apply this new scheme to address the multi-dimensional knapsack and surgery block allocation problems. The results show that the model with a hybrid ambiguity set yields less conservative solutions when encountering uncertainty over the model with an ambiguity set involving only the Wasserstein metric or moment information, verifying the merit of considering the hybrid ambiguity set, and that the linear approximations significantly reduce the computational time while maintaining high solution quality.},
  archive      = {J_COR},
  author       = {Zunhao Luo and Yunqiang Yin and Dujuan Wang and T.C.E Cheng and Chin-Chia Wu},
  doi          = {10.1016/j.cor.2023.106150},
  journal      = {Computers &amp; Operations Research},
  pages        = {106150},
  shortjournal = {Comput. Oper. Res.},
  title        = {Wasserstein distributionally robust chance-constrained program with moment information},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble framework for causality learning with heterogeneous
directed acyclic graphs through the lens of optimization. <em>COR</em>,
<em>152</em>, 106148. (<a
href="https://doi.org/10.1016/j.cor.2023.106148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed Acyclic Graphs (DAGs) are informative graphical outputs of causal learning algorithms to visualize the causal structure among variables. In practice, different causal learning algorithms are often used to establish a comprehensive analysis pool, which leads to the challenging problem of ensembling the heterogeneous DAGs with diverse and conflicting embedded information. While naive approaches such as MEDIAN and greedy heuristics are presented in the literature, a mathematical framework to build the ensemble DAG is not investigated. Therefore, we propose a two-stage ensemble framework for causality learning with heterogeneous DAGs. In the first stage, we implement a data partitioning procedure to categorize the input data. Then, we apply multiple causal learning algorithms to each class and ensemble the results across the partitions for each method. The results across different approaches in the second stage are then ensembled to produce the final DAG. We define a novel mathematical model based on the marginal contribution concept, reflecting the collective information for each edge from input graphs. We investigate the relationship between the proposed modeling approach and well-known problems such as rank aggregation and the Traveling Salesman Problem . We also present a parametric analysis for the distance function, enriched by insights from their asymptotic behavior . We design a simulation experiment to show the computational advantage of adopting a lazy constraints solution approach. In addition to the T-cell synthetic dataset , we use the dataset of water main breaks from 2017 to 2021 in the City of Tampa, Florida, to demonstrate the framework’s applicability. The results show that the optimal solution of the proposed framework outperforms current approaches in the literature based on causality-based Structural Intervention Distance performance measures.},
  archive      = {J_COR},
  author       = {Babak Aslani and Shima Mohebbi},
  doi          = {10.1016/j.cor.2023.106148},
  journal      = {Computers &amp; Operations Research},
  pages        = {106148},
  shortjournal = {Comput. Oper. Res.},
  title        = {Ensemble framework for causality learning with heterogeneous directed acyclic graphs through the lens of optimization},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous-time formulations for multi-mode project
scheduling. <em>COR</em>, <em>152</em>, 106147. (<a
href="https://doi.org/10.1016/j.cor.2023.106147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reviews compact continuous-time formulations for the multi-mode resource-constrained project scheduling problem. Specifically, we first point out a serious flaw in an existing start-end-event-based formulation owing to inconsistent mode choices. We propose two options to formulate the missing constraints and consider an equivalent reformulation with sparser constraint matrix. Second, we formulate an aggregate variant of an existing model that relies on on-off-events, and we clarify the role of mode consistency issues in such models. Third, we suggest two variants of an existing network flow formulation. We enhance our models by adapting several techniques that have been used previously, e.g., in cases with only a single mode . A large set of benchmark instances from the literature provides the basis for an up-to-date and fair computational study with an out-of-the-box solver package. We compare our models against two models from the literature. Our experiments assert confidently that network flow formulations prevail in the test bed, and they provide a hint on why event-based models become less competitive in multi-mode settings.},
  archive      = {J_COR},
  author       = {David Sayah},
  doi          = {10.1016/j.cor.2023.106147},
  journal      = {Computers &amp; Operations Research},
  pages        = {106147},
  shortjournal = {Comput. Oper. Res.},
  title        = {Continuous-time formulations for multi-mode project scheduling},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A branch-and-price-and-cut algorithm for operating room
scheduling under human resource constraints. <em>COR</em>, <em>152</em>,
106136. (<a href="https://doi.org/10.1016/j.cor.2022.106136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address an integrated operating room planning and scheduling problem that includes, with fine detail, constraints commonly encountered in practice ( i.e. , sequence, capacity and due date constraints) and for human resources other than surgeons, i.e. , nurses. A new model of the sequence-dependent operating room cleaning times that arise because of surgeries with different infection levels is considered. To solve this difficult integrated planning and scheduling problem, we devise a branch-and-price-and-cut algorithm based on the time-indexed formulation of the problem. The basic column generation scheme relies on a label-correcting algorithm that we purposely developed for solving the pricing problems that are modeled as single operating room scheduling problems with time-dependent costs and sequence-dependent cleaning times. The pricing problems are strongly NP-Hard. The efficiency of the label-correcting algorithm is ensured by dominance rules among labels and by two algorithms for computing the upper and lower bound of labels. An effective cutting procedure, inspired by Benders’ decomposition and based on duality theory for linear programming, is developed for tightening the linear relaxation of the problem. With instances from the literature and that we generated, we conduct a numerical study to demonstrate the computational effectiveness of the solution method.},
  archive      = {J_COR},
  author       = {Roberto Bargetto and Thierry Garaix and Xiaolan Xie},
  doi          = {10.1016/j.cor.2022.106136},
  journal      = {Computers &amp; Operations Research},
  pages        = {106136},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-price-and-cut algorithm for operating room scheduling under human resource constraints},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel optimization approach towards improving separability
of clusters. <em>COR</em>, <em>152</em>, 106135. (<a
href="https://doi.org/10.1016/j.cor.2022.106135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective functions in optimization models of the sum-of-squares clustering problem reflect intra-cluster similarity and inter-cluster dissimilarities and in general, optimal values of these functions can be considered as appropriate measures for compactness of clusters. However, the use of the objective function alone may not lead to the finding of separable clusters. To address this shortcoming in existing models for clustering, we develop a new optimization model where the objective function is represented as a sum of two terms reflecting the compactness and separability of clusters. Based on this model we develop a two-phase incremental clustering algorithm . In the first phase, the clustering function is minimized to find compact clusters and in the second phase, a new model is applied to improve the separability of clusters. The Davies–Bouldin cluster validity index is applied as an additional measure to compare the compactness of clusters and silhouette coefficients are used to estimate the separability of clusters. The performance of the proposed algorithm is demonstrated and compared with that of four other algorithms using synthetic and real-world data sets. Numerical results clearly show that in comparison with other algorithms the new algorithm is able to find clusters with better separability and similar compactness.},
  archive      = {J_COR},
  author       = {Adil Bagirov and Najmeh Hoseini-Monjezi and Sona Taheri},
  doi          = {10.1016/j.cor.2022.106135},
  journal      = {Computers &amp; Operations Research},
  pages        = {106135},
  shortjournal = {Comput. Oper. Res.},
  title        = {A novel optimization approach towards improving separability of clusters},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic shop-floor scheduling using real-time information: A
case study from the thermoplastic industry. <em>COR</em>, <em>152</em>,
106134. (<a href="https://doi.org/10.1016/j.cor.2022.106134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practical production planning and scheduling systems must promptly respond to major real-time events and adjust their plans and schedules accordingly. To highlight the importance of concurrency in such systems, this paper addresses the problem of dynamic shop-floor scheduling using real-time information in a case study from the thermoplastic industry . The considered production line is organized as unrelated parallel production cells with a set of identical parallel machines in each cell. Parts are produced in batches using different molds on specific machines. Due to the size and complicated design of the molds, they require extended recovery periods (i.e., maintenance) in case of major failures. Therefore, previously developed plans and schedules need to be revised using real-time information every time a mold’s major failure occurs. The production process is subject to the following constraints: batch processing, safety stocks, dedicated machines, machine-dependent setup times, precedence constraints, mold failures, and real-time updates. The problem is formulated as a mixed-integer programming model to minimize a weighted cost function that includes tardiness and operating costs. To solve the problem, a predictive-reactive scheduling approach is introduced based on a modified simulated annealing (SA) algorithm. The developed approach utilizes an event-driven rescheduling policy. It also embeds a problem-specific neighborhood structure and solution evaluation into the modified SA algorithm. The experimental study indicates that the proposed approach generates better real-life planning and scheduling results than the methods based on dispatching rules. The findings demonstrate that the proposed SA-based predictive-reactive scheduling approach generates the solutions with about a 26.1\% less tardiness cost and a 6.99\% less total weighted cost (on average). In addition, the results also show the competitiveness of the proposed SA-based predictive-reactive scheduling approach compared to two other approaches based on an iterated greedy (IG) algorithm and a Tabu Search (TS) algorithm from the literature.},
  archive      = {J_COR},
  author       = {Mageed Ghaleb and Sharareh Taghipour},
  doi          = {10.1016/j.cor.2022.106134},
  journal      = {Computers &amp; Operations Research},
  pages        = {106134},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic shop-floor scheduling using real-time information: A case study from the thermoplastic industry},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimizing tardiness scheduling measures with generalized
due-dates and a maintenance activity. <em>COR</em>, <em>152</em>,
106133. (<a href="https://doi.org/10.1016/j.cor.2022.106133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study single machine scheduling problems with the following features: ( i i ) Generalized due-dates are considered, i.e., the j j -th due-date is assigned to the j j -th completed job; ( ii ii ) A fixed maintenance activity during which no production is feasible is assumed; ( iii iii ) The objective functions are minimizing various tardiness measures. Specifically, four objective functions are considered: total tardiness, maximum tardiness, the number of tardy jobs and total late work. We introduce pseudo-polynomial solution algorithms for these NP-hard problems. Our numerical tests indicate that instances of medium size of all four problems are solved in very reasonable running times.},
  archive      = {J_COR},
  author       = {Matan Atsmony and Baruch Mor and Gur Mosheiov},
  doi          = {10.1016/j.cor.2022.106133},
  journal      = {Computers &amp; Operations Research},
  pages        = {106133},
  shortjournal = {Comput. Oper. Res.},
  title        = {Minimizing tardiness scheduling measures with generalized due-dates and a maintenance activity},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparing two SVM models through different metrics based on
the confusion matrix. <em>COR</em>, <em>152</em>, 106131. (<a
href="https://doi.org/10.1016/j.cor.2022.106131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support Vector Machines (SVM) are an efficient alternative for supervised classification . In the soft margin SVM model, two different objectives are optimized and the set of alternative solutions represent a Pareto-front of points, each one of them representing a different classifier. The performance of these classifiers can be evaluated and compared through some performance metrics that follow from the confusion matrix . Moreover, when the SVM includes feature selection, the model becomes hard to solve. In this paper, we present an alternative SVM model with feature selection and the performance of the new classifiers is compared to those of the classical soft margin model through some performance metrics based on the confusion matrix: the area under the ROC curve, Cohen’s Kappa coefficient and the F-Score. Both the classical soft margin SVM model with feature selection and our proposal have been implemented by metaheuristics , given the complexity of the models to solve.},
  archive      = {J_COR},
  author       = {Daniel Valero-Carreras and Javier Alcaraz and Mercedes Landete},
  doi          = {10.1016/j.cor.2022.106131},
  journal      = {Computers &amp; Operations Research},
  pages        = {106131},
  shortjournal = {Comput. Oper. Res.},
  title        = {Comparing two SVM models through different metrics based on the confusion matrix},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A chance-constraint optimization model for a multi-echelon
multi-product closed-loop supply chain considering brand diversity: An
accelerated benders decomposition algorithm. <em>COR</em>, <em>152</em>,
106130. (<a href="https://doi.org/10.1016/j.cor.2022.106130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The closed-loop supply chain (CLSC) network design has become one of the most critical issues due to the importance of resource optimization. Moreover, increasing competition in commercial markets leads to the diversity of a brand’s product portfolio to meet the customer’s demand. Hence, this paper develops a multi-period, multi-brand stochastic mixed-integer linear programming (MILP) model with direct and indirect distribution for the proposed CLSC network. Because of the uncertain nature of demand, the uncertainties for new and second-hand product demand are considered. Besides, a chance-constraint optimization (CCO) approach is applied to deal with uncertainty. Moreover, the accelerated Benders decomposition (BD) algorithm is designed to solve the proposed model. Several test problems are created and used to solve the accelerated BD compared with the conventional BD algorithm to investigate this model. Finally, the results are compared and described analytically, and some future research is suggested.},
  archive      = {J_COR},
  author       = {Meysam Borajee and Reza Tavakkoli-Moghaddam and Seyed-Houman Madani-Saatchi},
  doi          = {10.1016/j.cor.2022.106130},
  journal      = {Computers &amp; Operations Research},
  pages        = {106130},
  shortjournal = {Comput. Oper. Res.},
  title        = {A chance-constraint optimization model for a multi-echelon multi-product closed-loop supply chain considering brand diversity: An accelerated benders decomposition algorithm},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A sampling-based matheuristic for the continuous-time
stochastic inventory routing problem with time-windows. <em>COR</em>,
<em>152</em>, 106129. (<a
href="https://doi.org/10.1016/j.cor.2022.106129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers a continuous-time variant of the stochastic inventory routing problem . In most of the articles present in the literature related to inventory routing, customers reveal their demands at the end of each period, which is when the inventory level is calculated. In the variant of the problem at hand, the demand that each customer experiences on each period, results in a continuous decrease of the inventory for the customer during the period. This characteristic strongly affects the quantities that can be delivered to each customer and, if the deliveries are not sufficient or arrive too late, they can cause some stock-out situations within the periods. In the inventory routing problem, the vendor manages all the replenishment decisions of the vendees and, therefore, creates delivery plans for a planning horizon, aiming to reduce the routing, consistency, inventory and lost-sales costs. We formulate the problem as a two-stage mathematical program . Customers experience a continuous stochastic demand within each period and present information about inventory level and capacity at each period, as well as the time windows in which deliveries can take place. To solve this problem, we develop a matheuristic solution approach based on an adaptive large neighborhood search algorithm. In addition, we evaluate the impact of applying recourse actions to deal with expected lost sales during the planning horizon. We compare the performance of the algorithm with adapted variants of the multiple scenario approach and the branch and regret algorithms from the literature. Samples based on the stochastic demands are considered in the algorithms, to find robust solutions that can minimize the objective function. We evaluate the solutions by means of a sample average estimator procedure, and we compare the efficiency of the algorithms as well as the impact of different levels of stochasticity.},
  archive      = {J_COR},
  author       = {Emilio J. Alarcon Ortega and Karl F. Doerner},
  doi          = {10.1016/j.cor.2022.106129},
  journal      = {Computers &amp; Operations Research},
  pages        = {106129},
  shortjournal = {Comput. Oper. Res.},
  title        = {A sampling-based matheuristic for the continuous-time stochastic inventory routing problem with time-windows},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved memetic algorithm for integrated production
scheduling and vehicle routing decisions. <em>COR</em>, <em>152</em>,
106127. (<a href="https://doi.org/10.1016/j.cor.2022.106127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by traditional Chinese medicine decoction and delivery problems in our collaborative Chinese medicine decoction company, this study addresses integrated production scheduling and vehicle routing decisions. To deal with this problem, we first propose a mixed integer linear programming model considering hybrid flow shop production and multi-trip multi-vehicle delivery, which is challenging to solve for medium- and large-size instances. We then propose an improved memetic algorithm (MA) that combines a genetic algorithm (GA) with education operators, including local search procedures. To improve the performance of the MA, we consider the contribution of diversity in the fitness function to enhance the exploratory ability, propose a parent selection operator by considering the softmax function to balance exploitation and exploration, and design three customized crossover operators and five education operators with local search procedures. Numerical experiments show that the integrated scheduling method shortens the total makespan by 11.19\% compared with separated production scheduling and vehicle routing methods. We compare the proposed MA with Gurobi for small-size instances, and with the GA for special cases (single-stage production) for medium- or large-size instances. The results of numerical experiments for 360 instances show that the MA can find solutions with a gap of no more than 2\% from the optimal solution within 3 s for small-size instances, and can improve the solutions of the GA and the adaptive large neighborhood search (ALNS) algorithm by more than 30\% and 10\%.},
  archive      = {J_COR},
  author       = {Feier Qiu and Na Geng and Honggang Wang},
  doi          = {10.1016/j.cor.2022.106127},
  journal      = {Computers &amp; Operations Research},
  pages        = {106127},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved memetic algorithm for integrated production scheduling and vehicle routing decisions},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Home healthcare staff dimensioning problem for temporary
caregivers: A matheuristic solution approach. <em>COR</em>,
<em>152</em>, 106126. (<a
href="https://doi.org/10.1016/j.cor.2022.106126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Staff dimensioning, defined as determining the required numbers of caregivers with different types of skills, is a key decision for home healthcare systems. Home healthcare providers often use a combination of permanent and temporary (casual) caregivers. Determining the required number of temporary caregivers with different skill sets considering uncertainty and routing cost is the main objective of this study. To this end, we propose a two-stage stochastic programming model for the staff dimensioning problem for temporary caregivers, taking into account uncertainties in the required class of service, the required number of visits, and the required service time for each patient. Staff dimensioning decisions are defined in the first stage, and assignment with routing are positioned in the second stage of the model. To solve the problem, a two-phase matheuristic algorithm is developed where an initial solution is generated in the first phase by using an intermediate mathematical model and solving a series of Traveling Salesman Problems (TSPs), then a fix-and-optimize strategy is developed in the second phase to improve the obtained solution. The efficiency of the proposed matheuristic algorithm is examined by various test problems. The results highlight that the proposed model and solution method can be used by HHC providers to effectively utilize the option of recruitment of temporary caregivers in their resource planning considering inevitable uncertain parameters.},
  archive      = {J_COR},
  author       = {Erfaneh Nikzad and Mahdi Bashiri and Babak Abbasi},
  doi          = {10.1016/j.cor.2022.106126},
  journal      = {Computers &amp; Operations Research},
  pages        = {106126},
  shortjournal = {Comput. Oper. Res.},
  title        = {Home healthcare staff dimensioning problem for temporary caregivers: A matheuristic solution approach},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A neural network approach to performance analysis of tandem
lines: The value of analytical knowledge. <em>COR</em>, <em>152</em>,
106124. (<a href="https://doi.org/10.1016/j.cor.2022.106124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a neural network (NN) metamodeller for efficiently approximating the throughput of different finite-buffer multi-server tandem lines (with varying service rates, number of stations, buffers, and servers). The resulting NN serves as a quick performance evaluation tool and is subsequently used for optimising the tandem-line layout. Specifically, we discuss the optimal allocation of buffer places and optimising service rates where service rates at machines are associated with costs. Our NN metamodelling approach is new as we integrate (biased) analytical queuing knowledge into the training data. The setup and training of the NN metamodeller are discussed in the paper. In particular, we discuss the integration of analytical results from queuing theory . Our numerical studies corroborate the common belief that adding analytical knowledge (in this case from queueing theory) significantly improves the ensuing NN’s prediction power. The framework developed in this paper demonstrates how analytical system knowledge can be integrated with data science in performance evaluation and optimisation. Our message is that even basic NNs, combined with formulae available from OR theory, offer invaluable improvements for building metamodellers in simulation optimisation.},
  archive      = {J_COR},
  author       = {N.A. Dieleman and J. Berkhout and B. Heidergott},
  doi          = {10.1016/j.cor.2022.106124},
  journal      = {Computers &amp; Operations Research},
  pages        = {106124},
  shortjournal = {Comput. Oper. Res.},
  title        = {A neural network approach to performance analysis of tandem lines: The value of analytical knowledge},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The vehicle routing problem with drones and drone speed
selection. <em>COR</em>, <em>152</em>, 106112. (<a
href="https://doi.org/10.1016/j.cor.2022.106112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint parcel delivery by trucks and drones has enjoyed significant attention for some time, as the advantages of one delivery method offset the disadvantages of the other. This paper focuses on the vehicle routing problem with drones and drone speed selection (VRPD-DSS), which considers speed-dependent energy consumption and drone-charging in detail. For this purpose, we formulate a comprehensive mixed-integer problem that aims to minimize the operational costs consisting of fuel consumption costs of the trucks, labor costs for the drivers, and energy costs of the drones. The speed at which a drone performs a flight must be selected from a discrete set. We introduce preprocessing steps to eliminate dominated speeds for a flight to reduce the problem size and use valid inequalities to accelerate the solution process. The consideration of speed-dependent energy consumption leads to the fact that it is advisable to perform different flights at different speeds and not to consistently operate a drone at maximum speed. Instead, drone speed should be selected to balance drone range and speed of delivery. Our extensive computational study of a rural real-world setting shows that, by modeling energy consumption realistically, the savings in operational costs compared to truck-only delivery are significant but smaller than those identified in previously published work. Our analysis further reveals that the greatest savings stem from the fact that overall delivery time decreases compared to truck-only delivery, allowing costly truck-driver time to be reduced. The additional energy costs of the drone, however, are largely negligible.},
  archive      = {J_COR},
  author       = {Felix Tamke and Udo Buscher},
  doi          = {10.1016/j.cor.2022.106112},
  journal      = {Computers &amp; Operations Research},
  pages        = {106112},
  shortjournal = {Comput. Oper. Res.},
  title        = {The vehicle routing problem with drones and drone speed selection},
  volume       = {152},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing a multi-echelon location-inventory problem with
joint replenishment: A lipschitz ϵ-optimal approach using lagrangian
relaxation. <em>COR</em>, <em>151</em>, 106128. (<a
href="https://doi.org/10.1016/j.cor.2022.106128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a supply network design problem for cross-border e-commerce. The supply chain consists of suppliers, regional distribution centers, and distribution centers. Our goal is to determine simultaneously location decisions of regional distribution centers, and the inventory decisions for coordinated replenishment and delivery. We formulate this problem as a mixed-integer non-linear program, and develop a Lipschitz optimization algorithm and an iterative heuristic to solve it. Moreover, we propose a tight lower bound via constructing a dual problem. Computational results show that both the Lipschitz optimization method and the heuristic can produce a near-optimal solution with a gap below 1\%. Finally, we analyze the influence of integrated decision making and capacity constraints. An interesting finding is that the capacity of regional distribution centers has a critical influence, while the capacity of distribution centers is trivial. Integrated decision making can achieve remarkable cost savings only if the capacity constraints of regional distribution centers are loose. Nevertheless, capacity constraints of distribution centers make almost no impact. This result can be a good guide for a company’s investment plan: one should give top priority to regional distribution centers, and give only low priority to distribution centers.},
  archive      = {J_COR},
  author       = {Lin Wang and Sirui Wang and Yeming Gong and Lu Peng},
  doi          = {10.1016/j.cor.2022.106128},
  journal      = {Computers &amp; Operations Research},
  pages        = {106128},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing a multi-echelon location-inventory problem with joint replenishment: A lipschitz ϵ-optimal approach using lagrangian relaxation},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A solution technique for capacitated two-level hierarchical
time minimization transportation problem. <em>COR</em>, <em>151</em>,
106125. (<a href="https://doi.org/10.1016/j.cor.2022.106125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a generalization of two-level hierarchical time minimization transportation problem (2HTMTP), capacitated two-level hierarchical time minimization transportation problem (C2HTMTP) is a vital issue due to the route shipping capacity finiteness in reality, and no research report on C2HTMTP is available owing to the intractability. Only 4 approaches with defects are available in the literature to resolve 2HTMTP, and they cannot be applied directly to C2HTMTP although their generalized versions can. In this paper, by creating mathematical model along with auxiliary models and constructing network with lower and upper arc capacities, C2HTMTP is transformed into a collection of searching feasible flow in the constructed network, and consequently 4 iteration algorithms, with two respectively derived from other two by applying binary search, are developed as C2HTMTP’s solution method basing feasible flow algorithm. It is proved that the 4 iteration algorithms find C2HTMTP’s optimum solution in a polynomial computation time. Because of sufficiently exploiting C2HTMTP’s intrinsic network flow structure, the 4 iteration algorithms hold the merits such as no memory overflow, easier implementation on computer, higher computation efficiency, and easier extension to the capacitated multilevel hierarchical time minimization transportation problem with level exceeding two, and successfully overcome the deficiencies of extant solving approaches to 2HTMTP. Computational experiments validate that as compared to extant best solving method for 2HTMTP, the 4 iteration algorithms are robust and efficient C2HTMTP’s solution method able to serve as a powerful tool to solve other related complex optimization problems , where in terms of computation time, when applied to solve 2HTMTP, three algorithms vastly outperform (even the worst performing one rivals) extant best solving approach to 2HTMTP, especially when applied to solve C2HTMTP, two fast descent algorithms are rivals ranking first and second (one performs better for small and medium scale instances, another performs better for large scale instances), and significantly outperform the ranking third algorithm with rival as extant best 2HTMTP’s solving algorithm’s generalized version and great superiority to the ranking last algorithm.},
  archive      = {J_COR},
  author       = {Hui Ding and Fanrong Xie},
  doi          = {10.1016/j.cor.2022.106125},
  journal      = {Computers &amp; Operations Research},
  pages        = {106125},
  shortjournal = {Comput. Oper. Res.},
  title        = {A solution technique for capacitated two-level hierarchical time minimization transportation problem},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization of two-echelon last-mile delivery via cargo
tunnel and a delivery person. <em>COR</em>, <em>151</em>, 106123. (<a
href="https://doi.org/10.1016/j.cor.2022.106123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More and more people live in urban areas in general and in “megacities”, with 10 million inhabitants and more, in particular. One innovative instrument to reduce surface traffic and its negative impact on health, congestion, environment, and safety when supplying these urban inhabitants with goods is a cargo tunnel. Within the cargo tunnel concept, autonomous rail-bound, maglev, or automated guided vehicles deliver goods underground toward small inner-city hubs, from where the final leg toward customer homes can be executed with environmentally-friendly vehicles such as cargo bikes or electric vans. In addition to the huge investment costs for tunnel boring, this last-mile delivery option faces a challenging operational problem, which is the synchronization of goods arrivals at a capacity-restricted inner-city hub with the delivery tours. We formulate a basic two-echelon optimization problem that captures all main operational challenges of this synchronization task, derive suitable optimization procedures, and apply them in a computational study. The latter explores the interdependence between tunnel throughput, storage capacity at the hub, and vehicle capacity of the delivery person and their impact on delivery performance. An additional benchmark test with conventional truck-based deliveries shows that the reductions of carbon dioxide emissions promised by a cargo tunnel come for the price of excessive cargo bike traffic, especially if large urban regions are to be serviced from a micro hub.},
  archive      = {J_COR},
  author       = {Nils Boysen and Dirk Briskorn and Johannes Rupp},
  doi          = {10.1016/j.cor.2022.106123},
  journal      = {Computers &amp; Operations Research},
  pages        = {106123},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimization of two-echelon last-mile delivery via cargo tunnel and a delivery person},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-augmented heuristics for scheduling parallel
serial-batch processing machines. <em>COR</em>, <em>151</em>, 106122.
(<a href="https://doi.org/10.1016/j.cor.2022.106122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The addressed machine scheduling problem considers parallel machines with incompatible job families, sequence-dependent setup times, limited batch capacities, and arbitrary sizes combined with the serial-batch processing characteristic (i.e., the processing time of a batch is equal to the sum of processing times of all jobs grouped in a batch). The primary objective is the minimization of the total weighted tardiness, and a subordinate (secondary) objective is the minimization of the flow time. This scheduling problem arises in many production environments like cutting operations (metal-processing industry or garment industry) or in industrial 3D printing. For solving this problem, we propose a new multi-start construction heuristic with controlled batch urgencies. Furthermore, to improve solution efficiency, we use machine learning methods that are appropriate for multi-target regression with dependent outputs (i.e., Neural networks) to minimize the number of starts by predicting the most suitable heuristic parameters. Hereby, different learning aspects and pipeline parameters must be considered. Additionally, we apply a mixed-integer linear program and a local search mechanism with advanced termination criteria for solution improvement. To evaluate the performance of the new heuristic, we use an exhaustive set of small, large, and very large instances (with symmetric Euclidean, asymmetric Euclidean, and arbitrary sequence-dependent setup times) and heuristics from the literature. The results indicate the superiority of the new, learning-augmented heuristics in terms of solution quality and computation times.},
  archive      = {J_COR},
  author       = {Aykut Uzunoglu and Christian Gahm and Stefan Wahl and Axel Tuma},
  doi          = {10.1016/j.cor.2022.106122},
  journal      = {Computers &amp; Operations Research},
  pages        = {106122},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learning-augmented heuristics for scheduling parallel serial-batch processing machines},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iterated dynamic neighborhood search for packing equal
circles on a sphere. <em>COR</em>, <em>151</em>, 106121. (<a
href="https://doi.org/10.1016/j.cor.2022.106121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the equal circle packing problem on a sphere (ECPOS), which consists in packing N N equal non-overlapping circles on a unit sphere such that the radius of circles is maximized. The problem is of great interest in biology, engineering and operations research and thus has a rich research history both from theoretical and computational aspects. We propose from the point of view of computational research an effective iterated dynamic neighborhood search (IDNS) algorithm for the ECPOS problem. The algorithm includes a multiple-stage local optimization method, a general dynamic neighborhood search method and an adjustment method of the minimum distance between the points on the unit sphere. Extensive experiments are conducted with the proposed algorithm on 205 instances commonly used in the literature. Computational results show that the algorithm is highly effective by improving the best-known results for 42 instances and matching the best-known results for other 116 instances, while missing the best-known results for only 5 instances. For the remaining 42 instances, the best-known results are reported for the first time by the IDNS algorithm.},
  archive      = {J_COR},
  author       = {Xiangjing Lai and Dong Yue and Jin-Kao Hao and Fred Glover and Zhipeng Lü},
  doi          = {10.1016/j.cor.2022.106121},
  journal      = {Computers &amp; Operations Research},
  pages        = {106121},
  shortjournal = {Comput. Oper. Res.},
  title        = {Iterated dynamic neighborhood search for packing equal circles on a sphere},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of survivable wireless backhaul networks with
reliability considerations. <em>COR</em>, <em>151</em>, 106120. (<a
href="https://doi.org/10.1016/j.cor.2022.106120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-increasing need for stable, seamless, high-speed connectivity places an enormous burden on the communications infrastructure, comprised of access, backhaul, and core networks. Furthermore, recent advances in access technologies shift the capacity bottleneck towards the newly popularized wireless backhaul network , which is also susceptible to different types of failures. In this paper, a wireless backhaul network design under reliability and survivability constraints is formulated as a mixed integer linear programming (MILP) model to determine the minimum cost bandwidth assignment of wireless links . We developed an accelerated Benders decomposition algorithm to solve this model. Extensive computational experiments show the accuracy of the model proposed to tackle the problem and the efficiency of the solving method, particularly in larger networks.},
  archive      = {J_COR},
  author       = {Mohammad Ali Raayatpanah and Mahdi Kabiri Beheshtkhah and Farshad Eshghi and Manoochehr Kelarestaghi and Napoleão Nepomuceno},
  doi          = {10.1016/j.cor.2022.106120},
  journal      = {Computers &amp; Operations Research},
  pages        = {106120},
  shortjournal = {Comput. Oper. Res.},
  title        = {Design of survivable wireless backhaul networks with reliability considerations},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust optimization for the electric vehicle pickup and
delivery problem with time windows and uncertain demands. <em>COR</em>,
<em>151</em>, 106119. (<a
href="https://doi.org/10.1016/j.cor.2022.106119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, electric vehicles have become a viable option for city logistics to reduce air pollution and operating noise. In this study we consider the pickup and delivery problem with time windows involving battery-powered electric vehicles under demand uncertainly, where the uncertain demands fall within a budget polytope uncertainty set. We develop a two-stage adaptive robust model to find solutions that are insusceptible to a certain number of deviations in demands, where the routing, and the service start times and remaining battery capacities along a route are fixed before the realization of uncertain demands, while the quantities to load and unload along the route are adjustable to the demand scenario. To solve the model, we develop an exact two-phase decomposition method based on column-and-row generation to alleviate the computational difficulty arising from the large number of demand scenario-related variables and constraints, which decomposes the robust model into a master problem comprising only partial demand scenario-related variables and constraints, and an adversarial separation problem that verifies whether there are infeasible demand scenarios for the solution to the master problem. We develop a tailored branch-and-price-and-cut algorithm incorporating various acceleration strategies to solve the master problem, and a dynamic programming algorithm to solve the adversarial separation problem. We also conduct extensive numerical studies to evaluate the performance of the developed algorithm, ascertain the benefits of the robust model over the deterministic model , and analyze the effect of the charge consumption rate of the battery on the optimal solution.},
  archive      = {J_COR},
  author       = {Xiaochang Liu and Dujuan Wang and Yunqiang Yin and T.C.E. Cheng},
  doi          = {10.1016/j.cor.2022.106119},
  journal      = {Computers &amp; Operations Research},
  pages        = {106119},
  shortjournal = {Comput. Oper. Res.},
  title        = {Robust optimization for the electric vehicle pickup and delivery problem with time windows and uncertain demands},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resources synchronization in a full truckload pickup and
delivery problem: An exact approach. <em>COR</em>, <em>151</em>, 106118.
(<a href="https://doi.org/10.1016/j.cor.2022.106118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the Unpaired Full Truckload Pickup and Delivery Problem with Resource Synchronization is modeled and solved, where routes must be determined to transport commodities from pickup to delivery locations by a set of vehicles, subject to timing and resource synchronization constraints, to satisfy demands at minimum cost. Unlike previous works, the use of multiple resources for loading and unloading tasks at each location are considered and appropriately managed through a representation using discrete shifts. An integer linear programming model is proposed to simultaneously solve allocation, routing and resources synchronization optimization problems . In order to improve the model performance for large size instances, diverse reformulations, including additional inequalities and symmetric-breaking constraints, are implemented and tested. Moreover, a heuristic procedure is proposed to provide good initial feasible solutions. The capabilities of the proposed approach are assessed through several examples.},
  archive      = {J_COR},
  author       = {Luciana Melchiori and Graciela Nasini and Jorge M. Montagna and Gabriela Corsano},
  doi          = {10.1016/j.cor.2022.106118},
  journal      = {Computers &amp; Operations Research},
  pages        = {106118},
  shortjournal = {Comput. Oper. Res.},
  title        = {Resources synchronization in a full truckload pickup and delivery problem: An exact approach},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust permutation flow shop total weighted completion time
problem: Solution and application to the oil and gas industry.
<em>COR</em>, <em>151</em>, 106117. (<a
href="https://doi.org/10.1016/j.cor.2022.106117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes exact solution approaches for the m m -machine robust permutation flow shop problem, where operation processing times are uncertain and vary in a given interval. Following the concept of budgeted uncertainty, the objective is to obtain a robust scheduling that minimizes the total weighted completion time of the restricted worst-case scenario, in which only a subset of operation processing times will deviate to worst-case values. We develop several robust counterpart formulations, which can be used to derive optimal solutions for medium-sized problem instances by using a Column-and-Constraint Generation algorithm. The efficacy of the solution methods is validated through experiments on three sets of randomly-generated instances. Finally, a case study for the maintenance schedule of Brazilian oil platforms is presented.},
  archive      = {J_COR},
  author       = {Mario Levorato and David Sotelo and Rosa Figueiredo and Yuri Frota},
  doi          = {10.1016/j.cor.2022.106117},
  journal      = {Computers &amp; Operations Research},
  pages        = {106117},
  shortjournal = {Comput. Oper. Res.},
  title        = {Robust permutation flow shop total weighted completion time problem: Solution and application to the oil and gas industry},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust metro train scheduling integrated with skip-stop
pattern and passenger flow control strategy under uncertain passenger
demands. <em>COR</em>, <em>151</em>, 106116. (<a
href="https://doi.org/10.1016/j.cor.2022.106116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the passenger demands, especially commuters, in the megacities increase dramatically, the congestion problem of metro lines becomes severe and affects passengers’ travel experience. More and more metro stations have adopted passenger flow control measures to ensure operational security or implemented skip-stop patterns to ease transportation pressure. This paper investigates the collaborative optimization problem of timetable scheduling, passenger flow control, and skip-stop pattern on a metro line. A mixed integer nonlinear programming (MINLP) model is proposed to require a performance balance between service level and operation costs. The collaborative optimization model is constructed to optimize the train timetable by determining arrival and departure times with bounded dwell time and running time at intervals. Specifically, time-dependent passenger arrival rates are regarded as uncertain parameters here. The scenario-based robust optimization (SBRO) model with nonlinear constraints is further transformed into a model with linear constraints , which can be directly solved by commercial solvers. Finally, several sets of numerical experiments according to the actual data about the Beijing Changping metro line are performed to demonstrate the validity of the proposed model and method. The optimized train timetable integrated with the skip-stop pattern and passenger flow control strategy can effectively ease the congestion of stations and improve the safety and service quality of the metro system. The tradeoff between solution robustness and model robustness is obtained with critical practical insights.},
  archive      = {J_COR},
  author       = {Yuting Hu and Shukai Li and Yihui Wang and Huimin Zhang and Yun Wei and Lixing Yang},
  doi          = {10.1016/j.cor.2022.106116},
  journal      = {Computers &amp; Operations Research},
  pages        = {106116},
  shortjournal = {Comput. Oper. Res.},
  title        = {Robust metro train scheduling integrated with skip-stop pattern and passenger flow control strategy under uncertain passenger demands},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient sensor placement and online scheduling of bin
collection. <em>COR</em>, <em>151</em>, 106113. (<a
href="https://doi.org/10.1016/j.cor.2022.106113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several spatially distributed tasks can be completed more efficiently by using a combination of better sensing, prediction, and planning. When an agent needs to regularly move to serve different locations, it is necessary to find a compromise solution between the travel cost and the required quality of service. This problem is present in several contexts, namely waste collection, maintenance, and surveillance. This problem is very complex since it includes sensor placement and routing problems that, due to the uncertainty and combinatorial decision making, cannot be solved optimally in an efficient way. In this work, we develop a new efficient algorithm for sensor placement. It takes into account scheduling and route planning to serve distributed locations, considering not only the value of the information provided by each sensor but also the impact on travel efficiency and quality of service. We present examples of sensor placement and route planning in a waste collection environment.},
  archive      = {J_COR},
  author       = {Manuel Lopes and Tânia R.P. Ramos},
  doi          = {10.1016/j.cor.2022.106113},
  journal      = {Computers &amp; Operations Research},
  pages        = {106113},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficient sensor placement and online scheduling of bin collection},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of the quantiles and superquantiles of the
makespan in interval valued activity networks. <em>COR</em>,
<em>151</em>, 106098. (<a
href="https://doi.org/10.1016/j.cor.2022.106098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the evaluation of quantile-based risk measures for the makespan in scheduling problems represented as temporal networks with uncertainties on the activity durations. More specifically, for each activity only the interval for its possible duration values is known in advance to both the scheduler and the risk analyst. Given a feasible schedule, we calculate the quantiles and the superquantiles of the makespan which are of interest as risk indicators in various applications. To this aim we propose and test a set of novel algorithms to determine rapid and accurate numerical estimations based on the calculation of theoretically proven lower and upper bounds . An extensive experimental campaign computationally shows the validity of the proposed methods, and allows to highlight their performances through the comparison with respect to the state-of-the-art algorithms.},
  archive      = {J_COR},
  author       = {Carlo Meloni and Marco Pranzo},
  doi          = {10.1016/j.cor.2022.106098},
  journal      = {Computers &amp; Operations Research},
  pages        = {106098},
  shortjournal = {Comput. Oper. Res.},
  title        = {Evaluation of the quantiles and superquantiles of the makespan in interval valued activity networks},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A branch-and-bound algorithm for the unit-capacity resource
constrained project scheduling problem with transfer times.
<em>COR</em>, <em>151</em>, 106097. (<a
href="https://doi.org/10.1016/j.cor.2022.106097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a project scheduling problem where unit-capacity resources and transfer times are involved, and propose a branch-and-bound algorithm to solve it. In the problem, each resource is unique and the time on transferring resources between activities is nonnegligible. The aim is to find a feasible solution consisting of a vector of activity start times and a resource transfer plan so that the project makespan is minimized. Our branch-and-bound algorithm uses a branching scheme to branch over all eligible activities to be scheduled at each node, and a scheduling method to decide the start time of next activity, which must be feasible and no earlier than the start time of the last scheduled activity. Based on the combination of the branching scheme and the scheduling method, five effective dominance rules are designed to speed up the exploration of the branch-and-bound tree. With the dominance rules, multiple identical solutions at different nodes are avoided and a large number of unpromising nodes are pruned. At each node, two lower bounds are computed, and an upper bound is produced by a heuristic using a series of priority rules. Extensive computational experiments are conducted on the benchmark instances of the problem. The results show that our exact algorithm performs significantly better than solving the existing mathematical models for the problem using either CPLEX or CP Optimizer.},
  archive      = {J_COR},
  author       = {Ying Liu and Shuang Jin and Jing Zhou and Qian Hu},
  doi          = {10.1016/j.cor.2022.106097},
  journal      = {Computers &amp; Operations Research},
  pages        = {106097},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-bound algorithm for the unit-capacity resource constrained project scheduling problem with transfer times},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scheduling quay cranes and shuttle vehicles simultaneously
with limited apron buffer capacity. <em>COR</em>, <em>151</em>, 106096.
(<a href="https://doi.org/10.1016/j.cor.2022.106096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to schedule quay cranes (QCs) and shuttle vehicles (SVs) simultaneously or model them in an integrated scheduling problem is one of the most important problems in operations and management of a container terminal. This paper investigates an integrated QC and SV scheduling problem constrained by apron buffer capacity. In this problem, the decisions to make include the bay-to-QC assignment, the QC-bay sequence, the QC-job sequence, the job-to-SV assignment and the SV-job sequence. First, a mixed-integer linear programming model is formulated for this problem to minimize the makespan. Second, the relationships and interactive variables among the four segments of constraints of the proposed model (i.e., scheduling QCs for vessel bays, sequencing jobs handled by a QC in each bay, scheduling SVs for jobs, apron buffer capacity constraints for each vessel bay) are analyzed to present three rules: vessel block rule, near-to-far rule and full-buffer rule. Finally, a sequential insertion algorithm, a greedy insertion algorithm and an improved genetic algorithm are proposed to solve mid- and large-sized cases for the problem. Numerical experiments show that the algorithms perform well, compared to the off-the-shelf solver. Based on these experiments, managerial implications are discussed for container terminal operations and management.},
  archive      = {J_COR},
  author       = {Yu-Qi Yin and Meisu Zhong and Xin Wen and Ying-En Ge},
  doi          = {10.1016/j.cor.2022.106096},
  journal      = {Computers &amp; Operations Research},
  pages        = {106096},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling quay cranes and shuttle vehicles simultaneously with limited apron buffer capacity},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving non-permutation flow-shop scheduling problem via a
novel deep reinforcement learning approach. <em>COR</em>, <em>151</em>,
106095. (<a href="https://doi.org/10.1016/j.cor.2022.106095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-permutation flow-shop scheduling problem (NPFS) is studied. We model it as a Markov decision process , creating a massive arena for reinforcement learning (RL) algorithms to work. While RL approaches with function approximation generate a significant number of sequences of highly linked states, few studies have examined the connection between the state sequences but merely shuffled their orders. To this end, this paper proposes a novel deep reinforcement learning algorithm, named LSTM-TD(0), to address NPFS. Specifically, we design fifteen state features to represent a production state at each scheduling point and fourteen actions to choose an unprocessed operation on a given machine. This study applies long short-term memory (LSTM) network to capture the intrinsic connection of the state sequences in RL-based scheduling approaches. Moreover, we enhance the LSTM model with the one-step temporal difference (TD(0)) algorithm to select each action impartially in relation to the state value, avoiding the frequent overestimation of action values in Q-learning. The proposed LSTM-TD(0) was trained using two LSTM networks and enhanced by redesigning the reward value. A series of comparative experiments were conducted between simple heuristic rules, metaheuristic rules, general DRL methods, and LSTM-TD(0) using a group of well-known benchmark problems with different scales. Comparative results have confirmed both the superiority and universality of LSTM-TD(0) over its competitors. Scalability tests reveal that our approach can generalize to instances of different sizes without retraining or knowledge transferring.},
  archive      = {J_COR},
  author       = {Zhenyu Wang and Bin Cai and Jun Li and Deheng Yang and Yang Zhao and Huan Xie},
  doi          = {10.1016/j.cor.2022.106095},
  journal      = {Computers &amp; Operations Research},
  pages        = {106095},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving non-permutation flow-shop scheduling problem via a novel deep reinforcement learning approach},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Budget-balanced and strategy-proof auctions for ridesharing.
<em>COR</em>, <em>151</em>, 106094. (<a
href="https://doi.org/10.1016/j.cor.2022.106094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ridesharing services have become widespread, and pricing the rides is a crucial problem for these systems. We propose and analyze a budget-balanced and strategy-proof auction, the Weighted Minimum Surplus (WMS) auction, for the dynamic ridesharing problem with multiple passengers per ride. Under the assumption of downward closed alternatives, we obtain lower bounds for the surplus welfare and surplus profit of the WMS auction. We also propose and analyze a budget-balanced version of the well-known VCG mechanism, the V CG s V CGs . Encouraging experimental results were obtained for both the WMS auction and the V CG s V CGs .},
  archive      = {J_COR},
  author       = {Leonardo Y. Schwarzstein and Rafael C.S. Schouery},
  doi          = {10.1016/j.cor.2022.106094},
  journal      = {Computers &amp; Operations Research},
  pages        = {106094},
  shortjournal = {Comput. Oper. Res.},
  title        = {Budget-balanced and strategy-proof auctions for ridesharing},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The knapsack problem with forfeit sets. <em>COR</em>,
<em>151</em>, 106093. (<a
href="https://doi.org/10.1016/j.cor.2022.106093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a novel extension of the 0/1 Knapsack Problem in which we consider the existence of so-called forfeit sets. A forfeit set is a subset of items of arbitrary cardinality, such that including a number of its elements that exceeds a predefined allowance threshold implies some penalty costs to be paid in the objective function value. A global upper bound on these allowance violations is also considered. We show that the problem generalizes both the Knapsack Problem with conflicts among item pairs and the Knapsack Problem with forfeit pairs, that have been previously introduced in the literature. We present a polynomial subcase by proving the integrality of its LP relaxation polytope and, we introduce three heuristic approaches , namely a constructive greedy, an algorithm based on the recently introduced Carousel Greedy paradigm and a hybrid Memetic/Carousel Greedy algorithm . Finally, we validate the performances for the proposed algorithms on a set of benchmark instances that consider both random and correlated data .},
  archive      = {J_COR},
  author       = {Ciriaco D’Ambrosio and Federica Laureana and Andrea Raiconi and Gaetano Vitale},
  doi          = {10.1016/j.cor.2022.106093},
  journal      = {Computers &amp; Operations Research},
  pages        = {106093},
  shortjournal = {Comput. Oper. Res.},
  title        = {The knapsack problem with forfeit sets},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimizing the sum of completion times on a single machine
with health index and flexible maintenance operations. <em>COR</em>,
<em>151</em>, 106092. (<a
href="https://doi.org/10.1016/j.cor.2022.106092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is motivated by the development of Industry 4.0 and the need to better integrate production and maintenance decisions. Our problem considers a single machine on which jobs of different families are scheduled to minimize the sum of completion times. The machine has a health index which decreases when jobs are processed. To restore the machine health, maintenance operations must be scheduled. Moreover, to be scheduled, each job requires the machine to have a minimum health index which depends on the job family. Two cases are studied: (1) The daily case with a single flexible maintenance operation, and (2) The weekly case with two flexible maintenance operations. The second case is shown to be NP-complete. Two Mixed Integer Linear Programming models are presented for each case. The first model uses “classical” positional variables, while the second model improves the first model by using the notion of master sequence . Different valid inequalities are also proposed. Computational experiments show that the second model is much more efficient than the first model when solved with a standard solver, and the impact of the valid inequalities is discussed.},
  archive      = {J_COR},
  author       = {Louise Penz and Stéphane Dauzère-Pérès and Margaux Nattaf},
  doi          = {10.1016/j.cor.2022.106092},
  journal      = {Computers &amp; Operations Research},
  pages        = {106092},
  shortjournal = {Comput. Oper. Res.},
  title        = {Minimizing the sum of completion times on a single machine with health index and flexible maintenance operations},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative optimization of last-train timetables for
metro network to increase service time for passengers. <em>COR</em>,
<em>151</em>, 106091. (<a
href="https://doi.org/10.1016/j.cor.2022.106091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Last-train timetables are significant in metro systems and directly influence transportation organization efficiency and passenger service levels. This study focuses on the collaborative optimization of last-train timetables for a large-scale metro network. Different from most studies, which often focus on improving the ability of passengers to transfer between different metro lines (transfer accessibility) during the last-train period, or the ability of passengers to reach their destinations after boarding the last train service from the origin station (origin-destination (OD) accessibility), this work aims to optimize the latest time for passengers (LTP) to reach their destinations using the metro services. A mixed-integer linear programming (MILP) model is established to optimize the last-train timetables with maximizing LTPs. For comparison, two MILP models respectively aim at maximizing transfer accessibilities and OD accessibilities, are adopted as benchmarks. An improved genetic algorithm based on Q-learning (QGA) is developed to solve the proposed MILP models for optimizing last-train timetables for a large-scale metro network. The proposed method is validated by optimizing the last-train timetable of the metro network of Chengdu, China. The results indicate that compared with optimizing the transfer and OD accessibilities, optimizing LTPs can consider both single-line and multiple-line passenger benefits, and directly increase their accessibilities and feasible times to use the metro service.},
  archive      = {J_COR},
  author       = {Fangsheng Wang and Ruihua Xu and Xuyang Song and Pengling Wang},
  doi          = {10.1016/j.cor.2022.106091},
  journal      = {Computers &amp; Operations Research},
  pages        = {106091},
  shortjournal = {Comput. Oper. Res.},
  title        = {Collaborative optimization of last-train timetables for metro network to increase service time for passengers},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-objective linear programming model for scheduling
part families and designing a group layout in cellular manufacturing
systems. <em>COR</em>, <em>151</em>, 106090. (<a
href="https://doi.org/10.1016/j.cor.2022.106090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different industries compete to attract customers in different ways. In the field of production, group technology (GT) is defined by identifying and grouping similar parts based on their similarities in design and production. Cellular manufacturing (CM) is an application of GT to reconfigure the factory and job shop design. A manufacturing cell is a group of independent machines with different functions put together to produce a family of parts. Designing a cellular manufacturing system involves three major decisions: cell formation (CF), group layout (GL), and group scheduling (GS). Although these decisions are interrelated and can affect each other, they have been considered separately or sequentially in previous research. In this paper, CF, GL, and GS decisions are considered simultaneously. Accordingly, a multi-objective linear programming (MOLP) model is proposed to optimize weighted completion time, transportation cost, and machine idle time for a multi-product system. Finally, the model will be solved using the ϵ ϵ -constraint method, representing different scales solutions for decision-making. The proposed model is NP-hard. Therefore, a nondominated sorting genetic algorithm II (NSGA-II) is presented to solve it since GAMS software is unable to find optimal solutions for large-scale problems. Besides, to evaluate the performance of NSGA-II, the problem is solved by three metaheuristic algorithms .},
  archive      = {J_COR},
  author       = {Rasool Motahari and Zeinolabedin Alavifar and Abdullah Zareh Andaryan and Maxwell Chipulu and Morteza Saberi},
  doi          = {10.1016/j.cor.2022.106090},
  journal      = {Computers &amp; Operations Research},
  pages        = {106090},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multi-objective linear programming model for scheduling part families and designing a group layout in cellular manufacturing systems},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive large neighbourhood search metaheuristic for
hourly learning activity planning in personalised learning.
<em>COR</em>, <em>151</em>, 106089. (<a
href="https://doi.org/10.1016/j.cor.2022.106089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalised learning offers an alternative method to one-size-fits-all education in schools, and has seen increasing adoption over the past several years. Personalised learning’s focus on learner-driven education requires novel scheduling methods. In this paper we introduce the hourly, learner-driven activity planning problem of personalised learning, and formulate scheduling methods to solve it. We present an integer linear programming model of the problem, but this model does not generate schedules sufficiently quickly for use in practice. To overcome this, we propose an adaptive large neighbourhood search metaheuristic to solve the problem instead. The metaheuristic’s performance is compared against optimal solutions in a large numerical study of 14,400 instances. These instances are representative of secondary education in the Netherlands, and were developed from expert opinions. Solutions on average deviate only 1.6\% from optimal results. Further, our experiments numerically demonstrate the mitigating effects changes to the structure and staffing of secondary education have on the challenges of satisfying learner instruction demands in personalised learning.},
  archive      = {J_COR},
  author       = {Niels A. Wouda and Ayse Aslan and Iris F.A. Vis},
  doi          = {10.1016/j.cor.2022.106089},
  journal      = {Computers &amp; Operations Research},
  pages        = {106089},
  shortjournal = {Comput. Oper. Res.},
  title        = {An adaptive large neighbourhood search metaheuristic for hourly learning activity planning in personalised learning},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partitioning through projections: Strong SDP bounds for
large graph partition problems. <em>COR</em>, <em>151</em>, 106088. (<a
href="https://doi.org/10.1016/j.cor.2022.106088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph partition problem (GPP) aims at clustering the vertex set of a graph into a fixed number of disjoint subsets of given sizes such that the sum of weights of edges joining different sets is minimized. This paper investigates the quality of doubly nonnegative (DNN) relaxations, i.e., relaxations having matrix variables that are both positive semidefinite and nonnegative, strengthened by additional polyhedral cuts for two variations of the GPP: the k k -equipartition and the graph bisection problem. After reducing the size of the relaxations by facial reduction, we solve them by a cutting-plane algorithm that combines an augmented Lagrangian method with Dykstra’s projection algorithm. Since many components of our algorithm are general, the algorithm is suitable for solving various DNN relaxations with a large number of cutting planes. We are the first to show the power of DNN relaxations with additional cutting planes for the GPP on large benchmark instances up to 1,024 vertices. Computational results show impressive improvements in strengthened DNN bounds.},
  archive      = {J_COR},
  author       = {Frank de Meijer and Renata Sotirov and Angelika Wiegele and Shudian Zhao},
  doi          = {10.1016/j.cor.2022.106088},
  journal      = {Computers &amp; Operations Research},
  pages        = {106088},
  shortjournal = {Comput. Oper. Res.},
  title        = {Partitioning through projections: Strong SDP bounds for large graph partition problems},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven robust optimization using deep neural networks.
<em>COR</em>, <em>151</em>, 106087. (<a
href="https://doi.org/10.1016/j.cor.2022.106087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization has been established as a leading methodology to approach decision problems under uncertainty. To derive a robust optimization model, a central ingredient is to identify a suitable model for uncertainty, which is called the uncertainty set. An ongoing challenge in the recent literature is to derive uncertainty sets from given historical data that result in solutions that are robust regarding future scenarios. In this paper we use an unsupervised deep learning method to learn and extract hidden structures and anomalies from data, leading to non-convex uncertainty sets and better robust solutions. We prove that most of the classical uncertainty classes are special cases of our derived sets and that optimizing over them is strongly NP-hard. Nevertheless, we show that the trained neural networks can be integrated into a robust optimization model by formulating the adversarial problem as a convex quadratic mixed-integer program. This allows us to derive robust solutions through an iterative scenario generation process. In our computational experiments, we compare this approach to a similar approach using kernel-based support vector clustering and to other benchmark methods. We find that uncertainty sets derived by the unsupervised deep learning method find a better description of data and lead to robust solutions that often outperform the comparison methods both with respect to objective value and feasibility.},
  archive      = {J_COR},
  author       = {Marc Goerigk and Jannis Kurtz},
  doi          = {10.1016/j.cor.2022.106087},
  journal      = {Computers &amp; Operations Research},
  pages        = {106087},
  shortjournal = {Comput. Oper. Res.},
  title        = {Data-driven robust optimization using deep neural networks},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of a risk-averse objective function for
scheduling surgeries. <em>COR</em>, <em>151</em>, 106086. (<a
href="https://doi.org/10.1016/j.cor.2022.106086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional objective functions for scheduling surgeries, such as maximising utilisation of operating rooms, maximising throughput of surgeries, or minimising cost, can lead to inequitable outcomes for patients in terms of the time waiting for their operation. Using a simple mixed integer program and historical data from a surgical centre we compare two objective functions (a risk neutral and a risk averse objective) intended to reduce the lateness of the latest-performed operations. Further, the effects of other model parameters on the surgical schedules are compared. By applying the model to a case study at a surgical centre, it is demonstrated that, with the appropriate values of the other model parameters, the risk neutral objective can achieve similar schedules to the risk averse objective, and results in problems that are easier to solve.},
  archive      = {J_COR},
  author       = {T. Adams and M. O’Sullivan and C. Walker and K. Wang and L. Boyle},
  doi          = {10.1016/j.cor.2022.106086},
  journal      = {Computers &amp; Operations Research},
  pages        = {106086},
  shortjournal = {Comput. Oper. Res.},
  title        = {Application of a risk-averse objective function for scheduling surgeries},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asymmetric probabilistic minimum-cost hamiltonian cycle
problem considering arc and vertex failures. <em>COR</em>, <em>151</em>,
106084. (<a href="https://doi.org/10.1016/j.cor.2022.106084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the asymmetric probabilistic minimum-cost Hamiltonian cycle problem (APMCHCP) where arcs and vertices in the graph are possible to fail. APMCHCP is a generalization of traditional asymmetric minimum-cost Hamiltonian cycle problem, and it has applications in many emerging areas, such as post-disaster recovery, electronic circuit design, and security maintenance of wireless sensor networks . For each vertex, we define a chance-constraint to guarantee that the probability of arriving at the vertex must be greater than or equal to a given threshold. Four mixed-integer programming (MIP) formulations are proposed for modeling the problem, including two direct formulations and two recursive formulations. A combinatorial branch-and-bound (CBB) algorithm is proposed for solving the APMCHCP, where data preprocessing steps, feasibility rules, and approaches of finding upper and lower bounds are developed. In the numerical experiments, the CBB algorithm is compared with a commercial MIP solver (Gurobi 8.0) on a test-bed of two popular benchmark instance sets. The results show that the proposed CBB algorithm significantly outperforms Gurobi solver in terms of both the size of optimally solved instances and the computing time.},
  archive      = {J_COR},
  author       = {Saeid Rasti and Yiwen Xu},
  doi          = {10.1016/j.cor.2022.106084},
  journal      = {Computers &amp; Operations Research},
  pages        = {106084},
  shortjournal = {Comput. Oper. Res.},
  title        = {Asymmetric probabilistic minimum-cost hamiltonian cycle problem considering arc and vertex failures},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time series modeling and forecasting by mathematical
programming. <em>COR</em>, <em>151</em>, 106079. (<a
href="https://doi.org/10.1016/j.cor.2022.106079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an innovative approach to time-series analysis motivated by a desire to automate autoregressive integrated moving average (ARIMA) modeling and by extension, the process of building a reliable forecast. Our approach relies on optimization modeling and the decomposition of a time series into fixed seasonal effects, autoregressive (AR) terms, moving average (MA) terms, white noise, and any free variation outside of the selected model’s framework. The simultaneous selection of appropriately-lagged terms and estimation of their coefficients is achieved via mathematical programming to minimize normed errors subject to constraints that include a limit on the number of combined AR and MA terms to achieve desired parsimony. An estimator for white noise serves as a stationary reference signal for determining the MA coefficients and is modeled using wavelets, which facilitate the formulation of integer linear constraints. We report the results of numerical testing of this methodology on several real-world datasets and discuss the main implications for research and practice. We find that our models ( i ) achieve one step-ahead forecasting accuracy that outperforms other, widely-used interpretable methodologies, including random forests and gradient boosting models, ( ii ) offer interpretable results, and ( iii ) are computationally tractable.},
  archive      = {J_COR},
  author       = {Bogdan Bichescu and George G. Polak},
  doi          = {10.1016/j.cor.2022.106079},
  journal      = {Computers &amp; Operations Research},
  pages        = {106079},
  shortjournal = {Comput. Oper. Res.},
  title        = {Time series modeling and forecasting by mathematical programming},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dock assignment and truck scheduling problem; consideration
of multiple scenarios with resource allocation constraints.
<em>COR</em>, <em>151</em>, 106074. (<a
href="https://doi.org/10.1016/j.cor.2022.106074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of ‘resource’ plays an important role in the overall efficiency and performance of most cross-docks. The processing time can often be described in terms of the resources allocated to different trucks. Conversely, for a given processing time, different combinations of resources can be prescribed. We study the problem of truck scheduling and dock assignment in the presence of resource constraints. In the absence of a closed-form (or well-defined) linear formulation describing the processing times as a function of resources, expert’ knowledge has been mobilized to enable modelling of the problem as an integer linear model. Two cases are taken into account: In the first one, the expert believes in his/her estimation of the processing time for every truck and only proposes a different combination of resources for his/her estimation, while in the second one the expert proposes a limited number of resource deployment scenarios for serving trucks, each of which has a different combination of resources and different processing times. We propose a novel compact integer programming formulation for the problem, which is particularly designed with an embedded structure that can be exploited in dual decomposition techniques with a remarkably computationally efficient column generation approach in this case. The case in which a scenario with invariant processing time is considered and modelled as a special case of the proposed model. Since a direct application of commercial solvers such as CPLEX to solve instances of this problem is not realistic, we propose a branch-and-price framework and, moreover, several classes of valid inequalities . Our extensive computational experiments confirm that the proposed exact solution framework is very efficient and viable in solving real-size instances of the practice and in a reasonable amount of time.},
  archive      = {J_COR},
  author       = {Rahimeh Neamatian Monemi and Shahin Gelareh},
  doi          = {10.1016/j.cor.2022.106074},
  journal      = {Computers &amp; Operations Research},
  pages        = {106074},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dock assignment and truck scheduling problem; consideration of multiple scenarios with resource allocation constraints},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new formulation and an effective matheuristic for the
airport gate assignment problem. <em>COR</em>, <em>151</em>, 106073. (<a
href="https://doi.org/10.1016/j.cor.2022.106073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers an airport gate assignment problem where a set of aircraft arriving to an airport are assigned to the fixed gates of the airport terminal or to the apron. The aim is to lexicographically minimize the number of aircraft assigned to the apron, and then the total walking distance by passengers. A new mixed integer linear programming formulation and a matheuristic is proposed for the problem. The proposed formulation is based on the idea of flow of passengers and has smaller size compared to the existing formulations in the literature. The proposed matheuristic , which relies on solving a restricted version of the proposed formulation of the problem, is not only easy to implement but is also very effective. A computational study performed on benchmark instances reveals that the proposed formulation and the matheuristic outperform the existing exact and heuristic algorithms in the literature.},
  archive      = {J_COR},
  author       = {Özlem Karsu and Oğuz Solyalı},
  doi          = {10.1016/j.cor.2022.106073},
  journal      = {Computers &amp; Operations Research},
  pages        = {106073},
  shortjournal = {Comput. Oper. Res.},
  title        = {A new formulation and an effective matheuristic for the airport gate assignment problem},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On multivariate randomized classification trees: L0-based
sparsity, VC dimension and decomposition methods. <em>COR</em>,
<em>151</em>, 106058. (<a
href="https://doi.org/10.1016/j.cor.2022.106058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees are widely-used classification and regression models because of their interpretability and good accuracy. Classical methods such as CART are based on greedy approaches but a growing attention has recently been devoted to optimal decision trees. We investigate the nonlinear continuous optimization formulation proposed in Blanquero et al. (2020) for training sparse optimal randomized classification trees. Sparsity is important not only for feature selection but also to improve interpretability . We first consider alternative methods to sparsify such trees based on concave approximations of the l 0 l0 “norm”. Promising results are obtained on 24 datasets in comparison with the original l 1 l1 and l ∞ l∞ regularizations . Then, we derive bounds on the VC dimension of multivariate randomized classification trees. Finally, since training is computationally challenging for large datasets, we propose a general node-based decomposition scheme and a practical version of it. Experiments on larger datasets show that the proposed decomposition method is able to significantly reduce the training times without compromising the testing accuracy.},
  archive      = {J_COR},
  author       = {Edoardo Amaldi and Antonio Consolo and Andrea Manno},
  doi          = {10.1016/j.cor.2022.106058},
  journal      = {Computers &amp; Operations Research},
  pages        = {106058},
  shortjournal = {Comput. Oper. Res.},
  title        = {On multivariate randomized classification trees: L0-based sparsity, VC dimension and decomposition methods},
  volume       = {151},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal decisions in stochastic graphs with uncorrelated and
correlated edge weights. <em>COR</em>, <em>150</em>, 106085. (<a
href="https://doi.org/10.1016/j.cor.2022.106085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic graph models and algorithms for the computation of different stochastic shortest path problems (SSPPs) continue to play an important role in various fields of computer science and operations research , with recent applications ranging from vehicle routing to social networks and decision problems in finance . In this paper, we first introduce stochastic graph models where weights to pass an edge in a graph are, possibly correlated, random variables. Depending on the application context and the interpretation of uncertain edge weights, random variables either model the time to pass an edge or describe a reward one gains by traversing an edge. For modeling the random variables discrete phase type distributions are used. Several algorithms for the computation of optimal policies which depend on the current weight upon arriving at a vertex while still exploiting weight dependencies among edges are developed. It will be shown that with correlated edge weights the stochastic shortest path problems become PSPACE-complete and the solution of instances with a bounded number of phases is NP-hard such that for an exact computation of the shortest path, algorithms from partially observable Markov decision processes (POMDPs) or mixed integer linear programming (MILP) have to be applied. Alternatively, an efficient heuristic algorithm can be used which often yields good or even optimal results with a small effort.},
  archive      = {J_COR},
  author       = {Peter Buchholz and Iryna Dohndorf},
  doi          = {10.1016/j.cor.2022.106085},
  journal      = {Computers &amp; Operations Research},
  pages        = {106085},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal decisions in stochastic graphs with uncorrelated and correlated edge weights},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The vacation planning problem: A multi-level
clustering-based metaheuristic approach. <em>COR</em>, <em>150</em>,
106083. (<a href="https://doi.org/10.1016/j.cor.2022.106083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Vacation Planning Problem (VPP), an extension of the Tourist Trip Design Problem which is suitable for modelling scenarios wherein a tourist wishes to explore a large geographical area (e.g. an administrative region), rather than a single urban destination. Further to deriving personalized daily tourist routes i.e., ordered visits to points of interest (POIs) that maximize tourist satisfaction (profit), VPP also recommends intermediate destinations along the trip (most typically, towns to stay overnight) and accommodation areas, as well as optimal distribution of trip days among the different destinations. Herein, we formally define the VPP and present an innovative multi-level clustering scheme to group POIs together and an efficient dynamic programming approach for solving the problem. The proposed method yields higher-profit results compared to an existing approach, as it adopts a sophisticated approach in rendering the geography of the region to be visited by the tourist.},
  archive      = {J_COR},
  author       = {Nikolaos Vathis and Charalampos Konstantopoulos and Grammati Pantziou and Damianos Gavalas},
  doi          = {10.1016/j.cor.2022.106083},
  journal      = {Computers &amp; Operations Research},
  pages        = {106083},
  shortjournal = {Comput. Oper. Res.},
  title        = {The vacation planning problem: A multi-level clustering-based metaheuristic approach},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient GRASP-like algorithm for the multi-product
straight pipeline scheduling problem. <em>COR</em>, <em>150</em>,
106082. (<a href="https://doi.org/10.1016/j.cor.2022.106082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work deals with the multi-product straight pipeline scheduling problem. The considered straight pipeline system is used to transport refined petroleum products from a single source (refinery with storage tanks) to a single destination (distribution center). The main objective is to find a sequence of batches which aims to maximize the total volume to be transported via the pipeline, while meeting the daily customer demands over a fixed time horizon. Each batch contains only one product with a volume between its upper and lower bounds. Constraints related to inventory levels, batch settling periods and forbidden sequences between pairs of products must be respected, and pipeline stoppage periods should also be handled. A Mixed Integer Linear Programming (MILP) model and a Greedy Randomized Adaptive Search Procedure (GRASP)-like algorithm are proposed to tackle the problem under study. The MILP model is based on the discharging time axis with continuous representation for both time and volume formulation. The GRASP-like algorithm is composed of a construction method and an improvement procedure. The construction method generates a new sequence of batches in a random way with the use of a repair process to obtain an initial solution that satisfies all demands. Then, the improvement procedure is attempted to increase the fill rate of pipeline using volume optimization operators without change the sequence of products. A set of instances was generated from a real case study in order to validate the proposed approach. The performance of our approach is benchmarked against the MILP model (solved using Gurobi Solver), and the numerical experiments proved that the proposed approach obtains very competitive results both in term of solution quality and CPU time.},
  archive      = {J_COR},
  author       = {Meryem Bamoumen and Selwa Elfirdoussi and Libo Ren and Nikolay Tchernev},
  doi          = {10.1016/j.cor.2022.106082},
  journal      = {Computers &amp; Operations Research},
  pages        = {106082},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient GRASP-like algorithm for the multi-product straight pipeline scheduling problem},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A model-based evolutionary algorithm for home health care
scheduling. <em>COR</em>, <em>150</em>, 106081. (<a
href="https://doi.org/10.1016/j.cor.2022.106081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, for the first time a model-based evolutionary algorithm is presented for a real-life Home Health Care Routing and Scheduling Problem (HHCRSP). The algorithm generates routes consisting of care activities jointly with the underlying shift schedule, while taking into account the qualification levels. The performance is optimized in terms of travel time, time window waiting time and shift overtime. The algorithm is a novel extension of the permutation Gene-Pool Optimal Mixing Evolutionary Algorithm. Numerical experiments, using real-life data, show that the algorithm performs close to optimal for small instances, and outperforms schedules from a case study, leading to efficiency gains of 41\%. Furthermore, it is shown that the model-based evolutionary algorithm performs better than a more traditional evolutionary algorithm, which demonstrates the importance of learning and exploiting a model to guide the optimization in HHCRSP.},
  archive      = {J_COR},
  author       = {Yoram Clapper and Joost Berkhout and René Bekker and Dennis Moeke},
  doi          = {10.1016/j.cor.2022.106081},
  journal      = {Computers &amp; Operations Research},
  pages        = {106081},
  shortjournal = {Comput. Oper. Res.},
  title        = {A model-based evolutionary algorithm for home health care scheduling},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implications on managing inventory systems for products with
stock-dependent demand and nonlinear holding cost via the adaptive EOQ
policy. <em>COR</em>, <em>150</em>, 106080. (<a
href="https://doi.org/10.1016/j.cor.2022.106080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the incomplete information of inventory managers and the ease-of-implementation feature of the adaptive EOQ (AEOQ) policy, this paper investigates whether this policy is effective in managing inventory systems for products with stock-dependent demand and nonlinear holding cost when some underlying parameters are unknown. The effectiveness of the AEOQ policy is studied from both stability and profitability perspectives. Stability analysis shows that the iterative procedure may not be convergent. However, incorporating the exponential smoothing or weighted moving average methods into the AEOQ policy could benefit the stability of this policy. Moreover, the delay feedback control method could be used to stabilize this iterative procedure when fluctuations occur. Profitability analysis firstly introduces three objective functions and shows how the relative difference in each objective function between equilibrium and optimal order quantities is affected by key parameters. Then, by defining the AEOQ policy as an effective solution if the equilibrium order quantity could balance these objectives, this paper provides the conditions under which the AEOQ policy is effective. Finally, methods are developed for inventory managers to judge this effectiveness in terms of profitability. Results highlight the feasibility of this policy and provide some practical insights for retailers to use this policy properly.},
  archive      = {J_COR},
  author       = {Zhanbing Guo and Haojie Wang},
  doi          = {10.1016/j.cor.2022.106080},
  journal      = {Computers &amp; Operations Research},
  pages        = {106080},
  shortjournal = {Comput. Oper. Res.},
  title        = {Implications on managing inventory systems for products with stock-dependent demand and nonlinear holding cost via the adaptive EOQ policy},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iterated maximum large neighborhood search for the traveling
salesman problem with time windows and its time-dependent version.
<em>COR</em>, <em>150</em>, 106078. (<a
href="https://doi.org/10.1016/j.cor.2022.106078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a new algorithm for finding feasible or makespan-optimal solutions of Traveling Salesman Problems with Time Windows (TSPTWs) and Time-Dependent TSPTWs (TDTSPTWs). The algorithm starts from a sequence of visits of the customers involved in the problem, uses destroy and repair operations to iteratively improve this sequence, and applies perturbations to diversify search. For the destroy phase, customers are removed from the current sequence of visits as long as a parameter called the insertion-width is not too high. For the repair phase, the customers removed are reinserted for the best based on a dynamic programming procedure whose complexity is only linear in the number of customers. For the perturbation phase, some customers are randomly shifted in the sequence of visits. The algorithm obtained is called Iterated Maximum Large Neighborhood Search (ImaxLNS). On seven standard TSPTW benchmarks, it returns the best-known solution for each instance in less than one second on average. On two TDTSPTW benchmarks related to urban logistics, it provides new feasible solutions and best solutions. On a TDTSPTW benchmark related to Earth observing satellites, it solves most of the instances in less than a second.},
  archive      = {J_COR},
  author       = {Cédric Pralet},
  doi          = {10.1016/j.cor.2022.106078},
  journal      = {Computers &amp; Operations Research},
  pages        = {106078},
  shortjournal = {Comput. Oper. Res.},
  title        = {Iterated maximum large neighborhood search for the traveling salesman problem with time windows and its time-dependent version},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-wave tabu search for the boolean quadratic programming
problem with generalized upper bound constraints. <em>COR</em>,
<em>150</em>, 106077. (<a
href="https://doi.org/10.1016/j.cor.2022.106077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The boolean quadratic programming problem with generalized upper bound constraints (BQP-GUB) is an NP-hard problem with many practical applications. In this study, we propose an effective multi-wave tabu search algorithm for solving BQP-GUB. The algorithm performs a sequence of search waves, where each wave alternates between the forward and reverse phases, and the transition between two adjacent waves depends on a hybrid perturbation phase. The forward phase employs tabu search to reach a critical solution and the reverse phase follows to reverse previously performed moves and perform an equal number of moves by referring to the search information gathered from the latest search process. The hybrid perturbation phase randomly chooses a directed strategy, a frequency guided strategy and a recency guided strategy to achieve search diversification. Experimental results on 78 standard instances indicate that the proposed algorithm is able to improve the lower bounds for 6 instances and match the best solutions in the literature for most instances within competitive time.},
  archive      = {J_COR},
  author       = {Zhen Shang and Jin-Kao Hao and Songzheng Zhao and Yang Wang and Fei Ma},
  doi          = {10.1016/j.cor.2022.106077},
  journal      = {Computers &amp; Operations Research},
  pages        = {106077},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-wave tabu search for the boolean quadratic programming problem with generalized upper bound constraints},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient multistart heuristic for the driver and vehicle
routing problem. <em>COR</em>, <em>150</em>, 106076. (<a
href="https://doi.org/10.1016/j.cor.2022.106076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the Driver and Vehicle Routing Problem , a complex routing problem with two depots in which the vehicles go from one depot to the other, while the drivers leaving from a depot must return to it within a given time limit. With these assumptions, it is mandatory for drivers to change vehicles in order to be able to go back to their base depots. The exchange of vehicles can only take place at some point. The objective is to design feasible routes for the vehicles and the drivers, so that the total cost is minimized. Only small instances of this problem can be solved to optimality . We present a multistart heuristic to tackle the problem in an efficient way. The computational experiments show that the proposed heuristic usually manages to find the optimal solution for the benchmark instances in the literature, being competitive when compared with previous heuristic results, and it is able to provide feasible solutions to much larger instances.},
  archive      = {J_COR},
  author       = {Bencomo Domínguez-Martín and Inmaculada Rodríguez-Martín and Juan-José Salazar-González},
  doi          = {10.1016/j.cor.2022.106076},
  journal      = {Computers &amp; Operations Research},
  pages        = {106076},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient multistart heuristic for the driver and vehicle routing problem},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerating logic-based benders decomposition for railway
rescheduling by exploiting similarities in delays. <em>COR</em>,
<em>150</em>, 106075. (<a
href="https://doi.org/10.1016/j.cor.2022.106075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation of a railway system is subject to unpredictable delays or disruptions. Operators control the railway system to minimize losses in performance. Real-time rescheduling is the adaptation of a railway schedule to any unforeseen delay or disturbance and recovers an optimal system state. In this work we propose the extension of an existing Benders decomposition scheme used so far for timetabling, to the case of railway rescheduling. We show how to increase its computational speed by a factor 2, by considering libraries of Benders cuts computed for other instances, to be reused in the solution. We show how including extra cuts has to balance a speedup potential, with a general slowdown due to optimization problems of increased sizes. We show that, if delays in an instance of rescheduling are in fact unknown, but come from a known statistical distribution, we can use a similarity measure to identify a-priori the most promising libraries of Benders cuts, which lead to speedups up to 20\%.},
  archive      = {J_COR},
  author       = {Florin Leutwiler and Guillem Bonet Filella and Francesco Corman},
  doi          = {10.1016/j.cor.2022.106075},
  journal      = {Computers &amp; Operations Research},
  pages        = {106075},
  shortjournal = {Comput. Oper. Res.},
  title        = {Accelerating logic-based benders decomposition for railway rescheduling by exploiting similarities in delays},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modified modularity density maximization and density ratio
heuristic. <em>COR</em>, <em>150</em>, 106072. (<a
href="https://doi.org/10.1016/j.cor.2022.106072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network science is considered as an interdisciplinary research field engaging engineering, social, natural, and computer sciences. Most networks nestle vertices organized in groups called communities, modules or clusters. Communities are groups of vertices that perhaps partake similar features and/or function common roles within a graph. Modularity maximization objective is employed in community detection algorithms . However, modularity maximization solution has practical problems such as resolution limit and frailty. Recently, an alternative clustering measure known as modularity density has been developed to address the resolution limit of modularity maximization. Modularity Density Maximization (MDM) aims to reduce the out of cluster links. The less out connections improve the objective function. In this research, the out connections are perceived as distances. Thus, we propose a Modified Modularity Density Maximization (MMDM) as we consider minimizing the deepest out connection instead of minimizing the out links. Modified Modularity Density Maximization (MMDM) is formulated as a Mixed Integer Linear Programming (MILP). GAMS software is used to solve the model and the obtained results are compared with MDM using internal cluster validation approach. A novel heuristic clustering algorithm named Density Ratio (DR) Heuristic. DR is proposed to solve larger data sets that cannot be solved by MILP or take very long time to solve. The heuristic is applied on both MMDM and MDM approaches and the obtained results are compared using internal cluster validation approach. MMDM finds higher values compared to MDM based on internal validation for some datasets. The density ratio heuristic finds global optimal or near optimal solutions with the datasets employed for the MILP model.},
  archive      = {J_COR},
  author       = {Zead Saleh and Harun Pirim},
  doi          = {10.1016/j.cor.2022.106072},
  journal      = {Computers &amp; Operations Research},
  pages        = {106072},
  shortjournal = {Comput. Oper. Res.},
  title        = {Modified modularity density maximization and density ratio heuristic},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Opportunities for reinforcement learning in stochastic
dynamic vehicle routing. <em>COR</em>, <em>150</em>, 106071. (<a
href="https://doi.org/10.1016/j.cor.2022.106071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been a paradigm-shift in urban logistic services in the last years; demand for real-time, instant mobility and delivery services grows. This poses new challenges to logistic service providers as the underlying stochastic dynamic vehicle routing problems (SDVRPs) require anticipatory real-time routing actions. The complexity of finding efficient routing actions is multiplied by the challenge of evaluating such actions with respect to their effectiveness given future dynamism and uncertainty. Reinforcement learning (RL) is a promising tool for evaluating actions but it is not designed for searching the complex and combinatorial action space. Thus, past work on RL for SDVRP has either restricted the action space, that is solving only subproblems by RL and everything else by established heuristics, or focused on problems that reduce to resource allocation problems. For solving real-world SDVRPs, new strategies are required that address the combined challenge of combinatorial, constrained action space and future uncertainty, but as our findings suggest, such strategies are essentially non-existing. Our survey paper shows that past work relied either on action-space restriction or avoided routing actions entirely and highlights opportunities for more holistic solutions.},
  archive      = {J_COR},
  author       = {Florentin D. Hildebrandt and Barrett W. Thomas and Marlin W. Ulmer},
  doi          = {10.1016/j.cor.2022.106071},
  journal      = {Computers &amp; Operations Research},
  pages        = {106071},
  shortjournal = {Comput. Oper. Res.},
  title        = {Opportunities for reinforcement learning in stochastic dynamic vehicle routing},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring search space trees using an adapted version of
monte carlo tree search for combinatorial optimization problems.
<em>COR</em>, <em>150</em>, 106070. (<a
href="https://doi.org/10.1016/j.cor.2022.106070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we propose a heuristic algorithm to explore search space trees associated with instances of combinatorial optimization problems. The algorithm is based on Monte Carlo tree search, a popular algorithm in game playing that is used to explore game trees and represents the state-of-the-art algorithm for a number of games. Several enhancements to Monte Carlo tree search are proposed that make the algorithm more suitable in a combinatorial optimization context. These enhancements exploit the combinatorial structure of the problem and aim to efficiently explore the search space tree by pruning subtrees, using a heuristic simulation policy, reducing the domains of variables by eliminating dominated value assignments and using a beam width. The algorithm was implemented with its components specifically tailored to two combinatorial optimization problems : the quay crane scheduling problem with non-crossing constraints and the 0-1 knapsack problem. For the first problem our algorithm surpasses the state-of-the-art results and several new best solutions are found for a benchmark set of instances. For the second problem our algorithm typically produces near-optimal solutions that are slightly worse than the state-of-the-art results, but it needs only a small fraction of the time to do so. These results indicate that the algorithm is competitive with the state-of-the-art for two entirely different combinatorial optimization problems .},
  archive      = {J_COR},
  author       = {Jorik Jooken and Pieter Leyman and Tony Wauters and Patrick De Causmaecker},
  doi          = {10.1016/j.cor.2022.106070},
  journal      = {Computers &amp; Operations Research},
  pages        = {106070},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exploring search space trees using an adapted version of monte carlo tree search for combinatorial optimization problems},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel hybrid multi-objective algorithm to solve the
generalized cubic cell formation problem. <em>COR</em>, <em>150</em>,
106069. (<a href="https://doi.org/10.1016/j.cor.2022.106069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Generalized Cubic Cell Formation Problem (GCCFP) is a Multi-Objective (MO) optimization problem in manufacturing systems. It aims to find the suitable grouping of machines, products, and workers and their best assignment to manufacturing cells. During the resolution of the MO optimization problems, the decision maker should take decisions about multiple variables in order to optimize several objectives, or to find a good trade-off between the concerned objectives. Depending on the moment when the decision about the suitable configuration is taken, the resolution methods may be devised into (i) priori methods, (ii) interactive methods, and (iii) posteriori methods. In this study, a novel posteriori efficient algorithm called Robust Simulated Annealing-AUGMented ɛ ɛ ɛ -CONstraint (SA-AUGMECON-R) algorithm is introduced in order to solve the GCCFP. The proposed algorithm combines AUGMECON-R exact method and the simulated annealing meta-heuristic. To evaluate the performance of the algorithm, a comparative study was conducted. Regarding the values of the metrics that are used to evaluate the performance of MO algorithms, SA-AUGMECON-R algorithm provides excellent results comparing with AUGMECON 2, AUGMECON-R and NSGA-II.},
  archive      = {J_COR},
  author       = {Hamida Bouaziz and Dalal Bardou and Meryem Berghida and Samir Chouali and Ali Lemouari},
  doi          = {10.1016/j.cor.2022.106069},
  journal      = {Computers &amp; Operations Research},
  pages        = {106069},
  shortjournal = {Comput. Oper. Res.},
  title        = {A novel hybrid multi-objective algorithm to solve the generalized cubic cell formation problem},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven compensation scheme for last-mile delivery
with crowdsourcing. <em>COR</em>, <em>150</em>, 106059. (<a
href="https://doi.org/10.1016/j.cor.2022.106059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent relevant innovation in last-mile delivery is to consider the possibility of goods being delivered by couriers appointed through crowdsourcing. In this paper we focus on the setting of in-store customers delivering goods, ordered by online customers, on their way home. We assume that not all the proposed delivery tasks will necessarily be accepted, and use logistic regression to model the crowd agents’ willingness to undertake a delivery. This model is then used to build a novel compensation scheme that determines reward values, based on the current plan for the professional fleet’s routes and on the couriers’ probabilities of acceptance, by employing a direct search algorithm that seeks to minimise the expected cost.},
  archive      = {J_COR},
  author       = {Miguel Barbosa and João Pedro Pedroso and Ana Viana},
  doi          = {10.1016/j.cor.2022.106059},
  journal      = {Computers &amp; Operations Research},
  pages        = {106059},
  shortjournal = {Comput. Oper. Res.},
  title        = {A data-driven compensation scheme for last-mile delivery with crowdsourcing},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-stage improved base point slacks-based measure of
super-efficiency for negative data handling. <em>COR</em>, <em>150</em>,
106057. (<a href="https://doi.org/10.1016/j.cor.2022.106057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For most of the Slacks-Based Measure (SBM)-type models in Data Envelopment Analysis , the variable returns-to-scale (VRS) condition is required to become feasible and translation invariant while applied on negative data. Unlike them, the “Base Point SBM (BP-SBM)” and “Super BP-SBM” models accept negative values under four returns-to-scale (RTS) conditions; however, (i) they are not translation invariant , (ii) they are sensitive to some perturbation terms which help to translate negative data to positive data by avoiding division-by-zero irrationality, and (iii) the Super BP-SBM model suffers from infeasibility issue. To address the above limitations, this study improves the existing BP-SBM and Super BP-SBM models. The Improved BP-SBM (IBP-SBM) and Improved Super BP-SBM (ISBP-SBM) models are translation invariant under four different RTS conditions, and do not involve any perturbation terms. Although the proposed ISBP-SBM model is feasible under the four RTS conditions, it fails to provide Pareto efficient projections. Therefore, we propose a two-stage super-efficiency approach, where the ISBP-SBM model is applied on the first stage to obtain the input savings and output surpluses, which are incorporated in the IBP-SBM model to be applied on the second stage. To validate the proposed models, their results are compared with some state-of-the-art models using a benchmark dataset. Experimental findings indicate that the proposed models have overcome the limitations of the existing models while applied on negative data. Further, three real-life case studies of supplier selection, financial performance evaluation, and airline performance evaluation are used to discuss the applicability of the proposed approach.},
  archive      = {J_COR},
  author       = {Arup Ratan Paramanik and Sobhan Sarkar and Bijan Sarkar},
  doi          = {10.1016/j.cor.2022.106057},
  journal      = {Computers &amp; Operations Research},
  pages        = {106057},
  shortjournal = {Comput. Oper. Res.},
  title        = {A two-stage improved base point slacks-based measure of super-efficiency for negative data handling},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interval scheduling with economies of scale. <em>COR</em>,
<em>150</em>, 106056. (<a
href="https://doi.org/10.1016/j.cor.2022.106056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by applications in cloud computing , we study interval scheduling problems exhibiting economies of scale . An instance is given by a set of jobs, each with start time, end time, and a function representing the cost of scheduling a subset of jobs on the same machine. Specifically, we focus on the max-weight function and non-negative, non-decreasing concave functions of total schedule weight. The goal is a partition of the jobs that minimizes the total schedule cost, where overlapping jobs cannot be processed on the same machine. We propose a set cover formulation and a column generation algorithm to solve its linear relaxation. For the max-weight function, which is already NP-hard, we give a polynomial-time pricing algorithm; for the more general case of a function of the total weight, we have a pseudo-polynomial algorithm. To obtain integer solutions , we extend the column generation approach using branch-and-price. We computationally evaluate our methods on two different functions, using both random instances and instances derived from cloud computing data; our algorithm significantly outperforms known integer programming formulations (when these are available) and is able to provably optimize instances with hundreds of jobs.},
  archive      = {J_COR},
  author       = {Christopher Muir and Alejandro Toriello},
  doi          = {10.1016/j.cor.2022.106056},
  journal      = {Computers &amp; Operations Research},
  pages        = {106056},
  shortjournal = {Comput. Oper. Res.},
  title        = {Interval scheduling with economies of scale},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rollout-based routing strategies with embedded prediction: A
fish trawling application. <em>COR</em>, <em>150</em>, 106055. (<a
href="https://doi.org/10.1016/j.cor.2022.106055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an effort to replenish stocks after years of overfishing, the European Union has been implementing policies to restrict the catch in all fisheries including in the Baltic Sea. These regulations incentivize fishermen to seek operational efficiency to counter lower catch limits. In this study, we address the fish trawling problem as a stochastic dynamic orienteering problem and propose rollout-based routing policies. Using a prescriptive analytic approach, we propose several prediction models and combine them with dynamic routing policies, the combination of which forms a prescriptive model. We evaluate and validate the effectiveness of these prescriptive models using a Baltic dataset on the fish species cod (Gadus). We propose a spatiotemporal cross-validation procedure to fairly assess different prescriptive models. Our findings show that reoptimization-based rollout strategies coupled with simple prediction methods such as nearest neighbors perform better than prescriptive models that use complex spatiotemporal smoothing techniques.},
  archive      = {J_COR},
  author       = {Fahrettin Cakir and Barrett W. Thomas and W. Nick Street},
  doi          = {10.1016/j.cor.2022.106055},
  journal      = {Computers &amp; Operations Research},
  pages        = {106055},
  shortjournal = {Comput. Oper. Res.},
  title        = {Rollout-based routing strategies with embedded prediction: A fish trawling application},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ranking with multiple reference points: Efficient SAT-based
learning procedures. <em>COR</em>, <em>150</em>, 106054. (<a
href="https://doi.org/10.1016/j.cor.2022.106054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the multicriteria ranking problem, and specifically a ranking procedure based on reference points recently proposed in the literature, named Ranking with Multiple reference Points (RMP). Implementing RMP in a real world decision problem requires to elicit the model preference parameters. This can be done indirectly by inferring the parameters from stated preferences . Learning an RMP model from stated preferences proves however to be computationally costly, and can hardly be put in practice using currently available algorithms. In this paper, we propose a Boolean satisfiability formulation for inferring an RMP model from a set of pairwise comparisons which is much faster than the existing algorithms.},
  archive      = {J_COR},
  author       = {Khaled Belahcène and Vincent Mousseau and Wassila Ouerdane and Marc Pirlot and Olivier Sobrie},
  doi          = {10.1016/j.cor.2022.106054},
  journal      = {Computers &amp; Operations Research},
  pages        = {106054},
  shortjournal = {Comput. Oper. Res.},
  title        = {Ranking with multiple reference points: Efficient SAT-based learning procedures},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal flow and capacity allocation in multiple joint
quickest paths of directed networks. <em>COR</em>, <em>150</em>, 106053.
(<a href="https://doi.org/10.1016/j.cor.2022.106053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shared vertices or edges in joint paths bring difficulties to flow routing and scheduling with delay requirements in networks with consideration of both edge lengths and capacities since flow along the different paths will encounter each other in capacitated edges with time dislocation. For an amount of flow, the quickest path problem (QPP) presents a good link for path lengths and capacities with the transmission time of the flow. Extended from the QPP, we propose an edge-path form traffic model for an amount of flow through multiple joint paths with different lengths in one-source one-sink directed capacitated networks. Then, an optimization model for minimum transmission time within feasible traffic constrained by edge capacities is constructed. We then derived the vertex–edge form of the optimization model from the edge-path form. The proposed optimization models in both forms are proved to be linear fractional programming problems, which can be solved in polynomial time . A routing algorithm based on the solution of the vertex–edge form optimization is developed combined with the DFS-based route-searching method. The proposed model and algorithm could be applicable in the real-time operation and management of practical network systems.},
  archive      = {J_COR},
  author       = {Yu Wang and Rui Kang and Linhan Guo and Shunkun Yang and Jian Zhou and Chao Zhang},
  doi          = {10.1016/j.cor.2022.106053},
  journal      = {Computers &amp; Operations Research},
  pages        = {106053},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal flow and capacity allocation in multiple joint quickest paths of directed networks},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local-ideal-points based autonomous space decomposition
framework for the multi-objective periodic generalized directed rural
postman problem under length restrictions with intermediate facilities.
<em>COR</em>, <em>150</em>, 106052. (<a
href="https://doi.org/10.1016/j.cor.2022.106052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a Multi-objective Periodic Generalized Directed Rural Postman Problem under Length Restrictions with Intermediate Facilities (MO-PGDRPPLRIF) applied in the metro track inspection routing problem, which is a variant of the Arc Routing Problem (ARP). In the MO-PGDRPPLRIF, arcs are partitioned into given clusters, and each cluster is associated with a service frequency. As the vehicle has limited working hours per day, several trips may be necessary to complete all tasks. The vehicle must stop at an intermediate facility after each trip such that the parking location where the vehicle ends one day is the same as the position where the vehicle starts the next day. The following objectives are considered in the problem: (i) minimizing the total distance; (ii) making time intervals between two adjacent services for clusters with multiple service frequencies as consistent as possible; and (iii) minimizing the number of trips. In this paper, a novel multi-objective evolutionary algorithm, namely Local-Ideal-Points based Autonomous Space Decomposition (LIP-ASD), is developed to address the proposed problem. LIP-ASD employs a space-decomposition scheme to narrow the search space and exclude inferior solutions. The Discrete Particle Swarm Optimization (DPSO) is embedded to find a satisfactory solution in each decomposed space. The proposed approach is tested through the modified Capacitated ARP (CARP) benchmark instances and a real-world application in Beijing Metro Corporation. Computational results confirm that our solution approach can solve the problem effectively and outperforms the other three state-of-the-art multi-objective evolutionary algorithms.},
  archive      = {J_COR},
  author       = {Long Chen and Peng Xu and Xuedong Yan and Reginald R. Souleyrette and Teng (Alex) Wang},
  doi          = {10.1016/j.cor.2022.106052},
  journal      = {Computers &amp; Operations Research},
  pages        = {106052},
  shortjournal = {Comput. Oper. Res.},
  title        = {Local-ideal-points based autonomous space decomposition framework for the multi-objective periodic generalized directed rural postman problem under length restrictions with intermediate facilities},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multistage adaptive robust optimization for the hydrothermal
scheduling problem. <em>COR</em>, <em>150</em>, 106051. (<a
href="https://doi.org/10.1016/j.cor.2022.106051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current water scarcity faced by many countries increases the need to consider an appropriate representation of future hydro inflows in power system operation and planning models. Hydrothermal scheduling is the problem that seeks to use the water stored in reservoirs throughout time in order to find an optimal dispatch policy between hydro and thermal power plants. Due to both the inherent randomness of water inflows and the intertemporal decision process, this problem has been typically approached through multistage stochastic optimization , minimizing the total expected operational cost over the entire planning horizon. However, this approach has some practical disadvantages. Among the main ones we highlight (i) the complexity of balancing the statistical representativeness of the stochastic processes and the computational efficiency of the optimization model; (ii) the need to employ computationally intensive decomposition methods for its solvability; and (iii) the need to carry out network simplifications to tackle tractability issues arising in large networks. As an alternative, we propose a multistage adaptive robust optimization model for the hydrothermal scheduling problem. Robust optimization is useful to prevent the previous disadvantages because it does not make any distributional assumption and it works with the so-called uncertainty sets instead of carrying out sampling processes. In particular, we propose an efficient formulation based on linear decision rules and vector autoregressive models to represent the uncertainty in hydro inflows. Our experiments, based on the Chilean electric power system with hundreds of hydro nodes and connections, show the proposed model’s efficiency for large-scale systems and provide insights into the adequate balance between cost-effectiveness and reliability that robust optimization models guarantee.},
  archive      = {J_COR},
  author       = {Marcel Favereau and Álvaro Lorca and Matías Negrete-Pincetic},
  doi          = {10.1016/j.cor.2022.106051},
  journal      = {Computers &amp; Operations Research},
  pages        = {106051},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multistage adaptive robust optimization for the hydrothermal scheduling problem},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exact approaches for the minimum subgraph diameter problem.
<em>COR</em>, <em>150</em>, 106050. (<a
href="https://doi.org/10.1016/j.cor.2022.106050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the Minimum Subgraph Diameter Problem (MSDP), an NP-hard problem with applications to network design. Given an undirected graph with lengths and costs on the edges, the MSDP’s goal is to find a spanning subgraph with total cost limited by a given budget, such that the subgraph’s diameter is minimum. We propose a Mixed-Integer Linear Programming (MILP) model for the MSDP, along with two families of valid inequalities , which form the basis of the first exact approaches for the MSDP. We present an approach to apply lazy constraints on the MILP and a heuristic to generate upper bounds from fractional solutions. We propose a comprehensive benchmark for the MSDP and conduct a thorough computational study. The results show the effectiveness of each contribution towards reducing optimality gaps and computational times.},
  archive      = {J_COR},
  author       = {Arthur Pratti Dadalto and Fábio Luiz Usberti and Mário César San Felice},
  doi          = {10.1016/j.cor.2022.106050},
  journal      = {Computers &amp; Operations Research},
  pages        = {106050},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exact approaches for the minimum subgraph diameter problem},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrated optimization of train formation plan and rolling
stock scheduling under time-dependent demand. <em>COR</em>,
<em>150</em>, 106049. (<a
href="https://doi.org/10.1016/j.cor.2022.106049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both train formation plan (TFP) and rolling stock scheduling (RSS) have significant impacts on train operation. However, traditional sequential optimization could lead to infeasible RSS for the predetermined TFP, especially when the number of available rolling stocks is limited. This paper focuses on integrally optimizing TFP and RSS, where each train service can utilize different train formations and multiple turnaround operations occur in the depot. The key to solving the problem is to determine how many formations are needed for each train service and how train services are connected by rolling stocks. The multiple turnaround operations include immediate turnaround, turnaround with entering/exiting depot operations, and turnaround with coupling/decoupling operations. Considering the fixed costs and operating costs, we propose a multi-objective mixed-integer nonlinear programming (MINLP) model to minimize the number of rolling stocks (NR), the number of formations (NF), and the number of coupling/decoupling operations (NC) based on the time–space network. The model is further reformulated into a single-objective mixed-integer linear programming (MILP) model by the linearization method and fuzzy programming, and the reformulated model can be effectively solved by the MILP solver CPLEX. We test the model on realistic instances of the Batong Line in Beijing Subway Network to verify its effectiveness. The results demonstrate that the integrated model effectively solves the shortage of rolling stocks when the number of available rolling stocks is limited. Furthermore, in the integrated model, the decrease in the number of the rolling stocks and coupling/decoupling operations are at the cost of more formations used to balance the conflicts among objectives.},
  archive      = {J_COR},
  author       = {Yaqiong Zhao and Dewei Li and Yonghao Yin},
  doi          = {10.1016/j.cor.2022.106049},
  journal      = {Computers &amp; Operations Research},
  pages        = {106049},
  shortjournal = {Comput. Oper. Res.},
  title        = {Integrated optimization of train formation plan and rolling stock scheduling under time-dependent demand},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal budget allocation policy for tabu search in
stochastic simulation optimization. <em>COR</em>, <em>150</em>, 106046.
(<a href="https://doi.org/10.1016/j.cor.2022.106046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tabu search (TS) is a powerful method for solving combinatorial optimization problems . However, when TS is adopted for stochastic simulation optimization, the simulation noises may mislead the search direction and prevent TS from converging to high-quality solutions. This issue can be mitigated by increasing the number of simulation samples used for solution evaluation, however, real-world applications are generally constrained by a finite computing budget. Therefore, it is critical to reducing the noise effect by an efficient simulation budget allocation, i.e., splitting the total number of samples on solutions. Studies on the budget allocation problem of TS are sparse. Most of the works employ equal allocation or simple policies which are not optimal. Based on the large deviations framework, we propose a new budget allocation policy to enhance the performance of TS under stochastic settings. The proposed allocation policy, provided in closed-form formulas, is asymptotically optimal for maximizing the probability that TS performs the correct move in a single iteration . The efficiency of the proposed method is validated by solving different problems from manufacturing and healthcare scenarios, including an inventory control problem, a throughput maximization problem for the production line, and a physician scheduling problem for the radiotherapy center. The numerical results show that, with the proposed method, TS can obtain better results using the same amount of computational efforts.},
  archive      = {J_COR},
  author       = {Chunlong Yu and Nadia Lahrichi and Andrea Matta},
  doi          = {10.1016/j.cor.2022.106046},
  journal      = {Computers &amp; Operations Research},
  pages        = {106046},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal budget allocation policy for tabu search in stochastic simulation optimization},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time window optimization for attended home service delivery
under multiple sources of uncertainties. <em>COR</em>, <em>150</em>,
106045. (<a href="https://doi.org/10.1016/j.cor.2022.106045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a vehicle routing problem variant to optimize time window assignments together with vehicle routing and scheduling decisions, under the uncertainties of trip time, service time and possible customers’ cancellations. We minimize the expected cost of vehicles’ overtime, idleness, and customer waiting, when also allowing to add new customers to existing schedules. We formulate a two-stage stochastic mixed-integer programming model using finite samples of the uncertain parameters, where in the first stage, we optimize vehicle routes and assign service time windows to customers, and in the second stage, we construct a linear program to compute the resultant undesirable cost given routes and time windows. We also propose a re-optimization method and an insertion-based linear program for accommodating real-time requests in a rolling horizon way for dynamic operations. To speed up computation, we further decompose the problem into three phases and propose Assignment–Routing–Scheduling heuristics. We first design three clustering algorithms based on spatial similarities to assign customers to vehicles, and then combine the nearest-neighbor and smallest-variance rules to decide the route for each vehicle. Finally, we cast the scheduling part as a Newsvendor problem variant and apply inventory approximations to derive closed-form solutions for determining time windows. We conduct numerical studies on diverse instances generated using both well-established benchmark data sets and Ford’s mobile service data, to compare different approaches and demonstrate the benefits of allowing flexible time-window assignments.},
  archive      = {J_COR},
  author       = {Xian Yu and Siqian Shen and Babak Badri-Koohi and Haitham Seada},
  doi          = {10.1016/j.cor.2022.106045},
  journal      = {Computers &amp; Operations Research},
  pages        = {106045},
  shortjournal = {Comput. Oper. Res.},
  title        = {Time window optimization for attended home service delivery under multiple sources of uncertainties},
  volume       = {150},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online generalized assignment problem with historical
information. <em>COR</em>, <em>149</em>, 106047. (<a
href="https://doi.org/10.1016/j.cor.2022.106047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of online platforms has inspired a wide range of applications for timely resources allocations, such as the hotel booking, the cargo logistics, the cloud servers and so on. Motivated by such needs, we study the online versions of the famous generalized assignment problem (GAP) and the packing problem (also known as d-GAP) in the classic random order model, where the online items arrive over time randomly and uniformly and request specific offline resources. Along a recent line of research that uses historical information to improve the performance of online algorithms , we design effective competitive algorithms for both online GAP and d-GAP ( d ⩾ 2 d⩾2 ) with augmentation of historical information. Our algorithms are inspired by Albers et al.’s sequential approach (Albers et al., 2021). If no historical information can be accessed, our algorithm for online GAP reduces to Albers et al.’s algorithm, and our algorithm for online d-GAP ( d ⩾ 2 d⩾2 ) outperforms the current best algorithm (Kesselheim et al., 2018). The practical performance of the proposed algorithms is explored via experiments on both synthetic and real-life datasets. In particular, the positive effect of historical information can be verified by the experiment results.},
  archive      = {J_COR},
  author       = {Haodong Liu and Huili Zhang and Kelin Luo and Yao Xu and Yinfeng Xu and Weitian Tong},
  doi          = {10.1016/j.cor.2022.106047},
  journal      = {Computers &amp; Operations Research},
  pages        = {106047},
  shortjournal = {Comput. Oper. Res.},
  title        = {Online generalized assignment problem with historical information},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strip based compact formulation for two-dimensional
guillotine cutting problems. <em>COR</em>, <em>149</em>, 106044. (<a
href="https://doi.org/10.1016/j.cor.2022.106044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new mixed integer programming formulation for two-dimensional guillotine cutting and packing problems based on a strip decomposition of the rectangular spaces. The formulation covers most of the main related problems in the literature by setting parameters accordingly. The strip concept commonly used for problems with a limited number of stages (two or three stages) has been, in this study, extended to a general concept that can cover an arbitrary number of stages. Due to the easy adaptation of the proposed formulation, which is presented in both heuristic and exact version, an extensive set of computational experiments was performed with instances for the two-dimensional guillotine knapsack , cutting stock and bin packing problems . The experiments, which involve existing benchmark instances and randomly generated instances from the literature, showed that our proposed formulation, considering its heuristic version, can output competitive results both in terms of computational time and percentage of optimally solved instances.},
  archive      = {J_COR},
  author       = {Carlos Diego Rodrigues and Adriana Cristina Cherri and Silvio Alexandre de Araujo},
  doi          = {10.1016/j.cor.2022.106044},
  journal      = {Computers &amp; Operations Research},
  pages        = {106044},
  shortjournal = {Comput. Oper. Res.},
  title        = {Strip based compact formulation for two-dimensional guillotine cutting problems},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Branch-and-refine for solving time-expanded MILP
formulations. <em>COR</em>, <em>149</em>, 106043. (<a
href="https://doi.org/10.1016/j.cor.2022.106043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the standard approaches for solving discrete optimization problems which include the aspect of time, such as the traveling salesman problem with time windows or the shortest path problem with time windows is to derive a so-called time-indexed formulation. If the problem has an underlying structure that can be described by a graph, the time-indexed formulation is usually based on a different, extended graph, commonly referred to as the time-expanded graph. The time-expanded graph can often be derived in such a way that all time constraints are incorporated in its topology, and therefore algorithms for the corresponding time-independent variant become applicable. The downside of this approach is, that the sets of vertices and arcs of the time-expanded graph are much larger than the ones of the original graph. In recent works, however, it has been shown that for many practical applications a partial graph expansion, that might contain time infeasible paths, often suffices to find a proven optimal solution. These approaches, instead, iteratively refine the original graph and solve a relaxation of the time-expanded formulation in each iteration. When the solution of the current relaxation is time feasible an optimal solution can be derived from it and the algorithm terminates. In this work we present new ideas, that allow for the propagation of information about the optimal solution of a coarser graph to a more refined graph and show how these can be used in algorithms, which are based on graph refinement. More precisely we present a new algorithm for solving Mixed Integer Linear Program (MILP) formulations that allows for the graph refinement to be carried out during the exploration of the branch-and-bound tree instead of restarting whenever the optimal solution was found to be infeasible. For demonstrating the practical relevance of this algorithm we present numerical results on its application to the shortest path problem with time windows and the traveling salesman problem with time windows.},
  archive      = {J_COR},
  author       = {Fabian Gnegel and Armin Fügenschuh},
  doi          = {10.1016/j.cor.2022.106043},
  journal      = {Computers &amp; Operations Research},
  pages        = {106043},
  shortjournal = {Comput. Oper. Res.},
  title        = {Branch-and-refine for solving time-expanded MILP formulations},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maritime location inventory routing problem for island
supply chain network under periodic freight demand. <em>COR</em>,
<em>149</em>, 106042. (<a
href="https://doi.org/10.1016/j.cor.2022.106042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a model for island supply chain network design that integrates a maritime location inventory routing problem (MLIRP) and considers the periodic freight demand in the network. Owing to the complexity of the MLIRP, a bi-level parallel memetic algorithm (BPMA) was developed for solving the model. The proposed approach was tested on a set of MLIRP instances based on real-life islands in South China Sea and a set of existing benchmark MIRP instances from the literature. The results of the numerical analysis illustrated the effectiveness of the proposed approach. Moreover, a sensitivity analysis was carried out to understand the impacts of various parameters on the changes in total cost.},
  archive      = {J_COR},
  author       = {Yixuan Wang and Nuo Wang and Peixiu Han},
  doi          = {10.1016/j.cor.2022.106042},
  journal      = {Computers &amp; Operations Research},
  pages        = {106042},
  shortjournal = {Comput. Oper. Res.},
  title        = {Maritime location inventory routing problem for island supply chain network under periodic freight demand},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A location-or-routing problem with partial and decaying
coverage. <em>COR</em>, <em>149</em>, 106041. (<a
href="https://doi.org/10.1016/j.cor.2022.106041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a generalized location-or-routing problem by considering partial coverage of the users according to a distance-decaying coverage function. In this problem, there is a set of candidate locations where to open facilities, and a set of locations with given number of users that must be covered by the open facilities. Users may travel directly to an open facility if they are within the coverage range of it, or they may be transported to facilities by capacitated vehicles. A distance-decaying function for the facility coverage is considered and the vehicles are allowed to partially cover the users located at the same location. Two mixed integer programming models are presented that minimize the number of uncovered users subject to a restricted budget, and an adaptive large neighborhood search metaheuristic is developed as the solution methodology. Through several computational experiments, the efficiency of the proposed formulations and the solution algorithm are evaluated, and the ALNS algorithm is shown to perform well in terms of solution quality and computing time. Computational results indicate that considering the partial coverage of users reduces the number of uncovered ones as the vehicle capacity decreases, and this reduction is more significant under a distance-decaying facility coverage function. It is also observed that considering distance-decaying coverage increases both the number of uncovered users and the spent budget, especially with a continuous function such as an exponential decay function.},
  archive      = {J_COR},
  author       = {Maryam Haghi and Okan Arslan and Gilbert Laporte},
  doi          = {10.1016/j.cor.2022.106041},
  journal      = {Computers &amp; Operations Research},
  pages        = {106041},
  shortjournal = {Comput. Oper. Res.},
  title        = {A location-or-routing problem with partial and decaying coverage},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified exact approach for clustered and generalized
vehicle routing problems. <em>COR</em>, <em>149</em>, 106040. (<a
href="https://doi.org/10.1016/j.cor.2022.106040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Clustered Vehicle Routing Problem (CluVRP) and the Generalized Vehicle Routing Problem (GVRP) are variants of the classic capacitated vehicle routing where customers are partitioned into clusters. In the first problem, all customers in the same cluster must be visited in sequence by a single route. In the second problem, all customers in a cluster are served by visiting a single customer in it. This article proposes a model for GVRP, together with new reduction tests. Then, three different models for CluVRP are proposed and discussed. The best performing CluVRP model is actually a reduction of the problem to a GVRP. All models are implemented and solved by the branch-cut-and-price algorithm in the VRPSolver package. The computational results show that the new approach can solve instances with up to 1,200 customers, much larger than those that could be solved by previous exact algorithms.},
  archive      = {J_COR},
  author       = {Matheus Freitas and João Marcos Pereira Silva and Eduardo Uchoa},
  doi          = {10.1016/j.cor.2022.106040},
  journal      = {Computers &amp; Operations Research},
  pages        = {106040},
  shortjournal = {Comput. Oper. Res.},
  title        = {A unified exact approach for clustered and generalized vehicle routing problems},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative vehicle-drone distribution network
optimization for perishable products in the epidemic situation.
<em>COR</em>, <em>149</em>, 106039. (<a
href="https://doi.org/10.1016/j.cor.2022.106039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The collaborative vehicle-drone distribution network (CVDDN) optimization problem incorporates vehicle-drone collaboration mechanism, site selection, product perishability, and epidemic impact into the optimization framework. And it is formulated as a bi-objective mathematical model to minimize the total cost and the value loss for products distribution. An efficient two-phase hybrid heuristic algorithm based on the improved K-means clustering and the extended Non-dominated Sorting Genetic Algorithm-II (ENSGA-II) is proposed to solve the investigated CVDDN optimization problem. The improved K-means clustering algorithm is employed to find an effective location strategy for “contactless” distribution sites (DS) and act as a base for collaborative vehicle routing problem with drones (VRPD). The ENSGA-II combines the NSGA-II algorithm framework and flexible tabu search rules to ensure a large effective search and fast parallel calculations, which generates a real-coded solution space to find the hybrid vehicle-drone delivery routes for VRPD. Various experimental instances tests show that the ENSGA-II outperforms other algorithms. An empirical case study of Chengdu city in China indicates the efficiency of our proposed optimization model and solving approach. Sensitivity analysis is conducted to identify the impact of various parameters on the CVDDN optimization problem.},
  archive      = {J_COR},
  author       = {Jie Zhang and Yanfeng Li},
  doi          = {10.1016/j.cor.2022.106039},
  journal      = {Computers &amp; Operations Research},
  pages        = {106039},
  shortjournal = {Comput. Oper. Res.},
  title        = {Collaborative vehicle-drone distribution network optimization for perishable products in the epidemic situation},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized relax-and-fix heuristic. <em>COR</em>,
<em>149</em>, 106038. (<a
href="https://doi.org/10.1016/j.cor.2022.106038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a heuristic for mixed-integer mathematical programs , that can be seen as a generalization of the relax-and-fix heuristic: a sequence of derived subproblems is solved, progressively fixing variables in the original problem. We propose a generic implementation and report on numerical results for four well-known operational research applications: lot-sizing, vehicle routing, bin-packing and portfolio optimization. Results show that this heuristic may be competitive depending on the definition of subproblems .},
  archive      = {J_COR},
  author       = {C. Joncour and J. Kritter and S. Michel and X. Schepler},
  doi          = {10.1016/j.cor.2022.106038},
  journal      = {Computers &amp; Operations Research},
  pages        = {106038},
  shortjournal = {Comput. Oper. Res.},
  title        = {Generalized relax-and-fix heuristic},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A benders decomposition algorithm for the maximum
availability service facility location problem. <em>COR</em>,
<em>149</em>, 106030. (<a
href="https://doi.org/10.1016/j.cor.2022.106030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the maximum availability service facility location problem, which integrates the set covering and flow capturing problems to service both stationary and mobile demand in an urban region. The problem has applications in location of government offices, medical facilities and polling stations. We present a mixed-integer linear programming formulation and develop a Benders decomposition algorithm. We implement several acceleration techniques including multi-cut and Pareto-optimal cut generation. We construct these cuts analytically using closed-form expressions for subproblem solutions. Our best algorithm can optimally solve randomly generated instances with up to one thousand nodes, one million commuting customers and one hundred candidate facilities. We also conduct a case study with real data from the city of Chicago and show an application of our model for the location of medical facilities in a pandemic situation. We find that confinement restrictions in a pandemic do not significantly affect the total demand coverage, but facility layout may be significantly different under different confinement levels.},
  archive      = {J_COR},
  author       = {Ali Muffak and Okan Arslan},
  doi          = {10.1016/j.cor.2022.106030},
  journal      = {Computers &amp; Operations Research},
  pages        = {106030},
  shortjournal = {Comput. Oper. Res.},
  title        = {A benders decomposition algorithm for the maximum availability service facility location problem},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using VRPSolver to efficiently solve the differential
harvest problem. <em>COR</em>, <em>149</em>, 106029. (<a
href="https://doi.org/10.1016/j.cor.2022.106029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision farming in viticulture raises challenging combinatorial issues such as the Differential Harvest Problem . This problem might appear at first as similar to a simple Capacitated Vehicle Routing Problem but it exhibits problem-specific constraints that make this problem much harder to solve and which are discussed in this article. Our objective was to develop efficient exact methods using column generation and VRPSolver™ based models. In order to investigate possibilities of hybridization, two other models were designed: a constraint programming model and a local search model using LocalSolver™ . In order to reach good scalability, new valid inequalities and a hybrid solving scheme are proposed. Extensive experiments were performed both on simulated and real data sets . The results are discussed from operational cost point of view and also performance.},
  archive      = {J_COR},
  author       = {Gabriel Volte and Eric Bourreau and Rodolphe Giroudeau and Olivier Naud},
  doi          = {10.1016/j.cor.2022.106029},
  journal      = {Computers &amp; Operations Research},
  pages        = {106029},
  shortjournal = {Comput. Oper. Res.},
  title        = {Using VRPSolver to efficiently solve the differential harvest problem},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resource distribution under spatiotemporal uncertainty of
disease spread: Stochastic versus robust approaches. <em>COR</em>,
<em>149</em>, 106028. (<a
href="https://doi.org/10.1016/j.cor.2022.106028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of optimizing locations of distribution centers (DCs) and plans for distributing resources such as test kits and vaccines, under spatiotemporal uncertainties of disease spread and demand for the resources. We aim to balance the operational cost (including costs of deploying facilities, shipping, and storage) and quality of service (reflected by demand coverage), while ensuring equity and fairness of resource distribution across multiple populations. We compare a sample-based stochastic programming (SP) approach with a distributionally robust optimization (DRO) approach using a moment-based ambiguity set. Numerical studies are conducted on instances of distributing COVID-19 vaccines in the United States and test kits, to compare SP and DRO models with a deterministic formulation using estimated demand and with the current resource distribution plans implemented in the US. We demonstrate the results over distinct phases of the pandemic to estimate the cost and speed of resource distribution depending on scale and coverage, and show the “demand-driven” properties of the SP and DRO solutions. Our results further indicate that if the worst-case unmet demand is prioritized, then the DRO approach is preferred despite of its higher overall cost. Nevertheless, the SP approach can provide an intermediate plan under budgetary restrictions without significant compromises in demand coverage.},
  archive      = {J_COR},
  author       = {Beste Basciftci and Xian Yu and Siqian Shen},
  doi          = {10.1016/j.cor.2022.106028},
  journal      = {Computers &amp; Operations Research},
  pages        = {106028},
  shortjournal = {Comput. Oper. Res.},
  title        = {Resource distribution under spatiotemporal uncertainty of disease spread: Stochastic versus robust approaches},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An exact reduction technique for the k-colour shortest path
problem. <em>COR</em>, <em>149</em>, 106027. (<a
href="https://doi.org/10.1016/j.cor.2022.106027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k-Colour Shortest Path Problem is a variant of the classic Shortest Path Problem . This problem consists of finding a shortest path on a weighted edge-coloured graph, where the maximum number of different colours used in a feasible solution is fixed to be k k . The k-CSPP has several real-world applications, particularly in network reliability. It addresses the problem of reducing the connection cost while improving the reliability of the network. In this work, we propose a heuristic approach , namely Colour-Constrained Dijkstra Algorithm (CCDA), which is able to produce effective solutions. We propose a graph reduction technique, namely the Graph Reduction Algorithm (GRA), which removes more than 90\% of the nodes and edges from the input graph. Finally, using a Mixed-Integer Linear Programming (MILP) model, we present an exact approach, namely Reduced Integer Linear Programming Algorithm (RILP), that takes advantage of the heuristic CCDA and the GRA. Several tests were performed to verify the effectiveness of the proposed approaches. The computational results indicate that the produced approaches perform well, in terms of both the solution’s quality and computation times.},
  archive      = {J_COR},
  author       = {Carmine Cerrone and Davide Donato Russo},
  doi          = {10.1016/j.cor.2022.106027},
  journal      = {Computers &amp; Operations Research},
  pages        = {106027},
  shortjournal = {Comput. Oper. Res.},
  title        = {An exact reduction technique for the k-colour shortest path problem},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-based multi-objective evolutionary algorithm for
batching decision problem. <em>COR</em>, <em>149</em>, 106026. (<a
href="https://doi.org/10.1016/j.cor.2022.106026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates a multi-objective batching decision problem that arises in batch annealing operations in the iron and steel industry . The problem concerns selecting coils from a set of waiting coils to be annealed to form batches so as to maximize two conflicting objectives: product quality and equipment utilization. In this study, a multi-objective optimization model is formulated, and a data-driven method is developed to determine the technological parameters for the model. To improve the efficiency and effectiveness of the solution process, we propose a learning-based multi-objective evolutionary algorithm (LBMOEA) with novel evolution operators and a learning-based solution space reduction strategy. To more quickly solve the problem, a clustering method is adopted to achieve a parallel mechanism in the LBMOEA. In computational experiments on 20 randomly generated instances , the results demonstrate that the above evolution operators and strategy are effective, and that the clustering method can reduce the average time cost by 58.76\%. For 15 practical production instances, the results illustrate that the LBMOEA with the clustering method is superior to the non-dominated sorting genetic algorithm II (NSGA-II) and multi-objective evolutionary algorithm based on decomposition (MOEA/D), and shows good potential for application in practical production.},
  archive      = {J_COR},
  author       = {Ying Meng and Tianyang Li and Lixin Tang},
  doi          = {10.1016/j.cor.2022.106026},
  journal      = {Computers &amp; Operations Research},
  pages        = {106026},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learning-based multi-objective evolutionary algorithm for batching decision problem},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust optimization for lot-sizing problems under yield
uncertainty. <em>COR</em>, <em>149</em>, 106025. (<a
href="https://doi.org/10.1016/j.cor.2022.106025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production yield can be highly volatile and uncertain, especially in industries where exogenous and environmental factors such as the climate or raw material quality can impact the manufacturing process. Thus, for production planning, it is necessary to take into account the production yield uncertainty to obtain robust and efficient plans. In this paper, we consider lot-sizing problems under yield uncertainty. We propose a multi-period, single-item lot-sizing problem with backorder and yield uncertainty via a robust optimization methodology. First, we formulate a robust model under a budgeted uncertainty set, which is optimized under the worst case perspective to ensure the feasibility of the proposed plan for any realization of the yield described by the uncertainty set. Second, we analyze the structure of the optimal lot-sizing solution, and we derive the optimal robust policy for the special case of the inventory management problem under a box uncertainty. These results help us develop a dynamic program with polynomial complexity for the lot-sizing problem with stationary yield rate. Finally, extensive computational experiments show the robustness and effectiveness of the proposed model through an average and worst case analyses. The results demonstrate that the robust approach immunizes the system against uncertainty. Moreover, a comparison of the robust model with the nominal model, the deterministic model with safety stock, and the stochastic model shows that the robust model balances the costs better by reducing the backorders at the expense of more often producing a larger amount of goods.},
  archive      = {J_COR},
  author       = {Paula Metzker and Simon Thevenin and Yossiri Adulyasak and Alexandre Dolgui},
  doi          = {10.1016/j.cor.2022.106025},
  journal      = {Computers &amp; Operations Research},
  pages        = {106025},
  shortjournal = {Comput. Oper. Res.},
  title        = {Robust optimization for lot-sizing problems under yield uncertainty},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The heterogeneous fleet vehicle routing problem with draft
limits. <em>COR</em>, <em>149</em>, 106024. (<a
href="https://doi.org/10.1016/j.cor.2022.106024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, international maritime transport has been characterized by the advent of ever larger ships. This phenomenon is known as naval gigantism. If, on the one hand, naval gigantism allows to reduce transport costs by exploiting the economies of scale achievable by large ships, on the other hand, it implies a series of operational issues. Indeed, due to their large draft, such giant vessels are not allowed to enter small ports when fully or near-fully loaded, and in some cases, they cannot enter such small ports at all. In fact, their draft can strongly vary depending on the load on board. This implies restrictions for vessels in accessing ports, which impact not only at the strategical level on the fleet sizing problem, but also at the tactical/operational level, on the sequence of port visits among each route. In fact, given a set of ports that a ship has to visit, determining the optimal sequence of visits becomes a very challenging issue, as the sequence that gives the shortest travel distance (i.e., the smallest travel cost) may prove infeasible due to draft limit restrictions for accessing ports. Furthermore, the same sequence of ports, which may be infeasible for a large ship, may become viable if operated by a smaller ship. On the other hand, due to the economy of scale, travel costs per load unit are generally much lower for large ships than for small ones. Therefore, the draft restrictions also affect the fleet sizing problem. In this paper, we introduce the Heterogeneous Fleet Vehicle Routing Problem with Draft Limits (HF-VRP-DL). We propose a mixed integer programming formulation and several valid inequalities to strengthen it. Since the mathematical model is able to handle only small-sized instances, to address larger instances we propose a Large Neighborhood Search matheuristic (LNS) and an Iterated Local Search matheuristic (ILS). Computational tests carried out show excellent performances of the proposed approach. Further analysis is provided on the impact of the instance layout on the computation time required to solve the problem to optimality .},
  archive      = {J_COR},
  author       = {Paolo Fadda and Simona Mancini and Patrizia Serra and Gianfranco Fancello},
  doi          = {10.1016/j.cor.2022.106024},
  journal      = {Computers &amp; Operations Research},
  pages        = {106024},
  shortjournal = {Comput. Oper. Res.},
  title        = {The heterogeneous fleet vehicle routing problem with draft limits},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting flat subspaces in local search for p-center
problem and two fault-tolerant variants. <em>COR</em>, <em>149</em>,
106023. (<a href="https://doi.org/10.1016/j.cor.2022.106023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, local search algorithms are proposed for the p p -Center, α-Neighbour p p -Center and p p -Next Center facility location problems. The α-Neighbour p p -Center and p p -Next Center problems may be viewed as two fault-tolerant variants of the p p -Center problem. The algorithm proposed for p p -Center outperforms the most recent state-of-the-art metaheuristic for this problem using standard datasets. The proposed algorithm for p p -Next Center also outperforms an existing, more complex, state-of-the-art metaheuristic for this problem. The algorithm proposed for α-Neighbour p p -Center is the first metaheuristic for this problem, to the best of the author&#39;s knowledge. The proposed algorithms share a common design, which is the integration of the first-improvement local search with strategies to exploit flat subspaces in the search space. The overall success of this design paradigm motivates further investigation about its properties and applications to similar NP-hard optimisation problems.},
  archive      = {J_COR},
  author       = {Seyed R. Mousavi},
  doi          = {10.1016/j.cor.2022.106023},
  journal      = {Computers &amp; Operations Research},
  pages        = {106023},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exploiting flat subspaces in local search for p-center problem and two fault-tolerant variants},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scattered storage assignment: Mathematical model and valid
inequalities to optimize the intra-order item distances. <em>COR</em>,
<em>149</em>, 106022. (<a
href="https://doi.org/10.1016/j.cor.2022.106022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In scattered storage, individual items are intentionally distributed across multiple positions in the picking area. Especially in e-commerce environments, where orders typically consist of a few items in small quantities, such a storage policy can reduce picking travel times by increasing the likelihood that items belonging to the same order can be found in nearby positions. In this paper, we propose a scattered storage policy that, when determining the position where each replenished item should be stored, tries to minimize the sum of pairwise distances (SPD) between all items belonging to the same order including a drop-off point. However, when solving the exact mathematical model using integer programming techniques (0–1), the combinatorial nature of the problem hinders performance. We show that the solutions of the MIP solver can be improved by relaxing some variables and adding valid inequalities based on graph properties and knapsack cover constraints. Finally, we prove that the SPD objective is 65\% lower for our scattered storage policy than for a traditional volume based storage policy.},
  archive      = {J_COR},
  author       = {Harol Mauricio Gámez Albán and Trijntje Cornelissens and Kenneth Sörensen},
  doi          = {10.1016/j.cor.2022.106022},
  journal      = {Computers &amp; Operations Research},
  pages        = {106022},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scattered storage assignment: Mathematical model and valid inequalities to optimize the intra-order item distances},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal joint maintenance and orienteering strategy for
complex mission-oriented systems: A case study in offshore wind energy.
<em>COR</em>, <em>149</em>, 106020. (<a
href="https://doi.org/10.1016/j.cor.2022.106020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces and solves the joint maintenance and orienteering problem with an application to offshore wind farms. The quest for sustainable energy production is fueling the growth of offshore wind electricity generation. Energy producing offshore wind turbines are typically dispersed across several remote wind farms and must be maintained and operated with high reliability levels for long time-periods separated by scheduled maintenance rotations. Due to resource constraints such as travel time, cost, and availability of repair crews, only a subset of turbines and their components can be selected for maintenance operations during maintenance trips. This paper proposes a novel joint maintenance and orienteering framework to address the selection of turbines to visit, the components to maintain, the maintenance levels to be performed, the assignment of repair crews, and their routing with the goal of minimizing total cost while satisfying a minimum required reliability threshold during the next operating mission until the next maintenance rotation. A mixed-integer linear programming optimization model is developed and fully discussed. To solve the problem for large-scale instances, a column generation method based on Dantzig–Wolfe decomposition and labeling algorithm is proposed. Several numerical experiments demonstrate the validity of the proposed model and the benefit of jointly optimizing maintenance and orienteering decisions. The results show that inclusion of detailed reliability and multiple maintenance levels allows better maintenance and routing decisions. Numerical results also show trade-offs between reliability requirement, shift duration and total cost.},
  archive      = {J_COR},
  author       = {R. O’Neil and A. Khatab and C. Diallo and U. Venkatadri},
  doi          = {10.1016/j.cor.2022.106020},
  journal      = {Computers &amp; Operations Research},
  pages        = {106020},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal joint maintenance and orienteering strategy for complex mission-oriented systems: A case study in offshore wind energy},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolving test instances of the hamiltonian completion
problem. <em>COR</em>, <em>149</em>, 106019. (<a
href="https://doi.org/10.1016/j.cor.2022.106019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting and comparing algorithm performance on graph instances is challenging for multiple reasons. First, there is not always a standard set of instances to benchmark performance. Second, using existing graph generators results in a restricted spectrum of difficulty and the resulting graphs are not always diverse enough to draw sound conclusions. That is why recent work proposes a new methodology to generate a diverse set of instances by using evolutionary algorithms . We can then analyze the resulting graphs and get key insights into which attributes are most related to algorithm performance. We can also fill observed gaps in the instance space in order to generate graphs with previously unseen combinations of features. We apply this methodology to the instance space of the Hamiltonian completion problem using two different solvers, namely the Concorde TSP Solver and a multi-start local search algorithm .},
  archive      = {J_COR},
  author       = {Thibault Lechien and Jorik Jooken and Patrick De Causmaecker},
  doi          = {10.1016/j.cor.2022.106019},
  journal      = {Computers &amp; Operations Research},
  pages        = {106019},
  shortjournal = {Comput. Oper. Res.},
  title        = {Evolving test instances of the hamiltonian completion problem},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved formulations and new valid inequalities for a
hybrid flow shop problem with time-varying resources and chaining
time-lag. <em>COR</em>, <em>149</em>, 106018. (<a
href="https://doi.org/10.1016/j.cor.2022.106018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes revised and improved mathematical integer formulations for the Hybrid Flow Shop problem under time-varying resources and chaining time-lag constraints. First, we provide a structural classification and a complexity analysis of the tackled problem. Then, we prove the correctness of our novel modeling techniques. To reinforce the formulations, two valid inequalities are developed. The revised formulations are benchmarked, and the results show that the valid inequalities improve significantly the performance. Finally, we propose a hybrid model that outperforms the best formulations and can be applied in an industrial application.},
  archive      = {J_COR},
  author       = {Quoc Nhat Han Tran and Nhan Quy Nguyen and Farouk Yalaoui and Lionel Amodeo and Hicham Chehade},
  doi          = {10.1016/j.cor.2022.106018},
  journal      = {Computers &amp; Operations Research},
  pages        = {106018},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improved formulations and new valid inequalities for a hybrid flow shop problem with time-varying resources and chaining time-lag},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A variable neighborhood search-based algorithm with adaptive
local search for the vehicle routing problem with time windows and
multi-depots aiming for vehicle fleet reduction. <em>COR</em>,
<em>149</em>, 106016. (<a
href="https://doi.org/10.1016/j.cor.2022.106016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the Multi-Depot Vehicle Routing Problem with Time Windows with the minimization of the number of used vehicles, denominated as MDVRPTW*. This problem is a variant of the classical MDVRPTW, which only minimizes the total traveled distance. We developed an algorithm named Smart General Variable Neighborhood Search with Adaptive Local Search (SGVNSALS) to solve this problem, and, for comparison purposes, we also implemented a Smart General Variable Neighborhood Search (SGVNS) and a General Variable Neighborhood Search (GVNS) algorithms. The SGVNSALS algorithm alternates the local search engine between two different strategies. In the first strategy, the Randomized Variable Neighborhood Descent method (RVND) performs the local search, and, when applying this strategy, most successful neighborhoods receive a higher score. In the second strategy, the local search method is applied only in a single neighborhood, chosen by a roulette method. Thus, the application of the first local search strategy serves as a learning method for applying the second strategy. To test these algorithms, we use benchmark instances from MDVRPTW involving up to 960 customers, 12 depots, and 120 vehicles. The results show SGVNSALS performance surpassed both SGVNS and GVNS concerning the number of used vehicles and covered distance. As there are no algorithms in the literature dealing with MDVRPTW*, we compared the results from SGVNSALS with those of the best-known solutions concerning these instances for MDVRPTW, where the objective is only to minimize the total distance covered. The results showed that the proposed algorithm reduced the vehicle fleet by 91.18\% of the evaluated instances, and the fleet size achieved an average reduction of up to 23.32\%. However, there was an average increase of up to 31.48\% in total distance traveled in these instances. Finally, the article evaluated the contribution of each neighborhood to the local search and shaking operations of the algorithm, allowing the identification of the neighborhoods that most contribute to a better exploration of the solution space of the problem.},
  archive      = {J_COR},
  author       = {Sinaide Nunes Bezerra and Marcone Jamilson Freitas Souza and Sérgio Ricardo de Souza},
  doi          = {10.1016/j.cor.2022.106016},
  journal      = {Computers &amp; Operations Research},
  pages        = {106016},
  shortjournal = {Comput. Oper. Res.},
  title        = {A variable neighborhood search-based algorithm with adaptive local search for the vehicle routing problem with time windows and multi-depots aiming for vehicle fleet reduction},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unrelated parallel machine scheduling with multiple time
windows: An application to earth observation satellite scheduling.
<em>COR</em>, <em>149</em>, 106010. (<a
href="https://doi.org/10.1016/j.cor.2022.106010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a variant of the unrelated parallel machine scheduling problem with multiple time windows that is widely employed in the scheduling of earth observation satellites. Two mixed-integer linear programming formulations are proposed based on the concept of non-immediate precedence and the deep analysis of the relationship of time windows. To facilitate the problem solving, we develop a bidirectional rolling horizon preprocessing algorithm to reduce the problem size. Based on detailed overlapping analysis, more inequalities are obtained to tighten the formulations. Furthermore, the dominance among derived inequalities is analyzed, and only nondominated inequalities are appended to limit the size of the problem. The proposed formulation and algorithm can optimally solve instances of up to 800 jobs and 20 machines within 20 min. Moreover, to verify the practicality of our method, we also conducted numerous experiments on realistic instances of satellite scheduling. The experimental results prove that our algorithm is effective for obtaining optimal solutions and can be applied in practice.},
  archive      = {J_COR},
  author       = {Jianjiang Wang and Guopeng Song and Zhe Liang and Erik Demeulemeester and Xuejun Hu and Jin Liu},
  doi          = {10.1016/j.cor.2022.106010},
  journal      = {Computers &amp; Operations Research},
  pages        = {106010},
  shortjournal = {Comput. Oper. Res.},
  title        = {Unrelated parallel machine scheduling with multiple time windows: An application to earth observation satellite scheduling},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unrelated parallel machine scheduling with eligibility
constraints and delivery times to minimize total weighted tardiness.
<em>COR</em>, <em>149</em>, 105999. (<a
href="https://doi.org/10.1016/j.cor.2022.105999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses an unrelated parallel machine scheduling problem with job-machine-dependent delivery times and eligibility constraints motivated by a distributed manufacturing environment. The objective is total weighted tardiness minimization. We present a mixed integer linear programming (MILP) formulation and conduct an analysis of the scheduling problem to derive precedence properties that can be integrated in local search procedures to increase computational efficiency. We implement a variable neighborhood search (VNS) algorithm for the problem at hand and examine the effect of integrating the properties on the performance. The tests show that the theoretical findings can reduce computational effort significantly. Furthermore, we propose another heuristic approach based on the Apparent Tardiness Cost rule and a memetic biased random-key genetic algorithm. In experiments, we compare the MILP and (meta-)heuristics on a large set of randomly generated problem instances. The VNS procedure outperforms the other algorithms.},
  archive      = {J_COR},
  author       = {Söhnke Maecker and Liji Shen and Lars Mönch},
  doi          = {10.1016/j.cor.2022.105999},
  journal      = {Computers &amp; Operations Research},
  pages        = {105999},
  shortjournal = {Comput. Oper. Res.},
  title        = {Unrelated parallel machine scheduling with eligibility constraints and delivery times to minimize total weighted tardiness},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective loading in combined vehicle routing and container
loading problems. <em>COR</em>, <em>149</em>, 105988. (<a
href="https://doi.org/10.1016/j.cor.2022.105988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses more effective loading within the 3L-VRPTW, which is a combination of the vehicle routing problem with time windows and 3D loading constraints. We use a hybrid algorithm consisting of an outer Adaptive Large Neighborhood Search tackling the routing problem in combination with an inner Deepest-Bottom-Left-Fill algorithm solving the container loading problem. We propose and compare three new variants for the Deepest-Bottom-Left-Fill algorithm which differ in the representation and storage of available possible placement positions and the shift of items. The possible placement positions can be determined either by available points so that (1) a non-overlapping check between the items is necessary, (2) by available free spaces, or (3) by using a Rectangle Tree (RTree), where items and their positions are stored in a tree. For computational studies, two well-known instance sets are used. The algorithms are evaluated and compared concerning their solution quality and performance. Hereby, the algorithm with free spaces receives the best results with the smallest runtime. Moreover, the impact of different loading constraints is analyzed showing that the LIFO and minimal supporting area constraints have significant effects on the total travel distance. Several new best solutions were found. All results are validated and published at GitHub.},
  archive      = {J_COR},
  author       = {Corinna Krebs and Jan Fabian Ehmke and Henriette Koch},
  doi          = {10.1016/j.cor.2022.105988},
  journal      = {Computers &amp; Operations Research},
  pages        = {105988},
  shortjournal = {Comput. Oper. Res.},
  title        = {Effective loading in combined vehicle routing and container loading problems},
  volume       = {149},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
