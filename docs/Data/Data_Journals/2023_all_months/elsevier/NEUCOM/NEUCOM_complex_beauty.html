<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NEUCOM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="neucom---961">NEUCOM - 961</h2>
<ul>
<li><details>
<summary>
(2023). Multi-modal deep convolutional dictionary learning for image
denoising. <em>NEUCOM</em>, <em>562</em>, 126918. (<a
href="https://doi.org/10.1016/j.neucom.2023.126918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging the capabilities of traditional dictionary learning (DicL) and drawing upon the success of deep neural networks (DNNs), the recently proposed framework of deep convolutional dictionary learning (DCDicL) has exhibited remarkable behaviours in image denoising . Note that, the application of the DCDicL method is confined to single modality scenarios, whereas the images in practice often originate from diverse modalities. In this paper, to broaden the application scope of the DCDicL method, we design a multi-modal version of it, dubbed MMDCDicL. Specifically, within the mathematical model of MMDCDicL, we adopt an analytical approach to tackle the sub-problem linked to the guidance modality, harnessing its inherent reliability. Meanwhile, like in DCDicL, we utilize a network-based learning approach for the noisy modality to extract trustworthy information from the data. Based on the solution, we establish an interpretable network structure for MMDCDicL. Additionally, wherein, we design a multi-kernel channel attention block (MKCAB) in the structure to efficiently integrate the information from diverse modalities. Experimental results suggest that MMDCDicL can reconstruct higher-quality outcomes both quantitatively and perceptually. Code is available at http://www.diplab.net/lunwen/mmdcdicl.htm .},
  archive      = {J_NEUCOM},
  author       = {Zhonggui Sun and Mingzhu Zhang and Huichao Sun and Jie Li and Tingting Liu and Xinbo Gao},
  doi          = {10.1016/j.neucom.2023.126918},
  journal      = {Neurocomputing},
  pages        = {126918},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal deep convolutional dictionary learning for image denoising},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A semantically enhanced dual encoder for aspect sentiment
triplet extraction. <em>NEUCOM</em>, <em>562</em>, 126917. (<a
href="https://doi.org/10.1016/j.neucom.2023.126917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect sentiment triplet extraction (ASTE) is a crucial subtask of aspect-based sentiment analysis (ABSA) that aims to comprehensively identify sentiment triplets. Previous research has focused on enhancing ASTE through innovative table-filling strategies. However, these approaches often overlook the multi-perspective nature of language expressions, resulting in a loss of valuable interaction information between aspects and opinions. To address this limitation, we propose a framework that leverages both a basic encoder, primarily based on BERT , and a particular encoder comprising a Bi-LSTM network and graph convolutional network (GCN). The basic encoder captures the surface-level semantics of linguistic expressions, while the particular encoder extracts deeper semantics, including syntactic and lexical information. By modeling the dependency tree of comments and considering the part-of-speech and positional information of words, we aim to capture semantics that are more relevant to the underlying intentions of the sentences. An interaction strategy combines the semantics learned by the two encoders, enabling the fusion of multiple perspectives and facilitating a more comprehensive understanding of aspect–opinion relationships. Experiments conducted on benchmark datasets demonstrate the state-of-the-art performance of our proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Baoxing Jiang and Shehui Liang and Peiyu Liu and Kaifang Dong and Hongye Li},
  doi          = {10.1016/j.neucom.2023.126917},
  journal      = {Neurocomputing},
  pages        = {126917},
  shortjournal = {Neurocomputing},
  title        = {A semantically enhanced dual encoder for aspect sentiment triplet extraction},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPAR: An efficient self-attention network using switching
partition strategy for skeleton-based action recognition.
<em>NEUCOM</em>, <em>562</em>, 126915. (<a
href="https://doi.org/10.1016/j.neucom.2023.126915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCN) have become the mainstream in skeleton-based action recognition. For further performance improvement, existing methods propose to utilize self-attention to model long-range features of joints. However, these methods cannot balance accuracy with computational efficiency. In this paper, we propose the Switching Partition Strategy (SPAR) Network that uses the self-attention mechanism for the simultaneous and efficient extraction of spatial–temporal long-range information from the skeleton. We design two partition strategies that reduce the computational cost and improve the efficiency of the computation of self-attention. Extensive experiments are conducted on two large-scale datasets, i.e. NTU RGB+D 60 and NTU RGB+D 120, to evaluate the performance of the proposed SPAR network. The results demonstrate that our method outperforms the state-of-the-art on accuracy as well as computational cost.},
  archive      = {J_NEUCOM},
  author       = {ZiJie Zhu and RenDong Ying and Fei Wen and PeiLin Liu},
  doi          = {10.1016/j.neucom.2023.126915},
  journal      = {Neurocomputing},
  pages        = {126915},
  shortjournal = {Neurocomputing},
  title        = {SPAR: An efficient self-attention network using switching partition strategy for skeleton-based action recognition},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weed mapping in multispectral drone imagery using
lightweight vision transformers. <em>NEUCOM</em>, <em>562</em>, 126914.
(<a href="https://doi.org/10.1016/j.neucom.2023.126914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In precision agriculture, non-invasive remote sensing can be used to observe crops and weeds in visible and non-visible spectra. This paper proposes a novel approach for weed mapping using lightweight Vision Transformers . The method uses a lightweight Transformer architecture to process high-resolution aerial images obtained from drones and performs semantic segmentation to distinguish between crops and weeds. The method also employs specific architectural designs to enable transfer learning from RGB weights in a multispectral setting. For this purpose, the WeedMap dataset, acquired by drones equipped with multispectral cameras, was used. The experimental results demonstrate the effectiveness of the proposed method, exceeding the state-of-the-art. Our approach also enables more efficient mapping, allowing farmers to quickly and easily identify infested areas and prioritize their control efforts. These results encourage using drones as versatile computer vision flying devices for herbicide management, thereby improving crop yields. The code is available at https://github.com/pasqualedem/LWViTs-for-weedmapping .},
  archive      = {J_NEUCOM},
  author       = {Giovanna Castellano and Pasquale De Marinis and Gennaro Vessio},
  doi          = {10.1016/j.neucom.2023.126914},
  journal      = {Neurocomputing},
  pages        = {126914},
  shortjournal = {Neurocomputing},
  title        = {Weed mapping in multispectral drone imagery using lightweight vision transformers},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Event-triggered formation-containment control for
multi-agent systems based on sliding mode control approaches.
<em>NEUCOM</em>, <em>562</em>, 126905. (<a
href="https://doi.org/10.1016/j.neucom.2023.126905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, event-triggered (ET) formation-containment control is profoundly investigated for discrete-time multi-agent systems (DT-MASs) in the framework of sliding mode control (SMC). The ET mechanism is utilized to effectively relieve the communication burden and SMC is employed to reliably handle the matching disturbances to enhance the control performance. According to this task, a novel ET controller based on SMC is constructed to ensure that a desired formation shape (i.e. a convex hull) is definitely formed by all leaders, and involves the trajectories of all followers. Then, sufficient conditions to solve the desired controller settings are deduced with the aid of the feature of Laplacian matrices as well as some essential inequality techniques. Furthermore, the reachability of constructed sliding surfaces is systematically revealed and the predetermined manifold is reachable in finite time. Finally, the efficiency of the designed control rule is verified with simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Mingming Zhang and Ying Sun and Hongjian Liu and Xiaojian Yi and Derui Ding},
  doi          = {10.1016/j.neucom.2023.126905},
  journal      = {Neurocomputing},
  pages        = {126905},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered formation-containment control for multi-agent systems based on sliding mode control approaches},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of graph neural networks for electroencephalography
data analysis. <em>NEUCOM</em>, <em>562</em>, 126901. (<a
href="https://doi.org/10.1016/j.neucom.2023.126901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) sensors are flexible and non-invasive sensoring devices for the measurement of electrical brain activity which is extensively used in some areas of clinical practice and psychological/psychiatric research, such as epilepsy, sleep, emotion, and brain computer interfaces . Although EEG sensor do not provide actual brain localizations of the activity sources, they allow to study brain functional connectivity . In this paper we review current application of a specific family of computational methods, the Graph Neural Networks (GNN) to the analysis of EEG data. GNNs appear to be well suited to EEG data modeling as they deal with signals whose domain is defined by a graph instead of a regular lattice in Euclidean space. Readings of EEG electrodes fall in this category, hence the increasing research activity on the application of GNNs to EEG data.},
  archive      = {J_NEUCOM},
  author       = {Manuel Graña and Igone Morais-Quilez},
  doi          = {10.1016/j.neucom.2023.126901},
  journal      = {Neurocomputing},
  pages        = {126901},
  shortjournal = {Neurocomputing},
  title        = {A review of graph neural networks for electroencephalography data analysis},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The graph embedded topic model. <em>NEUCOM</em>,
<em>562</em>, 126900. (<a
href="https://doi.org/10.1016/j.neucom.2023.126900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of existing graph neural networks (GNNs) developed for the prevalent text-rich networks typically treat texts as node attributes. This kind of approach unavoidably results in the loss of important semantic structures and restricts the representational power of GNNs. In this work, we introduce a document similarity-based graph convolutional network (DS-GCN) encoder to combine graph topologies and document semantics for text-rich network representation. Then, a graph decoder , based on the latent position model, is used to reconstruct the graph while preserving the network topology . The document matrix is rebuilt by a document decoder , based on the embedded topic model, which considers both topic and word embeddings . By including a cluster membership variable for each node in the network, we thus develop an end-to-end clustering technique relying on a new deep probabilistic model called the graph embedded topic model (GETM). Numerical experiments on three simulated scenarios emphasize the ability of GETM in fusing the graph topology structure and the document embeddings , and highlight its node clustering performance. Moreover, an application on the Cora-enrich citation network is conducted to demonstrate the effectiveness and interest of GETM in practice.},
  archive      = {J_NEUCOM},
  author       = {Dingge Liang and Marco Corneli and Charles Bouveyron and Pierre Latouche},
  doi          = {10.1016/j.neucom.2023.126900},
  journal      = {Neurocomputing},
  pages        = {126900},
  shortjournal = {Neurocomputing},
  title        = {The graph embedded topic model},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network-based sliding mode controllers applied to
robot manipulators: A review. <em>NEUCOM</em>, <em>562</em>, 126896. (<a
href="https://doi.org/10.1016/j.neucom.2023.126896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, numerous attempts have been made to integrate sliding mode control (SMC) and neural networks (NN) in order to leverage the advantages of both methods while mitigating their respective disadvantages. These endeavors have yielded significant achievements, leading to diverse applications in enhancing control performance for nonlinear objects, including robots. This paper primarily focuses on investigating critical technical research issues, potential applications, and future perspectives of SMC based on NNs when applied to robot manipulators. Firstly, a comprehensive examination is conducted to assess the advantages, disadvantages, and potential applications of SMC and its various variants. Secondly, recent advancements in control systems have introduced NNs as a promising innovation. NNs offer an alternative approach to adaptive learning and control, effectively addressing the technical challenges associated with SMCs. Finally, the assessment of these combined approaches&#39; advantages and limitations is based on studies conducted over the last few decades, along with their future development directions.},
  archive      = {J_NEUCOM},
  author       = {Thanh Nguyen Truong and Anh Tuan Vo and Hee-Jun Kang},
  doi          = {10.1016/j.neucom.2023.126896},
  journal      = {Neurocomputing},
  pages        = {126896},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based sliding mode controllers applied to robot manipulators: A review},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GPro3D: Deriving 3D BBox from ground plane in monocular 3D
object detection. <em>NEUCOM</em>, <em>562</em>, 126894. (<a
href="https://doi.org/10.1016/j.neucom.2023.126894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the inherent ill-posed nature, monocular 3D object detection (M3OD) is extremely challenging. The ground plane prior is a highly informative geometry clue in M3OD. However, it has been neglected by most mainstream methods. This paper introduces an original M3OD framework that leverages the ground plane to directly derive the object’s 3D Bounding Box (BBox) and 3D attributes geometrically. We identify and tackle three key factors that limit the applicability of the ground plane: the projection point localization issue, the ground plane tilt issue, and the lack of ground plane annotation issue. For the projection point localization issue, we propose leveraging the car’s explicit and salient wheel pixels, which are easier for the neural network to detect compared to the bottom vertices or the bottom center of the 3D BBox. To tackle the ground plane tilt problem, we propose a vertical-edge-enhanced horizon line detection algorithm to precisely deduce the ground plane equation. Moreover, using only M3OD labels, wheel pixel and horizon line pseudo-labels can be easily generated to train the network without extra data or annotation cost. Extensive experiments demonstrate the effectiveness and superiority of our framework over previous methods.},
  archive      = {J_NEUCOM},
  author       = {Fan Yang and Xinhao Xu and Hui Chen and Yuchen Guo and Yuwei He and Kai Ni and Guiguang Ding},
  doi          = {10.1016/j.neucom.2023.126894},
  journal      = {Neurocomputing},
  pages        = {126894},
  shortjournal = {Neurocomputing},
  title        = {GPro3D: Deriving 3D BBox from ground plane in monocular 3D object detection},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tuning n-ary relation extraction as machine reading
comprehension. <em>NEUCOM</em>, <em>562</em>, 126893. (<a
href="https://doi.org/10.1016/j.neucom.2023.126893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with conventional binary relation extraction, n n -ary relation extraction is a particularly challenging task due to the presence of multiple entities that span across sentences. Although current methods have achieved remarkable results in this area, they often rely on complex modeling like dependency parsing , which easily suffers from error propagation. To address this predicament, this paper proposes a novel framework for n n -ary relation extraction that utilizes Machine Reading Comprehension (MRC) as its foundation. In particular, considering the unnameable relations or sub-relations between multiple entities, we resort to learning continuous prompting questions to make up for the deficiency of natural language questions. Additionally, to alleviate the high semantic similarity between close relation classes, we obtain supplementary prompt messages (i.e., additional knowledge) according to the statistical results for each relation class so as to equip the model with a better capacity to make distinctions. Finally, since the one-turn mechanism of MRC is prone to mistakes, especially in those challenging n n -ary tasks, we design a double-check mechanism that generates questions from multi-perspective to ascertain the final relation between all the entities by aggregating the answers to all questions. Our method has demonstrated the most advanced results on n n -ary relation extraction datasets through extensive experimentation.},
  archive      = {J_NEUCOM},
  author       = {Pengrui Ren and Tianyu Xu and Jianfeng Qu and Yu Sang and Zhixu Li and Junhua Fang and Pengpeng Zhao and Guilin Ma},
  doi          = {10.1016/j.neucom.2023.126893},
  journal      = {Neurocomputing},
  pages        = {126893},
  shortjournal = {Neurocomputing},
  title        = {Tuning N-ary relation extraction as machine reading comprehension},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). MOCPSO: A multi-objective cooperative particle swarm
optimization algorithm with dual search strategies. <em>NEUCOM</em>,
<em>562</em>, 126892. (<a
href="https://doi.org/10.1016/j.neucom.2023.126892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is a widely embraced meta-heuristic approach to tackling the complexities of multi-objective optimization problems (MOPs), renowned for its simplicity and swift convergence. However, when faced with large-scale multi-objective optimization problems (LSMOPs), most PSOs suffer from limited local search capabilities and insufficient randomness. This can result in suboptimal results, particularly in high-dimensional spaces. To address these issues, this paper introduces MOCPSO, a Multi-Objective Cooperative Particle Swarm Optimization Algorithm with Dual Search Strategies. MOCPSO incorporates a diversity search strategy (DSS) to augment perturbation and enhance the local search scope of particles, alongside a more convergent search strategy (CSS) to expedite particle convergence. Moreover, MOCPSO utilizes a three-category framework to effectively leverage the benefits of both DSS and CSS. Experimental results on benchmark LSMOPs with 500, 1000, and 2000 decision variables demonstrate that MOCPSO outperforms existing state-of-the-art large-scale multi-objective evolutionary algorithms on most test instances.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhang and Bingdong Li and Wenjing Hong and Aimin Zhou},
  doi          = {10.1016/j.neucom.2023.126892},
  journal      = {Neurocomputing},
  pages        = {126892},
  shortjournal = {Neurocomputing},
  title        = {MOCPSO: A multi-objective cooperative particle swarm optimization algorithm with dual search strategies},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A class of improved fractional physics informed neural
networks. <em>NEUCOM</em>, <em>562</em>, 126890. (<a
href="https://doi.org/10.1016/j.neucom.2023.126890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics informed neural networks (PINNs) are a type of deep learning framework which can use the knowledge of physical laws to facilitate the learning of various forward and inverse problems . PINNs have displayed significant efficiency in numerical computation, but there are still some limitations such as their inability in tackling differential equations with oscillations or singular perturbation. To alleviate this difficulty, a new deep learning framework called improved fractional physics informed neural networks (IFPINNs) is proposed in this paper. Compared to PINNs, the calculation in the weight propagation between layers is replaced with nonlinear functions rather than linear ones. This new architecture allows for a better usage of physical information of differential equations, thus leading to an improved fitting quality for the cases with high oscillations or singular perturbation. Under certain conditions, IFPINNs can be degenerated into PINNs. Moreover, this paper investigates the performance of IFPINNs in dealing with fractional differential equations with time-fractional orders ranging from 1 to 2. The numerical results demonstrate the proposed architecture can achieve a higher accuracy for various integral and fractional differential equations.},
  archive      = {J_NEUCOM},
  author       = {Hongpeng Ren and Xiangyun Meng and Rongrong Liu and Jian Hou and Yongguang Yu},
  doi          = {10.1016/j.neucom.2023.126890},
  journal      = {Neurocomputing},
  pages        = {126890},
  shortjournal = {Neurocomputing},
  title        = {A class of improved fractional physics informed neural networks},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). QDRJL: Quaternion dynamic representation with joint learning
neural network for heart sound signal abnormal detection.
<em>NEUCOM</em>, <em>562</em>, 126889. (<a
href="https://doi.org/10.1016/j.neucom.2023.126889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, deep learning based heart sound diagnosis algorithms are mostly complex and large models for high accuracy, which are difficult to deploy on mobile devices due to the high number of parameters and large computational cost. The current mainstream approach for processing heart sound signals involves utilizing their Mel-frequency cepstral coefficients (MFCC) features. However, most existing methods have overlooked the multi-channel characteristics of MFCC. To address this issue, we propose a Quaternion Dynamic Representation with Joint Learning (QDRJL) neural network for learning MFCC multi-channel features. Our proposed approach combines quaternion dynamic convolution with dynamic weighting and the Quaternion Interior Learning Block (QILB). Finally, we present a global and energy joint learning branch for jointly learning MFCC features. The success of the proposed quaternion network depends on its ability to utilize the internal relations between quaternion-valued input features and the definition of the dynamic weight variables in the augmented quaternion domain. We assessed various state-of-the-art classification algorithms for detecting heart sounds and found that our proposed classifier achieved an accuracy of up to 97.2\%, outperforming existing models. Our experimental evaluation, using the 2016 PhysioNet/CinC Challenge dataset, revealed that our model could reduce the number of network parameters to 25\% due to quaternion properties.},
  archive      = {J_NEUCOM},
  author       = {Lihong Qiao and Zhixiang Li and Bin Xiao and Yucheng Shu and Li Wang and Yuhang Shi and Weisheng Li and Xinbo Gao},
  doi          = {10.1016/j.neucom.2023.126889},
  journal      = {Neurocomputing},
  pages        = {126889},
  shortjournal = {Neurocomputing},
  title        = {QDRJL: Quaternion dynamic representation with joint learning neural network for heart sound signal abnormal detection},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Directly-trained spiking neural networks for deep
reinforcement learning: Energy efficient implementation of event-based
obstacle avoidance on a neuromorphic accelerator. <em>NEUCOM</em>,
<em>562</em>, 126885. (<a
href="https://doi.org/10.1016/j.neucom.2023.126885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNN) promise extremely low-power and low-latency inference on neuromorphic hardware. Recent studies demonstrate the competitive performance of SNNs compared with Artificial Neural Networks (ANN) in conventional classification tasks . In this work, we present an energy-efficient implementation of a Reinforcement Learning (RL) algorithm using SNNs to solve an obstacle avoidance task performed by an Unmanned Aerial Vehicle (UAV), taking a Dynamic Vision Sensor (DVS) as event-based input. We train the SNN directly, improving upon state-of-art implementations based on hybrid (not directly trained) SNNs. For this purpose, we devise an adaptation of the Spatio-Temporal Backpropagation algorithm (STBP) for RL. We then compare the SNN with a state-of-art Convolutional Neural Network (CNN) designed to solve the same task. To this aim, we train both networks by exploiting a photorealistic training pipeline based on AirSim. To achieve a realistic latency and throughput assessment for embedded deployment, we designed and trained three different embedded SNN versions to be executed on state-of-art neuromorphic hardware, targeting state-of-the-art. We compared SNN and CNN in terms of obstacle avoidance performance showing that the SNN algorithm achieves better results than the CNN with a factor of 6 × × less energy. We also characterize the different SNN hardware implementations in terms of energy and spiking activity.},
  archive      = {J_NEUCOM},
  author       = {Luca Zanatta and Alfio Di Mauro and Francesco Barchi and Andrea Bartolini and Luca Benini and Andrea Acquaviva},
  doi          = {10.1016/j.neucom.2023.126885},
  journal      = {Neurocomputing},
  pages        = {126885},
  shortjournal = {Neurocomputing},
  title        = {Directly-trained spiking neural networks for deep reinforcement learning: Energy efficient implementation of event-based obstacle avoidance on a neuromorphic accelerator},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Role of locality, fidelity and symmetry regularization in
learning explainable representations. <em>NEUCOM</em>, <em>562</em>,
126884. (<a href="https://doi.org/10.1016/j.neucom.2023.126884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their success deep neural networks still lack interpretability and are regarded as black boxes. This hampers a wider adoption in applications with societal, environmental or economical implications, and motivated a variety of techniques for explaining their outputs. Such explanations are however typically produced after model training so there is no guarantee that models learn faithful attributions, a goal they were not trained for. We evaluate the impact of different penalty terms in the loss function that promote explainable feature attributions, and that can be learned during training in an unsupervised way. We show that explainability-constrained models produce better saliency maps based on multiple metrics and tests. Regularizers imposing locality , fidelity and symmetry properties lead to the best performances in terms of MoRF and ROAR scores.},
  archive      = {J_NEUCOM},
  author       = {Michele Ronco and Gustau Camps-Valls},
  doi          = {10.1016/j.neucom.2023.126884},
  journal      = {Neurocomputing},
  pages        = {126884},
  shortjournal = {Neurocomputing},
  title        = {Role of locality, fidelity and symmetry regularization in learning explainable representations},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward extracting and exploiting generalizable knowledge of
deep 2D transformations in computer vision. <em>NEUCOM</em>,
<em>562</em>, 126882. (<a
href="https://doi.org/10.1016/j.neucom.2023.126882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep learning models suffer from out-of-distribution ( o.o.d. ) performance drop in computer vision tasks . In comparison, humans have a remarkable ability to interpret images, even if the scenes in the images are rare, thanks to the generalizability of acquired knowledge. This work attempts to answer two research questions: (1) the acquisition and (2) the utilization of generalizable knowledge about 2D transformations. To answer the first question, we demonstrate that deep neural networks can learn generalizable knowledge with a new training methodology based on synthetic datasets . The generalizability is reflected in the results that, even when the knowledge is learned from random noise, the networks can still achieve stable performance in parameter estimation tasks. To answer the second question, a novel architecture called “InterpretNet” is devised to utilize the learned knowledge in image classification tasks. The architecture consists of an estimator and an identifier , in addition to a classifier . By emulating the “hypothesis-verification” process in human visual perception, our InterpretNet improves classification accuracy by 21.1\%.},
  archive      = {J_NEUCOM},
  author       = {Jiachen Kang and Wenjing Jia and Xiangjian He},
  doi          = {10.1016/j.neucom.2023.126882},
  journal      = {Neurocomputing},
  pages        = {126882},
  shortjournal = {Neurocomputing},
  title        = {Toward extracting and exploiting generalizable knowledge of deep 2D transformations in computer vision},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning in news recommender systems: A comprehensive
survey, challenges and future trends. <em>NEUCOM</em>, <em>562</em>,
126881. (<a href="https://doi.org/10.1016/j.neucom.2023.126881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, people prefer to read news articles from online sources worldwide due to their easiness and availability. For the last few years, online searching for required information or content has been replaced by item recommendation, and news recommendation is also not an exception. For news recommendations, News Recommender System (NRS) helps the users to find the appropriate and pertinent content, alleviate the problem of information overload, and propose news that would be of interest to news readers. NRS also assists different users all around the world in this regard by recommending the most recent news articles based on their interests and past preferences. Many techniques such as traditional, Deep Learning (DL), and hybrid have been proposed to solve the NRS challenges and issues. DL techniques are considered one of the best techniques and have been successfully applied in various fields such as Natural Language Processing (NLP) and Computer Vision (CV). This survey article provides a detailed analysis of DL models-based techniques to build NRS. In this regard, firstly, a comprehensive comparison is provided between published survey articles on NRS and this research work. Secondly, it discusses the background of recommendation systems and their techniques. Furthermore, NRS is explored along with its current research challenges. Then background knowledge of DL and its methods have been discussed along with the analysis of year-wise published relevant articles having DL as the applied technique. The survey also presents widely used datasets and performance evaluation metrics used in the relevant literature. Finally, a detailed discussion provides several future directions and open research challenges for the researchers to consider DL applications in NRS.},
  archive      = {J_NEUCOM},
  author       = {Mian Muhammad Talha and Hikmat Ullah Khan and Saqib Iqbal and Mohammed Alghobiri and Tassawar Iqbal and Muhammad Fayyaz},
  doi          = {10.1016/j.neucom.2023.126881},
  journal      = {Neurocomputing},
  pages        = {126881},
  shortjournal = {Neurocomputing},
  title        = {Deep learning in news recommender systems: A comprehensive survey, challenges and future trends},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Neighborhood contrastive representation learning for
attributed graph clustering. <em>NEUCOM</em>, <em>562</em>, 126880. (<a
href="https://doi.org/10.1016/j.neucom.2023.126880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed graph clustering is a fundamental task in graph learning field. Because of the high-dimensional node features and the complex non-Euclidean graph structure, it is challenging for attributed graph clustering methods to exploit graph information . Recent studies on graph contrastive learning (GCL) have achieved promising results. However, existing GCL-based methods neither consider a clustering-friendly node representation nor a clustering-oriented loss function, resulting in inferior performance. To this end, we propose NCAGC, a neighborhood contrastive representation learning method for attributed graph clustering task . Specifically, NCAGC constrains the representation learning of similar nodes by a neighborhood contrast module to ensure the compactness in the latent space, thus facilitating the clustering task . Meanwhile, a contrastive self-expression module is present for learning a discriminative self-expression coefficient matrix , which is crucial for the subsequent subspace clustering. Moreover, the two designed modules are trained and optimized jointly, which benefits the node representation learning and clustering to achieve mutual refinement. Extensive experimental results on four attributed graph datasets demonstrate the superiority of NCAGC compared with 16 state-of-the-art methods, which surpasses the sub-optimal method on Cora dataset by 2.1\%, 4.3\%, and 3.7\% in terms of ACC, NMI, and ARI , respectively. Our code and dataset is available at https://github.com/wangtong627/NCAGC-NeuroCom .},
  archive      = {J_NEUCOM},
  author       = {Tong Wang and Junhua Wu and Yaolei Qi and Xiaoming Qi and Juwei Guan and Yuan Zhang and Guanyu Yang},
  doi          = {10.1016/j.neucom.2023.126880},
  journal      = {Neurocomputing},
  pages        = {126880},
  shortjournal = {Neurocomputing},
  title        = {Neighborhood contrastive representation learning for attributed graph clustering},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computationally efficient neural hybrid automaton framework
for learning complex dynamics. <em>NEUCOM</em>, <em>562</em>, 126879.
(<a href="https://doi.org/10.1016/j.neucom.2023.126879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a computationally efficient and effective data-driven modeling framework for dynamical systems . The proposed modeling framework employs a collection of shallow neural networks known as Extreme Learning Machines (ELMs) to model local system behaviors along with data-driven inferred transitions among local models to establish a neural hybrid automaton model. First, the sampled system inputs are mapped to the corresponding feature spaces to obtain data-driven partitions, which subsequently define the transitions and invariants of the neural hybrid automaton model through a novel data-driven mode clustering process . Then, a collection of ELMs are trained to approximate the local dynamics. The learning processes integrate a segmented data merging procedure for location identification and a local dynamics modeling process. The proposed neural hybrid automaton models can capture behaviors of complex dynamical systems with high modeling precision but significantly lower computational complexities in computationally expensive tasks such as training and verification, which are traditionally considered to be computationally expensive tasks for neural network models. A computationally efficient set-valued reachability analysis method which is commonly used in safety verification is then developed based on interval analysis and a novel Split and Combine process. Finally, applications to modeling the limit cycle and human handwritten motions are presented to show the effectiveness and efficiency of our approach.},
  archive      = {J_NEUCOM},
  author       = {Tao Wang and Yejiang Yang and Weiming Xiang},
  doi          = {10.1016/j.neucom.2023.126879},
  journal      = {Neurocomputing},
  pages        = {126879},
  shortjournal = {Neurocomputing},
  title        = {Computationally efficient neural hybrid automaton framework for learning complex dynamics},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid SVM and kernel function-based sparse representation
classification for automated epilepsy detection in EEG signals.
<em>NEUCOM</em>, <em>562</em>, 126874. (<a
href="https://doi.org/10.1016/j.neucom.2023.126874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic epilepsy detection based on electroencephalography (EEG) is crucial for advancing the diagnosis and treatment of epilepsy . In this paper, we propose a novel classification algorithm called SVM-KSRC, which differs from integrated learning approaches. The algorithm establishes a connection between support vector machine (SVM) and kernel sparse representation classification (KSRC) using support vectors. Specifically, we extract two types of features from the pre-processed EEG signals in this study. During the training phase, these features are utilized to train the SVM model and construct the kernel sparse representation dictionary. We differentiate the SVM part of the features of the test data to determine whether SVM or KSRC should be employed for classifying the test data. Our method is evaluated on two publicly available datasets: University of Bonn dataset and Neurology and Sleep Centre-New Delhi dataset. Through 10 times 10-fold cross validation, our method demonstrates superior performance in epilepsy detection when compared to existing machine learning methods. The experimental results demonstrate that SVM-KSRC is more effective compared to SVM and KSRC used separately. It achieves over 99\% accuracy in all binary classification tasks and attains 100\% accuracy in certain tasks. The source code is publicly available at https://github.com/Walkeraaa/SVM-KSRC .},
  archive      = {J_NEUCOM},
  author       = {Quanhong Wang and Weizhuang Kong and Jitao Zhong and Zhengyang Shan and Juan Wang and Xiaowei Li and Hong Peng and Bin Hu},
  doi          = {10.1016/j.neucom.2023.126874},
  journal      = {Neurocomputing},
  pages        = {126874},
  shortjournal = {Neurocomputing},
  title        = {A hybrid SVM and kernel function-based sparse representation classification for automated epilepsy detection in EEG signals},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying critical nodes via link equations and deep
reinforcement learning. <em>NEUCOM</em>, <em>562</em>, 126871. (<a
href="https://doi.org/10.1016/j.neucom.2023.126871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying an optimal set of nodes that can maximize the spread of influence in a network is a crucial challenge in network science. It has numerous applications such as epidemic control and rumor containment. However, most existing techniques are limited by their high computational costs, making them impractical for graphs with millions of nodes. Moreover, the previous approaches have primarily focused on the structural characteristics of the network while the characteristics of information diffusion are ignored. This paper proposes a deep reinforcement learning framework, DeepELE, to bridge these gaps. DeepELE incorporates a graph embedding technique to represent the graph states and applies a deep reinforcement learning method to learn the policy automatically. Note that we assess the contribution of links to spreading processes and further account for the diffusion-related contribution along with the graph structure information into convolutional neural and the Q network. Extensive experiments on both synthetic and real-world networks validate the efficiency and efficacy of DeepELE. The results demonstrate that DeepELE significantly outperforms the state-of-the-art methods, especially for large-scale networks with millions of nodes.},
  archive      = {J_NEUCOM},
  author       = {Peiyu Chen and Wenhui Fan},
  doi          = {10.1016/j.neucom.2023.126871},
  journal      = {Neurocomputing},
  pages        = {126871},
  shortjournal = {Neurocomputing},
  title        = {Identifying critical nodes via link equations and deep reinforcement learning},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FABSA: An aspect-based sentiment analysis dataset of user
reviews. <em>NEUCOM</em>, <em>562</em>, 126867. (<a
href="https://doi.org/10.1016/j.neucom.2023.126867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) aims at automatically extracting aspects of entities and classifying the polarity of each extracted aspect. The majority of available ABSA systems heavily rely on manually annotated datasets to train supervised machine learning models. However, the development of such manually curated datasets is a labour-intensive process and therefore existing ABSA datasets cover only a few domains and they are limited in size. In response, we present FABSA (Feedback ABSA), a new large-scale and multi-domain ABSA dataset of feedback reviews. FABSA consists of approximately 10,500 reviews which span across 10 domains. We conduct a number of experiments to evaluate the performance of state-of-the-art deep learning models when applied to the FABSA dataset. Our results demonstrate that ABSA models can generalise across different domains when trained on our FABSA dataset while the performance of the models is enhanced when using a larger training dataset. Our FABSA dataset is publicly available. 1},
  archive      = {J_NEUCOM},
  author       = {Georgios Kontonatsios and Jordan Clive and Georgia Harrison and Thomas Metcalfe and Patrycja Sliwiak and Hassan Tahir and Aji Ghose},
  doi          = {10.1016/j.neucom.2023.126867},
  journal      = {Neurocomputing},
  pages        = {126867},
  shortjournal = {Neurocomputing},
  title        = {FABSA: An aspect-based sentiment analysis dataset of user reviews},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating reinforcement learning with deterministic
learning for fault diagnosis of nonlinear systems. <em>NEUCOM</em>,
<em>562</em>, 126847. (<a
href="https://doi.org/10.1016/j.neucom.2023.126847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable fault diagnosis (FD) is important to ensure safety in nonlinear engineering systems. Modern engineering systems are often subject to unknown complex nonlinearities and varying operation conditions, therefore, one of the main challenges for FD of nonlinear systems is the robustness against these uncertainties. In this paper, a novel robust FD approach combining the reinforcement learning (RL) and the deterministic learning theory (DLT) is developed for a class of discrete-time nonlinear systems . The DLT is employed to pre-train the neural network (NN) aiming at approximating the unknown nonlinear complexity and obtaining dynamical fault models, then RL techniques are employed to adapt the NN parameters to improve the robustness of fault models. The stability of the learning process is rigorously analyzed using Lyapunov-based methods, and the effectiveness of the presented method is validated by a rotating stall warning experiment based on the data from Beihang University compressor test rig. Experiment results demonstrate that compared with other methods, the proposed method can achieve better performance in lead warning time and robustness.},
  archive      = {J_NEUCOM},
  author       = {Zejian Zhu and Weiming Wu and Tianrui Chen and Jingtao Hu and Cong Wang},
  doi          = {10.1016/j.neucom.2023.126847},
  journal      = {Neurocomputing},
  pages        = {126847},
  shortjournal = {Neurocomputing},
  title        = {Integrating reinforcement learning with deterministic learning for fault diagnosis of nonlinear systems},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing the confidence of deep learning classifiers via
interpretable saliency maps. <em>NEUCOM</em>, <em>562</em>, 126825. (<a
href="https://doi.org/10.1016/j.neucom.2023.126825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper quantifies the quality of heatmap-based eXplainable AI (XAI) methods w.r.t image classification problem. Here, a heatmap is considered desirable if it improves the probability of predicting the correct classes. Different XAI heatmap-based methods are empirically shown to improve classification confidence to different extents depending on the datasets, e.g. Saliency works best on ImageNet and Deconvolution on Chest X-ray Pneumonia dataset. The novelty includes a new gap distribution that shows a stark difference between correct and wrong predictions. Finally, the generative augmentative explanation is introduced, a method to generate heatmaps capable of improving predictive confidence to a high level.},
  archive      = {J_NEUCOM},
  author       = {Erico Tjoa and Hong Jing Khok and Tushar Chouhan and Cuntai Guan},
  doi          = {10.1016/j.neucom.2023.126825},
  journal      = {Neurocomputing},
  pages        = {126825},
  shortjournal = {Neurocomputing},
  title        = {Enhancing the confidence of deep learning classifiers via interpretable saliency maps},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid weight quantization strategy for memristive neural
networks. <em>NEUCOM</em>, <em>562</em>, 126778. (<a
href="https://doi.org/10.1016/j.neucom.2023.126778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the ability to store data and process information, the memristor-based neuromorphic system has attracted extensive attention. Its efficient parallel computing approach allows it to implement neural networks in hardware. However, due to the limitation of the range of memristor conductance, it is difficult to represent high-precision weights in memristive neural network. During the off-chip learning, it is crucial to find an efficient weight quantization scheme and map it to the memristor array. Therefore, a hybrid weight quantization strategy that combines uniform and non-uniform quantization is proposed to overcome these problems. Specifically, the curve fitting of pulse modulation for tantalum oxide-based memristor is carried out, and the mapping rules of weights are proposed to simplify the process of reading verification. Furthermore, the hybrid quantization strategy is proposed and applied to a multilayer perceptron and a convolutional neural network, respectively. The effectiveness and robustness of the hybrid quantization scheme are verified in the MNIST dataset. Experiments show that the proposed hybrid quantization scheme can achieve 99.26\% accuracy at 4 bits and tolerate 20\% noise interference. The simulation results in this paper also provide an effective solution for the hardware implementation of memristive neural networks .},
  archive      = {J_NEUCOM},
  author       = {Siyuan Shen and Shukai Duan and Lidan Wang},
  doi          = {10.1016/j.neucom.2023.126778},
  journal      = {Neurocomputing},
  pages        = {126778},
  shortjournal = {Neurocomputing},
  title        = {A hybrid weight quantization strategy for memristive neural networks},
  volume       = {562},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Methods to balance the exploration and exploitation in
differential evolution from different scales: A survey. <em>NEUCOM</em>,
<em>561</em>, 126899. (<a
href="https://doi.org/10.1016/j.neucom.2023.126899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the evolutionary process in nature, Differential Evolution (DE) has been widely concerned and used as a numerical global optimizer for decades of years, since its emerging in 1997. However, the performance of DE essentially depends on the balance of its exploration ability and exploitation ability. To better summarize the recent works on DE, especially from 2019 to 2023, this paper analysed the balancing strategies from different scales, including from the algorithm level, the operator level and the parameter level. And then, all of the recent works are categorized and discussed according to different scales. From the algorithm level, the hybridizing methods of DE are mainly reviewed. For the evolution operators, both the enhanced operators and operator selection strategies are introduced. And for the parameters of DE, mainly different adaptation controlling strategies are summarized. The main purpose of this paper is to give an update summary of DE research and review these works on exploration–exploitation balancing from different scales.},
  archive      = {J_NEUCOM},
  author       = {Yanyun Zhang and Guanyu Chen and Li Cheng and Quanyu Wang and Qi Li},
  doi          = {10.1016/j.neucom.2023.126899},
  journal      = {Neurocomputing},
  pages        = {126899},
  shortjournal = {Neurocomputing},
  title        = {Methods to balance the exploration and exploitation in differential evolution from different scales: A survey},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advances in teaching–learning-based optimization algorithm:
A comprehensive survey(ICIC2022). <em>NEUCOM</em>, <em>561</em>, 126898.
(<a href="https://doi.org/10.1016/j.neucom.2023.126898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teaching-learning-based optimization (TLBO) algorithm which imitates the teaching–learning process in a classroom, is one of population-based heuristic stochastic swarm intelligent algorithms. TLBO executes through similar iterative evolution processes as utilized by a standard evolutionary algorithm . Unlike traditional evolutionary algorithms and swarm intelligent algorithms, the iterative computation process of teaching–learning-based optimization is divided into two phases and each phase executes iterative learning operation. In this paper, we present a comprehensive survey on the recent advances in TLBO. A review of the current literature reveals intriguing challenges and suggests potential future research directions.},
  archive      = {J_NEUCOM},
  author       = {Guo Zhou and Yongquan Zhou and Wu Deng and Shihong Yin and Yunhui Zhang},
  doi          = {10.1016/j.neucom.2023.126898},
  journal      = {Neurocomputing},
  pages        = {126898},
  shortjournal = {Neurocomputing},
  title        = {Advances in teaching–learning-based optimization algorithm: A comprehensive survey(ICIC2022)},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of secure federated learning: Privacy leakage
threats, protection technologies, challenges and future directions.
<em>NEUCOM</em>, <em>561</em>, 126897. (<a
href="https://doi.org/10.1016/j.neucom.2023.126897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in the new generation of Internet of Things (IoT) technology are propelling the growth of intelligent industrial applications worldwide. Simultaneously, widespread adoption of artificial intelligence (AI) technologies, such as machine and deep learning, is accelerating. Traditional machine learning models rely heavily on massive amounts of data, however collecting and processing massive amounts of data generated by network-edge devices is costly and inefficient, and poses serious risks to data privacy. As a new paradigm for statistical model training in distributed edge networks, federated learning (FL) enables data to participate in federated model training without being localized. This approach can be used to solve traditional machine learning problems of low data utilization, data privacy, and information security caused by data isolation. However, the defects of the FL framework and insecure network environments cause many security and privacy leakage problems in actual application scenarios of FL. First, the concepts, classifications, and fundamental FL principles were described. Second, the mainstream privacy security issues and classification of FL were investigated. Privacy security protection techniques for FL were then identified. Finally, challenges and future research directions for the development of FL privacy security are discussed.},
  archive      = {J_NEUCOM},
  author       = {Lina Ge and Haiao Li and Xiao Wang and Zhe Wang},
  doi          = {10.1016/j.neucom.2023.126897},
  journal      = {Neurocomputing},
  pages        = {126897},
  shortjournal = {Neurocomputing},
  title        = {A review of secure federated learning: Privacy leakage threats, protection technologies, challenges and future directions},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of artificial intelligence approaches in blind
source separation. <em>NEUCOM</em>, <em>561</em>, 126895. (<a
href="https://doi.org/10.1016/j.neucom.2023.126895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In various signal processing applications , such as audio signal recovery, the extraction of desired signals from a mixture of other signals is a crucial task. To achieve superior performance and efficiency in separator systems, extensive research has been conducted. Blind source separation emerges as a relevant technique to address the challenge of separating and reconstructing unknown signals when only observations of their mixtures are available to end-users. Blind source separation involves retrieving a set of independent source signals mixed by an unknown and potentially destructive combining system. Notably, the separation process in blind source separation frameworks solely relies on observing the mixed sources without prior knowledge of the mixing algorithm or the source signal characteristics. The significance of blind source separation has garnered substantial attention, and its numerous applications have been demonstrated, which serves as the primary motivation for conducting this comprehensive study. This paper presents a systematic literature survey of blind source separation, encompassing existing methods, approaches, and applications, with a particular focus on artificial intelligence-based frameworks. Through a thorough review and examination, this work sheds light on the diverse techniques utilized in blind source separation and their performance in real-world scenarios. The study identifies research gaps in the current literature, highlighting areas that warrant further investigation and improvement. Moreover, potential avenues for future research are outlined to contribute to the ongoing development of blind source separation techniques.},
  archive      = {J_NEUCOM},
  author       = {Sam Ansari and Abbas Saad Alatrany and Khawla A. Alnajjar and Tarek Khater and Soliman Mahmoud and Dhiya Al-Jumeily and Abir Jaafar Hussain},
  doi          = {10.1016/j.neucom.2023.126895},
  journal      = {Neurocomputing},
  pages        = {126895},
  shortjournal = {Neurocomputing},
  title        = {A survey of artificial intelligence approaches in blind source separation},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable machine learning assessment. <em>NEUCOM</em>,
<em>561</em>, 126891. (<a
href="https://doi.org/10.1016/j.neucom.2023.126891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the surge of machine learning in AI and data science, there remains an urgent need to not only compare the performance of different methods across diverse datasets but also to analyze machine learning behaviors with sensitivity using an explainable approach. In this study, we introduce a uniquely designed diagnostic index: d-index to tackle this challenge. This tool integrates classification effectiveness from multiple dimensions, delivering a transparent and comprehensive assessment that transcends the limitations of traditional evaluation methods in classification. We propose two innovative concepts: breakeven states and imbalanced points in this study. Integrated with the d-index, these concepts afford a more profound understanding of the learning behaviors across different machine learning models compared to the existing classification metrics. Significantly, the d-index excels as a powerful tool, identifying learning singularity problems (LSPs) that remain elusive to most current machine learning models and imbalanced learning techniques. Furthermore, leveraging the d-index, we unravel the mechanisms behind imbalanced point generation in binary and multiclass classification . We also put forth a novel technique: identifying a priori informative kernels to optimize support vector machine learning, ensuring outstanding d-index values with the fewest necessary support vectors. Moreover, we address a seldom-discussed state of overfitting in deep learning , where overfitting occurs despite the training and testing loss curves exhibiting favorable trends throughout the epochs. To the best of our knowledge, this work represents a pioneering stride in the realm of explainable machine learning assessments and will inspire further studies in this area.},
  archive      = {J_NEUCOM},
  author       = {Henry Han and Yi Wu and Jiacun Wang and Ashley Han},
  doi          = {10.1016/j.neucom.2023.126891},
  journal      = {Neurocomputing},
  pages        = {126891},
  shortjournal = {Neurocomputing},
  title        = {Interpretable machine learning assessment},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leader–follower consensus control for a class of nonlinear
multi-agent systems using dynamical neural networks. <em>NEUCOM</em>,
<em>561</em>, 126888. (<a
href="https://doi.org/10.1016/j.neucom.2023.126888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the formation consensus tracking control problem of uncertain dynamical multi-agent system with nonlinear dynamics based on a leader–follower configuration based on a undirected communication topology. The control design is based on a novel combination of consensus protocols and dynamical neural networks , known as differential neural networks , to approximate the modeling uncertainties and external disturbances of the follower agents. The proposed controller-identifier structure forces the state of each agent to maintain a formation with respect to the leader ensuring limited residual errors . The stability proof supports the control design and guarantees the multi-agent system states to be ultimately bounded. In order to show the effectiveness of the proposed tracking controller and the superior performance against the static RBFNNs approach, some simulation results are presented considering a multi-robotic system with five agents following a helical three-dimensional reference signal of a virtual leader.},
  archive      = {J_NEUCOM},
  author       = {Filiberto Muñoz and José Manuel Valdovinos and Jorge Said Cervantes-Rojas and Sergio Salazar Cruz and Alejandro Morfín Santana},
  doi          = {10.1016/j.neucom.2023.126888},
  journal      = {Neurocomputing},
  pages        = {126888},
  shortjournal = {Neurocomputing},
  title        = {Leader–follower consensus control for a class of nonlinear multi-agent systems using dynamical neural networks},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dissimilarity-based indicator graph learning for clustering.
<em>NEUCOM</em>, <em>561</em>, 126887. (<a
href="https://doi.org/10.1016/j.neucom.2023.126887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although learning a similarity graph with a 0–1 value is regarded as an important issue for clustering tasks , this topic has been scarcely reported in the literature since its NP-hard. Along these lines, this issue is addressed in the work by introducing a novel concept. Concretely, the indicator graph clustering (IGC) method was proposed. Based on the dissimilarity and coordinate descent method, IGC is able to learn an indicator graph with a 0–1 value, which is just the similarity graph with a 0–1 value. Meanwhile, the clustering result can be directly obtained by the indicator graph. From the experimental results on several datasets, it was verified that IGC performs faster than k-means, especially on high-dimensional datasets. Furthermore, IGC was extended to a multi-view version, named indicator graph clustering for multi-view (IGCMV). Our model fused the clustering indicator matrices from different views, which can be obtained by IGC, into the final clustering indicator matrix by a projection matrix . To the best of our knowledge, this work is the first attempt to learn a consensus indicator graph from indicator graphs of all views. In addition different from most of the existing multi-view clustering algorithms , the proposed IGCMV enables the production of the final clustering result , as well as each view’s clustering result simultaneously. This is helpful for measuring the quality of each view. IGCMV can be efficiently optimized by an alternative iteration strategy. Extensive experiments were also carried out on several benchmark multi-view datasets demonstrating the effectiveness of the developed algorithm to the state-of-the-art multi-view clustering algorithms .},
  archive      = {J_NEUCOM},
  author       = {Lin Yuan and Xiaofei Yang and Yingcang Ma and Xiaolong Xin},
  doi          = {10.1016/j.neucom.2023.126887},
  journal      = {Neurocomputing},
  pages        = {126887},
  shortjournal = {Neurocomputing},
  title        = {Dissimilarity-based indicator graph learning for clustering},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous and discrete gradient-zhang neuronet (GZN) with
analyses for time-variant overdetermined linear equation system solving
as well as mobile localization applications. <em>NEUCOM</em>,
<em>561</em>, 126883. (<a
href="https://doi.org/10.1016/j.neucom.2023.126883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel continuous gradient-Zhang neuronet (GZN) model and three discrete GZN algorithms are proposed to solve time-variant overdetermined linear equation system (TVOLES) problems, and are developed on the basis of a gradient neuronet and Zhang neuronet. Specifically, the continuous GZN model is proposed and derived in the form of an explicit-dynamic equation, and its stability is analysed and proven using Lyapunov theory . To ensure that the problems can be solved and implemented on digital platforms , three discrete GZN algorithms are established by using three different discretization formulas. The numerical simulative results verify that, compared with the Zhang neuronet model, gradient neuronet model and variant-parameter neuronet model, the proposed continuous GZN model converges faster in some cases. Other computer experiments further substantiate that the proposed continuous model and its corresponding discrete GZN algorithms are effective and efficient. Finally, the proposed discrete GZN algorithms are applied to mobile object localizations, and the simulative results verify their applicability and effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Zanyu Tang and Yunong Zhang},
  doi          = {10.1016/j.neucom.2023.126883},
  journal      = {Neurocomputing},
  pages        = {126883},
  shortjournal = {Neurocomputing},
  title        = {Continuous and discrete gradient-zhang neuronet (GZN) with analyses for time-variant overdetermined linear equation system solving as well as mobile localization applications},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Dialog generation model based on variational bayesian
knowledge retrieval method. <em>NEUCOM</em>, <em>561</em>, 126878. (<a
href="https://doi.org/10.1016/j.neucom.2023.126878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For dialog generation models that introduce external knowledge, the key challenge lies in how to select the relevant knowledge. The existing common method is to directly use a retriever to fetch knowledge according to the prior distribution that is only conditioned on dialog history . In fact, the response also contains crucial information that is helpful for knowledge retrieval. If we can make use of it and conduct posterior retrieval of relevant knowledge according to both dialog history and response, the selected knowledge will be more relevant to the dialog. Therefore, this paper proposes a dialog generation model (DG-VBKR) based on variational Bayesian knowledge retrieval method , which consists of two modules: knowledge retrieval and dialog generation. During the training process, both a prior knowledge retriever and a posterior knowledge retriever are trained simultaneously, and the prior knowledge retriever is guided by the posterior knowledge retriever. Specifically, the KL Divergence is used to measure the difference between the retrieval results of the two retrievers and make the trained prior knowledge retriever achieve a similar effect to the posterior knowledge retriever. In addition, this paper constructs four versions of the proposed model by using GPT-2, BART, Transformer Decoder TransformerDecoder , and Transformer Enc−Dec TransformerEnc−Dec in dialog generation module. The experimental results show that the DG-VBKR model achieves certain improvements on several metrics compared to the baseline models . Among them, the GPT-2 version model with the best performance has improved by 7.0\% on the PPL metric compared with the model using only prior knowledge retrieval. This indicates that the DG-VBKR model can effectively select knowledge related to the dialog to generate high-quality responses.},
  archive      = {J_NEUCOM},
  author       = {Chun Liu and Baoqing Wang and Yuqiang Li},
  doi          = {10.1016/j.neucom.2023.126878},
  journal      = {Neurocomputing},
  pages        = {126878},
  shortjournal = {Neurocomputing},
  title        = {Dialog generation model based on variational bayesian knowledge retrieval method},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). IFRN: Insensitive feature removal network for zero-shot
mechanical fault diagnosis across fault severity. <em>NEUCOM</em>,
<em>561</em>, 126877. (<a
href="https://doi.org/10.1016/j.neucom.2023.126877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning is a promising technique for diagnosing mechanical faults in complex and uncertain environments. However, when diagnosing mechanical faults across different severities using zero-shot learning, the impact of insensitive features should be minimized due to the susceptibility of zero-shot prototypes and the vulnerability of vibration signals . To accomplish this, an Insensitive Feature Removal Network (IFRN) with an entire attention mechanism (EAM) module and a denoise autoencoder module is proposed to remove insensitive features hierarchically by dividing them into two categories: common insensitive features (CIF) and private insensitive features (PIF), each with different properties depending on their corresponding sub-labels presence in mechanical faults. Concretely, EAM removes insensitive features that the classifier cannot differentiate with the help of the entire attention weight comparison by attention generation, attention comparison, and attention limitation parts. Then, the denoise autoencoder module with long short memory term (LSTM) is utilized to remove the insensitive features that are not completely removed, especially for the insensitive features that independently arise. The IFRN’s effectiveness is demonstrated through comparative experiments and ablation studies using the Case Western Reserve University (CWRU) dataset, where the experimental result shows that IFRN outperforms conventional zero-shot learning methods. Furthermore, an analysis with prototype distance and sample aggregation is presented to further justify the effectiveness of the proposed method in reducing the prototype shift and improving classification accuracy by removing insensitive features.},
  archive      = {J_NEUCOM},
  author       = {Ziqi Liu and Rui Yang and Weibo Liu and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2023.126877},
  journal      = {Neurocomputing},
  pages        = {126877},
  shortjournal = {Neurocomputing},
  title        = {IFRN: Insensitive feature removal network for zero-shot mechanical fault diagnosis across fault severity},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boundary-guided part reasoning network for human parsing.
<em>NEUCOM</em>, <em>561</em>, 126876. (<a
href="https://doi.org/10.1016/j.neucom.2023.126876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of human parsing aims to segment the human body into different semantic regions. Despite advancements in this field, there are still two issues with current works: boundary indistinction and parsing inconsistency. In this paper, we investigate how to utilize structural information and auxiliary information to jointly solve the above two problems. Drawing inspiration from Transformer architecture, a Boundary-guided Part Reasoning Network (BPRNet) is proposed to combine edge information and associated semantics of body parts for human parsing. Specifically, we design a part representation module to represent human body parts as part features. Based on the Transformer decoder, a multi-head self-attention is used to capture the semantic correlation between the human body. Moreover, we propose a boundary-guided module consisting of absolute boundary attention and reinforced boundary attention. They take advantage of edge information and multi-scale image features to jointly constrain cross-attention to extract global features. Experiments and corresponding results on three public datasets show that the proposed method performs favorably against the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zhuo Su and Huiqiang Guan and Yuntian Lai and Fan Zhou and Yun Liang},
  doi          = {10.1016/j.neucom.2023.126876},
  journal      = {Neurocomputing},
  pages        = {126876},
  shortjournal = {Neurocomputing},
  title        = {Boundary-guided part reasoning network for human parsing},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed data-driven iterative learning point-to-point
consensus tracking control for unknown nonlinear multi-agent systems.
<em>NEUCOM</em>, <em>561</em>, 126875. (<a
href="https://doi.org/10.1016/j.neucom.2023.126875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the point-to-point consensus tracking problem for a class of nonlinear non-affine multi-agent systems, where the tracking target is a series of some given ideal output points rather than a complete ideal trajectory. For the unknown nonlinear dynamics of every agent, the relationship between its control input and the corresponding output signal at these given points is acquired, then a data-driven model is constructed based on adjacent-agent dynamic linearization technology. Furthermore, by optimizing two performance index functions, we design a novel point-to-point iterative learning tracking control scheme, which not only ensures the consensus tracking results of all agents only utilizing the I/O data of every agent at the given ideal output points, but also makes all agents reach consensus behavior at the rest of the time instants. The effectiveness of our algorithm is confirmed through rigorous theoretical analysis and two experimental simulations.},
  archive      = {J_NEUCOM},
  author       = {Mengdan Liang and Junmin Li},
  doi          = {10.1016/j.neucom.2023.126875},
  journal      = {Neurocomputing},
  pages        = {126875},
  shortjournal = {Neurocomputing},
  title        = {Distributed data-driven iterative learning point-to-point consensus tracking control for unknown nonlinear multi-agent systems},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Direct side information learning for zero-shot regression.
<em>NEUCOM</em>, <em>561</em>, 126873. (<a
href="https://doi.org/10.1016/j.neucom.2023.126873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning provides models for targets for which instances are not available, commonly called unobserved targets. The availability of target side information becomes crucial in this context in order to properly induce models for these targets. The literature is plenty of strategies to cope with this scenario, but specifically designed on the basis of a zero-shot classification scenario, mostly in computer vision and image classification , but they are either not applicable or easily extensible for a zero-shot regression framework for which a continuous value is required to be predicted rather than a label. In fact, there is a considerable lack of methods for zero-shot regression in the literature. Two approaches for zero-shot regression that work in a two-phase procedure were recently proposed. They first learn the observed target models through a classical regression learning ignoring the target side information. Then, they aggregate those observed target models afterwards exploiting the target side information and the models for the unobserved targets are induced. Despite both have shown quite good performance because of the different treatment they grant to the common features and to the side information, they exploit features and side information separately, avoiding a global optimization for providing the unobserved target models. The proposal of this paper is a novel method that jointly takes features and side information in a one-phase learning process, but treating side information properly and in a more deserving way than as common features. A specific kernel that properly merges features and side information is proposed for this purpose resulting in a novel approach that exhibits better performance over both artificial and real datasets.},
  archive      = {J_NEUCOM},
  author       = {Miriam Fdez-Díaz and Elena Montañés and José Ramón Quevedo},
  doi          = {10.1016/j.neucom.2023.126873},
  journal      = {Neurocomputing},
  pages        = {126873},
  shortjournal = {Neurocomputing},
  title        = {Direct side information learning for zero-shot regression},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Random forest feature selection for partial label learning.
<em>NEUCOM</em>, <em>561</em>, 126870. (<a
href="https://doi.org/10.1016/j.neucom.2023.126870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Label Learning (PLL) aims to induce a multi-class classifier to deal with the problem that each training instance is associated with a set of candidate labels, among which only one is valid but unknown. Feature selection, which choses some features related to the task (e.g., classification) and omits the unrelated ones, is challenging for PLL due to the ambiguous labeling information. In this paper, a random forest based method, namely, RFUTE, is developed to deal with the feature selection challenge in PLL. Due to the fact that the ground-truth labels are inaccessible in the training process, RFUTE first disambiguates the candidate labels, and then operates feature selection by calculating and sorting the total change of information entropy over all trees in the forest for all features. More importantly, a supplement approach is proposed after disambiguation to avoid the class imbalance problem . Comprehensive experiments over both synthetic and real-world partial label data sets empirically justify the effectiveness of RFUTE in improving the generalization performance of well-established PLL methods.},
  archive      = {J_NEUCOM},
  author       = {Xianran Sun and Jing Chai},
  doi          = {10.1016/j.neucom.2023.126870},
  journal      = {Neurocomputing},
  pages        = {126870},
  shortjournal = {Neurocomputing},
  title        = {Random forest feature selection for partial label learning},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pseudo dense counterfactual augmentation for aspect-based
sentiment analysis. <em>NEUCOM</em>, <em>561</em>, 126869. (<a
href="https://doi.org/10.1016/j.neucom.2023.126869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) is a fine-grained text classification task , and the cutting-edge ABSA models have achieved outstanding performance. Unfortunately, the robustness of these ABSA models is neglected. ABSA models must face numerous challenges to be robust, and we concentrate on one of these challenges caused by negation words, such as “not”, “un-”. In the actual context, these negation words intuitively result in two problems: negative sensitivity and spurious correlation. First, a negation word tends to reverse the sentiment polarity of a sentence. Meanwhile, in the ABSA datasets, most sentences containing negation words express Negative polarities, which will lead the predictive model to learn the spurious correlation between negation words and polarities. To resolve these ambiguous issues, we are inspired by causal inference and propose a novel data augmentation framework, namely Pseudo Dense Counterfactual Augmentation (PDC aug ) for ABSA. Specifically, we initialize a pseudo sequence and employ a multi-head multi-layer attention network to achieve counterfactual augmentation for a vanilla sentence in the hidden space. This pseudo sequence will be adversarially trained. PDC aug is a plug-and-play method for various ABSA models, so we evaluate it on discriminative models and generative prompt-based models. Our extensive experiments show that our PDC aug can significantly and consistently outperform several data augmentation methods and ABSA models.},
  archive      = {J_NEUCOM},
  author       = {Jihong Ouyang and Shi Feng and Bing Wang and Zhiyao Yang},
  doi          = {10.1016/j.neucom.2023.126869},
  journal      = {Neurocomputing},
  pages        = {126869},
  shortjournal = {Neurocomputing},
  title        = {Pseudo dense counterfactual augmentation for aspect-based sentiment analysis},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of multimodal emotion recognition from datasets,
preprocessing, features, and fusion methods. <em>NEUCOM</em>,
<em>561</em>, 126866. (<a
href="https://doi.org/10.1016/j.neucom.2023.126866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective computing is one of the most important research fields in modern human–computer interaction (HCI). The goal of affective computing is to study and develop the theories, methods, and systems that can recognize, explain, process, and simulate human emotions. As a branch of affective computing, emotion recognition aims to enlighten the machine/computer automatically analyzing human emotions, which has received increasing attention from researchers in various fields. Human beings generally observe and understand the emotional states of one person by integrating the perceived information from his/her facial expressions, voice tone, speech content, behavior , or physiological features. To imitate the emotion observation manner of humans, researchers have been devoted to constructing multimodal emotion recognition models by fusing information from two or more modalities. In this paper, we provide a comprehensive review of multimodal emotion recognition from the perspectives of multimodal datasets, data preprocessing , unimodal feature extraction, and multimodal information fusion methods in recent decades. Furthermore, challenges and future research directions of the topic are specified and discussed. The main motivations of this review are to conclude the recent emergence of abundant works on multimodal emotion recognition and to provide potential guidance to researchers in the related field for understanding the pipeline and mainstream approaches to multimodal emotion recognition.},
  archive      = {J_NEUCOM},
  author       = {Bei Pan and Kaoru Hirota and Zhiyang Jia and Yaping Dai},
  doi          = {10.1016/j.neucom.2023.126866},
  journal      = {Neurocomputing},
  pages        = {126866},
  shortjournal = {Neurocomputing},
  title        = {A review of multimodal emotion recognition from datasets, preprocessing, features, and fusion methods},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network adaptive observer design for nonlinear
systems with partially and completely unknown dynamics subject to
variable sampled and delay output measurement. <em>NEUCOM</em>,
<em>561</em>, 126865. (<a
href="https://doi.org/10.1016/j.neucom.2023.126865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel Neural Network Adaptive Observer (NNAO) for Nonlinear Systems with Partially and Completely Unknown Dynamics (NSPCUD), subject to variable sampled and delayed output. The method involves designing a neural network observer for partially unknown nonlinear systems with sampled and delayed outputs, using a radial basis function (RBF) neural network to approximate the system’s unknown part. A new weight update algorithm is proposed, along with a closed-loop output predictor for coping with variable samples, and a closed-loop integral compensation to handle variable delay. This approach is then extended to cover completely unknown systems as well. Numerical simulations and comparisons between the proposed method and previous methods on autonomous ground vehicle models were conducted to verify the effectiveness of the proposed NNAO.},
  archive      = {J_NEUCOM},
  author       = {Xincheng Zhuang and Yang Tian and Haoping Wang and Sofiane Ahmed Ali},
  doi          = {10.1016/j.neucom.2023.126865},
  journal      = {Neurocomputing},
  pages        = {126865},
  shortjournal = {Neurocomputing},
  title        = {Neural network adaptive observer design for nonlinear systems with partially and completely unknown dynamics subject to variable sampled and delay output measurement},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time stability of a class of systems and its
application on discontinuous neural networks. <em>NEUCOM</em>,
<em>561</em>, 126852. (<a
href="https://doi.org/10.1016/j.neucom.2023.126852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fixed-time stability of the discontinuous uncertain inertial neural networks (INNs) with distributed delay and time-varying delay. The conditions required by the theorem are less conservative, and fairly accurate settling time (ST) estimation is given under the condition that the derivative of Lyapunov–Krasovskii function is not always less than 0. Then, by using Power-Mean inequality and other inequality techniques, the controller is designed to make the system stable. Finally, two numerical examples are given to show that our results improve the previous ones.},
  archive      = {J_NEUCOM},
  author       = {Yuting Zhang and Yingxin Guo and Chuan Zhang},
  doi          = {10.1016/j.neucom.2023.126852},
  journal      = {Neurocomputing},
  pages        = {126852},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time stability of a class of systems and its application on discontinuous neural networks},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient block contrastive learning via parameter-free
meta-node approximation. <em>NEUCOM</em>, <em>561</em>, 126850. (<a
href="https://doi.org/10.1016/j.neucom.2023.126850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has recently achieved remarkable success in many domains including graphs. However contrastive loss , especially for graphs, requires a large number of negative samples which is unscalable and computationally prohibitive with a quadratic time complexity . Sub-sampling is not optimal. Incorrect negative sampling leads to sampling bias. In this work, we propose a meta-node based approximation technique that is (a) simple, (b) canproxy all negative combinations (c) in quadratic cluster size time complexity, (d) at graph level, not node level, and (e) exploit graph sparsity . By replacing node-pairs with additive cluster-pairs, we compute the negatives in cluster-time at graph level. The resulting Proxy approximated meta-node Contrastive (PamC) loss, based on simple optimized GPU operations, captures the full set of negatives, yet is efficient with a linear time complexity. By avoiding sampling, we effectively eliminate sample bias. We meet the criterion for larger number of samples, thus achieving block-contrastiveness, which is proven to outperform pair-wise losses. We use learnt soft cluster assignments for the meta-node construction, and avoid possible heterophily and noise added during edge creation. Theoretically, we show that real world graphs easily satisfy conditions necessary for our approximation. Empirically, we show promising accuracy gains over state-of-the-art graph clustering on 6 benchmarks. Importantly, we gain substantially in efficiency; over 2x reduction in training time and over 5x in GPU memory reduction. Additionally, our embeddings, combined with a single learnt linear transformation , is sufficient for node classification ; we achieve state-of-the-art on Citeseer classification benchmark. code: https://github.com/gayanku/PAMC},
  archive      = {J_NEUCOM},
  author       = {Gayan K. Kulatilleke and Marius Portmann and Shekhar S. Chandra},
  doi          = {10.1016/j.neucom.2023.126850},
  journal      = {Neurocomputing},
  pages        = {126850},
  shortjournal = {Neurocomputing},
  title        = {Efficient block contrastive learning via parameter-free meta-node approximation},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PP-GNN: Pretraining position-aware graph neural networks
with the NP-hard metric dimension problem. <em>NEUCOM</em>,
<em>561</em>, 126848. (<a
href="https://doi.org/10.1016/j.neucom.2023.126848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On a graph G = ( V , E ) G=(V,E) , we call S ⊂ V S⊂V resolving if ∀ u , v ∈ V ∀u,v∈V with u ≠ v u≠v , ∃ w ∈ V ∃w∈V such that d ( u , w ) ≠ d ( v , w ) . d(u,w)≠d(v,w). The smallest possible cardinality of S S is called the metric dimension, computing which is known to be NP-hard. Solving the metric dimension problem (MDP) and the associated minimal resolving set has many important applications across science and engineering. In this paper, we introduce MaskGNN, a method using a graph neural network (GNN) model to learn the minimal resolving set in a self-supervised manner by optimizing a novel surrogate objective. We provide a construction showing the global minimum of this objective coincides with the solution to the MDP. MaskGNN attains 51\%–72\% improvement over the best baseline and up to 98\% the reward of integer programming in 0.72\% of the running time. On this foundation, we introduce Pretraining Position-aware GNNs (PP-GNN) and evaluate on popular benchmark position-based tasks on graphs. PP-GNN’s strong results challenge the currently popular paradigm – heuristic-driven anchor-selection – with a new learning-based paradigm — simultaneously learning the metric basis of the graph and pretraining position-aware representations for transferring to downstream position-based tasks.},
  archive      = {J_NEUCOM},
  author       = {Michael Sun},
  doi          = {10.1016/j.neucom.2023.126848},
  journal      = {Neurocomputing},
  pages        = {126848},
  shortjournal = {Neurocomputing},
  title        = {PP-GNN: Pretraining position-aware graph neural networks with the NP-hard metric dimension problem},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Enhanced robust fuzzy k-means clustering joint ℓ0-norm
constraint. <em>NEUCOM</em>, <em>561</em>, 126842. (<a
href="https://doi.org/10.1016/j.neucom.2023.126842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an unsupervised classical data processing technique, in which Fuzzy K-Means is extensively researched in practical application owing to its efficiency. However, common outliers in real-world always lead to clustering degradation. In this paper, we design an Enhanced Robust Fuzzy K-Means clustering method (ERFKM) joint ℓ 0 ℓ0 -norm sparse nearest neighbor constraint as a countermeasure to above challenge. On one hand, we adaptively weigh different samples by binary vector to measure each contribution for robustness, among which the outliers can be effectively recognized to eliminate their impact on clustering. That is, the weighted term is able to steadily correct the cumulative drift deviation of cluster centroid via ignoring extremely large sample-centroid residuals from outliers. On the other hand, the fuzzy regularizer with ℓ 0 ℓ0 -norm constraint aims to further enhance the segmentation ability of indicated normal samples through automatic cluster neighbor assignment. Finally, an optimization algorithm for our model is devised to simultaneously update the binary weight of each sample and sparse membership matrix for achieving robust clustering. Comprehensive experiments demonstrate the advantages and effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jingyu Wang and Xinru Zhang and Feiping Nie and Xuelong Li},
  doi          = {10.1016/j.neucom.2023.126842},
  journal      = {Neurocomputing},
  pages        = {126842},
  shortjournal = {Neurocomputing},
  title        = {Enhanced robust fuzzy K-means clustering joint ℓ0-norm constraint},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning fair models without sensitive attributes: A
generative approach. <em>NEUCOM</em>, <em>561</em>, 126841. (<a
href="https://doi.org/10.1016/j.neucom.2023.126841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing fair classifiers rely on sensitive attributes to achieve fairness. However, for many scenarios, we cannot obtain sensitive attributes due to privacy and legal issues. The lack of sensitive attributes challenges many existing fair classifiers. Though we lack sensitive attributes, for many applications, there usually exists features/information of various formats that are relevant to sensitive attributes. For example, a person’s purchase history can reflect his/her race, which would help for learning fair classifiers on race. However, the work on exploring relevant features for learning fair models without sensitive attributes is rather limited. Therefore, in this paper, we study a novel problem of learning fair models without sensitive attributes by exploring relevant features. We propose a probabilistic generative framework to effectively estimate the sensitive attribute from the training data with relevant features in various formats and utilize the estimated sensitive attribute information to learn fair models. Experimental results on real-world datasets show the effectiveness of our framework in terms of both accuracy and fairness. Our source code is available at: https://github.com/huaishengzhu/FairWS .},
  archive      = {J_NEUCOM},
  author       = {Huaisheng Zhu and Enyan Dai and Hui Liu and Suhang Wang},
  doi          = {10.1016/j.neucom.2023.126841},
  journal      = {Neurocomputing},
  pages        = {126841},
  shortjournal = {Neurocomputing},
  title        = {Learning fair models without sensitive attributes: A generative approach},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust ADP-based control for uncertain nonlinear stackelberg
games. <em>NEUCOM</em>, <em>561</em>, 126834. (<a
href="https://doi.org/10.1016/j.neucom.2023.126834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stackelberg games allow players to access system information differently and take actions asynchronously. This paper introduces a robust adaptive dynamic programming-based method to solve the nonlinear two-player Stackelberg game subject to external disturbances. Combined with a neural network identifier, our method is implemented on the actor–critic-disturbance structure to approximate the optimal value function, i.e., the corresponding Stackelberg equilibrium. With the aid of costate, we transform this leader–follower optimization problem into solving two parametric equations and a costate equation. The coefficients of critic approximators and the costate are updated simultaneously to reach the Stackelberg equilibrium. The proposed control method finds real-time approximations of the Stackelberg-Saddle equilibrium while ensuring the closed-loop system’s stability. Finally, the simulation example shows the effectiveness and advantage of our method.},
  archive      = {J_NEUCOM},
  author       = {Lin Yu and Jing Lai and Junlin Xiong and Min Xie},
  doi          = {10.1016/j.neucom.2023.126834},
  journal      = {Neurocomputing},
  pages        = {126834},
  shortjournal = {Neurocomputing},
  title        = {Robust ADP-based control for uncertain nonlinear stackelberg games},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hyper-parameter tuning of physics-informed neural networks:
Application to helmholtz problems. <em>NEUCOM</em>, <em>561</em>,
126826. (<a href="https://doi.org/10.1016/j.neucom.2023.126826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider physics-informed neural networks (PINNs) (Raissiet al., 2019) for forward physical problems. In order to find optimal PINNs configuration, we introduce a hyper-parameter optimization (HPO) procedure via Gaussian processes-based Bayesian optimization. We apply the HPO to Helmholtz equation for bounded domains and conduct a thorough study, focusing on: (i) performance, (ii) the collocation points density r r and (iii) the frequency κ κ , confirming the applicability and necessity of the method. Numerical experiments are performed in two and three dimensions, including comparison to finite element methods .},
  archive      = {J_NEUCOM},
  author       = {Paul Escapil-Inchauspé and Gonzalo A. Ruz},
  doi          = {10.1016/j.neucom.2023.126826},
  journal      = {Neurocomputing},
  pages        = {126826},
  shortjournal = {Neurocomputing},
  title        = {Hyper-parameter tuning of physics-informed neural networks: Application to helmholtz problems},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly supervised semantic segmentation via self-supervised
destruction learning. <em>NEUCOM</em>, <em>561</em>, 126821. (<a
href="https://doi.org/10.1016/j.neucom.2023.126821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, weakly supervised semantic segmentation approaches adopt the Class Activation Map (CAM) to generate the initial attention maps from the standard classification backbone network , with only image-level class labels as training supervision. In this paper, we propose a novel “destruction learning” method via self-supervised manner, producing the CAM attention maps better covering the whole object rather than only the most discriminative regions as previous approaches. Region destruction mechanism is proposed to deliberately “destruct” the global structure in both Mid-Level and Low-Level feature learning following jigsaw puzzle operation, for better local feature extraction of the classification network. Specifically, a Mid-Level Distribution-and-Collection Module is proposed to firstly independently process local patches in parallel and then aggregate them, achieving enhanced local part sensitivity. For low-level “destruction learning”, a Low-Level Destruction Module is proposed to partition the original image into patches and shuffle them randomly to obtain a destructed image, which enforces the network to find weak information from the scattered discriminative small parts. The two destruction modules can be conveniently embedded into arbitrary backbone networks and trained in an end-to-end manner, without any extra annotations. Our proposed method achieves outstanding performance on the PASCAL VOC 2012 dataset ( e.g. , with 69.1\% mIoU on the testing set), which surpasses existing state-of-the-art weakly supervised semantic segmentation methods.},
  archive      = {J_NEUCOM},
  author       = {Jinlong Li and Zequn Jie and Xu Wang and Yu Zhou and Lin Ma and Jianmin Jiang},
  doi          = {10.1016/j.neucom.2023.126821},
  journal      = {Neurocomputing},
  pages        = {126821},
  shortjournal = {Neurocomputing},
  title        = {Weakly supervised semantic segmentation via self-supervised destruction learning},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spherical formation control of mobile target by multi-agent
systems with collision avoidance: A limit-cycle-based design approach.
<em>NEUCOM</em>, <em>561</em>, 126795. (<a
href="https://doi.org/10.1016/j.neucom.2023.126795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the control of spherical formation for multi-agent systems with double-integrator dynamics in three-dimensional space. To achieve the desired formation pattern on a spherical surface, N N agents must be distributed evenly around a target. Based on the information gathered about the target and its immediate neighbors, all agents can either remain stationary or rotate around the target at the same velocity on a spherical surface while the target moves in three-dimensional space. A decoupled control method with limit cycle oscillator characteristics is explored to achieve the desired formation geometric pattern. Accordingly, three subproblems are proposed to achieve the spherical formation more effectively. The first subproblem, target-spherical-surface , requires the agents to converge on a specified spherical surface with the target as its center. The second subproblem, target-circling , requires the agents to follow three prescribed orthometric circular orbits on the spherical surface to avoid collisions while moving. The final subproblem is distributed-adjustment , which involves agents to maintaining a prescribed angular distance from their immediate neighbors while remaining relatively stationary or rotating around the target. By addressing the first two sub-problems simultaneously, the agents can be guided to the desired position. The properties of the limit-cycle-based spherical formation controller are analyzed theoretically, and its effectiveness is demonstrated through numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Peng Bo and Guangming Xie and Fengzhong Qu},
  doi          = {10.1016/j.neucom.2023.126795},
  journal      = {Neurocomputing},
  pages        = {126795},
  shortjournal = {Neurocomputing},
  title        = {Spherical formation control of mobile target by multi-agent systems with collision avoidance: A limit-cycle-based design approach},
  volume       = {561},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On authoritative roles of media over co-evolution of
opinions in two-layer appraisal networks. <em>NEUCOM</em>, <em>560</em>,
126857. (<a href="https://doi.org/10.1016/j.neucom.2023.126857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Media wield the indispensable social power over the public in various contexts, such as political election, and marketing management. In this paper, we propose a novel opinion dynamics via a signed two-layer network with a time scale to model the participation of media in the co-evolution of public opinions and appraisals. We theoretically analyze the roles of media through investigating the topological evolution of strongly connected components (SCCs). We predict that the media play authoritative roles on both opinion bound and co-evolution rate. The maximal opinion convergence state among the media layer and the sink SCCs of individual layer will finally restrict the opinions of individuals in the non-sink SCCs. The faster updates of media’s comments will guide a faster opinion forming process. Besides, we discuss the factors of promoting and suppressing the roles of media, and find that the property of structural balance is significant for media in enhancing their potential to facilitate the public to share the bipartite consensus opinions with media. Our findings witness their sociological meanings in an empirical voting network.},
  archive      = {J_NEUCOM},
  author       = {Yingxuan Nie and Rongrong Kuang and Xiang Li},
  doi          = {10.1016/j.neucom.2023.126857},
  journal      = {Neurocomputing},
  pages        = {126857},
  shortjournal = {Neurocomputing},
  title        = {On authoritative roles of media over co-evolution of opinions in two-layer appraisal networks},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Quasi-synchronization of fractional-order complex-value
neural networks with discontinuous activations. <em>NEUCOM</em>,
<em>560</em>, 126856. (<a
href="https://doi.org/10.1016/j.neucom.2023.126856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, under the framework of Filippov solutions, quasi-synchronization issue of fractional-order complex-valued neural networks (FCNNs) with discontinuous activations and uncertainties is investigated. Firstly, using Laplace transform and the property of Mittag-Leffler function, a novel fractional differential inequality is derived. Then combining the newly constructed inequality with delay feedback control scheme, several quasi-synchronization conditions are obtained for the considered FCNNs by means of non-decomposable method. Eventually, a numerical example is provided to substantiate validation of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Lin Wang and Hong-Li Li and Long Zhang and Cheng Hu and Haijun Jiang},
  doi          = {10.1016/j.neucom.2023.126856},
  journal      = {Neurocomputing},
  pages        = {126856},
  shortjournal = {Neurocomputing},
  title        = {Quasi-synchronization of fractional-order complex-value neural networks with discontinuous activations},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive PI control for h∞ synchronization of multiple
delayed coupled neural networks. <em>NEUCOM</em>, <em>560</em>, 126855.
(<a href="https://doi.org/10.1016/j.neucom.2023.126855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the discussion of H ∞ H∞ synchronization in multiple state and delayed state coupled neural networks through the implementation of two adaptive proportional–integral (PI) controllers. Firstly, we consider two types of coupled neural networks with multi-weights. Subsequently, we formulate H ∞ H∞ synchronization criteria using inequality techniques and Lyapunov functional. Furthermore, we address the H ∞ H∞ synchronization problem for these two networks by employing node-/edge-based adaptive PI controllers. Finally, we validate the effectiveness of the proposed theoretical results through numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Yuting Cao and Linhao Zhao and Qishui Zhong and Song Zhu and Zhenyuan Guo and Shiping Wen},
  doi          = {10.1016/j.neucom.2023.126855},
  journal      = {Neurocomputing},
  pages        = {126855},
  shortjournal = {Neurocomputing},
  title        = {Adaptive PI control for h∞ synchronization of multiple delayed coupled neural networks},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic event-triggered adaptive NN consensus control for
nonlinear multiagent systems with unknown measurement sensitivity.
<em>NEUCOM</em>, <em>560</em>, 126854. (<a
href="https://doi.org/10.1016/j.neucom.2023.126854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the event-triggered adaptive neural network (NN) asymptotic consensus control problem is studied for nonlinear multi-agent systems (MASs) with unknown measurement sensitivity. A new distributed filter is designed to estimate the leader and solve the nondifferential problem of virtual controllers caused by the noncontinuous consensus error. The unknown nonlinear dynamics and measurement sensitivity are handled by using the NN approximators and adaptive estimation method, respectively. To avoid unnecessary data transmissions, a dynamic event-triggered mechanism (DETM) composed of the measurement and control channels is designed. Then based on backstepping technique, an asymptotic consensus controller is obtained. It is proved that the closed-loop signals are all bounded, and the consensus error asymptotically converges to the origin. Finally, to show the effectiveness of the developed control method , we apply the developed control method to multiple unmanned surface vehicles (USVs).},
  archive      = {J_NEUCOM},
  author       = {Jun Zhang and Shaocheng Tong},
  doi          = {10.1016/j.neucom.2023.126854},
  journal      = {Neurocomputing},
  pages        = {126854},
  shortjournal = {Neurocomputing},
  title        = {Dynamic event-triggered adaptive NN consensus control for nonlinear multiagent systems with unknown measurement sensitivity},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GAN-based watermarking for encrypted images in healthcare
scenarios. <em>NEUCOM</em>, <em>560</em>, 126853. (<a
href="https://doi.org/10.1016/j.neucom.2023.126853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it is very common for healthcare professionals or staff to transmit digital data in the form of images over public channels or store it on hard drives or third-party clouds. However, unauthorised users and cloud-service providers may view or abuse these sensitive images. This research proposes a generative adversarial network (GAN)-based watermarking for encrypted images to prevent data leakage in healthcare scenarios. The technique uses a combination of a chaotic map and randomised singular value decomposition (RSVD) to encrypt the image first. Subsequently, a GAN model is developed for watermark generation by hiding multiple marks within an image. Later, the encrypted image is marked by embedding the generated watermark for copyright protection and authentication . This fundamentally solves the problem of copyright violation and privacy leakage of medical data. Experimental results have demonstrated that the proposed method is imperceptible and successfully resists various attacks. The obtained results confirmed the superiority of this method over other techniques, which makes it more suitable for healthcare applications.},
  archive      = {J_NEUCOM},
  author       = {Himanshu Kumar Singh and Naman Baranwal and Kedar Nath Singh and Amit Kumar Singh and Huiyu Zhou},
  doi          = {10.1016/j.neucom.2023.126853},
  journal      = {Neurocomputing},
  pages        = {126853},
  shortjournal = {Neurocomputing},
  title        = {GAN-based watermarking for encrypted images in healthcare scenarios},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed/predefined-time synchronization of memristive neural
networks based on state variable index coefficient. <em>NEUCOM</em>,
<em>560</em>, 126849. (<a
href="https://doi.org/10.1016/j.neucom.2023.126849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper has investigated the fixed/predefined-time synchronization problem of delayed memristive neural networks(DNNs). Firstly, two novel controllers with state variable index coefficient are presented for achieving fixed-time synchronization of driver-response systems. Then, one effective control scheme is proposed out to realize predefined-time synchronization based on the results of fixed-time synchronization. Meanwhile, some conditions are given to direct how to select suitable controllers’ parameters by employing fixed-time and Lyapunov theory . The established control schemes are shown to have simpler structures and may need lower energy. In addition, the settling time of fixed time synchronization has been estimated independently on initial states while predefined-time can be set by user in advance. At last, numerical experiments are conducted to verify the effectiveness of the results.},
  archive      = {J_NEUCOM},
  author       = {Jian Xiao and Yiyin Hu and Zhigang Zeng and Ailong Wu and Shiping Wen},
  doi          = {10.1016/j.neucom.2023.126849},
  journal      = {Neurocomputing},
  pages        = {126849},
  shortjournal = {Neurocomputing},
  title        = {Fixed/predefined-time synchronization of memristive neural networks based on state variable index coefficient},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Group consensus for competitive multiagent systems with
input saturation and intermittent communication using current and
outdated states. <em>NEUCOM</em>, <em>560</em>, 126846. (<a
href="https://doi.org/10.1016/j.neucom.2023.126846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates group consensus control for first-order multi-agent systems (MASs) with input saturation and intermittent communication. A novel class of distributed group consensus protocols is designed by combining current and outdated states of agents, which differs from the standard one using only current states. Sufficient conditions for group consensus are derived for MASs without two conservative assumptions required by previous literature. The proposed protocol can accelerate the convergence speed of MASs by choosing appropriate outdated states. Several examples are provided to illustrate the effectiveness of our results.},
  archive      = {J_NEUCOM},
  author       = {Jiacheng Su and Shi Wang and Yaonan Wang},
  doi          = {10.1016/j.neucom.2023.126846},
  journal      = {Neurocomputing},
  pages        = {126846},
  shortjournal = {Neurocomputing},
  title        = {Group consensus for competitive multiagent systems with input saturation and intermittent communication using current and outdated states},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exponential stability of impulsive conformable
fractional-order nonlinear differential system with time-varying delay
and its applications. <em>NEUCOM</em>, <em>560</em>, 126845. (<a
href="https://doi.org/10.1016/j.neucom.2023.126845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the exponential stability of conformable fractional-order nonlinear differential systems with time-varying delay and impulses. The authors utilize the principle of comparison and the Lyapunov function method to establish sufficient conditions that guarantee the exponential stability of a specific class of conformable fractional-order nonlinear differential systems. These findings extend the existing results on systems with integer-order to a certain extent. Furthermore, the paper considers the effect of impulses in the delayed system, which was not addressed in previous literature The authors also apply the criterion for exponential stability to conformable fractional-order neural networks . Finally, two numerical examples are presented to illustrate the effectiveness of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Shuihong Xiao and Jianli Li},
  doi          = {10.1016/j.neucom.2023.126845},
  journal      = {Neurocomputing},
  pages        = {126845},
  shortjournal = {Neurocomputing},
  title        = {Exponential stability of impulsive conformable fractional-order nonlinear differential system with time-varying delay and its applications},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A distributed strategy for games in euler–lagrange systems
with actuator dead zone. <em>NEUCOM</em>, <em>560</em>, 126844. (<a
href="https://doi.org/10.1016/j.neucom.2023.126844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a distributed Nash equilibrium (NE) seeking problem for games in which the involved players are of Euler–Lagrange (EL) dynamics with actuator dead zone. To find NE of such games, a novel distributed algorithm with a dynamical dead-zone compensator is proposed. The compensating module in this new strategy is regarded as a fast dynamics that rapidly addresses the effect caused by actuator dead-zone characteristic. The other module of this algorithm is a slow optimizer that enables the actions of EL players to approach the NE. Since the designed strategy is a two-time-scale model, semi-global practical asymptotic stability of this strategy can be obtained by utilizing the generalized singular perturbation method. Finally, an electricity market game with six turbine-generator dynamics is utilized to validate the theoretical result of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Guangru Shao and Xue-Fang Wang and Rui Wang},
  doi          = {10.1016/j.neucom.2023.126844},
  journal      = {Neurocomputing},
  pages        = {126844},
  shortjournal = {Neurocomputing},
  title        = {A distributed strategy for games in Euler–Lagrange systems with actuator dead zone},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advances in quantum machine learning and deep learning for
image classification: A survey. <em>NEUCOM</em>, <em>560</em>, 126843.
(<a href="https://doi.org/10.1016/j.neucom.2023.126843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification , which is a fundamental element of Computer Vision (CV) and Artificial Intelligence (AI), has been researched intensively in numerous domains and embedded in many products. However, with the exponential increase in the number of images and the complexity of the required tasks, deep-learning classification algorithms demand more intensive resources and computational power to train the models and update the massive number of parameters. Quantum computing is a new research technology with a promising capability of exponential speed up and operational parallelization with its unique phenomena including superposition and entanglement. Researchers have already started utilizing Quantum Deep Learning (QDL) and Quantum Machine Learning (QML) in image classification. Yet, to our knowledge, there exists no comprehensive published literature review on quantum image classification. Therefore, this paper analyzes the advances in this field by dividing the studies based on a unique taxonomy, discussing the limitations, summarizing essential aspects of each research, and finally, emphasizing the gaps, challenges, and recommendations. One of the key challenges presented in the paper is that quantum computers are in the Noisy Intermediate-Scale Quantum (NISQ) era, where they contain a limited number of noisy qubits, therefore challenging complex quantum classifiers and complex images from advanced datasets. This research recommends constructing a novel quantum image encoding method that adapts to the available number of qubits and enables RGB images as a critical contribution to the existing research.},
  archive      = {J_NEUCOM},
  author       = {Ruba Kharsa and Ahmed Bouridane and Abbes Amira},
  doi          = {10.1016/j.neucom.2023.126843},
  journal      = {Neurocomputing},
  pages        = {126843},
  shortjournal = {Neurocomputing},
  title        = {Advances in quantum machine learning and deep learning for image classification: A survey},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HYB-PARSIMONY: A hybrid approach combining particle swarm
optimization and genetic algorithms to find parsimonious models in
high-dimensional datasets. <em>NEUCOM</em>, <em>560</em>, 126840. (<a
href="https://doi.org/10.1016/j.neucom.2023.126840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The PSO-PARSIMONY methodology (a heuristic for finding accurate and low-complexity models with particle swarm optimization (PSO)) allows obtaining machine learning models with a good balance between accuracy and complexity. However, when the datasets are of high dimensionality , the methodology does not sufficiently reduce the complexity of the models. This paper presents a new hybrid methodology, called HYB-PARSIMONY, that combines PSO with genetic algorithm (GA) based methods. In the early stages of the optimization process, GA methods have a preponderance to accelerate the search for parsimony. Later, PSO becomes more relevant to improve accuracy. This new methodology obtains significant improvements in the search for more accurate and low-complexity models in high-dimensional datasets.},
  archive      = {J_NEUCOM},
  author       = {Jose Divasón and Alpha Pernia-Espinoza and Francisco Javier Martinez-de-Pison},
  doi          = {10.1016/j.neucom.2023.126840},
  journal      = {Neurocomputing},
  pages        = {126840},
  shortjournal = {Neurocomputing},
  title        = {HYB-PARSIMONY: A hybrid approach combining particle swarm optimization and genetic algorithms to find parsimonious models in high-dimensional datasets},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Distributed adaptive finite-time fault-tolerant
formation-containment control for networked euler–lagrange systems under
directed communication interactions. <em>NEUCOM</em>, <em>560</em>,
126839. (<a href="https://doi.org/10.1016/j.neucom.2023.126839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the finite-time formation-containment control problem for multiple Euler–Lagrange systems with actuator faults and input saturations subject to external disturbances and nonlinear uncertainties under directed communication interactions. Systematic procedures on how to synthesize a distributed control scheme are developed based on adaptive backstepping control, fault-tolerant control, dynamic gain control and finite-time control such that leaders form a desired geometric configuration while tracking the virtual leader, and followers converge to the convex hull spanned by the leaders during a finite-time period with sufficient accuracy. Two auxiliary systems are constructed to facilitate the control scheme design. Finite-time convergence and ease of computation burden in the sense of not using fractional powers of cooperative error information are realized by integrating dynamic gain control, finite-time control and one auxiliary system. Actuator faults, control input saturations, external disturbances and nonlinear uncertainties are coupled together and dealt with by adaptive backstepping control, fault-tolerant control and the other auxiliary system. In the end, the effectiveness of the proposed control scheme is verified with simulation results.},
  archive      = {J_NEUCOM},
  author       = {Yue Li and Ting Xu and Ruohan Yang and Meng Wang},
  doi          = {10.1016/j.neucom.2023.126839},
  journal      = {Neurocomputing},
  pages        = {126839},
  shortjournal = {Neurocomputing},
  title        = {Distributed adaptive finite-time fault-tolerant formation-containment control for networked Euler–Lagrange systems under directed communication interactions},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NUTS-BSNN: A non-uniform time-step binarized spiking neural
network with energy-efficient in-memory computing macro.
<em>NEUCOM</em>, <em>560</em>, 126838. (<a
href="https://doi.org/10.1016/j.neucom.2023.126838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a network architecture NUTS-BSNN: A Non-uniform Time-step Binarized Spiking Neural Network. NUTS-BSNN is a fully binarized spiking neural network with all binary weights, including the input and output layers. In the input and output layers, the weights are represented as stochastic series of numbers, while in the hidden layers, they are approximated to binary values for using simple XNOR-based computations. To compensate for the information loss due to binarization , we increased the convolutions at the input layer sequentially computed over multiple time-steps. The results from these operations are accumulated before generating spikes for the subsequent layers to increase the overall performance. We chose 14 time-steps for accumulation to achieve a good tradeoff between performance and inference latency. The proposed technique was evaluated using three datasets by direct training method and using a surrogate gradient algorithm. We achieved classification accuracies of 93.25\%, 88.71\%, and 70.31\% on the Fashion-MNIST, CIFAR-10, and CIFAR-100 datasets, respectively. Further, we present an in-memory computing architecture for NUTS-BSNN, which limits resource and power consumption for hardware implementation.},
  archive      = {J_NEUCOM},
  author       = {Van-Ngoc Dinh and Ngoc-My Bui and Van-Tinh Nguyen and Deepu John and Long-Yang Lin and Quang-Kien Trinh},
  doi          = {10.1016/j.neucom.2023.126838},
  journal      = {Neurocomputing},
  pages        = {126838},
  shortjournal = {Neurocomputing},
  title        = {NUTS-BSNN: A non-uniform time-step binarized spiking neural network with energy-efficient in-memory computing macro},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring advanced architectural variations of nnUNet.
<em>NEUCOM</em>, <em>560</em>, 126837. (<a
href="https://doi.org/10.1016/j.neucom.2023.126837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nnUNet is a state-of-the-art deep learning based segmentation framework which automatically and systematically configures the entire network training pipeline. We extend the network architecture component of the nnUNet framework by newly integrating mechanisms from advanced U-Net variations including residual, dense, and inception blocks as well as three forms of the attention mechanism . We propose the following extensions to nnUNet, namely Residual-nnUNet, Dense-nnUNet, Inception-nnUNet, Spatial-Single-Attention-nnUNet, Spatial- Multi-Attention-nnUNet, and Channel-Spatial-Attention-nnUNet. Furthermore, within Channel-Spatial- Attention-nnUNet we integrate our newly proposed variation of the channel-attention mechanism. We demonstrate that use of the nnUNet allows for consistent and transparent comparison of U-Net architectural modifications, while maintaining network architecture as the sole independent variable across experiments with respect to a dataset. The proposed variants are evaluated on eight medical imaging datasets consisting of 20 anatomical regions which is the largest collection of datasets on which attention U-Net variants have been compared in a single work. Our results suggest that attention variants are effective at improving performance when applied to tumour segmentation tasks consisting of two or more target anatomical regions, and that segmentation performance is influenced by use of the deep supervision architectural feature.},
  archive      = {J_NEUCOM},
  author       = {Niccolò McConnell and Nchongmaje Ndipenoch and Yu Cao and Alina Miron and Yongmin Li},
  doi          = {10.1016/j.neucom.2023.126837},
  journal      = {Neurocomputing},
  pages        = {126837},
  shortjournal = {Neurocomputing},
  title        = {Exploring advanced architectural variations of nnUNet},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A text guided multi-task learning network for multimodal
sentiment analysis. <em>NEUCOM</em>, <em>560</em>, 126836. (<a
href="https://doi.org/10.1016/j.neucom.2023.126836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Sentiment Analysis (MSA) is an active area of research that leverages multimodal signals for affective understanding of user-generated videos. Existing research tends to develop sophisticated fusion techniques to fuse unimodal representations into multimodal representation and treat MSA as a single prediction task. However, we find that the text modality with the pre-trained model (BERT) learn more semantic information and dominates the training in multimodal models, inhibiting the learning of other modalities. Besides, the classification ability of each modality is also suppressed by single-task learning. In this paper, We propose a text guided multi-task learning network to enhance the semantic information of non-text modalities and improve the learning ability of unimodal networks. We conducted experiments on multimodal sentiment analysis datasets, CMU-MOSI, CMU-MOSEI, and CH-SIMS. The results show that our method outperforms the current SOTA method.},
  archive      = {J_NEUCOM},
  author       = {Yuanyi Luo and Rui Wu and Jiafeng Liu and Xianglong Tang},
  doi          = {10.1016/j.neucom.2023.126836},
  journal      = {Neurocomputing},
  pages        = {126836},
  shortjournal = {Neurocomputing},
  title        = {A text guided multi-task learning network for multimodal sentiment analysis},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cloud-assisted collaborative inference of convolutional
neural networks for vision tasks on resource-constrained devices.
<em>NEUCOM</em>, <em>560</em>, 126835. (<a
href="https://doi.org/10.1016/j.neucom.2023.126835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work analyses the most relevant research conducted under the mobile cloud computing paradigm to bring vision tasks supported by state-of-the-art deep convolutional neural networks closer to the end-user through collaborative intelligence. In particular, this review aims to comprehensively address collaborative inference on convolutional networks, offering the reader a detailed explanation of the main methods and technologies used to partition and deploy such models on the UE-edge-cloud continuum, which have made it possible to leverage the capabilities of resource-constrained devices to alleviate, and ideally eliminate, the traditional dependence on the cloud for high-performance computing, thereby enabling a more rational exploitation of the supporting hardware infrastructure. The paper details the technical aspects of the different frameworks designed to support these tasks, examining and comparing the mechanisms and techniques used to conceive pertinent configurations. Moreover, the study outlines the various algorithmic solutions developed for synthesizing optimal co-inference schemes, also covering the design conventions adopted and the tweaks implemented to optimize the overall performance delivered, concluding with a discussion of the specific challenges that have arisen thus far, as well as the following steps to be taken in this field.},
  archive      = {J_NEUCOM},
  author       = {Ivan Rodriguez-Conde and Celso Campos and Florentino Fdez-Riverola},
  doi          = {10.1016/j.neucom.2023.126835},
  journal      = {Neurocomputing},
  pages        = {126835},
  shortjournal = {Neurocomputing},
  title        = {Cloud-assisted collaborative inference of convolutional neural networks for vision tasks on resource-constrained devices},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BP-SRM: A directly training algorithm for spiking neural
network constructed by spike response model. <em>NEUCOM</em>,
<em>560</em>, 126832. (<a
href="https://doi.org/10.1016/j.neucom.2023.126832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) have attracted widespread attention due to their unique bio-interpretability and low-power properties, but the non-differentiability of discrete spike sequences fired by spiking neurons brings difficulties to the learning of SNNs. Recently, surrogate gradient (SG) and back-propagation through time (BPTT) have provided an excellent idea for training SNNs constructed by leaky integrate-and-fire (LIF) neuron models. The LIF neuron model has been widely used in previous SNNs due to its simplicity and low computational cost, however, this also limits its simulation of biological neuron dynamics, reducing the biological interpretability of SNNs. In this paper, we generalize SG and BPTT to SNNs constructed by spike response model (SRM) and propose the BP-SRM algorithm. Specifically, we address why BPTT succeeded in LIF neurons-based SNNs but failed in SRM neurons-based SNNs in previous researches. Then we establish an iterative form of the SRM neuron model by selecting different state variables. Based on iterable SRM, we get the spatiotemporal dependencies between the state variables of SRM neurons-based SNNs, which allows us to derive the gradient and update weights in SNN by BP-SRM. Then we design temporal channel normalization for BP-SRM and verify the performance of the SNNs on static image dataset, dynamic image dataset and engineering dataset, including Fashion-MNIST, Weather Dataset, N-MNIST, American Sign Language Dataset and bearing fault diagnosis dataset. The experiment results indicate that BP-SRM achieves the state-of-the-art performance of SNNs.},
  archive      = {J_NEUCOM},
  author       = {Jun Wang and Tianfu Li and Chuang Sun and Ruqiang Yan and Xuefeng Chen},
  doi          = {10.1016/j.neucom.2023.126832},
  journal      = {Neurocomputing},
  pages        = {126832},
  shortjournal = {Neurocomputing},
  title        = {BP-SRM: A directly training algorithm for spiking neural network constructed by spike response model},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedMCSA: Personalized federated learning via model
components self-attention. <em>NEUCOM</em>, <em>560</em>, 126831. (<a
href="https://doi.org/10.1016/j.neucom.2023.126831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) facilitates multiple clients to jointly train a machine learning model without sharing their private data. However, heterogeneous data that is not independent and identically distributed (Non-IID) from different clients presents a tough challenge for FL. Existing personalized FL approaches rely heavily on the default treatment of one complete model as a basic unit and ignore the significance of different layers on Non-IID data of clients. In this work, we propose a new framework, namely federated model components self-attention (FedMCSA), to handle Non-IID data in FL, which employs model components self-attention mechanism to granularly promote cooperation between different clients. This mechanism facilitates collaboration between similar model components while reducing interference between model components with large differences. We conduct extensive experiments to demonstrate that FedMCSA outperforms the previous methods on four benchmark datasets. Furthermore, we empirically show the effectiveness of the model components self-attention mechanism, which is complementary to existing personalized FL and can significantly improve the performance of FL.},
  archive      = {J_NEUCOM},
  author       = {Qi Guo and Yong Qi and Saiyu Qi and Di Wu and Qian Li},
  doi          = {10.1016/j.neucom.2023.126831},
  journal      = {Neurocomputing},
  pages        = {126831},
  shortjournal = {Neurocomputing},
  title        = {FedMCSA: Personalized federated learning via model components self-attention},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight channel-topology based adaptive graph
convolutional network for skeleton-based action recognition.
<em>NEUCOM</em>, <em>560</em>, 126830. (<a
href="https://doi.org/10.1016/j.neucom.2023.126830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of graph convolutional network (GCN) over the recent years, skeleton-based action recognition has achieved satisfactory results. However, some existing GCN-based models were complex because of lots of parameters in the models. Moreover, a large proportion of the existing GCN-based extraction methods for temporal feature could not effectively extract temporal features. To address this problem, a lightweight channel-topology based adaptive graph convolutional network (LC-AGCN), is proposed in this paper. And it includes three innovative and important blocks. To be specific, firstly, the channel-topology adaptive graph convolution (CAGC) block is proposed for spatial feature extraction (SConv), and a modified multi-scale convolution block is introduced to extract temporal features (TConv). Then, in order to decrease the quantity of parameters, the bottleneck structure is introduced to lighten the model and obtain the desired result. Finally, in order to embody the principle of ”few parameters with high evaluating accuracy”, a parameter λ a p λap is creatively proposed to reflect the performance of lightweight models, which means the ratio of precision to parameter quantity. Extensive experiments demonstrate that our method greatly reduces the quantity of parameters of the model while ensuring high enough accuracy. The superiority of LC-AGCN has been proved on two large-scale public datasets named NTU-RGB+D and NTU-RGB+D 120, respectively.},
  archive      = {J_NEUCOM},
  author       = {Kaixuan Wang and Hongmin Deng and Qilin Zhu},
  doi          = {10.1016/j.neucom.2023.126830},
  journal      = {Neurocomputing},
  pages        = {126830},
  shortjournal = {Neurocomputing},
  title        = {Lightweight channel-topology based adaptive graph convolutional network for skeleton-based action recognition},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supervised domain adaptation by transferring both the
parameter set and its gradient. <em>NEUCOM</em>, <em>560</em>, 126828.
(<a href="https://doi.org/10.1016/j.neucom.2023.126828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-known obstacle in the successful implementation of deep learning-based systems to real-world problems is the performance degradation that occurs when applying a network that was trained on data collected in one domain, to data from a different domain. In this study, we focus on the Supervised Domain Adaptation (SDA) setup where we assume the availability of a small amount of labeled data from the target domain. Our approach is based on transferring the gradient history of the pre-training phase to the fine-tuning phase in addition to the parameter set to improve the generalization achieved during pre-training while fine-tuning the model. We present two schemes to transfer the gradient’s information. Mixed Minibatch Transfer Learning (MMTL) is based on using examples from both the source and target domains and Optimizer-Continuation Transfer Learning (OCTL) preserves the gradient history when shifting from training to fine-tuning. This approach is also applicable to the more general setup of transfer learning across different tasks. We show that our methods outperform the state-of-the-art at different levels of data scarcity from the target domain, on multiple datasets and tasks involving both scenery and medical images.},
  archive      = {J_NEUCOM},
  author       = {Shaya Goodman and Hayit Greenspan and Jacob Goldberger},
  doi          = {10.1016/j.neucom.2023.126828},
  journal      = {Neurocomputing},
  pages        = {126828},
  shortjournal = {Neurocomputing},
  title        = {Supervised domain adaptation by transferring both the parameter set and its gradient},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memory capacity of recurrent neural networks with matrix
representation. <em>NEUCOM</em>, <em>560</em>, 126824. (<a
href="https://doi.org/10.1016/j.neucom.2023.126824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that canonical recurrent neural networks (RNNs) face limitations in learning long-term dependencies, which have been addressed by memory structures in long short-term memory (LSTM) networks. Neural Turing machines (NTMs) are a variant of RNNs that implement the notion of programmable memory with neural network controllers that can learn simple algorithmic tasks. Matrix neural networks, on the other hand, feature matrix representations which inherently has the potential to preserve the spatial structure of data when compared to canonical neural networks that use only vector-based representation. One may then argue that neural networks with matrix representations may have the potential to provide better memory capacity. In this paper, we define and study a probabilistic notion of memory capacity based on Fisher information for matrix-based RNNs. We find bounds on memory capacity for such networks under various hypotheses and compare them with their conventional (vector) counterparts. In particular, we show that the memory capacity of such networks is bounded by N 2 N2 , for N × N N×N state matrix which generalizes and provides similar results for vector networks. We also show and analyze the increase in memory capacity for such networks which is introduced when one exhibits an external state memory, such as NTMs. Consequently, we construct NTMs with RNN controllers with matrix-based representation of external memory, leading us to introduce Matrix NTMs. We demonstrate the performance of this class of memory networks under certain algorithmic learning tasks such as copying and recall and compare it with Matrix RNNs. We find an improvement in the performance of Matrix NTMs by the addition of external memory, in comparison to Matrix RNNs.},
  archive      = {J_NEUCOM},
  author       = {Animesh Renanse and Alok Sharma and Rohitash Chandra},
  doi          = {10.1016/j.neucom.2023.126824},
  journal      = {Neurocomputing},
  pages        = {126824},
  shortjournal = {Neurocomputing},
  title        = {Memory capacity of recurrent neural networks with matrix representation},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Token-level disentanglement for unsupervised text style
transfer. <em>NEUCOM</em>, <em>560</em>, 126823. (<a
href="https://doi.org/10.1016/j.neucom.2023.126823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text style transfer is the task of altering the style of a source text to a desired style while preserving the style-independent content. A common approach involves disentangling a given sentence into a style-agnostic content representation within the latent space and then generating the text in the desired style, guided by a separate style embedding. However, previous methods have a limitation in that they assume the input sentence is encoded by a fix-sized latent vector at the sentence level, making it challenging to capture rich semantic information at the token level, especially when dealing with longer texts. Consequently, this leads to suboptimal preservation of non-stylistic semantic content. In this paper, we address this challenge, and propose TED, a fine-grained model for disentangling content and style representation at the token level to enhance content preservation. Specifically, TED use tf–idfs to estimate the pivot tokens for different styles and incorporates multi-task and adversarial objectives to disentangle the content and style information of each token within the latent space. Experimental results on two popular text style transfer datasets show that our proposed model significantly outperforms state-of-the-art baselines, particularly in terms of content preservation. Moreover, the quantitative and qualitative experiments demonstrate the effectiveness of our model in achieving token-level disentanglement within the latent space.},
  archive      = {J_NEUCOM},
  author       = {Yahao Hu and Wei Tao and Yifei Xie and Yi Sun and Zhisong Pan},
  doi          = {10.1016/j.neucom.2023.126823},
  journal      = {Neurocomputing},
  pages        = {126823},
  shortjournal = {Neurocomputing},
  title        = {Token-level disentanglement for unsupervised text style transfer},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An iteration-based interactive attention network for 3D
point cloud registration. <em>NEUCOM</em>, <em>560</em>, 126822. (<a
href="https://doi.org/10.1016/j.neucom.2023.126822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several learning-based methods dedicated to 3D point cloud registration have been developed recently. However, the performance of such methods is limited due to a lack of effective feature interaction mechanisms. To overcome this problem, an iteration-based interactive attention network is proposed here for 3D point cloud registration that can effectively learn the overlapping features of point cloud pairs and improve the registration accuracy. Concretely, we first designed a condensed global information extractor to achieve aggregated global features. Meanwhile, to reduce the amount of calculation required for subsequent modules while maintaining high-level characteristic information, the number of point cloud features is reduced. Furthermore, an overlapping feature iterative attention module and a discriminant feature iterative expansion module are designed. The main function of both modules is to implement feature interaction in the form of cross-attention and self-attention as well as to deepen interactions iteratively. The former captures overlapping information by iteratively interacting with the features of the condensed global features of one point cloud and the local geometric features of another point cloud. The latter can expand the number of features back to the initial number of point clouds through the interaction of overlapping features and local geometric features. Finally, matching features with high discriminative ability are obtained and used to formulate a soft correspondence matrix. Furthermore, weighted singular-value decomposition is adopted to obtain the rigid transformation matrix. Extensive experiments demonstrate that the proposed method achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Jiatong Shi and Hailiang Ye and Bing Yang and Feilong Cao},
  doi          = {10.1016/j.neucom.2023.126822},
  journal      = {Neurocomputing},
  pages        = {126822},
  shortjournal = {Neurocomputing},
  title        = {An iteration-based interactive attention network for 3D point cloud registration},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic literature review on object detection using
near infrared and thermal images. <em>NEUCOM</em>, <em>560</em>, 126804.
(<a href="https://doi.org/10.1016/j.neucom.2023.126804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant advances have been achieved in object detection techniques using visible images for applications that include military operations, autonomous driving , and security surveillance. However, the quality of visible images suffers from various environmental and illumination conditions resulting in poor detection outcomes. To remedy this, a wide range of new methodologies using visual images together with infrared (IR) images of various wavelengths (including those referred to as thermal images) are being developed and presented to the open literature. Despite this progress, many challenges of object detection still prevail, and it is important to understand them. In this paper, we present a systematic literature review documenting recent advances in object detection using predominantly IR data. We discuss our systematic review process for the identification, filtering, screening, and selection of the relevant methodologies to include in the literature review. The selected methodologies are analyzed and organized into three main groups: (1) object detection in IR images, which includes detection of labeled objects, small target detection, and background subtraction , (2) object detection on multispectral data , and (3) data fusion approaches. Reviewed studies consider different types of objects, environmental conditions, and types of images, particularly in the IR domain . Finally, we discuss some of the key limitations of the current literature and opportunities for future research for improving object detection using both visible and IR data as well as LiDAR and radar data, when applicable.},
  archive      = {J_NEUCOM},
  author       = {Nicolas Bustos and Mehrsa Mashhadi and Susana K. Lai-Yuen and Sudeep Sarkar and Tapas K. Das},
  doi          = {10.1016/j.neucom.2023.126804},
  journal      = {Neurocomputing},
  pages        = {126804},
  shortjournal = {Neurocomputing},
  title        = {A systematic literature review on object detection using near infrared and thermal images},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Filter-wrapper combined feature selection and
adaboost-weighted broad learning system for transformer fault diagnosis
under imbalanced samples. <em>NEUCOM</em>, <em>560</em>, 126803. (<a
href="https://doi.org/10.1016/j.neucom.2023.126803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis is a rapidly evolving field within power engineering. Using gas-in-oil data is a reliable method for transformer fault diagnosis that has been widely adopted in the power industry. However, traditional machine learning methods often suffer from low diagnostic accuracy due to the lack of a clear and effective feature set for gas-in-oil data as well as an imbalance between classes of sample size. To overcome this challenge, this paper proposes a novel transformer fault diagnosis model that utilizes a Filter-Wrapper Combined Feature Selection method and an AdaBoost integrated weighted broad learning system (AdaBoost-WBLS). More specifically, the original data is expanded to extract meaningful features, and the Filter-Wrapper combined feature selection method is used to eliminate preliminary redundancy, relevance, and significance of current features. The Wrapper algorithm is then used for precise screening to obtain the optimal feature subset, which effectively improves the quality of transformer features. Furthermore, to address the issue of imbalanced transformer samples, an improved BLS and AdaBoost integration method is introduced, and a fault diagnosis model based on AdaBoost-WBLS is proposed. Compared with existing power transformer fault diagnosis methods , the proposed method has a more accurate and balanced effect on fault classification. Overall, this paper provides a comprehensive and effective approach to transformer fault diagnosis, which has important implications for the reliability and safety of power systems.},
  archive      = {J_NEUCOM},
  author       = {Beijia Zhao and Dongsheng Yang and Hamid Reza Karimi and Bowen Zhou and Shuai Feng and Guangdi Li},
  doi          = {10.1016/j.neucom.2023.126803},
  journal      = {Neurocomputing},
  pages        = {126803},
  shortjournal = {Neurocomputing},
  title        = {Filter-wrapper combined feature selection and adaboost-weighted broad learning system for transformer fault diagnosis under imbalanced samples},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved finite-time prescribed performance based adaptive
neural control for nonlinear systems with sensor faults.
<em>NEUCOM</em>, <em>560</em>, 126794. (<a
href="https://doi.org/10.1016/j.neucom.2023.126794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, based on a novel finite-time prescribed performance function, we consider the issue of the adaptive neural fault-tolerant tracking control problem for a type of nonlinear system with sensor faults. The control performance of the system may be affected when sensor faults occur. For the controlled system with sensor faults, an improved finite-time performance function is proposed so that its initial conditions do not need to be set in advance. Compared with existing performance functions, the performance functions in this paper can ensure that the system is always controllable, even if the sensor faults occur suddenly during the steady operation. Moreover, Radial basis function (RBF) neural networks (NNs) are employed to estimate the uncertain smooth nonlinear functions . With the help of the adaptive backstepping control technique, an improved adaptive prescribed performance control technique is developed, which can realize the boundedness of every signal in the closed-loop system, and the tracking error can be limited within the neighborhood near the origin. Simulation results demonstrate the effectiveness of the proposed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Huanqing Wang and Kexin Lu and Fu Zheng and Jiawei Ma and Cungen Liu},
  doi          = {10.1016/j.neucom.2023.126794},
  journal      = {Neurocomputing},
  pages        = {126794},
  shortjournal = {Neurocomputing},
  title        = {Improved finite-time prescribed performance based adaptive neural control for nonlinear systems with sensor faults},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local propagation of visual stimuli in focus of attention.
<em>NEUCOM</em>, <em>560</em>, 126775. (<a
href="https://doi.org/10.1016/j.neucom.2023.126775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast reactions to changes in the surrounding visual environment require efficient attention mechanisms to reallocate computational resources to the most relevant locations in the visual field. In this paper, we present a biologically-plausible computational model of focus of attention that exhibits spatiotemporal locality and that is very well-suited for parallel and distributed implementations. Attention emerges as a wave propagation process originated by visual stimuli corresponding to details and motion information. The resulting field obeys the principle of “inhibition of return” so as not to get stuck in potential holes. The proposed model is obtained as a hyperbolic regularization of the Poisson equation to which it reduces in the limit of high speed of propagation. According to the MultiMatch algorithm for scanpaths comparison, the proposed model achieves very competitive results when considering dynamical input stimuli.},
  archive      = {J_NEUCOM},
  author       = {Lapo Faggi and Alessandro Betti and Dario Zanca and Stefano Melacci and Marco Gori},
  doi          = {10.1016/j.neucom.2023.126775},
  journal      = {Neurocomputing},
  pages        = {126775},
  shortjournal = {Neurocomputing},
  title        = {Local propagation of visual stimuli in focus of attention},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Desire backpropagation: A lightweight training algorithm for
multi-layer spiking neural networks based on spike-timing-dependent
plasticity. <em>NEUCOM</em>, <em>560</em>, 126773. (<a
href="https://doi.org/10.1016/j.neucom.2023.126773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are a viable alternative to conventional artificial neural networks when resource efficiency and computational complexity are of importance. A major advantage of SNNs is their binary information transfer through spike trains which eliminates multiplication operations. The training of SNNs has, however, been a challenge, since neuron models are non-differentiable and traditional gradient-based backpropagation algorithms cannot be applied directly. Furthermore, spike-timing-dependent plasticity (STDP), albeit being a spike-based learning rule, updates weights locally and does not optimize for the output error of the network. We present desire backpropagation , a method to derive the desired spike activity of all neurons, including the hidden ones, from the output error. By incorporating this desire value into the local STDP weight update, we can efficiently capture the neuron dynamics while minimizing the global error and attaining a high classification accuracy . That makes desire backpropagation a spike-based supervised learning rule. We trained three-layer networks to classify MNIST and Fashion-MNIST images and reached an accuracy of 98.41\% and 87.56\%, respectively. In addition, by eliminating a multiplication during the backward pass, we reduce computational complexity and balance arithmetic resources between forward and backward pass, making desire backpropagation a candidate for training on low-resource devices.},
  archive      = {J_NEUCOM},
  author       = {Daniel Gerlinghoff and Tao Luo and Rick Siow Mong Goh and Weng-Fai Wong},
  doi          = {10.1016/j.neucom.2023.126773},
  journal      = {Neurocomputing},
  pages        = {126773},
  shortjournal = {Neurocomputing},
  title        = {Desire backpropagation: A lightweight training algorithm for multi-layer spiking neural networks based on spike-timing-dependent plasticity},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly-supervised anomaly detection with a sub-max strategy.
<em>NEUCOM</em>, <em>560</em>, 126770. (<a
href="https://doi.org/10.1016/j.neucom.2023.126770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study weakly-supervised anomaly detection where only video-level “anomalous”/“normal” labels are available in training, while anomaly events should be temporally localized in testing. For this task, a commonly used framework is multiple instance learning (MIL), where clip instances are sampled from individual videos to form video-level bags. This sampling process arguably is a bottleneck of MIL. If too many instances are sampled, we not only encounter high computational overheads but also have many noisy instances in the bag. On the other hand, when too few instances are used, e . g ., through enlarged grids, much background noise may be included in the anomaly instances. To resolve this dilemma, we propose a simple yet effective method named Sub-Max. In partitioned image regions, it identifies instances that are most probable candidates for anomaly events by selecting cuboids that have high optical flow magnitudes. We show that our method effectively brings down the computational cost of the baseline MIL and at the same time significantly filters out the influence of noise. Albeit simple, this strategy is shown to facilitate the learning of discriminative features and thus improve event classification and localization performance. For example, after annotating the event location ground truths of the UCF-Crime test set, we report very competitive accuracy compared with the state of the art on both frame-level and pixel-level metrics, corresponding to classification and localization, respectively.},
  archive      = {J_NEUCOM},
  author       = {Bohua Zhang and Jianru Xue},
  doi          = {10.1016/j.neucom.2023.126770},
  journal      = {Neurocomputing},
  pages        = {126770},
  shortjournal = {Neurocomputing},
  title        = {Weakly-supervised anomaly detection with a sub-max strategy},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural image caption generator based on crossbar array
design of memristor module. <em>NEUCOM</em>, <em>560</em>, 126766. (<a
href="https://doi.org/10.1016/j.neucom.2023.126766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crossbar array design method based on a single memristor provides an excessive writing error and cannot achieve the network’s requirements for the generation of image captions. In order to solve this problem, this paper highlights the following techniques. (1) A crossbar array of memristor modules is built, and the writing error is theoretically reduced to a maximum of 0.0619‰. (2) A method of linearly mapping the weights of neural networks to memristance values is proposed, and a memristive neural network based on a memristor module is designed. (3) A neural image caption generator based on VGG-16-LSTM is designed in light of the crossbar array of the memristor module. The design can achieve a maximum of 99.38\% of the reference network in BLEU scoring performance. The performance of neural networks based on memristor modules under different input conditions is discussed, and the paper’s best hardware design scheme, named it-10, is proposed. The it-8 simulation can obtain 97.37\% of the reference network in BLEU scoring performance, and it requires far less demanding input conditions. Moreover, this paper finds a way to design a novel crossbar array based on the memristor module and make a breakthrough in memristive neural network solution for the cross-modal image caption generation task.},
  archive      = {J_NEUCOM},
  author       = {Yongbin Yu and Daijin Yang and Qian Tang and Xiangxiang Wang and Nijing Yang and Man Cheng and Yuanjingyang Zhong and Kwabena Adu and Ekong Favour},
  doi          = {10.1016/j.neucom.2023.126766},
  journal      = {Neurocomputing},
  pages        = {126766},
  shortjournal = {Neurocomputing},
  title        = {Neural image caption generator based on crossbar array design of memristor module},
  volume       = {560},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Intelligent detection and behavior tracking under ammonia
nitrogen stress. <em>NEUCOM</em>, <em>559</em>, 126809. (<a
href="https://doi.org/10.1016/j.neucom.2023.126809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel YOLO-based detection model with deformable convolution network (DCN-YOLOv5) is developed, which is concerned with the object and key points detection and behavior tracking problem for Oplegnathus punctatus in the ammonia nitrogen environment. The proposed model can adapt to the posture change of the object by deforming the receptive field, which solves the problem of false and missed detection caused by the movement and occlusion. Moreover, a new multi-object multi-category tracking algorithm (MOMC-Tracking) is proposed to track and plot the trajectory and calculate the key behavioral characteristics parameters. In addition, an executable software which integrates the proposed DCN-YOLOv5 model and the MOMC-Tracking algorithm is proposed. Extensive experiments show that compared with the typical YOLO series of algorithms, the proposed model in this paper performs the best with the highest accuracy and the fastest convergence speed, where the mAP @0.5 and mAP @0.5:0.95 of the proposed DCN-YOLOv5 model are 93.71\% and 57.45\%, which are respectively improved by 1.78\% and 24.77\% as compared with those obtained by the original YOLOv5 model.},
  archive      = {J_NEUCOM},
  author       = {Juan Li and Weimei Chen and Yihao Zhu and Kui Xuan and Han Li and Nianyin Zeng},
  doi          = {10.1016/j.neucom.2023.126809},
  journal      = {Neurocomputing},
  pages        = {126809},
  shortjournal = {Neurocomputing},
  title        = {Intelligent detection and behavior tracking under ammonia nitrogen stress},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mldr.resampling: Efficient reference implementations of
multilabel resampling algorithms. <em>NEUCOM</em>, <em>559</em>, 126806.
(<a href="https://doi.org/10.1016/j.neucom.2023.126806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resampling algorithms are a useful approach to deal with imbalanced learning in multilabel scenarios. These methods have to deal with singularities in the multilabel data, such as the occurrence of frequent and infrequent labels in the same instance. Implementations of these methods are sometimes limited to the pseudocode provided by their authors in a paper. This Original Software Publication presents mldr.resampling , a software package that provides reference implementations for eleven multilabel resampling methods, with an emphasis on efficiency since these algorithms are usually time-consuming.},
  archive      = {J_NEUCOM},
  author       = {Antonio J. Rivera and Miguel A. Dávila and D. Elizondo and María J. del Jesus and Francisco Charte},
  doi          = {10.1016/j.neucom.2023.126806},
  journal      = {Neurocomputing},
  pages        = {126806},
  shortjournal = {Neurocomputing},
  title        = {Mldr.resampling: Efficient reference implementations of multilabel resampling algorithms},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Response fusion attention u-ConvNext for accurate
segmentation of optic disc and optic cup. <em>NEUCOM</em>, <em>559</em>,
126798. (<a href="https://doi.org/10.1016/j.neucom.2023.126798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is a pathological eye condition which requires accurate optic disc and optic cup segmentation for diagnosis. This study proposes Responsive Fusion Attention U-ConvNext, a novel encoder decoder network, for semantic segmentation of optic disc and optic cup structures from fundus images. Response Fusion Attention U-ConvNext is a U-Net like model containing a pre-trained ConvNext encoder network and a light-weight, modified ConvNext decoder network having skip connections between the encoder and decoder blocks. We also propose a new attention gate module called Dual-Path Response Fusion Attention (DPRFA) for smoothing the concatenation process of the encoder and upsampled feature maps. In addition, we propose a modified loss function by combining cross entropy, Dice and Jaccard losses for training the model accurately. The model has four sizes and all of them are trained and validated on DRISHTI-GS and REFUGE datasets. Our proposed models have acheived a dice coefficient of 0.9822 and 0.9269 on optic disc and optic cup segmentation of DRISHTI-GS dataset and a dice coefficient of 0.9788 and 0.9086 on optic disc and optic cup segmentation of REFUGE dataset. The experimental results thus obtained by our suggested models have shown state-of-the-art results when compared to other existing models. Code and models are available at : https://github.com/SiddMallick/RFAUCNxt-official .},
  archive      = {J_NEUCOM},
  author       = {Siddhartha Mallick and Jayanta Paul and Jaya Sil},
  doi          = {10.1016/j.neucom.2023.126798},
  journal      = {Neurocomputing},
  pages        = {126798},
  shortjournal = {Neurocomputing},
  title        = {Response fusion attention U-ConvNext for accurate segmentation of optic disc and optic cup},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synchronization of fractional complex-valued neural networks
with pantograph delays and inhibitory factors. <em>NEUCOM</em>,
<em>559</em>, 126797. (<a
href="https://doi.org/10.1016/j.neucom.2023.126797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the global synchronization of fractional complex-valued neural networks with pantograph delays and inhibitory factors is investigated, and some sufficient conditions are obtained. It deserves to mention that the attained sufficient conditions show that some factors including the pantograph coefficient, coupling connection weights, inhibitory factors, and the order of fractional derivative have an influence on network synchronization . Moreover, when complex-valued neural networks degenerate into real-valued cases and inhibitory factors are not taken into consideration, they are also discussed, and two corollaries are derived. Finally, to validate the feasibility of the theoretical results, a numerical example is presented. Meanwhile, some contrastive numerical results are given to illustrate the relationships among network synchronization , pantograph coefficient, and inhibitory factors.},
  archive      = {J_NEUCOM},
  author       = {Yao Xu and Haodong Wang and Jintong Yu and Wenxue Li},
  doi          = {10.1016/j.neucom.2023.126797},
  journal      = {Neurocomputing},
  pages        = {126797},
  shortjournal = {Neurocomputing},
  title        = {Synchronization of fractional complex-valued neural networks with pantograph delays and inhibitory factors},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Window token transformer: Can learnable window token help
window-based transformer build better long-range interactions?
<em>NEUCOM</em>, <em>559</em>, 126793. (<a
href="https://doi.org/10.1016/j.neucom.2023.126793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with the vanilla transformer, the window-based transformer offers a better trade-off between accuracy and efficiency. Although the window-based transformer has made great progress, its long-range modeling capabilities are limited due to the size of the local window and the window connection scheme. To address this problem, we propose a novel Window Token Transformer (WTT). The core mechanism of WTT is the addition of a window token for summarizing window information in each local window. We refer to this type of token interaction as Window Token Attention. These window tokens will interact spatially with the tokens in each window to enable long-range modeling. In order to preserve the hierarchical design of the window-based transformer, we design Feature Inheritance Module (FIM) in each phase of WTT to deliver the local window information from the previous phase to the window token in the next phase. In addition, we have designed a Global–Local Feedforward Network (GLFFN) in WTT, which can enhance the local awareness of the network while preserving the global awareness. Extensive experiments have shown that our WTT achieves competitive results with low parameters in image classification and downstream tasks.},
  archive      = {J_NEUCOM},
  author       = {Jiawei Mao and Yuanqi Chang and Xuesong Yin},
  doi          = {10.1016/j.neucom.2023.126793},
  journal      = {Neurocomputing},
  pages        = {126793},
  shortjournal = {Neurocomputing},
  title        = {Window token transformer: Can learnable window token help window-based transformer build better long-range interactions?},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedBrain: A robust multi-site brain network analysis
framework based on federated learning for brain disease diagnosis.
<em>NEUCOM</em>, <em>559</em>, 126791. (<a
href="https://doi.org/10.1016/j.neucom.2023.126791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning models have shown their advantages in neuroimage analysis, such as brain disease diagnosis. Unfortunately, it is usually difficult to acquire numerous brain networks at a single centralized site to effectively train a high-quality deep learning model. To address this issue, federated learning (FL) has gained popularity in brain disease diagnosis, which allows deep learning models to be trained without centralizing data. However, most FL-based works might still face two following challenges. Firstly, the high-dimensional features of brain networks are often far larger than sample size, which might lead to poor performance due to the curse of dimensionality. Secondly, differences in data distributions across different sites can impact the communication efficiency and performance of FL models. To overcome these challenges, we design a novel FL framework for diagnosing brain disorders, named FedBrain. Firstly, FedBrain proposes data augmentation based on L 1 L1 regularization to select significant features shared by all clients. The domain alignment loss based on the maximum mean discrepancy criterion is introduced to minimize differences in the marginal and conditional distributions between local clients. Furthermore, FedBrain proposes a personalized predictor based on mixture of experts to adapt to different clients, using a global and private predictor as two experts. Eventually, FedBrain integrates the above modules with differential privacy and homomorphic encryption into a unified FL framework. Experimental results on the Autism Brain Imaging Data Exchange (ABIDE) dataset demonstrate its effectiveness and robustness, which shows that FedBrain can reduce the communication burden of FL and achieve the highest average accuracy of 79\% against other counterparts.},
  archive      = {J_NEUCOM},
  author       = {Chang Zhang and Xiangzhu Meng and Qiang Liu and Shu Wu and Liang Wang and Huansheng Ning},
  doi          = {10.1016/j.neucom.2023.126791},
  journal      = {Neurocomputing},
  pages        = {126791},
  shortjournal = {Neurocomputing},
  title        = {FedBrain: A robust multi-site brain network analysis framework based on federated learning for brain disease diagnosis},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symmetric actor–critic deep reinforcement learning for
cascade quadrotor flight control. <em>NEUCOM</em>, <em>559</em>, 126789.
(<a href="https://doi.org/10.1016/j.neucom.2023.126789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even though deep reinforcement learning (DRL) has been extensively applied to quadrotor flight control to simplify parameter adjustment, it has some drawbacks in terms of control performance, such as instability and asymmetry. To address these problems, we propose an odd symmetric actor to achieve stable and symmetric control performance, and an even critic to stabilize the training process. Concretely, the bias of neural networks is eliminated, and the absolute value operation is adopted to construct the activation function . Furthermore, we devise a cascade architecture, where each module trained with DRL controls a symmetric subsystem of the quadrotor. Comparative simulations have verified the effectiveness of the proposed control scheme, which shows superiority in dealing with high-dimensional, nonlinear subsystems and disadvantage in dealing with low-dimensional, linear subsystems.},
  archive      = {J_NEUCOM},
  author       = {Haoran Han and Jian Cheng and Zhilong Xi and Maolong Lv},
  doi          = {10.1016/j.neucom.2023.126789},
  journal      = {Neurocomputing},
  pages        = {126789},
  shortjournal = {Neurocomputing},
  title        = {Symmetric actor–critic deep reinforcement learning for cascade quadrotor flight control},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). E3CM: Epipolar-constrained cascade correspondence matching.
<em>NEUCOM</em>, <em>559</em>, 126788. (<a
href="https://doi.org/10.1016/j.neucom.2023.126788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and robust correspondence matching is of utmost importance for various 3D computer vision tasks . However, traditional explicit programming-based methods often struggle to handle challenging scenarios, and deep learning-based methods require large well-labeled datasets for network training. In this article, we introduce Epipolar-Constrained Cascade Correspondence (E3CM), a novel approach that addresses these limitations. Unlike traditional methods, E3CM leverages pre-trained convolutional neural networks to match correspondence, without requiring annotated data for any network training or fine-tuning. Our method utilizes epipolar constraints to guide the matching process and incorporates a cascade structure for progressive refinement of matches. We extensively evaluate the performance of E3CM through comprehensive experiments and demonstrate its superiority over existing methods. To promote further research and facilitate reproducibility, we make our source code publicly available at https://mias.group/E3CM/ .},
  archive      = {J_NEUCOM},
  author       = {Chenbo Zhou and Shuai Su and Qijun Chen and Rui Fan},
  doi          = {10.1016/j.neucom.2023.126788},
  journal      = {Neurocomputing},
  pages        = {126788},
  shortjournal = {Neurocomputing},
  title        = {E3CM: Epipolar-constrained cascade correspondence matching},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On-line learning applied to spiking neural network for
antilock braking systems. <em>NEUCOM</em>, <em>559</em>, 126784. (<a
href="https://doi.org/10.1016/j.neucom.2023.126784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computationally replicating the behaviour of the cerebral cortex to perform the control tasks of daily life in a human being is a challenge today. First, it is necessary to know the structure and connections between the elements of the neural network that perform movement control. Next, a mathematical neural model that adequately resembles biological neurons has to be developed. Finally, a suitable learning model that allows adapting neural network response to changing conditions in the environment is also required. Spiking Neural Networks (SNN) are currently the closest approximation to biological neural networks. SNNs make use of temporal spike trains to deal with inputs and outputs, thus allowing a faster and more complex computation. In this paper, a controller based on an SNN is proposed to perform the control of an anti-lock braking system (ABS) in vehicles. To this end, two neural networks are used to regulate the braking force. The first one is devoted to estimating the optimal slip while the second one is in charge of setting the optimal braking pressure. The latter resembles biological reflex arcs to ensure stability during operation. This neural structure is used to control the fast regulation cycles that occur during ABS operation. Furthermore, an algorithm has been developed to train the network while driving. On-line learning is proposed to update the response of the controller. Hence, to cope with real conditions, a control algorithm based on neural networks that learn by making use of neural plasticity, similar to what occurs in biological systems, has been implemented. Neural connections are modulated using Spike-Timing-Dependent Plasticity (STDP) by means of a supervised learning structure using the slip error as input. Road-type detection has been included in the same neural structure. To validate and to evaluate the performance of the proposed algorithm, simulations as well as experiments in a real vehicle were carried out. The algorithm proved to be able to adapt to changes in adhesion conditions rapidly. This way, the capability of spiking neural networks to perform the full control logic of the ABS has been verified.},
  archive      = {J_NEUCOM},
  author       = {Javier Pérez and Manuel Alcázar and Ignacio Sánchez and Juan A. Cabrera and Mikael Nybacka and Juan J. Castillo},
  doi          = {10.1016/j.neucom.2023.126784},
  journal      = {Neurocomputing},
  pages        = {126784},
  shortjournal = {Neurocomputing},
  title        = {On-line learning applied to spiking neural network for antilock braking systems},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consensus of nonlinear multiagent systems under periodic
scaling attacks with input delays via truncated prediction approach.
<em>NEUCOM</em>, <em>559</em>, 126783. (<a
href="https://doi.org/10.1016/j.neucom.2023.126783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the consensus problem of nonlinear multiagent systems with uncertainties and switching network topology under truncated prediction feedback approach subjected to periodic scaling attacks. Here, a type of deception attack known as periodic scaling attack have been taken into consideration for both undirected and directed graphs during agent’s communication. The fundamental purpose of this paper is to develop a state feedback controller that can withstand actuator faults while ensuring the resultant closed loop systems. Furthermore, the truncated prediction feedback approach is utilized for handling input delays and then, a set of necessary conditions are derived in terms of linear matrix inequalities by developing an appropriate Lyapunov–Krasovskii functional. Eventually, to demonstrate the significance of the established theoretical results, two numerical simulation are conferred.},
  archive      = {J_NEUCOM},
  author       = {N. Sakthivel and M. Mounika Devi},
  doi          = {10.1016/j.neucom.2023.126783},
  journal      = {Neurocomputing},
  pages        = {126783},
  shortjournal = {Neurocomputing},
  title        = {Consensus of nonlinear multiagent systems under periodic scaling attacks with input delays via truncated prediction approach},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust prescribed-time containment control for high-order
uncertain multi-agent systems with extended state observer.
<em>NEUCOM</em>, <em>559</em>, 126782. (<a
href="https://doi.org/10.1016/j.neucom.2023.126782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the robust prescribed-time containment control with prescribed-time extended state observer is addressed for high-order multi-agent systems with model uncertainties and external disturbances. First, a prescribed-time distributed observer is developed for each follower to estimate the convex hull spanned by the states of the leaders. Namely, it can generate the reference tracking signal for each follower. Furthermore, since only the output of each follower is available and its dynamics is inevitably disturbed by diverse uncertainties and disturbances, a prescribed-time extended state observer is developed for estimation. In addition, a robust prescribed-time containment controller is put forward to realize the containment control. Then the proposed strategy is successfully applied to the wheeled mobile robots. Finally, experimental results verify the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Shaoping Chang and Yijing Wang and Zhiqiang Zuo and Hongjiu Yang and Xiaoyuan Luo},
  doi          = {10.1016/j.neucom.2023.126782},
  journal      = {Neurocomputing},
  pages        = {126782},
  shortjournal = {Neurocomputing},
  title        = {Robust prescribed-time containment control for high-order uncertain multi-agent systems with extended state observer},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual swin-transformer based mutual interactive network for
RGB-d salient object detection. <em>NEUCOM</em>, <em>559</em>, 126779.
(<a href="https://doi.org/10.1016/j.neucom.2023.126779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth information for RGB-D Salient Object Detection(SOD) is important and conventional deep models are usually relied on the CNN feature extractors. The long-range contextual dependencies, dense modeling on the saliency decoder, and multi-task learning assistance are usually ignored. In this work, we propose a Dual Swin-Transformer-based Mutual Interactive Network (DTMINet), aiming to learn contextualized, dense, and edge-aware features for RGB-D SOD. We adopt the Swin-Transformer as the visual backbone to extract contextualized features. A self-attention-based Cross-Modality Interaction module is proposed to strengthen the visual backbone for cross-modal interaction. In addition, a Gated Modality Attention module is designed for cross-modal fusion. At different decoding stages, enhanced with dense connections and progressively merge the multi-level encoding features with the proposed Dense Saliency Decoder. Considering the depth quality issue, a Skip Convolution module is introduced to provide guidance to the RGB modality for the saliency prediction. In addition, we add the edge prediction to the saliency predictor to regularize the learning process. Comprehensive experiments on five standard RGB-D SOD benchmark datasets over four evaluation metrics demonstrate the superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Chao Zeng and Sam Kwong and Horace Ip},
  doi          = {10.1016/j.neucom.2023.126779},
  journal      = {Neurocomputing},
  pages        = {126779},
  shortjournal = {Neurocomputing},
  title        = {Dual swin-transformer based mutual interactive network for RGB-D salient object detection},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quasi-projective synchronization of memristor-based complex
valued recurrent neural network with time-varying delay and mismatched
parameters. <em>NEUCOM</em>, <em>559</em>, 126774. (<a
href="https://doi.org/10.1016/j.neucom.2023.126774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the quasi-projective synchronization for a class of non-identical memristor-based complex-valued recurrent neural networks (MCVRNNs) with time-varying delays and parameters’ mismatched. Here, the quasi-projective synchronization is presented in two ways based on the Halanay inequality and some useful techniques. Some novel sufficient conditions are firstly derived for quasi-projective synchronization criteria of non-identical memristor-based CVRNNs with time-varying delays and parameters’ mismatched by using the matrix measure method. And then, by using the Lyapunov-Krasovskii functional, another sufficient stabilization condition for quasi-projective synchronization of the concerned model is presented. Finally, two numerical simulation results are given to demonstrate the usefulness and persistence of the proposed methods under some conditions.},
  archive      = {J_NEUCOM},
  author       = {Ankit Kumar and Subir Das and Young Hoon Joo},
  doi          = {10.1016/j.neucom.2023.126774},
  journal      = {Neurocomputing},
  pages        = {126774},
  shortjournal = {Neurocomputing},
  title        = {Quasi-projective synchronization of memristor-based complex valued recurrent neural network with time-varying delay and mismatched parameters},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking two-dimensional camera motion estimation
assessment for digital video stabilization: A camera motion field-based
metric. <em>NEUCOM</em>, <em>559</em>, 126768. (<a
href="https://doi.org/10.1016/j.neucom.2023.126768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital video stabilization aims to remove camera motion jitters through software implementation. The first step of the classical video stabilization methodology is called camera motion estimation, which is usually performed using only RGB frames of the unstable video. Despite recent advances in camera motion estimation strategies, methods classified as two-dimensional are still not properly evaluated, even though it is well known that motion estimation is a crucial step for classical approaches to video stabilization. The main purpose of this work is to draw attention to two-dimensional camera motion estimation assessment and reinforce its importance on video stabilization progress. We proposed a new approach to perform this evaluation using camera motion fields in a pixel-by-pixel comparison and demonstrated through experimental results that our metrics are reliable for diverse scenarios comparing them to image similarity metrics. In addition, we showed and analyzed the results of our metrics for a global and a local method of camera motion estimation. We believe that our assessment and study presented in this work is an important starting point for a more rigorous analysis of this task. In addition, this can be a foundation for coming 2D camera motion estimation methods based on deep learning .},
  archive      = {J_NEUCOM},
  author       = {Marcos Roberto e Souza and Helena de Almeida Maia and Helio Pedrini},
  doi          = {10.1016/j.neucom.2023.126768},
  journal      = {Neurocomputing},
  pages        = {126768},
  shortjournal = {Neurocomputing},
  title        = {Rethinking two-dimensional camera motion estimation assessment for digital video stabilization: A camera motion field-based metric},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A self-adaptive dynamic multi-objective optimization
algorithm based on transfer learning and elitism-based mutation.
<em>NEUCOM</em>, <em>559</em>, 126761. (<a
href="https://doi.org/10.1016/j.neucom.2023.126761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems (DMOPs) involve several conflicting objectives, and these objective functions change over time. Therefore, addressing DMOPs necessitates an effective response to environmental changes. However, most existing algorithms only deal with DMOPs with one particular type of environmental changes, whereas real-world dynamic changes are more complicated. Therefore, this paper proposes a self-adaptive DMOEA based on transfer learning and elitism-based mutation (ATM-DMOEA), aiming to efficiently tackle DMOPs exhibiting complex environmental changes. Specifically, a change evaluation method is devised to gauge change intensity and discern whether a change is drastic or gentle. Subsequently, an adaptive change response strategy is implemented to accommodate varying environmental changes. For drastic changes, the algorithm employs an elitism-based manifold transfer learning method, while gentle changes are handled with a diversity enhancement strategy introduced by adaptive elitism-based mutations with a varying mutation probability . The experiments have validated the competitiveness of the proposed ATM-DMOEA on the majority of DMOP test instances with different levels of change severity.},
  archive      = {J_NEUCOM},
  author       = {Xi Zhang and Yaochu Jin and Feng Qian},
  doi          = {10.1016/j.neucom.2023.126761},
  journal      = {Neurocomputing},
  pages        = {126761},
  shortjournal = {Neurocomputing},
  title        = {A self-adaptive dynamic multi-objective optimization algorithm based on transfer learning and elitism-based mutation},
  volume       = {559},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EVOLVE: Learning volume-adaptive phases for fast 3D magnetic
resonance scan and image reconstruction. <em>NEUCOM</em>, <em>558</em>,
126810. (<a href="https://doi.org/10.1016/j.neucom.2023.126810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with 2D Magnetic Resonance Imaging (MRI), 3D MRI is more powerful for generating high resolution images and visualizing small anatomical structures. However, 3D MRI acquisition is much more time-consuming due to the significantly larger number of phase encoding steps, which is directly proportional to the acquisition time. This paper proposes to select a volume-adaptive small subset of phases to accelerate 3D MRI scans and accurately reconstruct 3D images from the corresponding undersampled 3D k-space data. To avoid the delays caused by computationally expensive yet high-performance volume-adaptive phase selection, we propose a strategy of selecting multiple phases based on sampled slices from the volume during idle time within the repetition time (TR). To enhance the performance of phase selection, we propose a novel three-directional cross-attention phase selection network. Additionally, to improve the reconstruction performance, we introduce a three-directional slice-wise volume reconstruction. To the best of our knowledge, the proposed method, which we called EVOLVE (l e arning vol ume-adapti ve phases), is the first work that learns volume-adaptive phases for fast 3D MRI. The extensive experimental results on a large-scale 3D MRI dataset at various acceleration factors demonstrate the substantial performance improvement in terms of image reconstruction achieved by using the EVOLVE method for phase selection compared to traditional learning free 3D MRI phase selection methods.},
  archive      = {J_NEUCOM},
  author       = {Yiming Liu and Yanwei Pang and Xuebin Sun and Yonghong Hou and Hui Xu},
  doi          = {10.1016/j.neucom.2023.126810},
  journal      = {Neurocomputing},
  pages        = {126810},
  shortjournal = {Neurocomputing},
  title        = {EVOLVE: Learning volume-adaptive phases for fast 3D magnetic resonance scan and image reconstruction},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using combinatorial optimization to solve entity alignment:
An efficient unsupervised model. <em>NEUCOM</em>, <em>558</em>, 126802.
(<a href="https://doi.org/10.1016/j.neucom.2023.126802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment (EA) aims to discover unique equivalent entity pairs with the same meaning across different knowledge graphs (KG), which is a crucial step for expanding the scale of KGs. Existing EA methods commonly leverage graph neural networks (GNNs) to align entities. However, these methods inherit the complex structure of GNNs, which results in lower efficiency. Meanwhile, most EA methods are either limited in their performance due to insufficient utilization of available information or require extensive manual preprocessing to obtain additional information. Furthermore, seed alignment acquisition is challenging for most EA methods that rely on supervised learning. To address these challenges, this paper proposes a simple and effective unsupervised EA model named COEA. COEA leverages the entity name information to obtain reliable supplementary information for EA and enhances performance by combining text features captured by entity names with structural features of the KG. Importantly, COEA inherits the advantages of GNN while reducing redundancy. It only uses the way of aggregating neighbor features in graph convolutional network (GCN), and transforms the EA problems into combination optimization problems . Sufficient experimental of COEA on five datasets have validated the exceptional performance and generalization capabilities of the framework. COEA achieved the best performance in all performance indicators. Notably, the framework enables the rapid implementation of entity alignment with minimal computational delays.},
  archive      = {J_NEUCOM},
  author       = {Lin Lin and Lizheng Zu and Feng Guo and Song Fu and Yancheng Lv and Hao Guo and Jie Liu},
  doi          = {10.1016/j.neucom.2023.126802},
  journal      = {Neurocomputing},
  pages        = {126802},
  shortjournal = {Neurocomputing},
  title        = {Using combinatorial optimization to solve entity alignment: An efficient unsupervised model},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evading text based emotion detection mechanism via
adversarial attacks. <em>NEUCOM</em>, <em>558</em>, 126787. (<a
href="https://doi.org/10.1016/j.neucom.2023.126787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Textual Emotion Analysis (TEA) seeks to extract and assess the emotional states of users from the text. Various Deep Learning (DL) algorithms have emerged rapidly and demonstrated success in numerous disciplines, including audio, image, and natural language processing . The trend has shifted a growing number of researchers from standard machine learning to DL for scientific study. Using DL approaches, we offer an overview of TEA in this paper. After introducing the background for emotion analysis, including the definition of emotion, emotion classification methods, and application domains of emotion analysis, we demonstrated that, despite the immense success of deep learning models in NLP-related tasks, they are susceptible to adversarial attacks , which can lead to incorrect emotion classification. An adversarial text is constructed by altering a few words or characters so as to keep the overall semantic similarity of emotion for a human reader while tricking the machine into making erroneous predictions. This study demonstrates the vulnerability of emotion categorization by generating adversarial text using a variety of cutting-edge attack techniques. Comprehensive experiments are performed to assess the effectiveness of the attack methods against several widely-used models, such as Word-CNN, Bi-LSTM, and four powerful transformer models, namely BERT , DistilBERT, ALBERT, and RoBERTa. These models were trained on an emotion dataset utilized for the purpose of emotion classification. We evaluated and analyzed the behavior of different models under a variety of attack conditions to determine which is the most and least vulnerable. Also, we determine which perturbation technique affects transformer models the most. Using Attack Success Rates (ASR) as our evaluation metric , we have assessed the potential outcomes. The findings reveal that methodologies for classifying emotion prediction can be circumvented, which has implications for existing policy measures.},
  archive      = {J_NEUCOM},
  author       = {Ashish Bajaj and Dinesh Kumar Vishwakarma},
  doi          = {10.1016/j.neucom.2023.126787},
  journal      = {Neurocomputing},
  pages        = {126787},
  shortjournal = {Neurocomputing},
  title        = {Evading text based emotion detection mechanism via adversarial attacks},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LUKE-graph: A transformer-based approach with gated
relational graph attention for cloze-style reading comprehension.
<em>NEUCOM</em>, <em>558</em>, 126786. (<a
href="https://doi.org/10.1016/j.neucom.2023.126786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating prior knowledge has been identified as a promising approach to enhance existing pre-training models in cloze-style machine reading, as observed in recent studies. Despite the use of external knowledge graphs (KG) and transformer-based models like BERT in most existing models, the identification of the most pertinent ambiguous entities in KG, as well as the extraction of the optimal subgraphs, remains problematic. To address these challenges, we introduce the LUKE-Graph model, which constructs a heterogeneous graph based on the intuitive relationships between entities in the documents without relying on external KGs. We then employ a Relational Graph Attention (RGAT) network to combine the reasoning information of the graph with the contextual representation generated by the pre-trained LUKE model. In this way, we can take advantage of LUKE, to derive an entity-aware representation; and a graph model - to exploit relation-aware representation. Furthermore, we present Gated-RGAT, an enhancement to RGAT that incorporates a gating mechanism to control the question information during the graph convolution operation . This mechanism emulates the human reasoning process in selecting the most suitable entity candidate based on question information. Our experimental results demonstrate that the proposed LUKE-Graph model surpasses the LUKE state-of-the-art model on the ReCoRD dataset, which focuses on commonsense reasoning, and the WikiHop dataset, which centers on multi-hop reasoning problems.},
  archive      = {J_NEUCOM},
  author       = {Shima Foolad and Kourosh Kiani},
  doi          = {10.1016/j.neucom.2023.126786},
  journal      = {Neurocomputing},
  pages        = {126786},
  shortjournal = {Neurocomputing},
  title        = {LUKE-graph: A transformer-based approach with gated relational graph attention for cloze-style reading comprehension},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kernelized gradient descent method for learning from
demonstration. <em>NEUCOM</em>, <em>558</em>, 126781. (<a
href="https://doi.org/10.1016/j.neucom.2023.126781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from demonstration (LfD) has been widely studied as a convenient method for robot learning. In the LfD paradigm, the robot is required to learn relevant motion patterns from human demonstrations and apply them to various situations. Many advancements have been achieved in recent studies, however, there is a lack of studies on solutions for robots to learn the variability from demonstrations and adapt the reproduction to unseen scenarios in high-dimensional or long-trajectory cases. In this paper, a novel nonparametric kernelized gradient descent (KGD) method of LfD is proposed, which capitalizes on gradient descent and kernel-based approaches and produces a model with fewer open parameters than methods that employ basis functions. The proposed KGD method can accurately represent the complex demonstrations and utilize the variability of the demonstrations to adapt the trajectories smoothly to different unseen situations described by newly desired start-, via- and end-points precisely with high computational efficiency. Experiments were conducted to evaluate the performance of the proposed KGD method and compare it with commonly used probabilistic kernelized movement primitive (KMP) and mean-prior Gaussian process regression (MP-GPR) methods. The results indicated that the proposed KGD method performs better than KMP and MP-GPR in terms of the precision of the desired points, reproduction smoothness, and computation time. On account of the high efficiency and outstanding reproduction, KGD has the potential to be beneficial for better human–robot collaboration, facilitating assembly lines or improving robot learning. An important future challenge will be to extend the KGD towards considering the nonlinear constraints to learn more complex tasks.},
  archive      = {J_NEUCOM},
  author       = {Kui Hu and Jiwen Zhang and Dan Wu},
  doi          = {10.1016/j.neucom.2023.126781},
  journal      = {Neurocomputing},
  pages        = {126781},
  shortjournal = {Neurocomputing},
  title        = {Kernelized gradient descent method for learning from demonstration},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A color image decomposition model for image enhancement.
<em>NEUCOM</em>, <em>558</em>, 126772. (<a
href="https://doi.org/10.1016/j.neucom.2023.126772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary goal of image decomposition is to decompose an observed image into several independent components, which can be further manipulated to carry out more complex tasks effectively. Existing image decomposition methods apply a decomposition model either to each of the three channels separately in RGB color space, or to the intensity channel only in other color spaces, which leads to color error or unintuitive display. To address these issues, this paper proposes a color image decomposition model that acts directly on color images and yields visually piecewise smoothing base information, low/high contrast detail information, and rich color information. Specifically, the color information with characteristics of spherical geometry is separated by a spatial transformation at first. Then, the separation of base and detail information from a given image is achieved by combining low-rank approximation and the relative total variation with no artifacts. After yielding the three components via our decomposition model, we exploit the automatic arc tangent transformation and the visual saliency principle to implement two applications, contrast enhancement and infrared image fusion, respectively. We demonstrate the remarkable performance of our method through a reasonable qualitative and quantitative analysis of the experimental results.},
  archive      = {J_NEUCOM},
  author       = {Tianqing Hu and Qinglei Zhou and Xiaofei Nan and Renhao Lin},
  doi          = {10.1016/j.neucom.2023.126772},
  journal      = {Neurocomputing},
  pages        = {126772},
  shortjournal = {Neurocomputing},
  title        = {A color image decomposition model for image enhancement},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reducing noise-triplets via differentiable sampling for
knowledge-enhanced recommendation with collaborative signal guidance.
<em>NEUCOM</em>, <em>558</em>, 126771. (<a
href="https://doi.org/10.1016/j.neucom.2023.126771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph (KG) is widely used for recommendation tasks due to its rich semantic information and external structure. Current knowledge graph recommendation models are insufficient for the learning of user–item interactive behaviors as well as external knowledge, and ignore the noise information in KG. To alleviate these limitations, we present a Collaborative Relation-aware Attention Network with Differentiable sampling (DCRAN) that can fully learn user–item interactions and knowledge graphs, and accurately select recommendation-related entities in KG. Specifically, DCRAN explicitly learns the embeddings of users and items and encodes them into collaborative interaction signals, which are used as guidance signals to extract knowledge. Furthermore, DCRAN emphasizes the importance of KG relations and constructs a relation-aware attention network to learn the representation of items in KG. Most importantly, DCRAN applies a differentiable sampling strategy on entities, which can reduce triplets that have a negative effect on recommendation. Experimental results on three public datasets manifest the effectiveness of DCRAN.},
  archive      = {J_NEUCOM},
  author       = {Huajuan Duan and Xiufang Liang and Yingzheng Zhu and Zhenfang Zhu and Peiyu Liu},
  doi          = {10.1016/j.neucom.2023.126771},
  journal      = {Neurocomputing},
  pages        = {126771},
  shortjournal = {Neurocomputing},
  title        = {Reducing noise-triplets via differentiable sampling for knowledge-enhanced recommendation with collaborative signal guidance},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IIRI-net: An interpretable convolutional front-end inspired
by IIR filters for speaker identification. <em>NEUCOM</em>,
<em>558</em>, 126767. (<a
href="https://doi.org/10.1016/j.neucom.2023.126767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning interpretable filters in Convolutional Neural Networks (CNNs) is an approach that helps to build models with better generalization ability . Interpretable filters can reveal some hidden aspects of the task and help to improve the model. One of the most successful approaches in the field of the speech processing is SincNet , where the model learns some band-pass filters in the first layer of a CNN with a raw waveform as its input. In this paper, similar to SincNet , some meaningful filters are proposed, which here are inspired by Infinite Impulse Response (IIR) filters. The proposed model uses a phase correction process to ensure that phase linearity is satisfied. The effective length of the truncated IIR filter is calculated based on the accumulated energy, and the effect of changing the filter size on the final results has been investigated. The proposed model is evaluated in the speaker identification task on the TIMIT and Librispeech datasets and compared with traditional CNNs and four interpretable kernel-based models. The experimental results show the superiority of the proposed model both in performance and convergence speed. Moreover, some patterns of the speech signal, which lead to uniquely identifying a speaker, are analyzed by examining the spectrum of the learned filters.},
  archive      = {J_NEUCOM},
  author       = {Hossein Fayyazi and Yasser Shekofteh},
  doi          = {10.1016/j.neucom.2023.126767},
  journal      = {Neurocomputing},
  pages        = {126767},
  shortjournal = {Neurocomputing},
  title        = {IIRI-net: An interpretable convolutional front-end inspired by IIR filters for speaker identification},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Object and attribute recognition for product image with
self-supervised learning. <em>NEUCOM</em>, <em>558</em>, 126763. (<a
href="https://doi.org/10.1016/j.neucom.2023.126763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate class and attribute recognition is the critical technique to convert the unstructured product image data into structured knowledge base , which provides strong support for product design in the future. However, objects of different classes sharing similar attribute may vary a lot in visual appearances, making it challenging to accurately recognize the objects and their attributes. Different from the traditional multi-label image recognition, the attribute of the object, as high-level semantic information, is not corresponding to certain regions of the object and requires to learn more fine-grained features to represent the latent high level semantic information for the attribute across different object categories. Therefore, a self-supervised method called Deconstruction and Reconstruction Learning Network (DRLN) is proposed to solve the above problems in this paper. The DRLN tries to learn more fine-grained and local feature of the input product image by a self-supervised task, which deconstructs the input product images by randomly shuffling their local regions and further reconstructs the features of corresponding deconstructed images. Besides, the proposed model is optimized in an end-to-end manner by learning from multiple tasks, i.e., the multi-label classification task , the adversarial discrimination task, and the location alignment task. Experimental results demonstrate that the proposed method outperforms the state-of-the-arts for multi-label learning problems on both our product image dataset and another public available attribute recognition dataset. To facilitate future research in this field, all the datasets and codes are directly available online. 1},
  archive      = {J_NEUCOM},
  author       = {Yong Dai and Yi Li and Bin Sun},
  doi          = {10.1016/j.neucom.2023.126763},
  journal      = {Neurocomputing},
  pages        = {126763},
  shortjournal = {Neurocomputing},
  title        = {Object and attribute recognition for product image with self-supervised learning},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatiotemporal motor learning with reward-modulated hebbian
plasticity in modular reservoir computing. <em>NEUCOM</em>,
<em>558</em>, 126740. (<a
href="https://doi.org/10.1016/j.neucom.2023.126740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generation of complex patterns at a specific timing is crucial to most forms of learning and behavior , which are acquired through dopamine-modulated plasticity in the striatum. However, the neural mechanisms of such reward-based spatiotemporal processing remain unknown. Inspired by the cortico-striatal circuits, this study developed a new reservoir computing method, a class of recurrent neural networks , based on reward-modulated Hebbian learning (RMHL) for the spatiotemporal motor learning. We utilized a reservoir of basal dynamics (reBASICS), which generated self-sustained limit cycle oscillations with various frequencies, as a reservoir structure. Then, the oscillations were linearly integrated as readout output, in which readout weights were modulated with RMHL. The simulations showed that reBASICS-based RMHL was able to accomplish both motor timing and pattern drawing tasks, for which existing reservoir-based RMHL failed. Further, introducing an eligibility trace mechanism into RMHL allowed the model to learn motor timing even when reward-based modulation was delayed. In conclusion, this model is proposed as a new computational model of temporal processing of the striatum, where the cortical areas generate stable oscillations. From the oscillatory dynamics, spatiotemporal patterns are learned using RMHL in the striatum.},
  archive      = {J_NEUCOM},
  author       = {Yuji Kawai and Minoru Asada},
  doi          = {10.1016/j.neucom.2023.126740},
  journal      = {Neurocomputing},
  pages        = {126740},
  shortjournal = {Neurocomputing},
  title        = {Spatiotemporal motor learning with reward-modulated hebbian plasticity in modular reservoir computing},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive control for output projective synchronization of
fractional-order hybrid coupled neural networks with mismatched
dimensions. <em>NEUCOM</em>, <em>558</em>, 126738. (<a
href="https://doi.org/10.1016/j.neucom.2023.126738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with output projective synchronization (OPS) for fractional-order Hybrid Coupled neural networks (FOHCNNs) with mismatched dimensions. Distinguishing from the traditional projective synchronization, the concept of OPS for fractional-order systems is given. Moreover, a new fractional-order Halanay-type inequality is presented by the properties of the Mittag-Leffler function. Then, several new sufficient conditions to ensure OPS of FOHCNNs with mismatched dimensions are obtained via a new effective adaptive controller . In particular, several adaptive control strategies are given to ensure the output synchronization, output anti-synchronization, and stabilization of FOHCNNs with mismatched dimensions. Finally, a numerical example is given to show the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Dongsheng Yang and Guojian Ren and Hu Wang and Yongguang Yu and Xiaolin Yuan},
  doi          = {10.1016/j.neucom.2023.126738},
  journal      = {Neurocomputing},
  pages        = {126738},
  shortjournal = {Neurocomputing},
  title        = {Adaptive control for output projective synchronization of fractional-order hybrid coupled neural networks with mismatched dimensions},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RAPID: Enabling fast online policy learning in dynamic
public cloud environments. <em>NEUCOM</em>, <em>558</em>, 126737. (<a
href="https://doi.org/10.1016/j.neucom.2023.126737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource sharing between multiple workloads has become a prominent practice among cloud service providers , motivated by demand for improved resource utilization and reduced cost of ownership. Effective resource sharing, however, remains an open challenge due to the adverse effects that resource contention can have on high-priority, user-facing workloads with strict Quality of Service (QoS) requirements. Although recent approaches have demonstrated promising results, those works remain largely impractical in public cloud environments since workloads are not known in advance and may only run for a brief period, thus prohibiting offline learning and significantly hindering online learning. In this paper, we propose RAPID, a novel framework for fast, fully-online resource allocation policy learning in highly dynamic operating environments. RAPID leverages lightweight QoS predictions, enabled by domain-knowledge-inspired techniques for sample efficiency and bias reduction, to decouple control from conventional feedback sources and guide policy learning at a rate orders of magnitude faster than prior work. Evaluation on a real-world server platform with representative cloud workloads confirms that RAPID can learn stable resource allocation policies in minutes, as compared with hours in prior state-of-the-art, while improving QoS by 9.0x and increasing best-effort workload performance by 19\%–43\%.},
  archive      = {J_NEUCOM},
  author       = {Drew Penney and Bin Li and Lizhong Chen and Jaroslaw J. Sydir and Anna Drewek-Ossowicka and Ramesh Illikkal and Charlie Tai and Ravi Iyer and Andrew Herdrich},
  doi          = {10.1016/j.neucom.2023.126737},
  journal      = {Neurocomputing},
  pages        = {126737},
  shortjournal = {Neurocomputing},
  title        = {RAPID: Enabling fast online policy learning in dynamic public cloud environments},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prototype expansion and feature calibration for few-shot
point cloud semantic segmentation. <em>NEUCOM</em>, <em>558</em>,
126732. (<a href="https://doi.org/10.1016/j.neucom.2023.126732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot point cloud semantic segmentation has attracted increasing attention due to its applicability to real-world scenarios in which each novel class contains only a few labelled data. Although existing methods have made great progress, a great challenge still remains: inaccurate decision boundaries are induced by the scarcity of labelled data. In this paper, a Prototype Expansion and Feature Calibration (PEFC) method is proposed, which fully exploits the information contained in query data to increase the amounts of class prototypes and calibrate these prototypes. To this end, a Prototype Expansion Module (PEM) is designed, which clusters query data into pseudo prototypes and expands the set of class prototypes with pseudo prototypes that have a high similarity to the class prototypes. Then, a Feature Calibration Module (FCM) is designed to calibrate these class prototypes, which is achieved by enabling bidirectional information flow between class prototypes and query features in a task-aware manner. Extensive experiments on two benchmark datasets show that the proposed PEFC outperforms the state-of-the-art methods by a large margin in all experimental settings.},
  archive      = {J_NEUCOM},
  author       = {Qieshi Zhang and Tichao Wang and Fusheng Hao and Fuxiang Wu and Jun Cheng},
  doi          = {10.1016/j.neucom.2023.126732},
  journal      = {Neurocomputing},
  pages        = {126732},
  shortjournal = {Neurocomputing},
  title        = {Prototype expansion and feature calibration for few-shot point cloud semantic segmentation},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two analog neural models with the controllability on number
of assets for sparse portfolio design. <em>NEUCOM</em>, <em>558</em>,
126728. (<a href="https://doi.org/10.1016/j.neucom.2023.126728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this research is to use continuous time neural networks for solving the sparse portfolio problem, where the objective function includes a non-differentiable ℓ 1 -norm regularization term . To address the non-differentiable issue, we introduce two novel continuous time neural models that are based on the Lagrange programming neural network (LPNN) framework. The proposed neural models have the ability to control the number of the assets in the resulting portfolio and adjust the weighting between risk and return. The first model, called LPNN-Approximation, handles the non-differentiable ℓ 1 -norm term by utilizing a differentiable approximation. The second model merges the locally competitive algorithm (LCA) concept with the LPNN framework to address the non-differentiable term. It is called LPNN-LCA. For the LPNN-Approximation, we prove that the state of the network globally converges to the optimal solution of the sparse portfolio problem. Meanwhile, for the LPNN-LCA, we prove that all the equilibrium points of its dynamics correspond to the optimal solution of the sparse portfolio problem and are asymptotically stable. In addition, the realizations of the two models are discussed. Specifically, a thorough circuit realization for the thresholding elements of the LPNN-LCA model is presented. The effectiveness of the proposed approaches is verified by a number of numerical experiments, which show that the two proposed models outperform two state-of-the-art analog models.},
  archive      = {J_NEUCOM},
  author       = {Hao Wang and Chi-Sing Leung and Andy Hau-Ping Chan and Anthony G. Constantinides and Wenming Cao},
  doi          = {10.1016/j.neucom.2023.126728},
  journal      = {Neurocomputing},
  pages        = {126728},
  shortjournal = {Neurocomputing},
  title        = {Two analog neural models with the controllability on number of assets for sparse portfolio design},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient boosting bayesian neural networks via langevin
MCMC. <em>NEUCOM</em>, <em>558</em>, 126726. (<a
href="https://doi.org/10.1016/j.neucom.2023.126726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian neural networks harness the power of Bayesian inference which provides an approach to neural learning that not only focuses on accuracy but also uncertainty quantification. Markov Chain Monte Carlo (MCMC) methods implement Bayesian inference by sampling from the posterior distribution of the model parameters. In the case of Bayesian neural networks, the model parameters refer to weights and biases. MCMC methods suffer from scalability issues in large models, such as deep neural networks with thousands to millions of parameters. In this paper, we present a Bayesian ensemble learning framework that utilizes gradient boosting by combining multiple shallow neural networks (base learners) that are trained by MCMC sampling. We present two Bayesian gradient boosting strategies that employ simple neural networks as base learners with Langevin MCMC sampling. We evaluate the performance of these methods on various classification and time-series prediction problems. We demonstrate that the proposed framework improves the prediction accuracy of canonical gradient boosting while providing uncertainty quantification via Bayesian inference. Furthermore, we demonstrate that the respective methods scale well when the size of the dataset and model increases.},
  archive      = {J_NEUCOM},
  author       = {George Bai and Rohitash Chandra},
  doi          = {10.1016/j.neucom.2023.126726},
  journal      = {Neurocomputing},
  pages        = {126726},
  shortjournal = {Neurocomputing},
  title        = {Gradient boosting bayesian neural networks via langevin MCMC},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). “I do not know! But why?” — local model-agnostic
example-based explanations of reject. <em>NEUCOM</em>, <em>558</em>,
126722. (<a href="https://doi.org/10.1016/j.neucom.2023.126722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning based decision making systems in safety critical areas place high demands on the accuracy and generalization ability of the underlying model. A common strategy to deal with uncertainties and possible mistakes is offered by learning with reject option, i.e. a model can refrain from prediction in ambiguous cases and leave the decision to a human expert. Yet, as for the models themselves, human decision-making is hampered by the fact that reject options are often implemented as black-box rules: Experts cannot readily understand the reasons for rejection. In this work, we propose a model-agnostic framework that enriches classification with reject option by explanation mechanisms. More specifically, we combine conformal prediction as a popular mathematically based technology of certainty estimation with local surrogates derived for the region of interest. This allows us to provide local explanations in terms of example-based explanation methods, including counterfactual, semi-factual, and factual methods. We demonstrate the performance of this technology through a series of benchmarks using 6 different data sets; the associated code is open source. 1},
  archive      = {J_NEUCOM},
  author       = {André Artelt and Roel Visser and Barbara Hammer},
  doi          = {10.1016/j.neucom.2023.126722},
  journal      = {Neurocomputing},
  pages        = {126722},
  shortjournal = {Neurocomputing},
  title        = {“I do not know! but why?” — local model-agnostic example-based explanations of reject},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence accelerates multi-modal biomedical
process: A survey. <em>NEUCOM</em>, <em>558</em>, 126720. (<a
href="https://doi.org/10.1016/j.neucom.2023.126720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abundance of artificial intelligence AI algorithms and growing computing power has brought a disruptive revolution to the smart medical industry. Its powerful data abstraction and representation capabilities enable the modeling of hundreds of millions of medical data, such as sub-Computed Tomography tumor identification, retinal lesion screening, and survival curve analysis. However, all of these applications demonstrate AI’s use of unimodal data for specific tasks. In contrast, clinicians deal with multi-modal data from multiple sources when diagnosing, performing prognostic assessments, and deciding on treatment plans. These requirements have facilitated the development of multi-modal AI solutions and improved the performance of AI models in handling complex medical scenarios and data. In this paper, we provide an overview of the current state of the art and research in multi-modal biomedical AI, including applications, data, methods, and analytics. Additionally, we summarize potential research directions for multi-modal AI technologies in the future of healthcare.},
  archive      = {J_NEUCOM},
  author       = {Jiajia Li and Xue Han and Yiming Qin and Feng Tan and Yulong Chen and Zikai Wang and Haitao Song and Xi Zhou and Yuan Zhang and Lun Hu and Pengwei Hu},
  doi          = {10.1016/j.neucom.2023.126720},
  journal      = {Neurocomputing},
  pages        = {126720},
  shortjournal = {Neurocomputing},
  title        = {Artificial intelligence accelerates multi-modal biomedical process: A survey},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SSTM: Spatiotemporal recurrent transformers for multi-frame
optical flow estimation. <em>NEUCOM</em>, <em>558</em>, 126705. (<a
href="https://doi.org/10.1016/j.neucom.2023.126705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inaccurate optical flow estimates in and near occluded regions, and out-of-boundary regions are two of the current significant limitations of optical flow estimation algorithms. Recent state-of-the-art optical flow estimation algorithms are two-frame based methods where optical flow is estimated sequentially for each consecutive image pair in a sequence. While this approach gives good flow estimates, it fails to generalize optical flows in occluded regions mainly due to limited local evidence regarding moving elements in a scene. In this work, we propose a learning-based multi-frame optical flow estimation method that estimates two or more consecutive optical flows in parallel from multi-frame image sequences. Our underlying hypothesis is that by understanding temporal scene dynamics from longer sequences with more than two frames, we can characterize pixel-wise dependencies in a larger spatiotemporal domain, generalize complex motion patterns and thereby improve the accuracy of optical flow estimates in occluded regions. We present learning-based spatiotemporal recurrent transformers for multi-frame based optical flow estimation (SSTMs). Our method utilizes 3D Convolutional Gated Recurrent Units (3D-ConvGRUs) and spatiotemporal transformers to learn recurrent space–time motion dynamics and global dependencies in the scene and provide a generalized optical flow estimation. When compared with recent state-of-the-art two-frame and multi-frame methods on real world and synthetic datasets , performance of the SSTMs were significantly higher in occluded and out-of-boundary regions. Among all published state-of-the-art multi-frame methods, SSTM achieved state-of the-art results on the Sintel Final and KITTI2015 benchmark datasets. Software code, data and instructions : https://github.com/Computational-Ocularscience/SSTM .},
  archive      = {J_NEUCOM},
  author       = {Fisseha Admasu Ferede and Madhusudhanan Balasubramanian},
  doi          = {10.1016/j.neucom.2023.126705},
  journal      = {Neurocomputing},
  pages        = {126705},
  shortjournal = {Neurocomputing},
  title        = {SSTM: Spatiotemporal recurrent transformers for multi-frame optical flow estimation},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cluster-aware attentive convolutional recurrent network for
multivariate time-series forecasting. <em>NEUCOM</em>, <em>558</em>,
126701. (<a href="https://doi.org/10.1016/j.neucom.2023.126701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time-series (MTS) forecasting plays a crucial role in various real-world applications, but the complex dependencies between time-series variables (i.e., inter-series dependencies) make this task extremely challenging. While most existing studies focus on modeling intra-series (temporal) dependencies by capturing long- and short-term patterns, they fail to explore and exploit the inter-series dependencies to enhance MTS forecasting. In this paper, we propose a Cluster-aware Attentive Convolutional Recurrent Network (CACRN) to capture both inter-series and intra-series dependencies in MTS data. Specifically, CACRN first introduces a cluster-aware variable representation module that separates irrelevant variables and captures the interaction between relevant variables to learn cluster-aware variable representations. Then, CACRN feeds these representations into parallel convolutional recurrent neural networks (CRNNs) to capture the short- and long-term temporal dependencies in a cluster-wise manner. Next, a cluster-aware attention mechanism is introduced to attend to temporal information in each cluster and co-attend all cluster information jointly to capture intra-cluster and inter-cluster dependencies for the downstream forecasting task. Our extensive experiments on six real-world datasets demonstrate that CACRN is effective and outperforms representative and state-of-the-art baselines. Our proposed method is suitable for a wide range of real-world data collections, especially those with clear dependencies of variables.},
  archive      = {J_NEUCOM},
  author       = {Simeng Bai and Qi Zhang and Hui He and Liang Hu and Shoujin Wang and Zhendong Niu},
  doi          = {10.1016/j.neucom.2023.126701},
  journal      = {Neurocomputing},
  pages        = {126701},
  shortjournal = {Neurocomputing},
  title        = {Cluster-aware attentive convolutional recurrent network for multivariate time-series forecasting},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel watermarking framework for intellectual property
protection of NLG APIs. <em>NEUCOM</em>, <em>558</em>, 126700. (<a
href="https://doi.org/10.1016/j.neucom.2023.126700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language generation (NLG) models have attracted extensive attention and applications due to their combination with powerful deep learning techniques . Many NLG models are encapsulated in cloud APIs serving commercial organizations, which have become very important profitable services for these institutions. However, cloud platforms may suffer from model extraction attacks that aim to imitate the functionality of these NLG models in practical applications, thus infringing the intellectual property (IP) of the NLG APIs. Unfortunately, most current watermarking methods for protecting deep model IP are not directly applicable to IP protection of NLG APIs. In addition, the semantic similarity between the watermarked texts generated by the baseline method and the original texts is not high enough, which can be easily detected by attackers. To make up these gaps, we propose a novel watermarking framework which embeds watermarks by conducting lexical modification to the outputs of the NLG models, and uses the corresponding watermark identification method can identify the attackers and protect the IP of NLG APIs. Experiment result shows that our proposed watermarking method not only generates watermarked texts with higher semantically similar to the original texts but also achieves better identifiable performance compared with the baseline method . In addition, our watermarking method also exhibits outstanding performance in other aspects such as transferability, watermark undetectability and robustness.},
  archive      = {J_NEUCOM},
  author       = {Mingjie Li and Hanzhou Wu and Xinpeng Zhang},
  doi          = {10.1016/j.neucom.2023.126700},
  journal      = {Neurocomputing},
  pages        = {126700},
  shortjournal = {Neurocomputing},
  title        = {A novel watermarking framework for intellectual property protection of NLG APIs},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Replay attack detection and mitigation for cyber–physical
systems via RADIR algorithm with encryption scheduling. <em>NEUCOM</em>,
<em>558</em>, 126698. (<a
href="https://doi.org/10.1016/j.neucom.2023.126698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the security state estimation issue facing replay attacks in confidential cyber–physical systems. Smart sensor equipped with a power harvester transmits critical measurements to the remote estimator over wireless networks, in which the transmission modes include encrypted and normal. In order to complete the persistent threats, the adversary launches multi-stage discontinuous replay attacks to compromise the estimation process. In virtue of the designed label detection scheme, we transform attack detection into encryption scheduling optimization under the constraint of sensor energy harvesting and acquire a rigorous relationship between detection probability , attack duration, and encryption ratio. Different from most existing studies only focusing on attack detection, the localization of replay interval measured by detection immediacy is also analyzed. Subsequently, the optimal periodic encryption scheduling strategy is given to maximally determine the attack interval by adopting an optimization-based approach. Further, a complete algorithm of replay attack detection, isolation, and recovery (RADIR) is designed to minimize deterioration from multi-stage attacks, which can guarantee the estimated performance of the system as much as possible. Finally, the unmanned ground vehicle system is applied to validate the theoretical results, where the dataset of replay attacks is obtained by capturing the normal operation data of a moving vehicle. Also, we compare the optimal encryption strategy designed in this paper with general centralized and random scheduling strategies.},
  archive      = {J_NEUCOM},
  author       = {Yunbo Song and Dan Ye},
  doi          = {10.1016/j.neucom.2023.126698},
  journal      = {Neurocomputing},
  pages        = {126698},
  shortjournal = {Neurocomputing},
  title        = {Replay attack detection and mitigation for cyber–physical systems via RADIR algorithm with encryption scheduling},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PF-BERxiT: Early exiting for BERT with parameter-efficient
fine-tuning and flexible early exiting strategy. <em>NEUCOM</em>,
<em>558</em>, 126690. (<a
href="https://doi.org/10.1016/j.neucom.2023.126690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The industrial usage of huge pre-training language models such as BERT and ALBERT are limited by the computational probability problem in the fine-tuning process and overthinking problem in the inference process. PF-BERxiT has been proposed to optimize the pre-trained languages with a novel parameter-efficient fine-tuning method and a flexible early exiting strategy. Significantly, the new parameter-efficient fine-tuning model integrates a bottleneck adapter architecture parallel to the transformer architecture, and only the adapter&#39;s parameters are adjusted. In addition, we integrate an extra sub-learning module to learn the samples&#39; characteristics, improving the accuracy and efficiency simultaneously. The flexible exiting strategy allows the model to exit early if the similarity score of adjacent layers is less than the threshold for pre-defined times. It is more flexible than previous early exiting methods, for it can simultaneously adjust the similarity score thresholds and patience parameters according to the request traffic. Extensive experiments are conducted on the GLUE benchmark, demonstrating that: (1) PF-BERxiT outperforms conventional training and parameter-efficient strategies with only a few parameters fine-tuned. (2) PF-BERxiT strikes a better balance between model performances and speedup ratios than previous state-of-the-art (SOTA) early exiting methods such as PABEE and BERxiT. (3) Ablation studies in the fine-tuning process demonstrate that the best bottleneck dimension r of the adapters is 32, and the adapters placed parallel to the feed-forward module are more efficient. (4) Ablation studies in the inference process demonstrate that for variants of PF-BERxiT with different similarity scores, PF-BERxiT-kl and PF-BERxiT-bikl attain better speedup-accuracy trade-offs than PF-BERxiT-rekl. Our PF-BERxiT helps attain a better trade-off between performance and efficiency, providing a reference for the efficient application of neural computing.},
  archive      = {J_NEUCOM},
  author       = {Xiangxiang Gao and Yue Liu and Tao Huang and Zhongyu Hou},
  doi          = {10.1016/j.neucom.2023.126690},
  journal      = {Neurocomputing},
  pages        = {126690},
  shortjournal = {Neurocomputing},
  title        = {PF-BERxiT: Early exiting for BERT with parameter-efficient fine-tuning and flexible early exiting strategy},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning for few-shot text generation
adaptation. <em>NEUCOM</em>, <em>558</em>, 126689. (<a
href="https://doi.org/10.1016/j.neucom.2023.126689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel method based on reinforcement learning (RL) to control the generation model in adapting to new domains with limited samples. To avoid the problem of overfitting, the method combines maximum likelihood estimation (MLE) with RL process to improve the sample utilization rate and reduce the sample requirement of RL. The training process is divided into two parts: pre-training and fine-tuning, to effectively express the semantic of the target domain. In order to ensure the robustness of the reward function, adversarial training is introduced. A new measurement called “Net Accuracy” is proposed to better evaluate the domain relevance of the generated text and eliminate the problem of inaccurate domain relevance measurement caused by overfitting and generating a large amount of duplicate text. Finally, experimental results show the effectiveness and superiority of the proposed method in five target domains.},
  archive      = {J_NEUCOM},
  author       = {Pengsen Cheng and Jinqiao Dai and Jiamiao Liu and Jiayong Liu and Peng Jia},
  doi          = {10.1016/j.neucom.2023.126689},
  journal      = {Neurocomputing},
  pages        = {126689},
  shortjournal = {Neurocomputing},
  title        = {Reinforcement learning for few-shot text generation adaptation},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-relational dynamic graph representation learning.
<em>NEUCOM</em>, <em>558</em>, 126688. (<a
href="https://doi.org/10.1016/j.neucom.2023.126688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many dynamic graph representation learning methods have emerged due to the ubiquity of dynamic graph networks, such as social networks, medical networks, citation networks and traffic networks. Many researchers only consider the unitary relational topological information in a dynamic graph. However, real dynamic networks contain a large amount of multi-relational topological information. For example, there are different interactive relations such as sending a message, adding a friend, making a phone call, and sending an email in a social network, and they have different effects on node representation and should be distinguished. In addition, the non-topological information of nodes plays an important role in the node representation. Although these two types of information have been shown to improve the performance of many dynamic graph tasks, existing dynamic graph representation learning models could not integrate them well. Therefore, in this paper, we propose MRDGNN , a Multi-Relational Dynamic Graph Neural Network model, which can capture the dynamic evolution under each relational topology in the graph through a temporal multi-relational topology updater, including the participation of multi-relational topological and non-topological information of nodes. These two kinds of information will be adaptively fused into the representation of nodes by a merger. MRDGNN is continuously updated with the evolution of dynamic graphs and is a real-time learnable representation learning framework. Finally, we validate the effectiveness of MRDGNN for link prediction and relation prediction on four real datasets.},
  archive      = {J_NEUCOM},
  author       = {Pingtao Duan and Xiangsheng Ren and Yuting Liu},
  doi          = {10.1016/j.neucom.2023.126688},
  journal      = {Neurocomputing},
  pages        = {126688},
  shortjournal = {Neurocomputing},
  title        = {Multi-relational dynamic graph representation learning},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). DeformSg2im: Scene graph based multi-instance image
generation with a deformable geometric layout. <em>NEUCOM</em>,
<em>558</em>, 126684. (<a
href="https://doi.org/10.1016/j.neucom.2023.126684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, scene graph based image generation has emerged to be an important research direction for advanced multi-instance generation tasks. Scene layout generation, the phase that produces the instance-wise visual representations and maintains the spatial relationships among all instances, is vital in translating a scene graph to an image. However, the scene layouts generated by existing methods are too coarse and semantically inconsistent with the given scene graph, which results in quality degradation of the generated images. Motivated by this, we propose a novel scene graph based image generation model called DeformSg2im, which aims to generate visually appealing and semantically faithful images according to the given scene graphs. Our method addresses the aforementioned problems from two aspects. In one aspect, we present an attention-based instance embedding estimator to refine the shape information for each instance. By introducing attention maps to the estimation of instance embeddings, our method is able to generate more plausible instances with sharp edges on the images. In the other aspect, a spatial warping network (SWN) is proposed to adaptively capture the spatial dependencies among instances. With sequential modeling and geometric deformations, the SWN is capable of generating the scene layout conforming to the given scene graph. Extensive experiments show that our model generates images with high visual quality and achieves competitive quantitative results compared to existing works. Ablation studies on the proposed modules are also conducted, and the results demonstrate the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Zhiming Wang and Yuxiao Li and Danlan Huang and Juan Wang and Ning Ge and Jianhua Lu},
  doi          = {10.1016/j.neucom.2023.126684},
  journal      = {Neurocomputing},
  pages        = {126684},
  shortjournal = {Neurocomputing},
  title        = {DeformSg2im: Scene graph based multi-instance image generation with a deformable geometric layout},
  volume       = {558},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to refine object boundaries. <em>NEUCOM</em>,
<em>557</em>, 126742. (<a
href="https://doi.org/10.1016/j.neucom.2023.126742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Deep-Learning-based contour detectors suffer from the issues of the sharpness and the correctness of their predictions, which often need offline post-processing to sharpen the results as well as improve model performance. In this work, we present a novel method that can learn to refine object contour in training and directly output crisp object boundaries in inference. To this end, we first introduce a keypoint-focal loss that draws point-based attention to the isolated contour annotations. It allows an edge detector to jointly optimize the appearance thickness and the localization accuracy of predictions in the training procedure. Moreover, we present a regularization loss to further improve the performance of an edge detector. Lastly, we present the Contour Transformer model for precisely localizing object boundaries in images. We repurpose and integrate a Transformer-style hyper module into an encoder–decoder network, effectively aggregating global contextual information on high-level features and significantly enhancing the discriminative power for classifying foreground/background pixels. We train and test our Attention and Contour Transformer detector (ACTD) on four widely adopted datasets, i.e., BSDS500, NYUD, Multi-Cue, and RoadNet. The proposed method achieves an ODS F-score of 0.826 on BSDS500 and an ODS F-score of 0.783 on NYUD, outperforming previous top detectors.},
  archive      = {J_NEUCOM},
  author       = {Ruoxi Deng and Zhao-Min Chen and Huiling Chen and Jie Hu},
  doi          = {10.1016/j.neucom.2023.126742},
  journal      = {Neurocomputing},
  pages        = {126742},
  shortjournal = {Neurocomputing},
  title        = {Learning to refine object boundaries},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Homogeneous–heterogeneous hybrid ensemble for concept-drift
adaptation. <em>NEUCOM</em>, <em>557</em>, 126741. (<a
href="https://doi.org/10.1016/j.neucom.2023.126741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Homogeneous ensembles are very effective in concept-drift adaptation. However, choosing an appropriate base learner and its hyperparameters suitable for a stream is critical for their predictive performance . Moreover, the best base learner and its hyperparameters may change over time as the stream evolves, necessitating manual reconfiguration. On the other hand, heterogeneous ensembles train multiple base learners belonging to diverse algorithmic families with different inductive biases. Though it eliminates the need to manually choose the best base learner for a stream, their size is often restricted to the number of unique base learner algorithms, limiting their scalability. We combine the strengths of homogeneous and heterogeneous ensembles into a unified scalable ensemble framework with higher predictive performance , while eliminating the need to manually specify and adapt the optimal base learner and its hyperparameters for a stream. The proposed ensemble named H3E is a single-pass hybrid algorithm which uses a genetic algorithm (GA) based optimization in combination with stacking to provide high predictive performance at a competitive computational cost. Experiments on several real and synthetic data streams affected by diverse drift types confirm the superior predictive performance and utility of our approach in comparison to popular online ensembles.},
  archive      = {J_NEUCOM},
  author       = {Jobin Wilson and Santanu Chaudhury and Brejesh Lall},
  doi          = {10.1016/j.neucom.2023.126741},
  journal      = {Neurocomputing},
  pages        = {126741},
  shortjournal = {Neurocomputing},
  title        = {Homogeneous–Heterogeneous hybrid ensemble for concept-drift adaptation},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-player evolutionary game of federated learning
incentive mechanism based on system dynamics. <em>NEUCOM</em>,
<em>557</em>, 126739. (<a
href="https://doi.org/10.1016/j.neucom.2023.126739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has emerged as a new way of data sharing. The participants in the federation tend to choose different strategies based on their benefits, which is formalized into an evolutionary game model. Existing techniques can limit the malicious behavior of participants by detecting betrayers or weakening their influence. The problem that whether there is an incentive mechanism which makes participants spontaneously choose to cooperate honestly and maintains the stability of the federated learning system is urgent. In this paper, we develop a multi-player evolutionary game model in federated learning. We model the federated learning process by evaluating the payoffs of the central server, internal clients, and external clients. The stability of the federated learning system in the long-term dynamics process is assessed by seeking the evolutionarily stable equilibrium solutions. In this paper, mathematical reasoning and computer simulation are combined to analyze the impact of reward and punishment strategies in incentive mechanisms on the game process and game equilibrium. An incentive mechanism is designed to achieve evolutionarily stable equilibrium while make most clients join the federation spontaneously and cooperate honestly. Finally, the effectiveness, stability, and generalizability of this incentive mechanism are verified by sensitivity analysis and Lyapunov stability theory .},
  archive      = {J_NEUCOM},
  author       = {Pengxi Yang and Hua Zhang and Fei Gao and Yanxin Xu and Zhengping Jin},
  doi          = {10.1016/j.neucom.2023.126739},
  journal      = {Neurocomputing},
  pages        = {126739},
  shortjournal = {Neurocomputing},
  title        = {Multi-player evolutionary game of federated learning incentive mechanism based on system dynamics},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting cancer outcomes from whole slide images via
hybrid supervision learning. <em>NEUCOM</em>, <em>557</em>, 126736. (<a
href="https://doi.org/10.1016/j.neucom.2023.126736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaboratively leveraging limited pixel-level segmentation annotations and large-scale slide-level classification labels in hybrid supervision learning can significantly enhance model performance. However, the direct application of this approach within computational pathology presents challenges as end-to-end classification models grapple with processing high-resolution whole slide images (WSIs). An alternative approach is to use patch-based models with pixel-level pseudo-labels, but these models can be susceptible to the cumulative effects of noisy labels, leading to convergence and drift problems during iterative training. To surmount these hurdles, we propose a hybrid supervision learning framework tailored for pathological image classification . Our method employs coarse classification labels to optimize pixel-level pseudo-labels and incorporates a comprehensive strategy to diminish false negatives and positives throughout the segmentation process . This framework holistically integrates the supervised information derived from segmentation and classification procedures, and is applicable to the general classification of high-resolution images, thereby boosting both specificity and sensitivity. We assess our proposed method’s effectiveness using one publicly accessible dataset and two proprietary datasets, collectively constituting over 10,000 pathological images of various disease types such as gastric, cervical, and breast cancer. Our experimental results reveal a 100\% sensitivity rate in slide-level classification tasks , simultaneously reducing the false-positive rate to a mere third of the state-of-the-art. In conclusion, this paper presents a potent instrument for the precise and efficient classification of high-resolution pathological images, with promising results showcased across a wide array of datasets and disease types. Code is available at https://github.com/JarveeLee/HybridSupervisionLearning_Pathology .},
  archive      = {J_NEUCOM},
  author       = {Xianying He and Jiahui Li and Fang Yan and Linlin Wang and Wen Chen and Xiaodi Huang and Zhiqiang Hu and Qi Duan and Hongsheng Li and Shaoting Zhang and Jie Zhao},
  doi          = {10.1016/j.neucom.2023.126736},
  journal      = {Neurocomputing},
  pages        = {126736},
  shortjournal = {Neurocomputing},
  title        = {Predicting cancer outcomes from whole slide images via hybrid supervision learning},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leader learning loss function in neural network
classification. <em>NEUCOM</em>, <em>557</em>, 126735. (<a
href="https://doi.org/10.1016/j.neucom.2023.126735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning , based on Empirical Risk Minimization (ERM), typically aims to fit the ideal outputs of all samples due to its large capacity. However, models trained based on empirical losses like cross entropy (CE) or mean square error (MSE), often learn unnecessary information during classification, leading to premature overfitting. On the other hand, the result-focused loss functions, i.e., zero–one loss or hinge loss, are hard to optimize and thus are rarely applied directly in neural network . This paper proposes a novel leader learning in classification, where CE is gradually trained by classification results using sample-dependent cost-sensitive learning. As complementary, the stepwise-changed CE covers the deficiency on classification error while preserving the advantage of fast convergence. In this way, the deviation between CE and classification error can be corrected. Experimental results demonstrate that the proposed leader learning has a more significant convergence trend than the baseline algorithms. Moreover, the loss function learned from a specific dataset has broad generality that can be transferred to other models as prior knowledge.},
  archive      = {J_NEUCOM},
  author       = {Siyuan Zhang and Linbo Xie},
  doi          = {10.1016/j.neucom.2023.126735},
  journal      = {Neurocomputing},
  pages        = {126735},
  shortjournal = {Neurocomputing},
  title        = {Leader learning loss function in neural network classification},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Intent-aware graph neural network for point-of-interest
embedding and recommendation. <em>NEUCOM</em>, <em>557</em>, 126734. (<a
href="https://doi.org/10.1016/j.neucom.2023.126734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point of Interest (POI) recommendation algorithms can help users find the POIs that they prefer, and they can also help merchants to find potential customers. However, most existing methods still have difficulties effectively utilizing the information in users’ check-in data. Significantly, they ignore the intent behind the users’ check-in behaviors , which limits the recommendation performance. In this paper, we propose an I ntent A ware G raph N eural N etwork-based model(IAGNN) to predict/recommend the next POI with which the target user may interact. Specifically, IAGNN first models the user’s check-in behavior sequences as graphs and utilizes the information transmission mechanism of the graph neural network (GNN) to learn the feature vector representation (embedding) of POIs. Second, we devise a hierarchical attention network for capturing users’ preferences adaptively. At the same time, we design a user intent-aware module based on disentangled representations to extract the user’s intents. Finally, the user’s preferences and their intents obtained by the user intent perception module are combined to recommend the POI for the user. Extensive evaluations are conducted on two real-world POI check-in datasets. The experimental results show that our proposed model IAGNN outperforms the baselines in terms of both recall and MRR.},
  archive      = {J_NEUCOM},
  author       = {Xingliang Wang and Dongjing Wang and Dongjin Yu and Runze Wu and Qimeng Yang and Shuiguang Deng and Guandong Xu},
  doi          = {10.1016/j.neucom.2023.126734},
  journal      = {Neurocomputing},
  pages        = {126734},
  shortjournal = {Neurocomputing},
  title        = {Intent-aware graph neural network for point-of-interest embedding and recommendation},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binary multi-view clustering with spectral embedding.
<em>NEUCOM</em>, <em>557</em>, 126733. (<a
href="https://doi.org/10.1016/j.neucom.2023.126733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Techniques for large-scale multi-view clustering have attracted increasing attention in recent years. To explore complementary and consensus information across multiple views, mapping multi-view data into a hamming space for binary multi-view learning is highly effective. However, for binary multi-view clustering, it is difficult to adopt the local manifold structure of original data into the consensus representation. Therefore, a novel algorithm named Binary Multi-View Clustering With Spectral Embedding (BMVC_SE) is proposed in this study. This algorithm unifies binary consensus representation learning and multi-view spectral learning into a joint framework. Specifically, this algorithm exploits the shareable and individual information across multi-view data to learn a binary consensus representation. Furthermore, spectral rotation technique is employed to embed manifold information from original multi-view data into binary consensus representation. Note that a multi-view GPI algorithm is proposed in this study to obtain the better local manifold information. We also provide an effective optimization method to solve the existing method. Extensive experimental results show that our method outperforms some state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zeqi Ma and Wai Keung Wong and Li-ying Zhang},
  doi          = {10.1016/j.neucom.2023.126733},
  journal      = {Neurocomputing},
  pages        = {126733},
  shortjournal = {Neurocomputing},
  title        = {Binary multi-view clustering with spectral embedding},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Signed attention based graph neural network for graphs with
heterophily. <em>NEUCOM</em>, <em>557</em>, 126731. (<a
href="https://doi.org/10.1016/j.neucom.2023.126731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are an effective deep learning methodology used to encode graph-structured data. Several popular GNNs have demonstrated excellent results in various downstream tasks, including node classification and visualization, especially when homophily occurs in graphs where connected nodes may share identical features or labels. Although recent models can extend GNNs beyond homophily, two fundamental weaknesses limit their expressive ability. First, most of the existing GNNs fail to adaptively aggregate information from different neighbors, especially negative information from different classes. Even worse, they fail to encode the positional information, leading to the inevitable conflation of information from different neighborhoods that should be specified with different importance. To overcome these limitations, we propose a novel graph neural network model based on the Signed Attention mechanism (SA), namely SAGNN. Specifically, the signed attention mechanism is presented to adaptively learn the complex relationship between exact neighboring nodes. Compared with the original non-negative attention mechanism, SA aggregates information from both positive and negative neighbors, especially on graphs with heterophily. Furthermore, we propose an Exactly Higher-Order Neighborhood Aggregation that implicitly encodes positional information to specify the importance of different neighborhoods. Extensive experiments conducted on eight benchmark datasets demonstrate that the proposed SAGNN model learns more robust and expressive representations, and achieves superior performance on node classification and visualization tasks.},
  archive      = {J_NEUCOM},
  author       = {Yang Wu and Liang Hu and Yu Wang},
  doi          = {10.1016/j.neucom.2023.126731},
  journal      = {Neurocomputing},
  pages        = {126731},
  shortjournal = {Neurocomputing},
  title        = {Signed attention based graph neural network for graphs with heterophily},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Syntax-enhanced aspect-based sentiment analysis with
multi-layer attention. <em>NEUCOM</em>, <em>557</em>, 126730. (<a
href="https://doi.org/10.1016/j.neucom.2023.126730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key task of fine-grained sentiment analysis , aspect-based sentiment analysis aims to analyse people’s opinions at the aspect level from user-generated texts. Various sub-tasks have been defined according to different scenarios, extracting aspect terms, opinion terms, and the corresponding sentiment. However, most existing studies merely focus on a specific sub-task or a subset of sub-tasks, having many complicated models designed and developed. This hinders the practical applications of aspect-based sentiment analysis. Therefore, some unified frameworks are proposed to handle all the subtasks, but most of them suffer from two limitations. First, the syntactic features are neglected, but such features have been proven effective for aspect-based sentiment analysis. Second, very few efficient mechanisms are developed to leverage important syntactic features, e.g., dependency relations , dependency relation types, and part-of-speech tags. To address these challenges, in this paper, we propose a novel unified framework to handle all defined sub-tasks for aspect-based sentiment analysis. Specifically, based on the graph convolutional network , a multi-layer semantic model is designed to capture the semantic relations between aspect and opinion terms. Moreover, a multi-layer syntax model is proposed to learn explicit dependency relations from different layers. To facilitate the sub-tasks, the learned semantic features are propagated to the syntax model with better semantic guidance to learn the syntactic representations comprehensively. Different from the conventional syntactic model, the proposed framework introduces two attention mechanisms . One is to model dependency relation and type, and the other is to encode part-of-speech tags for detecting aspect and opinion term boundaries. Extensive experiments are conducted to evaluate the proposed novel unified framework, and the experimental results on four groups of real-world datasets explicitly demonstrate the superiority of the proposed framework over a range of baselines.},
  archive      = {J_NEUCOM},
  author       = {Jingli Shi and Weihua Li and Quan Bai and Yi Yang and Jianhua Jiang},
  doi          = {10.1016/j.neucom.2023.126730},
  journal      = {Neurocomputing},
  pages        = {126730},
  shortjournal = {Neurocomputing},
  title        = {Syntax-enhanced aspect-based sentiment analysis with multi-layer attention},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Within- cross- consensus-view representation-based
multi-view multi-label learning with incomplete data. <em>NEUCOM</em>,
<em>557</em>, 126729. (<a
href="https://doi.org/10.1016/j.neucom.2023.126729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a multi-view multi-label learning for incomplete data which are ubiquitous with the usage of three kinds of representations including within-view representation, cross-view representation, and consensus-view representation. Different from the recent learning machines , the proposed learning machine takes the feature-oriented information, label-oriented information, and associated information between features and labels in multiple representations together and exploits the hidden useful information of available instances with the usage of instance–instance correlations, feature–feature correlations, label-label correlations, and feature–label correlations. The developed learning machine is named as within- cross- consensus-view representation-based multi-view multi-label learning with incomplete data (WCC-MVML-ID). Extensive experiments on multiple multi-view and multi-label data sets with incomplete data validate the effectiveness of WCC-MVML-ID and it can be concluded that (1) WCC-MVML-ID outperforms other compared learning machines and its performances are more stable even though the missing rates of features and labels being larger; (2) compared with within-view information and consensus-view information, cross-view information is more useful for the processing problem about incomplete data; (3) WCC-MVML-ID can converge within 45 iterations.},
  archive      = {J_NEUCOM},
  author       = {Changming Zhu and Yanchen Liu and Duoqian Miao and Yilin Dong and Witold Pedrycz},
  doi          = {10.1016/j.neucom.2023.126729},
  journal      = {Neurocomputing},
  pages        = {126729},
  shortjournal = {Neurocomputing},
  title        = {Within- cross- consensus-view representation-based multi-view multi-label learning with incomplete data},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iterative sequential approximate solutions method to
hyers–ulam stability of time-varying delayed fractional-order neural
networks. <em>NEUCOM</em>, <em>557</em>, 126727. (<a
href="https://doi.org/10.1016/j.neucom.2023.126727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a key issue in the field of stability analysis for fractional-order neural networks (FONNs) concerning whether the exact solution of the FONNs exists under the condition that a series of successive approximate solutions of the models can be obtained. If so, can the state differences between the approximate solutions and the exact solution be estimated? Hyers–Ulam stability, as one of the powerful tools to solve this problem, has attracted the attention of scholars, and various related research achievements have been reported. In view of this, this paper aims to investigate the Hyers–Ulam stability of FONNs with time-varying delays. Using the successive approximation method and the modified retarded Henry–Gronwall integral inequality, several conditions guaranteeing the existence and uniqueness of the exact solution of FONNs with time-varying delays are derived. Moreover, the corresponding results on the Hyers–Ulam–Rassias stability of the addressed models are given. Finally, a numerical example is designed to illustrate the efficiency and rationality of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Mengqi Li and Xujun Yang and Qiankun Song and Xiaofeng Chen},
  doi          = {10.1016/j.neucom.2023.126727},
  journal      = {Neurocomputing},
  pages        = {126727},
  shortjournal = {Neurocomputing},
  title        = {Iterative sequential approximate solutions method to Hyers–Ulam stability of time-varying delayed fractional-order neural networks},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PWAGAT: Potential web attacker detection based on graph
attention network. <em>NEUCOM</em>, <em>557</em>, 126725. (<a
href="https://doi.org/10.1016/j.neucom.2023.126725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attacker probing behavior detection is a notch in the current security defense system. Most cyber-attack detection research focuses on real-time payload interception and attack source tracing. However, the defense system cannot predict the attack behavior before the attack launches and cannot provide sufficient reaction and preparation time for the network administrators. Therefore, the current security system urgently needs to be improved by detecting cyber-attack precursors. We propose a potential Web attacker identification method based on a graph attention network (PWAGAT) by studying the features of the attacker’s behavior pattern before launching a Web attack. The core of PWAGAT is to identify the probing behavior of attackers and find those suspicious users with a high probability of carrying out Web attacks. The PWAGAT trains the embedding learning representation of each behavioral node from the Web attack behavior graph (WABG) through GAT and then uses the deep forest algorithm to train a classification model that recognizes probing behaviors. On the WAB-dataset provided by the Institute of Information Security of Sichuan University, the experiment proved that PWAGAT performed better than other graph learning methods in performing node embedding and classification of hacking behaviors. The results showed that identifying hacker probing behavior could help discover potential Web attackers, alerting defenders to assist in subsequent attack detection.},
  archive      = {J_NEUCOM},
  author       = {Yijia Xu and Yong Fang and Zhonglin Liu and Qiang Zhang},
  doi          = {10.1016/j.neucom.2023.126725},
  journal      = {Neurocomputing},
  pages        = {126725},
  shortjournal = {Neurocomputing},
  title        = {PWAGAT: Potential web attacker detection based on graph attention network},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symmetric nonnegative matrix factorization: A systematic
review. <em>NEUCOM</em>, <em>557</em>, 126721. (<a
href="https://doi.org/10.1016/j.neucom.2023.126721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, symmetric non-negative matrix factorization (SNMF), a variant of non-negative matrix factorization (NMF), has emerged as a promising tool for data analysis. This paper mainly focuses on the theoretical idea, the basic model, the optimization method, and the variants of SNMF. The SNMF-related approaches can be generally classified into two main categories, Classic SNMFs and Extended SNMFs. The classic SNMFs contain Orthogonal SNMF, Sparse SNMF, Manifold structure based SNMF and Pairwise constraint based SNMF, besides, extended SNMFs include Self-supervised SNMF, MV-WSNMF and Multi-view SNMF. According to different classes of SNMFs, this review elaborates on the key concepts, characteristics, and current issues of these algorithms. The clustering performance of SNMF and its variants on three object image datasets is empirically compared. In addition, the effects of some algorithms for solving SNMF have been compared and the performance of similarity matrix construction methods is also compared. Finally, some open problems with SNMF are discussed.},
  archive      = {J_NEUCOM},
  author       = {Wen-Sheng Chen and Kexin Xie and Rui Liu and Binbin Pan},
  doi          = {10.1016/j.neucom.2023.126721},
  journal      = {Neurocomputing},
  pages        = {126721},
  shortjournal = {Neurocomputing},
  title        = {Symmetric nonnegative matrix factorization: A systematic review},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Internet of medical things: A systematic review.
<em>NEUCOM</em>, <em>557</em>, 126719. (<a
href="https://doi.org/10.1016/j.neucom.2023.126719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Medical Things (IoMT) refers to applying Internet of Things (IoT) into the medical field. The IoMT enables a medical system to connect various smart devices, such as wearable sensors, medical examination instruments, and hospital assets, for establishing an information platform. These smart devices act as the basic nodes in an IoMT system, collecting or generating health data and transmitting the data to the server for further processing and analysis. Physicians apply health data to make better medical decisions. Recently, the IoMT has been widely applied in many areas, including smart hospital, remote health monitoring, disease diagnosis, and infectious disease tracking. In this review, we investigated the IoMT from its concept and theory to its deployment domains, adopted technologies, and applications. We provided theoretical explanations with various examples and more than one hundred representative references. We also presented a cutting-edge discussion for the challenges and directions of the IoMT. We hoped that this systematic review would be beneficial to readers of all levels and backgrounds, including industry beginners, medical institution administrators, policy makers, and experienced researchers.},
  archive      = {J_NEUCOM},
  author       = {Chenxi Huang and Jian Wang and Shuihua Wang and Yudong Zhang},
  doi          = {10.1016/j.neucom.2023.126719},
  journal      = {Neurocomputing},
  pages        = {126719},
  shortjournal = {Neurocomputing},
  title        = {Internet of medical things: A systematic review},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive dynamic programming based composite control for
profile tracking with multiple constraints. <em>NEUCOM</em>,
<em>557</em>, 126711. (<a
href="https://doi.org/10.1016/j.neucom.2023.126711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A composite control method based on adaptive dynamic programming (ADP) is developed to solve the profile tracking problem of the hypersonic gliding vehicle (HGV) with multiple constraints (flight and input constraints). First, based on the framework of the standard profile guidance method, a standard drag acceleration–velocity profile is planned as the tracking target, which satisfies the flight constraints. Second, a composite controller based on ADP and dynamic surface control (DSC) is proposed to track the planned profile and satisfy both the terminal conditions and the input constraint. An ADP method is developed to realize the optimal control through a critic neural network (NN) approximation for the solution of Hamilton–Jacobi–Bellman (HJB) equation. By using DSC method, the steady control is realized. Finally, the states of the closed-loop system and the weight estimation error are proved to be uniformly ultimately bounded, and the effectiveness of the proposed composite control method is verified via simulations.},
  archive      = {J_NEUCOM},
  author       = {Rui Tang and Biao Luo and Yuxin Liao},
  doi          = {10.1016/j.neucom.2023.126711},
  journal      = {Neurocomputing},
  pages        = {126711},
  shortjournal = {Neurocomputing},
  title        = {Adaptive dynamic programming based composite control for profile tracking with multiple constraints},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning in colloids: Synapse-like ZnO + DMSO colloid.
<em>NEUCOM</em>, <em>557</em>, 126710. (<a
href="https://doi.org/10.1016/j.neucom.2023.126710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colloids subjected to electrical stimuli exhibit a reconfiguration that might be used to store information and potentially compute. In a colloidal suspension of ZnO nanoparticles in DMSO, we investigated the learning, memorization, time and stimulation’s voltage dependence of conductive network formation. The relationships between the critical resistance and stimulation time have been reconstructed. The critical voltage (i.e., the stimulation voltage required to drop the resistance) was found to decrease as stimulation time increased. We characterized a dispersion of conductive ZnO nanoparticles in the DMSO polymeric matrix using FESEM and UV–visible absorption spectrum.},
  archive      = {J_NEUCOM},
  author       = {Noushin Raeisi Kheirabadi and Alessandro Chiolerio and Neil Phillips and Andrew Adamatzky},
  doi          = {10.1016/j.neucom.2023.126710},
  journal      = {Neurocomputing},
  pages        = {126710},
  shortjournal = {Neurocomputing},
  title        = {Learning in colloids: Synapse-like ZnO + DMSO colloid},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EEG-based neural networks approaches for fatigue and
drowsiness detection: A survey. <em>NEUCOM</em>, <em>557</em>, 126709.
(<a href="https://doi.org/10.1016/j.neucom.2023.126709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drowsiness is a state of fatigue or sleepiness characterized by a strong urge to sleep. It is correlated with a progressive decline in response time, compromised processing of available information, more errors in short-term memory, and reduced vigilance behaviors . The electroencephalogram (EEG), a recording of the brain’s electrical activities, has demonstrated the most robust association with drowsiness. As a result, EEG is widely recognized as a dependable indicator for evaluating drowsiness, fatigue, and performance levels. In this survey paper, we thoroughly investigate the application of shallow and deep neural network approaches utilizing EEG signals for the detection of fatigue and drowsiness. As far as our knowledge extends, this is the pioneering survey paper dedicated to exploring this specific research domain. The paper presents a comprehensive overview of the diverse EEG features utilized in the detection of fatigue and drowsiness, the different types of neural networks, and the reported performance of these methods in the literature. Additionally, the paper thoroughly examines the challenges and limitations associated with EEG-based fatigue and drowsiness detection and highlights directions for future research. The survey aims to offer a comprehensive overview of the existing methods in EEG-based fatigue and drowsiness detection , serving as a valuable resource for researchers and practitioners working in the respective field.},
  archive      = {J_NEUCOM},
  author       = {Alice Othmani and Aznul Qalid Md Sabri and Sinem Aslan and Faten Chaieb and Hala Rameh and Romain Alfred and Dayron Cohen},
  doi          = {10.1016/j.neucom.2023.126709},
  journal      = {Neurocomputing},
  pages        = {126709},
  shortjournal = {Neurocomputing},
  title        = {EEG-based neural networks approaches for fatigue and drowsiness detection: A survey},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ChatAgri: Exploring potentials of ChatGPT on
cross-linguistic agricultural text classification. <em>NEUCOM</em>,
<em>557</em>, 126708. (<a
href="https://doi.org/10.1016/j.neucom.2023.126708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of sustainable smart agriculture, a vast amount of agricultural news text is posted online, accumulating significant agricultural knowledge. To efficiently access this knowledge, effective text classification techniques are urgently needed. Deep learning approaches, such as fine-tuning strategies on pre-trained language models (PLMs), have shown remarkable performance gains. Nonetheless, these methods face several complex challenges, including limited agricultural training data, poor domain transferability (especially across languages), and complex and expensive deployment of large models. Inspired by the success of recent ChatGPT models (e.g., GPT-3.5, GPT-4), this work explores the potential of applying ChatGPT in the field of agricultural informatization. Various crucial factors, such as prompt construction, answer parsing , and different ChatGPT variants, are thoroughly investigated to maximize its capabilities. A preliminary comparative study is conducted, comparing ChatGPT with PLMs-based fine-tuning methods and PLMs-based prompt-tuning methods. Empirical results demonstrate that ChatGPT effectively addresses the mentioned research challenges and bottlenecks, making it an ideal solution for agricultural text classification. Moreover, ChatGPT achieves comparable performance to existing PLM-based fine-tuning methods, even without fine-tuning on agricultural data samples. We hope this preliminary study could inspire the emergence of a general-purpose AI paradigm for agricultural text processing.},
  archive      = {J_NEUCOM},
  author       = {Biao Zhao and Weiqiang Jin and Javier Del Ser and Guang Yang},
  doi          = {10.1016/j.neucom.2023.126708},
  journal      = {Neurocomputing},
  pages        = {126708},
  shortjournal = {Neurocomputing},
  title        = {ChatAgri: Exploring potentials of ChatGPT on cross-linguistic agricultural text classification},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GAA-PPO: A novel graph adversarial attack method by
incorporating proximal policy optimization. <em>NEUCOM</em>,
<em>557</em>, 126707. (<a
href="https://doi.org/10.1016/j.neucom.2023.126707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Graph Convolutional Network (GCN) has demonstrated impressive performance in processing graph structured data. However recent studies have revealed that GCN is vulnerable to adversarial attacks , where a small amount of data modification can significantly affect the performance of the GCN models. While most existing studies node injection attacks with graph reinforcement learning by considering gradient information, they still suffer from the problems that the step size of the policy gradient is difficult to determine, and the attack effect needs to be further improved. In light of the above issues, this paper proposes a Graph Adversarial Attack method by incorporating Proximal Policy Optimization named GAA-PPO, which fills subtasks of sequentially generating features and links for injected nodes without modifying existing nodes or edges. GAA-PPO comprises two main components: node injection attack network ( actor network ) and value prediction network ( critic network ). Specifically, the actor network leverages a node generator and an edge sampler to generate appropriate features and edges for the injected nodes. Notably, a novel edge sampler that incorporates Approximation Personalized Propagation of Neural Prediction (APPNP) is introduced to effectively propagate malicious features of the injected nodes. On the other hand, the critic network evaluates the performance of the perturbed graph at each stage. To enhance the stability of the algorithm, GAA-PPO employs the importance sampling technique of Proximal Policy Optimization (PPO) during the training process. Extensive experiments on three publicly benchmark datasets show that GAA-PPO yields significant performance advantages over the state-of-the-art method.},
  archive      = {J_NEUCOM},
  author       = {Shuxin Yang and Xiaoyang Chang and Guixiang Zhu and Jie Cao and Weiping Qin and Youquan Wang and Zhendong Wang},
  doi          = {10.1016/j.neucom.2023.126707},
  journal      = {Neurocomputing},
  pages        = {126707},
  shortjournal = {Neurocomputing},
  title        = {GAA-PPO: A novel graph adversarial attack method by incorporating proximal policy optimization},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ESA: Excitation-switchable attention for convolutional
neural networks. <em>NEUCOM</em>, <em>557</em>, 126706. (<a
href="https://doi.org/10.1016/j.neucom.2023.126706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although various attention mechanisms can boost the representational power of convolutional neural networks (CNNs) and improve their performance, selecting an appropriate attention module becomes challenging when backbones or datasets change. Besides, as different CNN layers can learn distinct semantic features , applying the same attention module across all layers may not yield optimal results for enhancing the performance of a deep neural network. To address the above issues, we propose a novel excitation-switchable attention (ESA) to automatically select and integrate different excitation modules to compute attention maps, enabling a DNN to apply different attention modules in different layers for better feature learning and performance improvement. Extensive experiments on three widely-used image classification benchmarks demonstrate the superiority of our ESA over several well-known and widely-adopted attention modules.},
  archive      = {J_NEUCOM},
  author       = {Shanshan Zhong and Zhongzhan Huang and Wushao Wen and Zhijing Yang and Jinghui Qin},
  doi          = {10.1016/j.neucom.2023.126706},
  journal      = {Neurocomputing},
  pages        = {126706},
  shortjournal = {Neurocomputing},
  title        = {ESA: Excitation-switchable attention for convolutional neural networks},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ELM parameter estimation in view of maximum likelihood.
<em>NEUCOM</em>, <em>557</em>, 126704. (<a
href="https://doi.org/10.1016/j.neucom.2023.126704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme Learning Machine (ELM) can be considered a probabilistic model, wherein the output is a random variable characterized by its mean and variance, both crucial for assessing and enhancing ELM’s generalization ability . Despite its importance, limited research has been conducted on quantitative variance estimation and the underlying factors that influence connecting weight regularization . In this paper, we establish a connection between the variance and weights of ELM for regression problems , and propose maximum likelihood-based estimations for model parameters. We introduce a novel activation function and algorithms to generate hidden layer outputs and predicted outputs that adhere or approximate a normal distribution, as validated through experiments. Additionally, by leveraging the established relationship, we derive estimators for weights, variance, and confidence intervals of predicted values using Maximum Likelihood Estimation (MLE). The variance estimator enables a quantitative evaluation of generalization, and the link between variance and weights offers a theoretical basis for ELM regularization techniques.},
  archive      = {J_NEUCOM},
  author       = {Lanzhen Yang and Eric C.C. Tsang and Xizhao Wang and Chengling Zhang},
  doi          = {10.1016/j.neucom.2023.126704},
  journal      = {Neurocomputing},
  pages        = {126704},
  shortjournal = {Neurocomputing},
  title        = {ELM parameter estimation in view of maximum likelihood},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered impulsive control for synchronization in
finite time of fractional-order reaction–diffusion complex networks.
<em>NEUCOM</em>, <em>557</em>, 126703. (<a
href="https://doi.org/10.1016/j.neucom.2023.126703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the finite-time synchronization (FTS) issue for fractional-order reaction–diffusion complex networks (RDCNs). A finite-time stability principle, which plays a key role in the synchronization analysis later, is developed for fractional-order nonlinear impulsive system. A novel hybrid controller , which consists of a event-triggered controller and a impulsive controller, is designed to realize the global FTS objective for the considered network. By applying the Lyapunov stability theory and the fractional calculus, the global FTS conditions are addressed in the form of algebraic inequalities. In addition, the exclusion of Zeno behavior are proved for the designed event-triggered strategy. Finally, a numerical example is provided to illustrate the feasibility of the proposed control approach and the correctness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Xiaofei Xing and Huaiqin Wu and Jinde Cao},
  doi          = {10.1016/j.neucom.2023.126703},
  journal      = {Neurocomputing},
  pages        = {126703},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered impulsive control for synchronization in finite time of fractional-order reaction–diffusion complex networks},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A review-based feature-level information aggregation model
for graph collaborative filtering. <em>NEUCOM</em>, <em>557</em>,
126697. (<a href="https://doi.org/10.1016/j.neucom.2023.126697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To explicitly exploit the collaborative signals in the user-item interaction graph, a growing number of recent Collaborative Filtering (CF) studies adopt Graph Convolution Network (GCN) as a basis. Though effective, these methods basically treat all neighbors equally, ignoring the fact that neighbors should be target-related. While there are some works that assign different weights to neighbors via using the attention mechanism , they still suffer from two problems. First, the performance of them is limited by the lack of fine-grained details. Second, attention learned solely from interaction data may not reflect the user’s opinions accurately. To address these issues, we propose a Review-based Feature-level Information Aggregation (RFIA) graph model that incorporates the review information into the graph propagation to achieve more fine-grained information aggregation. The main idea of RFIA is to assign feature-level attention vectors for the interaction edges to adaptively adjust the contribution ratios of input neighbors across various dimensions, based on rich review information. Specifically, we first extract review features from text by BERT-Whitening. Then, we design non-linear feature extractors separately in two directions to further extract and refine these review features as feature-level attention. Finally, we design a graph contrastive learning module to optimize the learning of extractors under limited user behaviors . Experiments on three publicly available datasets validate the effectiveness and performance superiority of our proposed model.},
  archive      = {J_NEUCOM},
  author       = {Meng Liu and Xu Xu and Jianjun Li and Guohui Li},
  doi          = {10.1016/j.neucom.2023.126697},
  journal      = {Neurocomputing},
  pages        = {126697},
  shortjournal = {Neurocomputing},
  title        = {A review-based feature-level information aggregation model for graph collaborative filtering},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design, analysis, and application of fixed-time convergence
fuzzy ZNN model realized by dynamic fuzzy logic system for time-varying
sylvester equation. <em>NEUCOM</em>, <em>557</em>, 126696. (<a
href="https://doi.org/10.1016/j.neucom.2023.126696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the strengths of zeroing neural network (ZNN) in dealing with time-varying problems and the advantages of fuzzy logic system (FLS) in uncertain computing, a fixed-time convergence fuzzy ZNN (FTCFZNN) model realized by the FLS with dynamic membership functions is proposed for solving time-varying Sylvester equation (TVSE). The introduction of the dynamic membership functions in the FLS is one of the most meaningful attributes of this paper, and such a FLS is called the dynamic FLS (DFLS). The design parameter of the FTCFZNN model is the fuzzy parameter generated by the DFLS. Meanwhile, the fuzzy parameter is also employed in the proposed adaptive activation function , which makes the FTCFZNN model possess fixed-time convergence with less upper bound and has a better adaptable ability. Moreover, a series of theoretical analyses reflect the superior fixed-time convergence and adaptive robustness of the FTCFZNN model. Numerical simulations demonstrate the predominant performance of the FTCFZNN model and its effectiveness in solving the TVSE compared with serval existing ZNN models. Finally, the FTCFZNN model is applied to realize the consensus of multi-agent systems, which shows the application value of the FTCFZNN model.},
  archive      = {J_NEUCOM},
  author       = {Jianhua Dai and Ping Tan and Lin Xiao and Lei Jia and Liu Luo},
  doi          = {10.1016/j.neucom.2023.126696},
  journal      = {Neurocomputing},
  pages        = {126696},
  shortjournal = {Neurocomputing},
  title        = {Design, analysis, and application of fixed-time convergence fuzzy ZNN model realized by dynamic fuzzy logic system for time-varying sylvester equation},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AdaTerm: Adaptive t-distribution estimated robust moments
for noise-robust stochastic gradient optimization. <em>NEUCOM</em>,
<em>557</em>, 126692. (<a
href="https://doi.org/10.1016/j.neucom.2023.126692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing practicality of deep learning applications, practitioners are inevitably faced with datasets corrupted by noise from various sources such as measurement errors, mislabeling, and estimated surrogate inputs/outputs that can adversely impact the optimization results. It is a common practice to improve the optimization algorithm’s robustness to noise, since this algorithm is ultimately in charge of updating the network parameters. Previous studies revealed that the first-order moment used in Adam-like stochastic gradient descent optimizers can be modified based on the Student’s t-distribution. While this modification led to noise-resistant updates, the other associated statistics remained unchanged, resulting in inconsistencies in the assumed models. In this paper, we propose AdaTerm, a novel approach that incorporates the Student’s t-distribution to derive not only the first-order moment but also all the associated statistics. This provides a unified treatment of the optimization process, offering a comprehensive framework under the statistical model of the t-distribution for the first time. The proposed approach offers several advantages over previously proposed approaches, including reduced hyperparameters and improved robustness and adaptability. AdaTerm achieves this by considering the interdependence of gradient dimensions. In particular, upon detection, AdaTerm excludes aberrant gradients from the update process and enhances its robustness for subsequent updates. Conversely, it performs normal parameter updates when the gradients are statistically valid, allowing for flexibility in adapting its robustness. This noise-adaptive behavior contributes to AdaTerm’s exceptional learning performance, as demonstrated through various optimization problems with different and/or unknown noise ratios. Furthermore, we introduce a new technique for deriving a theoretical regret bound without relying on AMSGrad, providing a valuable contribution to the field.},
  archive      = {J_NEUCOM},
  author       = {Wendyam Eric Lionel Ilboudo and Taisuke Kobayashi and Takamitsu Matsubara},
  doi          = {10.1016/j.neucom.2023.126692},
  journal      = {Neurocomputing},
  pages        = {126692},
  shortjournal = {Neurocomputing},
  title        = {AdaTerm: Adaptive T-distribution estimated robust moments for noise-robust stochastic gradient optimization},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leader–follower sliding mode formation control of
fractional-order multi-agent systems: A dynamic event-triggered
mechanism. <em>NEUCOM</em>, <em>557</em>, 126691. (<a
href="https://doi.org/10.1016/j.neucom.2023.126691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the concept of the leader–follower formation for fractional-order multi-agent systems (FO-MASs) by utilizing dynamic event-triggered sliding mode control (SMC) method. Firstly, a dynamic event-triggered mechanism (DETM) is designed relying on the combined measurement vector , in which an auxiliary variable is introduced to dynamically adjust the threshold for each fractional-order agent system. Unlike most existing event-triggered communication mechanisms, whose threshold parameters are always fixed, the threshold parameters in our designed event-triggered conditions can be dynamically adjusted according to the fractional-order dynamic rule. Numerical results show that the proposed DETM can achieve a better system performance in reducing the sampling frequency and the expected formation performance. Secondly, the leader–follower formation control problem is transformed into checking the asymptotic stability problem of the closed-loop system. In addition, due to the memorability of fractional calculus operators, a distinctive condition is established to avoid the occurrence of Zeno behaviors reported in existing dynamic event-triggered schemes. Finally, a simulation example is presented to illustrate the effectiveness and feasibility of the dynamic event-triggered SMC method proposed in this paper.},
  archive      = {J_NEUCOM},
  author       = {Xin Meng and Baoping Jiang and Hamid Reza Karimi and Cunchen Gao},
  doi          = {10.1016/j.neucom.2023.126691},
  journal      = {Neurocomputing},
  pages        = {126691},
  shortjournal = {Neurocomputing},
  title        = {Leader–follower sliding mode formation control of fractional-order multi-agent systems: A dynamic event-triggered mechanism},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parallel extended state observer based control for uncertain
nonlinear systems. <em>NEUCOM</em>, <em>557</em>, 126687. (<a
href="https://doi.org/10.1016/j.neucom.2023.126687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a parallel extended state observer (PESO) is proposed by merging a series of different order linear tracking differentiators and first-order nonlinear differentiators . Both measurement noises and system uncertainties are taken into account in design procedures. A distinct feature of the parallel structure is that the observed information of each part is independent of each other, which effectively avoids the accumulation of the observation error of each part. The PESO is utilized to estimate the total disturbance, which reflects the combined impacts of internal uncertainties and external disturbances. Based on the observation results generated by the PESO, a composite controller is developed for output feedback control of uncertain nonlinear systems . The convergence performance of the proposed PESO and PESO-based controller is rigorously verified. Finally, some numerical simulation results are provided to verify the effectiveness and superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Xilian Zhang and Tao Xu and Zhao Zhang and Zhisheng Duan},
  doi          = {10.1016/j.neucom.2023.126687},
  journal      = {Neurocomputing},
  pages        = {126687},
  shortjournal = {Neurocomputing},
  title        = {Parallel extended state observer based control for uncertain nonlinear systems},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient asynchronous federated neuromorphic learning of
spiking neural networks. <em>NEUCOM</em>, <em>557</em>, 126686. (<a
href="https://doi.org/10.1016/j.neucom.2023.126686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) can be trained on resource-constrained devices at low computational costs. There has been little attention to training them on a large-scale distributed system like federated learning . Federated Learning (FL) can be exploited to perform collaborative training for higher accuracy, involving multiple resource-constrained devices. In this paper, we introduce SNNs into asynchronous federated learning (AFL), which adapts to the statistical heterogeneity of users and complex communication environments. A novel fusion weight based on information age and average spike rate is designed, which aims to reduce the impact of model staleness. Numerical experiments validate SNNs on federated learning with MNIST, FashionMNIST, CIFAR10 and SVHN benchmarks, achieving better accuracy and desirable convergence under Non-IID settings.},
  archive      = {J_NEUCOM},
  author       = {Yuan Wang and Shukai Duan and Feng Chen},
  doi          = {10.1016/j.neucom.2023.126686},
  journal      = {Neurocomputing},
  pages        = {126686},
  shortjournal = {Neurocomputing},
  title        = {Efficient asynchronous federated neuromorphic learning of spiking neural networks},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view semi-supervised learning with adaptive graph
fusion. <em>NEUCOM</em>, <em>557</em>, 126685. (<a
href="https://doi.org/10.1016/j.neucom.2023.126685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view Semi-supervised Learning (MSL) is effective in using limited labels and considerable label-free data to improve learning performance. It has been successfully applied to a lot of real scenarios. In this study, we propose a model, termed MSL with Adaptive Graph Fusion (MSLAGF), which provides a novel solution for MSL. Unlike most existing methods propagating label information through the linear combination of pre-built fixed view-based similarity graphs , MSLAGF merges view-based graph construction , graph fusion, and label propagation. It adaptively learns view-specific graphs and automatically assigns weight coefficients to them. A multi-view fusion optimal graph is cleverly learned depending not only on the raw feature space but also on the dynamically predicted label space. Moreover, we present an efficient optimization algorithm to solve the formulated model. The view-specific graphs, the weight coefficients, the optimal graph, and the predicted labels are mutually negotiated and optimized in the optimization procedure. Extensive experimental results on six benchmark datasets validate the superiority.},
  archive      = {J_NEUCOM},
  author       = {Qianyao Qiang and Bin Zhang and Feiping Nie and Fei Wang},
  doi          = {10.1016/j.neucom.2023.126685},
  journal      = {Neurocomputing},
  pages        = {126685},
  shortjournal = {Neurocomputing},
  title        = {Multi-view semi-supervised learning with adaptive graph fusion},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new pre-conditioned STDP rule and its hardware
implementation in neuromorphic crossbar array. <em>NEUCOM</em>,
<em>557</em>, 126682. (<a
href="https://doi.org/10.1016/j.neucom.2023.126682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new pre-conditioned spike-timing-dependent plasticity (STDP) learning rule as well as an efficient system-level time-domain circuit modeling and simulation method for the whole crossbar array structure. First, the new pre-conditioned STDP rule is conceived by exercising a slight perturbation to the conventional STDP curve. Software-wise, it can be described in spiking neural network (SNN) codes, while hardware-wise, it is realized by the memristor crossbar array in conjunction with specific spike signals, just as the conventional STDP. The new STDP rule enables the neural network in a neuromorphic chip to achieve better performance both in terms of software and hardware implementation compared with the conventional STDP rule. Second, a time-domain circuit modeling method is proposed for the simulation of the whole crossbar array. Numerical experiments demonstrate that the new pre-conditioned STDP is superior to the conventional STDP both in terms of accuracy and low power consumption . At the software level, a 784 × 100 spiking neural network, trained by the pre-conditioned STDP, for the MNIST handwritten digit recognition achieves an accuracy of 85.90\%, which is 3.09\% higher than that trained by the conventional STDP. At the hardware level, a downscaled 196 × 10 crossbar array is simulated and trained. The crossbar array trained by the new STDP consumes 21.5\% less power than that trained by the conventional STDP. Moreover, it does not compromise the original robustness when subject to non-ideal characteristics such as variation of conductance and resistance of the interconnect in the crossbar array.},
  archive      = {J_NEUCOM},
  author       = {Tuomin Tao and Da Li and Hanzhi Ma and Yan Li and Shurun Tan and En-xiao Liu and Jose Schutt-Aine and Er-Ping Li},
  doi          = {10.1016/j.neucom.2023.126682},
  journal      = {Neurocomputing},
  pages        = {126682},
  shortjournal = {Neurocomputing},
  title        = {A new pre-conditioned STDP rule and its hardware implementation in neuromorphic crossbar array},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance bounds of complex-valued nonlinear estimators in
learning systems. <em>NEUCOM</em>, <em>557</em>, 126681. (<a
href="https://doi.org/10.1016/j.neucom.2023.126681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widely linear estimator offers theoretical and practical advantages over the strictly linear counterpart for the processing of the generality of complex signals. When applying the widely linear technique to a nonlinear estimator of learning systems, the resulting augmented nonlinear estimator also empirically produces performance advantages over the standard (strictly) nonlinear estimator. However, the theoretical justification for this observation is still lacking in the literature. To this end, we establish performance bounds of the augmented nonlinear estimator over the strictly nonlinear one in this paper. By expanding the analytic nonlinear function with the first-order Taylor formula, we obtain the closed form of the MSE difference △ MSE △MSE and that of the complementary MSE difference △ CMSE △CMSE for the two estimators. By jointly considering the MSE and the complementary MSE, it is theoretically established that △ MSE &gt; 0 △MSE&amp;gt;0 always holds for noncircular input signals, and MSE performance advantages always exist in both the real and imaginary channels over its strictly nonlinear counterpart except for the jointly circular case. The simulation results validate our theoretical analysis.},
  archive      = {J_NEUCOM},
  author       = {Huisheng Zhang and Chunmei Qi and Qingqing Ma and Dongpo Xu},
  doi          = {10.1016/j.neucom.2023.126681},
  journal      = {Neurocomputing},
  pages        = {126681},
  shortjournal = {Neurocomputing},
  title        = {Performance bounds of complex-valued nonlinear estimators in learning systems},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information retrieval algorithms and neural ranking models
to detect previously fact-checked information. <em>NEUCOM</em>,
<em>557</em>, 126680. (<a
href="https://doi.org/10.1016/j.neucom.2023.126680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although in the last decade several fact-checking organizations have emerged to verify misinformation , fake news has continued to proliferate, especially through social media platforms . Even though adopting improved detection strategies is of utmost importance , the fact-checking process could be optimized by verifying whether a claim has been previously fact-checked. Despite some ad-hoc information retrieval approaches having been recently proposed, the utility of modern (neural) retrieval systems have not been investigated yet. In this paper, we consider the standard two-phases retriever-reranker architecture and benchmark different state-of-the-art techniques from the information retrieval and Q&amp;A literature. We design several experiments on a real-world Twitter dataset to analyze the efficiency and the effectiveness of the benchmark approaches. Our results show that combining standard and neural approaches is the most promising research direction to improve retrievers performance and that complex (neural) rerankers might still be efficient in practice since there is no need to process a high number of documents to improve ranking performance.},
  archive      = {J_NEUCOM},
  author       = {Tanmoy Chakraborty and Valerio La Gatta and Vincenzo Moscato and Giancarlo Sperlì},
  doi          = {10.1016/j.neucom.2023.126680},
  journal      = {Neurocomputing},
  pages        = {126680},
  shortjournal = {Neurocomputing},
  title        = {Information retrieval algorithms and neural ranking models to detect previously fact-checked information},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LUAD: A lightweight unsupervised anomaly detection scheme
for multivariate time series data. <em>NEUCOM</em>, <em>557</em>,
126644. (<a href="https://doi.org/10.1016/j.neucom.2023.126644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection of multivariate time series data has drawn extensive research attention recently, as it can be widely applied into various different domains, such as Prognostics Health Management, community behaviour monitoring, financial Anti-fraud and so on. Anomalies typically refer to unexpected observations or sequences within the captured data. The prevailing solutions of current anomaly detection methods are not only highly related to the individual use, but also rely on the domain-specific prior knowledge. Existing methods of anomaly detection by detecting aberrations encounter fundamental engineering challenges in terms of steam data online nature and the lack of expert knowledge for the training data set. Also, to meet the practical requirements, the anomaly detection model is often required to be used in edge architectures where the computing resources are limited, which leads to the demand for developing light-weight anomaly detection methods. To address these challenges, we propose a lightweight, unsupervised anomaly detection scheme, called LUAD. LUAD is consists of a detection model and a diagnosis model. The detection model learns the normal patterns of input data via an encoder–decoder scheme that combines Temporal Convolutional Network (TCN) and Variational Auto-Encoder (VAE) to deconstruct and reconstruct multivariate time series data. The diagnosis model improves LUAD’s overall detection accuracy and provides a reasonable explanation for an anomaly. Experiments on three very different public datasets indicate that LUAD is both highly generalizable and more accurate than the two current state-of-the-arts. Overall, the LUAD model outperforms the baselines both in effectiveness (0.71\% ∼ ∼ 1.45\% higher) and efficiency (31X smaller in model size, 1.9X faster in training time).},
  archive      = {J_NEUCOM},
  author       = {Jin Fan and Zhentao Liu and Huifeng Wu and Jia Wu and Zhanyu Si and Peng Hao and Tom H. Luan},
  doi          = {10.1016/j.neucom.2023.126644},
  journal      = {Neurocomputing},
  pages        = {126644},
  shortjournal = {Neurocomputing},
  title        = {LUAD: A lightweight unsupervised anomaly detection scheme for multivariate time series data},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relay hindsight experience replay: Self-guided continual
reinforcement learning for sequential object manipulation tasks with
sparse rewards. <em>NEUCOM</em>, <em>557</em>, 126620. (<a
href="https://doi.org/10.1016/j.neucom.2023.126620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with sparse rewards remains a challenging problem in reinforcement learning (RL). In particular, for sequential object manipulation tasks, the RL agent generally only receives a reward upon successful completion of the entire task, leading to low exploration efficiency. To address this sample inefficiency, we propose a novel self-guided continual RL framework, named Relay Hindsight Experience Replay (RHER). RHER decomposes a sequential task into several subtasks with increasing complexity, allowing the agent to learn from the simplest subtask and gradually complete the task. It is crucial that a Self-Guided Exploration Strategy (SGES) is proposed to use the already-learned simpler subtask policy to guide the exploration of a more complex subtask. This strategy allows the agent to break the barriers of sparse reward sequential tasks and achieve efficient learning stage by stage. As a result, the proposed RHER method achieves state-of-the-art performance on the benchmark tasks (FetchPush and FetchPickAndPlace). Furthermore, the experimental results demonstrate the superiority and high efficiency of RHER on a variety of single-object and multi-object manipulation tasks (e.g., ObstaclePush, DrawerBox, TStack, etc.). Finally, the proposed RHER method can also learn a contact-rich task on a real robot from scratch within 250 episodes.},
  archive      = {J_NEUCOM},
  author       = {Yongle Luo and Yuxin Wang and Kun Dong and Qiang Zhang and Erkang Cheng and Zhiyong Sun and Bo Song},
  doi          = {10.1016/j.neucom.2023.126620},
  journal      = {Neurocomputing},
  pages        = {126620},
  shortjournal = {Neurocomputing},
  title        = {Relay hindsight experience replay: Self-guided continual reinforcement learning for sequential object manipulation tasks with sparse rewards},
  volume       = {557},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of text detection and recognition algorithms based
on deep learning technology. <em>NEUCOM</em>, <em>556</em>, 126702. (<a
href="https://doi.org/10.1016/j.neucom.2023.126702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical Character Recognition (OCR) poses a crucial challenge within the realm of computer vision research, as it plays a pivotal role in converting vast amounts of unstructured text data into structured formats to support diverse artificial intelligence applications. The OCR process encompasses two core components: text detection and text recognition. Text detection involves identifying and extracting text regions, achieved through either object detection or segmentation techniques, while text recognition focuses on accurately deciphering the content within these identified regions. In recent years, remarkable strides have been made in the domain of text recognition, primarily driven by deep learning-based models. These models eliminate the need for manual feature processing and excel in recognizing text even within complex scenes, surpassing the performance of traditional text recognition methods and subsequently emerging as the dominant approach. The objective of this paper is to present a comprehensive survey of both text detection and text recognition models. Firstly, we systematically categorize and provide an overview of existing off-the-shelf text detection methods. Subsequently, we conduct an in-depth investigation of six distinct text recognition models, taking into account their unique implementations. Additionally, we explore and analyze the principal datasets that currently prevail in the field of text detection and recognition. Furthermore, this research entails a meticulous performance comparison of various text detection algorithms on the CTW1500, TotalText, and ICDAR2015 datasets. Additionally, we evaluate and scrutinize the efficacy of mainstream text recognition algorithms on the IIIT-5K, SVT, ICDAR2013, SVT-P, CUTE80, and ICDAR2015 datasets. Finally, we conclude with a discussion on the future development and research trends concerning text detection and recognition, providing insights that can further drive progress in this crucial area.},
  archive      = {J_NEUCOM},
  author       = {Xiao-Feng Wang and Zhi-Huang He and Kai Wang and Yi-Fan Wang and Le Zou and Zhi-Ze Wu},
  doi          = {10.1016/j.neucom.2023.126702},
  journal      = {Neurocomputing},
  pages        = {126702},
  shortjournal = {Neurocomputing},
  title        = {A survey of text detection and recognition algorithms based on deep learning technology},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive bipartite output containment control of
heterogeneous multi-agent systems with leaders bounded unknown inputs.
<em>NEUCOM</em>, <em>556</em>, 126699. (<a
href="https://doi.org/10.1016/j.neucom.2023.126699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper researches the adaptive bipartite output containment problem, for a signed graph of heterogeneous multi-agent systems (HMASs). The dynamics of leaders are subject to unknown but bounded inputs, which cannot be measured by followers. Therefore, an containment control protocol based on distributed observer is proposed. An adaptive state and an output feedback algorithm are designed to ensure that cooperative and antagonistic agents enter different convex hull . Then, based on the output regulation approach, Lyapunov stability analysis and some other methods, the bipartite output containment control is realized. Finally, we validate the analytical results by numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Jie Cheng and Xisheng Zhan and Jie Wu and Tao Han and Huaicheng Yan},
  doi          = {10.1016/j.neucom.2023.126699},
  journal      = {Neurocomputing},
  pages        = {126699},
  shortjournal = {Neurocomputing},
  title        = {Adaptive bipartite output containment control of heterogeneous multi-agent systems with leaders bounded unknown inputs},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SC2-net: Self-supervised learning for multi-view
complementarity representation and consistency fusion network.
<em>NEUCOM</em>, <em>556</em>, 126695. (<a
href="https://doi.org/10.1016/j.neucom.2023.126695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) seeks to improve the original single-view clustering by exploring the complementarity and consistency contained in multi-view data. While most subspace-based multi-view clustering methods now focus on exploring one of the consistency or complementarity features associated with multi-view datasets, rather than balancing the exploration of them. Meanwhile, the favored approach of combining deep learning tends to design the network structure to be relatively complex and then superimpose the constraints of multiple loss functions. Additionally, training results with unlabeled datasets are often unsatisfactory. To solve the aforementioned concerns, we present an innovative deep convolutional clustering network (SC 2 2 -Net) backed by self-supervised learning. SC 2 2 -Net learns multi-view complementarity representation and consistency fusion between views which adheres to the two principles of MVC. The clustering labels will be obtained by cooperating with k k -means, the overall structure is simple but efficient. In addition, we supervise the network training by using two self-supervised loss functions, making the training process free from using data with annotations. We test the proposed network under multiple sets of experimental parameter combinations and prove its effectiveness and robustness.},
  archive      = {J_NEUCOM},
  author       = {Liting Huang and Xiangyang Fan and Tianlin Xia and Yuhang Li and Youdong Ding},
  doi          = {10.1016/j.neucom.2023.126695},
  journal      = {Neurocomputing},
  pages        = {126695},
  shortjournal = {Neurocomputing},
  title        = {SC2-net: Self-supervised learning for multi-view complementarity representation and consistency fusion network},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperation of robot manipulators with motion constraint by
real-time RNN-based finite-time fault-tolerant control. <em>NEUCOM</em>,
<em>556</em>, 126694. (<a
href="https://doi.org/10.1016/j.neucom.2023.126694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinear cooperative dynamics of m robots with motion constraint and faulty input saturation is addressed. To the best of our knowledge, the motion constraint for the cooperative control of multiple robots is first discussed as one of the designed concepts such that the proposed cooperative control system is more practical and its performance is also improved. Together with a finite-time concept, a real-time recurrent-neural-network-based finite-time fault-tolerant cooperation constraint control (RT-RNN-FTFTCCC) is designed to tackle the aggregately dynamic uncertainties brought about by motion constraint error, cooperation uncertain dynamics, disturbance torque , faulty input saturation, unsatisfying skew-symmetric matrix condition, and others. Moreover, the stabilized learning law includes two terms to cover all the range of filtering cooperation errors such that learning weights converge even in uncertain circumstances. Finally, the stability analysis of the overall cooperation control system is achieved by Lyapunov stability theory . In comparison to adaptive compensation control, recurrent-neural-network-based control without the motion constraint compensation, and different stabilized learning laws, the cooperative control of bi-robotic arms of 3-link in-plane with new constraint validates the improvement and robustness of the proposed control.},
  archive      = {J_NEUCOM},
  author       = {Chih-Lyang Hwang},
  doi          = {10.1016/j.neucom.2023.126694},
  journal      = {Neurocomputing},
  pages        = {126694},
  shortjournal = {Neurocomputing},
  title        = {Cooperation of robot manipulators with motion constraint by real-time RNN-based finite-time fault-tolerant control},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Survey on multimodal approaches to emotion recognition.
<em>NEUCOM</em>, <em>556</em>, 126693. (<a
href="https://doi.org/10.1016/j.neucom.2023.126693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion is an instinctive state of mind created by the neurophysiological changes occurring in the human body as reactions to various internal or external stimuli. Emotions play a vital role in decision-making. The choices one makes in day-to-day life determine their behaviour and thus their character. Emotion and behaviour recognition are the key processes in ascertaining Emotional Intelligence (EQ) which is the inherent human potential to understand and manage one’s own emotions in positive ways. But the process requires high expertise in the field of psychology and is exhaustive and time-consuming. This has opened a new horizon for exploring the computational recognition of EQ. Emotion Recognition (ER) is one of its sub-processes that identifies various human emotional states. Emotions are detected from physiological signals and also through non-invasive, vision-based algorithms by exploiting video and audio modalities. With the emergence of big data and state-of-art deep learning architectures combined with the vast availability of emotion-rich video content from various streaming platforms, Multimodal Emotion Recognition (MER) which detects emotions through multiple and complementary input modalities from video has gathered momentum in recent years. This survey paper elaborately discusses the unimodal ER through visual, auditory, and linguistic modalities and reviews MER with combined features from these modalities. It also discusses the joint representations and fusion mechanisms used to acquire the intermodal correlations. Finally, we put forward the limitations and gaps identified in the literature along with a few suggestions for future work.},
  archive      = {J_NEUCOM},
  author       = {A. Aruna Gladys and V. Vetriselvi},
  doi          = {10.1016/j.neucom.2023.126693},
  journal      = {Neurocomputing},
  pages        = {126693},
  shortjournal = {Neurocomputing},
  title        = {Survey on multimodal approaches to emotion recognition},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Learning local graph from multiple kernels.
<em>NEUCOM</em>, <em>556</em>, 126683. (<a
href="https://doi.org/10.1016/j.neucom.2023.126683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph is a widely applied technique to characterize the relationship among data. Due to the excellent ability to handle nonlinear data and extract the useful information contained in base kernels, learning the connecting graph based on multiple kernel learning has been extensively discussed. Many existing algorithms construct the connecting graph based on the optimal kernel which is learned from base kernels. Observing these methods, we find they (1) ignore the local structure of data; (2) cannot assure that the optimal kernel is positive semi-definite; (3) cannot fully utilize the information contained in base kernels. Therefore, we introduce a novel local graph based on multiple kernel learning (LGMKL) in this paper. Specifically, LGMKL is constructed based on the optimal kernel which is automatically learned from base kernels with a nonlinear strategy and the information contained in different base kernels is also utilized in LGMKL. Then an iterative scheme with proven convergence is developed to optimize the objective function of LGMKL. Unlike most MKL-based graph learning methods, LGMKL focuses on the local structure of data. Finally, nine benchmark datasets and two synthetic datasets are adopted to test the performance of LGMKL. Extensive experiments demonstrate the superiorities of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zheng Liu and Shiluo Huang and Wei Jin and Ying Mu},
  doi          = {10.1016/j.neucom.2023.126683},
  journal      = {Neurocomputing},
  pages        = {126683},
  shortjournal = {Neurocomputing},
  title        = {Learning local graph from multiple kernels},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel model for tourism demand forecasting with
spatial–temporal feature enhancement and image-driven method.
<em>NEUCOM</em>, <em>556</em>, 126663. (<a
href="https://doi.org/10.1016/j.neucom.2023.126663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting tourism demand requires learning the spatial–temporal features of tourism demand, which is challenging due to constantly changing human behavior . This study presents a spatial–temporal feature enhancement model designed to maintain the integrity of tourism demand features. Specifically, the tourism system is modeled as an undirected graph and the steady-state analysis method is employed to learn spatial–temporal features. To enhance the feature learning ability for sparse features, we employ convolutional filters , and we convert the feature series into an image series while preserving the relationship of the spatial–temporal features. The method’s effectiveness is demonstrated using the digital footprints of tourists from the urban area of Zhuhai. Numerical experiments indicate that the proposed model outperforms state-of-the-art tourism demand forecasting models.},
  archive      = {J_NEUCOM},
  author       = {Yunxuan Dong and Binggui Zhou and Guanghua Yang and Fen Hou and Zheng Hu and Shaodan Ma},
  doi          = {10.1016/j.neucom.2023.126663},
  journal      = {Neurocomputing},
  pages        = {126663},
  shortjournal = {Neurocomputing},
  title        = {A novel model for tourism demand forecasting with spatial–temporal feature enhancement and image-driven method},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal metrics based aggregated graph convolution network
for traffic forecasting. <em>NEUCOM</em>, <em>556</em>, 126662. (<a
href="https://doi.org/10.1016/j.neucom.2023.126662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is one of the most well-studied problems in the Intelligent Transportation Systems (ITS). However, existing studies mainly utilize Euclidean distance or road network distance as the metrics at the spatial level, where the distance between two points is calculated based on the GPS coordinates. When using the spatial level metrics to construct the road network’s topological and indexing structure, two completed unrelated road segments such as the upper and lower levels of the viaduct will be contiguous in the adjacent matrix and consequently be indexed in the same block. However, it may taking a long time to drive through these two road segments, which makes the spatial proximity meaningless, and this is pretty common during the morning and evening rush hours. Thus, it is very important to take into consideration of the temporal metric along with the spatial distance metric when dealing with the traffic forecasting problem. Motivated by the above observation, we propose a novel Temporal Metrics Based Aggregated Graph Convolution Network (TMAGCN), which utilize the time reachability based road network weight metric, and reveal its unique characteristics. TMAGCN mainly consists of three components: spatio-temporal reachability calculation, region clustering(road segments aggregating), and traffic flow forecasting. We explore the cluster of road segments and the reconstruction of the spatio-temporal reachability graph with temporal-level information rather than spatial-level information for better capturing the latent region information. To the best of our knowledge, this paper is the first attempt on this problem. The comprehensive experiments indicate that TMAGCN achieves higher accuracy and efficiency than other off-the-shelf models.},
  archive      = {J_NEUCOM},
  author       = {Fangshu Chen and Yanqiang Qi and Jiahui Wang and Lu Chen and Yufei Zhang and Linxiang Shi},
  doi          = {10.1016/j.neucom.2023.126662},
  journal      = {Neurocomputing},
  pages        = {126662},
  shortjournal = {Neurocomputing},
  title        = {Temporal metrics based aggregated graph convolution network for traffic forecasting},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DyTSCL: Dynamic graph representation via tempo-structural
contrastive learning. <em>NEUCOM</em>, <em>556</em>, 126660. (<a
href="https://doi.org/10.1016/j.neucom.2023.126660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the massive growth of graph-structured data, extensive research has focused on graph representation learning. Recently, graph representation learning frameworks have made great efforts toward dynamic graph learning. Although dynamic graph methods have achieved impressive results, they require labeled data for model training. The contrastive learning does not require human annotation to complete model training and has been shown to be extremely competitive in visual representation learning and natural language processing . In this paper, we propose a novel Dy namic graph representation framework via T empo- S tructural C ontrastive L earning, DyTSCL , which trains the model by identifying three different subgraphs as a task, named Tempo-Structural subgraph, Non-Temporal subgraph and Non-Structural subgraph. Moreover, we propose a Tempo-Structural encoder, which aggregates the temporal and structural information. Finally, a Tempo-Structural contrastive learning module is proposed to maximize the consistency between node and subgraph in temporal and structural perspectives, respectively. To demonstrate the effectiveness of DyTSCL, we validate DyTSCL by applying it on the Wikipedia, Reddit and Mooc datasets, which show that DyTSCL can significantly outperform the existing approaches.},
  archive      = {J_NEUCOM},
  author       = {Jianian Li and Peng Bao and Rong Yan and Huawei Shen},
  doi          = {10.1016/j.neucom.2023.126660},
  journal      = {Neurocomputing},
  pages        = {126660},
  shortjournal = {Neurocomputing},
  title        = {DyTSCL: Dynamic graph representation via tempo-structural contrastive learning},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Priming cross-session motor imagery classification with a
universal deep domain adaptation framework. <em>NEUCOM</em>,
<em>556</em>, 126659. (<a
href="https://doi.org/10.1016/j.neucom.2023.126659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) based motor imagery (MI) brain–computer interfaces (BCI) are widely used in applications related to rehabilitation and external device control. However, due to the non-stationary and low signal-to-noise ratio characteristics of EEG, classifying motor imagery tasks of the same participant from different recording sessions is generally challenging. Whether the classification accuracy of cross-session MI can be improved from the perspective of domain adaptation is a question worth verifying. In this paper, we propose a Siamese deep domain adaptation (SDDA) framework for cross-session MI classification based on mathematical models in domain adaptation theory. The SDDA framework primarily consists of three components: a novel preprocessing method based on domain-invariant features, a maximum mean discrepancy (MMD) loss for aligning source and target domain embedding features, and an improved cosine-based center loss designed to suppress the influence of noise and outliers on the neural network . The SDDA framework has been validated with two classic and popular convolutional neural networks (EEGNet and ConvNet) from BCI research field in two MI EEG public datasets (BCI Competition IV IIA, IIB). Compared with the vanilla EEGNet and ConvNet, the SDDA framework improves the MI classification accuracy by 10.49\%, 7.60\% respectively in IIA dataset, and 4.59\%, 3.35\% in IIB dataset. The SDDA not only significantly improves the classification performance of the vanilla networks but also surpasses state-of-the-art transfer learning methods, making it a superior and user-friendly approach for MI classification.},
  archive      = {J_NEUCOM},
  author       = {Xin Zhang and Zhengqing Miao and Carlo Menon and Yelong Zheng and Meirong Zhao and Dong Ming},
  doi          = {10.1016/j.neucom.2023.126659},
  journal      = {Neurocomputing},
  pages        = {126659},
  shortjournal = {Neurocomputing},
  title        = {Priming cross-session motor imagery classification with a universal deep domain adaptation framework},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Caster: Cartoon style transfer via dynamic cartoon style
casting. <em>NEUCOM</em>, <em>556</em>, 126654. (<a
href="https://doi.org/10.1016/j.neucom.2023.126654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cartoon style transfer has attracted widespread attention. Although many researchers have proposed various methods to develop this field, there are still two areas for improvement: (1) existing image-to-image cartoon style transfer methods can only perform domain-to-domain cartoon style transfer, neglecting the specific color and texture of the cartoon images, and (2) arbitrary style transfer methods only transfer the style of the style image onto the content image, neglecting the style information of the style domain. To address these issues, we observe that artists often refer to specific paintings to fine-tune the color of their artworks. This behavior inspires us to propose a method that can dynamically encode the style information of a specific cartoon image based on Variational Autoencoders , allowing the style feature to be cast onto the content feature dynamically. We also introduce a cartoon contrastive learning loss to push the cartoon stylized image closer to the same cartoon stylized image and otherwise pull away. Extensive experiments demonstrate that our proposed method, Caster, can generate a high-quality stylized image with specific and domain cartoon style information than state-of-the-art cartoon style transfer methods.},
  archive      = {J_NEUCOM},
  author       = {Zhanjie Zhang and Jiakai Sun and Jiafu Chen and Lei Zhao and Boyan Ji and Zehua Lan and Guangyuan Li and Wei Xing and Duanqing Xu},
  doi          = {10.1016/j.neucom.2023.126654},
  journal      = {Neurocomputing},
  pages        = {126654},
  shortjournal = {Neurocomputing},
  title        = {Caster: Cartoon style transfer via dynamic cartoon style casting},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On exploring pose estimation as an auxiliary learning task
for visible–infrared person re-identification. <em>NEUCOM</em>,
<em>556</em>, 126652. (<a
href="https://doi.org/10.1016/j.neucom.2023.126652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible–infrared person re-identification (VI-ReID) has been challenging due to the existence of large discrepancies between visible and infrared modalities. Most pioneering approaches reduce intra-modality variations and inter-modality discrepancies by learning modality-shared features. However, an explicit modality-shared cue, i.e., body keypoints, has not been fully exploited in VI-ReID. Additionally, existing feature learning paradigms imposed constraints on either global features or partitioned feature stripes, which neglect the prediction consistency of global and part features. To address the above problems, we exploit Pose Estimation as an auxiliary learning task to assist VI-ReID in an end-to-end framework. By jointly training these two tasks in a mutually beneficial manner, our model learns higher quality ID-related features. On top of it, the learnings of global features and local features are seamlessly synchronized by Hierarchical Feature Constraint (HFC), where the former supervises the latter using the knowledge distillation strategy. Experimental results on two benchmark VI-ReID datasets show that the proposed method consistently improves state-of-the-art methods by significant margins. Specifically, our method achieves nearly 20\% mAP improvements against the state-of-the-art method on the RegDB dataset. Our intriguing findings highlight the usage of auxiliary task learning in VI-ReID. Our source code is available at https://github.com/yoqim/Pose_VIReID .},
  archive      = {J_NEUCOM},
  author       = {Yunqi Miao and Nianchang Huang and Xiao Ma and Qiang Zhang and Jungong Han},
  doi          = {10.1016/j.neucom.2023.126652},
  journal      = {Neurocomputing},
  pages        = {126652},
  shortjournal = {Neurocomputing},
  title        = {On exploring pose estimation as an auxiliary learning task for Visible–Infrared person re-identification},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multimodal fusion emotion recognition method based on
multitask learning and attention mechanism. <em>NEUCOM</em>,
<em>556</em>, 126649. (<a
href="https://doi.org/10.1016/j.neucom.2023.126649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With new developments in the field of human–computer interaction, researchers are now paying attention to emotion recognition, especially multimodal emotion recognition, as emotion is a multidimensional expression. In this study, we propose a multimodal fusion emotion recognition method (MTL-BAM) based on multitask learning and the attention mechanism to tackle the major problems encountered in multimodal emotion recognition tasks regarding the lack of consideration of emotion interactions among modalities and the focus on emotion similarity among modalities while ignoring the differences. By improving the attention mechanism, the emotional contribution of each modality is further analyzed so that the emotional representations of each modality can learn from and complement each other to achieve better interactive fusion effect, thereby building a multitask learning framework. By introducing three types of monomodal emotion recognition tasks as auxiliary tasks, the model can detect emotion differences. Simultaneously, the label generation unit is introduced into the auxiliary tasks, and the monomodal emotion label value can be obtained more accurately through two proportional formulas while preventing the zero value problem. Our results show that the proposed method outperforms selected state-of-the-art methods on four evaluation indexes of emotion classification (i.e., accuracy, F1 score, MAE, and Pearson correlation coefficient). The proposed method achieved accuracy rates of 85.36\% and 84.61\% on the published multimodal datasets of CMU-MOSI and CMU-MOSEI, respectively, which are 2–6\% higher than those of existing state-of-the-art models, demonstrating good multimodal emotion recognition performance and strong generalizability.},
  archive      = {J_NEUCOM},
  author       = {Jinbao Xie and Jiyu Wang and Qingyan Wang and Dali Yang and Jinming Gu and Yongqiang Tang and Yury I. Varatnitski},
  doi          = {10.1016/j.neucom.2023.126649},
  journal      = {Neurocomputing},
  pages        = {126649},
  shortjournal = {Neurocomputing},
  title        = {A multimodal fusion emotion recognition method based on multitask learning and attention mechanism},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A forecasting method for non-equal interval time series
based on recurrent neural network. <em>NEUCOM</em>, <em>556</em>,
126648. (<a href="https://doi.org/10.1016/j.neucom.2023.126648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown data can be forecast by learning the patterns of change from the historical data at regular intervals. However, when samples are not available at a regular interval, the forecasting task becomes very challenging. This paper proposes an improved Gated Recurrent Unit model for non-equal interval time series, abbreviated as NITS-GRU, to model the data of the series without resampling and data imputation. NITS-GRU includes GRU-ODE module, multivariate-based sample correlation calculation module, and information fusion module. The GRU-ODE module generates forecast information of adjacent samples by calculating their hidden layer states, as well as the accumulated difference information between each adjacent sample and forecasting sample over time intervals. Meanwhile, we calculate the correlations between each adjacent sample and forecasting sample based on multiple variables, and adopt attention mechanism to obtain correlation weights of these adjacent samples. The information fusion module applies the correlation weights on forecast information of the adjacent samples generated by the GRU-ODE module, to obtain the final forecast results. Experiments on different datasets demonstrate that NITS-GRU outperforms the state-of-the-art baselines for forecasting unknown data in non-equal interval time series.},
  archive      = {J_NEUCOM},
  author       = {Xin Liu and Hongli Du and Jian Yu},
  doi          = {10.1016/j.neucom.2023.126648},
  journal      = {Neurocomputing},
  pages        = {126648},
  shortjournal = {Neurocomputing},
  title        = {A forecasting method for non-equal interval time series based on recurrent neural network},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partial model averaging in federated learning: Performance
guarantees and benefits. <em>NEUCOM</em>, <em>556</em>, 126647. (<a
href="https://doi.org/10.1016/j.neucom.2023.126647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local Stochastic Gradient Descent (SGD) with periodic model averaging (FedAvg) is a foundational algorithm in Federated Learning . The algorithm independently runs SGD on multiple clients and periodically averages the model across all the clients. This periodic model averaging potentially causes a significant model discrepancy across the clients making the global loss converge slowly. While recent advanced optimization methods tackle the issue focused on non-IID settings, there still exists the model discrepancy issue due to the underlying periodic model averaging. We propose a partial model averaging framework that mitigates the model discrepancy issue in Federated Learning . The partial averaging encourages the local models to stay close to each other on parameter space, and it enables to more effectively minimize the global loss. We extensively evaluate the performance of the partial averaging strategy using CIFAR-10/100 and FEMNIST benchmarks. Given a fixed number of training iterations and a large number of clients (128), the partial averaging achieves up to 2.2\% higher accuracy than the periodic full averaging.},
  archive      = {J_NEUCOM},
  author       = {Sunwoo Lee and Anit Kumar Sahu and Chaoyang He and Salman Avestimehr},
  doi          = {10.1016/j.neucom.2023.126647},
  journal      = {Neurocomputing},
  pages        = {126647},
  shortjournal = {Neurocomputing},
  title        = {Partial model averaging in federated learning: Performance guarantees and benefits},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). 3D-unified spatial-temporal graph for group activity
recognition. <em>NEUCOM</em>, <em>556</em>, 126646. (<a
href="https://doi.org/10.1016/j.neucom.2023.126646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early group activity recognition is typically conducted in a 2D scenario. This paper proposes a group activity recognition method in a 3D space. In practical applications, differences in camera angle and mutual shielding during the peak flow of people will affect the extraction of individual characteristics and the calculation of individual relationships. Therefore, a method using 3D relationships is proposed. We first detect the 3D backbone of pedestrians and calculate the movement relationship of individuals in the group based on it. Second, we calculate the 3D-unified spatial–temporal graphs (3D-USTG) of the group and the individuals in the group using global-G3D (G-G3D). The experimental results demonstrate that the proposed method can effectively solve the problems caused by occlusion and shooting angle compared with a 2D method, which indicates that the proposed method can achieve better results when applied to intersections of different specifications. Additionally, the proposed method achieves strong performance metrics with two publicly available datasets for group activity recognition.},
  archive      = {J_NEUCOM},
  author       = {Lukun Wang and Wancheng Feng and Chunpeng Tian and Liquan Chen and Jiaming Pei},
  doi          = {10.1016/j.neucom.2023.126646},
  journal      = {Neurocomputing},
  pages        = {126646},
  shortjournal = {Neurocomputing},
  title        = {3D-unified spatial-temporal graph for group activity recognition},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synchronization of reaction–diffusion neural networks with
random time-varying delay via intermittent boundary control.
<em>NEUCOM</em>, <em>556</em>, 126645. (<a
href="https://doi.org/10.1016/j.neucom.2023.126645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under boundary measurement (BM), this paper solves the synchronization problem via intermittent boundary proportional–derivative (PD) control of delayed reaction–diffusion neural networks (RDNNs), where the random time-varying delay (RTVD) belongs to two intervals and is considered by a probabilistic way to take the influence of uncertain factors. The intermittent boundary PD synchronization scheme, which considers the inevitable actuator limitations, is based on BM and only available at some specified boundary position. By using the inequality techniques and switching Lyapunov functional, the mean square exponential stability (MSES) of the synchronization error system (SES) containing the response and drive dynamics is ensured by some synchronization criteria, which are established via an intermittent boundary PD controller under BM and expressed as linear matrix inequalities. Lastly, the proposed intermittent boundary PD synchronization approach is verified by a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Zi-Peng Wang and Xu Zhang and Jun-Fei Qiao and Huai-Ning Wu and Tingwen Huang},
  doi          = {10.1016/j.neucom.2023.126645},
  journal      = {Neurocomputing},
  pages        = {126645},
  shortjournal = {Neurocomputing},
  title        = {Synchronization of reaction–diffusion neural networks with random time-varying delay via intermittent boundary control},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual adaptation of federated reservoirs in pervasive
environments. <em>NEUCOM</em>, <em>556</em>, 126638. (<a
href="https://doi.org/10.1016/j.neucom.2023.126638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When performing learning tasks in pervasive environments , the main challenge arises from the need of combining federated and continual settings. The former comes from the massive distribution of devices with privacy-regulated data. The latter is required by the low resources of the participating devices, which may retain data for short periods of time. In this paper, we propose a setup for learning with Echo State Networks (ESNs) in pervasive environments . Our proposal focuses on the use of Intrinsic Plasticity ( IP ), a gradient-based method for adapting the reservoir’s non-linearity. First, we extend the objective function of IP to include the uncertainty arising from the distribution of the data over space and time. Then, we propose Federated Intrinsic Plasticity ( FedIP ), which is intended for client–server federated topologies with stationary data, and adapts the learning scheme provided by Federated Averaging ( FedAvg ) to include the learning rule of IP . Finally, we further extend this algorithm for learning to Federated Continual Intrinsic Plasticity ( FedCLIP ) to equip clients with CL strategies for dealing with continuous data streams. We evaluate our approach on an incremental setup built upon real-world datasets from human monitoring, where we tune the complexity of the scenario in terms of the distribution of the data over space and time. Results show that both our algorithms improve the representation capabilities and the performance of the ESN, while being robust to catastrophic forgetting.},
  archive      = {J_NEUCOM},
  author       = {Valerio De Caro and Claudio Gallicchio and Davide Bacciu},
  doi          = {10.1016/j.neucom.2023.126638},
  journal      = {Neurocomputing},
  pages        = {126638},
  shortjournal = {Neurocomputing},
  title        = {Continual adaptation of federated reservoirs in pervasive environments},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constraint guided gradient descent: Training with inequality
constraints with applications in regression and semantic segmentation.
<em>NEUCOM</em>, <em>556</em>, 126636. (<a
href="https://doi.org/10.1016/j.neucom.2023.126636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is typically performed by learning a neural network solely from data in the form of input–output pairs ignoring available domain knowledge. In this work, the Constraint Guided Gradient Descent (CGGD) framework is proposed that enables the injection of domain knowledge into the training procedure. The domain knowledge is assumed to be described as a conjunction of hard inequality constraints which appears to be a natural choice for several applications. Compared to other neuro-symbolic approaches, the proposed method converges to a point that makes an arbitrarily small error with respect to any inequality constraint on the training data and does not require to first transform the constraints into some ad-hoc term that is added to the learning (optimization) objective. It is empirically shown on four independent and small data sets that CGGD makes training less dependent on the initialization of the network, improves the constraint satisfiability on all data, improves the generalization of the model to unseen data, and relaxes the need for annotated data. Moreover, the method is tested for a regression and a semantic segmentation task.},
  archive      = {J_NEUCOM},
  author       = {Quinten Van Baelen and Peter Karsmakers},
  doi          = {10.1016/j.neucom.2023.126636},
  journal      = {Neurocomputing},
  pages        = {126636},
  shortjournal = {Neurocomputing},
  title        = {Constraint guided gradient descent: Training with inequality constraints with applications in regression and semantic segmentation},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on evolutionary reinforcement learning algorithms.
<em>NEUCOM</em>, <em>556</em>, 126628. (<a
href="https://doi.org/10.1016/j.neucom.2023.126628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) has proven to be highly effective in various real-world applications. However, in certain scenarios, Evolutionary Algorithms (EAs) have been utilized as an alternative to RL algorithms. Recently, Evolutionary Reinforcement Learning algorithms (ERLs) have emerged as a promising solution that combines the advantages of both RL and EA. This paper presents a comprehensive survey that encompasses a majority of the studies in this exciting research area. We classify these ERLs according to the EA used in their frameworks and analyze the strengths and limitations of various EA components and combination schemes. Additionally, we conduct several experiments to evaluate the performance of some representative ERLs. By categorizing the different approaches and assessing their effectiveness, the paper can assist researchers and practitioners in selecting the most suitable method for their particular application.},
  archive      = {J_NEUCOM},
  author       = {Qingling Zhu and Xiaoqiang Wu and Qiuzhen Lin and Lijia Ma and Jianqiang Li and Zhong Ming and Jianyong Chen},
  doi          = {10.1016/j.neucom.2023.126628},
  journal      = {Neurocomputing},
  pages        = {126628},
  shortjournal = {Neurocomputing},
  title        = {A survey on evolutionary reinforcement learning algorithms},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comprehensive review on vehicle detection, classification
and counting on highways. <em>NEUCOM</em>, <em>556</em>, 126627. (<a
href="https://doi.org/10.1016/j.neucom.2023.126627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle detection, counting and finally classification has been an important aspect of traffic analysis specially on highways in many developed and developing nations. This has vitalized the monitoring of freeways and reduced the reliance on human traffic monitors specially in developed nations. However, much research carried out in this regard since 1995 have been slow to progress until around 2000. Since then, much more encouraging outcomes have been achieved. This has been mainly due to the advances on vision-based computing and the miniaturizing of hardware since the early 2000. Initial vision-based systems used basic computer vision approaches such as background subtraction and edge detection to detect and count vehicles. Early progress of classification had little success until around 2010. Since 2010, many computer vision approaches using Neural Networks have been gradually increasing the efficiency and the realtime operation of such systems. Since then, many deep learning based neural network approaches have produced remarkable outcomes specially in classification. We have also reported highly accurate and efficient deep learning based YOLOv5 system that has recorded an astounding success. We have used models YOLOv5l, YOLOv5m, YOLOv5n and YOLOv5s in our research to ascertain the best model for the task. However, low light conditions associated with overcast, and dusk have significantly reduced the accuracy in many deep learning-based systems. There are other techniques based on approaches such as headlight detection have appeared to increase the accuracy of counting however, classification at night without adequate lighting still pauses a formidable challenge. The work presented here analyses the vehicle counting problem using computer vision providing many different viewpoints in a view to provide the reader with accurate problem definition.},
  archive      = {J_NEUCOM},
  author       = {Prashan Premaratne and Inas Jawad Kadhim and Rhys Blacklidge and Mark Lee},
  doi          = {10.1016/j.neucom.2023.126627},
  journal      = {Neurocomputing},
  pages        = {126627},
  shortjournal = {Neurocomputing},
  title        = {Comprehensive review on vehicle detection, classification and counting on highways},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive survey on segmentation techniques for
retinal vessel segmentation. <em>NEUCOM</em>, <em>556</em>, 126626. (<a
href="https://doi.org/10.1016/j.neucom.2023.126626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, enormous research has been carried out on the segmentation of blood vessels. Segmentation of blood vessels in retinal images is crucial for diagnosing, treating, evaluating clinical results, and early detection of eye disorders. A successful segmentation accurately reflects the blood vessels’ structure and helps obtain patterns that can be used to identify retinal disorders and diseases. Most recent research on vessel segmentation employs multiple processes to determine the appropriate segmentation. Finding the best techniques for segmentation is a complex process. In certain circumstances, it requires a thorough understanding of every step that can only be acquired through years of training. Comprehension and expertise in segmentation procedures are essential for accurate segmentation. This paper briefly introduces the segmentation of blood vessels in retinal images, describes many preprocessing and segmentation techniques, and summarizes challenges and trends. Furthermore, the limitations of the current systems will be identified.},
  archive      = {J_NEUCOM},
  author       = {Jair Cervantes and Jared Cervantes and Farid García-Lamont and Arturo Yee-Rendon and Josué Espejel Cabrera and Laura Domínguez Jalili},
  doi          = {10.1016/j.neucom.2023.126626},
  journal      = {Neurocomputing},
  pages        = {126626},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive survey on segmentation techniques for retinal vessel segmentation},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-domain video action recognition via adaptive gradual
learning. <em>NEUCOM</em>, <em>556</em>, 126622. (<a
href="https://doi.org/10.1016/j.neucom.2023.126622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based Unsupervised Domain Adaptation (UDA) methods concentrate on addressing domain shift and improving the robustness of video models. It can be naturally applied to cross-domain action recognition tasks, but the inherent complexity of videos makes this task more challenging. Though several recent attempts have achieved superior performance in the video UDA field, most of them intend to mitigate domain shift directly from the source domain to the target domain. These methods will cause a performance drop when the domain distribution shift is large. To better realize the domain adaptation , this paper proposes an effective gradual learning framework by constructing multiple auxiliary domains to achieve progressive transfer for cross-domain video action recognition . Specifically, a Dynamic CutMix Mechanism (DCM) is introduced to build the auxiliary domains that mitigate the domain gap caused by object distance and background discrepancies. Furthermore, the Gradual Transfer Strategy (GTS) utilizes these auxiliary domains to realize the cross-domain action classification gradually. Extensive experiments validate the effectiveness of our proposed method, and the experimental results can significantly outperform state-of-the-art methods on multiple benchmark cross-domain datasets.},
  archive      = {J_NEUCOM},
  author       = {Dan Liu and Zhenwei Bao and Jinpeng Mi and Yan Gan and Mao Ye and Jianwei Zhang},
  doi          = {10.1016/j.neucom.2023.126622},
  journal      = {Neurocomputing},
  pages        = {126622},
  shortjournal = {Neurocomputing},
  title        = {Cross-domain video action recognition via adaptive gradual learning},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive review of extreme learning machine on
medical imaging. <em>NEUCOM</em>, <em>556</em>, 126618. (<a
href="https://doi.org/10.1016/j.neucom.2023.126618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The feedforward neural network based on randomization has been of great interest in the scientific community, particularly extreme learning machines , due to its simplicity, training speed, and levels of accuracy comparable to traditional learning algorithms. Extreme learning machines (ELMs) are a type of artificial neural network (ANN) with one or more hidden layers that are trained under supervised, unsupervised, or semi-supervised learning approaches. These networks are widely used in various research areas, such as medical image processing (MI). This research work presents an exhaustive review of extreme learning machines (ELM) and medical image processing (MI), due to the high impact that these networks have had on the scientific community and the importance of MI for physicians who use them to diagnose different injuries and diseases. First, the theoretical construct of ELMs is developed based on the types of supervised, unsupervised, and semi-supervised learning. Then, the importance of MI for the diagnosis of a disease or classification of the most commonly used imaging modalities is analyzed for articles concerning radiography, computed tomography (CT), magnetic resonance (MR), ultrasound (US), and mammography (MG). Next, the reference data sets linked to various human body organs, such as the brain, lungs, skin, eyes, breasts, and cervix are described. Then, a review, analysis, and classification of the development of the last 6 years (2017–2022) of ELMs, based on learning types and MI, is performed. With the information obtained above, a construction of summary tables of the articles, classified according to the type of learning, is performed, highlighting the organ, reference, year, methodology, database, modality, and results. Finally, the discussion, conclusions and challenges related to this topic are presented. The findings indicate that the review articles reported in the literature have not addressed the relationship between ELMs and medical imaging in depth and have excluded key aspects, which are developed in this article. These aspects include a comprehensive analysis of the most popular imaging modalities , a detailed description of both the most popular databases and the most relevant databases for the machine learning community and, finally, the incorporation of schemes that explain the fundamentals of the main learnings considered when generating ELM-based trained smart models, which can be useful for medical image processing.},
  archive      = {J_NEUCOM},
  author       = {Yoleidy Huérfano-Maldonado and Marco Mora and Karina Vilches and Ruber Hernández-García and Rodrigo Gutiérrez and Miguel Vera},
  doi          = {10.1016/j.neucom.2023.126618},
  journal      = {Neurocomputing},
  pages        = {126618},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive review of extreme learning machine on medical imaging},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A contrastive learning framework for event detection via
semantic type prototype representation modelling. <em>NEUCOM</em>,
<em>556</em>, 126613. (<a
href="https://doi.org/10.1016/j.neucom.2023.126613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diversity of natural language expressions for describing events poses a challenge for the task of Event Detection (ED) with machine learning methods. To detect and classify event mentions, ED models essentially need to construct a semantic linkage between representations of the mentions and a set of target types. Unfortunately, most existing models use meaningless homogeneous one-hot vectors to represent the event type classes in ED, ignoring the fact that the event type labels also consist of meaningful words and can provide important clues for type representation learning . In this paper, we propose a Contrastive Sem antic P rototype R epresentation Learning Framework for E vent Detection (SemPRE), which exploits the pre-defined event type label words to inject the semantic information of the types and guide event detection. Specifically, we utilize pre-trained BERT to fuse text and event type into a joint representation space, and employ a contrastive-regularized module to enhance cross-type interaction. We conduct extensive experiments on the ACE 2005 and MAVEN benchmark datasets. The performance results show that our proposed SemPRE model achieves state-of-the-art performance on the datasets and outperforms existing baselines on limited annotated data and without using any external resources. Further analysis shows that our model is also effective in detecting multiple events and ambiguous trigger words.},
  archive      = {J_NEUCOM},
  author       = {Anran Hao and Anh Tuan Luu and Siu Cheung Hui and Jian Su},
  doi          = {10.1016/j.neucom.2023.126613},
  journal      = {Neurocomputing},
  pages        = {126613},
  shortjournal = {Neurocomputing},
  title        = {A contrastive learning framework for event detection via semantic type prototype representation modelling},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Position and structure-aware graph learning.
<em>NEUCOM</em>, <em>556</em>, 126581. (<a
href="https://doi.org/10.1016/j.neucom.2023.126581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning methods have gained great popularity in tackling various analytics tasks, such as node classification , link prediction and graph classification. However, most of graph representation learning methods merely consider the local information around the nodes. In addition, information about the global relative position information of each node is not fully taken into account. Recently, Position-aware Graph Neural Networks have been proposed to capture positions of nodes with respect to the anchor nodes and embed this position information into the feature representation, which aims to distinguish nodes which are locally structurally similar. This network aggregates position information from the randomly sampled anchor set nodes to the given target node. With such randomness, the sampled nodes lack particularity, and not all of them are significant enough in the graph to be used as position reference points. To address these issues, we propose a Position and Structure-aware Graph Learning framework (PSGL). The proposed PSGL extracts local topology information of nodes through the structure representation module, obtains anchor set nodes through graph pooling and further calculates global position information of the nodes to each anchor set node. The attention mechanism is used to weigh the obtained local topology and the global position information adaptively. Our proposed PSGL is capable of learning structural and positional information adaptively and encoding more informative characteristics in real-world networks. Our experimental results demonstrate that the proposed PSGL outperforms the state-of-the-art graph representation learning methods. Our code is available at https://github.com/leaf-ygq/PSGL .},
  archive      = {J_NEUCOM},
  author       = {Guoqiang Ye and Juan Song and Mingtao Feng and Guangming Zhu and Peiyi Shen and Liang Zhang and Syed Afaq Ali Shah and Mohammed Bennamoun},
  doi          = {10.1016/j.neucom.2023.126581},
  journal      = {Neurocomputing},
  pages        = {126581},
  shortjournal = {Neurocomputing},
  title        = {Position and structure-aware graph learning},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Class incremental learning based on identically distributed
parallel one-class classifiers. <em>NEUCOM</em>, <em>556</em>, 126579.
(<a href="https://doi.org/10.1016/j.neucom.2023.126579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning requires models to learn new-class knowledge without forgetting old-class information. As a natural solution, the parallel one-class framework (POC) has attracted extensive attention. However, POC is prone to suffer the problem of lacking comparability between classifiers due to their inconsistent output distributions. To address this drawback, we propose an incremental learning method based on I dentically D istributed P arallel O ne-class C lassifiers (IDPOC). The core of IDPOC is a novel one-class classifier with Gaussian distributed output, referred to as Deep-SVD 2 2 D. Deep-SVD 2 2 D encourages the distribution of sample representations to follow the standard multivariate Gaussian. Consequently, the distance between the representation and its class center will approximately follow a chi-square distribution with some freedom degree. IDPOC further eliminates the freedom degree to ensure the output of all classifiers to follow an identical distribution, thus enhancing the comparability between different classifiers. We evaluate IDPOC on four popular benchmarks: MNIST, CIFAR10, CIFAR100, and Tiny-ImageNet. The experimental results show that IDPOC achieves state-of-the-art performance, e.g., it outperforms the best baseline by 1.6\% and 2.8\% on two large-scale benchmarks of CIFAR100 and Tiny-ImageNet, respectively 1 .},
  archive      = {J_NEUCOM},
  author       = {Wenju Sun and Qingyong Li and Jing Zhang and Wen Wang and YangLi-ao Geng},
  doi          = {10.1016/j.neucom.2023.126579},
  journal      = {Neurocomputing},
  pages        = {126579},
  shortjournal = {Neurocomputing},
  title        = {Class incremental learning based on identically distributed parallel one-class classifiers},
  volume       = {556},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PipePar: Enabling fast DNN pipeline parallel training in
heterogeneous GPU clusters. <em>NEUCOM</em>, <em>555</em>, 126661. (<a
href="https://doi.org/10.1016/j.neucom.2023.126661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, pipeline parallelism for large-scale Deep Neural Network (DNN) training has been developed, which partitions the DNN model across multiple devices (e.g., GPUs) and improves the training efficiency by processing data divided into minibatches as a pipeline. However, existing model partitioning algorithms are mostly designed for homogeneous clusters with the same GPU devices and network connections (e.g., bandwidths), while heterogeneous GPU clusters are widely used in mainstream computing infrastructures. In heterogeneous environment, devices are equipped with different GPUs and network connections, and the efficiency of previous approaches is unsatisfactory due to the unbalanced load of the pipeline stages . In this paper, we propose PipePar, a model partitioning and task placement algorithm for pipeline parallel DNN training in heterogeneous GPU clusters. PipePar is based on dynamic programming with search space pruning that takes into consideration both the heterogeneity of GPUs and network bandwidth . PipePar can profile the DNN model for each type of GPU and conduct model partitioning and task placement based on given GPUs and network connections, which can optimize pipeline load balancing in heterogeneous environments and thus improve training efficiency. We design and implement a pipeline-based distributed deep learning training system in a heterogeneous GPU cluster and show through extensive experiments that PipePar outperforms the baseline approaches in the speed of large-scale DNN training.},
  archive      = {J_NEUCOM},
  author       = {Jinghui Zhang and Geng Niu and Qiangsheng Dai and Haorui Li and Zhihua Wu and Fang Dong and Zhiang Wu},
  doi          = {10.1016/j.neucom.2023.126661},
  journal      = {Neurocomputing},
  pages        = {126661},
  shortjournal = {Neurocomputing},
  title        = {PipePar: Enabling fast DNN pipeline parallel training in heterogeneous GPU clusters},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combined scaling for zero-shot transfer learning.
<em>NEUCOM</em>, <em>555</em>, 126658. (<a
href="https://doi.org/10.1016/j.neucom.2023.126658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in multimodal training methodologies, including CLIP and ALIGN, obviate the necessity for individual data labeling. These approaches utilize pairs of data and corresponding textual information found online as a form of weak supervision signal. However, models employing this kind of weak supervision are not as competitive as their supervised and semi-supervised counterparts when sufficient labeled data is accessible. This performance gap constrains the applicability of weekly supervised models. In this paper, we narrow the gap by proposing a combined scaling method, named BASIC, that achieves 85.7\% top-1 accuracy on the ImageNet ILSVRC-2012 validation set without learning from any labeled ImageNet example. This accuracy surpasses best-published similar models, CLIP and ALIGN, by 9.3\%. Our BASIC model also shows significant improvements in robustness benchmarks. For instance, on 5 test sets with natural distribution shifts such as ImageNet-{A,R,V2,Sketch} and ObjectNet, our model achieves 84.3\% top-1 average accuracy, only a small drop from its original ImageNet accuracy. To achieve these results, we first develop a theoretical framework which shows that larger contrastive batch sizes lead to smaller generalization gaps for image-text models such as CLIP and ALIGN. Based on this theoretical result, we scale up the contrastive learning framework of CLIP and ALIGN in three dimensions (data size, model size, and batch size) by proposing a new method using gradient checkpointing and model parallelism. As a result, our dataset has 6.6B noisy image-text pairs, which is 4x larger than ALIGN, and 16x larger than CLIP. Our largest model has 3B weights, which is 3.75x larger in parameters and 8x larger in FLOPs than ALIGN and CLIP. Finally, our batch size is 65536 which is 2x more than CLIP and 4x more than ALIGN.},
  archive      = {J_NEUCOM},
  author       = {Hieu Pham and Zihang Dai and Golnaz Ghiasi and Kenji Kawaguchi and Hanxiao Liu and Adams Wei Yu and Jiahui Yu and Yi-Ting Chen and Minh-Thang Luong and Yonghui Wu and Mingxing Tan and Quoc V. Le},
  doi          = {10.1016/j.neucom.2023.126658},
  journal      = {Neurocomputing},
  pages        = {126658},
  shortjournal = {Neurocomputing},
  title        = {Combined scaling for zero-shot transfer learning},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multilevel adaptive reduction technique for time series.
<em>NEUCOM</em>, <em>555</em>, 126657. (<a
href="https://doi.org/10.1016/j.neucom.2023.126657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise in this paper a Multilevel Adaptive Reduction Technique (MART) for time series data . MART extracts the main features of a time series and encodes them in a reduced data structure called reduct. The extracted features are leveraged to establish a distance between reducts that satisfies the lower bounding constraint. Furthermore, we show how MART can be further applied on the reduced data and operate at different levels. We conduct experiments on time series datasets that show MART based classification accuracy and multilevel reduction power. We present also a comparative study with well-known SAX based time series reduction techniques and deep learning time series classification techniques .},
  archive      = {J_NEUCOM},
  author       = {Hamdi Yahyaoui and Hosam AboElfotoh and Yanjun Shu},
  doi          = {10.1016/j.neucom.2023.126657},
  journal      = {Neurocomputing},
  pages        = {126657},
  shortjournal = {Neurocomputing},
  title        = {A multilevel adaptive reduction technique for time series},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel momentum prototypical neural network to cross-domain
fault diagnosis for rotating machinery subject to cold-start.
<em>NEUCOM</em>, <em>555</em>, 126656. (<a
href="https://doi.org/10.1016/j.neucom.2023.126656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain rotating machinery fault diagnosis has achieved great success recently with the development of deep transfer learning . However, conventional deep transfer learning methods encounter a severe decline in prediction accuracy when fault samples are limited. Moreover, conventional deep transfer learning methods require additional parameter tuning rather than cold-start when applied to the target tasks, hampering their implementation in practical fault diagnosis applications. In this paper, a novel method, named momentum prototypical neural network (MoProNet), is proposed for cross-domain few-shot rotating machinery fault diagnosis. The MoProNet progressively updates the support encoder to address the prototype oscillation problem and enable the model to apply limited source domain samples to predict target domain faults with cold-start. The performance of the proposed MoProNet is tested on a bearing dataset and a hardware-in-the-loop high-speed train simulation platform, respectively, with over forty cross-domain few-shot fault diagnosis tasks. The experimental results demonstrate that the proposed MoProNet achieves satisfactory results and outperforms the other comparable methods in the same cross-domain few-shot scenarios with the simple AlexNet backbone.},
  archive      = {J_NEUCOM},
  author       = {Xiaohan Chen and Rui Yang and Yihao Xue and Chao Yang and Baoye Song and Maiying Zhong},
  doi          = {10.1016/j.neucom.2023.126656},
  journal      = {Neurocomputing},
  pages        = {126656},
  shortjournal = {Neurocomputing},
  title        = {A novel momentum prototypical neural network to cross-domain fault diagnosis for rotating machinery subject to cold-start},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). YOLO*c — adding context improves YOLO performance.
<em>NEUCOM</em>, <em>555</em>, 126655. (<a
href="https://doi.org/10.1016/j.neucom.2023.126655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {You Only Look Once (YOLO) algorithms deliver state-of-the-art performance in object detection. This research proposes a novel one-stage YOLO-based algorithm that explicitly models the spatial context inherent in traffic scenes. The new YOLO*C algorithm introduces the MCTX context module and integrates loss function changes, effectively leveraging rich global context information. The performance of YOLO*C models is tested on BDD100K traffic data with multiple context variables. The results show that including context improves YOLO detection results without losing efficiency. Smaller models report the most significant improvements. The smallest model accomplished more than a 10\% increase in mAP .5 compared to the baseline YOLO model. Modified YOLOv7 outperformed all models on mAP .5, including two-stage and transformer-based detectors, available at the dataset zoo. The analysis shows that improvement mainly results from better detection of smaller traffic objects, which presents a significant detection challenge within the complex traffic environment.},
  archive      = {J_NEUCOM},
  author       = {Goran Oreski},
  doi          = {10.1016/j.neucom.2023.126655},
  journal      = {Neurocomputing},
  pages        = {126655},
  shortjournal = {Neurocomputing},
  title        = {YOLO*C — adding context improves YOLO performance},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis and control for synchronization of coupled
reaction–diffusion neural networks with multiple couplings subject to
topology attacks. <em>NEUCOM</em>, <em>555</em>, 126653. (<a
href="https://doi.org/10.1016/j.neucom.2023.126653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the synchronization for coupled reaction–diffusion neural networks (CRNNs) with multistate couplings or multiple spatial-diffusion couplings suffering topology attacks. By selecting appropriate Lyapunov functional and utilizing the Kronecker product , several network synchronization criteria are formulated. Moreover, since networks suffering attacks may not be synchronized in some circumstances, two simple controllers are also developed. Finally, the effectiveness of the devised control schemes are verified through two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Xin-Yu Zhao and Jin-Liang Wang},
  doi          = {10.1016/j.neucom.2023.126653},
  journal      = {Neurocomputing},
  pages        = {126653},
  shortjournal = {Neurocomputing},
  title        = {Analysis and control for synchronization of coupled reaction–diffusion neural networks with multiple couplings subject to topology attacks},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph-based interpretability method for deep neural
networks. <em>NEUCOM</em>, <em>555</em>, 126651. (<a
href="https://doi.org/10.1016/j.neucom.2023.126651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of artificial intelligence , the most representative deep learning has been applied to various fields, which is greatly influencing human society. However, deep neural networks (DNNs) are still a black-box model, and the process how they make decisions internally is still difficult to understand and control. At the same time, DNNs take up more hardware resources, resulting in high energy consumption. Therefore, it is significant to study the characteristics of deep AI models and deeply understand the interactions between parameters within AI models so as to improve the interpretability of DNNs, optimize their structure and increase their computational efficiency. In this paper, we propose a graph-based interpretability method for deep neural networks (GIMDNN). The running parameters of DNNs are modeled as a graph by using a kernel function or the Graph Transformer Networks (GTN), where the nodes of the graph are obtained by dimensional mapping of the parameters of the DNNs, and the edges are calculated by the Gaussian kernel function. The generated graphs are classified by a graph convolutional network (GCN). The association relationship between the adjacent layers and the running mechanism of DNNs are analyzed, and the importance of the parameters of each layer in the DNNs for the final classification result can be obtained. Convolutional neural networks (CNNs) are one of the most representative models in DNNs. The proposed method is experimentally evaluated on the CNNs. The experimental results show that the proposed method can interpret the associations among the weight parameters as well as the correlation between two adjacent layers. Therefore, the DNNs for special tasks, such as portable applications, edge computing , and so on, can be customized, the number of parameters can be reduced. It is valuable to interpret the operation and principle of CNNs.},
  archive      = {J_NEUCOM},
  author       = {Tao Wang and Xiangwei Zheng and Lifeng Zhang and Zhen Cui and Chunyan Xu},
  doi          = {10.1016/j.neucom.2023.126651},
  journal      = {Neurocomputing},
  pages        = {126651},
  shortjournal = {Neurocomputing},
  title        = {A graph-based interpretability method for deep neural networks},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Fixed-time consensus-based distributed nash equilibrium
seeking for noncooperative game with second-order players.
<em>NEUCOM</em>, <em>555</em>, 126650. (<a
href="https://doi.org/10.1016/j.neucom.2023.126650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to study the Nash equilibrium (NE) seeking algorithm of noncooperative game with second-order system under strongly connected digraph . In the algorithm, velocity information is not directly accessible to players, in order to avoid the need for additional velocity observers. Meanwhile, for position information, the position estimation of all the other players under local communication is completed in fixed time. To address the aforementioned concern, a NE seeking algorithm with a two-time-scale structure is designed. (1) For reduced system, a second-order velocity estimation model based on state observer is introduced to avoid direct acquisition of velocity information; (2) For fast compensation mechanism, each player uses leader-following consensus protocol to estimate the position of all the other players. The fixed-time consensus protocol is utilized to ensure that the position is estimated in fixed time. Then, aiming to reduce the communication costs and communication burden among players, the event-triggered mechanism is introduced into the above algorithm, and Zeno behavior is excluded. Lastly, a self-organized network problem involving autonomous vehicles is presented to validate the efficacy of the proposed theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Mengxin Wang and Mengting Zhou and Sitian Qin},
  doi          = {10.1016/j.neucom.2023.126650},
  journal      = {Neurocomputing},
  pages        = {126650},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time consensus-based distributed nash equilibrium seeking for noncooperative game with second-order players},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classical-to-quantum convolutional neural network transfer
learning. <em>NEUCOM</em>, <em>555</em>, 126643. (<a
href="https://doi.org/10.1016/j.neucom.2023.126643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning using quantum convolutional neural networks (QCNNs) has demonstrated success in both quantum and classical data classification . In previous studies, QCNNs attained a higher classification accuracy than their classical counterparts under the same training conditions in the few-parameter regime. However, the general performance of large-scale quantum models is difficult to examine because of the limited size of quantum circuits , which can be reliably implemented in the near future. We propose transfer learning as an effective strategy for utilizing small QCNNs in the noisy intermediate-scale quantum era to the full extent. In the classical-to-quantum transfer learning framework, a QCNN can solve complex classification problems without requiring a large-scale quantum circuit by utilizing a pre-trained classical convolutional neural network (CNN). We perform numerical simulations of QCNN models with various sets of quantum convolution and pooling operations for MNIST data classification under transfer learning, in which a classical CNN is trained with Fashion-MNIST data. The results show that transfer learning from classical to quantum CNN performs considerably better than purely classical transfer learning models under similar training conditions.},
  archive      = {J_NEUCOM},
  author       = {Juhyeon Kim and Joonsuk Huh and Daniel K. Park},
  doi          = {10.1016/j.neucom.2023.126643},
  journal      = {Neurocomputing},
  pages        = {126643},
  shortjournal = {Neurocomputing},
  title        = {Classical-to-quantum convolutional neural network transfer learning},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Teex: A toolbox for the evaluation of explanations.
<em>NEUCOM</em>, <em>555</em>, 126642. (<a
href="https://doi.org/10.1016/j.neucom.2023.126642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present teex , a Python t oolbox for the e valuation of ex planations. teex focuses on the evaluation of local explanations of the predictions of machine learning models by comparing them to ground-truth explanations. It supports several types of explanations: feature importance vectors, saliency maps, decision rules, and word importance maps. A collection of evaluation metrics is provided for each type. Real-world datasets and generators of synthetic data with ground-truth explanations are also contained within the library. teex contributes to research on explainable AI by providing tested, streamlined, user-friendly tools to compute quality metrics for the evaluation of explanation methods. Source code and a basic overview can be found at github.com/chus-chus/teex , and tutorials and full API documentation are at teex.readthedocs.io .},
  archive      = {J_NEUCOM},
  author       = {Jesús M. Antoñanzas and Yunzhe Jia and Eibe Frank and Albert Bifet and Bernhard Pfahringer},
  doi          = {10.1016/j.neucom.2023.126642},
  journal      = {Neurocomputing},
  pages        = {126642},
  shortjournal = {Neurocomputing},
  title        = {Teex: A toolbox for the evaluation of explanations},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-based explanations of concept drift. <em>NEUCOM</em>,
<em>555</em>, 126640. (<a
href="https://doi.org/10.1016/j.neucom.2023.126640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept drift refers to the phenomenon that the distribution generating the observed data changes over time. If drift is present, machine learning models can become inaccurate and need adjustment. While there do exist methods to detect concept drift or to adjust models in the presence of observed drift, the question of explaining drift, i.e., describing the potentially complex and high dimensional change of distributions in a human-understandable fashion, has hardly been considered so far. This problem is of importance since it enables an inspection of the most prominent characteristics of how and where drift manifests. Hence, it allows human understanding of the change and it increases acceptance of life-long learning models. In this paper, we present a novel technology characterizing concept drift in terms of the characteristic change of spatial features based on various explanation techniques. To do so, we propose a methodology to reduce the explanation of concept drift to an explanation of models that are trained in a suitable way to extract relevant information from the drift. This way, a large variety of explanation schemes is available, and a suitable method can be selected for the problem at hand. We outline the potential of this approach and demonstrate its usefulness in several examples.},
  archive      = {J_NEUCOM},
  author       = {Fabian Hinder and Valerie Vaquet and Johannes Brinkrolf and Barbara Hammer},
  doi          = {10.1016/j.neucom.2023.126640},
  journal      = {Neurocomputing},
  pages        = {126640},
  shortjournal = {Neurocomputing},
  title        = {Model-based explanations of concept drift},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A conditional branch predictor based on weightless neural
networks. <em>NEUCOM</em>, <em>555</em>, 126637. (<a
href="https://doi.org/10.1016/j.neucom.2023.126637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional branch prediction allows the speculative fetching and execution of instructions before knowing the direction of conditional statements . As in other areas, machine learning techniques are a promising approach to building branch predictors , e.g., the Perceptron predictor. However, those traditional solutions demand large input sizes, which impose a considerable area overhead. We propose a conditional branch predictor based on the WiSARD (Wilkie, Stoneham, and Aleksander’s Recognition Device) weightless neural network model. The WiSARD-based predictor implements one-shot online training designed to address branch prediction as a binary classification problem. We compare the WiSARD-based predictor with two state-of-the-art predictors: TAGE-SC-L (TAgged GEometric-Statistical Corrector-Loop) and the Multiperspective Perceptron . Our experimental evaluation shows that our proposed predictor, with a smaller input size, outperforms the perceptron-based predictor by about 0.09\% and achieves similar accuracy to that of TAGE-SC-L. In addition, we perform an experimental sensitivity analysis to find the best predictor for each dataset, and based on these results, we designed new specialized predictors using a particular parameter composition for each dataset. The results show that the specialized WiSARD-based predictor outperforms the state-of-the-art by more than 2.3\% in the best case. Furthermore, through the implementation of specialized predictor classifiers, we discovered that utilizing 90\% of the specialized predictor for a specific dataset yielded comparable performance to the corresponding specialized predictor.},
  archive      = {J_NEUCOM},
  author       = {Luis A.Q. Villon and Zachary Susskind and Alan T.L. Bacellar and Igor D.S. Miranda and Leandro S. de Araújo and Priscila M.V. Lima and Mauricio Breternitz Jr. and Lizy K. John and Felipe M.G. França and Diego L.C. Dutra},
  doi          = {10.1016/j.neucom.2023.126637},
  journal      = {Neurocomputing},
  pages        = {126637},
  shortjournal = {Neurocomputing},
  title        = {A conditional branch predictor based on weightless neural networks},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Static and adaptive subspace information fusion for
indefinite heterogeneous proximity data. <em>NEUCOM</em>, <em>555</em>,
126635. (<a href="https://doi.org/10.1016/j.neucom.2023.126635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous data is common in many real-world machine learning applications, such as healthcare, market analysis, environmental sciences, and social media analysis. In these domains, data is often represented in different modalities and, most of the time, in non-vectorial formats, like text, images, and video. Traditional machine learning algorithms are often limited in their ability to effectively analyze and learn from such diverse data types . In this paper, we propose two approaches for such heterogeneous data analysis: static and adaptive subspace kernel fusion. The first approach is a kernel-based method extracting the essential parts of the subspace of each input modality and creating one single fused representation of the data. The second approach utilizes an adaptation step by integrating the weighting of spectral properties into the fusion process in order to improve the data’s representation with respect to a given classification task . Our proposed methods are evaluated on several multi-modal, heterogeneous data sets and demonstrate significant performance improvement compared to other methods in the field. Our results highlight the importance of fusing the underlying subspace information of heterogeneous data for achieving superior performance in machine learning tasks.},
  archive      = {J_NEUCOM},
  author       = {Maximilian Münch and Manuel Röder and Simon Heilig and Christoph Raab and Frank-Michael Schleif},
  doi          = {10.1016/j.neucom.2023.126635},
  journal      = {Neurocomputing},
  pages        = {126635},
  shortjournal = {Neurocomputing},
  title        = {Static and adaptive subspace information fusion for indefinite heterogeneous proximity data},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-survey on outlier and anomaly detection.
<em>NEUCOM</em>, <em>555</em>, 126634. (<a
href="https://doi.org/10.1016/j.neucom.2023.126634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impact of outliers and anomalies on model estimation and data processing is of paramount importance, as evidenced by the extensive body of research spanning various fields over several decades: thousands of research papers have been published on the subject. As a consequence, numerous reviews, surveys, and textbooks have sought to summarize the existing literature, encompassing a wide range of methods from both the statistical and data mining communities. While these endeavors to organize and summarize the research are invaluable, they face inherent challenges due to the pervasive nature of outliers and anomalies in all data-intensive applications, irrespective of the specific application field or scientific discipline. As a result, the resulting collection of papers remains voluminous and somewhat heterogeneous. To address the need for knowledge organization in this domain, this paper implements the first systematic meta-survey of general surveys and reviews on outlier and anomaly detection. Employing a classical systematic survey approach, the study collects nearly 500 papers using two specialized scientific search engines. From this comprehensive collection, a subset of 56 papers that claim to be general surveys on outlier detection is selected using a snowball search technique to enhance field coverage. A meticulous quality assessment phase further refines the selection to a subset of 25 high-quality general surveys. Using this curated collection, the paper investigates the evolution of the outlier detection field over a 20-year period, revealing emerging themes and methods. Furthermore, an analysis of the surveys sheds light on the survey writing practices adopted by scholars from different communities who have contributed to this field. Finally, the paper delves into several topics where consensus has emerged from the literature. These include taxonomies of outlier types, challenges posed by high-dimensional data, the importance of anomaly scores, the impact of learning conditions, difficulties in benchmarking, and the significance of neural networks . Non-consensual aspects are also discussed, particularly the distinction between local and global outliers and the challenges in organizing detection methods into meaningful taxonomies.},
  archive      = {J_NEUCOM},
  author       = {Madalina Olteanu and Fabrice Rossi and Florian Yger},
  doi          = {10.1016/j.neucom.2023.126634},
  journal      = {Neurocomputing},
  pages        = {126634},
  shortjournal = {Neurocomputing},
  title        = {Meta-survey on outlier and anomaly detection},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selected confidence sample labeling for domain adaptation.
<em>NEUCOM</em>, <em>555</em>, 126624. (<a
href="https://doi.org/10.1016/j.neucom.2023.126624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain adaptation (UDA) aims to transfer knowledge from the labeled source domain to the unlabeled target domain. Recently, to achieve reliable knowledge learning, progressively labeling (PL) is proposed to select reliable target samples for training. Although PL achieves fruitful results, there are two problems that limit its performance: (a) PL may neglect to filter out the uncertain samples that lie in the classification boundaries, which might select low-quality target samples for training, and lead to error accumulations; and (b) PL might overlook the consistent selection in the sample selection stage during iteration, which might result in unstable sample selection. To cope with these problems, we propose a novel method called Selected Confidence Sample Labeling (SCSL). SCSL consists of three parts: Discriminative Progressively Labeling (DPL), Consistency Strategy (CS), and Differential Learning (DL). First, DPL selects the high-confidence target samples with the maximum probability difference between the highest and the second-highest probabilities of classification. In this way, the uncertain samples are filtered out, while the qualities of the selected target samples are ensured. Second, CS includes a group of consistency strategies to make the selected high-confidence target samples near to the class-centroids. This further improves the confidence degree of the selected target samples, and ensures that the proposed model does not remove or replace the selected target samples during iteration. At last, DL is a bi-strategic training approach that applies CS and top- k k fuzzy probability clustering to train the high-confidence and the remaining target samples, respectively. In doing so, all the target samples are trained simultaneously, and the generalization of the model is improved. Extensive experiments on four benchmark datasets with the comparison of several advanced algorithms demonstrate the superiority of SCSL.},
  archive      = {J_NEUCOM},
  author       = {Zefeng Zheng and Shaohua Teng and Naiqi Wu and Luyao Teng and Wei Zhang and Lunke Fei},
  doi          = {10.1016/j.neucom.2023.126624},
  journal      = {Neurocomputing},
  pages        = {126624},
  shortjournal = {Neurocomputing},
  title        = {Selected confidence sample labeling for domain adaptation},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Speech emotion recognition via multiple fusion under
spatial–temporal parallel network. <em>NEUCOM</em>, <em>555</em>,
126623. (<a href="https://doi.org/10.1016/j.neucom.2023.126623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech, as a necessary way to express emotions, plays a vital role in human communication. With the continuous deepening of research on emotion recognition in human–computer interaction, speech emotion recognition (SER) has become an essential task to improve the human–computer interaction experience. When performing emotion feature extraction of speech, the method of cutting the speech spectrum will destroy the continuity of speech. Besides, the method of using the cascaded structure without cutting the speech spectrum cannot simultaneously extract speech spectrum information from both temporal and spatial domains. To this end, we propose a spatial–temporal parallel network for speech emotion recognition without cutting the speech spectrum. To further mix the temporal and spatial features, we design a novel fusion method (called multiple fusion) that combines the concatenate fusion and ensemble strategy. Finally, the experimental results on five datasets demonstrate that the proposed method outperforms state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Chenquan Gan and Kexin Wang and Qingyi Zhu and Yong Xiang and Deepak Kumar Jain and Salvador García},
  doi          = {10.1016/j.neucom.2023.126623},
  journal      = {Neurocomputing},
  pages        = {126623},
  shortjournal = {Neurocomputing},
  title        = {Speech emotion recognition via multiple fusion under spatial–temporal parallel network},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global entropy pooling layer for convolutional neural
networks. <em>NEUCOM</em>, <em>555</em>, 126615. (<a
href="https://doi.org/10.1016/j.neucom.2023.126615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel Global Entropy Pooling (GEP) layer for Convolutional Neural Networks (CNNs). This is the first approach that uses the Entropy value directly for pooling rather than creating a weighting mechanism for feature maps obtained via convolution. This way, we use the ”amount” of information (expressed by Entropy) to describe the feature maps in contrast to the most commonly used averaging (Global Average Pooling , GAP). We use our method in a rather unusual way. We replace GAP with GEP and use the same feature extractor and classifier weights for the prediction — with no additional training. Our layer can be easily integrated (instead of the GAP layer) into various pre-trained CNN models. From a technical perspective, it is possible to integrate GEP without additional training, because it does not contain any parameters that have to be trained. Also, its input and output have the same format as the GAP’s one. We examine how the replacement impacts the model behavior . Despite a completely different form of pooling, utilization of the GEP layer in the examined pre-trained models (InceptionV3, Xception and InceptionResNetV2) allowed us to obtain some accuracy improvements in comparison to the original networks on the subsets of the ImageNet dataset. Moreover, networks modified with our layer exhibit an interesting property — they are more ”confident” in the predictions they return. It manifests itself through higher values of the probabilities assigned to correctly predicted classes. This opens a possibility to use not only the initial layers of the pretrained network, but also to modify network’s middle parts and reuse its classifier trained on an original model as well.},
  archive      = {J_NEUCOM},
  author       = {Katarzyna Filus and Joanna Domańska},
  doi          = {10.1016/j.neucom.2023.126615},
  journal      = {Neurocomputing},
  pages        = {126615},
  shortjournal = {Neurocomputing},
  title        = {Global entropy pooling layer for convolutional neural networks},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SMAR: Summary-aware multi-aspect recommendation.
<em>NEUCOM</em>, <em>555</em>, 126614. (<a
href="https://doi.org/10.1016/j.neucom.2023.126614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting user preferences and item features from reviews to assist recommendations is becoming increasingly popular. However, on the one hand, existing works generally select reviews based on how well user reviews match item reviews. They ignore that reviews may contain noise such as irrelevant phrases, which will affect the accuracy of selecting important reviews. In contrast, summaries written by users are abstracts of reviews that contain critical item feature information. They can be adopted to identify crucial reviews and further capture user’s fine-grained preferences from reviews. In addition, current methods do not consider that different items have different aspects in the same domain. They normally set a fixed number of aspects of the entire domain to get coarse-grained user preferences and item features. However, when modeling the user’s preferences for the current item, it might be more important to capture the corresponding aspects of the item preferences. Therefore, in this paper, we are motivated to propose a Summary-Aware Multi-Aspect Recommendation (SMAR). Specifically, we first construct a Summary-Aware Review Selection Module which adopts summaries to alleviate noise in reviews, identifying key reviews accurately. We then design a Summary-Aware Multi-Aspect Module which captures targeted user preferences towards the current item’s aspects. Finally, we employ Latent Factor Model to complete the recommendation process. The experimental results on Amazon datasets show that our method significantly outperfoms state-of-art approaches in terms of rating prediction accuracy.},
  archive      = {J_NEUCOM},
  author       = {Liye Shi and Wen Wu and Jiayi Chen and Wenxin Hu and Wei Zheng and Xi Chen and Liang He},
  doi          = {10.1016/j.neucom.2023.126614},
  journal      = {Neurocomputing},
  pages        = {126614},
  shortjournal = {Neurocomputing},
  title        = {SMAR: Summary-aware multi-aspect recommendation},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Difference-guided multiscale graph convolution network for
unsupervised change detection in PolSAR images. <em>NEUCOM</em>,
<em>555</em>, 126611. (<a
href="https://doi.org/10.1016/j.neucom.2023.126611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image change detection is important in polarimetric synthetic aperture radar (PolSAR) image analysis and interpretation. However, improving its accuracy is challenging because of the interference of multiplicative speckle noise. To address this issue, we propose an unsupervised PolSAR image change detection method based on a multiscale graph convolutional network (GCN). First, a Shannon entropy difference image is introduced and improved to obtain an enhanced difference image (EDI) that can effectively suppress speckle noise while preserving edge information. The generated EDI can be further utilised to construct a pseudo-label set required for unsupervised change detection. Subsequently, a difference constraint joint graph construction (DCJGC) module is proposed to obtain the object-level input information of the network. This uses the joint superpixels of multitemporal PolSAR images as graph nodes, and then introduces the difference information in the EDI to constrain the formation process of the edges between the nodes, efficiently and accurately constructing undirected graphs . Finally, a difference-guided multiscale GCN (DGMGCN) is designed for PolSAR image change detection. The network utilises difference information to eliminate the adverse effect of speckle noise on change detection and fully capture the change-aware features of multitemporal PolSAR images at fine and coarse scales, thereby improving feature discriminability . Experimental results on six real Gaofen-3 PolSAR datasets validate the superiority of the proposed approach over other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Dazhi Xu and Ming Li and Yan Wu and Peng Zhang and Xinyue Xin and Zhifei Yang},
  doi          = {10.1016/j.neucom.2023.126611},
  journal      = {Neurocomputing},
  pages        = {126611},
  shortjournal = {Neurocomputing},
  title        = {Difference-guided multiscale graph convolution network for unsupervised change detection in PolSAR images},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Plant leaf deep semantic segmentation and a novel benchmark
dataset for morning glory plant harvesting. <em>NEUCOM</em>,
<em>555</em>, 126609. (<a
href="https://doi.org/10.1016/j.neucom.2023.126609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision and deep learning have made substantial progress in the areas of agriculture and smart farming, particularly for enhancing crop production using image segmentation techniques for crop yield prediction. Further improvements to crop yield prediction results can be achieved by developing accurate and efficient methods. In response to such demands, this paper proposes a novel convolutional neural network architecture, called densely connected SegNet (D-SegNet) and demonstrates its advantages on plant segmentation using a new morning glory plant dataset, and also on a complimentary publicly available dataset to promote research in this direction. The D-SegNet is evaluated using 10-fold cross validation. It achieves performance better than the state-of-the-art SegNet algorithm. The evaluated precision, recall and F1-score values are 98.20\%, 90.64\% and 94.26\%, respectively, for the morning glory plant dataset. The intersection over union (IoU) value in the image segmentation tasks is 90.56\%. A series of experiments on the morning glory plant dataset as well as on the publicly available dataset were conducted. The results show that the proposed method achieves accurate segmentation results and can be useful for assessing the plant weight during harvesting. In summary, this new plant segmentation network , D-SegNet, could form an important component of future cloud-based machine learning systems to predict crop yield from noisy smartphone images taken in the field.},
  archive      = {J_NEUCOM},
  author       = {Jingxuan Su and Sean Anderson and Mahed Javed and Charoenchai Khompatraporn and Apinanthana Udomsakdigool and Lyudmila Mihaylova},
  doi          = {10.1016/j.neucom.2023.126609},
  journal      = {Neurocomputing},
  pages        = {126609},
  shortjournal = {Neurocomputing},
  title        = {Plant leaf deep semantic segmentation and a novel benchmark dataset for morning glory plant harvesting},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous graph attention network with motif clique.
<em>NEUCOM</em>, <em>555</em>, 126608. (<a
href="https://doi.org/10.1016/j.neucom.2023.126608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information networks (HINs) have been proven to be powerful in modeling various real-world networks, such as academic networks and social media networks. By distinguishing the types of relationships and nodes, HINs obtain the capability to model multifarious data, while bringing challenges to data mining and analysis. Specifically, how to comprehensively mine the semantic information in HINs remains an open question. Although recently studied network schemas such as meta-paths or meta-graphs have achieved empirical success, they still have limitations in modeling the complex underlying relations to facilitate the graph neural networks , e.g. , different schemas may overlap in semantics and lead to redundant computations. To address this issue, we leverage a recently introduced higher-order network schema known as the motif clique (abbreviated as m-clique). This schema offers greater expressiveness, enabling us to effectively construct the semantic neighborhood of nodes. We further propose a novel heterogeneous graph attention network with m-cliques, named HAMC, which employs a two-level attention mechanism (node-level and semantic-level) to learn node representations. The two-level attention measures the importance of neighbors and m-cliques for each node, respectively. Extensive experiments demonstrate that the proposed HAMC outperforms the state-of-the-art methods in many heterogeneous network analytic tasks such as node classification and clustering. Our code is available at https://github.com/wcx21/HAMC-Heterogeneous-Graph-Attention-Network-with-Motif-Clique .},
  archive      = {J_NEUCOM},
  author       = {Chenxu Wang and Minnan Luo and Zhen Peng and Yixiang Dong and Huaping Liu},
  doi          = {10.1016/j.neucom.2023.126608},
  journal      = {Neurocomputing},
  pages        = {126608},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous graph attention network with motif clique},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastively enforcing distinctiveness for multi-label
image classification. <em>NEUCOM</em>, <em>555</em>, 126605. (<a
href="https://doi.org/10.1016/j.neucom.2023.126605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, as an effective way of learning latent representations, contrastive learning has been increasingly popular and successful in various domains. The success of contrastive learning in single-label classifications motivates us to leverage this learning framework to enhance distinctiveness for better performance in multi-label image classification . In this paper, we show that a direct application of contrastive learning can hardly improve in multi-label cases. Accordingly, we propose a novel framework for multi-label classification with contrastive learning in a fully supervised setting, which learns multiple representations of an image under the context of different labels. This introduces a simple yet intuitive adaption of contrastive learning into our model to boost its performance in multi-label image classification . Extensive experiments on four benchmark datasets show that the proposed framework achieves state-of-the-art performance in the comparison with the advanced methods in multi-label classification.},
  archive      = {J_NEUCOM},
  author       = {Son D. Dao and He Zhao and Dinh Phung and Jianfei Cai},
  doi          = {10.1016/j.neucom.2023.126605},
  journal      = {Neurocomputing},
  pages        = {126605},
  shortjournal = {Neurocomputing},
  title        = {Contrastively enforcing distinctiveness for multi-label image classification},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modal fusion for millimeter-wave communication
systems: A spatio-temporal enabled approach. <em>NEUCOM</em>,
<em>555</em>, 126604. (<a
href="https://doi.org/10.1016/j.neucom.2023.126604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In millimeter-wave (mmWave) massive multi-input multi-output (MIMO) systems, beam selection can enhance channel capacity and reduce error rate. However, existing beam selection methods for MIMO systems rely on traditional optimization techniques, which may not be feasible for real-time data transmission. Hence, this paper proposes a novel beam prediction approach via multi-modal fusion and spatio-temporal-enabled features. Specifically, the proposed method can improve MIMO system performance by integrating information from multiple perspectives, such as temporal, spatial, and frequency domains. Moreover, the proposed approach is based on a deep learning framework utilizing 3-dimensional convolutional neural networks (3DCNNs) and transformer module to capture spatio-temporal data correlations. Extensive simulation results show that the proposed mechanism outperforms massive benchmarks in terms of beam prediction accuracy from 2.63\% to 11\%.},
  archive      = {J_NEUCOM},
  author       = {Quan Zhou and Yuping Lai and Hongyu Yu and Ronghui Zhang and Xiaojun Jing and Lijuan Luo},
  doi          = {10.1016/j.neucom.2023.126604},
  journal      = {Neurocomputing},
  pages        = {126604},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal fusion for millimeter-wave communication systems: A spatio-temporal enabled approach},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Embracing ambiguity: Improving similarity-oriented tasks
with contextual synonym knowledge. <em>NEUCOM</em>, <em>555</em>,
126583. (<a href="https://doi.org/10.1016/j.neucom.2023.126583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contextual synonym knowledge is crucial for those similarity-oriented tasks whose core challenge lies in capturing semantic similarity between entities in their contexts, such as entity linking and entity matching. However, most Pre-trained Language Models (PLMs) lack synonym knowledge due to inherent limitations of their pre-training objectives such as masked language modeling (MLM). Existing works which inject synonym knowledge into PLMs often suffer from two severe problems: (i) Neglecting the ambiguity of synonyms, and (ii) Undermining semantic understanding of original PLMs, which is caused by inconsistency between the exact semantic similarity of the synonyms and the broad conceptual relevance learned from the original corpus. To address these issues, we propose PICSO, a flexible framework that supports the injection of contextual synonym knowledge from multiple domains into PLMs via a novel entity-aware Adapter which focuses on the semantics of the entities (synonyms) in the contexts. Meanwhile, PICSO stores the synonym knowledge in additional parameters of the Adapter structure, which prevents it from corrupting the semantic understanding of the original PLM. Extensive experiments demonstrate that PICSO can dramatically outperform the original PLMs and the other knowledge and synonym injection models on four different similarity-oriented tasks. In addition, experiments on GLUE prove that PICSO also benefits general natural language understanding tasks. Codes and data will be public.},
  archive      = {J_NEUCOM},
  author       = {Yangning Li and Jiaoyan Chen and Yinghui Li and Tianyu Yu and Xi Chen and Hai-Tao Zheng},
  doi          = {10.1016/j.neucom.2023.126583},
  journal      = {Neurocomputing},
  pages        = {126583},
  shortjournal = {Neurocomputing},
  title        = {Embracing ambiguity: Improving similarity-oriented tasks with contextual synonym knowledge},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TSDTVOS: Target-guided spatiotemporal dual-stream
transformers for video object segmentation. <em>NEUCOM</em>,
<em>555</em>, 126582. (<a
href="https://doi.org/10.1016/j.neucom.2023.126582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video object segmentation automatically separates the interested objects from the background across a video sequence and was an active research area in recent years. The crucial challenge lies in investigating an effective architecture to fully exploit spatiotemporal correlation in a given video sequence for achieving accurate segmentation results. In this paper, we propose a novel semi-supervised Transformer-based framework called Target-guided Spatiotemporal Dual-stream Transformers (TSDT) with two separate streams to enable effective spatiotemporal context propagation. Technically, the temporal stream is used to aggregate rich temporal cues from past frames, while the spatial stream is trained to encode object location and appearance information stored in the current frame. To compress and integrate temporal features, a target guidance block (TGB) is designed to retrieve target information in the past video flow under the guidance of the current frame. The experimental results on video object segmentation benchmarks demonstrate the feasibility and effectiveness of the proposed framework. Codes and trained models are available at https://github.com/zhouweii234/TSDTVOS .},
  archive      = {J_NEUCOM},
  author       = {Wei Zhou and Yuqian Zhao and Fan Zhang and Biao Luo and Lingli Yu and Baifan Chen and Chunhua Yang and Weihua Gui},
  doi          = {10.1016/j.neucom.2023.126582},
  journal      = {Neurocomputing},
  pages        = {126582},
  shortjournal = {Neurocomputing},
  title        = {TSDTVOS: Target-guided spatiotemporal dual-stream transformers for video object segmentation},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Class attention to regions of lesion for imbalanced medical
image recognition. <em>NEUCOM</em>, <em>555</em>, 126577. (<a
href="https://doi.org/10.1016/j.neucom.2023.126577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated medical image classification is the key component in intelligent diagnosis systems. However, most medical image datasets contain plenty of samples of common diseases and just a handful of rare ones, leading to major class imbalances. Currently, it is an open problem in intelligent diagnosis to effectively learn from imbalanced training data. In this paper, we propose a simple yet effective framework, named C lass A ttention to RE gions of the lesion (CARE), to handle data imbalance issues by embedding attention into the training process of C onvolutional N eural N etworks (CNNs). The proposed attention module helps CNNs attend to lesion regions of rare diseases, therefore helping CNNs to learn their characteristics more effectively. In addition, this attention module works only during the training phase and does not change the architecture of the original network, so it can be directly combined with any existing CNN architecture. The CARE framework needs bounding boxes to represent the lesion regions of rare diseases. To alleviate the need for manual annotation, we further developed variants of CARE by leveraging the traditional saliency methods or a pretrained segmentation model for bounding box generation. Results show that the CARE variants with automated bounding box generation are comparable to the original CARE framework with manual bounding box annotations. A series of experiments on an imbalanced skin image dataset and a pneumonia dataset indicates that our method can effectively help the network focus on the lesion regions of rare diseases and remarkably improves the classification performance of rare diseases.},
  archive      = {J_NEUCOM},
  author       = {Jia-Xin Zhuang and Jiabin Cai and Jianguo Zhang and Wei-shi Zheng and Ruixuan Wang},
  doi          = {10.1016/j.neucom.2023.126577},
  journal      = {Neurocomputing},
  pages        = {126577},
  shortjournal = {Neurocomputing},
  title        = {Class attention to regions of lesion for imbalanced medical image recognition},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Refined SBERT: Representing sentence BERT in manifold space.
<em>NEUCOM</em>, <em>555</em>, 126453. (<a
href="https://doi.org/10.1016/j.neucom.2023.126453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed sentence representations have shown great power in a wide range of natural language processing (NLP) tasks. Meanwhile, a contextualized sentence representation, called Sentence BERT (SBERT), achieves excellent performance in quite a few NLP tasks. However, Sentence BERT is typically learned in the Euclidean space, the geometric structure of sentence representations and their relations to the representations of sentence’s contexts has not been carefully studied yet. In this paper, we propose a new sentence representation method, named Refined SBERT, which utilizes manifold learning to refine sentence BERT by re-embedding sentence vectors from the original embedding space to a new refined semantic space. In order to map sentences to manifold space, we utilize neighborhood preserving embedding to construct the local manifold structure of the sentences. Our method can discover the local geometric structure and obtain a compact sentence BERT subspace, which can best detect the essential semantic structure. We conduct comprehensive experiments on various sentence embedding tasks including semantic textual similarity tasks, text classification and document clustering , and the experimental results show that the proposed model achieved promising results, comparing to several popular sentence representations.},
  archive      = {J_NEUCOM},
  author       = {Yonghe Chu and Heling Cao and Yufeng Diao and Hongfei Lin},
  doi          = {10.1016/j.neucom.2023.126453},
  journal      = {Neurocomputing},
  pages        = {126453},
  shortjournal = {Neurocomputing},
  title        = {Refined SBERT: Representing sentence BERT in manifold space},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SGDAT: An optimization method for binary neural networks.
<em>NEUCOM</em>, <em>555</em>, 126431. (<a
href="https://doi.org/10.1016/j.neucom.2023.126431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent (SGD), one of the most popular neural network optimization algorithms , has a solid theoretical foundation as well as good generalization performance . However vanilla SGD performs catastrophically in Binary Neural Networks (BNNs). Many studies have identified this phenomenon without explaining its causes in depth. In this paper, we try to experimentally understand the possible reasons for this and significantly improve the performance of vanilla SGD in BNNs training by adjusting the training strategy to be comparable to Adam. We subsequently propose a new optimization method for training deep neural networks (DNNs) with binary weights. In the proposed SGD with A daptive T hreshold, referred to as SGDAT, we suppress the frequency of weights flipping by thresholds and adjust the threshold of each parameter according to the number of flipping to further reduce the network noise, stabilize the network training, and improve the network generalization ability . Also, we present a complete ablation study of the hyperparameters space, as well as experimentally analyze the impact of using adaptive thresholds. Furthermore, we conduct image classification experiments over the CIFAR10, CIFAR100 and TinyImageNet datasets using BinaryNet and ResNet-18 network structure. The experiments show that SGDAT outperforms other binary optimizers. Code is available at: https://github.com/gushan/SGDAT.},
  archive      = {J_NEUCOM},
  author       = {Gu Shan and Zhang Guoyin and Jia Chengwei and Wu Yanxia},
  doi          = {10.1016/j.neucom.2023.126431},
  journal      = {Neurocomputing},
  pages        = {126431},
  shortjournal = {Neurocomputing},
  title        = {SGDAT: An optimization method for binary neural networks},
  volume       = {555},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature subset selection in data-stream environments using
asymmetric hidden markov models and novelty detection. <em>NEUCOM</em>,
<em>554</em>, 126641. (<a
href="https://doi.org/10.1016/j.neucom.2023.126641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of computational power and memory capacity, it is possible to record and analyse lots of features of different nature in real time or in a data stream manner. Nonetheless, in many applications, not all variables may be relevant to explain the nature of the data. Feature subset selection strategies are therefore required to extract the relevant features to understand the data generating process. Much work has been performed in the area of supervised classification problems regarding feature selection, whereas for unsupervised environments, scarce studies have been conducted. In current feature subset selection methodologies for unsupervised data streams, the set of relevant variables are reevaluated or forgotten whenever a new instance or chunk of data arrives: this approach can be computationally expensive or unnecessary. Therefore, in this article, we provide a method to perform feature subset selection in unsupervised data streams. An embedded feature subset selection methodology based on asymmetric hidden Markov models and novel concept discovery strategies is used. This methodology can be used to detect novel concepts in data, and update the set of relevant features when a drift in the data stream is detected. Thus, the relevant variables are updated only when needed. To make this possible, we provide a model for batch and online problems, that is capable of dynamically determining the relevant variables to address feature selection in data streams. Additionally, the model provides domain insights using context-specific Bayesian networks which can be helpful to understand the dynamic process. To validate the proposed methodology, synthetic and real data from ball-bearings are used. Additionally, the proposed methodology is compared with other state of the art methodologies. The proposed method can be used to update the relevant features when needed and is more stable than its competitors.},
  archive      = {J_NEUCOM},
  author       = {Carlos Puerto-Santana and Pedro Larrañaga and Concha Bielza},
  doi          = {10.1016/j.neucom.2023.126641},
  journal      = {Neurocomputing},
  pages        = {126641},
  shortjournal = {Neurocomputing},
  title        = {Feature subset selection in data-stream environments using asymmetric hidden markov models and novelty detection},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view kernel PCA for time series forecasting.
<em>NEUCOM</em>, <em>554</em>, 126639. (<a
href="https://doi.org/10.1016/j.neucom.2023.126639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a kernel principal component analysis model for multi-variate time series forecasting, where the training and prediction schemes are derived from the multi-view formulation of Restricted Kernel Machines . The training problem is simply an eigenvalue decomposition of the summation of two kernel matrices corresponding to the views of the input and output data. When a linear kernel is used for the output view, it is shown that the forecasting equation takes the form of kernel ridge regression . When that kernel is non-linear, a pre-image problem has to be solved to forecast a point in the input space. We evaluate the model on several standard time series datasets, perform ablation studies, benchmark with closely related models and discuss its results.},
  archive      = {J_NEUCOM},
  author       = {Arun Pandey and Hannes De Meulemeester and Bart De Moor and Johan A.K. Suykens},
  doi          = {10.1016/j.neucom.2023.126639},
  journal      = {Neurocomputing},
  pages        = {126639},
  shortjournal = {Neurocomputing},
  title        = {Multi-view kernel PCA for time series forecasting},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An overview on density peaks clustering. <em>NEUCOM</em>,
<em>554</em>, 126633. (<a
href="https://doi.org/10.1016/j.neucom.2023.126633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peaks clustering (DPC) algorithm is a new algorithm based on density clustering analysis , which can quickly obtain the cluster centers by drawing the decision diagram by using the calculation of local density and relative distance. Without prior knowledge and iteration, the parameters and structure are simple and easy to implement. Since it was proposed in 2014, it has attracted a large number of researchers to explore experiments and improve applications in recent years. In this paper, we first analyze the theory of DPC and its performance advantages and disadvantages. Secondly, it summarizes the improvement of DPC in recent years, analyzes the improvement effect, and shows it with experimental data. The related application research of DPC in different fields is introduced. Finally, the clustering results of DPC, LCDPC, DCHDPC and NADPC algorithms in different data sets are analyzed. Experiments show that the improved algorithm can divide the clustering more accurately, which provides new ideas for improving DPC algorithm in the future. At the same time, this paper summarizes and prospects the improvement and development of DPC.},
  archive      = {J_NEUCOM},
  author       = {Xiuxi Wei and Maosong Peng and Huajuan Huang and Yongquan Zhou},
  doi          = {10.1016/j.neucom.2023.126633},
  journal      = {Neurocomputing},
  pages        = {126633},
  shortjournal = {Neurocomputing},
  title        = {An overview on density peaks clustering},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-proximity based embedding scheme for learning vector
quantization-based classification of biochemical structured data.
<em>NEUCOM</em>, <em>554</em>, 126632. (<a
href="https://doi.org/10.1016/j.neucom.2023.126632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a data embedding technique for structured data that allows for the direct application of standard vector-based machine learning models without the need for explicit feature extraction. Our approach relies on multiple notions of data proximity , making it suitable for handling mixed data types or incorporating domain knowledge. Our method also reduces the computational costs of pairwise proximity calculations, resulting in improved efficiency and scalability. We demonstrate the effectiveness of our technique on graph and sequence datasets from the biochemical domain. In particular, we show that the method can efficiently be combined with interpretable machine learning approaches like relevance-based learning vector quantization for sophisticated classification learning .},
  archive      = {J_NEUCOM},
  author       = {Katrin Sophie Bohnsack and Julius Voigt and Marika Kaden and Florian Heinke and Thomas Villmann},
  doi          = {10.1016/j.neucom.2023.126632},
  journal      = {Neurocomputing},
  pages        = {126632},
  shortjournal = {Neurocomputing},
  title        = {Multi-proximity based embedding scheme for learning vector quantization-based classification of biochemical structured data},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of dynamic pickup and delivery problems.
<em>NEUCOM</em>, <em>554</em>, 126631. (<a
href="https://doi.org/10.1016/j.neucom.2023.126631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the ubiquitous real-world applications of logistics and supply chain management over the past two decades, dynamic pickup and delivery problems (DPDPs), as a subclass of dynamic vehicle routing problems in which objects or people must be collected and delivered in real time, have become a popular research topic in the field of combinatorial optimization. This article provides a comprehensive review of the DPDP literature from 2004 to 2023, in which their corresponding characteristics, principles, and theoretical analysis are discussed in detail. Furthermore, a taxonomy of the related solution methods for DPDPs is given, which can be segmented into four categories: exact methods, heuristics, metaheuristics, and learning-based methods. Moreover, some experimental comparisons and analysis of up-to-date real-word DPDP benchmarks from Huawei Company are included. Finally, a brief conclusion is given to summarize some potential future directions for DPDPs.},
  archive      = {J_NEUCOM},
  author       = {Junchuang Cai and Qingling Zhu and Qiuzhen Lin and Lijia Ma and Jianqiang Li and Zhong Ming},
  doi          = {10.1016/j.neucom.2023.126631},
  journal      = {Neurocomputing},
  pages        = {126631},
  shortjournal = {Neurocomputing},
  title        = {A survey of dynamic pickup and delivery problems},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nature-inspired algorithms for 0-1 knapsack problem: A
survey. <em>NEUCOM</em>, <em>554</em>, 126630. (<a
href="https://doi.org/10.1016/j.neucom.2023.126630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {0-1 knapsack problem (KP01) is one of the classic variants of knapsack problems in which the aim is to select the items with the total profit to be in the knapsack. In contrast, the constraint of the maximum capacity of the knapsack is satisfied. KP01 has many applications in real-world complex problems such as resource distribution, portfolio optimization, etc. This study reviews the basic theory and main algorithms of 0-1 knapsack, proposes many different types of nature-inspired metaheuristic algorithms, and divides existing 0-1 knapsack problems into 6 types according to the different coding methods of the algorithms, for a comprehensive overview of it. In this paper, a comprehensive survey on the recent advances in 0-1 knapsack problem is presented. Literature survey reveals some interesting challenges and future research directions.},
  archive      = {J_NEUCOM},
  author       = {Yongquan Zhou and Yan Shi and Yuanfei Wei and Qifang Luo and Zhonghua Tang},
  doi          = {10.1016/j.neucom.2023.126630},
  journal      = {Neurocomputing},
  pages        = {126630},
  shortjournal = {Neurocomputing},
  title        = {Nature-inspired algorithms for 0-1 knapsack problem: A survey},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A review of deep learning in dentistry. <em>NEUCOM</em>,
<em>554</em>, 126629. (<a
href="https://doi.org/10.1016/j.neucom.2023.126629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oral diseases have a significant impact on human health, often going unnoticed in their early stages. Deep learning, a promising field in artificial intelligence, has shown remarkable success in various domains, especially dentistry. This paper aims to provide an overview of recent research on deep learning applications in dentistry, with a focus on dental imaging. Deep learning algorithms perform well in difficult tasks such as image segmentation and recognition, enabling accurate identification of oral conditions and abnormalities. Integration of deep learning with other oral health data offers a holistic understanding of the relationship between oral and systemic health. However, there are still many challenges that need to be addressed.},
  archive      = {J_NEUCOM},
  author       = {Chenxi Huang and Jiaji Wang and Shuihua Wang and Yudong Zhang},
  doi          = {10.1016/j.neucom.2023.126629},
  journal      = {Neurocomputing},
  pages        = {126629},
  shortjournal = {Neurocomputing},
  title        = {A review of deep learning in dentistry},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MARN: Multi-level attentional reconstruction networks for
weakly supervised video temporal grounding. <em>NEUCOM</em>,
<em>554</em>, 126625. (<a
href="https://doi.org/10.1016/j.neucom.2023.126625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video temporal grounding is a challenging task in computer vision that involves localizing a video segment semantically related to a given query from a set of videos and queries. In this paper, we propose a novel weakly-supervised model called the Multi-level Attentional Reconstruction Networks (MARN), which is trained on video-sentence pairs. During the training phase, we leverage the idea of attentional reconstruction to train an attention map that can reconstruct the given query. At inference time, proposals are ranked based on attention scores to localize the most suitable segment. In contrast to previous methods, MARN effectively aligns video-level supervision and proposal scoring, thereby reducing the training-inference discrepancy. In addition, we incorporate a multi-level framework that encompasses both proposal-level and clip-level processes. The proposal-level process generates and scores variable-length time sequences, while the clip-level process generates and scores fix-length time sequences to refine the predicted scores of the proposal in both training and testing. To improve the feature representation of the video, we propose a novel representation mechanism that utilizes intra-proposal information and adopts 2D convolution to extract inter-proposal clues for learning reliable attention maps. By accurately representing these proposals, we can better align them with the textual modalities, and thus facilitate the learning of the model. Our proposed MARN is evaluated on two benchmark datasets, and extensive experiments demonstrate its superiority over existing methods.},
  archive      = {J_NEUCOM},
  author       = {Yijun Song and Jingwen Wang and Lin Ma and Jun Yu and Jinxiu Liang and Liu Yuan and Zhou Yu},
  doi          = {10.1016/j.neucom.2023.126625},
  journal      = {Neurocomputing},
  pages        = {126625},
  shortjournal = {Neurocomputing},
  title        = {MARN: Multi-level attentional reconstruction networks for weakly supervised video temporal grounding},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph convolution with topology refinement for automatic
reinforcement learning. <em>NEUCOM</em>, <em>554</em>, 126621. (<a
href="https://doi.org/10.1016/j.neucom.2023.126621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning faces the challenge of sparse rewards. Existing research utilizes reward shaping based on graph convolutional neural networks (GCNs) to address this challenge. However, the automatic construction of optimal graph has been a long standing issue. Here we propose Graph Convolution with Topology Refinement for Automatic Reinforcement Learning (GTR), based on the construction of new latent graph to replace the original input graph for more effective reward shaping. It is found from this work that, the most suitable state node can be extracted through the graph entropy. Subsequently we map the original graph to subset of nodes adaptively to form a new and more compact latent graph. Since GTR utilizes trainable projection vectors for projecting all node features into one-dimensional representation, the inter-connections between the nodes of the newly constructed latent graph are consistent with the original ones. The proposed GTR stems from mathematical grounds, and preliminary experiments have shown that the proposed GTR has considerable improvement on Atari benchmark and Mujoco benchmark. Further experiment and ablation analysis have given further supports to this work.},
  archive      = {J_NEUCOM},
  author       = {Jianghui Sang and Yongli Wang},
  doi          = {10.1016/j.neucom.2023.126621},
  journal      = {Neurocomputing},
  pages        = {126621},
  shortjournal = {Neurocomputing},
  title        = {Graph convolution with topology refinement for automatic reinforcement learning},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CaPTURe: Cartoon pose transfer using reverse attention.
<em>NEUCOM</em>, <em>554</em>, 126619. (<a
href="https://doi.org/10.1016/j.neucom.2023.126619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the previous pose transfer methods require additional input data such as joint keypoints of the target pose extracted by a pre-trained network in a human domain. However, in the fields where cartoon characters are used, such as animation or webtoons, the body proportions and structures of the characters often deviate from those of real-life humans. Therefore, it is not appropriate to utilize a pre-trained network designed for the human domain to extract additional data from these cartoon characters. Even if the network is newly trained in the cartoon domain, expensive data labeling is necessary. As a result, most of the previous pose transfer methods are not suitable for application in the cartoon domain. To address these issues, we propose a cartoon pose transfer network named CaPTURe that can successfully perform pose transfer in the cartoon domain with only target images and no other input data. Here, we incorporate the attention mechanism to accurately generate the desired identity. Additionally, we employ reverse attention to enhance the precision of generating the target pose. This approach eliminates the influence of identity information in the pose feature, enabling our network to focus solely on utilizing pose information. Consequently, through comparative experiments using a cartoon domain dataset, CaPTURe shows significant improvements in quantitative results over the previous state-of-the-art methods. Specifically, it achieves a 4.7\% reduction in L1 Distance, a 0.1\% improvement in SSIM, and a 0.8\% enhancement in LPIPS. Moreover, CaPTURe exhibits superior qualitative performance than the previous state-of-the-art methods. In addition, we demonstrate that CaPTURe is capable of achieving effective pose transfer not just in the cartoon domains, but also in the human domains, as evidenced by our experiments on a human domain dataset.},
  archive      = {J_NEUCOM},
  author       = {Chang-Hyeon An and Hyun-Chul Choi},
  doi          = {10.1016/j.neucom.2023.126619},
  journal      = {Neurocomputing},
  pages        = {126619},
  shortjournal = {Neurocomputing},
  title        = {CaPTURe: Cartoon pose transfer using reverse attention},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-attention-based long temporal sequence modeling method
for temporal action detection. <em>NEUCOM</em>, <em>554</em>, 126617.
(<a href="https://doi.org/10.1016/j.neucom.2023.126617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Action Detection (TAD) is a basic and complex task in video understanding. It aims at detecting both the localization and category of actions in a video. The anchor-free TAD methods directly predict the action classes at each location and regress the distances to the boundaries. However, current anchor-free models based on convolutional neural network encode spatiotemporal sequences by 3D convolution networks. Due to the limited receptive field and the basic prior of the translation invariance, effective long temporal sequence modeling cannot be achieved. As a result, these methods cannot effectively detect temporal boundaries. To solve this problem, we design a novel end-to-end self-attention temporal enhancement TAD model, which introduces the Temporal Enhancement module to enhance the temporal feature encoding of the videos and expand the receptive field. Extensive experiments demonstrate that the self-attention Temporal Enhancement model yields an effective improvement on previous work, which improves the performance on THUMOS14 by 1.2\%, reaching 53.2\% on average mAP. Meanwhile, a competitive result of 34.7\% average mAP is achieved on ActivityNet-1.3.},
  archive      = {J_NEUCOM},
  author       = {Jing Huang and Peng Zhao and Guiqin Wang and Shusen Yang and Jie Lin},
  doi          = {10.1016/j.neucom.2023.126617},
  journal      = {Neurocomputing},
  pages        = {126617},
  shortjournal = {Neurocomputing},
  title        = {Self-attention-based long temporal sequence modeling method for temporal action detection},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive dynamic programming for data-based optimal state
regulation with experience replay. <em>NEUCOM</em>, <em>554</em>,
126616. (<a href="https://doi.org/10.1016/j.neucom.2023.126616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional model-based control methods require accurate system dynamics. However, the dynamics are usually unknown and it is challenging to tune the control parameters manually when controlling a complex nonlinear system . In this paper, we propose a novel reinforcement learning method that combines the advantages of a model-based method, namely Adaptive Dynamic Programming (ADP), with the actor-critic method. Specifically, a linear approximate model is chosen to obtain the estimated dynamics as part of the optimal policy. Then, a designed actor-critic structure is used to obtain the sub–policy. We provide the theoretical proof of convergence and validate the proposed method through simulation experiments. The experimental results demonstrate the effectiveness of the proposed method with smaller tracking errors and faster learning speed compared with the controller trained by the actor-critic method.},
  archive      = {J_NEUCOM},
  author       = {Chen An and Jiaxi Zhou},
  doi          = {10.1016/j.neucom.2023.126616},
  journal      = {Neurocomputing},
  pages        = {126616},
  shortjournal = {Neurocomputing},
  title        = {Adaptive dynamic programming for data-based optimal state regulation with experience replay},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disentangling private classes through regularization.
<em>NEUCOM</em>, <em>554</em>, 126612. (<a
href="https://doi.org/10.1016/j.neucom.2023.126612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are nowadays broadly deployed to solve an incredibly large variety of tasks. However, little attention has been devoted to connected legal aspects. In 2016, the European Union approved the General Data Protection Regulation which entered into force in 2018. Its main rationale was to protect the privacy and data protection of its citizens by the way of operating the so-called “Data Economy”. As data is the fuel of modern Artificial Intelligence , it is argued that the GDPR can be partly applicable to a series of algorithmic decision-making tasks before a more structured AI Regulation enters into force. In the meantime, AI should not allow undesired information leakage deviating from the purpose for which is created. In this work, we propose DisP, an approach for deep learning models disentangling the information related to some classes we desire to keep private, from the data processed by AI. In particular, DisP is a regularization strategy de-correlating the features belonging to the same private class at training time, hiding the information about private class membership. Our experiments on state-of-the-art deep learning models show the effectiveness of DisP, minimizing the risk of extraction for the classes we desire to keep private.},
  archive      = {J_NEUCOM},
  author       = {Enzo Tartaglione and Francesca Gennari and Victor Quétu and Marco Grangetto},
  doi          = {10.1016/j.neucom.2023.126612},
  journal      = {Neurocomputing},
  pages        = {126612},
  shortjournal = {Neurocomputing},
  title        = {Disentangling private classes through regularization},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). JS-SpoofNet: A jointly supervised parallel branched neural
network for spoof detection. <em>NEUCOM</em>, <em>554</em>, 126610. (<a
href="https://doi.org/10.1016/j.neucom.2023.126610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spoof detection in complex real-world conditions has always been challenging for the face anti-spoofing research community. Most existing datasets need more practical variations for spoof detection in the wild and thus generate the need for a more complex dataset encompassing the required diversities. The single-image-based anti-spoofing solutions for face recognition systems sometimes suffer from inconclusiveness in scenarios with cluttered backgrounds or variable illumination. To address these issues, we first collected a diverse spoof detection dataset, CSDiNE, with a wide range of illumination intensities and background variations. Secondly, we proposed a jointly supervised parallel branched neural network , JS-SpoofNet, that utilizes temporal cues derived from a video sequence for robust spoof detection. JS-SpoofNet consists of a parallel branched architecture with a spoof classification network aided by an auxiliary network that utilizes intermediate features from the main branch for depth estimation. We conducted an elaborate ablation study and performed an extensive performance evaluation of our proposed method. On the in-house CSDiNE dataset, the proposed spoof detector attained a minimum average classification error rate (ACER) of 0.94\%. Furthermore, the designed neural network outperformed existing video-based state-of-the-art spoof detection methods on popular diverse benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Shyam Sunder Prasad and Naval Kishore Mehta and Abeer Banerjee and Sumeet Saurav and Sanjay Singh},
  doi          = {10.1016/j.neucom.2023.126610},
  journal      = {Neurocomputing},
  pages        = {126610},
  shortjournal = {Neurocomputing},
  title        = {JS-SpoofNet: A jointly supervised parallel branched neural network for spoof detection},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CIGNet: Category-and-intrinsic-geometry guided network for
3D coarse-to-fine reconstruction. <em>NEUCOM</em>, <em>554</em>, 126607.
(<a href="https://doi.org/10.1016/j.neucom.2023.126607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object reconstruction from arbitrary view intensity images is a challenging but meaningful research topic in computer vision. The main limitations of existing approaches are that they lack complete and efficient prior information and might not be able to deal with serious occlusion or partial observation of 3D objects, which may produce incomplete and unreliable reconstructions. To reconstruct structure and recover missing or unseen parts of objects, category prior and intrinsic geometry relation are particularly useful and necessary during the 3D reconstruction process. In this paper, we propose Category-and-Intrinsic-Geometry Guided Network (CIGNet) for 3D coarse-to-fine reconstruction from arbitrary view intensity images by leveraging category prior and intrinsic geometry relation. CIGNet combines a category prior guided reconstruction module with an intrinsic geometry relation guided refinement module. In the first reconstruction module, we leverage semantic class context by adding a supervision term over object categories to output coarse reconstructed results. In the second refinement module, we model the coarse 3D volumetric data as 2D slices and consider intrinsic geometry relations between them to design graph structures of coarse 3D volumes to finish the graph-based refinement. CIGNet can accomplish high-quality 3D reconstruction tasks by exploring the intra-category characteristics of objects as well as the intrinsic geometry relations of each object, both of which serve as useful complements to the visual information of images, in a coarse-to-fine fashion. Extensive quantitative and qualitative experiments on a synthetic dataset ShapeNet and real-world datasets Pix3D , Statue Model Repository , and BlendedMVS indicate that CIGNet outperforms several state-of-the-art methods in terms of accuracy and detail recovery.},
  archive      = {J_NEUCOM},
  author       = {Junna Gao and Dehui Kong and Shaofan Wang and Jinghua Li and Baocai Yin},
  doi          = {10.1016/j.neucom.2023.126607},
  journal      = {Neurocomputing},
  pages        = {126607},
  shortjournal = {Neurocomputing},
  title        = {CIGNet: Category-and-intrinsic-geometry guided network for 3D coarse-to-fine reconstruction},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MCI-HyperNet: A multiple contextual information-based
adaptive weight learning network for controllable image reconstruction.
<em>NEUCOM</em>, <em>554</em>, 126606. (<a
href="https://doi.org/10.1016/j.neucom.2023.126606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary deep learning methods for image reconstruction have shown promising results over classical methods. However, they are not robust to image alterations due to deviations in the imaging conditions at test time. The training process does not account for explicit variations in the contextual information about the imaging task, such as image control parameters and input settings that could hold a causal relationship to the visual content of the reconstructed image. In this work, we propose dynamic weight prediction (DWP) networks to learn the contextual settings and the relationships between them. This model-based meta-learning approach would offer two valuable capabilities in a single network - (i) scalability to multiple input settings and (ii) tunability to continuously varying control settings with the knowledge of a few settings. The proposed network, MCI-HyperNet, is a controllable image reconstruction network with DWP sub-networks conditioned on multiple contextual settings. The proposed approach strikes a balance between reliable context-adaptive weight learning and context-agnostic weight learning to obtain robust image reconstructions. We have extensively experimented with our network for accelerated MRI reconstruction considering the essential research directions provided in the fastMRI challenge results. The proposed method exhibits (i) superior reconstruction quality with improvement margins of ∼ ∼ 0.5 dB in PSNR and ∼ ∼ 0.01 in SSIM over adaptive reconstruction methods for cardiac MRI and multiple brain MRI contrasts, (ii) better scalability to multiple anatomies, contrasts, and under-sampling mask patterns with accuracy improvement margins of ∼ ∼ 0.2 dB in PSNR and ∼ ∼ 0.005 in SSIM over joint training and context-specific models for knee MRI, and (iii) generality to 40 arbitrary acceleration factors over joint training when trained on just five acceleration factors. Our model can learn multiple contrast sequences through continual learning without catastrophically forgetting old MRI sequences. Furthermore, our method is benchmarked for reconstruction quality against other MRI reconstruction architectures trained for a specific contextual setting. Besides, an interpretability analysis using a relational knowledge distillation measure shows that our model exhibits superior context-specific and relational knowledge across contexts over jointly trained models. Our source code is publicly available at https://github.com/sriprabhar/MCI-HyperNet .},
  archive      = {J_NEUCOM},
  author       = {Sriprabha Ramanarayanan and Balamurali Murugesan and Arun Palla and Keerthi Ram and Ramesh Venkatesan and Mohanasankar Sivaprakasam},
  doi          = {10.1016/j.neucom.2023.126606},
  journal      = {Neurocomputing},
  pages        = {126606},
  shortjournal = {Neurocomputing},
  title        = {MCI-HyperNet: A multiple contextual information-based adaptive weight learning network for controllable image reconstruction},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid knowledge distillation from intermediate layers for
efficient single image super-resolution. <em>NEUCOM</em>, <em>554</em>,
126592. (<a href="https://doi.org/10.1016/j.neucom.2023.126592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional and Transformer models have achieved remarkable results for Single Image Super-Resolution (SISR). However, the tremendous memory and computation consumption of these models restricts their usage in resource-limited scenarios. Knowledge distillation , as an effective model compression technique, has received great research focus on the SISR task. In this paper, we propose a novel efficient SISR method via hybrid knowledge distillation from intermediate layers, termed HKDSR, which leverages the knowledge from frequency information into that RGB information. To accomplish this, we first pre-train the teacher with multiple intermediate upsampling layers to generate the intermediate SR outputs. We then construct two kinds of intermediate knowledge from the Frequency Similarity Matrix (FSM) and Adaptive Channel Fusion (ACF). FSM aims to mine the relationship of frequency similarity between the Ground-truth (GT) HR image, and the intermediate SR outputs of teacher and student by Discrete Wavelet Transformation . ACF merges the intermediate SR output of the teacher and GT HR image in a channel dimension to adaptively align the intermediate SR output of the student. Finally, we leverage the knowledge from FSM and ACF into reconstruction loss to effectively improve student performance. Extensive experiments demonstrate the effectiveness of HKDSR on different benchmark datasets and network architectures .},
  archive      = {J_NEUCOM},
  author       = {Jiao Xie and Linrui Gong and Shitong Shao and Shaohui Lin and Linkai Luo},
  doi          = {10.1016/j.neucom.2023.126592},
  journal      = {Neurocomputing},
  pages        = {126592},
  shortjournal = {Neurocomputing},
  title        = {Hybrid knowledge distillation from intermediate layers for efficient single image super-resolution},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SLR: A million-scale comprehensive crossword dataset for
simultaneous learning and reasoning. <em>NEUCOM</em>, <em>554</em>,
126591. (<a href="https://doi.org/10.1016/j.neucom.2023.126591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The progress of the natural language understanding (NLU) community has put forward higher demands for the knowledge reserve and reasoning ability of the model. However, existing schemes for improving model capabilities often split them into two separate tasks. The task of enabling models to learn and reason about knowledge simultaneously has not received sufficient attention. In this paper, we propose a novel crossword-based NLU task that imparts knowledge information to a model by solving crossword clues and simultaneously trains the model to infer new knowledge from existing knowledge. To this end, we construct a comprehensive crossword dataset SLR containing more than 4 million unique clue-answer pairs. Compared to existing crossword datasets, SLR is more comprehensive and contains linguistic knowledge, expertise in various fields, and commonsense knowledge . Meanwhile, to evaluate the reasoning ability of the model, we design clever details in the reasoning of the answers, most clues require the solver to reason through two or more pieces of knowledge to arrive at an answer. We analyze the composition of the dataset and the similarities and differences of the various types of clues via sampling and consider various data partitioning methods to enhance the generalization ability of the training set. Furthermore, we test the performance of several different advanced models and methods on this dataset and analyze the strengths and weaknesses of each. An interesting conclusion is that even powerful language models perform poorly on tasks that require reasoning.},
  archive      = {J_NEUCOM},
  author       = {Chao Wang and Tinghui Zhu and Zhixu Li and Jingping Liu},
  doi          = {10.1016/j.neucom.2023.126591},
  journal      = {Neurocomputing},
  pages        = {126591},
  shortjournal = {Neurocomputing},
  title        = {SLR: A million-scale comprehensive crossword dataset for simultaneous learning and reasoning},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global priors guided modulation network for joint
super-resolution and SDRTV-to-HDRTV. <em>NEUCOM</em>, <em>554</em>,
126590. (<a href="https://doi.org/10.1016/j.neucom.2023.126590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watching low resolution standard dynamic range (LR SDR) video on a 4K high dynamic range (HDR) TV is not the best viewing experience. Joint super-resolution (SR) and SDRTV-to-HDRTV aims to enhance the visual quality of LR SDR videos that have quality deficiencies in resolution and dynamic range. Previous methods that rely on learning local information typically cannot do well in preserving color conformity and long-range structural similarity, resulting in unnatural color transition and texture artifacts. In order to tackle these challenges, we propose a global priors guided modulation network (GPGMNet). In particular, we design a global priors extraction module (GPEM) to extract color conformity prior and structural similarity prior that are beneficial for SDRTV-to-HDRTV and SR tasks, respectively. To further exploit the global priors and preserve spatial information, we devise multiple global priors-guided spatial-wise modulation blocks (GSMBs) with a few parameters for intermediate feature modulation. In these GSMBs, the modulation parameters are generated by the shared global priors and the spatial features map from the spatial pyramid convolution block (SPCB). With these elaborate designs, the GPGMNet can achieve higher visual quality with lower computational complexity . Extensive experiments demonstrate that our proposed GPGMNet is superior to the state-of-the-art methods. Specifically, our proposed model exceeds the state-of-the-art by 0.64 dB in PSNR, with 69\% fewer parameters and 3.1 × × speedup.},
  archive      = {J_NEUCOM},
  author       = {Gang He and Shaoyi Long and Li Xu and Chang Wu and Wenxin Yu and Jinjia Zhou},
  doi          = {10.1016/j.neucom.2023.126590},
  journal      = {Neurocomputing},
  pages        = {126590},
  shortjournal = {Neurocomputing},
  title        = {Global priors guided modulation network for joint super-resolution and SDRTV-to-HDRTV},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered adaptive neural networks tracking control
for incommensurate fractional-order nonlinear systems with external
disturbance. <em>NEUCOM</em>, <em>554</em>, 126586. (<a
href="https://doi.org/10.1016/j.neucom.2023.126586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The event-triggered adaptive neural networks (NNs) tracking control issue is considered in this paper for a type of incommensurate fractional-order systems (IFOSs) with disturbance. Unlike the existing works for IFOSs, the hypothesis of disturbance-like function and the frequency distributed model are avoided in this study by utilizing the continuity of fractional-order derivative (FOD). Then, based on the radial basis function (RBF) NNs and backstepping method, the adaptive control scheme is proposed to ensure that the reference signal can be tracked by the system output, where the derivative order of adaptive laws does not depend on the one of IFOS. Additionally, to further reduce the burden of communication network, an exponentially convergent term is introduced into traditional dynamic event-triggered mechanism (ETM) and the Zeno behavior is avoided. Finally, two illustrative examples are exhibited to verify the performance of designed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Boqiang Cao and Xiaobing Nie and Jinde Cao},
  doi          = {10.1016/j.neucom.2023.126586},
  journal      = {Neurocomputing},
  pages        = {126586},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered adaptive neural networks tracking control for incommensurate fractional-order nonlinear systems with external disturbance},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ydata-profiling: Accelerating data-centric AI with
high-quality data. <em>NEUCOM</em>, <em>554</em>, 126585. (<a
href="https://doi.org/10.1016/j.neucom.2023.126585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ydata-profiling is an open-source Python package for advanced exploratory data analysis that enables users to generate data profiling reports in a simple, fast, and efficient manner, fostering a standardized and visual understanding of the data. Beyond traditional descriptive properties and statistics, ydata-profiling follows a Data-Centric AI approach to exploratory analysis, as it focuses on the automatic detection and highlighting of complex data characteristics often associated with potential data quality issues, such as high ratios of missing or imbalanced data, infinite, unique, or constant values, skewness, high correlation, high cardinality, non-stationarity, seasonality, duplicate records, and other inconsistencies. The source code, documentation, and examples are available in the GitHub repository: https://github.com/ydataai/ydata-profiling .},
  archive      = {J_NEUCOM},
  author       = {Fabiana Clemente and Gonçalo Martins Ribeiro and Alexandre Quemy and Miriam Seoane Santos and Ricardo Cardoso Pereira and Alex Barros},
  doi          = {10.1016/j.neucom.2023.126585},
  journal      = {Neurocomputing},
  pages        = {126585},
  shortjournal = {Neurocomputing},
  title        = {Ydata-profiling: Accelerating data-centric AI with high-quality data},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scale-aware frequency attention network for
super-resolution. <em>NEUCOM</em>, <em>554</em>, 126584. (<a
href="https://doi.org/10.1016/j.neucom.2023.126584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scale-arbitrary super-resolution (SASR) has recently gained widespread attention in the community, which aims to super-resolve an image to arbitrary desired resolutions. Existing SASR methods always use a fixed convolution neural network (CNN) as the backbone to share the same image features for different resolutions, leading to limited reconstruction performance due to the lack of distinctive feature extraction for individual resolutions. Meanwhile, these CNN-based methods always tend to overfit low-frequency components while losing high-frequency ones. This frequency gap leads to blurred structures in the reconstructed image. To address these issues, we propose a S cale A ware F requency A ttention network (SAFANet), which consists of Scale-Aware Frequency Attention (SAFA) modules and a Scale-Guided Continuous Reconstruction (SGCR) module. Additionally, frequency-domain attention learning is introduced to optimize the scale-adapted features to explicitly focus on high-frequency components, thereby overcoming the frequency restoration gap. Finally, the SGCR module combines the input scale as guidance with the optimized features to reconstruct images with arbitrary resolutions by using an implicit reconstruction function, thus adaptively achieving continuous image restoration. Our proposed SAFANet can be easily incorporated into existing CNN-based SR networks to achieve interactive SR at arbitrary scales. Extensive experiments demonstrate that SAFANet achieves superior performance, which is competitive with or even better than the state-of-the-art methods across a vast scale range ( × 1 ∼ × 30 ×1∼×30 ) via a single model.},
  archive      = {J_NEUCOM},
  author       = {Wei Yu and Zonglin Li and Qinglin Liu and Feng Jiang and Changyong Guo and Shengping Zhang},
  doi          = {10.1016/j.neucom.2023.126584},
  journal      = {Neurocomputing},
  pages        = {126584},
  shortjournal = {Neurocomputing},
  title        = {Scale-aware frequency attention network for super-resolution},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Learning relationship-preserving representation for
multi-task adversarial attacks. <em>NEUCOM</em>, <em>554</em>, 126580.
(<a href="https://doi.org/10.1016/j.neucom.2023.126580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are susceptible to adversarial samples that are carefully crafted to mislead the DNNs with imperceptible perturbations. To test the robustness of DNNs, attack methods based on adversarial samples have gained popularity due to their practicality and effectiveness in achieving encouraging attack results. However, most of these methods do not consider the more realistic multi-task attacks. The main challenge of multi-task attacks is that different tasks have different objective functions, making it difficult to find an optimal optimization goal to generate adversarial samples. To address this issue, we propose a new multi-task adversarial attack paradigm called Multi-Task Adversarial Attacks (MTAA) that uses a relationship-preserving representation to learn adversarial patterns. Unlike previous methods, our attack method does not rely on a task-specific loss function or an attack agent model. Instead, we design a relationship-preserving module that projects samples into a low-dimensional embedding space while preserving their intrinsic geometric structure for adversarial pattern reasoning. This module effectively removes redundant information from high-dimensional features, providing an effective latent space for adversarial pattern reasoning. To learn adversarial representation in the latent space, we introduce a novel adversarial mechanism. Our attack method can deceive different networks on multiple tasks since it is independent of task-specific loss functions and the attack agent. Extensive experimental results show that our attack approach outperforms state-of-the-art universal and transferable attack strategies on multi-task attacks. The codes for MTAA are available at https://github.com/antachen/MTAA .},
  archive      = {J_NEUCOM},
  author       = {Yong Chen and Xu Wang and Peng Hu and Zhong Yuan and Dezhong Peng and Qilin Li},
  doi          = {10.1016/j.neucom.2023.126580},
  journal      = {Neurocomputing},
  pages        = {126580},
  shortjournal = {Neurocomputing},
  title        = {Learning relationship-preserving representation for multi-task adversarial attacks},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unity is strength: Improving the detection of adversarial
examples with ensemble approaches. <em>NEUCOM</em>, <em>554</em>,
126576. (<a href="https://doi.org/10.1016/j.neucom.2023.126576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge in computer vision and deep learning is the definition of robust strategies for the detection of adversarial examples. In this work, we propose the adoption of ensemble approaches to leverage the effectiveness of multiple detectors in exploiting distinct properties of the input data. To this end, the ENsemble Adversarial Detector ( ENAD ) framework integrates scoring functions from state-of-the-art detectors based on Mahalanobis distance, Local Intrinsic Dimensionality, and One-Class Support Vector Machines, which process the hidden features of deep neural networks. ENAD is designed to ensure high standardization and reproducibility to the computational workflow. Extensive tests on benchmark datasets, models and adversarial attacks show that ENAD outperforms all competing methods in the large majority of settings. The improvement over the state-of-the-art and the intrinsic generality of the framework, which allows one to easily extend ENAD to include any set of detectors and integration strategies, set the foundations for the new area of ensemble adversarial detection.},
  archive      = {J_NEUCOM},
  author       = {Francesco Craighero and Fabrizio Angaroni and Fabio Stella and Chiara Damiani and Marco Antoniotti and Alex Graudenzi},
  doi          = {10.1016/j.neucom.2023.126576},
  journal      = {Neurocomputing},
  pages        = {126576},
  shortjournal = {Neurocomputing},
  title        = {Unity is strength: Improving the detection of adversarial examples with ensemble approaches},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLSpell: Contrastive learning with phonological and visual
knowledge for chinese spelling check. <em>NEUCOM</em>, <em>554</em>,
126468. (<a href="https://doi.org/10.1016/j.neucom.2023.126468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of Chinese Spelling Check (CSC) is to identify and correct spelling errors in text, which are mainly caused by phonologically and visually similar characters. Although pre-trained language models are helpful for this task, they lack phonological and visual information. Previous works have primarily focused on identifying errors based on local contextual data, while neglecting the importance of sentence-level information. To address the above issues, C ontrastive L earning S pell (CLSpell) is proposed, which combines phonetic and glyphic information through contrastive learning and simultaneously acquires local and global information through multi-task joint learning. During pretraining, token representations are learned using a combination of phonological, visual, and semantic information. Moreover, we propose to include an auxiliary task of correct sentence discrimination in the multi-task joint training process to capture sentence-level information. Experiments on widely used benchmarks demonstrate that the proposed method surpasses all competing methods.},
  archive      = {J_NEUCOM},
  author       = {Xingliang Mao and Youran Shan and Fangfang Li and Xiaohong Chen and Shichao Zhang},
  doi          = {10.1016/j.neucom.2023.126468},
  journal      = {Neurocomputing},
  pages        = {126468},
  shortjournal = {Neurocomputing},
  title        = {CLSpell: Contrastive learning with phonological and visual knowledge for chinese spelling check},
  volume       = {554},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble anomaly score for video anomaly detection using
denoise diffusion model and motion filters. <em>NEUCOM</em>,
<em>553</em>, 126589. (<a
href="https://doi.org/10.1016/j.neucom.2023.126589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection is a crucial task that aims to differentiate between normal and abnormal events. The current mainstream approach involves constructing an anomaly score based on the reconstruction error from a prediction model trained on normal frame sequences. However, this approach is limited by its deterministic nature, which may cause the anomaly score to be sensitive to underlying noise in the video. To address this limitation, this paper proposes an ensemble anomaly score constructed using a series of stochastic reconstructions of the original prediction. Specifically, we introduce the denoise diffusion model as a perturbation-denoise tool. First, the original prediction undergoes a perturbation process through a diffusion process . Then, a denoise diffusion model trained on normal predictions is used to directly reconstruct a series of noise-free predictions from the perturbed versions with different noise levels. Finally, an ensemble of all the reconstruction errors is used to provide a more generic and regularized anomaly score. Furthermore, we introduce motion filters into the detection pipeline to improve the modeling accuracy of the image distribution. The proposed method is evaluated on public datasets, and experimental results demonstrate its effectiveness, particularly in detecting performance under out-of-distribution (OOD) conditions.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Wang and Xiaojing Gu and Jingyu Hu and Xingsheng Gu},
  doi          = {10.1016/j.neucom.2023.126589},
  journal      = {Neurocomputing},
  pages        = {126589},
  shortjournal = {Neurocomputing},
  title        = {Ensemble anomaly score for video anomaly detection using denoise diffusion model and motion filters},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MWCapsNet: A novel multi-level wavelet capsule network for
insider threat detection using image representations. <em>NEUCOM</em>,
<em>553</em>, 126588. (<a
href="https://doi.org/10.1016/j.neucom.2023.126588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of insider threats is a significant challenge for many organizations due to the complexities of the data, the potential for changes in user behavior , and limited ground truth. Current techniques for detecting insider threats, including balancing datasets, anomaly detection , and image classification , have challenges such as lower precision and a high False Positive Rate (FPR). This is due to complex and heterogeneous data and the disregard of the spatial arrangement and relationships between features in image classification techniques that are essential to understanding the detailed behavior pattern of a user. To address these issues, a novel image-based insider threat detection framework is proposed, which integrates Multi-level Wavelet decomposition into a Capsule Network (MWCapsNet). The image generator for tabular data (IGTD) framework is used to generate image representations by identifying the correlation between the features which depict user behavior. The multi-level wavelet decomposition helps extract spectral and spatial features, whereas the capsule network captures contextual relationships between features from the generated image representations. Thus, improving the accuracy and precision of the MWCapsNet model with much lower false alarms. The proposed MWCapsNet model outperforms existing state-of-the-art techniques, achieving 98.88\% accuracy and 99.21\% precision with a lower rate of false positives when evaluated using the CERT insider threat datasets.},
  archive      = {J_NEUCOM},
  author       = {Krunal Dhanraj Randive and Mohan Ramasundaram},
  doi          = {10.1016/j.neucom.2023.126588},
  journal      = {Neurocomputing},
  pages        = {126588},
  shortjournal = {Neurocomputing},
  title        = {MWCapsNet: A novel multi-level wavelet capsule network for insider threat detection using image representations},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Multi-modality 3D object detection in autonomous driving: A
review. <em>NEUCOM</em>, <em>553</em>, 126587. (<a
href="https://doi.org/10.1016/j.neucom.2023.126587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving perception has made significant strides in recent years, but accurately sensing the environment using a single sensor remains a daunting task. This review offers a comprehensive overview of the current research on LiDAR and camera fusion for 3D object detection in multi-modality domains. The review first identifies the perception task, open public detection dataset, and data representation related to 3D object detection . It then presents an in-depth survey of coarse-grained and fine-grained fusion approaches, reporting their respective performances on the KITTI and nuScenes datasets. The review identifies general trends in multi-modality 3D object detection and provides insights and promising research directions based on these observations. Additionally, the review summarizes the current challenges of fusion strategies for perception problems in autonomous driving. Based on a critical review of existing literature, this paper identifies and discusses key research directions in the field of fusion-based 3D object detection approach for perception problems in autonomous driving, which is instructive for future work.},
  archive      = {J_NEUCOM},
  author       = {Yingjuan Tang and Hongwen He and Yong Wang and Zan Mao and Haoyu Wang},
  doi          = {10.1016/j.neucom.2023.126587},
  journal      = {Neurocomputing},
  pages        = {126587},
  shortjournal = {Neurocomputing},
  title        = {Multi-modality 3D object detection in autonomous driving: A review},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reward poisoning attacks in deep reinforcement learning
based on exploration strategies. <em>NEUCOM</em>, <em>553</em>, 126578.
(<a href="https://doi.org/10.1016/j.neucom.2023.126578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep reinforcement learning (DRL) has been widely applied in various fields, and its vulnerability to adversarial samples, which is inherited from deep learning , has also received considerable attention for training robust DRL agents. However, most of existing attack approaches aim to perturb the observations of DRL agents, and poisoning attacks against DRL through perturbing the reward from the environment have been studied less. In this paper, we propose a novel reward poisoning adversarial attack method that employs the exploration strategy of reinforcement learning to help effectively attack a target. The adversary first builds a deep neural network to attain the exploration value of each state–action pair, i.e., the E E -value, which is utilized to determine the appropriate time to attack the target and the sign of adversarial perturbation to generate adversary samples to the reward. The experimental results demonstrate that the reward poisoning attack algorithm based on E-values proposed in this paper enables an adversary to improve the efficiency of attacks with fewer adversarial samples.},
  archive      = {J_NEUCOM},
  author       = {Kanting Cai and Xiangbin Zhu and Zhaolong Hu},
  doi          = {10.1016/j.neucom.2023.126578},
  journal      = {Neurocomputing},
  pages        = {126578},
  shortjournal = {Neurocomputing},
  title        = {Reward poisoning attacks in deep reinforcement learning based on exploration strategies},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Abnormal event detection for video surveillance using an
enhanced two-stream fusion method. <em>NEUCOM</em>, <em>553</em>,
126561. (<a href="https://doi.org/10.1016/j.neucom.2023.126561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal event detection is a critical component of intelligent surveillance systems, focusing on identifying abnormal objects or unusual human behaviours in video sequences. However, conventional methods struggle due to the scarcity of labelled data. Existing solutions typically train on normal data, establish boundaries for regular events, and identify outliers during testing. These approaches are often inadequate as they do not efficiently leverage the geometry and image texture information, and they lack a specific focus on different types of abnormal events. This paper introduces a novel two-stream fusion algorithm for abnormal event detection to address these diverse abnormal events better. We first extract the object, pose, and optical flow features. Then, the object and pose information is combined early on to eliminate occluded pose graphs. The trusted pose graphs are fed into a Spatio-Temporal Graph Convolutional Network (ST-GCN) to detect abnormal behaviours. Simultaneously, we propose a video prediction framework that identifies abnormal frames by measuring the difference between predicted and ground truth frames. Lastly, we execute a decision-level fusion between the classification and prediction streams to achieve the final results. Our results on the UCSD PED1 dataset indicate the enhanced performance of the fusion model for various abnormal events. Furthermore, experimental results on the UCSD PED2 dataset and the ShanghaiTech campus dataset underscore our approach’s effectiveness compared to other related works.},
  archive      = {J_NEUCOM},
  author       = {Yuxing Yang and Zeyu Fu and Syed Mohsen Naqvi},
  doi          = {10.1016/j.neucom.2023.126561},
  journal      = {Neurocomputing},
  pages        = {126561},
  shortjournal = {Neurocomputing},
  title        = {Abnormal event detection for video surveillance using an enhanced two-stream fusion method},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aggregating transformers and CNNs for salient object
detection in optical remote sensing images. <em>NEUCOM</em>,
<em>553</em>, 126560. (<a
href="https://doi.org/10.1016/j.neucom.2023.126560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) in optical remote sensing images (RSIs) plays a significant role in many areas such as agriculture, environmental protection, and the military. However, since the difference in imaging mode and image complexity between RSIs and natural scene images (NSIs), it is difficult to achieve remarkable results by directly extending the saliency method targeting NSIs to RSIs. Besides, we note that the convolutional neural networks (CNNs) based U-Net cannot effectively acquire the global long-range dependency, and the Transformer doesn’t adequately characterize the spatial local details of each patch. Therefore, to conduct salient object detection in RSIs, we propose a novel two-branch architecture based network for Aggregating the Transformers and CNNs, namely ATC-Net, where the local spatial details and the global semantic information are fused into the final high-quality saliency map. Specifically, our saliency model adopts an encoder-decoder architecture including two parallel encoder branches and a decoder. Firstly, the two parallel encoder branches extract global and local features by using Transformer and CNNs, respectively. Then, the decoder employs a series of feature-enhanced fusion (FF) modules to aggregate multi-level global and local features by interactive guidance and enhance the fused feature via attention mechanism . Finally, the decoder deploys the read out (RO) module to fuse the aggregated feature of FF module and the low-level CNN feature, steering the feature to focus more on spatial local details. Extensive experiments are performed on two public optical RSIs datasets, and the results show that our saliency model consistently outperforms 30 state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Liuxin Bao and Xiaofei Zhou and Bolun Zheng and Haibing Yin and Zunjie Zhu and Jiyong Zhang and Chenggang Yan},
  doi          = {10.1016/j.neucom.2023.126560},
  journal      = {Neurocomputing},
  pages        = {126560},
  shortjournal = {Neurocomputing},
  title        = {Aggregating transformers and CNNs for salient object detection in optical remote sensing images},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial-temporal knowledge graph network for event
prediction. <em>NEUCOM</em>, <em>553</em>, 126557. (<a
href="https://doi.org/10.1016/j.neucom.2023.126557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting multiple concurrent events has a remarkable effect on understanding social dynamics and acting in advance to reduce damage. (1) From the perspective of spatial connection, trans-regional implication, which means the cause of the incident is not local but somewhere else, is an important reason for the occurrence of events. However, existing works neglect to model this spatial influence and only leverage the local information for event prediction. (2) From the perspective of temporal connection, future events are triggered by the continuous evolution of the region. Nonetheless, most studies assign events to different timestamps and recognize their sequential patterns, ignoring the continuity of the evolution process. To tackle the above two problems, we propose a s patial and t emporal k nowledge g raph neural n etwork ( STKGN ). Specifically, to construct the cross-regional connection, we propose a novel spatial-temporal event graph, where each region is denoted as a node and trans-regional influences are reflected by bidirectional edges. To simulate the continuously evolving process, we propose an event-driven memory network to represent the state of each entity and continually update the state embeddings by emerging events. Then we use a broadcast network to spread the local changes in the graph to obtain high-order reasons like the trans-regional implication. Extensive experiments on two real-world datasets demonstrate that STKGN achieves significant improvements over state-of-the-art methods. Further analysis shows the interpretability of the trans-regional implication.},
  archive      = {J_NEUCOM},
  author       = {Zepeng Huai and Dawei zhang and Guohua Yang and Jianhua Tao},
  doi          = {10.1016/j.neucom.2023.126557},
  journal      = {Neurocomputing},
  pages        = {126557},
  shortjournal = {Neurocomputing},
  title        = {Spatial-temporal knowledge graph network for event prediction},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NIT: Searching for rumors in social network through
neighborhood information transmission. <em>NEUCOM</em>, <em>553</em>,
126552. (<a href="https://doi.org/10.1016/j.neucom.2023.126552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumor detection has been a hot issue in current online public opinion governance. Most of the recent rumor detection methods tend to be supervised learning, while research about unsupervised detection methods is relatively rare, which focuses on deep learning models. For both interpretability and high performance, an unsupervised rumor detection method based on neighborhood information transmission (NIT) is proposed. Firstly, the initial importance regarded as the initial information of the object is evaluated from the perspective of local and global heterogeneous distance. Then the neighborhood information graph is constructed based on the neighborhood relationship on mixed data. On the neighborhood graph, NIT performs information transmission between neighbors and constantly updates the importance score by paying attention to the correlation between objects. Finally, the rumor object can be sought out by importance score ranking. In addition, to enhance the rumor identification effect, a propagation-based enhancement strategy is proposed to improve the performance of the unsupervised rumor detection algorithm by the propagation index of each object. Experiments were conducted on two UCI datasets and Weibo real-world rumor dataset, and the results proved the effectiveness of the NIT algorithm and the feasibility of the enhancement strategy.},
  archive      = {J_NEUCOM},
  author       = {Biao Wang and Hongquan Wei and Shuxin Liu and Kai Wang and Ran Li},
  doi          = {10.1016/j.neucom.2023.126552},
  journal      = {Neurocomputing},
  pages        = {126552},
  shortjournal = {Neurocomputing},
  title        = {NIT: Searching for rumors in social network through neighborhood information transmission},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An incremental random walk algorithm for sampling continuous
fitness landscapes. <em>NEUCOM</em>, <em>553</em>, 126549. (<a
href="https://doi.org/10.1016/j.neucom.2023.126549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fitness landscape analysis (FLA) is used to mathematically characterize optimization problems . It is critical to get appropriate sampling points using random walk (RW) algorithms to perform FLA on continuous optimization problems . However, most of the existing approaches face the problems of poor robustness of the RW algorithm and inadequate coverage of the fitness landscape. In this study, an incremental random walk (IRW) algorithm is proposed to sample the fitness landscape for continuous optimization problems. IRW includes two major improvements: (i) An incremental perturbation mechanism is proposed to generate perturbation variables to enhance the diverse distribution of sampling points. (ii) The problem of getting trapped in the local region is alleviated by using the mirrored boundary handling method. The experimental results tested on various cases demonstrate the excellence of IRW in terms of coverage. Moreover, IRW has shown superior reliability at different problem dimensions on other different benchmark functions . Consequently, IRW is well-suited as an alternative for sampling continuous fitness landscapes under a variety of problem dimensions.},
  archive      = {J_NEUCOM},
  author       = {Yaxin Li and Jing Liang and Caitong Yue and Kunjie Yu and Hao Guo},
  doi          = {10.1016/j.neucom.2023.126549},
  journal      = {Neurocomputing},
  pages        = {126549},
  shortjournal = {Neurocomputing},
  title        = {An incremental random walk algorithm for sampling continuous fitness landscapes},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On k-means iterations and gaussian clusters.
<em>NEUCOM</em>, <em>553</em>, 126547. (<a
href="https://doi.org/10.1016/j.neucom.2023.126547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, k -means remains arguably the most popular clustering algorithm (Jain, 2010; Vouros et al., 2021). Two of its main properties are simplicity and speed in practice. Here, our main claim is that the average number of iterations k -means takes to converge ( τ ¯ τ¯ ) is in fact very informative. We find this to be particularly interesting because τ ¯ τ¯ is always known when applying k -means but has never been, to our knowledge, used in the data analysis process. By experimenting with Gaussian clusters, we show that τ ¯ τ¯ is related to the structure of a data set under study. Data sets containing Gaussian clusters have a much lower τ ¯ τ¯ than those containing uniformly random data. In fact, we go considerably further and demonstrate a pattern of inverse correlation between τ ¯ τ¯ and the clustering quality . We illustrate the importance of our findings through two practical applications. First, we describe the cases in which τ ¯ τ¯ can be effectively used to identify irrelevant features present in a given data set or be used to improve the results of existing feature selection algorithms. Second, we show that there is a strong relationship between τ ¯ τ¯ and the number of clusters in a data set, and that this relationship can be used to find the true number of clusters it contains.},
  archive      = {J_NEUCOM},
  author       = {Renato Cordeiro de Amorim and Vladimir Makarenkov},
  doi          = {10.1016/j.neucom.2023.126547},
  journal      = {Neurocomputing},
  pages        = {126547},
  shortjournal = {Neurocomputing},
  title        = {On k-means iterations and gaussian clusters},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive map matching based on dynamic word embeddings for
indoor positioning. <em>NEUCOM</em>, <em>553</em>, 126545. (<a
href="https://doi.org/10.1016/j.neucom.2023.126545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Map matching has been widely used in various indoor localization technologies. However, conventional map matching technologies based on probabilistic models, such as particle filter (PF), still have a series of limitations, such as underutilization of map information, poor generalization, and relatively low precision. To improve the performance of PF-based map matching technique, this paper proposes MapDem, a novel map matching model fusing dynamic word embeddings and Variational Autoencoder (VAE) to improve matching performance significantly. The key to our approach is to extract map information using dynamic word embeddings to represent each reachable point on the map as word vectors with allowable oriented trajectory information. The same point has different representations on different trajectories so that MapDem can adaptively learn the contextual information of map for position estimation. Unlike traditional particle filters, MapDem focuses on the learning of particle sets distribution by a statistical model, Variational Autoencoder (VAE), followed by estimating position with combined current and previous sequence information. Extensive experiments have been conducted with 610 trajectories in three real-world scenarios. Numerical results demonstrate the adaptability of MapDem which works equally well in all three different scenarios, outperforming traditional particle filters by 18\% on average.},
  archive      = {J_NEUCOM},
  author       = {Xinyue Lan and Lijia Zhang and Zhuoling Xiao and Bo Yan},
  doi          = {10.1016/j.neucom.2023.126545},
  journal      = {Neurocomputing},
  pages        = {126545},
  shortjournal = {Neurocomputing},
  title        = {Adaptive map matching based on dynamic word embeddings for indoor positioning},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Radial-based undersampling approach with adaptive
undersampling ratio determination. <em>NEUCOM</em>, <em>553</em>,
126544. (<a href="https://doi.org/10.1016/j.neucom.2023.126544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, machine learning techniques are employed in a wide range of applications, where classification is a common task in machine learning . It predicts the class label of a previously unseen example according to the decision of a classification model , which is learned by running a classifier learning algorithm on the collected training examples set. On the other hand, in many practical applications, the collected training sets are usually class imbalanced, that is, one class can have significantly more examples than the other class(es), but the minority class usually carries much valuable information and is more important than the majority class. However, most classifier learning algorithms are designed under the assumption that each class in a training set has approximately the same number of examples, leading to the consequence that they often can not achieve satisfactory classification performance on imbalanced data especially for the minority class examples. To solve this problem, a Radial-Based Undersampling approach with Adaptive undersampling Ratio (RBU-AR) is proposed in this paper. The main novelty of RBU-AR is that it attempts to determine the proper undersampling ratio according to the class overlap data complexity rather than adopting the default value 1 or using the empirical trial and error strategy as many existing undersampling approaches do. Experiments are conducted on 30 benchmark imbalanced datasets and 10 artificial datasets, the obtained results and corresponding statistical tests indicate that class overlap degree indeed has a great influence on the achievable classification performance and is usually more important than the class imbalance ratio IR, and our undersampling approach RBU-AR generally achieves highly competitive or better performance with respect to several state-of-the-art approaches. Therefore, this work provides a theoretical guideline in determining the proper extent of undersampling by utilizing the class overlap data complexity information.},
  archive      = {J_NEUCOM},
  author       = {Bo Sun and Qian Zhou and Zhijun Wang and Peng Lan and Yunsheng Song and Shaomin Mu and Aifeng Li and Haiyan Chen and Peng Liu},
  doi          = {10.1016/j.neucom.2023.126544},
  journal      = {Neurocomputing},
  pages        = {126544},
  shortjournal = {Neurocomputing},
  title        = {Radial-based undersampling approach with adaptive undersampling ratio determination},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Camouflaged object detection with counterfactual
intervention. <em>NEUCOM</em>, <em>553</em>, 126530. (<a
href="https://doi.org/10.1016/j.neucom.2023.126530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) aims to identify camouflaged objects hiding in their surroundings, which is a valuable yet challenging task. The main challenge is that there are ambiguous semantic biases in the camouflaged object datasets , which affect the results of COD. To address this challenge, we design a counterfactual intervention network (CINet) to mitigate the influences of ambiguous semantic biases and obtain accurate COD. Specifically, our CINet consists of three key modules, i.e., texture-aware interaction module (TIM), context-aware fusion module (CFM), and counterfactual intervention module (CIM). The TIM is designed to extract the refined textures for accurate localization, the CFM is proposed to fuse the multi-scale contextual features to enhance the detection performance, and the CIM is presented to learn more effective textures and make unbiased predictions. Unlike most existing COD methods that directly capture contextual features through the final loss function, we develop a counterfactual intervention strategy to learn more effective contextual textures. Extensive experiments on four challenging benchmark datasets demonstrate that our CINet significantly outperforms 31 state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaofei Li and Hongying Li and Hao Zhou and Miaomiao Yu and Dong Chen and Shuohao Li and Jun Zhang},
  doi          = {10.1016/j.neucom.2023.126530},
  journal      = {Neurocomputing},
  pages        = {126530},
  shortjournal = {Neurocomputing},
  title        = {Camouflaged object detection with counterfactual intervention},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy approximation-based optimal consensus control for
nonlinear multiagent systems via adaptive dynamic programming.
<em>NEUCOM</em>, <em>553</em>, 126529. (<a
href="https://doi.org/10.1016/j.neucom.2023.126529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fuzzy approximation-based optimal consensus control problem for nonlinear multiagent systems with unknown perturbations. By constructing local error dynamics, the considered optimal consensus problem is reformulated as finding Nash-equilibrium solutions to zero-sum games. Then, by using sliding mode control technology and the concept of hierarchical design, a series of control signals are sequentially designed to regulate the consensus error and minimize the local value function. In addition, an identifier-critic architecture is developed by using generalized fuzzy hyperbolic models, where the identifier is employed to relax the requirement for complete system dynamics information, and the hierarchical sliding mode surface-based critic network is applied to approximate optimal control inputs. Finally, A simulation example is presented to illustrate the validity of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Heng Zhao and Huanqing Wang and Ning Xu and Xudong Zhao and Sanaa Sharaf},
  doi          = {10.1016/j.neucom.2023.126529},
  journal      = {Neurocomputing},
  pages        = {126529},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy approximation-based optimal consensus control for nonlinear multiagent systems via adaptive dynamic programming},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Enhancing aspect-based sentiment analysis using a
dual-gated graph convolutional network via contextual affective
knowledge. <em>NEUCOM</em>, <em>553</em>, 126526. (<a
href="https://doi.org/10.1016/j.neucom.2023.126526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary goal of aspect-based sentiment analysis is to identify sentiment polarity concerning the given aspect in a sentence. Recent investigations have demonstrated the superior performance of graph convolutional neural network (GCN) on dependency parsing tree. However, these GCN-based models fail to take the given aspect into account when calculating the hidden node representation vector, as well as lack exploration of contextual commonsense knowledge . On the contrary, the gating mechanism enables the interaction of the context and the given aspect to enhance the impact of the given aspect on the context. Nevertheless, such interactions are frequently inadequate resulting in insufficient extraction of sentiment information. This paper proposes a dual-gated graph convolutional network via contextual affective knowledge (DGGCN) to address these issues. The core idea is to incorporate GCN into the gating mechanism to enhance GCN to fully aggregate node information while strengthening the concentration on the given aspect. Simultaneously, the incorporation of contextual affective knowledge into graph networks can refine the perception of affective features. Experimental findings on five benchmark datasets reveal that our proposed DGGCN surpasses state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Hongtao Liu and Yiming Wu and Qingyu Li and Wanying Lu and Xin Li and Jiahao Wei and Xueyan Liu and Jiangfan Feng},
  doi          = {10.1016/j.neucom.2023.126526},
  journal      = {Neurocomputing},
  pages        = {126526},
  shortjournal = {Neurocomputing},
  title        = {Enhancing aspect-based sentiment analysis using a dual-gated graph convolutional network via contextual affective knowledge},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Alignment and stability of embeddings: Measurement and
inference improvement. <em>NEUCOM</em>, <em>553</em>, 126517. (<a
href="https://doi.org/10.1016/j.neucom.2023.126517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning (RL) methods learn objects’ latent embeddings where information is preserved by distance. Since certain distance functions are invariant to certain linear transformations , one may obtain different embeddings while preserving the same information. In dynamic systems, a temporal difference in embeddings may be explained by the stability of the system or by the misalignment of embeddings due to arbitrary transformations. This study focuses on the embedding alignment problem to distinguish structural changes inherent to a system from arbitrary changes caused by representation learning methods, and quantify their magnitudes. In order to avoid any confusion due to the naming conventions in the literature, it should be noted that embedding alignment problems are different from graph matching/network alignment problems. In the representation learning literature, although the embedding alignment issue has been acknowledged, its measurement and empirical analysis have not received sufficient interest. In this work, we explore the embedding alignment and its parts, propose novel metrics to measure alignment and stability, and show their suitability through synthetic experiments. Real-world experiments show that both static and dynamic RL methods are prone to produce misaligned embeddings and such misalignment worsens the performance of dynamic network inference tasks. By ensuring alignment, the prediction accuracy raises by up to 90\% in static and up to 40\% in dynamic RL methods.},
  archive      = {J_NEUCOM},
  author       = {Furkan Gürsoy and Mounir Haddad and Cécile Bothorel},
  doi          = {10.1016/j.neucom.2023.126517},
  journal      = {Neurocomputing},
  pages        = {126517},
  shortjournal = {Neurocomputing},
  title        = {Alignment and stability of embeddings: Measurement and inference improvement},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fault tolerant control for a class of nonlinear systems with
multiple faults using neuro-dynamic programming. <em>NEUCOM</em>,
<em>553</em>, 126502. (<a
href="https://doi.org/10.1016/j.neucom.2023.126502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the multiple fault scenario, i.e., both actuator and sensor faults occur simultaneously, this paper develops a neuro-dynamic programming (NDP)-based fault tolerant control (FTC) scheme for a class of nonlinear systems . By combining a descriptor observer with an adaptive observer, system states and multiple faults are estimated simultaneously. For the nominal system, i.e., the fault-free system, a critic neural network (NN) is employed to solve the Hamilton–Jacobi-Bellman (HJB) equation, and the approximate optimal control policy is obtained. To eliminate the influence of sensor faults, the accurate estimations of system states are used instead of system states from faulty sensors to construct the approximate optimal control policy. Then, by combining the estimations of actuator faults with the approximate optimal control policy, an FTC law is developed to suppress the influence of actuator faults . The stability of the closed-loop nonlinear system is analyzed to be uniformly ultimately bounded via the Lyapunov stability theorem. The effectiveness of the present FTC scheme is demonstrated by two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Chujian Zeng and Bo Zhao and Derong Liu},
  doi          = {10.1016/j.neucom.2023.126502},
  journal      = {Neurocomputing},
  pages        = {126502},
  shortjournal = {Neurocomputing},
  title        = {Fault tolerant control for a class of nonlinear systems with multiple faults using neuro-dynamic programming},
  volume       = {553},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Patch-based camera-aware person-to-group learning and group
similarity strategy for unsupervised group re-identification.
<em>NEUCOM</em>, <em>552</em>, 126565. (<a
href="https://doi.org/10.1016/j.neucom.2023.126565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real life, people often go together in groups, which extends to an important but less researched task of computer vision: group re-identification. Differing from the related task of person re-identification, group re-identification involves unique challenges: self-occlusion, layout changes, membership changes, and the lack of labeled data. To solve these problems, we propose a patch-based camera-aware person-to-group unsupervised learning network. For the problem of high labeling costs, we train an unsupervised feature extraction network to extract the features of group members. Moreover, the feature extraction network is based on image patches, which solves the problem of group member alignment caused by occlusion within the group. To handle the large intra-ID variance resulting from changes in camera views, we add camera information to the model and propose the multi-grained camera-aware loss. For the problems of layout changes and membership changes, we adopt a person-to-group strategy. Specifically, we propose a novel group distance metric, named Modified Hausdorff Distance , to exploit the information of all the group members. Experimental results on two public datasets demonstrate the superiority of our approach.},
  archive      = {J_NEUCOM},
  author       = {Lisha Yu and Sien Huang and Jianhuang Lai and Zhanxiang Feng},
  doi          = {10.1016/j.neucom.2023.126565},
  journal      = {Neurocomputing},
  pages        = {126565},
  shortjournal = {Neurocomputing},
  title        = {Patch-based camera-aware person-to-group learning and group similarity strategy for unsupervised group re-identification},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CSCIM_FS: Cosine similarity coefficient and information
measurement criterion-based feature selection method for
high-dimensional data. <em>NEUCOM</em>, <em>552</em>, 126564. (<a
href="https://doi.org/10.1016/j.neucom.2023.126564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) based on mutual information (MI) metrics needs to discretize the data in preprocessing, which is a convenient way to identify correlation between features. However, information loss often occurs in data discretization. In order to solve this information loss problem, this paper proposes a FS algorithm based on cosine similarity coefficient and information measurement criterion (CSCIM_FS). First, the MI between features and tags is calculated, and features are sorted out according to the MI calculated. Then, a feature matrix is constructed to transform the one-dimensional feature sequence into a two-dimensional square matrix. Next, cosine transform is adopted to obtain the high-frequency components of the feature matrix, and sampling is conducted to derive the hash fingerprint of the feature matrix. After that, the similarity between every two features is calculated on the basis of the hash fingerprints of different features. Finally, the feature weight is calculated according to tags, the MI and similarity between features, and a key feature subset is obtained and used to conduct feature selection from the data. The experimental results on several UCI public datasets show that CSCIM_FS algorithm selected a feature subset with high accuracy, and that this algorithm performs better than MIM, CMIM, mRMR and other algorithms.},
  archive      = {J_NEUCOM},
  author       = {Gaoteng Yuan and Yi Zhai and Jiansong Tang and Xiaofeng Zhou},
  doi          = {10.1016/j.neucom.2023.126564},
  journal      = {Neurocomputing},
  pages        = {126564},
  shortjournal = {Neurocomputing},
  title        = {CSCIM_FS: Cosine similarity coefficient and information measurement criterion-based feature selection method for high-dimensional data},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving long-tail relation extraction via adaptive
adjustment and causal inference. <em>NEUCOM</em>, <em>552</em>, 126563.
(<a href="https://doi.org/10.1016/j.neucom.2023.126563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting long-tail relations poses a significant challenge. Traditional models struggle with weak generalization on tail classes due to the limited sample size. To overcome the limitation, we propose a novel long-tail relation extraction model based on Adaptive Adjustment and Causal Inference (AACI). Specifically, AACI leverages class-adaptive adjustment terms to increase the relative margins between head and tail classes, improving the discriminability of tail classes and further enhancing their generalization. Moreover, the learning of our model may encounter multiple spurious correlations due to confounding variables. Therefore, we construct a Structural Causal Model (SCM) for AACI to formalize all spurious correlations and apply causal inference methods to eliminate negative effects of these correlations, thus improving the robustness of AACI. We evaluate our model on the NYT24 and NYT datasets. Our experiments demonstrate that AACI effectively modulates the class margins, eliminates the spurious correlations, and outperforms existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jingyao Tang and Lishuang Li and Hongbin Lu and Beibei Zhang and Haiming Wu},
  doi          = {10.1016/j.neucom.2023.126563},
  journal      = {Neurocomputing},
  pages        = {126563},
  shortjournal = {Neurocomputing},
  title        = {Improving long-tail relation extraction via adaptive adjustment and causal inference},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view cost-sensitive kernel learning for imbalanced
classification problem. <em>NEUCOM</em>, <em>552</em>, 126562. (<a
href="https://doi.org/10.1016/j.neucom.2023.126562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view imbalanced learning concentrates on recognizing valuable patterns from multi-view imbalanced data . There are numerous algorithm-level multi-view imbalanced learning methods including multi-view ensemble learning methods and multi-view cost-sensitive learning methods. However, these approaches have two drawbacks. Firstly, from the multi-view representation perspective, they either ignore the agreement among different views, or fail to fully exploit the complementarity information contained in multi-view data. Secondly, from the class-imbalanced perspective, multi-view ensemble learning first needs to design a specific data pre-processing scheme to generate views and then fuses the local and global information with multi-view ensemble schemes. Such models are closely related to practical problems and lack universality. In contrast, multi-view cost-sensitive learning methods possess concise formulations. But the success of such methods depends on imposing appropriate misclassification cost to the majority and minority classes. Inspired by elegant merits of asymmetric LINEX loss function, we propose a multi-view cost-sensitive kernel learning method with LINEX loss termed as MVCSKL. It not only fully exploits the consensus and complementary information of multiple views, but also adaptively learns and adjusts the misclassification cost of different classes through the asymmetric LINEX loss function. Besides, the introduction of the kernel function enables the MVCSKL model to handle complex nonlinear problem and further guarantees its prediction performance. Furthermore, we adopt the alternating direction method of multipliers and gradient descent algorithm to solve MVCSKL. Based on the Rademacher complexity, we analyze the generalization capability of MVCSKL. Extensive experiments are conducted to verify the effectiveness of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Tang and Zhaojie Hou and Xiaotong Yu and Saiji Fu and Yingjie Tian},
  doi          = {10.1016/j.neucom.2023.126562},
  journal      = {Neurocomputing},
  pages        = {126562},
  shortjournal = {Neurocomputing},
  title        = {Multi-view cost-sensitive kernel learning for imbalanced classification problem},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain adaptation for complex shadow removal with shadow
transformer network. <em>NEUCOM</em>, <em>552</em>, 126559. (<a
href="https://doi.org/10.1016/j.neucom.2023.126559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shadows observed in practical scenes have complex shapes, and removing them is a very challenging task in computer vision. In particular, previous studies on complex shadow removal have limitations in that they can be learned only on paired datasets. Taking the issues into consideration, we present a new domain-adaptive shadow removal framework. The proposed approach includes domain adaptation, detection, and removal stages. The shadow-preserving domain translator in the first stage compensates for the lack of real data through domain transformation of the synthetic data. In the second stage, efficient shadow detection is performed through the domain adaptive mean teacher network. Last, a novel attention network removes complex shadows using detected shadows as a query, effectively removing complex shadows. The feasibility and effectiveness of the proposed framework are validated through the newly collected Grand Theft Auto-Road Shadow dataset. The proposed method outperforms existing methods for quantitative and qualitative metrics related to shadow detection and removal.},
  archive      = {J_NEUCOM},
  author       = {Woo-Jin Ahn and Geon Kang and Hyun-Duck Choi and Myo-Taeg Lim},
  doi          = {10.1016/j.neucom.2023.126559},
  journal      = {Neurocomputing},
  pages        = {126559},
  shortjournal = {Neurocomputing},
  title        = {Domain adaptation for complex shadow removal with shadow transformer network},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-camera multi-object tracking: A review of current
trends and future advances. <em>NEUCOM</em>, <em>552</em>, 126558. (<a
href="https://doi.org/10.1016/j.neucom.2023.126558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nascent applicability of multi-camera tracking (MCT) in numerous real-world applications makes it a significant computer vision problem. While visual tracking of objects, especially in video obtained from single camera setup, has drawn huge research attention, the constant identification and tracking of targets as they transit across multiple cameras remains an open research problem. In addition to the linking of target appearance and trajectory information across frames, effective association of such data across multiple cameras is also very critical in MCT. Occlusion, appearance variability, camera motion, as well as nonrigid object structure and motion are widely recognized constraints and major sources of concerns in MCT. In recent years, several literatures have been contributed suggesting a variety of approaches to addressing various problems in MCT. However, studies that critically review and report the advances and trends of research in MCT are still limited. This current study presents a comprehensive and up-to-date review of visual object tracking in multi-camera settings. In this paper, we analyze and categorize existing works based on six crucial facets: problem formulation, adopted problem solving approach, data association requirements, mutual exclusion constraints, benchmark datasets, and performance metrics. Furthermore, the study summarizes the outcomes of 30 state-of-the-art MCT algorithms on common datasets to allow quantitative comparison and analysis of their experimental results. Finally, we examine recent advances in MCT and suggest some promising future research directions.},
  archive      = {J_NEUCOM},
  author       = {Temitope Ibrahim Amosa and Patrick Sebastian and Lila Iznita Izhar and Oladimeji Ibrahim and Lukman Shehu Ayinla and Abdulrahman Abdullah Bahashwan and Abubakar Bala and Yau Alhaji Samaila},
  doi          = {10.1016/j.neucom.2023.126558},
  journal      = {Neurocomputing},
  pages        = {126558},
  shortjournal = {Neurocomputing},
  title        = {Multi-camera multi-object tracking: A review of current trends and future advances},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Positive unlabeled learning with tensor networks.
<em>NEUCOM</em>, <em>552</em>, 126556. (<a
href="https://doi.org/10.1016/j.neucom.2023.126556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positive unlabeled learning is a binary classification problem with positive and unlabeled data. It is common in domains where negative labels are costly or impossible to obtain, e.g., medicine and personalized advertising. Most approaches to positive unlabeled learning apply to specific data types (e.g., images, categorical data) and can not generate new positive and negative samples. This work introduces a feature-space distance-based tensor network approach to the positive unlabeled learning problem. The presented method is not domain specific and significantly improves the state-of-the-art results on the MNIST image and 15 categorical/mixed datasets. The trained tensor network model is also a generative model and enables the generation of new positive and negative instances.},
  archive      = {J_NEUCOM},
  author       = {Bojan Žunkovič},
  doi          = {10.1016/j.neucom.2023.126556},
  journal      = {Neurocomputing},
  pages        = {126556},
  shortjournal = {Neurocomputing},
  title        = {Positive unlabeled learning with tensor networks},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple finite-time synchronization and settling-time
estimation of delayed competitive neural networks. <em>NEUCOM</em>,
<em>552</em>, 126555. (<a
href="https://doi.org/10.1016/j.neucom.2023.126555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite-time synchronization and its settling-time estimation has been a hot topic in fields of science and engineering. This paper proposes a unified control framework to study the multiple finite-time synchronization of delayed competitive neural networks (DCNNs). Firstly, a more comprehensive finite-time framework lemma is systematically established. Compared with existing finite-time control method , the proposed framework involves several kinds of synchronization results and it enhances the estimation of settling-time. Then, based on the control framework, the finite-time, fixed-time and preassigned-time synchronization of DCNNs can be achieved simultaneously by modifying the controller parameters. Finally, numerical example and image encryption application are presented to demonstrate the validity and superiority of the deduced results.},
  archive      = {J_NEUCOM},
  author       = {Leimin Wang and Xingxing Tan and Qingyi Wang and Junhao Hu},
  doi          = {10.1016/j.neucom.2023.126555},
  journal      = {Neurocomputing},
  pages        = {126555},
  shortjournal = {Neurocomputing},
  title        = {Multiple finite-time synchronization and settling-time estimation of delayed competitive neural networks},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Complexity-based drift detection for nonstationary data
streams. <em>NEUCOM</em>, <em>552</em>, 126554. (<a
href="https://doi.org/10.1016/j.neucom.2023.126554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This publication presents the Complexity Drift Detector (C2D) – the method for detecting a concept shift in the data stream based on the classification task complexity measures. The method belongs to the group of detectors agnostic to the recognition quality of the base classifier . The possibility of selecting a set of difficulty measures taken into account during the data stream processing allows applying the method to many tasks in which the detection of a classification task complexity change is expected. The publication includes experiments analyzing the hyperparameters’ influence on the operation of the method and a broad comparative experiment comparing the proposed algorithm with state-of-the-art solutions. The experiments were carried out on synthetic data streams of different dimensions and with different concept drift characteristics, also presenting the effects of processing real-world data streams. The results of the conducted research confirm the high efficiency of the method in detecting concept changes, sensitive not only to the fact of drift occurrence but also to its dynamics.},
  archive      = {J_NEUCOM},
  author       = {Joanna Komorniczak and Pawel Ksieniewicz},
  doi          = {10.1016/j.neucom.2023.126554},
  journal      = {Neurocomputing},
  pages        = {126554},
  shortjournal = {Neurocomputing},
  title        = {Complexity-based drift detection for nonstationary data streams},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust sequential online prediction with dynamic ensemble of
multiple models: A review. <em>NEUCOM</em>, <em>552</em>, 126553. (<a
href="https://doi.org/10.1016/j.neucom.2023.126553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of time series for sequential online prediction (SOP) has long been a research topic, but achieving robust and computationally efficient SOP with non-stationary time series remains a challenge. This paper reviews a framework, called Bayesian Dynamic Ensemble of Multiple Models (BDEMM), which addresses SOP in a theoretically elegant way, and have found widespread use in various fields. BDEMM utilizes a model pool of weighted candidate models, adapted online using Bayesian formalism to capture possible temporal evolutions of the data. This review comprehensively describes BDEMM from five perspectives: its theoretical foundations, algorithms, practical applications, connections to other research, and strengths, limitations, and potential future directions.},
  archive      = {J_NEUCOM},
  author       = {Bin Liu},
  doi          = {10.1016/j.neucom.2023.126553},
  journal      = {Neurocomputing},
  pages        = {126553},
  shortjournal = {Neurocomputing},
  title        = {Robust sequential online prediction with dynamic ensemble of multiple models: A review},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A meta-learning network with anti-interference for few-shot
fault diagnosis. <em>NEUCOM</em>, <em>552</em>, 126551. (<a
href="https://doi.org/10.1016/j.neucom.2023.126551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the changing working conditions of rotating machinery in operation, it is often difficult to collect data accurately in some severe fault states, and the lack of data can lead to poor performance of deep learning-based fault diagnosis models. In the few-shot scenario, traditional meta-learning methods yield superior predictions by identifying ideal initialization parameters. When the update gradients of tasks are in different directions, meta-learning modifies the weights of samples in the current tasks to average them out, which may lead to negative transfer between tasks and poor generalization of biases. Based on the above problems, we propose a meta-learning network with anti-interference (AIML) for few-shot fault diagnosis, which is obtained by combining a dynamic fine-tuning technique to increase the gradient agreement of the tasks. AIML consists of two functions: the feature encoding network (FEN) and the base network. AIML uses the property of shared parameters about transfer learning to learn shared feature representations of different tasks, while FEN dynamically adjusts the loss weights of conflicting tasks due to meta-learning with two-level optimization techniques. First, in the internal loop, AIML updates the gradient of the base network while the network parameters of FEN are fixed. Instead of immediately computing the gradient of the optimal parameters for the new task, the FEN is then integrated in the outer loop to learn the meta-representation, and the weights obtained for the various tasks relate to the gradient for meta-optimization. Only during the outer loop stage of the meta-training is the FEN updated. Three publicly available datasets are used to assess the performance of AIML, and the results show that it is more effective at resolving problems involving few-shot fault diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Zhiqian Zhao and Runchao Zhao and Xianglin Wu and Xiuli Hu and Renwei Che and Xiang Zhang and Yinghou Jiao},
  doi          = {10.1016/j.neucom.2023.126551},
  journal      = {Neurocomputing},
  pages        = {126551},
  shortjournal = {Neurocomputing},
  title        = {A meta-learning network with anti-interference for few-shot fault diagnosis},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive weighted fuzzy clustering based on intra-cluster
data divergence. <em>NEUCOM</em>, <em>552</em>, 126550. (<a
href="https://doi.org/10.1016/j.neucom.2023.126550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy C-means clustering (FCM) approach is an effective method for clustering and has been successfully applied in numbers of real-world problems. In this paper, we propose an improving adaptive weighted FCM based on data divergence, with the merits of three aspects: 1) to avoid randomization of cluster centers, we propose a new cluster centers initialization method ; 2) we present an adaptive parameter reflecting the changes of intra-cluster data divergence in the process of cluster formation from iteration to iteration for correcting the unreasonable factors resulting from the changes timely; 3) we propose a new data weighting method. By integrating the adaptive parameter and feature weighting method, we propose a novel adaptive objective function, by which the updating iterative formulas of the membership degrees, the feature weights and the cluster centers are obtained. Experimental results have shown that the novel clustering approach put forward can improve the clustering performance effectively.},
  archive      = {J_NEUCOM},
  author       = {Ziheng Wu and Yuan Zhao and Wenyan Wang and Cong Li},
  doi          = {10.1016/j.neucom.2023.126550},
  journal      = {Neurocomputing},
  pages        = {126550},
  shortjournal = {Neurocomputing},
  title        = {Adaptive weighted fuzzy clustering based on intra-cluster data divergence},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rumor detection on social networks focusing on endogenous
psychological motivation. <em>NEUCOM</em>, <em>552</em>, 126548. (<a
href="https://doi.org/10.1016/j.neucom.2023.126548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging information acquisition methods represented by social networks are increasingly popular. The freedom and concealment make social media become the main platform for rumor spreading. Rumor detection has attracted the attention of both academia and industry, and a series of rumor detection methods have emerged. However, existing methods focus on modeling exogenous features such as text content and user characteristics, while ignoring the endogenous psychological motivation of users. Sociological and psychological researches on rumor have demonstrated the correlation between the endogenous psychology of users and their behavior in social networks. Therefore, this study focuses on the intrinsic psychological motivation of users, probes the psychological changes of users after they are exposed to rumors from the perspectives of active sharing and passive response, analyzes and judges user behaviors to explore an efficient rumor detection method. Among them, active sharing behavior is based on the investigation of social users’ motivation, decision making and goal setting, and is related to users’ motivation to actively participate in content by creating posts and so on. Passive response, which is closely related to personal emotions originating from the influence of external factors, is a study of users’ cognitive processes and is associated with the way they handle information without active participation. Experiments demonstrate the superiority of our proposed method in rumor detection tasks, improving accuracy by 2.1\% over the current baseline on the Twitter16 dataset and enabling early detection of rumors as they emerge.},
  archive      = {J_NEUCOM},
  author       = {Yeqing Yan and Yongjun Wang and Peng Zheng},
  doi          = {10.1016/j.neucom.2023.126548},
  journal      = {Neurocomputing},
  pages        = {126548},
  shortjournal = {Neurocomputing},
  title        = {Rumor detection on social networks focusing on endogenous psychological motivation},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully distributed dynamic event-triggering formation control
for multi-agent systems under DoS attacks: Theory and experiment.
<em>NEUCOM</em>, <em>552</em>, 126546. (<a
href="https://doi.org/10.1016/j.neucom.2023.126546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fully distributed time-varying formation (TVF) control problem is investigated for multi-agent systems (MASs) subject to Denial-of-Service (DoS) attacks. An asynchronous dynamic event-triggering (DET) mechanism is introduced to alleviate agents’ communication burden suitably, and a fully distributed DET-TVF control protocol is designed. Sufficient conditions and theoretical analysis prove that this protocol can achieve the desired TVF configuration under DoS attacks , and Zeno behavior is excluded. Finally, experimental examples using six quadrotors demonstrate and fully showcase the efficacy of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Hui Cao and Liang Han and Dongyu Li and Qinglei Hu},
  doi          = {10.1016/j.neucom.2023.126546},
  journal      = {Neurocomputing},
  pages        = {126546},
  shortjournal = {Neurocomputing},
  title        = {Fully distributed dynamic event-triggering formation control for multi-agent systems under DoS attacks: Theory and experiment},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Malware classification with disentangled representation
learning of evolutionary triplet network. <em>NEUCOM</em>, <em>552</em>,
126534. (<a href="https://doi.org/10.1016/j.neucom.2023.126534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware is a significant threat to the security of computer systems and networks worldwide, and its sophistication and diversity continue to increase over time. One of the key challenges in malware detection and classification is the high variability and similarity of the malicious code. This paper proposes a novel method for malware classification with disentangled representation from an evolutionary triplet network. We aim to learn a representation of malware samples that captures the underlying factors of variation, making it easier to distinguish between different malware types. The genetic algorithm-based optimization enables us to find the optimal distance representation of malware, which helps to minimize the intra-class distance and maximize the inter-class distance in the disentangled space. By evolutionary optimization of the triplet network, our model is able to better capture the subtle differences in the structural characteristics of malware, which led to significant improvements of classification accuracy and recall in three benchmark datasets. Furthermore, this method demonstrates significant improvement on t-SNE visualization, indicating that the learned features are more discriminative and better capture the underlying structure of the malware.},
  archive      = {J_NEUCOM},
  author       = {Seok-Jun Bu and Sung-Bae Cho},
  doi          = {10.1016/j.neucom.2023.126534},
  journal      = {Neurocomputing},
  pages        = {126534},
  shortjournal = {Neurocomputing},
  title        = {Malware classification with disentangled representation learning of evolutionary triplet network},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exponential control design on fixed-time synchronization of
fully quaternion-valued memristive delayed neural networks without
decomposition. <em>NEUCOM</em>, <em>552</em>, 126532. (<a
href="https://doi.org/10.1016/j.neucom.2023.126532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article mainly explores fixed-time (FXT) synchronization of fully quaternion-valued memristive neural networks (QVMNNs) with generalized delays. Firstly, based on the set-valued mapping theory and the nonsmooth approach, the discontinuity of quaternion-valued memristive connection weights is successfully solved. Next, by introducing the signum function, absolute-like norm and quadratic norm in the quaternion field, a direct non-decomposing method is put forward. Under this framework, several exponential-type controllers are designed, which have only one exponential term and no longer contain the traditional linear part and the power-law terms. Compared with designing four real-value controllers, the control schemes proposed in this article are simpler in form. Besides, several criteria of FXT synchronization and the upper bound of the setting time are deduced based on Lyapunov method and Taylor expansion . Lastly, the achieved synchronization results are confirmed via numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Ziwei Guo and Jinshui Ren and Zhen Liu and Xuzheng Liu and Cheng Hu},
  doi          = {10.1016/j.neucom.2023.126532},
  journal      = {Neurocomputing},
  pages        = {126532},
  shortjournal = {Neurocomputing},
  title        = {Exponential control design on fixed-time synchronization of fully quaternion-valued memristive delayed neural networks without decomposition},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synchronization of switched complex dynamical networks with
impulses: State-dependent switching approach. <em>NEUCOM</em>,
<em>552</em>, 126528. (<a
href="https://doi.org/10.1016/j.neucom.2023.126528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the globally exponential synchronization ( GES ) of a class of complex dynamical networks ( CDNs ) with switching topology involving impulse action. A novel state-dependent switching ( SDS ) approach to tune the switching topology of CDNs is designed based on the information of the node dynamics with impulses. Different from the traditional SDS results which are based on continuous state space, some sufficient conditions for network synchronization based on SDS are proposed in the framework of impulse action. A relationship between impulse action, the network structure, and switching topology is established, which is crucial to design the SDS law. Two different impulse actions on the network dynamics are fully considered in this paper, namely, stabilizing continuous dynamics with desynchronizing impulses and destabilizing continuous dynamics with synchronizing impulses. Finally, two numerical simulations are given to demonstrate the effectiveness of the proposed control method .},
  archive      = {J_NEUCOM},
  author       = {Dan Yang and Xiaodi Li and Shiji Song},
  doi          = {10.1016/j.neucom.2023.126528},
  journal      = {Neurocomputing},
  pages        = {126528},
  shortjournal = {Neurocomputing},
  title        = {Synchronization of switched complex dynamical networks with impulses: State-dependent switching approach},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task-aware network: Mitigation of task-aware and task-free
performance gap in online continual learning. <em>NEUCOM</em>,
<em>552</em>, 126527. (<a
href="https://doi.org/10.1016/j.neucom.2023.126527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online continual learning (OCL) is a challenging task that accesses training data only once and trains a deep model to cover a new task while preserving the capability of previous tasks. Due to the poor performance, early works tend to measure the performance in a task-aware (TA) manner, which assumes task labels in the testing time. However, requiring such an assumption is far from the real world. Although recent works also measure the performance without the assumption ( i.e., a task-free (TF) manner), there is still a large performance gap between TA and TF in the online environment. In this paper, we observe that the severe performance gap is due to the overlapped information between different tasks. Inspired by this observation, we propose the Task-Aware Network (TANet), which learns both class-specific and task-specific information using a dual-encoder framework. However, it is difficult to learn the global distribution of previous tasks since only a few samples ( i.e., exemplars) of the tasks can be accessed. To solve the problem, we utilize the prototype feature that reflects the global distribution of each task. Using the prototype features, TANet learns the task-specific information with Prototype-based Task Contrastive Learning (PTCL) and generates pseudo-task labels. In testing time, we introduce the hybrid task-free (TF) classifier, which only activates the task that the pseudo label indicates. The proposed method achieves state-of-the-art performances in various datasets for OCL.},
  archive      = {J_NEUCOM},
  author       = {Yongwon Hong and Sungho Park and Hyeran Byun},
  doi          = {10.1016/j.neucom.2023.126527},
  journal      = {Neurocomputing},
  pages        = {126527},
  shortjournal = {Neurocomputing},
  title        = {Task-aware network: Mitigation of task-aware and task-free performance gap in online continual learning},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MPP-net: Multi-perspective perception network for dense
video captioning. <em>NEUCOM</em>, <em>552</em>, 126523. (<a
href="https://doi.org/10.1016/j.neucom.2023.126523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying deformable transformer for dense video captioning has achieved great success recently. However, deformable transformer only explores local-perspective perception by attending to a small set of key sampling points, which will make the decoder short-sighted and generate semantically incoherent and contradictory dense captions for a long video. In this paper, we propose a novel Multi-Perspective Perception Network to improve this problem. We first introduce a hierarchical temporal-spatial summary method to generate global-perspective summary context for each decoder layer and avoid redundant information. Then our new designed multi-perspective attention encourages the model to selectively incorporate the multi-perspective perception feature. Finally, we propose a novel multi-perspective generator to perform both multi-perspective feature fusion and caption generation. Experiments show that our proposed model outperforms previously published methods and achieves a competitive performance on ActivityNet Captions and YouCook2. The design of our model also shows the universality of other visual tasks that we obtain comparable results by applying our model for Object Detection and Paragraph Video Captioning.},
  archive      = {J_NEUCOM},
  author       = {Yiwei Wei and Shaozu Yuan and Meng Chen and Xin Shen and Longbiao Wang and Lei Shen and Zhiling Yan},
  doi          = {10.1016/j.neucom.2023.126523},
  journal      = {Neurocomputing},
  pages        = {126523},
  shortjournal = {Neurocomputing},
  title        = {MPP-net: Multi-perspective perception network for dense video captioning},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spiking neural p systems with myelin and dendritic spines.
<em>NEUCOM</em>, <em>552</em>, 126522. (<a
href="https://doi.org/10.1016/j.neucom.2023.126522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the dendritic and axonal morphology, some authors modeled the transmission speed of action potentials through of fixed dendritic and axonal delays, respectively. However, in practice, the exploration of dendrites and axons with variable delays potentially allows the improvement of advanced engineering applications. Taking inspiration from the structure of the dendritic spines and the process of myelination of axons, we introduce a new variant of the spiking neural P systems with variable axonal and dendritic delays named as a spiking neural P system with myelin and dendritic spines computation (MDSCSN P system). The inclusion of these experimentally proven biological features of axon and dendrites into standard spiking neural P systems allows to control the timing of dendritic/axonal transmissions. As a consequence, the soma processing of neurons is significantly reduced since it receives stable firing patterns. In contrast, standard spiking neural P systems and their recent variants use a large number of neurons/synapses to do the same. To demonstrate this, we generate a small universal SN P system by employing only neurons with standard rules to perform any Turing computable function and to figure out the Subset Sum problem in the uniform way.},
  archive      = {J_NEUCOM},
  author       = {Luis Garcia and Giovanny Sanchez and Juan-Gerardo Avalos and Eduardo Vazquez},
  doi          = {10.1016/j.neucom.2023.126522},
  journal      = {Neurocomputing},
  pages        = {126522},
  shortjournal = {Neurocomputing},
  title        = {Spiking neural p systems with myelin and dendritic spines},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural module networks: A review. <em>NEUCOM</em>,
<em>552</em>, 126518. (<a
href="https://doi.org/10.1016/j.neucom.2023.126518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability of deep neural networks to automatically learn informative features from data is their asset. For instance, a convolutional layer learns the filters based on their placement in the architecture, i.e., the low-level features in the early layers and more abstract features in the higher level. The question is whether we can learn at the sub-task level and automate the process. In other words, can a neural architecture learn to decompose a complex task into sub-tasks (i.e., elemental tasks), solve each sub-task, and aggregate the results? This way, we gain full transparency and explainability of how a complex task has been solved. This is the goal of neural module networks (NMN). Each module represents a sub-task that conveys a symbolic meaning. Each module learns the assigned sub-task based on its placement in the modules’ layout, internal architecture, or both. The NMN re-shapes itself for each sample by choosing the sample-specific modules (i.e., sub-tasks) and placing them into an appropriate layout. This review provides a comprehensive overview of neural module networks and their applications and assumes little prior knowledge. We showcased different applications of NMNs and compared their various implementations. To better compare the performance of each application, we also chose a few non-modular approaches for the completeness of the comparisons. We hope this review and the added benefit of NMN’s explainability attract more researchers to solve the current challenges.},
  archive      = {J_NEUCOM},
  author       = {Homa Fashandi},
  doi          = {10.1016/j.neucom.2023.126518},
  journal      = {Neurocomputing},
  pages        = {126518},
  shortjournal = {Neurocomputing},
  title        = {Neural module networks: A review},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental specialized and specialized-generalized matrix
factorization models based on adaptive learning rate optimizers.
<em>NEUCOM</em>, <em>552</em>, 126515. (<a
href="https://doi.org/10.1016/j.neucom.2023.126515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems suggest items that are likely to be preferred by a particular user based on historical behavior, actions, and feedback. In real-world applications, data on users and items are continuously generated at a fast pace, such as in e-commerce, social media, digital marketing, and content consumption applications. Since interactions occur over time, these scenarios can be formulated as a data stream where users’ interests are potentially dynamic, i.e., they change over time. Given that changes are expected to occur, one of the current research challenges in streaming recommender systems is that models must adapt their parameters when changes occur to maintain performance. As such changes do not occur for all users and items in the stream at the same time, we consider adapting learning schemes to account for user or item identifiers and model individual parameters. Therefore, we used specialized parameters to adjust the step size for each dataset user or item. More specifically, this study proposes four specialized and specialized-generalized variants of four well-known adaptive learning rate optimizers and shows how they are combined with incremental matrix factorization methods. We tested our proposed optimization strategies on different datasets and showed that one of the proposed specialized variants, that is, InAMSGradUser, improves the RECALL and NDCG rates by up to 11.1 and 7.5 percentage points, respectively, compared to the traditional stochastic gradient descent (SGD) optimizer.},
  archive      = {J_NEUCOM},
  author       = {Antônio David Viniski and Jean Paul Barddal and Alceu de Souza Britto Jr and Humberto Vinicius Aparecido de Campos},
  doi          = {10.1016/j.neucom.2023.126515},
  journal      = {Neurocomputing},
  pages        = {126515},
  shortjournal = {Neurocomputing},
  title        = {Incremental specialized and specialized-generalized matrix factorization models based on adaptive learning rate optimizers},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge-centric effective connection network based on
muti-modal MRI for the diagnosis of alzheimer’s disease.
<em>NEUCOM</em>, <em>552</em>, 126512. (<a
href="https://doi.org/10.1016/j.neucom.2023.126512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is an irreversible neurodegenerative disease. But if AD is detected early, it can greatly reduce the severity of the disease. Functional connection networks (FCNs) can be used for the early diagnosis of AD, but they are undirected graphs and lack the description of causal information. Moreover, most of FCNs take brain regions as nodes, and few studies have been carried out focusing on the connections of the brain network. Although effective connection networks (ECNs) are digraphs, they do not reflect the causal relationships between brain connections. Therefore, we innovatively propose an edge-centric ECN (EECN) to explore the causality of the co-fluctuating connection in brain networks. Firstly, the traditional conditional Granger causality (GC) method is improved for constructing ECNs based on the suppression relationship between structural connection network (SCN) and FCN. Then based on the improved GC method, edge time series and EECNs are constructed. Finally, we perform dichotomous tasks on four stages of AD to verify the accuracy of our proposed method. The results show that this method achieves good results in six classification tasks. Finally, we present some brain connections that may be essential for early AD classification tasks. This study may have a positive impact on the application of brain networks.},
  archive      = {J_NEUCOM},
  author       = {Shunqi Zhang and Haiyan Zhao and Weiping Wang and Zhen Wang and Xiong Luo and Alexander Hramov and Jürgen Kurths},
  doi          = {10.1016/j.neucom.2023.126512},
  journal      = {Neurocomputing},
  pages        = {126512},
  shortjournal = {Neurocomputing},
  title        = {Edge-centric effective connection network based on muti-modal MRI for the diagnosis of alzheimer’s disease},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing text representations separately with entity
descriptions. <em>NEUCOM</em>, <em>552</em>, 126511. (<a
href="https://doi.org/10.1016/j.neucom.2023.126511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several studies have focused on incorporating language models with entity descriptions to facilitate the model with a better understanding of knowledge. Existing methods usually either integrate descriptions in the pre-training stage by designing description-related tasks, or in the fine-tuning stage by directly appending description strings to the original input, this paper falls into the latter group. We separate entity descriptions from the original text and process them by another lighter module. Specifically, we use the original large model to encode the original input, while the lighter module processes the entity descriptions. We also propose a layer-wise fusion strategy to deeply couple the representations of the input and descriptions. To further improve the fusion of the two representations, we explore two auxiliary tasks: the entity-description enhancement task and the entity contrastive task. Experiments on (Open Entity, FIGER, FewRel, TACRED, SST) datasets yield respective improvements of (0.9, 1.4, 0.6, 0.5, 0.3). Utilizing ChatGPT as the description embedding method holds the potential for even more promising results.},
  archive      = {J_NEUCOM},
  author       = {Qinghua Zhao and Yuxuan Lei and Qiang Wang and Zhongfeng Kang and Junfeng Liu},
  doi          = {10.1016/j.neucom.2023.126511},
  journal      = {Neurocomputing},
  pages        = {126511},
  shortjournal = {Neurocomputing},
  title        = {Enhancing text representations separately with entity descriptions},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Economic system forecasting based on temporal fusion
transformers: Multi-dimensional evaluation and cross-model comparative
analysis. <em>NEUCOM</em>, <em>552</em>, 126500. (<a
href="https://doi.org/10.1016/j.neucom.2023.126500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although helpful in reducing the uncertainty associated with economic activities, economic forecasting often suffers from low accuracy. Recognizing the high compatibility between deep learning and the nonlinear characteristics of socioeconomic systems, in this paper, we introduce state-of-the-art temporal fusion transformers (TFTs) into the field of economic system forecasting and predict the performance of the Chinese macroeconomic system. Based on an extended analysis of gross final product (GFP) and the intertemporal dynamic relationship between demand-side indicators and output indicators, we establish a scientific economic forecasting framework. To summarize the forecasting characteristics of the TFT algorithm, we compare its one-step and three-step modeling effects in forecasting output indicators with a series of representative benchmark models . According to our proposed four-dimensional evaluation system, the forecasts for China’s macroeconomic system provided by the TFT model have obvious advantages in terms of overall stability, forecasting efficiency, reduction of numerical and timing errors, direction accuracy, and turning point accuracy. The forecast results show that China’s economy faces a risk of slowing growth in the post-pandemic period.},
  archive      = {J_NEUCOM},
  author       = {Yang Han and Ying Tian and Liangliang Yu and Yuning Gao},
  doi          = {10.1016/j.neucom.2023.126500},
  journal      = {Neurocomputing},
  pages        = {126500},
  shortjournal = {Neurocomputing},
  title        = {Economic system forecasting based on temporal fusion transformers: Multi-dimensional evaluation and cross-model comparative analysis},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge-based BERT word embedding fine-tuning for emotion
recognition. <em>NEUCOM</em>, <em>552</em>, 126488. (<a
href="https://doi.org/10.1016/j.neucom.2023.126488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition has received considerable attention in recent years, with the popularity of social media. It is noted, however, that the state-of-the-art language models such as Bidirectional Encoder Representations from Transformers (BERT) may not produce the best performance in emotion recognition. We found the main cause of the problem is that the embedding of emotional words from the pre-trained BERT model may not exhibit high between-class difference and within-class similarity. While BERT model fine-tuning is a common practice when it is applied to specific tasks, this may not be practical in emotion recognition because most datasets are small and some texts are short and noisy, without containing much useful contextual information. In this paper, we propose to use the knowledge of emotion vocabulary to fine-tune embedding of emotional words. As a separate module independent of the embedding learning model, the fine-tuning model aims to produce emotional word embedding with improved within-class similarity and between-class difference. By combining the emotionally discriminative fine-tuned embedding with contextual information-rich embedding from pre-trained BERT model, the emotional features underlying the texts could be more effectively captured in the subsequent feature learning module, which in turn leads to improved emotion recognition performance. The knowledge-based word embedding fine-tuning model is tested on five datasets of emotion recognition, and the results and analysis demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zixiao Zhu and Kezhi Mao},
  doi          = {10.1016/j.neucom.2023.126488},
  journal      = {Neurocomputing},
  pages        = {126488},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-based BERT word embedding fine-tuning for emotion recognition},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). AOG-LSTM: An adaptive attention neural network for visual
storytelling. <em>NEUCOM</em>, <em>552</em>, 126486. (<a
href="https://doi.org/10.1016/j.neucom.2023.126486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual storytelling is the task of generating a related story for a given image sequence, which has received significant attention. However, using general RNNs (such as LSTM and GRU) as the decoder limit the performance of the models in this task. This is because they can not differentiate different types of information representations. In addition, optimizing the probabilities of subsequent words conditioned on the previous ground-truth sequences can cause error accumulation during inference. Moreover, the existing method of alleviating error accumulation based on replacing reference words does not take into account the different effects of each word. To address the above problems, we propose a modified neural network named AOG-LSTM and a modified training strategy named ARS, respectively. AOG-LSTM can adaptatively pay appropriate attention to different information representations within it when predicting different words. During training, ARS replaces some words in the reference sentences with model predictions similar to the existing method. However, we utilize the selection network and selection strategy to select more appropriate words for the replacement to better improve the model. Experiments on the VIST Dataset demonstrate that our model outperforms several strong baselines on the most commonly used metrics.},
  archive      = {J_NEUCOM},
  author       = {Hanqing Liu and Jiacheng Yang and Chia-Hao Chang and Wei Wang and Hai-Tao Zheng and Yong Jiang and Hui Wang and Rui Xie and Wei Wu},
  doi          = {10.1016/j.neucom.2023.126486},
  journal      = {Neurocomputing},
  pages        = {126486},
  shortjournal = {Neurocomputing},
  title        = {AOG-LSTM: An adaptive attention neural network for visual storytelling},
  volume       = {552},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual transformer with stable prior and patch-level
attention for single image dehazing. <em>NEUCOM</em>, <em>551</em>,
126535. (<a href="https://doi.org/10.1016/j.neucom.2023.126535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-image dehazing aims to recover blurred image details and improve image quality, which is a challenging ill-posed problem due to severe information degradation. In the image dehazing task, extracting local features from adjacent regions is particularly important. However, Transformer-based methods lack relative awareness of patch-level features. Furthermore, due to the sensitivity of self-attention to textcolorreddata distribution, the model suffers severe performance degradation when migrating from synthetic domain to real domain. To alleviate the above problems, we propose visual transformer with stable prior and patch-level attention (VSPPA) for image dehazing. Firstly, we propose a region-aware patch-level attention module to obtain the positional correlation between local patches and contexts, which can enhance the concentration of local patch-related features. Next, due to the instability problem caused by distribution shifts, we introduce dataset-independent prior to guide the transformer model, thereby preventing feature drift thus to improve the robustness of the model. Finally, domain-drift leads to insufficient dehazing when the model trained on synthetic data while migrates to the real environment, we come up with a introduce a patch filling strategy (PFS) for fuzzy data to narrow the domain gap and realize the generalization in real scenes. Extensive experiments show that the model achieves State-of-the-Art on the SOTS synthetic dataset and effective generalization to real-world scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jinzhe Liu and Heqiang Yuan and Zhiqiang Yuan and Li Liu and Bin Lu and Miao Yu},
  doi          = {10.1016/j.neucom.2023.126535},
  journal      = {Neurocomputing},
  pages        = {126535},
  shortjournal = {Neurocomputing},
  title        = {Visual transformer with stable prior and patch-level attention for single image dehazing},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The survey and meta-analysis of the attacks, transgressions,
countermeasures and security aspects common to the cloud, edge and IoT.
<em>NEUCOM</em>, <em>551</em>, 126533. (<a
href="https://doi.org/10.1016/j.neucom.2023.126533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing , edge computing , and Internet-of-Things - these new Internet concepts have already irreversibly changed and influenced people’s lives. The security of the three patterns must not be taken for granted, though. Similar to other emerging technologies, the cloud, edge and IoT are under constant attack. In the case of these paradigms, the potential breaches may paralyse transportation systems, business sectors or even turn out to be life-threatening. So far, there has not yet been a scientific meta-analysis of the overlap of the attacks in the cloud, edge and IoT; one that would result in constructing a concise threat catalogue as well as seeking a more universal solution which could contribute to ensuring the security of the whole ecosystem. In order to fill this substantial gap, this systematic review gathers, analyses and extracts data from a substantial number of quality scientific literature papers pertaining to the security issues of the cloud, edge and IoT, and compares the attacks in each concept in order to find the areas of overlap. Another contribution of this paper is that it constructs a catalogue of the identified attacks. In addition to this, it also suggests a number of possible solutions and countermeasures which, when applied, may contribute to safer cloud, edge and IoT alike.},
  archive      = {J_NEUCOM},
  author       = {Marek Pawlicki and Aleksandra Pawlicka and Rafał Kozik and Michał Choraś},
  doi          = {10.1016/j.neucom.2023.126533},
  journal      = {Neurocomputing},
  pages        = {126533},
  shortjournal = {Neurocomputing},
  title        = {The survey and meta-analysis of the attacks, transgressions, countermeasures and security aspects common to the cloud, edge and IoT},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private distributed online mirror descent
algorithm. <em>NEUCOM</em>, <em>551</em>, 126531. (<a
href="https://doi.org/10.1016/j.neucom.2023.126531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines a private distributed online convex optimization problem in which each agent strives to minimize the sum of objective functions while also tending to keep their individual objective functions confidential. We use differential privacy as the metric to safeguard each agent’s privacy and offer a distributed online mirror descent technique that is differentially private. We demonstrate that for strongly convex objective functions, our proposed algorithm satisfies the expected regret bound of O ln T OlnT while maintaining differential privacy , where T is the number of iterations. The established expected regret bound matches the optimal theoretical regret bound with respect to T . We further illuminate the trade-off between the extent of privacy-preserving and the expected regret bound through numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Meng Yuan and Jinlong Lei and Yiguang Hong},
  doi          = {10.1016/j.neucom.2023.126531},
  journal      = {Neurocomputing},
  pages        = {126531},
  shortjournal = {Neurocomputing},
  title        = {Differentially private distributed online mirror descent algorithm},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConCur: Self-supervised graph representation based on
contrastive learning with curriculum negative sampling. <em>NEUCOM</em>,
<em>551</em>, 126525. (<a
href="https://doi.org/10.1016/j.neucom.2023.126525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has made breakthrough advancements in graph representation learning, which encourages the representation of positive samples to be close and those of negative samples to be far away. However, existing graph contrastive learning (GCL) frameworks have made great efforts toward designing different augmentation strategies for positive samples, while randomly utilizing all other nodes as negative samples and treating them equally, completely ignoring the differences between negative samples. Moreover, almost every GCL framework replaces original graph with different augmented views, which may lead to unexpected information missing caused by randomly perturbing edges and features. To address these issues, we propose a self-supervised graph Con trastive learning framework with Cur riculum negative sampling, called ConCur , which feeds negative samples in an easy-to-hard fashion for contrastive learning by performing our proposed curriculum negative sampling strategy. More specifically, ConCur consists of two phases: Graph Augmentations and Curriculum Contrastive Training. Graph Augmentations aim at constructing positive and negative samples through different graph augmentation strategies. In the Curriculum Contrastive Training, we first utilize a triplet network to learn node representations by receiving original graph and different augmented views as input. Then, we propose a curriculum negative sampling strategy to enumerate negative samples from easy to hard for contrastive training. Finally, we utilize a unified contrastive loss to optimize node representations. Comprehensive experiments on five real-world datasets reveal that ConCur yields substantial relative encouraging results on the node classification task.},
  archive      = {J_NEUCOM},
  author       = {Rong Yan and Peng Bao},
  doi          = {10.1016/j.neucom.2023.126525},
  journal      = {Neurocomputing},
  pages        = {126525},
  shortjournal = {Neurocomputing},
  title        = {ConCur: Self-supervised graph representation based on contrastive learning with curriculum negative sampling},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving adversarial robustness of deep neural networks via
adaptive margin evolution. <em>NEUCOM</em>, <em>551</em>, 126524. (<a
href="https://doi.org/10.1016/j.neucom.2023.126524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training is the most popular and general strategy to improve Deep Neural Network (DNN) robustness against adversarial noises. Many adversarial training methods have been proposed in the past few years. However, most of these methods are highly susceptible to hyperparameters, especially the training noise upper bound. Tuning these hyperparameters is expensive and difficult for people not in the adversarial robustness research domain, which prevents adversarial training techniques from being used in many application fields. In this study, we propose a new adversarial training method, named Adaptive Margin Evolution (AME). Besides being hyperparameter-free for the user, our AME method places adversarial training samples into the optimal locations in the input space by gradually expanding the exploration range with self-adaptive and gradient-aware step sizes. We evaluate AME and the other seven well-known adversarial training methods on three common benchmark datasets (CIFAR10, SVHN, and Tiny ImageNet) under the most challenging adversarial attack: AutoAttack. The results show that: (1) On the three datasets, AME has the best overall performance; (2) On the Tiny ImageNet dataset, which is much more challenging, AME has the best performance at every noise level. Our work may pave the way for adopting adversarial training techniques in application domains where hyperparameter-free methods are preferred.},
  archive      = {J_NEUCOM},
  author       = {Linhai Ma and Liang Liang},
  doi          = {10.1016/j.neucom.2023.126524},
  journal      = {Neurocomputing},
  pages        = {126524},
  shortjournal = {Neurocomputing},
  title        = {Improving adversarial robustness of deep neural networks via adaptive margin evolution},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view clustering via label-embedded regularized NMF
with dual-graph constraints. <em>NEUCOM</em>, <em>551</em>, 126521. (<a
href="https://doi.org/10.1016/j.neucom.2023.126521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) methods have achieved remarkable performances in multi-view clustering due to their effectiveness and efficiency. To better obtain a low-dimensional common representation, the limited labels and the geometric structure of the multi-view data should be fully utilized in clustering. In this work, we introduce a novel multi-view learning approach, dubbed label-embedded regularized NMF with dual-graph constraints (LeNMF-DC), for clustering. Our proposed LeNMF-DC approach mainly utilizes matrix factorization to obtain a low-dimensional common representation of the multi-view data, in which the prior knowledge hidden in data can be fully explored. Specifically, we construct three graph regularization terms to preserve the manifold structure in the data, feature and label space, respectively. Moreover, we take advantage of the labels of the labeled samples without additional parameters. In addition, we develop an alternate iterative optimization scheme to solve the model of LeNMF-DC and then show its convergence rate. Compared with traditional multi-view clustering approaches , the labels of unlabeled samples in our proposed LeNMF-DC approach are assigned by the label constraint matrix rather than the clustering algorithm , and thus it avoids performance loss during the clustering. Experimental results on four benchmark datasets manifest that our LeNMF-DC approach can achieve superior performances than several state-of-the-art approaches in multi-view clustering.},
  archive      = {J_NEUCOM},
  author       = {Bin Li and Zhenqiu Shu and Yingbo Liu and Cunli Mao and Shengxiang Gao and Zhengtao Yu},
  doi          = {10.1016/j.neucom.2023.126521},
  journal      = {Neurocomputing},
  pages        = {126521},
  shortjournal = {Neurocomputing},
  title        = {Multi-view clustering via label-embedded regularized NMF with dual-graph constraints},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Additive autoencoder for dimension estimation.
<em>NEUCOM</em>, <em>551</em>, 126520. (<a
href="https://doi.org/10.1016/j.neucom.2023.126520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimension reduction is one of the key data transformation techniques in machine learning and knowledge discovery. It can be realized by using linear and nonlinear transformation techniques. An additive autoencoder for dimension reduction, which is composed of a serially performed bias estimation, linear trend estimation, and nonlinear residual estimation, is proposed and analyzed. Compared to the classical model, adding an explicit linear operator to the overall transformation and considering the nonlinear residual estimation in the original data dimension significantly improves the data reproduction capabilities of the proposed model. The computational experiments confirm that an autoencoder of this form, with only a shallow network to encapsulate the nonlinear behavior , is able to identify an intrinsic dimension of a dataset with low autoencoding error. This observation leads to an investigation in which shallow and deep network structures, and how they are trained, are compared. We conclude that the deeper network structures obtain lower autoencoding errors during the identification of the intrinsic dimension. However, the detected dimension does not change compared to a shallow network. As far as we know, this is the first experimental result concluding no benefit from a deep architecture compared to its shallow counterpart.},
  archive      = {J_NEUCOM},
  author       = {Tommi Kärkkäinen and Jan Hänninen},
  doi          = {10.1016/j.neucom.2023.126520},
  journal      = {Neurocomputing},
  pages        = {126520},
  shortjournal = {Neurocomputing},
  title        = {Additive autoencoder for dimension estimation},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental event detection via an improved knowledge
distillation based model. <em>NEUCOM</em>, <em>551</em>, 126519. (<a
href="https://doi.org/10.1016/j.neucom.2023.126519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event detection (ED) is of fundamental importance for many information extraction tasks. But conventional ED models require a fixed set of pre-defined event types. When an event trigger that cannot be categorized as any of these types occurs, they have to be re-trained from scratch with data from both old and new classes, so they are impractical in real life. In this paper, we propose a more realistic incremental event detection (IED) model that incrementally learns new event types at different times while not catastrophically forgetting the learned old classes. Although a knowledge distillation-based (KD-based) approach can be used to solve catastrophic forgetting, we find that conflicts arise when applying a general KD method to the IED task. Specifically, such conflicts mainly occur in two common scenarios: the first is that the triggers are labeled as a non-trigger word class in the current step, but at the same time, predicted as an old event type by the previous model (None-old class label confusion). The second is that the triggers are labeled as a new event type in the current step, but at the same time, predicted as a non-trigger word class by the previous model (None-new class label confusion). To solve the conflicts in each scenario, we generate pseudo labels and modify the distillation loss to improve the prediction accuracy on old and new classes, respectively. Comparative experiments demonstrate the effectiveness of our method, outperforming the state-of-the-art model.},
  archive      = {J_NEUCOM},
  author       = {Yi Lin and Changhua Xu and Hang Yu and Pinzhuo Tian and Xiangfeng Luo},
  doi          = {10.1016/j.neucom.2023.126519},
  journal      = {Neurocomputing},
  pages        = {126519},
  shortjournal = {Neurocomputing},
  title        = {Incremental event detection via an improved knowledge distillation based model},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularized boosting with an increasing coefficient
magnitude stop criterion as meta-learner in hyperparameter optimization
stacking ensemble. <em>NEUCOM</em>, <em>551</em>, 126516. (<a
href="https://doi.org/10.1016/j.neucom.2023.126516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperparameter Optimization (HPO) aims to tune hyperparameters for a system in order to improve the predictive performance . Typically, only the hyperparameter configuration with the best performance is chosen after performing several trials. However, some works try to take advantage of the effort made when training all the models with every hyperparameter configuration trial and, instead of discarding all but one, they propose performing an ensemble of all the models. However, this ensemble consists of simply averaging the model predictions or weighting the models by a certain probability. Recently, some of the so-called Automated Machine Learning (AutoML) frameworks have included other more sophisticated ensemble strategies, such as the Caruana method or the stacking strategy. On the one hand, the Caruana method has been shown to perform well in HPO ensemble, since it is not affected by the issues caused by multicollinearity, which is prevalent in HPO. It just computes the average over a subset of predictions, previously chosen through a forward stepwise selection with replacement. But it does not benefit from the generalization power of a learning process. On the other hand, stacking approaches include a learning procedure since a meta-learner is required to perform the ensemble. Yet, one hardly finds advice about which meta-learner can be adequate. Besides, some possible meta-learners may suffer from problems caused by multicollinearity or need to be tuned in order to mitigate or reduce this obstacle. In an attempt to reduce this lack of advice, this paper exhaustively explores possible meta-learners for stacking ensemble in HPO, free of hyperparameter tuning and able to mitigate the problems derived from multicollinearity as well as taking advantage of the generalization power that a learning process may include in the ensemble. Particularly, the boosting strategy shows promise in this context as a stacking meta-learner, since it satisfies the required conditions. In addition, boosting is even able to completely remove the effects of multicollinearity. This paper provides advice on how to use boosting as a meta-learner in the stacking ensemble. In any case, its main contribution is to propose an implicit regularization in the classical boosting algorithm and a novel non-parametric stop criterion suitable only for boosting and specifically designed for the HPO context. The existing synergy between these two improvements performed over boosting exhibits competitive and promising predictive power performance as a stacking meta-learner in HPO compared to other existing meta-learners and ensemble approaches for HPO other than the stacking ensemble.},
  archive      = {J_NEUCOM},
  author       = {Laura Fdez-Díaz and José Ramón Quevedo and Elena Montañés},
  doi          = {10.1016/j.neucom.2023.126516},
  journal      = {Neurocomputing},
  pages        = {126516},
  shortjournal = {Neurocomputing},
  title        = {Regularized boosting with an increasing coefficient magnitude stop criterion as meta-learner in hyperparameter optimization stacking ensemble},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification and generation of real-world data with an
associative memory model. <em>NEUCOM</em>, <em>551</em>, 126514. (<a
href="https://doi.org/10.1016/j.neucom.2023.126514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drawing from memory the face of a friend you have not seen in years is a difficult task. However, if you happen to cross paths, you would easily recognize each other. The biological memory is equipped with an impressive compression algorithm that can store the essential, and then infer the details to match perception. The Willshaw Memory is a simple abstract model for cortical computations which implements mechanisms of biological memories. Using our recently proposed sparse coding prescription for visual patterns [34] , this model can store and retrieve an impressive amount of real-world data in a fault-tolerant manner. In this paper, we extend the capabilities of the basic Associative Memory Model by using a Multiple-Modality framework. In this setting, the memory stores several modalities (e.g., visual, or textual) of each pattern simultaneously. After training, the memory can be used to infer missing modalities when just a subset is perceived. Using a simple encoder-memory-decoder architecture, and a newly proposed iterative retrieval algorithm for the Willshaw Model, we perform experiments on the MNIST dataset. By storing both the images and labels as modalities, a single Memory can be used not only to retrieve and complete patterns but also to classify and generate new ones. We further discuss how this model could be used for other learning tasks, thus serving as a biologically-inspired framework for learning.},
  archive      = {J_NEUCOM},
  author       = {Rodrigo Simas and Luis Sa-Couto and Andreas Wichert},
  doi          = {10.1016/j.neucom.2023.126514},
  journal      = {Neurocomputing},
  pages        = {126514},
  shortjournal = {Neurocomputing},
  title        = {Classification and generation of real-world data with an associative memory model},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Abnormal discharge detection using adaptive neuro-fuzzy
inference method with probability density-based feature and modified
subtractive clustering. <em>NEUCOM</em>, <em>551</em>, 126513. (<a
href="https://doi.org/10.1016/j.neucom.2023.126513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal discharge (AD) is a discharge mode in electroencephalogram (EEG) with sharp outlines. Lack of related open-access datasets and insufficient annotation hamper the development of AD detection, while cognitive neuroscience , clinical research and pilots’ neural screening demand stable and reliable AD detection methods. An adaptive neuro-fuzzy inference method for AD detection is proposed in this work. First, a probability-density-based (PD) method is proposed to extract lognormal amplitude features from EEG envelopes. Second, the subtractive clustering method (SCM) is modified so that clustering radii can adapt to cluster shapes for each dimension instead of using identical radii for each cluster. The outputs of modified SCM (mSCM), coordinates of cluster centers and adjusting rates for radius components are used to automatically initialize Gaussian membership functions of adaptive-network-based fuzzy inference system (ANFIS). Finally, we conducted multiple experiments to validate mSCM-based ANFIS, comparing it with traditional machine learning classifiers (support vector machines, multi-layer perceptrons, decision trees , and random forests) and the state-of-the-art deep learning-based time-series classification methods InceptionTime and Minirocket, using synthetic data, small-size datasets and a private EEG dataset. Results show that combining PD features with features proposed in previous studies, such as smoothed nonlinear energy operator features and discrete wavelet transform features, achieved higher accuracy (95.13 ± 0.86\%) and recall (89.17 ± 3.06\%) than other feature combinations. mSCM created more suitable cluster boundaries than SCM on small-size datasets, and its clustering results demonstrated potential in helping interpretation of classification rules built in the ANFIS network. Results of comparison experiments showed that mSCM-based ANFIS produced competitive results in accuracy and recall for AD detection, with lower computational cost, compared to the top 2 results obtained by InceptionTime and Minrocket.},
  archive      = {J_NEUCOM},
  author       = {Guanhao Liang and Haotian Liao and Zhaoyang Huang and Xiaoli Li},
  doi          = {10.1016/j.neucom.2023.126513},
  journal      = {Neurocomputing},
  pages        = {126513},
  shortjournal = {Neurocomputing},
  title        = {Abnormal discharge detection using adaptive neuro-fuzzy inference method with probability density-based feature and modified subtractive clustering},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepInfusion: A dynamic infusion based-neuro-symbolic AI
model for segmentation of intracranial aneurysms. <em>NEUCOM</em>,
<em>551</em>, 126510. (<a
href="https://doi.org/10.1016/j.neucom.2023.126510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and segmentation of cerebral aneurysms is a crucial step in the development of a clinical decision support system for estimating aneurysm rupture risk. However, accurately identifying and segmenting regions of interest in two-dimensional (2D) medical images is often challenging, particularly when using deep learning (DL) methods on small datasets with limited annotated data. The accuracy of DL approaches is often affected by the availability of large, annotated training datasets that are required for effective deep learning. Additionally, when using DL to differentiate aneurysms from arterial loops in 2D DSA images, DL can fail to detect aneurysms in areas where dye concentration is low. To address these issues and enhance the reliability and accuracy of aneurysm detection and segmentation methods , incorporating medical expert-advised, hand-crafted features can provide a clinical perspective to DL methods. This approach can help to improve the performance of DL methods by providing additional information that is not captured in the data. To this end, a novel Neuro-symbolic AI-based DeepInfusion model is proposed which allows for the infusion of human intellect through hand-crafted features into deep neural networks (DNNs), thus combining the strengths of DL with the knowledge and expertise of medical professionals. The proposed approach includes a novel technique for dynamic layer selection and feature weight adjustment during the model infusion process. The performance of the DeepInfusion model is evaluated on an in-house prepared dataset of 409 DSA images, and experimental results demonstrate the effectiveness of the proposed method for the segmentation of cerebral aneurysms . The model achieves an IOU score of 96.76\% and an F1-score of 94.15\% on unseen DSA images. The model is also tested on two publicly available datasets of Kvasir-SEG polyp and DRIVE for vessel segmentation of retinal images. The results show a significant improvement compared to existing methods, which indicates the generalizability of the approach in medical segmentation. The complete code for DeepInfusion is available on our GitHub repository at https://github.com/smileslab/deep-infusion/blob/main/deepinfusion.ipynb .},
  archive      = {J_NEUCOM},
  author       = {Iram Abdullah and Ali Javed and Khalid Mahmood Malik and Ghaus Malik},
  doi          = {10.1016/j.neucom.2023.126510},
  journal      = {Neurocomputing},
  pages        = {126510},
  shortjournal = {Neurocomputing},
  title        = {DeepInfusion: A dynamic infusion based-neuro-symbolic AI model for segmentation of intracranial aneurysms},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drug-target interactions prediction based on network
topology feature representation embedded deep forest. <em>NEUCOM</em>,
<em>551</em>, 126509. (<a
href="https://doi.org/10.1016/j.neucom.2023.126509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying drug-target interactions (DTIs) is instructive in drug design and disease treatment. Existing studies typically used the properties of nodes (drug chemical structure and protein sequence) to construct drug and target features while ignoring the influence of network topology information on the prediction of DTIs. In this study, a hybrid computation model is proposed to predict DTIs based on the network topological feature representation embedded the deep forest model (NTFRDF). The main idea is to capture the topological differences by learning the low-dimensional feature representation of drugs and targets from the heterogeneous network . In addition, the multi-similarity fusion strategy is proposed to mine hidden useful information in the known DTIs from multi-view to enrich network features of the heterogeneous network . Based on the deep forest framework, the performance of the proposed method is examined on four benchmark datasets. Our experimental results verify that the proposed method is competitive compared with some existing DTIs prediction models.},
  archive      = {J_NEUCOM},
  author       = {Majun Lian and Xinjie Wang and Wenli Du},
  doi          = {10.1016/j.neucom.2023.126509},
  journal      = {Neurocomputing},
  pages        = {126509},
  shortjournal = {Neurocomputing},
  title        = {Drug-target interactions prediction based on network topology feature representation embedded deep forest},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge-based adaptive secure consensus for nonlinear
multiagent systems with communication link attacks. <em>NEUCOM</em>,
<em>551</em>, 126505. (<a
href="https://doi.org/10.1016/j.neucom.2023.126505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully distributed secure consensus control of nonlinear multiagent systems under communication link attacks is achieved, where the design criteria are independent of the Laplacian matrix related to the communication topology and its corresponding eigenvalues. Firstly, this article proposes an edge-based fully distributed adaptive protocol for leaderless nonlinear multiagent systems with communication link attacks to achieve secure consensus control, where the interaction strengths between neighboring agents are adaptively adjusted on the foundation of the transmitted relative states to counteract influences of communication link attacks. Then, the problem of secure consensus control for leaderless nonlinear multiagent systems with communication link attacks is transformed into the stability of secure consensus error systems, and sufficient conditions for leaderless nonlinear multiagent systems achieving fully distributed secure consensus control are given. Furthermore, main results for leaderless nonlinear multiagent systems are extended to leader-following cases. Finally, theoretical results are verified by two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Miao Zhao and Jianxiang Xi and Le Wang and Kehan Xia and Yuanshi Zheng},
  doi          = {10.1016/j.neucom.2023.126505},
  journal      = {Neurocomputing},
  pages        = {126505},
  shortjournal = {Neurocomputing},
  title        = {Edge-based adaptive secure consensus for nonlinear multiagent systems with communication link attacks},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simplified reinforcement learning control algorithm for
p-norm multiagent systems with full-state constraints. <em>NEUCOM</em>,
<em>551</em>, 126504. (<a
href="https://doi.org/10.1016/j.neucom.2023.126504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the bipartite consensus tracking control problem with full-state constraints for p-norm multiagent systems. For the full-state constraints problem of p-norm multiagent systems, a transformed function is utilized to achieve the objective of the constraints, which has the property of low complexity because it avoids the intervention of log-type functions or trigonometric functions in the controllers. Meanwhile, the bipartite control performance of p-norm multiagent systems is also guaranteed. Moreover, under the simplified reinforcement learning framework, a compensation strategy is utilized to compensate the unknown ideal weights caused by the simplified reinforcement learning algorithm of critic-actor method, and greatly improve the accuracy of the tracking performance for p-norm multiagent systems. Furthermore, the effectiveness of the proposed strategy is illustrated by an actual simulation.},
  archive      = {J_NEUCOM},
  author       = {Min Wang and Liang Cao and Hongjing Liang and Wenbin Xiao},
  doi          = {10.1016/j.neucom.2023.126504},
  journal      = {Neurocomputing},
  pages        = {126504},
  shortjournal = {Neurocomputing},
  title        = {Simplified reinforcement learning control algorithm for p-norm multiagent systems with full-state constraints},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multistability of switched complex-valued neural networks
with state-dependent switching rules. <em>NEUCOM</em>, <em>551</em>,
126499. (<a href="https://doi.org/10.1016/j.neucom.2023.126499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper focuses on the multistability problems of the switched complex-valued neural networks with state-dependent switching rules. Based on the differential inclusions theory and fixed point theorem , several sufficient conditions are derived to ascertain that there exist 25 n 25n equilibria, 9 n 9n of which are locally ex for n -neuron switched complex-valued neural networks . The number of stable equilibria of an n -neuron switched complex-valued neural network increases significantly from 4 n 4n to 9 n 9n compared with the conventional complex-valued neural networks. Finally, four numerical examples are presented to substantiate the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Shiqin Ou and Zhenyuan Guo and Jingxuan Ci and Shuqing Gong and Shiping Wen},
  doi          = {10.1016/j.neucom.2023.126499},
  journal      = {Neurocomputing},
  pages        = {126499},
  shortjournal = {Neurocomputing},
  title        = {Multistability of switched complex-valued neural networks with state-dependent switching rules},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised progressive dehazing network using unlabeled
contrastive guidance. <em>NEUCOM</em>, <em>551</em>, 126494. (<a
href="https://doi.org/10.1016/j.neucom.2023.126494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image dehazing aims to restore the missing high-quality content from its original hazy observation. Most of the existing learning-based methods achieve promising achievements by designing various networks. However, these approaches cannot generalize well on real-world scenes, since they fail to exploit natural haze priors. Towards this end, we propose a novel Semi-supervised Progressive Dehazing Network (Semi-PDNet), which leverages both synthetic and real-world images in training process. The overall network follows a progressive architecture, and can be divided into three core stages: image encode stage (IES), feature enhance stage (FES) and hierarchical reconstruction stage (HRS). Specifically, IES is responsible for encoding shallow features from the corrupted hazy image. Then, our FES tries to distill finer local and global features via the well-designed dual stream attentive block (DSAB). The HRS is to estimate semantic and contextual information based on a hierarchical structure, and accurately reconstructs the final clear image. This stage-by-stage paradigm can make full use of informative features from shallow to deep, thus facilitating network for better haze removal. Furthermore, we utilize an unlabeled contrastive guidance (UCG) to bridge the domain gap between synthetic and real-world images. Extensive experimental comparisons show that our Semi-PDNet can obtain comparable results with other state-of-the-art dehazing algorithms.},
  archive      = {J_NEUCOM},
  author       = {Weichao Yi and Liquan Dong and Ming Liu and Mei Hui and Lingqin Kong and Yuejin Zhao},
  doi          = {10.1016/j.neucom.2023.126494},
  journal      = {Neurocomputing},
  pages        = {126494},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised progressive dehazing network using unlabeled contrastive guidance},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GCL: Contrastive learning instead of graph convolution for
node classification. <em>NEUCOM</em>, <em>551</em>, 126491. (<a
href="https://doi.org/10.1016/j.neucom.2023.126491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning as an effective representation learning technique has attracted tremendous attention due to its general success in downstream tasks. However, the theoretical explanations and quantitative experimental analyses of its generalization ability are still limited. These issues are pivotal yet challenging for improving both the interpretability and performance of contrastive learning. To address these issues, we first re-examine the least squares bias-variance decomposition and successfully derive GCL, a novel bias-variance decomposition with two optional generalized biases and one generalized variance. GCL is shown to be extendable to common contrastive learning models so that it can be utilized as a unified contrastive learning framework. Meanwhile, a surprising finding that the gradient descent of contrastive loss concerning feature representation is closely related to the message passing mechanism (graph convolution) of Graph Neural Networks (GNNs). The contrastive learning model called GCP is then proposed as a convincing implementation of GCL. GCP has a pure MLP-based structure and employs a conventional cross-entropy to reduce the bias between predictions and ground truth labels, two optional contrastive losses to optimize the variance of the model. Finally, extensive experiments demonstrate that the two biases proposed by GCL have their own merits; GCP achieves comparable or even better performance than GNNs in a more efficient and robust manner, its bias and variance meet the bias-variance tradeoff to some extent.},
  archive      = {J_NEUCOM},
  author       = {Shu Li and Lixin Han and Yang Wang and YongLin Pu and Jun Zhu and Jingxian Li},
  doi          = {10.1016/j.neucom.2023.126491},
  journal      = {Neurocomputing},
  pages        = {126491},
  shortjournal = {Neurocomputing},
  title        = {GCL: Contrastive learning instead of graph convolution for node classification},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Precise crop classification of UAV hyperspectral imagery
using kernel tensor slice sparse coding based classifier.
<em>NEUCOM</em>, <em>551</em>, 126487. (<a
href="https://doi.org/10.1016/j.neucom.2023.126487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise crop classification plays a significant role in the agriculture field. An appropriate data source for precise crop classification is high spatial resolutions hyperspectral imagery (H2 imagery) acquired by unmanned aerial vehicle (UAV). However, for imagery with many different classes of crops, crop classification of UAV H2 imagery is a huge challenge. The significant spectral diversity, spatial heterogeneity and nonlinear data structure of UAV H2 imagery results in poor spectral discriminability. To improve the discriminability, a kernel tensor slice sparse coding-based classifier (KTSSCC) is proposed for precise crop classification of UAV H2 imagery in this research. The kernel tensor representation mechanism in KTSSCC can reduce the nonlinear separation while well preserving the spectral characteristics and spatial constraints of land-covers, and thus the discriminability is greatly improved. Furthermore, this paper puts forward the kernel tensor slice sparse orthogonal matching pursuit (KTSSOMP) algorithm to optimize kernel tensor slice sparse coding in the spectral space, which greatly reduces the computation cost. Moreover, there are very few parameters to be tuned in our proposed model. We assess the performance of KTSSCC on two real UAV hyperspectral imagery datasets, and find that, based on visual and quantitative results, it provides satisfactory crop classification results and outperforms the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Lixia Yang and Jinwei Chen and Rui Zhang and Shuyuan Yang and Xinyu Zhang and Licheng Jiao},
  doi          = {10.1016/j.neucom.2023.126487},
  journal      = {Neurocomputing},
  pages        = {126487},
  shortjournal = {Neurocomputing},
  title        = {Precise crop classification of UAV hyperspectral imagery using kernel tensor slice sparse coding based classifier},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ice hockey puck tracking through broadcast video.
<em>NEUCOM</em>, <em>551</em>, 126484. (<a
href="https://doi.org/10.1016/j.neucom.2023.126484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ice-hockey puck tracking is a non-trivial task in hockey video analysis as it highlights the puck in the video for broadcasting, tactical play analysis, or referee assisting. However, difficulties, such as high speed, low texture features in images and constantly changing shape, make well-developed object tracker fail to track the puck. This paper introduces a real-time online-learning ice hockey puck detection and tracking system solely depending on video input to tackle this problem. The proposed approach categorizes pucks into free-moving and control-moving states, using a combination of contour fitting, correlation filter, and motion estimation techniques to detect and track them. A thorough analysis is performed focusing on the tracking scenario using broadcast video. To our knowledge, this is the first approach addressing detection and tracking nearly invisible high-speed pucks when shooting actions take place. Experiments with a comparison between a previous work targeting puck tracking show promising results in detection and tracking the ice hockey puck through broadcast video.},
  archive      = {J_NEUCOM},
  author       = {Muyu Li and Henan Hu and Hong Yan},
  doi          = {10.1016/j.neucom.2023.126484},
  journal      = {Neurocomputing},
  pages        = {126484},
  shortjournal = {Neurocomputing},
  title        = {Ice hockey puck tracking through broadcast video},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid trilinear and bilinear programming for aligning
partially overlapping point sets. <em>NEUCOM</em>, <em>551</em>, 126482.
(<a href="https://doi.org/10.1016/j.neucom.2023.126482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications, we need algorithms which can align partially overlapping point sets and are invariant to the corresponding transformations. In this work, a method possessing such properties is realized by minimizing the objective of the robust point matching (RPM) algorithm. We first show that the RPM objective is a cubic polynomial. We then utilize the convex envelopes of trilinear and bilinear monomials to derive its lower bound function. The resulting lower bound problem has the merit that it can be efficiently solved via linear assignment and low dimensional convex quadratic programming . We next develop a branch-and-bound (BnB) algorithm which only branches over the transformation variables and runs efficiently. Experimental results demonstrated better robustness of the proposed method against non-rigid deformation, positional noise and outliers in case that outliers are not mixed with inliers when compared with the state-of-the-art approaches. They also showed that it has competitive efficiency and scales well with problem size.},
  archive      = {J_NEUCOM},
  author       = {Wei Lian and Wangmeng Zuo},
  doi          = {10.1016/j.neucom.2023.126482},
  journal      = {Neurocomputing},
  pages        = {126482},
  shortjournal = {Neurocomputing},
  title        = {Hybrid trilinear and bilinear programming for aligning partially overlapping point sets},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Protecting by attacking: A personal information protecting
method with cross-modal adversarial examples. <em>NEUCOM</em>,
<em>551</em>, 126481. (<a
href="https://doi.org/10.1016/j.neucom.2023.126481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years’ development of AI technology brings more convenience to our life while at the same time increasing the risk of personal information leakage. In this work, we try to protect personal information contained in the images by generating adversarial examples to fool the image captioning models. The generated adversarial examples are user-oriented which means the users can manipulate or hide sensitive information on the text output as they wish. By doing so, our personal information can be well protected from image captioning models. To fulfill the task, we adopt five kinds of adversarial attack. Experimental results show our method can successfully protect user security. The Pytorch® implementations can be downloaded from an open-source GitHub project (https://github.com/Dlut-lab-zmn/Image-Captioning-Attack/).},
  archive      = {J_NEUCOM},
  author       = {Mengnan Zhao and Bo Wang and Weikuo Guo and Wei Wang},
  doi          = {10.1016/j.neucom.2023.126481},
  journal      = {Neurocomputing},
  pages        = {126481},
  shortjournal = {Neurocomputing},
  title        = {Protecting by attacking: A personal information protecting method with cross-modal adversarial examples},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boosted local dimensional mutation and all-dimensional
neighborhood slime mould algorithm for feature selection.
<em>NEUCOM</em>, <em>551</em>, 126467. (<a
href="https://doi.org/10.1016/j.neucom.2023.126467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The slime mould algorithm (SMA) is a population-based optimization algorithm that mimics the foraging behavior of slime moulds with a simple structure and few hyperparameters. However, SMA has some limitations, such as getting trapped in local optima when dealing with multimodal or combinatorial functions. To overcome these limitations and improve the algorithm&#39;s exploration and exploitation abilities, a local dimensional mutation strategy and an all-dimensional neighborhood search strategy for SMA, known as LASMA, were introduced. To evaluate the performance of LASMA, experiments were conducted on 30 benchmark functions from the CEC2014 competition, and the results were compared with up to 27 peers. The experimental results were then synthesized, and the Wilcoxon signed-rank test was used to evaluate the performance of LASMA. The results showed that LASMA outperformed other algorithms in terms of solution accuracy, stability, and convergence speed, with at least a 53.3\% improvement in optimization performance on the 30 tested functions. Moreover, to demonstrate the applicability of LASMA to feature selection problems, a binary version of LASMA called bLASMA was developed and compared with eight binary classification algorithms on 18 datasets from the UCI repository. The experimental results showed that bLASMA not only had faster convergence speed and higher convergence accuracy in handling optimization problems but also performed well in feature selection applications. Thus, LASMA is a promising optimization tool for handling global and binary optimization problems , and its binary version, bLASMA, can be used for feature selection tasks. By addressing the limitations of SMA and improving the algorithm&#39;s exploration and exploitation abilities, LASMA provides a robust and effective solution for various optimization problems.},
  archive      = {J_NEUCOM},
  author       = {Xinsen Zhou and Yi Chen and Zongda Wu and Ali Asghar Heidari and Huiling Chen and Eatedal Alabdulkreem and José Escorcia-Gutierrez and Xianchuan Wang},
  doi          = {10.1016/j.neucom.2023.126467},
  journal      = {Neurocomputing},
  pages        = {126467},
  shortjournal = {Neurocomputing},
  title        = {Boosted local dimensional mutation and all-dimensional neighborhood slime mould algorithm for feature selection},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fusing sentiment knowledge and inter-aspect dependency based
on gated mechanism for aspect-level sentiment classification.
<em>NEUCOM</em>, <em>551</em>, 126462. (<a
href="https://doi.org/10.1016/j.neucom.2023.126462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect level sentiment classification is a fine-grained sentiment analysis task that aims to identify the sentiment polarity of one or more given aspects in a sentence. In natural language, words frequently carry certain sentimental tendencies, which can be beneficial in obtaining the features between aspects and contexts. On the other hand, the dependencies between different aspects in a sentence can provide sufficient information for the sentiment polarity discrimination of a target aspect. However, existing models tend to focus on sentiment knowledge or aspect interactions individually without leveraging their converged information. Therefore, we propose a model based on G ated M echanism F using S entiment K nowledge and I nter- A spect dependency (GMF-SKIA) for Aspect-level Sentiment Classification in this paper, aiming to dynamically fuse sentiment knowledge information of words and inter-aspect dependency. Specifically, the model uses the SenticNet sentiment dictionary to add sentiment knowledge information to words during dependency tree construction, and then we introduce a graph convolutional network to obtain sentiment information of dependency tree. We utilize an aspect-related multiheaded self-attention mechanism to model the inter-aspect interactions. Moreover, we design an information gate based on gated mechanism to fuse sentiment knowledge and inter-aspect features. We performed experiments on four publicly available datasets, our model outperforms the best benchmark model by an average of 2.1\%\% and achieves the highest accuracy of 91.56\%\% on the Rest16 dataset.},
  archive      = {J_NEUCOM},
  author       = {Yu Han and Xiaotang Zhou and Guishen Wang and Yuncong Feng and Hui Zhao and Junhua Wang},
  doi          = {10.1016/j.neucom.2023.126462},
  journal      = {Neurocomputing},
  pages        = {126462},
  shortjournal = {Neurocomputing},
  title        = {Fusing sentiment knowledge and inter-aspect dependency based on gated mechanism for aspect-level sentiment classification},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed representation learning with skip-gram model for
trained random forests. <em>NEUCOM</em>, <em>551</em>, 126434. (<a
href="https://doi.org/10.1016/j.neucom.2023.126434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random forest family has been extensively studied due to its wide applications in machine learning and data analytics . However, the representation abilities of forests have not been explored yet. The existing forest representation is mainly based on feature hashing on the indices of leaf nodes. Feature hashing typically disregards the information from tree structures, i.e., the relationships between leaf nodes. Furthermore, the visualisation abilities of feature hashing are limited. On the contrary, the Skip-Gram model has been widely explored in word and node embedding due to its excellent representation ability. This paper proposes distributed representation learning for trained forests (DRL-TF) to extract co-occurrence relationships of samples and tree structures, and further boost the representation abilities of the trained forest using the Skip-Gram model. The experimental results demonstrate that the proposed DRL-TF outperforms the challenging baselines. To the best of the authors’ knowledge, the visualisation by DRL-TF is the first tool to analyse the trained forests. The code is available at: https://github.com/machao199271/DRL-TF.},
  archive      = {J_NEUCOM},
  author       = {Chao Ma and Tianjun Wang and Le Zhang and Zhiguang Cao and Yue Huang and Xinghao Ding},
  doi          = {10.1016/j.neucom.2023.126434},
  journal      = {Neurocomputing},
  pages        = {126434},
  shortjournal = {Neurocomputing},
  title        = {Distributed representation learning with skip-gram model for trained random forests},
  volume       = {551},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Magnum: Tackling high-dimensional structures with
self-organization. <em>NEUCOM</em>, <em>550</em>, 126508. (<a
href="https://doi.org/10.1016/j.neucom.2023.126508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A big challenge in dealing with real-world problems is scalability. In fact, this is partially the reason behind the success of deep learning over other learning paradigms. Here, we tackle the scalability of a novel learning paradigm proposed in 2021 based solely on self-organizing principles. This paradigm consists of only dynamical equations which self-organize with the input to create attractor-repeller points that are related to the patterns found in data. To achieve scalability for such a system, we propose the Magnum algorithm, which utilizes many self-organizing subsystems (Inertia-SyncMap) each with subsets of the problem’s variables. The main idea is that by merging Inertia-SyncMaps, Magnum builds over time a variable correlation by consensus, capable of accurately predicting the structure of large groups of variables. Experiments show that Magnum surpasses or ties with other unsupervised algorithms in all of the high-dimensional chunking problems, each with distinct types of shapes and structural features. Moreover, Inertia-SyncMap alone outperforms or ties with other unsupervised algorithms in six out of seven basic chunking problems. Thus, this work sheds light on how self-organization learning paradigms can be scaled up to deal with high-dimensional structures and compete with current learning paradigms.},
  archive      = {J_NEUCOM},
  author       = {Poyuan Mao and Yikfoong Tham and Heng Zhang and Danilo Vasconcellos Vargas},
  doi          = {10.1016/j.neucom.2023.126508},
  journal      = {Neurocomputing},
  pages        = {126508},
  shortjournal = {Neurocomputing},
  title        = {Magnum: Tackling high-dimensional structures with self-organization},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating cooperative-competitive dynamics with deep
q-learning. <em>NEUCOM</em>, <em>550</em>, 126507. (<a
href="https://doi.org/10.1016/j.neucom.2023.126507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model cooperative-competitive social group dynamics with multi-agent environments, specialized in cases with a large number of agents from only a few distinct types. The multi-agent optimization problems are addressed in turn with multi-agent reinforcement learning algorithms to obtain flexible and robust solutions. We analyze the effectiveness of centralized and decentralized algorithms using three variants of deep Q-networks on these cooperative-competitive environments: first, we use the decentralized training independent learning with deep Q-networks, secondly the centralized monotonic value factorizations for deep learning , and lastly the multi-agent variational exploration. We test the algorithms in simulated predator–prey multi-agent environments in two distinct environments: the adversary pursuit and simple tag . The experiments highlight the performance of the different deep Q-learning methods, and we conclude that decentralized training of deep Q-networks accumulates higher episode rewards during training and evaluation in comparison with the selected centralized learning approaches.},
  archive      = {J_NEUCOM},
  author       = {Anikó Kopacz and Lehel Csató and Camelia Chira},
  doi          = {10.1016/j.neucom.2023.126507},
  journal      = {Neurocomputing},
  pages        = {126507},
  shortjournal = {Neurocomputing},
  title        = {Evaluating cooperative-competitive dynamics with deep Q-learning},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Addressing heterophily in node classification with graph
echo state networks. <em>NEUCOM</em>, <em>550</em>, 126506. (<a
href="https://doi.org/10.1016/j.neucom.2023.126506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node classification tasks on graphs are addressed via fully-trained deep message-passing models that learn a hierarchy of node representations via multiple aggregations of a node’s neighbourhood. While effective on graphs that exhibit a high ratio of intra-class edges, this approach poses challenges in the opposite case, i.e. heterophily, where nodes belonging to the same class are usually further apart. In graphs with a high degree of heterophily, the smoothed representations based on close neighbours computed by convolutional models are no longer effective. So far, architectural variations in message-passing models to reduce excessive smoothing or rewiring the input graph to improve longer-range message passing have been proposed. In this paper, we address the challenges of heterophilic graphs with Graph Echo State Network (GESN) for node classification. GESN is a reservoir computing model for graphs, where node embeddings are recursively computed by an untrained message-passing function. Our experiments show that reservoir models are able to achieve better or comparable accuracy with respect to most fully trained deep models that implement ad hoc variations in the architectural bias or perform rewiring as a preprocessing step on the input graph, with an improvement in terms of efficiency/accuracy trade-off. Furthermore, our analysis shows that GESN is able to effectively encode the structural relationships of a graph node, by showing a correlation between iterations of the recursive embedding function and the distribution of shortest paths in a graph.},
  archive      = {J_NEUCOM},
  author       = {Alessio Micheli and Domenico Tortorella},
  doi          = {10.1016/j.neucom.2023.126506},
  journal      = {Neurocomputing},
  pages        = {126506},
  shortjournal = {Neurocomputing},
  title        = {Addressing heterophily in node classification with graph echo state networks},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Barycentric coordinate-based distributed localization for
wireless sensor networks subject to random lossy links. <em>NEUCOM</em>,
<em>550</em>, 126503. (<a
href="https://doi.org/10.1016/j.neucom.2023.126503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed localization in wireless sensor networks is essential for verifying the positions of the sensor nodes deployed in the sensing field based on information interactions. However, the information transmitted from the controller to the actuator for each sensor node may be lost owing to communication noise, channel interference , or network congestion . With this in mind, this paper aims at investigating the distributed localization for wireless sensor networks subject to random lossy links. The barycentric coordinate , which can be determined by the distance measurements between node pairs in the network, is used as the basic scheme for range-based localization. First, based on the characterization of random link loss in wireless sensor networks with a Bernoulli random variable, a distributed iterative localization algorithm is proposed. And then, the global convergence of the proposed localization algorithm which ensures accurate localization is theoretically proved by using the convergence of sub-stochastic matrices’ product. Finally, numerical examples are conducted to illustrate the effectiveness of the proposed localization algorithm.},
  archive      = {J_NEUCOM},
  author       = {Ya Wang and Lei Shi and Xinming Chen and Jinliang Shao and Yuhua Cheng and Houjun Wang and Lijun Wang},
  doi          = {10.1016/j.neucom.2023.126503},
  journal      = {Neurocomputing},
  pages        = {126503},
  shortjournal = {Neurocomputing},
  title        = {Barycentric coordinate-based distributed localization for wireless sensor networks subject to random lossy links},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time stability of cohen-grossberg BAM neural networks
with impulsive perturbations. <em>NEUCOM</em>, <em>550</em>, 126501. (<a
href="https://doi.org/10.1016/j.neucom.2023.126501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article concerns the problem of fixed-time stability (FXTS) of a Cohen-Grossberg bidirectional associative memory neural network (CGBAMNN) with destabilizing impulsive effects. A novel sufficient condition for the impulsive dynamical systems (IDSs) to be FXTS for destabilizing impulses is obtained. Different from the usual Lyapunov inequality for FXTS of IDSs, we have applied a new Lyapunov inequality to obtain the results under impulsive perturbations. Based on the average impulsive interval (AII) and the comparison principle, we have derived the results of this paper. Two types of continuous controllers: one with signum terms and another without signum terms, based on a new Lyapunov inequality, FXTS of CGBAMNN have been studied. The settling-time functions obtained in this article depend on the parameters of the impulsive sequences. Finally, two numerical examples, one is a cyber-physical system with deception attacks and another is a neural network , are given to validate the efficiency of our obtained theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Md Arzoo Jamal and Rakesh Kumar and Santwana Mukhopadhyay and Oh-Min Kwon},
  doi          = {10.1016/j.neucom.2023.126501},
  journal      = {Neurocomputing},
  pages        = {126501},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time stability of cohen-grossberg BAM neural networks with impulsive perturbations},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bipartite synchronization for cooperative-competitive neural
networks with reaction–diffusion terms via dual event-triggered
mechanism. <em>NEUCOM</em>, <em>550</em>, 126498. (<a
href="https://doi.org/10.1016/j.neucom.2023.126498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pinning-like bipartite synchronization is investigated for reaction–diffusion neural networks with cooperative-competitive interactions in this paper. First, a dural event-triggered control algorithm based on the time–space sampled-data scheme is employed to further decrease the transmission resources’ consumption. Then, some sufficient conditions that guarantee the bipartite synchronization for the target neural networks with the signed graph are obtained by virtue of the Lyapunov method, Halanay’s inequalities, and the pinning control technique. Moreover, new weighted integral inequalities are introduced to get higher upper bounds than what traditional inequality produces. Finally, a numerical simulation result is given to validate the advantages of the proposed method for realizing bipartite synchronization.},
  archive      = {J_NEUCOM},
  author       = {Xiaona Song and Nana Wu and Shuai Song and Yijun Zhang and Vladimir Stojanovic},
  doi          = {10.1016/j.neucom.2023.126498},
  journal      = {Neurocomputing},
  pages        = {126498},
  shortjournal = {Neurocomputing},
  title        = {Bipartite synchronization for cooperative-competitive neural networks with reaction–diffusion terms via dual event-triggered mechanism},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stability analysis of fractional reaction-diffusion
memristor-based neural networks with neutral delays via lyapunov
functions. <em>NEUCOM</em>, <em>550</em>, 126497. (<a
href="https://doi.org/10.1016/j.neucom.2023.126497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of stability analysis for fractional neutral neural networks , it is not uncommon to encounter erroneous Lyapunov functions . To investigate the stability of fractional memristor-based neural networks with neutral delays and reaction–diffusion (FNRDMNNs), this study presents a novel modified Lyapunov–Krasovskii functions. By invoking Green’s theorem and employing inequality techniques, we derive two nonconservative criteria and a corollary through the design of two enhanced pinning controllers, ensuring the stability of FNRDMNNs. Furthermore, the contributions of this paper not only serve as refinements to existing findings but also hold broader applicability for advancing the theoretical analysis of fractional neutral-type systems. To corroborate the obtained results, we perform a series of simulations.},
  archive      = {J_NEUCOM},
  author       = {Xiang Wu and Shutang Liu and Huiyu Wang and Jie Sun and Wei Qiao},
  doi          = {10.1016/j.neucom.2023.126497},
  journal      = {Neurocomputing},
  pages        = {126497},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis of fractional reaction-diffusion memristor-based neural networks with neutral delays via lyapunov functions},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised t-SNE with multi-scale neighborhood
preservation. <em>NEUCOM</em>, <em>550</em>, 126496. (<a
href="https://doi.org/10.1016/j.neucom.2023.126496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised dimensionality reduction (DR) aims to preserve input data structure in a low-dimensional (LD) space based on neighborhood information. In contrast, supervised DR intends to improve the learning performance, i.e., classification and regression, in an LD representation. Unfortunately, obtaining the complete label outputs of a data set for real-world applications is hard. Here, we introduce a novel DR framework coupling both available class labels and input feature similarities to extend the well-known t -distributed Stochastic Neighbor Embedding (SNE) for semi-supervised scenarios. Our proposal, termed Semi-Supervised t -SNE (SS. t -SNE), properly fixes the widths of Gaussian neighborhoods to reveal the salient local and global data structures in an LD space. Indeed, our approach is presented as a generalization of unsupervised and supervised versions of t -SNE. SS. t -SNE outperforms other semi-supervised DR methods in data visualization and classification tasks in LD embeddings.},
  archive      = {J_NEUCOM},
  author       = {Walter Serna-Serna and Cyril de Bodt and Andres M. Alvarez-Meza and John A. Lee and Michel Verleysen and Alvaro A. Orozco-Gutierrez},
  doi          = {10.1016/j.neucom.2023.126496},
  journal      = {Neurocomputing},
  pages        = {126496},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised t-SNE with multi-scale neighborhood preservation},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leader–follower output consensus of multiagent systems over
finite fields. <em>NEUCOM</em>, <em>550</em>, 126495. (<a
href="https://doi.org/10.1016/j.neucom.2023.126495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the output consensus problem of leader–follower multiagent systems (MASs) over finite fields via semi-tensor product (STP). First, the leader–follower MASs over finite fields are modeled as algebraic form, based on which, the output consensus problem is transformed into the set stabilization problem about the systems with algebraic form. Second, all the output feedback control invariant sets (OFCISs) are calculated from the state feedback maximum control invariant set (SFMCIS). Third, some criteria of the output consensus as well as the design method of output feedback controller are presented by the truth matrix technique. Finally, an example is shown to demonstrate the effectiveness of the results.},
  archive      = {J_NEUCOM},
  author       = {Miao Yu and Jianwei Xia and Jun-e Feng and Shihua Fu and Hao Shen},
  doi          = {10.1016/j.neucom.2023.126495},
  journal      = {Neurocomputing},
  pages        = {126495},
  shortjournal = {Neurocomputing},
  title        = {Leader–follower output consensus of multiagent systems over finite fields},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NeuroNorm: An r package to standardize multiple structural
MRI. <em>NEUCOM</em>, <em>550</em>, 126493. (<a
href="https://doi.org/10.1016/j.neucom.2023.126493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preprocessing of structural MRI involves multiple steps to clean and standardize data before further analysis. Typically, researchers use numerous tools to create tailored preprocessing workflows that adjust to their dataset. This process hinders research reproducibility and transparency. In this paper, we introduce NeuroNorm , a robust and reproducible preprocessing pipeline that addresses the challenges of preparing structural MRI data. NeuroNorm adapts its workflow to the input datasets without manual intervention and uses state-of-the-art methods to guarantee high-standard results. We demonstrate NeuroNorm ’s strength by preprocessing hundreds of MRI scans from three different sources with specific parameters on image dimensions, voxel intensity ranges, patients characteristics, acquisition protocols and scanner type. The preprocessed images can be visually and analytically compared to each other as they share the same geometrical and intensity space. NeuroNorm supports clinicians and researchers with a robust, adaptive and comprehensible preprocessing pipeline, increasing and certifying the sensitivity and validity of subsequent analyses. NeuroNorm requires minimal user inputs and interaction, making it a user-friendly set of tools for users with basic programming experience.},
  archive      = {J_NEUCOM},
  author       = {David Payares-Garcia and Jorge Mateu and Wiebke Schick},
  doi          = {10.1016/j.neucom.2023.126493},
  journal      = {Neurocomputing},
  pages        = {126493},
  shortjournal = {Neurocomputing},
  title        = {NeuroNorm: An r package to standardize multiple structural MRI},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding contributing neurons via attribution
visualization. <em>NEUCOM</em>, <em>550</em>, 126492. (<a
href="https://doi.org/10.1016/j.neucom.2023.126492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding contributing neuron features is crucial to explaining convolutional neural network (CNN) decisions. The attribution research provides an effective way to detect contributing neuron features and numerically assign them attribution scores. However, a method to clearly and intuitively represent the implications hidden in neuron attributions is lacking. Attribution scores show the numerical importance of contributing neurons, but the meanings implied by these numerical scores are still not available. To mitigate this gap, we propose an optimization-based visualization method named attribution visualization, which enables an intuitive understanding of neuron attributions. Our approach is distinguished from existing visualization methods by its ability to produce noise-free result, i.e. , the ability to remove irrelevant regions from visualizations. We achieve this by introducing an optimizable mask into the visualization process and designing an objective function that simultaneously optimizes the area-constrained mask and visualization. Furthermore, we propose the fractal noise pyramid with diverse and natural frequency spectra as our mask perturbation technique which is key to removing unrelated noise in visualization. We implement several comparisons and user studies with other visual explanations to demonstrate the unique properties of our attribution visualization. We also apply our attribution visualization on two representative CNNs, showcasing its ability to intuitively understand contributing neuron features.},
  archive      = {J_NEUCOM},
  author       = {Rui Shi and Tianxing Li and Yasushi Yamaguchi},
  doi          = {10.1016/j.neucom.2023.126492},
  journal      = {Neurocomputing},
  pages        = {126492},
  shortjournal = {Neurocomputing},
  title        = {Understanding contributing neurons via attribution visualization},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularized spectral clustering under the mixed membership
stochastic block model. <em>NEUCOM</em>, <em>550</em>, 126490. (<a
href="https://doi.org/10.1016/j.neucom.2023.126490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed membership community detection is a challenging problem in network analysis. Previous spectral clustering algorithms for this problem are developed based on the adjacency matrix instead of regularized Laplacian matrix . To close this gap, under the popular mixed membership stochastic blockmodels (MMSB), this article proposes two efficient spectral clustering algorithms based on an application of the regularized Laplacian matrix , the Simplex Regularized Spectral Clustering (SRSC) algorithm, and the Cone Regularized Spectral Clustering (CRSC) algorithm. SRSC and CRSC are developed based on the simplex structure and the cone structure in the variants of the eigendecomposition of the regularized Laplacian matrix. We show that these two approaches SRSC and CRSC are asymptotically consistent under mild conditions by providing error bounds for the estimated membership vector of each node under MMSB. These two proposed approaches are successfully applied to synthetic and empirical networks with encouraging results compared with some benchmark methods.},
  archive      = {J_NEUCOM},
  author       = {Huan Qing and Jingli Wang},
  doi          = {10.1016/j.neucom.2023.126490},
  journal      = {Neurocomputing},
  pages        = {126490},
  shortjournal = {Neurocomputing},
  title        = {Regularized spectral clustering under the mixed membership stochastic block model},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). AED: An black-box NLP classifier model attacker.
<em>NEUCOM</em>, <em>550</em>, 126489. (<a
href="https://doi.org/10.1016/j.neucom.2023.126489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) have been successful in solving real-world tasks in domains such as connected and automated vehicles, disease, and job hiring. However, their implications are far-reaching in critical application areas. Hence, there is a growing concern regarding the potential bias and robustness of these DNN models. A transparency and robust model is always demanded in high-stakes domains where reliability and safety are enforced, such as healthcare and finance. While most studies have focused on adversarial image attack scenarios, fewer studies have investigated the robustness of DNN models in natural language processing (NLP) due to their adversarial samples are difficult to generate. To address this gap, we propose a word-level NLP classifier attack model called ”AED,” which stands for A ttention mechanism enabled post-model E xplanation with D ensity peaks clustering algorithm for synonyms search and substitution. AED aims to test the robustness of NLP DNN models by interpretability their weaknesses and exploring alternative ways to optimize them. By identifying vulnerabilities and providing explanations, AED can help improve the reliability and safety of DNN models in critical application areas such as healthcare and automated transportation. Our experiment results demonstrate that compared with other existing models, AED can effectively generate adversarial examples that can fool the victim model while maintaining the original meaning of the input.},
  archive      = {J_NEUCOM},
  author       = {Yueyang Liu and Yan Huang and Zhipeng Cai},
  doi          = {10.1016/j.neucom.2023.126489},
  journal      = {Neurocomputing},
  pages        = {126489},
  shortjournal = {Neurocomputing},
  title        = {AED: An black-box NLP classifier model attacker},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultra-low latency spiking neural networks with
spatio-temporal compression and synaptic convolutional block.
<em>NEUCOM</em>, <em>550</em>, 126485. (<a
href="https://doi.org/10.1016/j.neucom.2023.126485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs), as one of the brain-inspired models, has spatio-temporal information processing capability, low power feature, and high biological plausibility. The effective spatio-temporal feature makes it suitable for event streams classification. However, neuromorphic datasets, such as N-MNIST, CIFAR10-DVS, DVS128-gesture, need to aggregate individual events into frames with a new higher temporal resolution for event stream classification, which causes high training and inference latency. In this work, we proposed a spatio-temporal compression method to aggregate individual events into a few time steps of synaptic current to reduce the training and inference latency. To keep the accuracy of SNNs under high compression ratios, we also proposed a synaptic convolutional block to balance the dramatic changes between adjacent time steps. And multi-threshold Leaky Integrate-and-Fire (LIF) models with learnable membrane time constants are introduced to increase their information processing capability. We evaluate the proposed method for event stream classification tasks on neuromorphic N-MNIST, CIFAR10-DVS, and DVS128 gesture datasets. The experiment results show that our proposed method outperforms the state-of-the-art accuracy on nearly all datasets, using fewer time steps.},
  archive      = {J_NEUCOM},
  author       = {Changqing Xu and Yi Liu and Yintang Yang},
  doi          = {10.1016/j.neucom.2023.126485},
  journal      = {Neurocomputing},
  pages        = {126485},
  shortjournal = {Neurocomputing},
  title        = {Ultra-low latency spiking neural networks with spatio-temporal compression and synaptic convolutional block},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MDGAD: Meta domain generalization for distribution drift in
anomaly detection. <em>NEUCOM</em>, <em>550</em>, 126483. (<a
href="https://doi.org/10.1016/j.neucom.2023.126483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalies often experience distribution drift over time in anomaly detection . Traditional anomaly detection methods detect anomalies with the same distribution effectively, but it is difficult to detect anomalies with changing distributions. In this paper, we propose a m eta d omain g eneralization based a nomaly d etection (MDGAD) framework to detect anomalies when distribution drifts. The framework first divides the data into a series of subsets. We measure the domain shift between sets with a class-sensitive distance metric, and merge similar sets, thereby generating different source domains to enhance domain diversity. We utilize the distribution shifts that existed on these source domains to simulate the distribution shifts that would be encountered when the model was applied. Meta learning is employed during training. First, the network is updated once on the meta-training set, and then another update is performed on the meta-verification set. These two gradients together determine the update direction of the network. At the same time, our framework will complete the domain alignment task on multiple source domains to extract domain invariant features and enhance the generalization of feature learning . We use Devnet as the base model and test our framework on 5 simulated data sets. The results confirm that our MDGAD outperforms current popular algorithms in detecting unknown anomalies and has better robustness. In addition, we also test our framework on real financial datasets to demonstrate the effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Sinong Zhao and Zhaoyang Yu and Trent G. Marbach and Gang Wang and Airu Yin and Yatao Zhou and Xiaoguang Liu},
  doi          = {10.1016/j.neucom.2023.126483},
  journal      = {Neurocomputing},
  pages        = {126483},
  shortjournal = {Neurocomputing},
  title        = {MDGAD: Meta domain generalization for distribution drift in anomaly detection},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A distributed neurodynamic algorithm for sparse signal
reconstruction via ℓ1-minimization. <em>NEUCOM</em>, <em>550</em>,
126480. (<a href="https://doi.org/10.1016/j.neucom.2023.126480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a distributed neurodynamic algorithm for sparse signal reconstruction by addressing ℓ 1 ℓ1 -minimization problems. Firstly, a ℓ 1 ℓ1 -minimization problem is transformed into a distributed model, drawing support from multi-agent consensus theory. Secondly, to address this distributed model, a novel distributed neurodynamic algorithm is proposed by employing derivative feedback and projection operator. It is proved that the proposed neurodynamic algorithm is globally convergent by utilizing the properties of projection operator and set-valued system. Moreover, compared with the existing distributed neurodynamic algorithms, the proposed neurodynamic algorithm is inverse-free and does not involve any matrix decomposition . Finally, some experimental results on sparse signal reconstruction indicate the effectiveness of the proposed neurodynamic algorithm.},
  archive      = {J_NEUCOM},
  author       = {Xin Han and Xing He and Xingxing Ju},
  doi          = {10.1016/j.neucom.2023.126480},
  journal      = {Neurocomputing},
  pages        = {126480},
  shortjournal = {Neurocomputing},
  title        = {A distributed neurodynamic algorithm for sparse signal reconstruction via ℓ1-minimization},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A mixed-categorical correlation kernel for gaussian process.
<em>NEUCOM</em>, <em>550</em>, 126472. (<a
href="https://doi.org/10.1016/j.neucom.2023.126472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a growing interest for mixed-categorical meta-models based on Gaussian process (GP) surrogates. In this setting, several existing approaches use different strategies either by using continuous kernels ( e.g. , continuous relaxation and Gower distance based GP) or by using a direct estimation of the correlation matrix . In this paper, we present a kernel-based approach that extends continuous exponential kernels to handle mixed-categorical variables. The proposed kernel leads to a new GP surrogate that generalizes both the continuous relaxation and the Gower distance based GP models . We demonstrate, on both analytical and engineering problems, that our proposed GP model gives a higher likelihood and a smaller residual error than the other kernel-based state-of-the-art models. Our method is available in the open-source software SMT.},
  archive      = {J_NEUCOM},
  author       = {P. Saves and Y. Diouane and N. Bartoli and T. Lefebvre and J. Morlier},
  doi          = {10.1016/j.neucom.2023.126472},
  journal      = {Neurocomputing},
  pages        = {126472},
  shortjournal = {Neurocomputing},
  title        = {A mixed-categorical correlation kernel for gaussian process},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised domain adaptation via style adaptation and
boundary enhancement for medical semantic segmentation. <em>NEUCOM</em>,
<em>550</em>, 126469. (<a
href="https://doi.org/10.1016/j.neucom.2023.126469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of semantic segmentation in cross-modal medicine is to align the distribution among different domains. The images from different domains contain various styles and boundary information, which the previous method ignores. Inspired by this observation, we considered employing the style and boundary information from features. We proposed a simple but effective way containing a style adaptation module and boundary enhancement module to facilitate the medical semantic segmentation on an unlabeled domain. In particular, the style adaptation module highlights the style information from the deep features through Fast Fourier Transform and low pass filter to assist in aligning the domain distributions. The boundary enhancement module utilizes the phase spectrum of features to obtain the boundary information and improve the segmentation ability by aggregating the boundary information. Results from experiments on two public datasets show that our proposed method effectively improves the segmentation performance of unlabeled target images and outperforms the most advanced domain adaptation approaches. Both qualitative and quantitative results evaluate the effectiveness of style features and boundary information in domain alignment.},
  archive      = {J_NEUCOM},
  author       = {Yisu Ge and Zhao-Min Chen and Guodao Zhang and Ali Asghar Heidari and Huiling Chen and Shu Teng},
  doi          = {10.1016/j.neucom.2023.126469},
  journal      = {Neurocomputing},
  pages        = {126469},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised domain adaptation via style adaptation and boundary enhancement for medical semantic segmentation},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bi-fidelity evolutionary multiobjective search for
adversarially robust deep neural architectures. <em>NEUCOM</em>,
<em>550</em>, 126465. (<a
href="https://doi.org/10.1016/j.neucom.2023.126465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have been found vulnerable to adversarial attacks , thus raising potential concerns in security-sensitive contexts. To address this problem, recent research has investigated the adversarial robustness of deep neural networks from the architectural point of view. However, searching for architectures of deep neural networks is computationally expensive, particularly when coupled with an adversarial training process. To meet the above challenge, this paper proposes a bi-fidelity multiobjective neural architecture search approach. First, we formulate the neural architecture search (NAS) problem for enhancing the adversarial robustness of deep neural networks into a multiobjective optimization problem . Specifically, in addition to using low-fidelity estimations as the primary objectives, we leverage the output of a surrogate model trained with high-fidelity evaluations as an auxiliary objective. Secondly, we reduce the computational cost by combining three performance estimation methods, i.e., parameter sharing, low-fidelity evaluation, and surrogate-based predictor. The effectiveness of the proposed approach is confirmed by extensive experiments conducted on CIFAR-10, CIFAR-100 and SVHN datasets.},
  archive      = {J_NEUCOM},
  author       = {Jia Liu and Ran Cheng and Yaochu Jin},
  doi          = {10.1016/j.neucom.2023.126465},
  journal      = {Neurocomputing},
  pages        = {126465},
  shortjournal = {Neurocomputing},
  title        = {Bi-fidelity evolutionary multiobjective search for adversarially robust deep neural architectures},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based covert brain infarct detection from
multiple MRI sequences. <em>NEUCOM</em>, <em>550</em>, 126464. (<a
href="https://doi.org/10.1016/j.neucom.2023.126464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic and accurate detection of covert brain infarcts may help identify individuals at risk of cognitive decline, dementia, and vascular events who could be eligible for early preventive measures or enrollment in clinical trials. We propose a novel deep learning-based framework to detect covert brain infarcts from multiple MRI sequences, including T1-weighted and T2-weighted fluid attenuated inversion recovery (FLAIR) scans. First, we design a simple yet effective cross-sequence registration method to register T1 and FLAIR by slice-level and pixel-level alignment. The accurate registration enables different sequences to share the infarct annotations. Second, we employ a fully convolutional one-stage object detector for each sequence to obtain infarct candidates. The exploitation of the contextual information of adjacent slices and the elimination of predefining anchor boxes and proposals can achieve high sensitivity with computational efficiency. Finally, we propose a multi-sequence fusion strategy with attention mechanisms to jointly combine different sequences so that their complementary representation can be explored to reduce false positives . The attention mechanisms are designed to consider the importance of different sequences, spatial locations , and channels. To evaluate the effectiveness of the proposed method, we construct a novel dataset with 264 cases and 738 brain infarcts with pixel-level annotations. Extensive experiments are conducted on this dataset and the results demonstrate that our method achieves state-of-the-art infarct detection performance with a sensitivity of over 80\% and less than 5 false positives per case.},
  archive      = {J_NEUCOM},
  author       = {Sicheng Zhao and Hamid F. Bagce and Vadim Spektor and Yen Chou and Ge Gao and Clarissa D. Morales and Hao Yang and Jingchen Ma and Lawrence H. Schwartz and Jennifer J. Manly and Richard P. Mayeux and Adam M. Brickman and Jose D. Gutierrez and Binsheng Zhao},
  doi          = {10.1016/j.neucom.2023.126464},
  journal      = {Neurocomputing},
  pages        = {126464},
  shortjournal = {Neurocomputing},
  title        = {Deep learning-based covert brain infarct detection from multiple MRI sequences},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fractional-order visual neural model for small target
motion detection. <em>NEUCOM</em>, <em>550</em>, 126459. (<a
href="https://doi.org/10.1016/j.neucom.2023.126459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting small moving targets consisting of one or few pixels is technically demanding due to their limited visual features. Motivated by nature, some bio-inspired models have been developed that simulate the behavior of small target motion detectors (STMDs), a class of specialized neurons found in insects’ visual neural systems dominating in detecting small moving targets during activities such as predation or courtship. However, the existing models’ high dependence on the sampling frequency of input videos becomes a bottleneck that seriously hinders their real-time applications in the physical world. This is because massive computational power is required to capture and process high-sampling-frequency videos. While model detection performance in low-sampling-frequency videos is plagued by significant spatial errors and weak responses. To address these issues, we propose an STMD-based visual neural model with a fractional-order difference operator for small target motion detection. The fractional-order operator captures instantaneous luminance change and integrates it with memory information, where the instantaneous information dominates the integrated signal. The STMD network further separates the rising and falling luminance components , which are aligned in the time domain and then multiplied to predict the location of moving small targets. Due to the rapid response of instantaneous information and the supplement of memory information, the proposed model locates the small moving targets accurately and robustly in low-sampling-frequencies. Numerical experiments show that the proposed model significantly improves the detection performance for low-sampling-frequency videos.},
  archive      = {J_NEUCOM},
  author       = {Mingshuo Xu and Hongxin Wang and Hao Chen and Haiyang Li and Jigen Peng},
  doi          = {10.1016/j.neucom.2023.126459},
  journal      = {Neurocomputing},
  pages        = {126459},
  shortjournal = {Neurocomputing},
  title        = {A fractional-order visual neural model for small target motion detection},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Communication-efficient ADMM-based distributed algorithms
for sparse training. <em>NEUCOM</em>, <em>550</em>, 126456. (<a
href="https://doi.org/10.1016/j.neucom.2023.126456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale distributed machine learning (DML), the synchronization efficiency of the distributed algorithm becomes a critical factor that affects the training time of machine learning models as the computing scale increases. To address this challenge, we propose a novel algorithm called G rouped S parse A llReduce based on the 2D-T orus topology ( 2D-TGSA ), which enables constant transmission traffic that does not change with the number of workers. Our experimental results demonstrate that 2D-TGSA outperforms several benchmark algorithms in terms of synchronization efficiency. Moreover, we integrate the general form consistent ADMM with 2D-TGSA to develop a distributed algorithm ( 2D-TGSA-ADMM ) that exhibits excellent scalability and can effectively handle large-scale distributed optimization problems . Furthermore, we enhance 2D-TGSA-ADMM by adopting the resilient adap t ive p enalty parameter approach, resulting in a new algorithm called 2D-TGSA-TPADMM . Our experiments on training the logistic regression model with ℓ 1 ℓ1 -norm on the Tianhe-2 supercomputing platform demonstrate that our proposed algorithm can significantly reduce the synchronization time and training time compared to state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Guozheng Wang and Yongmei Lei and Yongwen Qiu and Lingfei Lou and Yixin Li},
  doi          = {10.1016/j.neucom.2023.126456},
  journal      = {Neurocomputing},
  pages        = {126456},
  shortjournal = {Neurocomputing},
  title        = {Communication-efficient ADMM-based distributed algorithms for sparse training},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual frame-level and region-level alignment for unsupervised
video domain adaptation. <em>NEUCOM</em>, <em>550</em>, 126454. (<a
href="https://doi.org/10.1016/j.neucom.2023.126454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing unsupervised video domain adaptation methods focus on extracting frame-level features and using temporal attention to create a domain-invariant feature space. However, this ignores the importance of different image regions and temporal dynamics. In this study, we propose a method that considers both frame-level and image-region level alignment to learn a dual spatial and temporal domain-invariant feature space. This is achieved by: 1) extracting frame-level image features and aligning them into a domain-invariant latent feature space; 2) extracting region-level temporal features and aligning them into a domain-invariant latent feature space. Optimal frame-level correlation is achieved through video-frame level alignment, while optimal image-region level correlation is demonstrated through image-region level alignment between the source and target videos. We use an LSTM network to parameterize this dual feature alignment, which is more efficient than attention mechanisms and results in significantly improved performance and reduced GPU memory cost by over 40\% compared to current state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xinyue Hu and Yingying Zhu},
  doi          = {10.1016/j.neucom.2023.126454},
  journal      = {Neurocomputing},
  pages        = {126454},
  shortjournal = {Neurocomputing},
  title        = {Dual frame-level and region-level alignment for unsupervised video domain adaptation},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble deep learning in speech signal tasks: A review.
<em>NEUCOM</em>, <em>550</em>, 126436. (<a
href="https://doi.org/10.1016/j.neucom.2023.126436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning methods are extensively used for processing and analysing speech signals by virtue of their performance gains over multiple domains. Deep learning and ensemble learning are the two most commonly used techniques, which results in benchmark performance across different downstream tasks. Ensemble deep learning is a recent development which combines these two techniques to result in a robust architecture having substantial performance gains, as well as better generalization performance over the individual techniques. In this paper, we extensively review the use of ensemble deep learning methods for different speech signal related tasks, ranging from general objectives such as automatic speech recognition and voice activity detection , to more specific areas such as biomedical applications involving the detection of pathological speech or music genre detection. We provide a discussion on the use of different ensemble strategies such as bagging, boosting and stacking in the context of speech signals, and identify the various salient features and advantages from a broader perspective when coupled with deep learning architectures. The main objective of this study is to comprehensively evaluate existing works in the area of ensemble deep learning, and highlight the future directions that may be explored to further develop it as a tool for several speech related tasks. To the best of our knowledge, this is the first review study which primarily focuses on ensemble deep learning for speech applications. This study aims to serve as a valuable resource for researchers in academia and in industry working with speech signals, supporting advanced novel applications of ensemble deep learning models towards solving challenges in existing speech processing systems.},
  archive      = {J_NEUCOM},
  author       = {M. Tanveer and Aryan Rastogi and Vardhan Paliwal and M.A. Ganaie and A.K. Malik and Javier Del Ser and Chin-Teng Lin},
  doi          = {10.1016/j.neucom.2023.126436},
  journal      = {Neurocomputing},
  pages        = {126436},
  shortjournal = {Neurocomputing},
  title        = {Ensemble deep learning in speech signal tasks: A review},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GraphMFT: A graph network based multimodal fusion technique
for emotion recognition in conversation. <em>NEUCOM</em>, <em>550</em>,
126427. (<a href="https://doi.org/10.1016/j.neucom.2023.126427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal machine learning is an emerging area of research, which has received a great deal of scholarly attention in recent years. Up to now, there are few studies on multimodal Emotion Recognition in Conversation (ERC). Since Graph Neural Networks (GNNs) possess the powerful capacity of relational modeling, they have an inherent advantage in the field of multimodal learning. GNNs leverage the graph constructed from multimodal data to perform intra- and inter-modal information interaction, which effectively facilitates the integration and complementation of multimodal data. In this work, we propose a novel Graph network based Multimodal Fusion Technique (GraphMFT) for emotion recognition in conversation. Multimodal data can be modeled as a graph, where each data object is regarded as a node, and both intra- and inter-modal dependencies existing between data objects can be regarded as edges. GraphMFT utilizes multiple improved graph attention networks to capture intra-modal contextual information and inter-modal complementary information. In addition, the proposed GraphMFT attempts to address the challenges of existing graph-based multimodal conversational emotion recognition models such as MMGCN. Empirical results on two public multimodal datasets reveal that our model outperforms the State-Of-The-Art (SOTA) approaches with the accuracy of 67.90\% and 61.30\%.},
  archive      = {J_NEUCOM},
  author       = {Jiang Li and Xiaoping Wang and Guoqing Lv and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2023.126427},
  journal      = {Neurocomputing},
  pages        = {126427},
  shortjournal = {Neurocomputing},
  title        = {GraphMFT: A graph network based multimodal fusion technique for emotion recognition in conversation},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring lottery ticket hypothesis in few-shot learning.
<em>NEUCOM</em>, <em>550</em>, 126426. (<a
href="https://doi.org/10.1016/j.neucom.2023.126426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lottery Ticket Hypothesis (LTH) [14] has gathered great focus since being proposed. Researchers then succeed in figuring out alternative ways to find the ”winning ticket” and extending the vanilla version to various kinds of situations ranging from image segmentation to language pretraining. However, these works all emphasize fully supervised learning with plenty of training instances, whilst they ignore the important scenario of learning from few examples, i.e., Few-Shot Learning (FSL). Different from classical many-shot learning tasks, the common FSL setting assumes the disjoint of source and target categories. To the best of our knowledge, the lottery ticket hypothesis has for the first time, systematically studied in few-shot learning scenarios. To validate the hypothesis, we conduct extensive experiments on several few-shot learning methods with three widely-used datasets, mini ImageNet, CUB, CIFARFS. Results reveal that we can even find “winning tickets” for some high-performance methods. In addition, our experiments on Cross-Domain FSL further validates the transferability of the found “winning tickets”. Furthermore, the process of finding LTH can be costly. So we study the early-stage LTH for FSL via exploring the Inverse Scale Space(ISS). Empirical results validate the efficacy of early-stage LTH.},
  archive      = {J_NEUCOM},
  author       = {Yu Xie and Qiang Sun and Yanwei Fu},
  doi          = {10.1016/j.neucom.2023.126426},
  journal      = {Neurocomputing},
  pages        = {126426},
  shortjournal = {Neurocomputing},
  title        = {Exploring lottery ticket hypothesis in few-shot learning},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive growing grid model for a non-stationary
environment. <em>NEUCOM</em>, <em>550</em>, 126405. (<a
href="https://doi.org/10.1016/j.neucom.2023.126405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-organizing map (SOM) represents high-dimensional input samples by a 2-dimensional output topological structure , whereby similar input samples are mapped onto the same output unit or neighboring units on a map for visualization. Although many extended SOM models have been proposed, the need to determine a grid structure of SOM before learning, and the lack of adaptability to rapid changes in input data have not yet been fully overcome. This research proposes an adaptive growing grid (AGG) model, which is a novel neural self-organizing map (SOM), for projecting high-dimensional input samples onto an output grid. Due to the need for a grid structure for visualization, the AGG uses both growing and pruning functions and an adaptive learning process in order to adapt its output grid structure and learning function to constantly and rapidly changing input data in a non-stationary environment. The proposed AGG is tested on four basic data sets and one cross-domain data set. In addition, the t -test is used to test whether the proposed AGG outperforms the benchmark model , the growing grid (GG). Based on three evaluation measures, i.e. average quantization error (AQE), topographic error (TE) and dead unit ratio (DUR), the AGG significantly outperforms the GG in a non-stationary environment.},
  archive      = {J_NEUCOM},
  author       = {Chihli Hung and Stefan Wermter and Yu-Liang Chi and Chih-Fong Tsai},
  doi          = {10.1016/j.neucom.2023.126405},
  journal      = {Neurocomputing},
  pages        = {126405},
  shortjournal = {Neurocomputing},
  title        = {An adaptive growing grid model for a non-stationary environment},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical graph attention network for temporal knowledge
graph reasoning. <em>NEUCOM</em>, <em>550</em>, 126390. (<a
href="https://doi.org/10.1016/j.neucom.2023.126390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graphs (TKGs) reasoning has attracted increasing research interest in recent years. However, most of the existing TKGs reasoning models aim to learn a dynamic entity representation by binding timestamps information with the entities, neglecting to learn adaptive entity representation that is valuable to the query from relevant historical facts. To this end, we propose a Hierarchical Graph Attention neTwork (HGAT) for the TKGs reasoning task. Specifically, we design a hierarchical neighbor encoder to model the time-oriented and task-oriented roles of the entities. The time-aware mechanism is developed in the first layer to differentiate the contributions of query-relevant historical facts at different timestamps to the query. The designed relation-aware attention is used in the second layer to discern the contributions of the structural neighbors of an entity. Through this hierarchical encoder, our model can absorb valuable knowledge effectively from the relevant historical facts, and thus learn more expressive adaptive entity representation for the query. Finally, we evaluate our model performance on four TKGs datasets and justify its superiority against vaerious state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Pengpeng Shao and Jiayi He and Guanjun Li and Dawei Zhang and Jianhua Tao},
  doi          = {10.1016/j.neucom.2023.126390},
  journal      = {Neurocomputing},
  pages        = {126390},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical graph attention network for temporal knowledge graph reasoning},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual attentional transformer for video visual relation
prediction. <em>NEUCOM</em>, <em>550</em>, 126372. (<a
href="https://doi.org/10.1016/j.neucom.2023.126372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video visual relation detecti on (VidVRD) is to detect visual relations among instances as well as the trajectories of the corresponding subjects and objects in the video. Most current works improve the accuracy of tracking the objects but neglect the other key challenge, predicting the reliable visual relations in the videos, a vital meant for downstream tasks further. In this paper, we propose a dual attentional transformer network (VRD-DAT) for predicting the visual relations, also known as the predicates, in multi-relation videos. Specifically, our network first respectively targets modeling action visual predicates (Act-T) and spatial locating visual relations (Spa-T) via two parallel visual transformer structures simultaneously. Then, an attentional weighting module obtains the final precise merged visual relations. We conduct extensive experiments on two public datasets, ImageNet-VidVRD and VidOR, to demonstrate our model is capable of outperforming other state-of-the-art methods effectively on the task of video visual relation prediction. Quantitative and qualitative results also show that with more accurate visual relations, the performance of the video visual relation detection task can be further boosted.},
  archive      = {J_NEUCOM},
  author       = {Mingcheng Qu and Ganlin Deng and Donglin Di and Jianxun Cui and Tonghua Su},
  doi          = {10.1016/j.neucom.2023.126372},
  journal      = {Neurocomputing},
  pages        = {126372},
  shortjournal = {Neurocomputing},
  title        = {Dual attentional transformer for video visual relation prediction},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drop-relationship learning for semi-supervised facial action
unit recognition. <em>NEUCOM</em>, <em>550</em>, 126361. (<a
href="https://doi.org/10.1016/j.neucom.2023.126361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial action units (AUs) recognition becomes important for facial analysis and has been widely applied in psychological research. Existing work on AU relationship learning only considers the relationship between AUs simultaneously, and does not consider the complex co-adaptation between AUs. Co-adaptation is good, but not always good. Learning the AU relationship simultaneously will inhibit the robust features of network learning. And AU relationship learning often requires additional landmark information. To solve these problems, we propose a novel AU Drop-relationship learning inspired by dropout. The AU Drop-relationship learning constructs the AU relationship units through prior knowledge. We further design the relationship regularization module to constraint the relationship between AU pairs. We randomly drop AU relationship units during training to suppress co-adaptation, forcing the network to learn more robust features. In addition, considering that there are massive unlabeled web facial images in reality, manual labeling of AU requires experts and is particularly time-consuming. To address this problem, we propose a method composed of consistency regularization and pseudo-multi-labeling for semi-supervised AU recognition. The proposed method outperforms the state-of-the-art semi-supervised and supervised methods on two widely used AU datasets (BP4D and DISFA).},
  archive      = {J_NEUCOM},
  author       = {Xin Hu and Ruicong Zhi and Caixia Zhou},
  doi          = {10.1016/j.neucom.2023.126361},
  journal      = {Neurocomputing},
  pages        = {126361},
  shortjournal = {Neurocomputing},
  title        = {Drop-relationship learning for semi-supervised facial action unit recognition},
  volume       = {550},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RM-FSP: Regret minimization optimizes neural fictitious
self-play. <em>NEUCOM</em>, <em>549</em>, 126471. (<a
href="https://doi.org/10.1016/j.neucom.2023.126471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To compute the optimal strategy in competitive games, algorithms have been developed to achieve the Nash equilibrium . Current deep learning algorithms have succeeded in many games; however, optimizing the algorithms to approach the Nash equilibrium in imperfect-information games like StarCraft and Poker remains challenging. Neural Fictitious Self-Play (NFSP) is an effective end-to-end algorithm to learn an approximate Nash equilibrium in imperfect-information games. However, because a player in NFSP trains its best response according to its opponents’ past strategies, a discrepancy exists between the optimal strategy and the learned best response after the player updates its strategies. We call this discrepancy the optimality gap . During training, the optimality gap does not decay monotonically, which causes suboptimal results or unstable convergence of NFSP. We improve the performance of NFSP by allowing the optimality gap to decay monotonically. In this study, we propose Regret Minimization Fictitious Self-Play (RM-FSP), which applies a regret minimization method to compute NFSP’s best response. The regret minimization method effectively converges the optimality gap monotonically and faster than in NFSP. We prove there will be a better learning bound than the original NFSP after applying regret minimization methods to NFSP. Experiments on three typical environments in OpenSpiel demonstrate that RM-FSP outperforms NFSP in both exploitability (discrepancy between the learned policy profile and the Nash equilibrium) and time efficiency.},
  archive      = {J_NEUCOM},
  author       = {Yuxuan Chen and Li Zhang and Shijian Li and Xili Chen and Gang Pan and Zhijie Pan},
  doi          = {10.1016/j.neucom.2023.126471},
  journal      = {Neurocomputing},
  pages        = {126471},
  shortjournal = {Neurocomputing},
  title        = {RM-FSP: Regret minimization optimizes neural fictitious self-play},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A convolutional spiking neural network with adaptive coding
for motor imagery classification. <em>NEUCOM</em>, <em>549</em>, 126470.
(<a href="https://doi.org/10.1016/j.neucom.2023.126470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery (MI) signal classification is crucial for brain-computer interfaces (BCI). The third-generation neural network, spiking neural network (SNN), has rich neurodynamic properties in the spatiotemporal domain, and therefore it is more suitable for processing EEG signals. However, the feature extraction capability of the SNN previously applied to MI signal classification is limited by its structure, and the model’s classification accuracy is not comparable to the state-of-the-art algorithms. In this paper, we propose a spiking neural network model called SCNet, which combines the feature extraction capability of CNN with the biological interpretability of SNN, making the model structurally closer to the biological neuronal dynamical system and improving the classification accuracy. SCNet reduces information loss by adaptive coding with learnability and solves the training difficulties of spiking neural networks by surrogate gradient learning. We evaluated the performance of the proposed SCNet on three typically representative motor imagery datasets. The validation shows that the model outperforms state-of-the-art SNN-based MI classification methods and various ANN and machine learning methods. The experimental results demonstrate the generality and effectiveness of the proposed motor imagery EEG signal classification model. Better classification results can be obtained by designing a well-structured spiking neural network.},
  archive      = {J_NEUCOM},
  author       = {Xiaojian Liao and Yuli Wu and Zi Wang and Deheng Wang and Hongmiao Zhang},
  doi          = {10.1016/j.neucom.2023.126470},
  journal      = {Neurocomputing},
  pages        = {126470},
  shortjournal = {Neurocomputing},
  title        = {A convolutional spiking neural network with adaptive coding for motor imagery classification},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extraordinary MHNet: Military high-level camouflage object
detection network and dataset. <em>NEUCOM</em>, <em>549</em>, 126466.
(<a href="https://doi.org/10.1016/j.neucom.2023.126466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the first systematic work on Military High-level Camouflage object Detection (MHCD), aiming to identify objects visibly embedded in chaotic backgrounds. The high intrinsic similarities (e.g., texture, intensity, color, etc.) between the attention object and its background give the task far more challenging than general object detection. In this paper, we construct a benchmark MHCD2022 dataset, which consists of 3000 images with dense annotations covering 5 categories from multiple real-world scenes. Remarkably, based on the observation that biological vision usually first obtains perception from global search and strives to recover the complete object, we propose a novel Military High-level detection Network, called MHNet, which is characterized by four ingenious modules: Subject Perception Gathering (SPG), Part-object Relationships Mining (PRM), Concept Recovery/Feature Clue Supplement (CR/FCS) and Springboard Selection (SS). Firstly, a SPG is designed for global foreground rough perception by the exploitation of depth information. Second, a PRM is particularly used to mine part-object potential relations in diverse environments. After that, we propose CR/FCS and SS to enhance the destroyed instance-level representation and suppress the domain imbalance problem, respectively. Extensive experimental results show that previous methods suffered from poor performance, MHNet significantly outperforms camouflage baselines and competing methods on the MHCD2022 for the high-level camouflaged object. Finally, we also present and highlight the practical application value and several future directions of the research.},
  archive      = {J_NEUCOM},
  author       = {Maozhen Liu and Xiaoguang Di},
  doi          = {10.1016/j.neucom.2023.126466},
  journal      = {Neurocomputing},
  pages        = {126466},
  shortjournal = {Neurocomputing},
  title        = {Extraordinary MHNet: Military high-level camouflage object detection network and dataset},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical block aggregation network for long-tailed
visual recognition. <em>NEUCOM</em>, <em>549</em>, 126463. (<a
href="https://doi.org/10.1016/j.neucom.2023.126463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is usually supposed that training database is manually balanced in traditional visual recognition tasks. However, in nature, data tends to follow long-tailed distributions. In recent years, many plug-and-play methods based on data augmentation or representation learning have been proposed to tackle the long-tailed visual recognition task. Although these methods are effective, we find that when different plug-and-play methods are applied to the same long-tail recognition model, they sometimes fail to promote each other. The reason for this phenomenon may lie in the fact that the overall performance of the model is constrained by the insufficient capability of a traditional feature extractor. Motivated by this fact, we first propose Hierarchical Block Aggregation Network (HBAN), a network structure with stronger feature extraction capability. Then, we design a Quantity-Aware Balanced (QAB) loss and a decoupled training paradigm to optimize HBAN. The effectiveness of HBAN is demonstrated by extensive experiments. In particular, HBAN achieves significant improvements over our baseline on three benchmark datasets, and outperforms the state-of-the-art methods on CIFAR 100-LT.},
  archive      = {J_NEUCOM},
  author       = {Shanmin Pang and Weiye Wang and Renzhong Zhang and Wenyu Hao},
  doi          = {10.1016/j.neucom.2023.126463},
  journal      = {Neurocomputing},
  pages        = {126463},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical block aggregation network for long-tailed visual recognition},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Obsession, compulsion and learning in obsessive-compulsive
disorder: A multilevel computational model. <em>NEUCOM</em>,
<em>549</em>, 126461. (<a
href="https://doi.org/10.1016/j.neucom.2023.126461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obsessive-compulsive disorder (OCD) is characterized symptomatically by obsessive thoughts and compulsive behaviors to separate its behavioral features. Despite extensive research efforts into the pathogenesis and neural substrates in OCD, the interactions and causal associations between the two behaviors remain unclear. To theoretically fill this gap in mechanisms, we combine a cortico-basal ganglia-thalamic model of motor loops and a limbic system model based on classical reward prediction errors to model the complex dynamics between different loops in OCD. Based on the widely accepted hypothesis that dopamine bursts and reinforcement learning influence synaptic plasticity, we explore the mechanisms behind the progression of OCD related to stress triggers, overtraining, and striatal lesions, in terms of behavioral flexibility as a measurement. The obtained results indicate that reinforcement learning affects synaptic gain, which in turn influences loop stability and contributes to imbalance between loops. At the same time, it pulls the network into an over-stable state, similar to compulsive actions. Learning serves as the bridge between the limbic system (obsession) and the motor system (compulsion). Both systems work synergistically to facilitate the etiological transmission and progression of OCD. Our model provides plausible theoretical explanations for the behavioral features of OCD and may offer new approaches for its treatment.},
  archive      = {J_NEUCOM},
  author       = {Lining Yin and Fang Han and Ying Yu and Qingyun Wang},
  doi          = {10.1016/j.neucom.2023.126461},
  journal      = {Neurocomputing},
  pages        = {126461},
  shortjournal = {Neurocomputing},
  title        = {Obsession, compulsion and learning in obsessive-compulsive disorder: A multilevel computational model},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed/prescribed-time synchronization of quaternion-valued
fuzzy BAM neural networks under aperiodic intermittent pinning control:
A non-separation approach. <em>NEUCOM</em>, <em>549</em>, 126460. (<a
href="https://doi.org/10.1016/j.neucom.2023.126460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article concerns the fixed-time (FET) and prescribed-time (PET) synchronization of quaternion-valued fuzzy BAM neural networks via aperiodic intermittent pinning control. First of all, two improved inequalities for FET and PET stability are proposed to reduce the conservatism of existing results in theoretical analysis. Subsequently, by excluding the control input of the rest interval in previous semi-intermittent design, two novel quaternion-valued aperiodic intermittent pinning controllers are developed. Furthermore, regarding the original quaternion-valued networks as an entirety instead of decomposing it into four real-valued subnetworks , several sufficient criteria that ensure the FET and PET synchronization of quaternion-valued fuzzy BAM neural networks are obtained by means of the improved stability inequalities and the designed controllers. Finally, the validity of the theoretical results is verified by three numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Xuejiao Qin and Haijun Jiang and Jianlong Qiu and Cheng Hu},
  doi          = {10.1016/j.neucom.2023.126460},
  journal      = {Neurocomputing},
  pages        = {126460},
  shortjournal = {Neurocomputing},
  title        = {Fixed/prescribed-time synchronization of quaternion-valued fuzzy BAM neural networks under aperiodic intermittent pinning control: A non-separation approach},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view intuitionistic fuzzy support vector machines with
insensitive pinball loss for classification of noisy data.
<em>NEUCOM</em>, <em>549</em>, 126458. (<a
href="https://doi.org/10.1016/j.neucom.2023.126458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view support vector machines (MvSVMs) have been widely used to solve multi-view classification problems. However, the conventional MvSVMs often overlook the presence of noise and outliers that commonly exist in the original data. In this paper, we propose two novel multi-view intuitionistic fuzzy support vector machines with insensitive pinball loss that can not only handle the general multi-view classification problems but also be robust to noisy data. In the proposed convex optimization models, the pinball loss is incorporated into the multi-view learning, which enables the maximization of the quantization distance. Moreover, to utilize multi-view information more effectively, the intuitionistic fuzzy score is introduced to assign a weight to each multi-view sample. The intuitionistic fuzzy score combines the membership and non-membership functions, which provides an efficient mechanism to assign weights to the multi-view samples. Further, we provide a discussion of the proposed models with the state-of-the-art technologies. Experiments are conducted on a series of datasets, and the results show that the proposed convex models outperform several state-of-the-art models. The code is available at 1.},
  archive      = {J_NEUCOM},
  author       = {Chunling Lou and Xijiong Xie},
  doi          = {10.1016/j.neucom.2023.126458},
  journal      = {Neurocomputing},
  pages        = {126458},
  shortjournal = {Neurocomputing},
  title        = {Multi-view intuitionistic fuzzy support vector machines with insensitive pinball loss for classification of noisy data},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feedback coupling induced synchronization of neural
networks. <em>NEUCOM</em>, <em>549</em>, 126457. (<a
href="https://doi.org/10.1016/j.neucom.2023.126457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synchronization emerges ubiquitously in natural and engineering systems and at different scales. For real-world systems with invisible governing equations, recurrent neural networks provide effective approach to embed their dynamics from observations and facilitate intensive study, including the synchronization and its mechanisms. Synchronization at a scale of neural networks’ dynamics instead of the component neurons’ has seldom been studied. Here, we define the synchronization of reservoir computers at a macroscopic level, named by hyper-synchronization, from a viewpoint of dynamical systems theory. HyperSync is realized, with a merged attractor emerging, in reservoir computers trained by different chaotic systems through a proposed feedback coupling mechanism. Numerical experiments demonstrate its effectiveness, and we further provide guidance for realizing synchronization among multiple reservoir computers coupled with different topologies. This work articulates an appealing framework to realize synchronization of neural networks and anticipates potential applications in fields such as communications and biological systems.},
  archive      = {J_NEUCOM},
  author       = {Zhihao Zuo and Ruizhi Cao and Zhongxue Gan and Jiawen Hou and Chun Guan and Siyang Leng},
  doi          = {10.1016/j.neucom.2023.126457},
  journal      = {Neurocomputing},
  pages        = {126457},
  shortjournal = {Neurocomputing},
  title        = {Feedback coupling induced synchronization of neural networks},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning controllable elements oriented representations for
reinforcement learning. <em>NEUCOM</em>, <em>549</em>, 126455. (<a
href="https://doi.org/10.1016/j.neucom.2023.126455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning (deep RL) has been successfully applied to solve various decision-making problems in recent years. However, the observations in many real-world tasks are often high dimensional and include much task-irrelevant information, limiting the applications of RL algorithms. To tackle this problem, we propose LCER, a representation learning method that aims to provide RL algorithms with compact and sufficient descriptions of the original observations. Specifically, LCER trains representations to retain the controllable elements of the environment, which can reflect the action-related environment dynamics and thus are likely to be task-relevant. We demonstrate the strength of LCER on the DMControl Suite, proving that it can achieve state-of-the-art performance. LCER enables the pixel-based SAC to outperform state-based SAC on the DMControl 100 K benchmark, showing that the obtained representations can match the oracle descriptions ( i . e i.e . the physical states) of the environment. We also carry out experiments to show that LCER can efficiently filter out various distractions, especially when those distractions are not controllable.},
  archive      = {J_NEUCOM},
  author       = {Qi Yi and Rui Zhang and Shaohui Peng and Jiaming Guo and Xing Hu and Zidong Du and Qi Guo and Ruizhi Chen and Ling Li and Yunji Chen},
  doi          = {10.1016/j.neucom.2023.126455},
  journal      = {Neurocomputing},
  pages        = {126455},
  shortjournal = {Neurocomputing},
  title        = {Learning controllable elements oriented representations for reinforcement learning},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of graph neural network based recommendation in
social networks. <em>NEUCOM</em>, <em>549</em>, 126441. (<a
href="https://doi.org/10.1016/j.neucom.2023.126441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread popularization of social network platforms, user-generated content and other social network data are growing rapidly. It is difficult for social users to select interested contents from the numerous social data. To alleviate information overload problem and enhance overall user experience of social networks, recommendation systems relying on historical behavioural data and social friendship relations of users, are widely used in social networks. Although researches on social recommendations have been conducted in recent years, recommendation systems of social networks still suffer from several challenges, such as data sparsity and lower performance. Since graph neural network has huge advantages in graph data learning by aggregating neighbors representations of the central node, it has been gathering pace in recent years. In this survey, we review graph neural network based literature for solving recommendation problems in social networks. We first introduce backgrounds of graph neural network and recommendation systems in social networks. Then, for different types of recommendation problems in social networks, we review different graph neural network based recommendation methods briefly. In particular, we first review GNN-based methods for general social recommendation and then review GNN-based methods for different social recommendation scenarios (such as friend recommendation and point-of-interest recommendation). Finally, we briefly discuss promising future directions of the graph neural network based recommendation in social networks.},
  archive      = {J_NEUCOM},
  author       = {Xiao Li and Li Sun and Mengjie Ling and Yan Peng},
  doi          = {10.1016/j.neucom.2023.126441},
  journal      = {Neurocomputing},
  pages        = {126441},
  shortjournal = {Neurocomputing},
  title        = {A survey of graph neural network based recommendation in social networks},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Context-aware transformer for image captioning.
<em>NEUCOM</em>, <em>549</em>, 126440. (<a
href="https://doi.org/10.1016/j.neucom.2023.126440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, image captioning models have made remarkable progress by introducing transformer architecture, which utilizes self-attention to explore intra- and inter-modal interactions. However, most existing methods only consider region-level characteristic during the attention weight calculation and ignore the image-level information. This seriously hinders the whole model from understanding the scene content. In this paper, we propose a Context-Aware Transformer (CATNet) with two novel designs, namely Context Augmented Attention (CAA) and Dual Way Controller (DWC). Concretely, CAA in encoder enables the extraction of more comprehensive visual representation through modeling the communications between multi-level visual features. DWC in decoder is used to enhance the fusion between visual features and language representation through utilizing complementarity of global context and local regions. Extensive experiments conducted on MSCOCO dataset show that the proposed CATNet has achieved state-of-the-art performance on both Karpathy test set and online test.},
  archive      = {J_NEUCOM},
  author       = {Xin Yang and Ying Wang and Haishun Chen and Jie Li and Tingting Huang},
  doi          = {10.1016/j.neucom.2023.126440},
  journal      = {Neurocomputing},
  pages        = {126440},
  shortjournal = {Neurocomputing},
  title        = {Context-aware transformer for image captioning},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep emotion change detection via facial expression
analysis. <em>NEUCOM</em>, <em>549</em>, 126439. (<a
href="https://doi.org/10.1016/j.neucom.2023.126439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expressions are one of the most essential channels to communicate a person’s emotional state. In social interaction , the capability to accurately read subtle changes in facial expressions, which reveal emotional fluctuations, is critical for 1) comprehending others’ emotions in context and background situations, 2) identifying responsiveness to others’ emotions, and 3) developing social skills in human–computer interaction. In this paper, we first introduce automatic emotion change detection via facial expression that discovers timings or temporal locations in a video where facial expression significantly changes. We propose a weakly-supervised deep emotion change detection framework that does not require facial expression videos with expensive temporal annotations and instead learns static images for training. Incorporating these ideas, we performed extensive experiments to demonstrate fundamental insights into emotion change detection and the efficacy of our framework using three video datasets, i.e., CASME II, MMI, and our YoutubeECD. Furthermore, we modified our framework for temporal spotting, which is the most similar task to emotion change detection, and showed comparable results with state-of-the-art methods on CAS(ME) 2 , proving justification for the problem. Even though we only employed the AffectNet to train our framework rather than the CASME II, MMI, YoutubeECD, and CAS(ME) 2 , experimental results demonstrate its exceptional generalization capability in cross-dataset environments.},
  archive      = {J_NEUCOM},
  author       = {ByungOk Han and Cheol-Hwan Yoo and Ho-Won Kim and Jang-Hee Yoo and Jinhyeok Jang},
  doi          = {10.1016/j.neucom.2023.126439},
  journal      = {Neurocomputing},
  pages        = {126439},
  shortjournal = {Neurocomputing},
  title        = {Deep emotion change detection via facial expression analysis},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining CNN and transformers for full-reference and
no-reference image quality assessment. <em>NEUCOM</em>, <em>549</em>,
126437. (<a href="https://doi.org/10.1016/j.neucom.2023.126437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most deep learning approaches for image quality assessment use regression from deep features extracted by CNN (Convolutional Neural Networks). However, non-local information is usually neglected in existing methods. Motivated by the recent success of transformers in modeling contextual information, we propose a hybrid framework that utilizes a vision transformer backbone to extract features and a CNN decoder for quality estimation. We propose a shared feature extraction scheme for both FR and NR settings. A two-branch structured attentive quality predictor is devised for quality prediction. Evaluation experiments on various IQA datasets, including LIVE, CSIQ and TID2013, LIVE-Challenge, KADID-10 K, and KONIQ-10 K, show that our proposed models achieve outstanding performance for both FR and NR settings.},
  archive      = {J_NEUCOM},
  author       = {Chao Zeng and Sam Kwong},
  doi          = {10.1016/j.neucom.2023.126437},
  journal      = {Neurocomputing},
  pages        = {126437},
  shortjournal = {Neurocomputing},
  title        = {Combining CNN and transformers for full-reference and no-reference image quality assessment},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning ensembles for accurate fog-related
low-visibility events forecasting. <em>NEUCOM</em>, <em>549</em>,
126435. (<a href="https://doi.org/10.1016/j.neucom.2023.126435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose and discuss different Deep Learning-based ensemble algorithms for a problem of low-visibility events prediction due to fog. Specifically, seven different Deep Learning (DL) architectures have been considered, from which multiple individual learners are generated. Hyperparameters of the models, including parameters concerning data preprocessing , models architecture and training procedure, are randomly selected for each model within a pre-defined discrete range. Also, every model is trained with slightly different data sampled randomly, assuring that every models introduce variety in the ensemble. Then, three different information fusion techniques are employed to build the ensemble models. The influence of the filtering process and the elitism level (the percentage of the individual models entering the ensemble) is also assessed. The performance of the proposed methodology have been tested in two real problems of low-visibility events prediction due to orographical and radiation fog, at the north of Spain. Comparison with different Machine Learning , alternative DL algorithms and meteorological-based methods show the good performance of the proposed deep learning ensembles in this problem.},
  archive      = {J_NEUCOM},
  author       = {C. Peláez-Rodríguez and J. Pérez-Aracil and A. de Lopez-Diz and C. Casanova-Mateo and D. Fister and S. Jiménez-Fernández and S. Salcedo-Sanz},
  doi          = {10.1016/j.neucom.2023.126435},
  journal      = {Neurocomputing},
  pages        = {126435},
  shortjournal = {Neurocomputing},
  title        = {Deep learning ensembles for accurate fog-related low-visibility events forecasting},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lip landmark-based audio-visual speech enhancement with
multimodal feature fusion network. <em>NEUCOM</em>, <em>549</em>,
126432. (<a href="https://doi.org/10.1016/j.neucom.2023.126432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional speech enhancement uses only audio signals to obtain clean speech by removing background noise. Audio-visual speech enhancement uses additional visual information to improve the intelligibility and perceptual quality of noisy speech, which can be applied to video conferencing. However, the original visual cues contain redundant information, which causes high latency and makes the model prone to overfitting. Meanwhile, related methods do not pay much attention to exploiting critical visual features and fusing multimodal audio-visual features. In this paper, we propose an efficient multimodal feature fusion network (MFF-Net) for audio-visual speech enhancement. Specifically, we are the first to use fine-grained 3D lip landmarks to represent visual features. This visual representation can provide refined 3D visual information while protecting privacy. We design a multi-scale enhancement module (MEM) with a multi-branch structure that extracts critical multi-scale features by using dilated convolutions and attention mechanisms. Besides, we propose an audio-visual fusion module (AFM) that uses a mutually reinforcing strategy to effectively fuse visual and audio features. To verify the effectiveness of our method, we construct two speech enhancement datasets based on lip landmarks and conduct related experiments. Extensive experimental results show that our proposed MFF-Net has competitive performance compared to other methods.},
  archive      = {J_NEUCOM},
  author       = {Yangke Li and Xinman Zhang},
  doi          = {10.1016/j.neucom.2023.126432},
  journal      = {Neurocomputing},
  pages        = {126432},
  shortjournal = {Neurocomputing},
  title        = {Lip landmark-based audio-visual speech enhancement with multimodal feature fusion network},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge convolutional networks: Decomposing graph convolutional
networks for stochastic training with independent edges.
<em>NEUCOM</em>, <em>549</em>, 126430. (<a
href="https://doi.org/10.1016/j.neucom.2023.126430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After the success of Graph Convolutional Networks (GCN), many stochastic training methods have been proposed to resolve the scalability and efficiency issues of GCN by sampling. In mini-batch training, a common phase of these methods is to form a small-scale subgraph rooting in the given batch. The subgraph formation leads to heavy time consumption, additional space occupation, and complex implementation. To rectify these issues, we eliminate the subgraph formation phase and propose Edge Convolutional Network (ECN), which is trained with independently sampled edges. It has constant time complexity for sampling, reducing the sampling time by orders of magnitude without compromising convergence speed. Specifically, when there are two convolutional layers, as in the most common situation, GCN can also be trained with the techniques behind ECN, gaining substantial sampling time reduction without trade-offs. We prove that the expressiveness difference between ECN and GCN is theoretically bounded and examine the inference performance of ECN through excessive experiments on real-world, large-scale graphs. Furthermore, we improve ECN with advanced mechanisms of GCN, including skip connection, identity mapping, embedding, and attention. With proper mechanisms integrated, ECN rivals state-of-the-art (SotA) baselines in inductive node classification and produces new SotA accuracy on the dataset of Flickr. The code is available at https://github.com/cf020031308/ECN .},
  archive      = {J_NEUCOM},
  author       = {Yi Luo and Yan Huang and Guangchun Luo and Ke Qin and Aiguo Chen},
  doi          = {10.1016/j.neucom.2023.126430},
  journal      = {Neurocomputing},
  pages        = {126430},
  shortjournal = {Neurocomputing},
  title        = {Edge convolutional networks: Decomposing graph convolutional networks for stochastic training with independent edges},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Neighbor importance-aware graph collaborative filtering for
item recommendation. <em>NEUCOM</em>, <em>549</em>, 126429. (<a
href="https://doi.org/10.1016/j.neucom.2023.126429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging topic of Graph Neural Networks (GNN) has attracted increasing attention and achieved state-of-the-art (SOTA) performance in many recommendation problems, due to its strong ability in node representation with exploring high-order information. To learn a node’s representation, previous methods usually linearly combine the embeddings of node features, amusing the equal importance of neighbors. However, due to the intrinsic differences (i.e., degree, create time) over neighbors, we argue that these differences carry important signals for node representation. Ignoring them will lead to a suboptimal in node representation and thus weaken the effectiveness of the follow-up graph-based operations. To address it, we propose BIG-SAGE@ for item recommendation with rating prediction task, which is a neighbor importance-aware graph neural network. Specifically, its main idea is twofold: 1) A rating confidence-based neighborhood sampling method is introduced, making the sampling process biased to those more valuable nodes. 2) An attention network is integrated to achieve the rating prediction task, by flexibly incorporating information from user and item embedding features. Finally, we verified the effectiveness of the proposed model on six public data sets. Extensive experimental results demonstrate the superior performance of BIG-SAGE@ in the rating prediction and TopN ranking tasks, compared to the SOTA methods.},
  archive      = {J_NEUCOM},
  author       = {Qingxian Wang and Suqiang Wu and Yanan Bai and Quanliang Liu and Xiaoyu Shi},
  doi          = {10.1016/j.neucom.2023.126429},
  journal      = {Neurocomputing},
  pages        = {126429},
  shortjournal = {Neurocomputing},
  title        = {Neighbor importance-aware graph collaborative filtering for item recommendation},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving the reconstruction-generation trade-off: Generative
model with implicit embedding learning. <em>NEUCOM</em>, <em>549</em>,
126428. (<a href="https://doi.org/10.1016/j.neucom.2023.126428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational Autoencoder (VAE) and Generative adversarial network (GAN) are two classic generative models that generate realistic data from a predefined prior distribution, such as a Gaussian distribution. One advantage of VAE over GAN is its ability to simultaneously generate high-dimensional data and learn latent representations that are useful for data manipulation. However, it has been observed that a trade-off exists between reconstruction and generation in VAE, as matching the prior distribution for the latent representations may destroy the geometric structure of the data manifold. To address this issue, we propose an autoencoder-based generative model that allows the prior to learn the embedding distribution, rather than imposing the latent variables to fit the prior. To preserve the geometric structure of the data manifold to the maximum, the embedding distribution is trained using a simple regularized autoencoder architecture. Then an adversarial strategy is employed to achieve a latent mapping. We provide both theoretical and experimental support for the effectiveness of our method, which eliminates the contradiction between preserving the geometric structure of the data manifold and matching the distribution in latent space. Once this paper is accepted, the code will be released on https://github.com/gengcong940126/GMIEL .},
  archive      = {J_NEUCOM},
  author       = {Cong Geng and Jia Wang and Li Chen and Zhiyong Gao},
  doi          = {10.1016/j.neucom.2023.126428},
  journal      = {Neurocomputing},
  pages        = {126428},
  shortjournal = {Neurocomputing},
  title        = {Solving the reconstruction-generation trade-off: Generative model with implicit embedding learning},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian physics-informed extreme learning machine for
forward and inverse PDE problems with noisy data. <em>NEUCOM</em>,
<em>549</em>, 126425. (<a
href="https://doi.org/10.1016/j.neucom.2023.126425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed extreme learning machine (PIELM) has recently received significant attention as a rapid version of physics-informed neural network (PINN) for solving partial differential equations (PDEs). The key characteristic is to fix input layer weights with random values and use Moore–Penrose generalized inverse for the output weights. The framework is effective, but it easily suffers from overfitting noisy data and lacks uncertainty quantification for the solution under noise scenarios. To this end, we develop a novel Bayesian physics-informed extreme learning machine (BPIELM) to solve both forward and inverse linear PDE problems with noisy data in a unified framework. In our framework, a prior probability distribution is introduced in the output layer for extreme learning machine with physic laws and the Bayesian method is used to estimate the posterior of parameters. Besides, for inverse PDE problems, problem parameters considered as new output weights are unified in a framework with forward PDE problems. Finally, we demonstrate BPIELM considering both forward problems, including Poisson, advection, and diffusion equations, as well as inverse problems , where unknown problem parameters are estimated. The results show that, compared with PIELM, BPIELM quantifies uncertainty arising from noisy data and provides more accurate predictions. In addition, BPIELM is considerably cheaper than PINN in terms of the computational cost.},
  archive      = {J_NEUCOM},
  author       = {Xu Liu and Wen Yao and Wei Peng and Weien Zhou},
  doi          = {10.1016/j.neucom.2023.126425},
  journal      = {Neurocomputing},
  pages        = {126425},
  shortjournal = {Neurocomputing},
  title        = {Bayesian physics-informed extreme learning machine for forward and inverse PDE problems with noisy data},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-learning representations for clustering with infinite
gaussian mixture models. <em>NEUCOM</em>, <em>549</em>, 126423. (<a
href="https://doi.org/10.1016/j.neucom.2023.126423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appropriate representations are critical for a better clustering performance. Although many neural network-based clustering methods have been proposed, they do not directly train neural networks to improve the clustering performance. We propose a method that can meta-learn knowledge for clustering from various labeled data and uses the knowledge for clustering unseen unlabeled data . The proposed method trains neural networks to obtain representations such that the clustering performance improves when the representations are clustered by variational Bayesian (VB) inference with an infinite Gaussian mixture model . For the objective function, we propose a continuous approximation of the adjusted Rand index (ARI) by which we can evaluate the clustering performance from soft clustering assignments. Since the approximated ARI and the VB inference procedure are differentiable, we can backpropagate the objective function through the VB inference procedure to train the neural networks. With experiments using text and image datasets, we demonstrate that our proposed method has a higher adjusted Rand index than the existing methods.},
  archive      = {J_NEUCOM},
  author       = {Tomoharu Iwata},
  doi          = {10.1016/j.neucom.2023.126423},
  journal      = {Neurocomputing},
  pages        = {126423},
  shortjournal = {Neurocomputing},
  title        = {Meta-learning representations for clustering with infinite gaussian mixture models},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic item feature modeling for rating prediction in
recommender systems. <em>NEUCOM</em>, <em>549</em>, 126412. (<a
href="https://doi.org/10.1016/j.neucom.2023.126412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional recommendation methods focus on optimizing user and item representations using various modelling methods. While persistent features of items are well studied, time varying hidden features of items are largely neglected. We argue that it is desirable to model both static and dynamic representations of items in one framework. Moreover, dynamic features often exhibit periodic variation characteristics. Identifying dynamic features of items can help merchants recognize evolving trends of their product and provide better services to customers for more trading benefit. Based on our observations, a period-aware correlational-temporal user/item feature modeling method in the form of a double-chained BiGRU model with attention mechanism is proposed. Furthermore, heterogeneous graph-based meta-paths are incorporated to model static features of items. To the best of our knowledge, this is the first effort to model both static and dynamic representations of items in one setting. A h eterogeneous co rrelational temp oral framework (HCoTemp) fusing static and dynamic item representations along with dynamic user representation for sequential recommendation is proposed. Empirical studies of 4 Amazon review benchmark datasets demonstrate that our model outperforms state-of-the-art methods in both MSE and HR. We also conducted extensive ablation experiments, which reveal that each component of HCoTemp contributes to performance improvements. Randomly selected cases from the Amazon Game dataset also confirm our findings.},
  archive      = {J_NEUCOM},
  author       = {Xianglin Zuo and Shining Liang and Xiaosong Yuan and Shuang Yu and Bo Yang},
  doi          = {10.1016/j.neucom.2023.126412},
  journal      = {Neurocomputing},
  pages        = {126412},
  shortjournal = {Neurocomputing},
  title        = {Dynamic item feature modeling for rating prediction in recommender systems},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decorrelated spectral regression: An unsupervised dimension
reduction method under data selection bias. <em>NEUCOM</em>,
<em>549</em>, 126406. (<a
href="https://doi.org/10.1016/j.neucom.2023.126406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In manipulating high-dimensional data arising from real applications, dimension reduction methods have been proven to be effective and necessary. Nevertheless, the widespread selection bias, induced in the process of data collection, has long been unaware and its negative effects have been ignored. The accidental spurious correlation between the features brought by selection bias will deteriorate the performance of dimension reduction approaches. It is vital to remove such bias and consider its influence on dimension reduction. In this paper, we propose a novel decorrelated spectral regression algorithm for unsupervised dimension reduction on data with sample selection bias. In this method, the sample weights of the global feature distribution are learned by introducing the decorrelation regularizer. The learned weights are then combined with the regression model to obtain the dimension reduction mapping. Thus, the dimension reduction results are less affected by the accidental spurious correlation of data caused by selection bias. In addition, we also propose the updating rules of the parameters in our algorithm. A large number of experimental results on real-world datasets show that our method has achieved a significant improvement, indicating that it is effective and necessary to remove the accidental spurious correlation between features caused by selection bias in dimension reduction.},
  archive      = {J_NEUCOM},
  author       = {Xiuqi Huang and Haotian Ni and Tingjin Luo and Hong Tao and Chenping Hou},
  doi          = {10.1016/j.neucom.2023.126406},
  journal      = {Neurocomputing},
  pages        = {126406},
  shortjournal = {Neurocomputing},
  title        = {Decorrelated spectral regression: An unsupervised dimension reduction method under data selection bias},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural computing for grey richards differential equation to
forecast traffic parameters with various time granularity.
<em>NEUCOM</em>, <em>549</em>, 126394. (<a
href="https://doi.org/10.1016/j.neucom.2023.126394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing traffic parameter prediction methods generally adopt a single prediction model, but the fusion of different theories and methods can complement each other and improve the prediction performance of the model. Starting from the statistical distribution characteristics of traffic flow, this work introduces the Richards equation to conduct grey modeling, which is used to simulate the development trend of traffic parameters; and then fuses the abilities of error feedback adjustment and complex nonlinear fitting of neural network to estimate the parameters of the grey model and forecast the volatility of traffic flow respectively. At the same time, a dynamic prediction framework of real-time data update is built for the new model, and finally establish the dynamic grey Richards neural network model (DGR-NN).Apply the new model to different traffic parameters (Speed; Volume; Jam mileage) and data resolutions (5 min; 15 min; 1 h), the modeling effect of DGR-NN is significantly improved compared to the grey Richards model (GRM), and the training and testing errors of the model in the three forecast scenarios are reduced to varying degrees, where the testing MAPE, RMSE and STD are reduced by 1.80\% ∼ 10.87\%, 2.55\% ∼ 7.26\% and 8.08–25.56\% respectively. Furthermore, the results of the new model were verified and analyzed with the other five comparison models, among which the boxplot of APE shows that the error distribution of DGR-NN prediction data is concentrated and the value level is relatively low. It can be seen that DGR-NN can accurately and stably forecast traffic parameters of different time granularities .},
  archive      = {J_NEUCOM},
  author       = {Jing He and Shuhua Mao and Adolf K.Y. Ng},
  doi          = {10.1016/j.neucom.2023.126394},
  journal      = {Neurocomputing},
  pages        = {126394},
  shortjournal = {Neurocomputing},
  title        = {Neural computing for grey richards differential equation to forecast traffic parameters with various time granularity},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel welch-transform based enhanced spectro-temporal
analysis for cognitive microsleep detection using a single electrode
EEG. <em>NEUCOM</em>, <em>549</em>, 126387. (<a
href="https://doi.org/10.1016/j.neucom.2023.126387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand for semi-autonomous human–machine systems has led to an increased requirement for human fatigue detection. Direct and invasive approaches for microsleep detection include cognitive computing methods using Brain-Computer Interfaces (BCI). The contextual integration of multi-channel or heterogeneous signals for sleep staging remains a formidable challenge. In addition, the cost of acquiring many signals is significantly higher than that of acquiring a single signal. Consequently, researchers have recently attempted to utilize single-channel EEG over multi-channel acquisition systems for sleep staging. The Fast Fourier Transform (FFT) has been widely used in previous research findings for spectral analysis of complex time-series data streams. In contrast to the FFT, we utilize here, for the first time, the Welch Transform which can give higher stability in noise reduction for spectral analysis. Specifically, we provide a novel method to implement the short-time Welch transform (STWT) as an enhanced technique for the spectro-temporal analysis of single-electrode EEG signals. Further, our proposed model utilizes attention-based spatial and channel-wise inter-dependencies using a one-dimensional causal convolutional neural network (CNN) to extract contextual features automatically. Finally, we demonstrate an end-to-end proof of concept for our data extraction, adaptive data resampling, manual feature extraction, and deep-neural network-based modeling architecture. Comparative simulation results using the benchmark, maintenance of wake-fullness test (MWT) dataset for microsleep detection during automobile transportation, show that our proposed end-to-end system, utilizing novel STWT-based enhanced spectro-temporal analysis, outperforms current state-of-the-art methods, delivering 95\% and 89\% test accuracy for the case of temporal and spectral data inputs, respectively.},
  archive      = {J_NEUCOM},
  author       = {Jash Shah and Amit Chougule and Vinay Chamola and Amir Hussain},
  doi          = {10.1016/j.neucom.2023.126387},
  journal      = {Neurocomputing},
  pages        = {126387},
  shortjournal = {Neurocomputing},
  title        = {Novel welch-transform based enhanced spectro-temporal analysis for cognitive microsleep detection using a single electrode EEG},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An data augmentation method for source code summarization.
<em>NEUCOM</em>, <em>549</em>, 126385. (<a
href="https://doi.org/10.1016/j.neucom.2023.126385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code comments improve the readability and intelligibility of codes, Unfortunately, code comments are often missing, or outdated in software projects, which negatively affects the efficiency of developers to infer the functionality from source code and affect the efficiency of software maintenance and evolution. To solve this problem, many source code summarization algorithms have been proposed, which automatically generate code comments from source code. However, these methods usually try to collect a large data set which contains the mapping between code comments and source code to train models. However, there are two limitations for the training sets: the insufficient data collection limitation (i.e., generate a large amount of noises-free training data) and data distribution bias limitation (i.e., generate training data for infrequently used methods). To address this issues, we have proposed a data augmentation method for code comments, named CDA-CS. Training models on the augmented dataset, the state-of-the-art algorithms can easily get a further 1.37\% to 2.24\% improvement in terms of different evaluation metrics (i.e., BLUE-4, METEOR, ROUGH_L).},
  archive      = {J_NEUCOM},
  author       = {Zixuan Song and Hui Zeng and Xiuwei Shang and Guanxi Li and Hui Li and Shikai Guo},
  doi          = {10.1016/j.neucom.2023.126385},
  journal      = {Neurocomputing},
  pages        = {126385},
  shortjournal = {Neurocomputing},
  title        = {An data augmentation method for source code summarization},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-agent flocking collaborative control method for
stochastic dynamic environment via graph attention autoencoder based
reinforcement learning. <em>NEUCOM</em>, <em>549</em>, 126379. (<a
href="https://doi.org/10.1016/j.neucom.2023.126379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The environmental adaptability of the multi-agent flocking collaborative control system is vital to practical applications. Focusing on the adaptive problem of multi-agent flocking collaborative control system in stochastic dynamic environment, this paper proposes a distributed multi-agent flocking collaborative control algorithm based on a graph attention autoencoder (GAE) based multi-agent reinforcement learning (MARL). In our algorithm, a distance-based graph attention (GAT) mechanism is introduced into the networks of MARL to improve the non-stationarity problem of state transition in MARL caused by stochastic dynamic environment and enhance agents’ comprehension to the observation state. Based on the distance-based GAT, a GAE is designed to adapt to dynamic scale scenes. In addition, a global reward based strategy evaluation method is used to minimize the system loss of the flocking collaborative control system. The experimental results demonstrate that the proposed flocking algorithm has better environmental adaptability and better global control strategy than other RL-based flocking algorithms. The conclusion that the control strategies learned by our algorithm can be well transferred to the scenes with different agents and obstacles is also verified. This paper provides a novel and effective solution scheme to the multi-agent flocking collaborative control problem in a stochastic dynamic environment, which is conducive to promoting the application of flocking algorithm.},
  archive      = {J_NEUCOM},
  author       = {Jian Xiao and Guohui Yuan and Zhuoran Wang},
  doi          = {10.1016/j.neucom.2023.126379},
  journal      = {Neurocomputing},
  pages        = {126379},
  shortjournal = {Neurocomputing},
  title        = {A multi-agent flocking collaborative control method for stochastic dynamic environment via graph attention autoencoder based reinforcement learning},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Observer-based h∞ control of memristor-based neural networks
with unbounded time-varying delays. <em>NEUCOM</em>, <em>549</em>,
126357. (<a href="https://doi.org/10.1016/j.neucom.2023.126357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is devoted to developing observer-based H ∞ H∞ control of memristor-based neural networks with unbounded time-varying delays. A suitable observer is first designed, and then the controller is implemented based on the estimated states. Taking into account the dynamic equation of the MNN and that of the observer error, an augmented closed-loop system is given. By proposing a system solutions-based estimation method, sufficient conditions are obtained to guarantee that the augmented system is globally exponentially stable and satisfies a prescribed H ∞ H∞ performance level. This approach requires neither model transformation nor the construction of Lyapunov–Krasovskii functionals. In addition, the obtained sufficient conditions contain only a few scalar inequalities, which can be easily addressed by MATLAB. Finally, illustrative simulations are given to test the validity of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Xianhe Meng and Yantao Wang and Chunyan Liu},
  doi          = {10.1016/j.neucom.2023.126357},
  journal      = {Neurocomputing},
  pages        = {126357},
  shortjournal = {Neurocomputing},
  title        = {Observer-based h∞ control of memristor-based neural networks with unbounded time-varying delays},
  volume       = {549},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Task context transformer and GCN for few-shot learning of
cross-domain. <em>NEUCOM</em>, <em>548</em>, 126433. (<a
href="https://doi.org/10.1016/j.neucom.2023.126433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-Domain Few-Shot Learning (CD-FSL) to recognize new categories in a new domain with few samples has attracted significant attention. Recently, task-specific CD-FSL emerges as promising research for its great generalization. However, the existing task-specific CD-FSL methods are not robust enough in task context modeling and task-specific feature learning , especially under the cross-domain setting. To tackle this problem, a Task Context Transformer and Graph Convolutional Network (TCT-GCN) method for CD-FSL is proposed. The proposed TCT-GCN constructs three modules: 1) Multi-Level Feature Fusion , which fuses domain-shared low-level features into domain-unshared high-level features; 2) Transformer-based Task Context Encoder, which models sample order-independent task context; 3) Graph Convolutional Network-based Adaptive Feature Learner, which adaptively learns task-specific features. Experiments on eight CD-FSL datasets reveal the effectiveness of our TCT-GCN.},
  archive      = {J_NEUCOM},
  author       = {Pengfang Li and Fang Liu and Licheng Jiao and Lingling Li and Puhua Chen and Shuo Li},
  doi          = {10.1016/j.neucom.2023.126433},
  journal      = {Neurocomputing},
  pages        = {126433},
  shortjournal = {Neurocomputing},
  title        = {Task context transformer and GCN for few-shot learning of cross-domain},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced physics-informed neural networks with augmented
lagrangian relaxation method (AL-PINNs). <em>NEUCOM</em>, <em>548</em>,
126424. (<a href="https://doi.org/10.1016/j.neucom.2023.126424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINNs) have become a prominent application of deep learning in scientific computation, as they are powerful approximators of solutions to nonlinear partial differential equations (PDEs). There have been numerous attempts to facilitate the training process of PINNs by adjusting the weight of each component of the loss function, called adaptive loss-balancing algorithms. In this paper, we propose an Augmented Lagrangian relaxation method for PINNs (AL-PINNs). We treat the initial and boundary conditions as constraints for the optimization problem of the PDE residual. By employing Augmented Lagrangian relaxation , the constrained optimization problem becomes a sequential max–min problem so that the learnable parameters λ λ adaptively balance each loss component. Our theoretical analysis reveals that the sequence of minimizers of the proposed loss functions converges to an actual solution for the Helmholtz, viscous Burgers, and Klein–Gordon equations. We demonstrate through various numerical experiments that AL-PINNs yield a much smaller relative error compared with that of state-of-the-art adaptive loss-balancing algorithms.},
  archive      = {J_NEUCOM},
  author       = {Hwijae Son and Sung Woong Cho and Hyung Ju Hwang},
  doi          = {10.1016/j.neucom.2023.126424},
  journal      = {Neurocomputing},
  pages        = {126424},
  shortjournal = {Neurocomputing},
  title        = {Enhanced physics-informed neural networks with augmented lagrangian relaxation method (AL-PINNs)},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection for domain adaptation using complexity
measures and swarm intelligence. <em>NEUCOM</em>, <em>548</em>, 126422.
(<a href="https://doi.org/10.1016/j.neucom.2023.126422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle Swarm Optimization is an optimization algorithm that mimics the behaviour of a flock of birds, setting multiple particles that explore the search space guided by a fitness function in order to find the best possible solution. We apply the Sticky Binary Particle Swarm Optimization algorithm to perform feature selection for domain adaptation, a specific type of transfer learning in which the source and the target domain have a common feature space, a common task, but different distributions. When applying Particle Swarm Optimization, classification error is usually employed in the fitness function to evaluate the goodness of subsets of features. In this paper, we aim to compare this approach with using complexity metrics instead, under the assumption that reducing the complexity of the problem will lead to results that are independent from the classifier used for testing while being less computationally demanding. Therefore, we carried out experiments to compare the performance of both approaches in terms of classification accuracy, speed and number of features selected. We found out that our proposal, although in some cases incurs in a slight degradation of classification performance, it is indeed faster and selects fewer features, making it a feasible trade-off.},
  archive      = {J_NEUCOM},
  author       = {G. Castillo-García and L. Morán-Fernández and V. Bolón-Canedo},
  doi          = {10.1016/j.neucom.2023.126422},
  journal      = {Neurocomputing},
  pages        = {126422},
  shortjournal = {Neurocomputing},
  title        = {Feature selection for domain adaptation using complexity measures and swarm intelligence},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PSO-PARSIMONY: A method for finding parsimonious and
accurate machine learning models with particle swarm optimization.
Application for predicting force–displacement curves in t-stub steel
connections. <em>NEUCOM</em>, <em>548</em>, 126414. (<a
href="https://doi.org/10.1016/j.neucom.2023.126414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present PSO-PARSIMONY, a new methodology to search for parsimonious and highly accurate models by means of particle swarm optimization. PSO-PARSIMONY uses automatic hyperparameter optimization and feature selection to search for accurate models with low complexity. To evaluate the new proposal, a comparative study with multilayer perceptron algorithm was performed with public datasets and by applying it to predict two important parameters of the force–displacement curve in T-stub steel connections: initial stiffness and maximum strength. Models optimized with PSO-PARSIMONY showed an excellent trade-off between goodness-of-fit and parsimony. The new proposal was compared with GA-PARSIMONY, our previously published methodology that uses genetic algorithms in the optimization process. The new method needed more iterations and obtained slightly more complex individuals, but it performed better in the search for accurate models.},
  archive      = {J_NEUCOM},
  author       = {Jose Divasón and Julio Fernandez Ceniceros and Andres Sanz-Garcia and Alpha Pernia-Espinoza and Francisco Javier Martinez-de-Pison},
  doi          = {10.1016/j.neucom.2023.126414},
  journal      = {Neurocomputing},
  pages        = {126414},
  shortjournal = {Neurocomputing},
  title        = {PSO-PARSIMONY: A method for finding parsimonious and accurate machine learning models with particle swarm optimization. application for predicting force–displacement curves in T-stub steel connections},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning-based multimodal architecture to predict
signs of dementia. <em>NEUCOM</em>, <em>548</em>, 126413. (<a
href="https://doi.org/10.1016/j.neucom.2023.126413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a multimodal deep learning architecture combining text and audio information to predict dementia, a disease which affects around 55 million people all over the world and makes them in some cases dependent people. The system was evaluated on the DementiaBank Pitt Corpus dataset, which includes audio recordings as well as their transcriptions for healthy people and people with dementia. Different models have been used and tested, including Convolutional Neural Networks (CNN) for audio classification, Transformers for text classification , and a combination of both in a multimodal ensemble. These models have been evaluated on a test set, obtaining the best results by using the text modality, achieving 90.36\% accuracy on the task of detecting dementia. Additionally, an analysis of the corpus has been conducted for the sake of explainability, aiming to obtain more information about how the models generate their predictions and identify patterns in the data.},
  archive      = {J_NEUCOM},
  author       = {David Ortiz-Perez and Pablo Ruiz-Ponce and David Tomás and Jose Garcia-Rodriguez and M. Flores Vizcaya-Moreno and Marco Leo},
  doi          = {10.1016/j.neucom.2023.126413},
  journal      = {Neurocomputing},
  pages        = {126413},
  shortjournal = {Neurocomputing},
  title        = {A deep learning-based multimodal architecture to predict signs of dementia},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mutually aided uncertainty incorporated dual consistency
regularization with pseudo label for semi-supervised medical image
segmentation. <em>NEUCOM</em>, <em>548</em>, 126411. (<a
href="https://doi.org/10.1016/j.neucom.2023.126411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning has contributed plenty to promoting computer vision tasks . Especially concerning medical images, semi-supervised image segmentation can significantly reduce the labor and time cost of labeling images. Among the existing semi-supervised methods, pseudo-labelling and consistency regularization prevail; however, the current related methods still need to achieve satisfactory results due to the poor quality of the pseudo-labels generated and needing more certainty awareness the models. To address this problem, we propose a novel method that combines pseudo-labelling with dual consistency regularization based on a high capability of uncertainty awareness. This method leverages a cycle-loss regularized to lead to a more accurate uncertainty estimate. Followed by the uncertainty estimation , the certain region with its pseudo-label is further trained in a supervised manner. In contrast, the uncertain region is used to promote the dual consistency between the student and teacher networks. The developed approach was tested on three public datasets and showed that: 1) The proposed method achieves excellent performance improvement by leveraging unlabeled data ; 2) Compared with several state-of-the-art (SOTA) semi-supervised segmentation methods , ours achieved better or comparable performance.},
  archive      = {J_NEUCOM},
  author       = {Shanfu Lu and Zijian Zhang and Ziye Yan and Yiran Wang and Tingting Cheng and Rongrong Zhou and Guang Yang},
  doi          = {10.1016/j.neucom.2023.126411},
  journal      = {Neurocomputing},
  pages        = {126411},
  shortjournal = {Neurocomputing},
  title        = {Mutually aided uncertainty incorporated dual consistency regularization with pseudo label for semi-supervised medical image segmentation},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GFR: Generic feature representations for class incremental
learning. <em>NEUCOM</em>, <em>548</em>, 126410. (<a
href="https://doi.org/10.1016/j.neucom.2023.126410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning (CIL) aims to continuously learn new classes while maintaining discrimination for old classes with sequentially coming data. Due to the lack of old-class samples, existing CIL methods fail to learn discriminative representations for both old and new classes simultaneously, resulting in a severe performance drop in old classes, which is the well-known catastrophic forgetting phenomenon. Different from most existing works, we facilitate CIL by learning generic feature representations that perform well in seen and unseen classes. Specifically, we prove that representations with a substantial number of significant singular values benefit CIL via better old knowledge reservation. However, the overly uniform singular value spectrum will hurt the discrimination of current tasks. Furthermore, we propose that increasing the embedding dimension can enhance the number of significant singular values and validate this assumption from two perspectives: adopting different pooling techniques and devising a wider network. Meanwhile, we also prove that satisfactory current task accuracy and old knowledge reservation can be achieved simultaneously. Finally, the simple yet effective generic feature representation regulation (GFR) is devised and incorporated into two baselines. Extensive experiments are conducted on CIFAR100, ImageNet-Subset, and ImageNet. The results show that the proposed method boosts the performance of both baselines with a large margin (2.00\%-9.58\% on CIFAR100, 0.68\%-7.10\% on ImageNet-Subset and 1.18\%-5.04\% on ImageNet) which outperforms existing SOTAs.},
  archive      = {J_NEUCOM},
  author       = {Zhichuan Wang and Linfeng Xu and Zihuan Qiu and Qingbo Wu and Fanman Meng and Hongliang Li},
  doi          = {10.1016/j.neucom.2023.126410},
  journal      = {Neurocomputing},
  pages        = {126410},
  shortjournal = {Neurocomputing},
  title        = {GFR: Generic feature representations for class incremental learning},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BCRNet: Bidirectional contrastive representation network for
deep multimodal learning of exercise representations in online education
systems. <em>NEUCOM</em>, <em>548</em>, 126409. (<a
href="https://doi.org/10.1016/j.neucom.2023.126409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online education systems, learning exercise representation is a fundamental task in many applications, such as exercise retrieval and recommendation. To capture the heterogeneous data information of exercises (i.e., texts and images), deep multimodal approaches show the promising performance. However, these methods have two limitations: (1) they only care about context on one side, which fails to utilize the future context chunks in the exercises; (2) they cannot ensure the presentation ability due to the scarcity of labelled data. In this paper, we propose a bidirectional contrastive representation network (BCRNet) to tackle these issues. First, we construct a representation module with a masking constraint loss to take into account the bidirectional context contents of exercises. Second, we design a contrastive learning approach which uses a multimodal contrastive loss to reshape the multimodal representation space and improve model presentation ability without labelled data. Moreover, a text-image matching strategy is designed to provide semantic links between texts and images. On the real-world dataset, experiments demonstrate BCRNet performs significantly better than many strong baselines.},
  archive      = {J_NEUCOM},
  author       = {Jie Mu and Xianchao Zhang and Yujiao Du and Yuxiang Hu and Han Liu and Jian Xu},
  doi          = {10.1016/j.neucom.2023.126409},
  journal      = {Neurocomputing},
  pages        = {126409},
  shortjournal = {Neurocomputing},
  title        = {BCRNet: Bidirectional contrastive representation network for deep multimodal learning of exercise representations in online education systems},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating virtual samples to improve learning performance
in small datasets with non-linear and asymmetric distributions.
<em>NEUCOM</em>, <em>548</em>, 126408. (<a
href="https://doi.org/10.1016/j.neucom.2023.126408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s highly competitive environment, modeling the relationship between inputs and outputs using limited data for a management system at the early stages is important, but difficult. The virtual sample generation (VSG) method has been proposed in many studies to explore potential information to improve prediction performance of learning models for small datasets. However, those studies in general must assume an underlying distribution such as a linear triangular membership function or a Gaussian distribution to generate virtual samples. Thus, previous VSG methods may not effectively upgrade learning performance when the assumed distribution is not elastic enough for small datasets. To address this issue, in this paper, we proposed a novel VSG method called Newton-VSG method to generate virtual samples for small datasets with non-linear and asymmetric distributions. In the suggested method, we used Newton&#39;s method to estimate the minimum value of data range and the shape of data distribution. Further, we developed two deep learning models including Siamese network (SN) model for screening virtual sample input values and bagging auto-encoder (AE) model for predicting virtual sample output to ensure the quality of virtual samples. One real dataset for solidification cracking susceptibility test data and an other real dataset obtained from TFT-LCD process of a leading company in Taiwan were used to demonstrate the efficacy of the proposed method. On the partial least square regression (PLSR) and the back propagation neural network (BPNN) predictive models, we compared the proposed method with three state-of-the-art VSG methods in items of the mean absolute error (MAE) and the root mean squared error (RMSE). The experimental results demonstrated that the proposed method outperforms the other three VSG methods in prediction accuracy for small datasets.},
  archive      = {J_NEUCOM},
  author       = {Liang-Sian Lin and Yao-San Lin and Der-Chiang Li},
  doi          = {10.1016/j.neucom.2023.126408},
  journal      = {Neurocomputing},
  pages        = {126408},
  shortjournal = {Neurocomputing},
  title        = {Generating virtual samples to improve learning performance in small datasets with non-linear and asymmetric distributions},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedInf: Social influence prediction with federated learning.
<em>NEUCOM</em>, <em>548</em>, 126407. (<a
href="https://doi.org/10.1016/j.neucom.2023.126407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks are ubiquitous in contemporary society, where one’s opinions and behaviors are easily influenced by those around them. The effectiveness of social influence analysis has become significant for numerous application fields such as online recommendation, advertising, and viral marketing. Graph-based deep learning has achieved significant success in influence prediction. However, the existing methods ignore the privacy issue and are incapable of cross-organizational collaboration. Inspired by the recent success of federated learning in privacy protection and breaking the data barrier. In this paper, a novel federated learning framework, FedInf, is proposed to tackle the problem of social influence prediction. Specially, to further protect user privacy and achieve secure aggregation for multiple local models, we introduce differential privacy into the local parameters, adding artificial noise before model aggregation. In order to trade-off utility and privacy, we first freeze the embedding layers to reduce the number of upload parameters, and then project model parameters into low-dimensional space. Therefore, less noise is required to provide the same level of privacy protection. Extensive experiments on four real-world datasets demonstrate that the proposed FedInf is effective while providing privacy protection.},
  archive      = {J_NEUCOM},
  author       = {Lei Song and Hongbin Wang and Guoyin Zhang and Shui Yu},
  doi          = {10.1016/j.neucom.2023.126407},
  journal      = {Neurocomputing},
  pages        = {126407},
  shortjournal = {Neurocomputing},
  title        = {FedInf: Social influence prediction with federated learning},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple hypotheses based motion compensation for learned
video compression. <em>NEUCOM</em>, <em>548</em>, 126396. (<a
href="https://doi.org/10.1016/j.neucom.2023.126396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, learned video compression has attracted copious research attention. However, among the existing methods, the motion used for alignment is limited to one hypothesis only, leading to inaccurate motion estimation, especially for the complicated scenes with complex movements. Motivated by multiple hypotheses philosophy in traditional video compression , we develop the multiple hypotheses based motion compensation for the learned video compression, in an effort to enhance the motion compensation efficiency by providing diverse hypotheses with efficient temporal information fusion. In particular, the multiple hypotheses module which produces multiple motions and warped features for mining sufficient temporal information, is proposed to provide various hypotheses inferences from the reference frame. To utilize these hypotheses more copiously, the hypotheses attention module is adopted by introducing the channel-wised squeeze-and-excitation layer and the multi-scale network. In addition, the context combination is employed to fuse the weighted hypotheses to generate effective contexts with powerful temporal priors. Finally, the valid contexts are used for promoting the compression efficiency by merging weighted warped features. Extensive experiments show that the proposed method can significantly improve the rate-distortion performance of learned video compression. Compared with the state-of-the-art method for end-to-end video compression, over 13\% bit rate reductions on average in terms of PSNR and MS-SSIM can be achieved.},
  archive      = {J_NEUCOM},
  author       = {Rongqun Lin and Meng Wang and Pingping Zhang and Shiqi Wang and Sam Kwong},
  doi          = {10.1016/j.neucom.2023.126396},
  journal      = {Neurocomputing},
  pages        = {126396},
  shortjournal = {Neurocomputing},
  title        = {Multiple hypotheses based motion compensation for learned video compression},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Investigation of proper orthogonal decomposition for echo
state networks. <em>NEUCOM</em>, <em>548</em>, 126395. (<a
href="https://doi.org/10.1016/j.neucom.2023.126395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo State Networks (ESN) are a type of Recurrent Neural Network that yields promising results in representing time series and nonlinear dynamic systems. Although they are equipped with a very efficient training procedure, Reservoir Computing strategies, such as the ESN, require high-order networks, i.e., many neurons, resulting in a large number of states that are magnitudes higher than the number of model inputs and outputs. A large number of states not only makes the time-step computation more costly but also may pose robustness issues, especially when applying ESNs to problems such as Model Predictive Control (MPC) and other optimal control problems . One way to circumvent this complexity issue is through Model Order Reduction strategies such as the Proper Orthogonal Decomposition (POD) and its variants (POD-DEIM), whereby we find an equivalent lower order representation to an already trained high dimension ESN. To this end, this work aims to investigate and analyze the performance of POD methods in Echo State Networks , evaluating their effectiveness through the Memory Capacity (MC) of the POD-reduced network compared to the original (full-order) ESN. We also perform experiments on two numerical case studies: a NARMA10 difference equation and an oil platform containing two wells and one riser. The results show that there is little loss of performance comparing the original ESN to a POD-reduced counterpart and that the performance of a POD-reduced ESN tends to be superior to a normal ESN of the same size. Also, the POD-reduced network achieves speedups of around 80\% 80\% compared to the original ESN.},
  archive      = {J_NEUCOM},
  author       = {Jean Panaioti Jordanou and Eric Aislan Antonelo and Eduardo Camponogara and Eduardo Gildin},
  doi          = {10.1016/j.neucom.2023.126395},
  journal      = {Neurocomputing},
  pages        = {126395},
  shortjournal = {Neurocomputing},
  title        = {Investigation of proper orthogonal decomposition for echo state networks},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sequential recommendation model integrating micro-behaviors
and attribute enhancement. <em>NEUCOM</em>, <em>548</em>, 126393. (<a
href="https://doi.org/10.1016/j.neucom.2023.126393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation predicts the items that the user may interact with next based on the time-series information of the user-item interactions, and learns the users’ dynamic preferences. However, most existing sequential recommendation models ignore the micro-behaviors and the importance of attribute information. Thus, we propose a new model named Sequential Recommendation Model Integrating Micro-behaviors and Attribute Enhancement (SRMA). First, we build a user-item interaction graph and a user-item-attribute interaction graph by introducing user and item attributes. In addition, we perform the temporal attention embedding propagation in the user-item interaction graph, in which the multi-head attention is used to learn the temporal neighborhood weights under micro-behaviors. Simultaneously, we perform the attribute attention embedding propagation in the user-item-attribute interaction graph, which learns the high-hop interactions among users, items and attributes under micro-behaviors, and assigns different weights to attributes through the attribute attention. Finally, the prediction is made by combining the embedding of each layer in the two graphs. Experiments on two real datasets show that the model has good performance.},
  archive      = {J_NEUCOM},
  author       = {Yulan Gao and Xianying Huang and Jia Tao},
  doi          = {10.1016/j.neucom.2023.126393},
  journal      = {Neurocomputing},
  pages        = {126393},
  shortjournal = {Neurocomputing},
  title        = {Sequential recommendation model integrating micro-behaviors and attribute enhancement},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Learning graph representation by aggregating subgraphs via
mutual information maximization. <em>NEUCOM</em>, <em>548</em>, 126392.
(<a href="https://doi.org/10.1016/j.neucom.2023.126392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information theory has shown a notable performance in the field of computer vision (CV) and natural language processing (NLP), therefore, many works start to learn better node-level and graph-level representations in the information theory perspective. Previous works have shown great performance by maximizing the mutual information between graph and node representation to capture graph information . However, a simple mixture of information in a single node representation leads to a lack of information related to the graph structure, which leads to the information gap between model and theoretical optimal solution. To solve this problem, we propose to replace the node representation with subgraph representation to reduce the information gap between the model and the optimal case. And to capture enough information of original graph, three operators (information aggregators): attribute-conv , layer-conv and subgraph-conv , are designed to gather information from different aspects, respectively. Moreover, to generate more expressive subgraphs, we propose a universal framework to generate subgraphs autoregressively, which provides a comprehensive understanding of the graph structure in a learnable way. We proposed a Head–Tail negative sampling method to provide more negative samples for more efficient and effective contrastive learning . Moreover, all these components can be plugged into any existed Graph Neural Networks . Experimentally, we achieve new state-of-the-art results in several benchmarks under the unsupervised case. We also evaluate our model on semi-supervised learning tasks and make a fair comparison to state-of-the-art semi-supervised methods.},
  archive      = {J_NEUCOM},
  author       = {Ziwen Liu and Chenguang Wang and Congying Han and Tiande Guo},
  doi          = {10.1016/j.neucom.2023.126392},
  journal      = {Neurocomputing},
  pages        = {126392},
  shortjournal = {Neurocomputing},
  title        = {Learning graph representation by aggregating subgraphs via mutual information maximization},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining the theoretical bound and deep adversarial network
for machinery open-set diagnosis transfer. <em>NEUCOM</em>,
<em>548</em>, 126391. (<a
href="https://doi.org/10.1016/j.neucom.2023.126391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep transfer learning-based intelligent machine diagnosis has been well investigated, and the source and the target domain are commonly assumed to share the same fault categories, which can be called as the closed-set diagnosis transfer (CSDT). However, this assumption is hard to cover real engineering scenarios because some unknown new fault may occur unexpectedly due to the uncertainty and complexity of machinery components, which is called as the open-set diagnosis transfer (OSDT). To solve this challenging but more realistic problem, a Theory-guided Progressive Transfer Learning Network (TPTLN) is proposed in this paper. First, the upper bound of transfer learning model under open-set setting is thoroughly analyzed, which provides a theoretical insight to guide the model optimization. Second, a two-stage module is designed to carry out distracting unknown target samples and attracting known samples through progressive learning, which could effectively promote inter-class separability and intra-class compactness. The performance of proposed TPTLN is evaluated in two OSDT cases, where the diagnosis knowledge is transferred across bearings and gearbox running under different working conditions. Comparative results show that the proposed method achieves better robustness and diagnostic performance under different degrees of domain shift and openness variance. The source codes and links to the data can be found in the following GitHub repository: https://github.com/phoenixdyf/Theory-guided-Progressive-Transfer-LearningNetwork .},
  archive      = {J_NEUCOM},
  author       = {Yafei Deng and Jun Lv and Delin Huang and Shichang Du},
  doi          = {10.1016/j.neucom.2023.126391},
  journal      = {Neurocomputing},
  pages        = {126391},
  shortjournal = {Neurocomputing},
  title        = {Combining the theoretical bound and deep adversarial network for machinery open-set diagnosis transfer},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal attention fusion network for RGB-d semantic
segmentation. <em>NEUCOM</em>, <em>548</em>, 126389. (<a
href="https://doi.org/10.1016/j.neucom.2023.126389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D semantic segmentation is crucial for robots to understand scenes. Most existing methods take depth information as an additional input, leading to cross-modal semantic segmentation networks that cannot achieve the purpose of multi-scale global and local cross-modal feature complementation. In this paper, we propose a cross-modal attention fusion network for RGB-D semantic segmentation. Specifically, we adopt a coordinate attention feature interaction module (CA-FIM) to aggregate RGB and depth features at the spatial and channel levels through the coordinate attention mechanism . Then, the gated cross-attention feature fusion module (GC-FFM) fuses the expanded modal features to achieve cross-modal global inference by the gated cross-attention mechanism. Utilizing the above two modules in four stages of the network, our framework can learn multi-modal and multi-level information to reduce the uncertainty of the final prediction. Extensive experiments on the NYU Depth V2, SUN RGB-D, and Cityscapes datasets demonstrate that our cross-modal attention fusion network is effective in RGB-D semantic segmentation for various complicated scenes.},
  archive      = {J_NEUCOM},
  author       = {Qiankun Zhao and Yingcai Wan and Jiqian Xu and Lijin Fang},
  doi          = {10.1016/j.neucom.2023.126389},
  journal      = {Neurocomputing},
  pages        = {126389},
  shortjournal = {Neurocomputing},
  title        = {Cross-modal attention fusion network for RGB-D semantic segmentation},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-source point cloud registration: Challenges, progress
and prospects. <em>NEUCOM</em>, <em>548</em>, 126383. (<a
href="https://doi.org/10.1016/j.neucom.2023.126383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging topic of cross-source point cloud (CSPC) registration has attracted increasing attention with the fast development background of 3D sensor technologies. Different from the conventional same-source point clouds that focus on data from same kind of 3D sensor (e.g., Kinect), CSPCs come from different kinds of 3D sensors (e.g., Kinect and LiDAR). CSPC registration generalizes the requirement of data acquisition from same-source to different sources, which leads to generalized applications and combines the advantages of multiple sensors. In this paper, we provide a systematic review on CSPC registration. We first present the characteristics of CSPC, and then summarize the key challenges in this research area, followed by the corresponding research progress consisting of the most recent and representative developments on this topic. Finally, we discuss the important research directions in this vibrant area and explain the role in several application fields.},
  archive      = {J_NEUCOM},
  author       = {Xiaoshui Huang and Guofeng Mei and Jian Zhang},
  doi          = {10.1016/j.neucom.2023.126383},
  journal      = {Neurocomputing},
  pages        = {126383},
  shortjournal = {Neurocomputing},
  title        = {Cross-source point cloud registration: Challenges, progress and prospects},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-triggered bipartite formation-containment control for
heterogeneous multi-agent systems with disturbances. <em>NEUCOM</em>,
<em>548</em>, 126382. (<a
href="https://doi.org/10.1016/j.neucom.2023.126382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of the bipartite formation containment tracking for heterogeneous multi-agent systems is discussed in the present paper. The external disturbances are considered in the agent dynamic systems and the all state vectors are inaccessible. Therefore, unknown input observers are constructed for the followers to obtain the state and the disturbance estimates using an interval observer. Then to achieve the formation containment control, an event-triggered compensator state system is constructed for each follower using information from its neighbours to obtain the estimation of the convex hull formed by the output vectors of the leaders where Zeno behaviour is also excluded. Finally, a self-triggered protocol is proposed so that the triggering instants can be calculated locally to realize a fully distribute formation containment control. The performances of the presented method are demonstrated by the simulation of formation containment control for a heterogeneous MAS with a group of vehicles and unmanned aerial vehicles .},
  archive      = {J_NEUCOM},
  author       = {Younan Zhao and Fanglai Zhu and Dezhi Xu},
  doi          = {10.1016/j.neucom.2023.126382},
  journal      = {Neurocomputing},
  pages        = {126382},
  shortjournal = {Neurocomputing},
  title        = {Self-triggered bipartite formation-containment control for heterogeneous multi-agent systems with disturbances},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Policy ensemble gradient for continuous control problems in
deep reinforcement learning. <em>NEUCOM</em>, <em>548</em>, 126381. (<a
href="https://doi.org/10.1016/j.neucom.2023.126381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy gradient algorithms for reinforcement learning (RL) have successfully tackled a broad range of high-dimensional continuous RL problems, including many challenging robotic control problems. These algorithms can be largely divided into two categories, i.e., on-policy algorithms and off-policy algorithms. Off-policy deep RL (DRL) algorithms enjoy better sample efficiency than and often outperform on-policy algorithms. However, cutting-edge off-policy algorithms still suffer from the low-quality estimation of policy gradients, resulting in compromised learning performance and high sensitivity to hyper-parameter settings. To address this issue, we propose a new concept of robust policy gradient (RPG). Driven by RPG, this paper further develops a new policy ensemble gradient (PEG) algorithm for DRL, inspired by the recent success of several ensemble DRL algorithms. PEG efficiently and effectively estimates RPG by using multiple policy gradients obtained respectively from several off-policy base learners in an ensemble. The estimated RPG is then utilized for training all base learners simultaneously. Comprehensive experiments have been performed on six Mujoco benchmark problems. Compared to four state-of-the-art off-policy algorithms and four cutting-edge ensemble policy gradient algorithms, our new PEG algorithm achieved highly competitive stability, performance and sample efficiency. Further analysis shows that PEG is insensitive to varied hyper-parameter settings, confirming the positive role of RPG in building reliable and effective off-policy DRL algorithms.},
  archive      = {J_NEUCOM},
  author       = {Guoqiang Liu and Gang Chen and Victoria Huang},
  doi          = {10.1016/j.neucom.2023.126381},
  journal      = {Neurocomputing},
  pages        = {126381},
  shortjournal = {Neurocomputing},
  title        = {Policy ensemble gradient for continuous control problems in deep reinforcement learning},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel virtual sample generation method to improve the
quality of data and the accuracy of data-driven models. <em>NEUCOM</em>,
<em>548</em>, 126380. (<a
href="https://doi.org/10.1016/j.neucom.2023.126380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small data volume and data imbalance often lead to statistical failure and seriously restrict the accuracy of data-driven models, which has become a bottleneck problem, needing to be solved, in small sample modeling. The data expansion method has become the main way to solve small sample modeling. However, the randomness in the process of virtual sample generation and combination leads to many invalid data, resulting in poor consistency between the expanded data and the original data. For this reason, this paper proposes a virtual sample generation method based on acceptable area and joint probability distribution sampling (APS-VSG) to limit the randomness in the data expansion method, reduce the proportion of invalid data, improve data consistency after expansion, and improve the accuracy of the data-driven model under the condition of small samples. Firstly, the concept of “compact range of interaction (CRI)” was proposed, which further limits the domain estimation range of data to approximate the valid area of the data. Secondly, the prior knowledge was used to improve mega-trend-diffusion (MTD), and the CRI is delineated according to the trend dispersion to obtain the acceptable area of the virtual data. Finally, a joint probability distribution was constructed based on the true values of small samples in the acceptable area, and data sampling was conducted based on the probability distribution to generate virtual data. The experimental results of standard function datasets show that the virtual samples generated by the proposed method can ensure validity of more than 85\%. The experimental results of the NASA li-ion battery dataset show that, compared with Interpolation, Noise, MD-MTD, GAN, and GMM-VSG methods, the error of the data-driven model trained with virtual data generated by the proposed method is significantly reduced. Compared with GAN and GMM-VSG, MSE, RMSE, MAE, and MAPE are reduced by at least 19.3\%, 10.6\%, 15.4\%, and 16.7\%, respectively.},
  archive      = {J_NEUCOM},
  author       = {Zhiwen Chen and Zhigang Lv and Ruohai Di and Peng Wang and Xiaoyan Li and Xiaojing Sun and Yuntao Xu},
  doi          = {10.1016/j.neucom.2023.126380},
  journal      = {Neurocomputing},
  pages        = {126380},
  shortjournal = {Neurocomputing},
  title        = {A novel virtual sample generation method to improve the quality of data and the accuracy of data-driven models},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning in a spiking neural model of striatum
plasticity. <em>NEUCOM</em>, <em>548</em>, 126377. (<a
href="https://doi.org/10.1016/j.neucom.2023.126377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The basal ganglia (BG), and more specifically the striatum, have long been proposed to play an essential role in action-selection based on a reinforcement learning (RL) paradigm. However, some recent findings, such as striatal spike-timing-dependent plasticity (STDP) or striatal lateral connectivity, require further research and modelling as their respective roles are still not well understood. Theoretical models of spiking neurons with homeostatic mechanisms, lateral connectivity, and reward-modulated STDP have demonstrated a remarkable capability to learn sensorial patterns that statistically correlate with a rewarding signal. In this article, we implement a functional and biologically inspired network model of the striatum, where learning is based on a previously proposed learning rule called spike-timing-dependent eligibility (STDE), which captures important experimental features in the striatum. The proposed computational model can recognize complex input patterns and consistently choose rewarded actions to respond to such sensorial inputs. Moreover, we assess the role different neuronal and network features, such as homeostatic mechanisms and lateral inhibitory connections, play in action-selection with the proposed model. The homeostatic mechanisms make learning more robust (in terms of suitable parameters) and facilitate recovery after rewarding policy swapping, while lateral inhibitory connections are important when multiple input patterns are associated with the same rewarded action. Finally, according to our simulations, the optimal delay between the action and the dopaminergic feedback is obtained around 300 ms, as demonstrated in previous studies of RL and in biological studies.},
  archive      = {J_NEUCOM},
  author       = {Álvaro González-Redondo and Jesús Garrido and Francisco Naveros Arrabal and Jeanette Hellgren Kotaleski and Sten Grillner and Eduardo Ros},
  doi          = {10.1016/j.neucom.2023.126377},
  journal      = {Neurocomputing},
  pages        = {126377},
  shortjournal = {Neurocomputing},
  title        = {Reinforcement learning in a spiking neural model of striatum plasticity},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring the association between time series features and
forecasting by temporal aggregation using machine learning.
<em>NEUCOM</em>, <em>548</em>, 126376. (<a
href="https://doi.org/10.1016/j.neucom.2023.126376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a forecast of the total value over several time periods ahead is required, forecasters are presented with two temporal aggregation (TA) approaches to produce required forecasts: i) aggregated forecast (AF) or ii) aggregate data using non-overlapping temporal aggregation (AD). Often, the recommendation is to aggregate data to a frequency relevant to the decision the eventual forecast will support and then produce the forecast. However, this might not be always the best choice and we argue that both AF and AD approaches may outperform each other in different situations. Moreover, there is a lack of evidence on what indicators may determine the superiority of each approach. We design and execute an empirical experiment framework to first explore the performance of these approaches using monthly time series of M4 competition dataset. We further turn the problem into a classification supervised learning by constructing a database consisting of features of each time series as predictor and model class labelled as AF/AD as response/outcome. We then build machine learning algorithms to investigate the association between time series features and the performance of AF and AD. Our findings suggest that both AF and AD approaches may not consistently generate accurate results for every individual series. AF is shown to be significantly better than AD for the monthly M4 time series, especially for longer horizons. We build several machine learning approaches using a set of extracted time series features as input to predict accurately whether AD or AF should be used. We find out that Random Forest (RF) is the most accurate approach in correctly classifying the outcome assessed both by statistical measures such as misclassification error, F-statistics, area under the curve, and a utility measure. The RF approach reveals that curvature, nonlinearity, seas_pacf, unitroot_pp, mean, ARCHM.LM, Coefficient of Variation , stability, linearity, and max_level_shif are among the most important features in driving the predictions of the model. Our findings indicate that the strength of trend, ARCH.LM, hurst, autocorrelation lag 1, unitroot_pp, and seas_pacf may favour AF approach, while lumpiness, entropy, nonlinearity, curvature, and strength of seasonality may increase the chance of AD performing better. We conclude the study by summarising the findings and present an agenda for further research.},
  archive      = {J_NEUCOM},
  author       = {Bahman Rostami-Tabar and Dejan Mircetic},
  doi          = {10.1016/j.neucom.2023.126376},
  journal      = {Neurocomputing},
  pages        = {126376},
  shortjournal = {Neurocomputing},
  title        = {Exploring the association between time series features and forecasting by temporal aggregation using machine learning},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective multimodal representation and fusion method for
multimodal intent recognition. <em>NEUCOM</em>, <em>548</em>, 126373.
(<a href="https://doi.org/10.1016/j.neucom.2023.126373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intent recognition is a crucial task in natural language understanding. Current research mainly focuses on task-specific unimodal intent recognition. However, in real-world scenes, human intentions are complex and need to be judged by integrating information such as speech, tone, expression, and action. Therefore, this paper proposes an effective multimodal representation and fusion method (EMRFM) for intent recognition in real-world multimodal scenes. First, text, audio, and vision features are extracted based on pre-trained BERT, Wav2vec 2.0, and Faster R-CNN. Then, considering the complementarity and consistency among the modalities, the modality-shared and modality-specific encoders are constructed to learn shared and specific feature representations of the modalities. Finally, an adaptive multimodal fusion method based on an attention-based gated neural network is designed to eliminate noise features. Comprehensive experiments are conducted on the multimodal intent recognition MIntRec benchmark dataset. Our proposed model achieves higher accuracy, precision, recall, and F1-score than state-of-the-art multimodal learning methods. We also conduct multimodal sentiment recognition experiments on the CMU-MOSI dataset, and our model still outperforms state-of-the-art methods. In addition, the experiment demonstrates that the model’s multimodal representation well learned the modality’s shared and specific features. The multimodal fusion of the model achieves adaptive fusion and effectively reduces possible noise interference.},
  archive      = {J_NEUCOM},
  author       = {Xuejian Huang and Tinghuai Ma and Li Jia and Yuanjian Zhang and Huan Rong and Najla Alnabhan},
  doi          = {10.1016/j.neucom.2023.126373},
  journal      = {Neurocomputing},
  pages        = {126373},
  shortjournal = {Neurocomputing},
  title        = {An effective multimodal representation and fusion method for multimodal intent recognition},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Align-then-abstract representation learning for low-resource
summarization. <em>NEUCOM</em>, <em>548</em>, 126356. (<a
href="https://doi.org/10.1016/j.neucom.2023.126356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative transformer-based models have achieved state-of-the-art performance in text summarization. Nevertheless, they still struggle in real-world scenarios with long documents when trained in low-resource settings of a few dozen labeled training instances, namely in low-resource summarization (LRS). This paper bridges the gap by addressing two key research challenges when summarizing long documents, i.e., long-input processing and document representation, in one coherent model trained for LRS. Specifically, our novel align-then-abstract representation learning model ( Athena ) jointly trains a segmenter and a summarizer by maximizing the alignment between the chunk-target pairs in output from the text segmentation. Extensive experiments reveal that Athena outperforms the current state-of-the-art approaches in LRS on multiple long document summarization datasets from different domains.},
  archive      = {J_NEUCOM},
  author       = {Gianluca Moro and Luca Ragazzi},
  doi          = {10.1016/j.neucom.2023.126356},
  journal      = {Neurocomputing},
  pages        = {126356},
  shortjournal = {Neurocomputing},
  title        = {Align-then-abstract representation learning for low-resource summarization},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simple is good: Investigation of history-state ensemble deep
neural networks and their validation on rotating machinery fault
diagnosis. <em>NEUCOM</em>, <em>548</em>, 126353. (<a
href="https://doi.org/10.1016/j.neucom.2023.126353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work is motivated by the desire to find an efficient approach that can improve the performance of deep neural networks in a general sense. To this end, an easy-to-implement ensemble approach is proposed in this paper leveraging the ‘local sub-optima’ of deep networks, which is referred as to history-state ensemble (HSE) method. We demonstrated that neural networks can naturally generate multiple ‘local sub-optima’ with diversity during training process, and their combination can effectively improve the accuracy and stability of the single network. The merits of HSE are twofold: (1) It does not require additional training cost in order to acquire multiple base models, which is one of the main drawbacks limiting the generalization of ensemble techniques in deep learning. (2) It can be easily applied to any types of deep networks without tuning of network architectures. We proposed the simplest way to perform HSE and investigated more than 20 ensemble strategies for HSE as comparison. Experiments are conducted on six datasets and eight popular network architectures for the case of rotating machinery fault diagnosis. It is demonstrated that the stability and accuracy of neural networks can be generally improved through the simplest ensemble strategy proposed in this paper.},
  archive      = {J_NEUCOM},
  author       = {Yu Wang and Alexey Vinogradov},
  doi          = {10.1016/j.neucom.2023.126353},
  journal      = {Neurocomputing},
  pages        = {126353},
  shortjournal = {Neurocomputing},
  title        = {Simple is good: Investigation of history-state ensemble deep neural networks and their validation on rotating machinery fault diagnosis},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D human pose and shape estimation via de-occlusion
multi-task learning. <em>NEUCOM</em>, <em>548</em>, 126284. (<a
href="https://doi.org/10.1016/j.neucom.2023.126284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional human pose and shape estimation is to compute a full human 3D mesh given a single image. The contamination of features caused by occlusion usually degrades its performance significantly. Recent progress in this field typically addressed the occlusion problem implicitly. By contrast, in this paper, we address it explicitly using a simple yet effective de-occlusion multi-task learning network. Our key insight is that feature for mesh parameter regression should be noiseless. Thus, in the feature space, our method disentangles the occludee that represents the noiseless human feature from the occluder. Specifically, a spatial regularization and an attention mechanism are imposed in the backbone of our network to disentangle the features into different channels. Furthermore, two segmentation tasks are proposed to supervise the de-occlusion process. The final mesh model is regressed by the disentangled occlusion-aware features. Experiments on both occlusion and non-occlusion datasets are conducted, and the results prove that our method is superior to the state-of-the-art methods on two occlusion datasets, while achieving competitive performance on a non-occlusion dataset. We also demonstrate that the proposed de-occlusion strategy is the main factor to improve the robustness against occlusion. The code is available at https://github.com/qihangran/De-occlusion_MTL_HMR .},
  archive      = {J_NEUCOM},
  author       = {Hang Ran and Xin Ning and Weijun Li and Meilan Hao and Prayag Tiwari},
  doi          = {10.1016/j.neucom.2023.126284},
  journal      = {Neurocomputing},
  pages        = {126284},
  shortjournal = {Neurocomputing},
  title        = {3D human pose and shape estimation via de-occlusion multi-task learning},
  volume       = {548},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stability and hopf bifurcation analysis for fractional-order
SVEIR computer virus propagation model with nonlinear incident rate and
two delays. <em>NEUCOM</em>, <em>547</em>, 126397. (<a
href="https://doi.org/10.1016/j.neucom.2023.126397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the stability and Hopf bifurcation for a fractional-order Susceptible-Vaccinated-Exposed-Infectious-Recovered (SVEIR) computer virus propagation model with a nonlinear incident rate. By employing the linearization technique and Routh-Hurwitz method, the sufficient criterion is established for the locally asymptotic stability of endemic equilibrium point. The Hopf bifurcation is also studied for the SVEIR computer virus model by taking time delay as the bifurcation parameter . The research results show that the stability and Hopf bifurcation of proposed model are significantly affected by both time delay and the order of the fractional derivative. Examples with proper parameters and several simulations are given to illustrate the validity of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Linji Yang and Qiankun Song and Yurong Liu},
  doi          = {10.1016/j.neucom.2023.126397},
  journal      = {Neurocomputing},
  pages        = {126397},
  shortjournal = {Neurocomputing},
  title        = {Stability and hopf bifurcation analysis for fractional-order SVEIR computer virus propagation model with nonlinear incident rate and two delays},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neuromorphic high-frequency 3D dancing pose estimation in
dynamic environment. <em>NEUCOM</em>, <em>547</em>, 126388. (<a
href="https://doi.org/10.1016/j.neucom.2023.126388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology-mediated dance experiences, as a medium of entertainment, are a key element in both traditional and virtual reality-based gaming platforms. These platforms predominantly depend on unobtrusive and continuous human pose estimation as a means of capturing input. Current solutions primarily employ RGB or RGB-Depth cameras for dance gaming applications; however, the former is hindered by low-light conditions due to motion blur and reduced sensitivity, while the latter exhibits excessive power consumption, diminished frame rates, and restricted operational distance. Boasting ultra-low latency, energy efficiency, and a wide dynamic range, neuromorphic cameras present a viable solution to surmount these limitations. Here, we introduce YeLan , a neuromorphic camera-driven, three-dimensional, high-frequency human pose estimation (HPE) system capable of withstanding low-light environments and dynamic backgrounds. We have compiled the first-ever neuromorphic camera dance HPE dataset and devised a fully adaptable motion-to-event, physics-conscious simulator. YeLan surpasses baseline models under strenuous conditions and exhibits resilience against varying clothing types, background motion, viewing angles, occlusions, and lighting fluctuations.},
  archive      = {J_NEUCOM},
  author       = {Zhongyang Zhang and Kaidong Chai and Haowen Yu and Ramzi Majaj and Francesca Walsh and Edward Wang and Upal Mahbub and Hava Siegelmann and Donghyun Kim and Tauhidur Rahman},
  doi          = {10.1016/j.neucom.2023.126388},
  journal      = {Neurocomputing},
  pages        = {126388},
  shortjournal = {Neurocomputing},
  title        = {Neuromorphic high-frequency 3D dancing pose estimation in dynamic environment},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-sensor fusion particle filtering for boolean networks
with multi-step randomly-delayed measurements. <em>NEUCOM</em>,
<em>547</em>, 126386. (<a
href="https://doi.org/10.1016/j.neucom.2023.126386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with developing particle filters for Boolean networks with multi-step randomly-delayed measurements. Based on the semi-tensor product of matrices and dummy selection matrices, a generalized measurement model including multi-step randomly-delayed measurements is introduced. Besides, multi-sensor fusion particle filtering is proposed and two recursive algorithms are designed to minimize the mean-square estimation errors by fusing multi-sensor measurements. Simulation results show the effectiveness of the proposed multi-sensor fusion particle filters. It can be seen from the simulation results that the estimation performance of multi-sensor fusion has been improved compared to that of one sensor.},
  archive      = {J_NEUCOM},
  author       = {Shao Shao and Linying Xiang},
  doi          = {10.1016/j.neucom.2023.126386},
  journal      = {Neurocomputing},
  pages        = {126386},
  shortjournal = {Neurocomputing},
  title        = {Multi-sensor fusion particle filtering for boolean networks with multi-step randomly-delayed measurements},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PETNet: A YOLO-based prior enhanced transformer network for
aerial image detection. <em>NEUCOM</em>, <em>547</em>, 126384. (<a
href="https://doi.org/10.1016/j.neucom.2023.126384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) have been applied to inspect in various scenarios due to their high efficiency, low cost, and excellent mobility. However, the objects in aerial images are much smaller and denser than general objects, causing it difficult for current object detection methods to achieve the expected results. To solve this issue, a prior enhanced Transformer network (PETNet) based on YOLO is proposed in this paper. Specifically, a novel prior enhanced Transformer (PET) module and a one-to-many feature fusion (OMFF) mechanism are proposed to embed into the network. Two additional detection heads are added to the shallow feature maps. In this work, PET is used to capture enhanced global information to improve the expressive ability of the network. The OMFF aims to fuse multi-type features to minimize the information loss of small objects. In addition, the added detection heads provide more possibility of detecting smaller-scale objects, and the extended multi-head parallel detection is more suitable for the multi-scale transformation of objects in aerial images. On the VisDrone-2021 and UAVDT databases, the proposed PETNet achieves state-of-the-art results with average precision (AP) of 35.3 and 21.5, respectively, which indicates that the proposed network is more suitable for aerial image detection and is of a great reference value.},
  archive      = {J_NEUCOM},
  author       = {Tianyu Wang and Zhongjing Ma and Tao Yang and Suli Zou},
  doi          = {10.1016/j.neucom.2023.126384},
  journal      = {Neurocomputing},
  pages        = {126384},
  shortjournal = {Neurocomputing},
  title        = {PETNet: A YOLO-based prior enhanced transformer network for aerial image detection},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reduced-reference image deblurring quality assessment based
on multi-scale feature enhancement and aggregation. <em>NEUCOM</em>,
<em>547</em>, 126378. (<a
href="https://doi.org/10.1016/j.neucom.2023.126378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image deblurring is a basic task in the field of computer vision, and has attracted much attention because of its application prospects in traffic monitoring and medical imaging , etc. Due to the inherent weakness of the model, it is difficult to obtain well-pleasing deblurred images for all the visual contents so far. Therefore, how to objectively evaluate the quality of these deblurred results is very important for the rapid development of image deblurring. In recent years, numerous convolutional neural networks based quality assessment methods have been proposed to automatically predict the quality of synthetic and authentic distorted images, producing results that are mildly consistent with subjective perception. However, they are limited in Image Deblurring Quality Assessment (IDQA). For IDQA, it is more meaningful to predict the quality difference of blurry-deblurred image (BDI) pair than to make prediction on single deblurred image. Inspired by this, we propose a novel reduced-reference image deblurring quality assessment method based on multi-scale feature enhancement and aggregation. Firstly, the multi-scale features of BDI pair are generated from a versatile vision Transformer . Secondly, the discrepancy information is exploited to implicitly enhance the initial deep features. Finally, the enhanced features of different scales are aggregated and then mapped to the quality difference of BDI pair. Experimental results on four challenging datasets demonstrate that the proposed method is superior to the state-of-the-art quality assessment methods.},
  archive      = {J_NEUCOM},
  author       = {Bo Hu and Shuaijian Wang and Xinbo Gao and Leida Li and Ji Gan and Xixi Nie},
  doi          = {10.1016/j.neucom.2023.126378},
  journal      = {Neurocomputing},
  pages        = {126378},
  shortjournal = {Neurocomputing},
  title        = {Reduced-reference image deblurring quality assessment based on multi-scale feature enhancement and aggregation},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Dynamic updating self-training for semi-weakly supervised
object detection. <em>NEUCOM</em>, <em>547</em>, 126375. (<a
href="https://doi.org/10.1016/j.neucom.2023.126375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-weakly supervised object detection (SWSOD) needs to label only a small portion of images in the training set to train an initial detector. This detector is then used to select some reliable unlabeled images and generate pseudo labels for them. The pseudo-labeled images are combined with the labeled images to re-train the detector. One potential problem of SWSOD is that some pseudo labels could be incorrect so that the detector cannot be improved progressively. To address this problem, we propose a dynamic updating self-training (DUST) mechanism, which divides unlabeled images into multiple folds ranging from simple to complex and dynamically updates pseudo labels. In each fold, we apply an intra-fold updating at each training iteration to iteratively select some images from the current fold and update their pseudo labels to retrain the detector. At the end of each fold, we apply an inter-fold updating to update the pseudo labels of all previous folds and transfer the remaining unlabeled images into the next fold for further pseudo labels mining. To reduce the influence of noisy labels during the intra-fold updating, we propose a label reliability sensitive (LRS) loss for the labeled images to weigh the cross entropy. Meanwhile, a sample difficulty sensitive (SDS) loss is proposed for unlabeled images to balance the contributions of samples with different confidences. Extensive experiments on PASCAL VOC and MS-COCO benchmarks demonstrate the effectiveness of our method. For instance, by using 20 positive images and 20 negative images in each category as the labeled images, our method outperforms the state-of-the-art method [46] by 4.1\% and achieves 93\% of the WSOD performance on the PASCAL VOC 2007 dataset.},
  archive      = {J_NEUCOM},
  author       = {Ming Zhang and Shuaicheng Liu and Bing Zeng},
  doi          = {10.1016/j.neucom.2023.126375},
  journal      = {Neurocomputing},
  pages        = {126375},
  shortjournal = {Neurocomputing},
  title        = {Dynamic updating self-training for semi-weakly supervised object detection},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AAIN: Attentional aggregative interaction network for deep
learning based recommender systems. <em>NEUCOM</em>, <em>547</em>,
126374. (<a href="https://doi.org/10.1016/j.neucom.2023.126374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature engineering is a classical problem in recommender systems , and feature interactions is one of the most important parts of feature engineering. Factorization based models are widely used for explicit feature interactions. However, most current works utilize separate features to model cross features. Such a pattern limits the significance of cross features, since realistic recommendation scenarios are rich in associations between features. In this paper, we classify the basic feature interactions into sum-interaction and product-interaction, and improve the current general strategy of explicit feature interactions. Based on these theoretical studies, we propose a novel explicit feature interactions model Attentional Aggregative Interaction Network (AAIN), which models higher-order features using a cyclic explicit module. Specifically, we introduce attention mechanism for the reorganization of separate features, followed by product-interaction and higher-order features’ compression and output. The model is efficient since: 1) AAIN automatically learns high-order feature interactions and filters them with different weights. 2) AAIN optimizes the interaction between features into the interaction between feature groups, which allows for other relevant information to be considered when performing interactions. Furthermore, we integrate AAIN model with the classical deep neural network (DNN) model into a new model Deep Attentional Aggregative Interaction Network (DAAIN). Experiments on real-world datasets show that our models achieve state-of-the-art results.},
  archive      = {J_NEUCOM},
  author       = {Haitao He and Ruixi Zhang and Yangsen Zhang and Jiadong Ren},
  doi          = {10.1016/j.neucom.2023.126374},
  journal      = {Neurocomputing},
  pages        = {126374},
  shortjournal = {Neurocomputing},
  title        = {AAIN: Attentional aggregative interaction network for deep learning based recommender systems},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Perturbations of tensor-schur decomposition and its
applications to multilinear control systems and facial recognitions.
<em>NEUCOM</em>, <em>547</em>, 126359. (<a
href="https://doi.org/10.1016/j.neucom.2023.126359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perturbation analysis has been primarily considered to be one of the main issues in many fields. The Schur decomposition can factor a square matrix as the product of a unitary matrix and an upper triangular matrix , which contains eigenvalues of the square matrix. In view of the importance of T-eigenvalue problems, this paper discusses a tensor Schur decomposition (T-Schur), the T-Schur decomposition = U ∗ T ∗ U ∗ =U∗T∗U∗ , which is based on T-product multiplication of third-order tensors. We present the normwise and componentwise perturbation analysis for the unitary tensor U U , the upper triangular tensor T T and T-eigenvalues of the tensor A A . We explore some applications of the T-Schur decomposition and perform the T-Schur form to solve the tensor pole assignment. We give an algorithm to solve the tensor based T-Sylvester equation and present its perturbation bound and the backward error . The T-Sylvester equation can also be used to estimate the condition of the T-sign function. We apply the T-Schur decomposition to facial recognation and compare it with other types of tensor decompositions.},
  archive      = {J_NEUCOM},
  author       = {Juefei Chen and Wanli Ma and Yun Miao and Yimin Wei},
  doi          = {10.1016/j.neucom.2023.126359},
  journal      = {Neurocomputing},
  pages        = {126359},
  shortjournal = {Neurocomputing},
  title        = {Perturbations of tensor-schur decomposition and its applications to multilinear control systems and facial recognitions},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature-aware conditional GAN for category text generation.
<em>NEUCOM</em>, <em>547</em>, 126352. (<a
href="https://doi.org/10.1016/j.neucom.2023.126352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Category text generation receives considerable attentions since it is beneficial for various natural language processing tasks. Recently, the generative adversarial network (GAN) has attained promising performance in text generation, attributed to its adversarial training process. However, there are several issues in text GANs, including discreteness, training instability, mode collapse, lack of diversity and controllability etc. To address these issues, this paper proposes a novel GAN framework, the feature-aware conditional GAN (FA-GAN), for controllable category text generation. In FA-GAN, the generator has a sequence-to-sequence structure for improving sentence diversity, which consists of three encoders including a special feature-aware encoder and a category-aware encoder, and one relational-memory-core-based decoder with the Gumbel SoftMax activation function . The discriminator has an additional category classification head. To generate sentences with specified categories, the multi-class classification loss is supplemented in the adversarial training . Comprehensive experiments have been conducted, and the results show that FA-GAN consistently outperforms 10 state-of-the-art text generation approaches on 6 text classification datasets. The case study demonstrates that the synthetic sentences generated by FA-GAN can match the required categories and are aware of the features of conditioned sentences, with good readability, fluency, and text authenticity.},
  archive      = {J_NEUCOM},
  author       = {Xinze Li and Kezhi Mao and Fanfan Lin and Zijian Feng},
  doi          = {10.1016/j.neucom.2023.126352},
  journal      = {Neurocomputing},
  pages        = {126352},
  shortjournal = {Neurocomputing},
  title        = {Feature-aware conditional GAN for category text generation},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Future-guided offline imitation learning for long action
sequences via video interpolation and future-trajectory prediction.
<em>NEUCOM</em>, <em>547</em>, 126325. (<a
href="https://doi.org/10.1016/j.neucom.2023.126325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation learning is the task of optimizing a policy network to imitate demonstrations. The policy sequentially predicts each time-step action based on observations. The observations are videos in this study. Offline imitation learning only uses a pre-collected demonstration dataset to train the policy and thus is applicable even in scenarios where interaction with the environment, or exploration, is impractical in the training stage. One of the problems of offline imitation learning is error accumulation. Since the prediction error is accumulated along time-steps, the distribution of future observations is gradually shifted from the pre-collected dataset. One of the solutions is utilizing a forward dynamics model that predicts the observation of the shifted distribution from past observations and actions. This forward dynamics model enables the optimization of the policy to minimize the accumulated error. However, there are still the following two problems: (1) Since predicting future observations is an extrapolation problem, it is difficult to predict observations correctly because of the uncertainty. (2) Since the policy and the forward dynamics model are used recurrently, optimizing the policy with long sequences takes a vast amount of memory. In this paper, we resolve these problems using (1) a new forward dynamics model that predicts the observation as interpolation and (2) auxiliary learning of future-trajectory images that makes a policy learn the ideal future state without recurrent learning . We demonstrate that our proposed methods reduce the accumulated error and improve the task success rate in various robot manipulation tasks in a simulator.},
  archive      = {J_NEUCOM},
  author       = {Takeru Oba and Norimichi Ukita},
  doi          = {10.1016/j.neucom.2023.126325},
  journal      = {Neurocomputing},
  pages        = {126325},
  shortjournal = {Neurocomputing},
  title        = {Future-guided offline imitation learning for long action sequences via video interpolation and future-trajectory prediction},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anchor-based multi-view subspace clustering with graph
learning. <em>NEUCOM</em>, <em>547</em>, 126320. (<a
href="https://doi.org/10.1016/j.neucom.2023.126320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) has been drawn wide attentions in the area of pattern recognition and data mining. However, for a multi-view dataset with n samples and V views from k clusters, MVSC commonly requires O ( Vn 2 ) O(Vn2) memory for storing the view-specific graph matrices and O ( n 3 ) O(n3) time for the eigenvalue decomposition of a shared graph matrix. Hence, most of MVSC methods are difficult to handle the large-scale multi-view data problem. To address this issue, this paper proposes an Anchor-based Multi-View Subspace Clustering with Graph Learning (AMVSCGL) method. Instead of constructing a n × n n×n graph matrix, our method generates a shared coefficient matrix with the size of n × k n×k based on few learned view-specific anchors. Moreover, through further merging a graph learning term, this shared coefficient matrix can simultaneously capture the global and local information among multiple views and few learned view-specific anchors for clustering. Experimental results on seven large-scale multi-view data verify our AMVSCGL’s effectiveness and superiority in comparison with some state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Chao Su and Haoliang Yuan and Loi Lei Lai and Qiang Yang},
  doi          = {10.1016/j.neucom.2023.126320},
  journal      = {Neurocomputing},
  pages        = {126320},
  shortjournal = {Neurocomputing},
  title        = {Anchor-based multi-view subspace clustering with graph learning},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-objective memetic algorithm for automatic
adversarial attack optimization design. <em>NEUCOM</em>, <em>547</em>,
126318. (<a href="https://doi.org/10.1016/j.neucom.2023.126318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of adversarial examples has been revealed in variant scenarios. Recent studies show that well-designed adversarial defense strategies can improve the robustness of deep learning models against adversarial examples . However, with the rapid development of defense technologies, it also tends to be more difficult to evaluate the robustness of the defensed model due to the weak performance of existing manually designed adversarial attacks . To address the challenge, given the defensed model, the efficient adversarial attack with less computational burden and lower robust accuracy is needed to be further exploited. Therefore, we propose a multi-objective memetic algorithm for auto adversarial attack optimization design, which realizes the automatic search for the near-optimal adversarial attack towards defensed models. Firstly, the more general mathematical model of auto adversarial attack optimization design is constructed, where the search space includes not only the attacker operations, magnitude, iteration number, and loss functions but also the connection ways of multiple adversarial attacks . In addition, we develop a multi-objective memetic algorithm combining NSGA-II and local search to solve the optimization problem . Finally, to decrease the evaluation cost during the search, we propose a representative data selection strategy based on sorting cross entropy loss values of images output by models. Experiments on CIFAR10, CIFAR100, and ImageNet datasets show that our method can efficiently find near-optimal adversarial attacks with lower robust accuracy and less time cost, which can provide more reliable and efficient robustness evaluation for defensed models.},
  archive      = {J_NEUCOM},
  author       = {Jialiang Sun and Wen Yao and Tingsong Jiang and Xiaoqian Chen},
  doi          = {10.1016/j.neucom.2023.126318},
  journal      = {Neurocomputing},
  pages        = {126318},
  shortjournal = {Neurocomputing},
  title        = {A multi-objective memetic algorithm for automatic adversarial attack optimization design},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fourier-based type-2 fuzzy neural network: Simple and
effective for high dimensional problems. <em>NEUCOM</em>, <em>547</em>,
126316. (<a href="https://doi.org/10.1016/j.neucom.2023.126316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main contribution of this study is to introduce a simple and effective deep learning Fourier-based type-2 fuzzy neural network for high-dimensional problems. The rules are directly constructed by fast Fourier transformation. The input matrix/vector is segmented, and each segment represents a fuzzy rule. The upper/lower bounds of rule firings are obtained by the Fourier transformation approach. The output is computed by a simple type-reduction method. All antecedent and consequent parameters are optimized by simple gradient descent and fuzzy correntropy-based extended Kalman filter . The kernel size of a conventional correntropy-based filters is determined by a fuzzy system. The convergence of the learning method is proved by the Lyapunov method. The effectiveness of the suggested approach is verified by the face recognition problem (1024 input variables), English handwriting digit recognition (1024 input variables), and modeling problem with real-world data set (32 input variables). The simulations and comparisons demonstrate the superiority of the introduced scheme.},
  archive      = {J_NEUCOM},
  author       = {Ardashir Mohammadzadeh and Chunwei Zhang and Khalid A. Alattas and Fayez F.M. El-Sousy and Mai The Vu},
  doi          = {10.1016/j.neucom.2023.126316},
  journal      = {Neurocomputing},
  pages        = {126316},
  shortjournal = {Neurocomputing},
  title        = {Fourier-based type-2 fuzzy neural network: Simple and effective for high dimensional problems},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep actor critic reinforcement learning framework for
learning to rank. <em>NEUCOM</em>, <em>547</em>, 126314. (<a
href="https://doi.org/10.1016/j.neucom.2023.126314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a Deep Reinforcement learning based approach for Learning to rank task. Reinforcement Learning has been applied in the ranking task with good success, but the existing Policy Gradient based approaches suffer from noisy gradients and high variance, resulting in unstable learning. The natural policy gradient methods like REINFORCE perform Monte Carlo sampling, thus taking samples randomly, which leads to high variance. As the action space becomes large, i.e., with a very large number of documents, traditional RL techniques lack the complex model required in the scenario to deal with a large number of items. We propose a Deep Reinforcement learning based approach for learning to rank task in this paper to address these issues. By combining Deep learning with the Reinforcement Learning framework, our approach can learn a complex function as deep neural networks can provide significant function approximation. We used Actor-Critic framework where the critic network can reduce variance by utilizing techniques such as clipped delayed policy updates, clipped double q learning, etc. Also, due to the enormous space of the web, the most relevant results are needed to be returned for the corresponding query from within a large action space. Policy gradient algorithms have been effectively applied to problems in large action spaces(items) with deep neural networks as they don’t rely on finding value for each action(item) as in value-based methods. Further, we use an actor-network with a CNN layer in the ranking process to capture the sequential patterns among the documents. We utilize the TD3 method to train our Reinforcement Learning agent with a listwise loss function, which performs delayed policy updates resulting in value estimates with lower variance. To the best of our knowledge, this is the first Deep reinforcement learning method applied in Learning to Rank for document retrieval. We performed experiments on the various Letor datasets and showed that our method outperforms various state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Vaibhav Padhye and Kailasam Lakshmanan},
  doi          = {10.1016/j.neucom.2023.126314},
  journal      = {Neurocomputing},
  pages        = {126314},
  shortjournal = {Neurocomputing},
  title        = {A deep actor critic reinforcement learning framework for learning to rank},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SGAT: Snapshot-guided adversarial training of neural
networks. <em>NEUCOM</em>, <em>547</em>, 126294. (<a
href="https://doi.org/10.1016/j.neucom.2023.126294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that ensembles of different models can achieve better performance. Unfortunately, training multiple deep neural networks is time-consuming and expensive. Also, they require more space for storage and more computation for inference, making them unsuitable for applications with limited resources, such as mobile and embedded devices. To address these two fundamental problems in ensemble learning, we propose a novel method called Snapshot-Guided Adversarial Training (SGAT) to automatically accumulate and distill knowledge from the training, where knowledge from the earlier training iterations of the network is distilled, and transferred into its late training iterations via an adversarial learning strategy. To accumulate knowledge from the training process, we employ a cyclic annealing schedule and take a model snapshot at the end of each training interval. Furthermore, we use a shared discriminator to encourage the distillation process. The main advantages of our method are: (1) We can directly train a network with its free snapshots for knowledge distillation, instead of heavily depending on pre-trained models; (2) the inference cost remains the same as using a single model after finishing knowledge transferring; (3) SGAT is a general method and can be applied to the existing network architectures. Our extensive experiments show that SGAT consistently outperforms the standing training method with a clear margin. For example, with the same training budget, it achieves 2.86\% more accuracy on average than the baseline when training MobileNet-V2 from scratch on CIFAR-100. Meanwhile, SGAT also achieves better performance in most cases than the existing ensemble method and knowledge distillation. For example, to train MobileNet-V2 from scratch on ImageNet, it gets 0.7\% more accuracy than snapshot ensembles, and 0.93\% more accuracy than snapshot distillation. More importantly, our accumulated learning strategy makes SGAT achieve much better performance when we increase training time. For example, compared with the standard training method for MobileNet-V2, it gets 3.13\% more accuracy on ImageNet.},
  archive      = {J_NEUCOM},
  author       = {Wen Xu and Jing He and Yanfeng Shu and Guangyan Huang},
  doi          = {10.1016/j.neucom.2023.126294},
  journal      = {Neurocomputing},
  pages        = {126294},
  shortjournal = {Neurocomputing},
  title        = {SGAT: Snapshot-guided adversarial training of neural networks},
  volume       = {547},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DOLG-NeXt: Convolutional neural network with deep orthogonal
fusion of local and global features for biomedical image segmentation.
<em>NEUCOM</em>, <em>546</em>, 126362. (<a
href="https://doi.org/10.1016/j.neucom.2023.126362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical image segmentation (BMIS) is an essential yet challenging task for the visual analysis of biomedical images. Modern deep learning-based architectures, such as UNet, UNet-based variants, Transformers-based networks, and their combinations, have achieved reasonable success in BMIS. However, they still face certain shortcomings in extracting fine-grained features. They are also limited by scenarios where the modeling of local and global feature representations needs to be optimized correctly for spatial dependency in the decoding process, which can result in duplicate data utilization throughout the architecture. Besides, Transformer-based models lack inductive bias in addition to the complexity of the models. As a result, it can perform unsatisfactorily in a lesser biomedical image setting. This paper proposes a novel encode-decoder architecture named DOLG-NeXt, incorporating three major enhancements over the UNet-based variants. Firstly, we integrate squeeze and excitation network (SE-Net)-driven ConvNeXt stages as encoder backbone for effective feature extraction. Secondly, we employ a deep orthogonal fusion of local and global (DOLG) features module in the decoder to retrieve fine-grained contextual feature representations. Finally, we construct a SE-Net-like lightweight attention network alongside the DOLG module to provide refined target-relevant channel-based feature maps for decoding. To objectively validate the proposed DOLG-NeXt method, we perform extensive quantitative and qualitative analysis on four benchmark datasets from different biomedical image modalities: colonoscopy, electron microscopy, fluorescence, and retinal fundus imaging. DOLG-NeXt achieves a dice coefficient score of 95.10\% in CVC-ClinicDB, 95.80\% in ISBI 2012, 94.77\% in 2018 Data Science Bowl, and 84.88\% in the DRIVE dataset, respectively. The experimental analysis shows that DOLG-NeXt outperforms several state-of-the-art models for BMIS tasks.},
  archive      = {J_NEUCOM},
  author       = {Md. Rayhan Ahmed and Md. Asif Iqbal Fahim and A.K.M. Muzahidul Islam and Salekul Islam and Swakkhar Shatabda},
  doi          = {10.1016/j.neucom.2023.126362},
  journal      = {Neurocomputing},
  pages        = {126362},
  shortjournal = {Neurocomputing},
  title        = {DOLG-NeXt: Convolutional neural network with deep orthogonal fusion of local and global features for biomedical image segmentation},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial complementary and self-repair learning for occluded
person re-identification. <em>NEUCOM</em>, <em>546</em>, 126360. (<a
href="https://doi.org/10.1016/j.neucom.2023.126360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occluded person re-identification (ReID) is more challenging than holistic person ReID, as the appearance clues are insufficient and misaligned in cluttered scenarios. By digging pose/foreground priors, numerous previous methods focus on visible body regions to achieve alignment but they are complicated. To alleviate these issues, we present spatial complementary and self-repair learning (SCSRL), a simple yet effective approach that constructs holistic representations without extra priors. Specifically, SCSRL includes two learning branches, a spatial complementary learning (SCL) one and a self-repair learning (SRL) one. The SCL branch extracts aggregation features that reflect integral information of the human appearance. The SRL branch not only mines visible features for each input but also repairs missing/invisible appearance clues via a proposed repair loss. Moreover, we construct a large-scale occluded dataset namely Occluded-Market which contains more percentage of occlusion samples than existing datasets. The experiments show that our approach achieves state-of-the-art performance on Occluded-Market and other occluded datasets.},
  archive      = {J_NEUCOM},
  author       = {Shoudong Han and Donghaisheng Liu and Ziwen Zhang and Delie Ming},
  doi          = {10.1016/j.neucom.2023.126360},
  journal      = {Neurocomputing},
  pages        = {126360},
  shortjournal = {Neurocomputing},
  title        = {Spatial complementary and self-repair learning for occluded person re-identification},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive orthogonal gradient descent algorithm for fully
complex-valued neural networks. <em>NEUCOM</em>, <em>546</em>, 126358.
(<a href="https://doi.org/10.1016/j.neucom.2023.126358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For optimization algorithms of fully complex-valued neural networks , complex-valued stepsize is helpful to make the training escape from saddle points. In this paper, an adaptive orthogonal gradient descent algorithm with complex-valued stepsize is proposed for the efficient training of fully complex-valued neural networks . The basic idea is that, at each iteration, the search direction is constructed as a combination of two orthogonal gradient directions by using the algebraic representation of complex-valued stepsize. It is then shown that the determination of suitable complex-valued stepsize is facilitated by a decoupling method such that the computational complexity involved in the training process is greatly reduced. The experiments are finally conducted on pattern classification, nonlinear channel equalization and signal prediction to confirm the advantages of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Weijing Zhao and He Huang},
  doi          = {10.1016/j.neucom.2023.126358},
  journal      = {Neurocomputing},
  pages        = {126358},
  shortjournal = {Neurocomputing},
  title        = {Adaptive orthogonal gradient descent algorithm for fully complex-valued neural networks},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online video super-resolution using information replenishing
unidirectional recurrent model. <em>NEUCOM</em>, <em>546</em>, 126355.
(<a href="https://doi.org/10.1016/j.neucom.2023.126355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent Neural Networks (RNN) are widespread for Video Super-Resolution (VSR) because of their proven ability to learn spatiotemporal inter-dependencies across the temporal dimension. Despite RNN’s ability to propagate memory across longer sequences of frames, vanishing gradient and error accumulation remain major obstacles to unidirectional RNNs in VSR. Several bi-directional recurrent models are suggested in the literature to alleviate this issue; however, these models are only applicable to offline use cases due to heavy demands for computational resources and the number of frames required per input. This paper proposes a novel unidirectional recurrent model for VSR, namely “Replenished Recurrency with Dual-Duct” (R2D2), that can be used in an online application setting. R2D2 incorporates a recurrent architecture with a sliding-window-based local alignment resulting in a recurrent hybrid architecture . It also uses a dual-duct residual network for concurrent and mutual refinement of local features along with global memory for full utilisation of the information available at each timestamp. With novel modelling and sophisticated optimisation, R2D2 demonstrates competitive performance and efficiency despite the lack of information available at each time-stamp compared to its offline (bi-directional) counterparts. Ablation analysis confirms the additive benefits of the proposed sub-components of R2D2 over baseline RNN models.The PyTorch-based code for the R2D2 model will be released at R2D2 GitRepo .},
  archive      = {J_NEUCOM},
  author       = {Arbind Agrahari Baniya and Tsz-Kwan Lee and Peter W. Eklund and Sunil Aryal and Antonio Robles-Kelly},
  doi          = {10.1016/j.neucom.2023.126355},
  journal      = {Neurocomputing},
  pages        = {126355},
  shortjournal = {Neurocomputing},
  title        = {Online video super-resolution using information replenishing unidirectional recurrent model},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully aperiodic intermittent pinning control for exponential
bipartite synchronization of multilayer signed stochastic coupled neural
networks. <em>NEUCOM</em>, <em>546</em>, 126354. (<a
href="https://doi.org/10.1016/j.neucom.2023.126354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims to address the exponential bipartite synchronization (EBS) issue of multilayer signed stochastic coupled neural networks under the fully aperiodic intermittent pinning control (FAIPC) strategy. At first, a network model incorporating stochastic perturbations, multilayer signed graphs and multiple time-varying delays is built. Subsequently, instead of the maximum rest rate condition, by means of the average control rate of aperiodically intermittent control, an improved differential inequality is established to reduce the conservatism of existing results. Furthermore, by employing the presented differential inequality and stochastic analysis technique, some sufficient conditions for ensuring mean square EBS are obtained based on FAIPC with constant control gains and FAIPC with adaptive control gains, respectively. Finally, the availability of the theoretical results is verified by some numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Yue Ren and Haijun Jiang and Cheng Hu and Xinman Li and Xuejiao Qin},
  doi          = {10.1016/j.neucom.2023.126354},
  journal      = {Neurocomputing},
  pages        = {126354},
  shortjournal = {Neurocomputing},
  title        = {Fully aperiodic intermittent pinning control for exponential bipartite synchronization of multilayer signed stochastic coupled neural networks},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature aggregation with transformer for RGB-t salient
object detection. <em>NEUCOM</em>, <em>546</em>, 126329. (<a
href="https://doi.org/10.1016/j.neucom.2023.126329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main purpose of RGB-T salient object detection (SOD) is to fully integrate and exploit the information from the complementary fusion of modalities to address the underperformance of RGB SOD in some challenging scenes. In this paper, we propose a novel feature aggregation network that can fully mine multi-scale and multi-modal information for complete and accurate RGB-T SOD. Subsequently, a cross-attention fusion module is proposed to adaptively integrate high-level features by using the attention mechanism in the Transformer. Then we design a simple yet effective fast feature aggregation module to fuse low-level features. Through the combined work of the above modules, our network can perform well in some complex scenes by effectively fusing features from RGB and thermal modalities. Finally, several experiments on publicly available datasets such as VT821, VT1000, and VT5000 demonstrate that our method outperforms state-of-the-art methods. And our code has been released at: https://github.com/ELOESZHANG/FANet .},
  archive      = {J_NEUCOM},
  author       = {Ping Zhang and Mengnan Xu and Ziyan Zhang and Pan Gao and Jing Zhang},
  doi          = {10.1016/j.neucom.2023.126329},
  journal      = {Neurocomputing},
  pages        = {126329},
  shortjournal = {Neurocomputing},
  title        = {Feature aggregation with transformer for RGB-T salient object detection},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time series prediction with granular neural networks.
<em>NEUCOM</em>, <em>546</em>, 126328. (<a
href="https://doi.org/10.1016/j.neucom.2023.126328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional artificial neural networks are inherently equipped with an ambiguous (uncertain) structure which is hard to be quantified and explained. Time series forecasting using neural networks thus becomes a highly challenging task also due to the fact that time series data are always nonlinear and uncertain (because of some disturbances). Considering this, we propose a granular neural network-based time series prediction model connecting the uncertainty of models and data with the concept of information granularity . We aim to provide an explainable time series prediction model to resist the disturbance inner time series data and reduce the vagueness of the model. The functionalities of the granular neural network model are threefold: (1) It reveals the uncertainty of a time series data set through the level of granularity , coverage and specificity and possesses high prediction accuracy; (2) It provides an optimized interval output endowed with enough specificity and sufficient coverage and this interval is more robust than a single value; (3) It owns an interpretable and flexible structure that reflects the uncertainty of the initial numeric neural network and the generalization and robustness of connections while being faced with disturbances. The experimental studies elaborate on each function of our model in detail and show that the developed method performed better than the existing approaches present in the literature when experimenting on several time series data sets.},
  archive      = {J_NEUCOM},
  author       = {Mingli Song and Yan Li and Witold Pedrycz},
  doi          = {10.1016/j.neucom.2023.126328},
  journal      = {Neurocomputing},
  pages        = {126328},
  shortjournal = {Neurocomputing},
  title        = {Time series prediction with granular neural networks},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A residual convolution transfer framework based on slow
feature for cross-domain machinery fault diagnosis. <em>NEUCOM</em>,
<em>546</em>, 126322. (<a
href="https://doi.org/10.1016/j.neucom.2023.126322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis plays a vital role in ensuring the stable, reliable and safe operation of machinery equipment. However, data distribution doesn’t meet the assumption of the same distribution in the practical scene due to environmental changes. Traditional transfer learning methods can solve the situation of data distribution shift, but they encounter obstacles without adequately considering the possibility of introducing feature pre-extraction into deep learning and fusing pre-extracted low-dimensional feature with high-dimensional feature. In this study, a residual convolution transfer learning framework based on slow feature, which is an invariant or slowly varing signal learned from a vector signal, is presented to address this issue. Firstly, slow feature analysis is employed to implement preliminary feature extraction, which obtains latent variable that reflects the fundamental information of the equipment. Then, slow feature is sent to a residual convolution network for further abstraction and low-dimensional feature aggregates with high-dimensional feature by a bypass branch. Furthermore, maximum mean discrepancy is introduced to calculate the distance between two distributions in the Reproducing Kernel Hilbert Space (RKHS) and reduce the discrepancy of feature distribution. The proposed method is evaluated on Xi’an Jiao Tong University (XJTU) dataset and Case Western Reserve University (CWRU) dataset, and the average accuracy is higher than 99\%. Experimental results show that the proposed framework has superior transferability and robustness under different working conditions.},
  archive      = {J_NEUCOM},
  author       = {Shubin Chen and Weishi Zheng and Hua Xiao and Peng Han and Kaiqing Luo},
  doi          = {10.1016/j.neucom.2023.126322},
  journal      = {Neurocomputing},
  pages        = {126322},
  shortjournal = {Neurocomputing},
  title        = {A residual convolution transfer framework based on slow feature for cross-domain machinery fault diagnosis},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainability in image captioning based on the latent
space. <em>NEUCOM</em>, <em>546</em>, 126319. (<a
href="https://doi.org/10.1016/j.neucom.2023.126319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the representation/latent space in neural architectures to develop an end-to-end explanation approach for Image Captioning (IC) models. By injecting Gaussian perturbations into the latent space of each component of the architecture, we first analyze and identify the parts of the model likely to be the most decisive/influential in the caption generation. The results show that the visual part, mainly composed of visual encoding and attention mechanism , is more decisive than the language part, which could lead to more subtle explanations. We then follow this approach with an in-depth explanation protocol that also utilizes the latent space and focuses on the visual modality to design and compare two explanation methods with different scopes; (1) a surrogate-based method with Local Interpretable Model-Agnostic Explanations (LIME), with local scope. (2) a backpropagation-based method with Layer-wise Relevance Propagation (LRP) for global explanations. To assess the quality of the obtained explanations, we propose the new concept of Latent Ablation, which proves to be more consistent than classical Ablation, which usually leads to inconsistencies and truncated information. Extensive experiments show that both methods achieve comparable results and that their scope has no explicit impact on the quality of the explanations.},
  archive      = {J_NEUCOM},
  author       = {Sofiane Elguendouze and Adel Hafiane and Marcilio C.P. de Souto and Anaïs Halftermeyer},
  doi          = {10.1016/j.neucom.2023.126319},
  journal      = {Neurocomputing},
  pages        = {126319},
  shortjournal = {Neurocomputing},
  title        = {Explainability in image captioning based on the latent space},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Short-term solar irradiance forecasting in streaming with
deep learning. <em>NEUCOM</em>, <em>546</em>, 126312. (<a
href="https://doi.org/10.1016/j.neucom.2023.126312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar energy is one of the most common and promising sources of renewable energy. In photovoltaic (PV) systems, operators can benefit from future solar irradiance predictions for efficient load balancing and grid stability. Therefore, short-term solar irradiance forecasting plays a crucial role in the transition to renewable energy. Modern PV grids collect large volumes of data that provide valuable information for forecasting models. Although the nature of these data presents an ideal setting for online learning methodologies, research to date has mainly focused on offline approaches. Hence, this work proposes a novel data streaming method for real-time solar irradiance forecasting on days with variable weather conditions and cloud coverage. Our method operates under an asynchronous dual-pipeline framework using deep learning models. For the experimental study, two datasets from a Canadian PV solar plant have been simulated as streams at different data frequencies. The experiments involve an exhaustive parameter grid search to evaluate four state-of-the-art deep learning architectures: multilayer perceptron (MLP), long-short term memory network (LSTM), convolutional network (CNN), and Transformer network. The obtained results demonstrate the suitability of deep learning models for this problem. In particular, MLP and CNN achieved the best accuracy, with a high capacity to adapt to the evolving data stream.},
  archive      = {J_NEUCOM},
  author       = {Pedro Lara-Benítez and Manuel Carranza-García and José María Luna-Romera and José C. Riquelme},
  doi          = {10.1016/j.neucom.2023.126312},
  journal      = {Neurocomputing},
  pages        = {126312},
  shortjournal = {Neurocomputing},
  title        = {Short-term solar irradiance forecasting in streaming with deep learning},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft querying powered by user-defined functions in j-CO-QL+.
<em>NEUCOM</em>, <em>546</em>, 126311. (<a
href="https://doi.org/10.1016/j.neucom.2023.126311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft querying on databases (i.e., selecting data items that partially match selection conditions) was investigated on top of classical relational databases in past research works; however, constraints and limitations posed by relational DBMSs significantly limited the practical effects of this research. The advent of JSON as the format for representing and sharing data over the Internet, together with the birth of JSON document stores (a specific category of NoSQL databases), is now changing the panorama. In fact, the need to integrate and query large JSON data sets is now calling for novel and powerful tools for managing and integrating JSON data sets in a flexible way. At the University of Bergamo (Italy), we are devising the J-CO Framework, which is a platform-independent tool that relies on a high-level and general-purpose language named J-CO-QL + : among all its features, it provides capabilities towards “soft querying” of JSON documents. However, a general-purpose language, although extremely powerful, cannot provide support for domain-specific computations that often relies on procedural algorithms. In this paper, we show how supporting user-defined functions actually empowers J-CO-QL + users towards applying soft querying on JSON data sets. User-defined functions written both in JavaScript and in Java are accepted by the J-CO-QL + Engine : in this paper, we present how to define them and the different execution performance.},
  archive      = {J_NEUCOM},
  author       = {Paolo Fosci and Giuseppe Psaila},
  doi          = {10.1016/j.neucom.2023.126311},
  journal      = {Neurocomputing},
  pages        = {126311},
  shortjournal = {Neurocomputing},
  title        = {Soft querying powered by user-defined functions in J-CO-QL+},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network-based adaptive controller design for robotic
manipulator subject to varying loads and unknown dead-zone.
<em>NEUCOM</em>, <em>546</em>, 126293. (<a
href="https://doi.org/10.1016/j.neucom.2023.126293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, aiming at handling the trajectory tracking issue of industrial manipulator system (IMS) with modeling uncertainty, varying loads (VL) and unknown dead-zone characteristic, a compensation-based adaptive switching controller synthesis is proposed. In this scheme, the dynamic model of the IMS under VL is regarded as a switched system (SS) with a specified modal set. The nonlinear term related to plant model in each subsystem is approximated by radial basis function neural network (RBFNN) so as to avoid the reliance of the controller on the accurate model, and the unknown dead-zone is estimated and compensated by NN, from which the corresponding NN robust compensation term is developed to eliminate the potential perturbations and estimated errors. The designed controller with switching mechanism effectively solves the problem of degradation of the tracking accuracy caused by VL. Finally, the uniform ultimate boundedness of error signals is analyzed by the average dwell time (ADT) approach, multi-Lyapunov function method and the synthesized adaptive control law, and the effectiveness of the developed scheme is verified by simulation.},
  archive      = {J_NEUCOM},
  author       = {Xingqiang Zhao and Zhen Liu and Quanmin Zhu},
  doi          = {10.1016/j.neucom.2023.126293},
  journal      = {Neurocomputing},
  pages        = {126293},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based adaptive controller design for robotic manipulator subject to varying loads and unknown dead-zone},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved max-value entropy search for multi-objective
bayesian optimization with constraints. <em>NEUCOM</em>, <em>546</em>,
126290. (<a href="https://doi.org/10.1016/j.neucom.2023.126290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present MESMOC+, an improved version of Max-value Entropy search for Multi-Objective Bayesian optimization with Constraints (MESMOC). MESMOC+ can be used to solve constrained multi-objective problems when the objectives and the constraints are expensive to evaluate. It is based on minimizing the entropy of the solution of the optimization problem in function space (i.e., the Pareto front) to guide the search for the optimum. The cost of MESMOC+ is linear in the number of objectives and constraints. Furthermore, it is often significantly smaller than the cost of alternative methods based on minimizing the entropy of the Pareto set. The reason for this is that it is easier to approximate the required computations in MESMOC+. Moreover, MESMOC+’s acquisition function is expressed as the sum of one acquisition per each black-box (objective or constraint). Therefore, it can be used in a decoupled evaluation setting in which it is chosen not only the next input location to evaluate, but also which black-box to evaluate there. We compare MESMOC+ with related methods in synthetic, benchmark and real optimization problems. These experiments show that MESMOC+ has similar performance to that of state-of-the-art acquisitions based on entropy search, but it is faster to execute and simpler to implement. Moreover, our experiments also show that MESMOC+ is more robust with respect to the number of samples of the Pareto front.},
  archive      = {J_NEUCOM},
  author       = {Daniel Fernández-Sánchez and Eduardo C. Garrido-Merchán and Daniel Hernández-Lobato},
  doi          = {10.1016/j.neucom.2023.126290},
  journal      = {Neurocomputing},
  pages        = {126290},
  shortjournal = {Neurocomputing},
  title        = {Improved max-value entropy search for multi-objective bayesian optimization with constraints},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep image captioning: A review of methods, trends and
future challenges. <em>NEUCOM</em>, <em>546</em>, 126287. (<a
href="https://doi.org/10.1016/j.neucom.2023.126287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning, also called report generation in medical field, aims to describe visual content of images in human language, which requires to model semantic relationship between visual and textual elements and generate corresponding descriptions that conform to human language cognition. Image captioning is significant for promoting human–computer interaction in all fields and particularly, for computer-aided diagnosis in medical field. Currently, with the rapid development of deep learning technologies, image caption has attracted increasing attention of many researchers in artificial intelligence-related fields. To this end, this study attempts to provide readers with systematic and comprehensive research about different deep image captioning methods in natural and medical fields. We first introduce workflow of image captioning from perspective of simulating human process of describing images, including seeing, focusing and telling, which is respectively behavioralized into feature representation, visual encoding and language generation. Within it, we present common-used feature representation, visual encoding and language generation models. Then, we review datasets, evaluations and basic losses used in image captioning, and summarize typical caption methods which are generally divided into that with or without using reinforcement learning . Besides, we describe advantages and disadvantages of existing methods, and conclusion and challenges are finally presented.},
  archive      = {J_NEUCOM},
  author       = {Liming Xu and Quan Tang and Jiancheng Lv and Bochuan Zheng and Xianhua Zeng and Weisheng Li},
  doi          = {10.1016/j.neucom.2023.126287},
  journal      = {Neurocomputing},
  pages        = {126287},
  shortjournal = {Neurocomputing},
  title        = {Deep image captioning: A review of methods, trends and future challenges},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedMed-GAN: Federated domain translation on unsupervised
cross-modality brain image synthesis. <em>NEUCOM</em>, <em>546</em>,
126282. (<a href="https://doi.org/10.1016/j.neucom.2023.126282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilizing multi-modal neuroimaging data is proven to be effective in investigating human cognitive activities and certain pathologies. However, it is not practical to obtain the full set of paired neuroimaging data centrally since the collection faces several constraints, e.g. , high examination cost, long acquisition time, and image corruption. In addition, these data are dispersed into different medical institutions and thus cannot be aggregated for centralized training considering the privacy issues. There is a clear need to launch federated learning and facilitate the integration of dispersed data from different institutions. In this paper, we propose a new benchmark for federated domain translation on unsupervised brain image synthesis (FedMed-GAN) to bridge the gap between federated learning and medical GAN . FedMed-GAN mitigates the mode collapse without sacrificing the performance of generators, and is widely applied to different proportions of unpaired and paired data with variation adaptation properties. We treat the gradient penalties using the federated averaging algorithm and then leverage the differential privacy gradient descent to regularize the training dynamics. A comprehensive evaluation is provided for comparing FedMed-GAN and other centralized methods, demonstrating that the proposed algorithm outperforms the state-of-the-art. Our code is available at: https://github.com/M-3LAB/FedMed-GAN.},
  archive      = {J_NEUCOM},
  author       = {Jinbao Wang and Guoyang Xie and Yawen Huang and Jiayi Lyu and Feng Zheng and Yefeng Zheng and Yaochu Jin},
  doi          = {10.1016/j.neucom.2023.126282},
  journal      = {Neurocomputing},
  pages        = {126282},
  shortjournal = {Neurocomputing},
  title        = {FedMed-GAN: Federated domain translation on unsupervised cross-modality brain image synthesis},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain-invariant information aggregation for domain
generalization semantic segmentation. <em>NEUCOM</em>, <em>546</em>,
126273. (<a href="https://doi.org/10.1016/j.neucom.2023.126273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization semantic segmentation methods aim to generalize well on out-of-distribution scenes, which is crucial for real-world applications. Recent works focus on learning domain-invariant content information by using normalization, whitening, and domain randomization to remove style information. Although these methods improve the performance on out-of-distribution scenes to some extent, they ignore the learning of edge and semantic layout information. The edge information describes the shape and boundary of an object and the semantic layout information contains the common sense priors (e.g., the spatial position of objects). For one thing, we observe that the shape of the same object with different styles is domain-invariant in the edge map. For another, we observe that the common sense priors in the semantic layout information of different scenes are domain-invariant. Motivated by these observations, a novel approach is proposed for domain generalization semantic segmentation by using the edge and semantic layout information. Specifically, the proposed approach contains the edge reconstruction module (ERM), the semantic layout reconstruction module (SLRM), and the triple information aggregation module (TIAM). The ERM and SLRM aim to explicitly learn the edge and semantic layout information. The TIAM aggregates the edge and semantic layout information to refine the content information. Extensive experiments demonstrate that our approach achieves superior performance over current approaches on domain generalization segmentation tasks . The source code will be released at https://github.com/seabearlmx/DIIA.},
  archive      = {J_NEUCOM},
  author       = {Muxin Liao and Shishun Tian and Yuhang Zhang and Guoguang Hua and Wenbin Zou and Xia Li},
  doi          = {10.1016/j.neucom.2023.126273},
  journal      = {Neurocomputing},
  pages        = {126273},
  shortjournal = {Neurocomputing},
  title        = {Domain-invariant information aggregation for domain generalization semantic segmentation},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble strategy learning for imperfect information games.
<em>NEUCOM</em>, <em>546</em>, 126241. (<a
href="https://doi.org/10.1016/j.neucom.2023.126241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithms with several paradigms (such as rule-based methods, game theory and reinforcement learning) have achieved great success in solving imperfect information games (IIGs). However, agents based on a single paradigm tend to be brittle in certain aspects due to the paradigm’s weaknesses. In this paper, we first present three base-solvers with diversified paradigms for IIGs, and then combine them to design three ensemble-solvers (including an attention ensemble-solver, a gradient ensemble-solver and an evolution ensemble-solver) to learn ensemble strategies given base-solvers’ strengths. We evaluate our methods on Leduc poker with nonstationary opponents and limited games. The results show that our ensemble strategy learning method can effectively integrate the advantages of various advanced individual algorithms and significantly outperform them.},
  archive      = {J_NEUCOM},
  author       = {Weilin Yuan and Shaofei Chen and Peng Li and Jing Chen},
  doi          = {10.1016/j.neucom.2023.126241},
  journal      = {Neurocomputing},
  pages        = {126241},
  shortjournal = {Neurocomputing},
  title        = {Ensemble strategy learning for imperfect information games},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of hate speech automatic detection using
natural language processing. <em>NEUCOM</em>, <em>546</em>, 126232. (<a
href="https://doi.org/10.1016/j.neucom.2023.126232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the multiplication of social media platforms , which offer anonymity, easy access and online community formation and online debate, the issue of hate speech detection and tracking becomes a growing challenge to society, individual, policy-makers and researchers. Despite efforts for leveraging automatic techniques for automatic detection and monitoring, their performances are still far from satisfactory, which constantly calls for future research on the issue. This paper provides a systematic review of literature in this field, with a focus on natural language processing and deep learning technologies, highlighting the terminology, processing pipeline, core methods employed, with a focal point on deep learning architecture. From a methodological perspective, we adopt PRISMA guideline of systematic review of the last 10 years literature from ACM Digital Library and Google Scholar. In the sequel, existing surveys, limitations, and future research directions are extensively discussed.},
  archive      = {J_NEUCOM},
  author       = {Md Saroar Jahan and Mourad Oussalah},
  doi          = {10.1016/j.neucom.2023.126232},
  journal      = {Neurocomputing},
  pages        = {126232},
  shortjournal = {Neurocomputing},
  title        = {A systematic review of hate speech automatic detection using natural language processing},
  volume       = {546},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural networks in the cloud: Review, applications,
challenges and research directions. <em>NEUCOM</em>, <em>545</em>,
126327. (<a href="https://doi.org/10.1016/j.neucom.2023.126327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are currently being deployed as machine learning technology in a wide range of important real-world applications. DNNs consist of a huge number of parameters that require millions of floating-point operations (FLOPs) to be executed both in learning and prediction modes. A more effective method is to implement DNNs in a cloud computing system equipped with centralized servers and data storage sub-systems with high-speed and high-performance computing capabilities. This paper presents an up-to-date survey on current state-of-the-art deployed DNNs for cloud computing . Various DNN complexities associated with different architectures are presented and discussed alongside the necessities of using cloud computing. We also present an extensive overview of different cloud computing platforms for the deployment of DNNs and discuss them in detail. Moreover, DNN applications already deployed in cloud computing systems are reviewed to demonstrate the advantages of using cloud computing for DNNs. The paper emphasizes the challenges of deploying DNNs in cloud computing systems and provides guidance on enhancing current and new deployments.},
  archive      = {J_NEUCOM},
  author       = {Kit Yan Chan and Bilal Abu-Salih and Raneem Qaddoura and Ala’ M. Al-Zoubi and Vasile Palade and Duc-Son Pham and Javier Del Ser and Khan Muhammad},
  doi          = {10.1016/j.neucom.2023.126327},
  journal      = {Neurocomputing},
  pages        = {126327},
  shortjournal = {Neurocomputing},
  title        = {Deep neural networks in the cloud: Review, applications, challenges and research directions},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised object discovery with pseudo label generated
using k-means and self-supervised transformer. <em>NEUCOM</em>,
<em>545</em>, 126326. (<a
href="https://doi.org/10.1016/j.neucom.2023.126326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation is a fundamental task in the field of computer vision. It aims to assign every pixel to an appropriate class and localize objects within bounding boxes. However, expensive pixel-level segmentation labels are essential for training current state-of-the-art instance segmentation models. In this paper, we propose IMST, a simple method for generating instance-level pseudo-object mask labels without any form of human annotation. IMST leverages the fact that self-supervised transformers embed background and foreground into distinct cluster spaces. This characteristic allows us to discover class-agnostic object masks from unlabeled image datasets using cosine distance K-means clustering. We also present an object mask refinement method that employs ensemble results of K-means in a single image. Despite its simplicity, IMST achieves state-of-the-art performance in the unsupervised object mask discovery task. In unsupervised class-agnostic instance segmentation, IMST outperforms concurrent works by margins of 5.3 AP and 4.0 AP, respectively, on COCO20k and COCO val2017 . Our proposed method can be extended to object box discovery tasks, such as unsupervised class-agnostic object detection and unsupervised single object discovery, surpassing previous works.},
  archive      = {J_NEUCOM},
  author       = {Lim SeongTaek and Park JaeEon and Lee MinYoung and Lee HongChul},
  doi          = {10.1016/j.neucom.2023.126326},
  journal      = {Neurocomputing},
  pages        = {126326},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised object discovery with pseudo label generated using K-means and self-supervised transformer},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multikernel correntropy based robust least squares one-class
support vector machine. <em>NEUCOM</em>, <em>545</em>, 126324. (<a
href="https://doi.org/10.1016/j.neucom.2023.126324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Least-squares one-class support vector machine (LS-OCSVM) is one of the most popular methods to perform one-class classification tasks , in which only the data of a specific class are available to train the classification model . However, the learning performance of LS-OCSVM heavily relies on the effectiveness of a squared loss function, which is sensitive to outliers, resulting in the poor robustness of LS-OCSVM to deal with contaminated data. In this paper, the original optimization problem of LS-OCSVM is therefore reformulated with a recently proposed robust similarity measure, called multikernel correntropy, generating a multikernel correntropy based LS-OCSVM (MKCLS-OCSVM). To find the solution to the new optimization problem effectively, a dynamic optimization algorithm developed with the popular half-quadratic optimization technique is adopted to perform the optimization process. Meanwhile, the convergence and computational complexity of the developed optimization algorithm are analyzed from theoretical perspectives. To further facilitate the implementation of MKCLS-OCSVM, an operationally simple search strategy, inspired by the hunting behavior of humpback whales, is designed for parameters selection. Experimental results on various one-class classification tasks are reported to demonstrate the performance superiority of the proposed MKCLS-OCSVM in comparison with LS-OCSVM and other robust LS-OCSVM variants.},
  archive      = {J_NEUCOM},
  author       = {Yunfei Zheng and Shiyuan Wang and Badong Chen},
  doi          = {10.1016/j.neucom.2023.126324},
  journal      = {Neurocomputing},
  pages        = {126324},
  shortjournal = {Neurocomputing},
  title        = {Multikernel correntropy based robust least squares one-class support vector machine},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Event-triggered consensus control based on maximum
correntropy criterion for discrete-time multi-agent systems.
<em>NEUCOM</em>, <em>545</em>, 126323. (<a
href="https://doi.org/10.1016/j.neucom.2023.126323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An event-triggered consensus problem of discrete-time multi-agent systems with impulsive noise under directed switching topology is investigated in this paper, where the control input of each agent is determined by its own state information and the state information of its neighbors that may be corrupted by impulsive noise. Firstly, to reduce the adverse effect of impulsive noise on consensus performance of the discrete-time multi-agent systems, maximum correntropy criterion (MCC) derived from information theoretic learning is introduced to calculate the communication weights among the agents, and an event-triggered strategy is adopted to drive the state variables of each agent to eventually converge to a same value. Secondly, the condition to guarantee consensus of the discrete-time multi-agent systems is derived by graph theory and Lyapunov stability theorem. Finally, the effectiveness of the theory is verified by several numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Jun Liu and Guobin Yang and Nan Zhou and Kaiyu Qin and Badong Chen and Yonghong Wu and Kup-Sze Choi},
  doi          = {10.1016/j.neucom.2023.126323},
  journal      = {Neurocomputing},
  pages        = {126323},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered consensus control based on maximum correntropy criterion for discrete-time multi-agent systems},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TIVE: A toolbox for identifying video instance segmentation
errors. <em>NEUCOM</em>, <em>545</em>, 126321. (<a
href="https://doi.org/10.1016/j.neucom.2023.126321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce TIVE, a T oolbox for I dentifying V ideo instance segmentation E rrors. By directly operating output prediction files, TIVE defines isolated error types and weights each type’s damage to mAP, for the purpose of distinguishing model characters. By decomposing localization quality in spatial–temporal dimensions, model’s potential drawbacks on spatial segmentation and temporal association can be revealed. TIVE can also report mAP over instance temporal length for real applications. We conduct extensive experiments by the toolbox to further illustrate how spatial segmentation and temporal association affect each other. We expect the analysis of TIVE can give the researchers more insights, guiding the community to promote more meaningful explorations for video instance segmentation. The proposed toolbox is available at https://github.com/wenhe-jia/TIVE .},
  archive      = {J_NEUCOM},
  author       = {Wenhe Jia and Lu Yang and Zilong Jia and Wenyi Zhao and Yilin Zhou and Qing Song},
  doi          = {10.1016/j.neucom.2023.126321},
  journal      = {Neurocomputing},
  pages        = {126321},
  shortjournal = {Neurocomputing},
  title        = {TIVE: A toolbox for identifying video instance segmentation errors},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Echo state networks: Novel reservoir selection and
hyperparameter optimization model for time series forecasting.
<em>NEUCOM</em>, <em>545</em>, 126317. (<a
href="https://doi.org/10.1016/j.neucom.2023.126317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of computational intelligence models for multi-step time series forecasting tasks has presented satisfactory results in such a way that they are considered models with an excellent future for this type of problem. From the point of view of computational cost, the current alternatives combined with classical models are generating hybrid models that present even better results. Within the AutoML category, the optimization of hyperparameters and the selection of network topologies has become a challenge. Reservoir Computing , which is within the area of ​​Recurrent Neural Networks (RNN), proposes a particular model called Echo State Networks . which has been tested in different applications with excellent results; however, the difficulty in specifying the hyperparameters has been the subject of continuous study given the random nature of the set of neurons called Reservoir. Based on the Separation Ratio Graph (SRG) model for performance analysis, this paper proposes a new model, called Echo State Network - Genetic Algorithm - Separation Ratio Graph (ESN-GA-SRG), which optimizes network hyperparameters and at the same time selects the best topology for the Reservoir using the SRG coefficient, to find the reservoir that offers the most suitable dynamic behavior . The performance of this new model is evaluated on forecasting two sets of time series benchmarks with different characteristics of sampling periodicity, skewness, and stationarity. The results obtained show that the ESN-GA-SRG model was superior in predicting these time series in most cases, with statistical significance, when compared to other models that have been presented for this type of problem in the literature.},
  archive      = {J_NEUCOM},
  author       = {Cesar H. Valencia and Marley M.B.R. Vellasco and Karla Figueiredo},
  doi          = {10.1016/j.neucom.2023.126317},
  journal      = {Neurocomputing},
  pages        = {126317},
  shortjournal = {Neurocomputing},
  title        = {Echo state networks: Novel reservoir selection and hyperparameter optimization model for time series forecasting},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resilient distributed hypothesis testing under time-varying
multi-agent networks with multiple types of adversarial agents.
<em>NEUCOM</em>, <em>545</em>, 126315. (<a
href="https://doi.org/10.1016/j.neucom.2023.126315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the resilient distributed hypothesis testing problem under multi-agent networks is studied, where the normal agents that are not attacked aim to cooperatively learn a true state from a set of hypotheses. Different from the existing works, the considered network is heterogeneous and time-varying, and it is allowed that multiple types of agents can be attacked. Within this framework, by designing a novel filtering mechanism, an effective resilient distributed algorithm is developed to solve the considered hypothesis testing problem. In the convergence analysis of the algorithm, a key definition about the robustness of heterogeneous time-varying networks is firstly introduced, then by combining the designed filtering mechanism with a delay-based analysis approach, it is proven that the beliefs of the true state held by all normal agents converge to 1 under the proposed algorithm, which means that the normal agents successfully learn the true state. Finally, the theoretical findings are verified through simulations, and a comparison is provided to show that the proposed algorithm by utilizing the network heterogeneity may tolerate more adversarial agents than the algorithm designed in homogeneous networks.},
  archive      = {J_NEUCOM},
  author       = {Chong-Xiao Shi and Guang-Hong Yang},
  doi          = {10.1016/j.neucom.2023.126315},
  journal      = {Neurocomputing},
  pages        = {126315},
  shortjournal = {Neurocomputing},
  title        = {Resilient distributed hypothesis testing under time-varying multi-agent networks with multiple types of adversarial agents},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sea surface height data reconstruction via inter and intra
layer features based on dual attention. <em>NEUCOM</em>, <em>545</em>,
126313. (<a href="https://doi.org/10.1016/j.neucom.2023.126313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding of geoscience relies on spatio-temporal continuous fields, such as Sea Surface Height (SSH). Data reconstruction for restoring spatio-temporal continuous and gridded maps from incomplete observations and inaccuracy interpolation products has long been a crucial challenge in the marine geoscience. Despite remarkable progress, most existing learning-based reconstruction methods neglect to fully and discriminatively utilize the inter-layer and intra-layer features. The inter-layer semantics are complementary, and the significance of intra-layer components varies with frequency. To address these issues, we propose a multi-layer Feature Combination Network based on Attention mechanism (FCANet) for SSH data reconstruction. Specifically, a novel trainable Multi-layer Feature Combination Block (MFCB) is developed to enrich the features through inter-layer dependencies. Dual attention mechanism is introduced into the MFCB to enhance saliency of intra-layer features by adaptively rescaling the spatial-wise and channel-wise features. Furthermore, experimental results on SSH variable demonstrate the superiority of our FCANet over state-of-the-art reconstruction methods in the metrics of RMSE and SSIM.},
  archive      = {J_NEUCOM},
  author       = {Ke Zhang and Lei Huang and Zhiqiang Wei and Chen An and Xianqing Lv},
  doi          = {10.1016/j.neucom.2023.126313},
  journal      = {Neurocomputing},
  pages        = {126313},
  shortjournal = {Neurocomputing},
  title        = {Sea surface height data reconstruction via inter and intra layer features based on dual attention},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous transfer of neural network representational
similarity for incremental learning. <em>NEUCOM</em>, <em>545</em>,
126300. (<a href="https://doi.org/10.1016/j.neucom.2023.126300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incremental learning paradigm in machine learning has consistently been a focus of academic research. It is similar to the way in which biological systems learn, and reduces energy consumption by avoiding excessive retraining. Existing studies utilize the powerful feature extraction capabilities of pre-trained models to address incremental learning, but there remains a problem of insufficient utilization of neural network feature knowledge. To address this issue, this paper proposes a novel method called Pre-trained Model Knowledge Distillation (PMKD) which combines knowledge distillation of neural network representations and replay. This paper designs a loss function based on centered kernel alignment to transfer neural network representations knowledge from the pre-trained model to the incremental model layer-by-layer. Additionally, the use of memory buffer for Dark Experience Replay helps the model retain past knowledge better. Experiments show that PMKD achieved superior performance on various datasets and different buffer sizes. Compared to other methods, our class incremental learning accuracy reached the best performance. The open-source code is published at https://github.com/TianSongS/PMKD-IL .},
  archive      = {J_NEUCOM},
  author       = {Songsong Tian and Weijun Li and Xin Ning and Hang Ran and Hong Qin and Prayag Tiwari},
  doi          = {10.1016/j.neucom.2023.126300},
  journal      = {Neurocomputing},
  pages        = {126300},
  shortjournal = {Neurocomputing},
  title        = {Continuous transfer of neural network representational similarity for incremental learning},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of deep learning segmentation methods for carotid
artery ultrasound images. <em>NEUCOM</em>, <em>545</em>, 126298. (<a
href="https://doi.org/10.1016/j.neucom.2023.126298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The carotid artery is a critical blood vessel that supplies blood to the brain, and its health and function are essential for preventing cardiovascular diseases such as stroke. Ultrasound imaging is commonly used to diagnose the carotid artery and monitor its health, but traditional methods have limitations in terms of accuracy and efficiency. In recent years, deep learning segmentation methods have been developed to improve the diagnosis of the carotid artery, which have shown great potential for improving the accuracy and efficiency of cardiovascular diagnosis. In this paper, we aim to review and summarize the recent research on deep learning segmentation methods for the carotid artery ultrasound images . Specifically, we focus on techniques for the segmentation of the intima-media, plaque, and lumen sites, which are important for clinical diagnosis. Through our analysis of the literature, we seek to identify the key trends and challenges in this field, and to provide insights into the opportunities and challenges for future research and development in this area.},
  archive      = {J_NEUCOM},
  author       = {Qinghua Huang and Haozhe Tian and Lizhi Jia and Ziming Li and Zishu Zhou},
  doi          = {10.1016/j.neucom.2023.126298},
  journal      = {Neurocomputing},
  pages        = {126298},
  shortjournal = {Neurocomputing},
  title        = {A review of deep learning segmentation methods for carotid artery ultrasound images},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient spatiotemporal context modeling for action
recognition. <em>NEUCOM</em>, <em>545</em>, 126289. (<a
href="https://doi.org/10.1016/j.neucom.2023.126289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contextual information is essential in action recognition. However, local operations have difficulty in modeling two distant elements, and directly computing the dense relations between any two points brings huge computation and memory burden. Inspired by the recurrent 2D criss-cross attention (RCCA-2D) in image segmentation, we propose a recurrent 3D criss-cross attention (RCCA-3D) that factorizes the global relation map into sparse relation maps to model long-range spatiotemporal context with minor costs for video-based action recognition. Specifically, we first propose a 3D criss-cross attention (CCA-3D) module. Compared with the CCA-2D which only works in space, it can capture the spatiotemporal relationship between the points in the same line along the direction of width, height and time. However, only replacing the two CCA-2Ds in the RCCA-2D with our CCA-3Ds cannot model the spatiotemporal context in videos. Therefore, we further duplicate the CCA-3D with a recurrent mechanism to transmit the relation between the points in a line to a plane and finally to the whole spatiotemporal space. To make the RCCA-3D adaptive for action recognition, we propose a novel recurrent structure rather than directly extending the original 2D structure to 3D. In the experiments, we make a thorough analysis of different structures of RCCA-3D, verifying the proposed structure is more suitable for action recognition. We also compare our RCCA-3D with the non-local attention, showing that the RCCA-3D requires 25\% fewer parameters and 30\% fewer FLOPs with even higher accuracy. Finally, equipped with our RCCA-3D, 3 networks achieve better and leading performance on 5 RGB-based and skeleton-based datasets.},
  archive      = {J_NEUCOM},
  author       = {Congqi Cao and Yue Lu and Yifan Zhang and Dongmei Jiang and Yanning Zhang},
  doi          = {10.1016/j.neucom.2023.126289},
  journal      = {Neurocomputing},
  pages        = {126289},
  shortjournal = {Neurocomputing},
  title        = {Efficient spatiotemporal context modeling for action recognition},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite-time group-bipartite consensus tracking for
second-order nonlinear multi-agent systems. <em>NEUCOM</em>,
<em>545</em>, 126283. (<a
href="https://doi.org/10.1016/j.neucom.2023.126283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the finite-time group-bipartite consensus problem for nonlinear second-order multi-agent systems (MASs) is studied. By designing the control protocol, based on the proof of the system reaching asymptotically group-bipartite consensus, the homogeneous dilation method is used to obtain sufficient conditions for all agents to reach the finite-time group-bipartite consensus. Moreover, nonlinear functions are constrained by the Lipschitz condition . In addition, two examples demonstrate the operability of the control protocol.},
  archive      = {J_NEUCOM},
  author       = {Rongxiang Lu and Jie Wu and Xisheng Zhan and Huaicheng Yan and Senior Member, IEEE},
  doi          = {10.1016/j.neucom.2023.126283},
  journal      = {Neurocomputing},
  pages        = {126283},
  shortjournal = {Neurocomputing},
  title        = {Finite-time group-bipartite consensus tracking for second-order nonlinear multi-agent systems},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Whose emotion matters? Speaking activity localisation
without prior knowledge. <em>NEUCOM</em>, <em>545</em>, 126271. (<a
href="https://doi.org/10.1016/j.neucom.2023.126271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of emotion recognition in conversations (ERC) benefits from the availability of multiple modalities, as provided, for example, in the video-based M ultimodal E motion L ines D ataset (MELD). However, only a few research approaches use both acoustic and visual information from the MELD videos. There are two reasons for this: First, label-to-video alignments in MELD are noisy, making those videos an unreliable source of emotional speech data. Second, conversations can involve several people in the same scene, which requires the localisation of the utterance source. In this paper, we introduce MELD with F ixed A udiovisual I nformation via R ealignment (MELD-FAIR) by using recent active speaker detection and automatic speech recognition models, we are able to realign the videos of MELD and capture the facial expressions from speakers in 96.92\% of the utterances provided in MELD. Experiments with a self-supervised voice recognition model indicate that the realigned MELD-FAIR videos more closely match the transcribed utterances given in the MELD dataset. Finally, we devise a model for emotion recognition in conversations trained on the realigned MELD-FAIR videos, which outperforms state-of-the-art models for ERC based on vision alone. This indicates that localising the source of speaking activities is indeed effective for extracting facial expressions from the uttering speakers and that faces provide more informative visual cues than the visual features state-of-the-art models have been using so far. The MELD-FAIR realignment data, and the code of the realignment procedure and of the emotional recognition, are available at https://github.com/knowledgetechnologyuhh/MELD-FAIR .},
  archive      = {J_NEUCOM},
  author       = {Hugo Carneiro and Cornelius Weber and Stefan Wermter},
  doi          = {10.1016/j.neucom.2023.126271},
  journal      = {Neurocomputing},
  pages        = {126271},
  shortjournal = {Neurocomputing},
  title        = {Whose emotion matters? speaking activity localisation without prior knowledge},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretability for reliable, efficient, and self-cognitive
DNNs: From theories to applications. <em>NEUCOM</em>, <em>545</em>,
126267. (<a href="https://doi.org/10.1016/j.neucom.2023.126267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, remarkable achievements have been made in artificial intelligence tasks and applications based on deep neural networks (DNNs), especially in the fields of vision, speech, text, and multimodal analysis. The learning of DNNs is not only the process of abstracting essential laws from data but also the result of nonlinear fitting from massive high-dimensional data. However, the architecture, operation mode, and learning ability of DNNs are still far from those of human brain neurons, and the calculation and reasoning are extremely complex, making the model’s analysis and interpretation crucial. To free DNNs from their dependence on complex structures and massive data, a lot of related works toward the interpretability of DNNs have been proposed. In this review, we elaborate on the definition of model interpretability from the three perspectives of model reliability, feature efficiency, and self-cognition. The interpretability theory of DNNs is summarized from four aspects: model adversarial attack and defense, feature representations, information and geometry, and causal counterfactual. In addition, we categorize the interpretable methods involved according to typical application scenarios. Finally, we discuss the research goals that have not yet been achieved. We sincerely hope that our work will benefit the field and attract more researchers to devote their energy to the interpretability of DNNs, thereby pushing forward the long-term development of artificial neural networks and artificial intelligence .},
  archive      = {J_NEUCOM},
  author       = {Xu Kang and Jie Guo and Bin Song and Binghuang Cai and Hongyu Sun and Zhebin Zhang},
  doi          = {10.1016/j.neucom.2023.126267},
  journal      = {Neurocomputing},
  pages        = {126267},
  shortjournal = {Neurocomputing},
  title        = {Interpretability for reliable, efficient, and self-cognitive DNNs: From theories to applications},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A confidence-aware and path-enhanced convolutional neural
network embedding framework on noisy knowledge graph. <em>NEUCOM</em>,
<em>545</em>, 126261. (<a
href="https://doi.org/10.1016/j.neucom.2023.126261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Knowledge Graphs (KGs) have been widely used in applications such as search engines and Q&amp;A systems. During construction, errors were inevitably introduced and KGs may contain many incorrect facts. However, most KG representation learning methods assume that all triple facts are correct, making KG noise detection a challenge. Although some knowledge representation methods are based on a confidence-aware framework, they are usually limited by the translation assumption in TransE and confidence calculation methods. To address the above problems, we propose a more accurate and effective confidence-aware and path-enhanced convolutional neural network knowledge embedding framework (CPConvKE). It makes use of structural, entity type, and rule information for knowledge graph noise detection and knowledge representation learning simultaneously. Specifically, for representation learning, we introduce a gating-based path embedding method to filter out noise while learning entity and relation embeddings. For the confidence evaluation, we propose a triple confidence estimator that uses entity type and rule information as prior probability and defines posterior probability based on the embedding. We evaluate the effectiveness of our model on the knowledge graph noise detection, completion, and triple classification tasks . The experimental results show that our confidence-aware model achieves significant and consistent improvements on all tasks, which confirms the ability of CPConvKE to detect noise and learn clean embeddings in a noisy knowledge graph.},
  archive      = {J_NEUCOM},
  author       = {Xiaohan Yang and Ning Wang},
  doi          = {10.1016/j.neucom.2023.126261},
  journal      = {Neurocomputing},
  pages        = {126261},
  shortjournal = {Neurocomputing},
  title        = {A confidence-aware and path-enhanced convolutional neural network embedding framework on noisy knowledge graph},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross task neural architecture search for EEG signal
recognition. <em>NEUCOM</em>, <em>545</em>, 126260. (<a
href="https://doi.org/10.1016/j.neucom.2023.126260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalograms (EEGs) are brain dynamics measured outside of the brain, which have been widely utilized in non-invasive brain-computer interface applications. Recently, various neural network approaches have been proposed to improve the accuracy of EEG signal recognition. However, these approaches severely rely on manually designed network structures for different tasks which normally are not sharing the same empirical design cross-task-wise. In this paper, we propose a cross-task neural architecture search (CTNAS-EEG) framework for EEG signal recognition, which can automatically design the network structure across tasks and improve the recognition accuracy of EEG signals. Specifically, a compatible search space for cross-task searching and an efficient constrained searching method is proposed to overcome challenges brought by EEG signals. By unifying structure search on different EEG tasks, this work is the first to explore and analyze the searched structure difference in cross-task-wise. Moreover, by introducing architecture search, this work is the first to analyze model performance by customizing model structure for each human subject. Detailed experimental results suggest that the proposed CTNAS-EEG could reach state-of-the-art performance on different EEG tasks, such as Motor Imagery (MI) and Emotion recognition. Extensive experiments and detailed analysis are provided as a good reference for follow-up researchers.},
  archive      = {J_NEUCOM},
  author       = {Yiqun Duan and Zhen Wang and Yi Li and Jianhang Tang and Yu-Kai Wang and Chin-Teng Lin},
  doi          = {10.1016/j.neucom.2023.126260},
  journal      = {Neurocomputing},
  pages        = {126260},
  shortjournal = {Neurocomputing},
  title        = {Cross task neural architecture search for EEG signal recognition},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disease-grading networks with ordinal regularization for
medical imaging. <em>NEUCOM</em>, <em>545</em>, 126245. (<a
href="https://doi.org/10.1016/j.neucom.2023.126245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The severity of diseases develops gradually, and early screening is critical to apply timely medical interventions. Previous deep learning classification methods for disease grading have ignored the ordinal relationships among stages of disease severity, but this study shows they can be used to boost disease-grading performance. In this paper, we design an ordinal regularized module to represent the orderliness in disease severity, which can be flexibly embedded into general classification networks to grade diseases more accurately. In addition, this ordinal regularized module also predicts the progress of disease development. The proposed method is evaluated on three public benchmark datasets: the IDRiD challenge dataset, LUng Nodule Analysis 2016 (LUNA16) dataset, and Messidor dataset. Experiments show that the proposed method is not only superior to the baselines from common classification models but also outperforms deep learning approaches, especially on the IDRiD challenge dataset, where our method has a joint accuracy of 68.0\%. Furthermore, the proposed method achieves excellent performance in both single-disease and joint-disease grading tasks on the aforementioned datasets, and it can be applied to other disease-grading tasks. Our code is publicly available at https://github.com/ahtwq/ORNet .},
  archive      = {J_NEUCOM},
  author       = {Wenqiang Tang and Zhouwang Yang and Yanzhi Song},
  doi          = {10.1016/j.neucom.2023.126245},
  journal      = {Neurocomputing},
  pages        = {126245},
  shortjournal = {Neurocomputing},
  title        = {Disease-grading networks with ordinal regularization for medical imaging},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kernel-based learning of orthogonal functions.
<em>NEUCOM</em>, <em>545</em>, 126237. (<a
href="https://doi.org/10.1016/j.neucom.2023.126237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating a set of orthogonal functions from a finite set of noisy data plays a crucial role in several areas such as imaging, dictionary learning and compressed sensing . The problem turns out especially hard due to its intrinsic non-convexity. In this paper, we solve it by recasting it in the framework of multi-task learning in Hilbert spaces , where orthogonality plays a role as inductive bias. Two perspectives are analyzed. The first one is mainly theoretic. It considers a formulation of the problem where non-orthogonal function estimates are seen as noisy data belonging to an infinite-dimensional space from which orthogonal functions have to be reconstructed. We then provide results concerning the existence and the convergence of the optimizers. The second one is more oriented towards applications. It consists in a learning scheme where orthogonal functions are directly inferred from a finite amount of noisy data. It relies on regularization in reproducing kernel Hilbert spaces and on the introduction of special penalty terms promoting orthogonality among tasks. The problem is then cast in a Bayesian framework , overcoming non-convexity through an efficient Markov chain Monte Carlo scheme. If orthogonality is not certain, our scheme can also understand from data if such form of task interaction really holds.},
  archive      = {J_NEUCOM},
  author       = {Anna Scampicchio and Mauro Bisiacco and Gianluigi Pillonetto},
  doi          = {10.1016/j.neucom.2023.126237},
  journal      = {Neurocomputing},
  pages        = {126237},
  shortjournal = {Neurocomputing},
  title        = {Kernel-based learning of orthogonal functions},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accurate polyp segmentation through enhancing feature fusion
and boosting boundary performance. <em>NEUCOM</em>, <em>545</em>,
126233. (<a href="https://doi.org/10.1016/j.neucom.2023.126233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal polyps are known to be potential precursors to colorectal cancer. Effective polyp segmentation during colonoscopy examinations can help the clinicians accurately locate potential polyp areas, and reduce misdiagnosis and missed diagnosis. Although existing approaches have achieved significant breakthroughs in medical image segmentation , polyp segmentation is still far from being solved. This is mainly due to the following reasons: (1) most of them tend to ignore the feature misalignment issues during the feature aggregation process; and (2) few algorithms explicitly consider the impact of boundary information on the performance of polyp segmentation. To solve the above issues, we formulate a novel neural network for polyp segmentation in endoscopy images. Different from existing approaches, we explore a new paradigm to enhance multi-level feature fusion by introducing the Feature Fusion Module, which leverages the semantic offset field learned to align the multi-level feature maps for resolving the feature misalignment issue. In addition, we design an auxiliary boundary branch to focus on boundary-aware information, and thus boost the performance of boundary prediction. Specifically, the reference boundary map learned through end-to-end optimization can be considered as a complementary feature of the high-level semantics representation , and then integrated into the main branch via the Boundary Embedding Module, which in turn promotes further refinement of the prediction, especially the boundary. Extensive experiments demonstrate that our approach achieves state-of-the-art performance in polyp segmentation.},
  archive      = {J_NEUCOM},
  author       = {Yanzhou Su and Jian Cheng and Chuqiao Zhong and Chengzhi Jiang and Jin Ye and Junjun He},
  doi          = {10.1016/j.neucom.2023.126233},
  journal      = {Neurocomputing},
  pages        = {126233},
  shortjournal = {Neurocomputing},
  title        = {Accurate polyp segmentation through enhancing feature fusion and boosting boundary performance},
  volume       = {545},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConvPose: A modern pure ConvNet for human pose estimation.
<em>NEUCOM</em>, <em>544</em>, 126301. (<a
href="https://doi.org/10.1016/j.neucom.2023.126301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based networks almost thoroughly outperformed those based on convolutional neural network (ConvNet) and predominate in the field of pose estimation. To get off the hook and resuscitate ConvNets, we propose ConvPose, which is a pure ConvNet that does not utilize conventional improvement strategies like attention mechanisms and lightweight approaches, but instead pioneeringly modernizes network structures. The modernization process includes: deepening the stem cell and transition layers, using a separate pointwise convolution layer, adopting a batch normalization (BN) layer after resizing the feature maps, employing large-kernel depthwise separable convolutions and designing re-parameterized-style structures, constructing two consecutive modules that contain a mixer and an inverted bottleneck, etc. All of these designs are similar to the corresponding Transformer architectures, which means translating Transformer-specific components into convolutional variations and incorporating them into a ConvNet. A modern ConvNet not only maintains the simplicity of convolutional, but also takes advantage of Transformers. The experiments show that ConvPose-BL achieves a 76.0 Average Precision (AP) score on the COCO val2017 dataset. ConvPose performs on par or better than the existing representative networks those based on Transformer and ConvNet, and represents slight superiority in terms of speed.},
  archive      = {J_NEUCOM},
  author       = {Yue Niu and Annan Wang and Xuewu Wang and Shengxi Wu},
  doi          = {10.1016/j.neucom.2023.126301},
  journal      = {Neurocomputing},
  pages        = {126301},
  shortjournal = {Neurocomputing},
  title        = {ConvPose: A modern pure ConvNet for human pose estimation},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preciser comparison: Augmented multi-layer dynamic
contrastive strategy for text2text question classification.
<em>NEUCOM</em>, <em>544</em>, 126299. (<a
href="https://doi.org/10.1016/j.neucom.2023.126299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text2text question classification (TQC), as a particular application case of question classification (QC), is of great practical value. Traditional QC methods usually label categories of questions using one or multiple keywords provided by users. In contrast, in TQC, each question in natural language is automatically categorized into pre-designed standard question classes, which are coded in the form of short text. Because of this unique characteristic, TQC relies on a specifically designed framework and should be trained and validated based on customized experimental datasets. Previous TQC-related work mainly utilized textual similarity-matching methods. However, no effective pairwise learning paradigm has been proposed in TQC to model correlations between input text and classes; and the influence of distance metrics and loss function in TQC has not been investigated. In this work, we propose a novel and comprehensive strategy, A ugmented D ynamic M ulti-layer C ontrastive (ADMC), to resolve the challenge of TQC. Our framework consists of (1) an optional data augmentation module, (2) one stage for dynamic negative sampling, and (3) one stage for precise matching. The comprehensive TQC framework with ADMC strategy in this work resolves data imbalance and explores distance metrics learning via multiple augmentation options and dynamic negative sampling based on multi-layer contrastive learning . To compensate for the shortage of public datasets for this task, we collected two real-world datasets and adaptively expanded three existing public datasets, which will be available after data masking. The results show that our ADMC outperformed other baseline methods investigated in this paper. The codes are available at https://github.com/WJULYW/ADMC .},
  archive      = {J_NEUCOM},
  author       = {Jiyao Wang and Zijie Chen and Yijia Zhang and Dengbo He and Fangzhen Lin},
  doi          = {10.1016/j.neucom.2023.126299},
  journal      = {Neurocomputing},
  pages        = {126299},
  shortjournal = {Neurocomputing},
  title        = {Preciser comparison: Augmented multi-layer dynamic contrastive strategy for text2text question classification},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Filter pruning by quantifying feature similarity and entropy
of feature maps. <em>NEUCOM</em>, <em>544</em>, 126297. (<a
href="https://doi.org/10.1016/j.neucom.2023.126297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning can effectively reduce the time cost and computing resources of convolutional neural networks (CNNs), and is well applied to lightweight edge devices. However, most of the current pruning methods focus on the inherent properties of the filters themselves to prune the network, and pay less attention to the connection between the filters and the feature maps. Feature similarity (FSIM) utilizes the fact that the human visual system is more sensitive to the underlying features of the images to more accurately assess image quality. We discover that FSIM is also suitable for evaluating feature maps of CNNs. In addition, the information richness in the feature maps reflects the degree of importance of the filters. Based on the above research, we propose to quantify the importance of feature maps with FSIM and two-dimensional entropy (2D Entropy) indicator to further guide filter pruning (FSIM-E). The FSIM-E is executed on CIFAR-10 and ILSVRC-2012 to demonstrate that FSIM-E can effectively compress and accelerate the network model. For example, for ResNet-110 on CIFAR-10, FSIM-E prunes 71.1\% of the FLOPs and 66.5\% of the parameters, while improving the accuracy by 0.1\%. With ResNet-50, FSIM-E can achieve 57.2\% pruning rate of FLOPs and 53.1\% pruning rate of parameters on ILSVRC-2012 with loss of only 0.42\% of Top-5 accuracy.},
  archive      = {J_NEUCOM},
  author       = {Yajun Liu and Kefeng Fan and Dakui Wu and Wenju Zhou},
  doi          = {10.1016/j.neucom.2023.126297},
  journal      = {Neurocomputing},
  pages        = {126297},
  shortjournal = {Neurocomputing},
  title        = {Filter pruning by quantifying feature similarity and entropy of feature maps},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSCDP: Multi-step crowd density predictor in indoor
environment. <em>NEUCOM</em>, <em>544</em>, 126296. (<a
href="https://doi.org/10.1016/j.neucom.2023.126296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring and predicting crowd movements in indoor environments are of great importance in crowd management to prevent crushing and trampling. Existing works mostly focused on individual trajectory forecasting in a less crowded scene, or crowd counting and density estimation. Only a very few works predict the crowd density distribution. However, this study is failing to realize multi-step prediction or exploits only density heatmaps modality and ignores the information complementation with corresponding video frames. Therefore, we are motivated to predict crowd density distribution in multiple time steps to facilitate long-term prediction. In this paper, a Multi-Step Crowd Density Predictor (MSCDP) to fuse video frame sequences and corresponding density heatmaps, is proposed to accurately forecast future crowd density heatmaps. To capture long-term periodic movement features, the long-term optical flow context memory (LOFCM) module is designed to store learnable patterns. We conducted extensive experiments on two real-world datasets. Evaluation results show that our MSCDP outperforms the state-of-the-art baseline techniques and MSCDP variants in terms of various prediction errors, demonstrating the effectiveness of MSCDP and each of its key components in multi-step crowd density prediction.},
  archive      = {J_NEUCOM},
  author       = {Shuyu Wang and Yan Lyu and Yuhang Xu and Weiwei Wu},
  doi          = {10.1016/j.neucom.2023.126296},
  journal      = {Neurocomputing},
  pages        = {126296},
  shortjournal = {Neurocomputing},
  title        = {MSCDP: Multi-step crowd density predictor in indoor environment},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TISS-net: Brain tumor image synthesis and segmentation using
cascaded dual-task networks and error-prediction consistency.
<em>NEUCOM</em>, <em>544</em>, 126295. (<a
href="https://doi.org/10.1016/j.neucom.2023.126295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of brain tumors from medical images is important for diagnosis and treatment planning, and it often requires multi-modal or contrast-enhanced images. However, in practice some modalities of a patient may be absent. Synthesizing the missing modality has a potential for filling this gap and achieving high segmentation performance. Existing methods often treat the synthesis and segmentation tasks separately or consider them jointly but without effective regularization of the complex joint model, leading to limited performance. We propose a novel brain Tumor Image Synthesis and Segmentation network (TISS-Net) that obtains the synthesized target modality and segmentation of brain tumors end-to-end with high performance. First, we propose a dual-task-regularized generator that simultaneously obtains a synthesized target modality and a coarse segmentation, which leverages a tumor-aware synthesis loss with perceptibility regularization to minimize the high-level semantic domain gap between synthesized and real target modalities. Based on the synthesized image and the coarse segmentation, we further propose a dual-task segmentor that predicts a refined segmentation and error in the coarse segmentation simultaneously, where a consistency between these two predictions is introduced for regularization. Our TISS-Net was validated with two applications: synthesizing FLAIR images for whole glioma segmentation, and synthesizing contrast-enhanced T1 images for Vestibular Schwannoma segmentation. Experimental results showed that our TISS-Net largely improved the segmentation accuracy compared with direct segmentation from the available modalities, and it outperformed state-of-the-art image synthesis-based segmentation methods.},
  archive      = {J_NEUCOM},
  author       = {Jianghao Wu and Dong Guo and Lu Wang and Shuojue Yang and Yuanjie Zheng and Jonathan Shapey and Tom Vercauteren and Sotirios Bisdas and Robert Bradford and Shakeel Saeed and Neil Kitchen and Sebastien Ourselin and Shaoting Zhang and Guotai Wang},
  doi          = {10.1016/j.neucom.2023.126295},
  journal      = {Neurocomputing},
  pages        = {126295},
  shortjournal = {Neurocomputing},
  title        = {TISS-net: Brain tumor image synthesis and segmentation using cascaded dual-task networks and error-prediction consistency},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spiking neural predictive coding for continually learning
from data streams. <em>NEUCOM</em>, <em>544</em>, 126292. (<a
href="https://doi.org/10.1016/j.neucom.2023.126292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For energy-efficient computation in specialized neuromorphic hardware, we present spiking neural coding , an instantiation of a family of artificial neural models grounded in the theory of predictive coding . This model, the first of its kind, works by operating in a never-ending process of “guess-and-check”, where neurons predict the activity values of one another and then adjust their own activities to make better future predictions. The interactive, iterative nature of our system fits well into the continuous time formulation of sensory stream prediction and, as we show, the model’s structure yields a local synaptic update rule, which can be used to complement or as an alternative to online spike-timing dependent plasticity. In this article, we experiment with an instantiation of our model consisting of leaky integrate-and-fire units. However, the framework within which our system is situated can naturally incorporate more complex neurons such as the Hodgkin-Huxley model. Our experimental results in pattern recognition demonstrate the potential of the model when binary spike trains are the primary paradigm for inter-neuron communication. Notably, spiking neural coding is competitive in terms of classification performance and experiences less forgetting when learning from a task sequence, offering a more computationally economical, biologically-motivated alternative to popular artificial neural networks .},
  archive      = {J_NEUCOM},
  author       = {Alexander Ororbia},
  doi          = {10.1016/j.neucom.2023.126292},
  journal      = {Neurocomputing},
  pages        = {126292},
  shortjournal = {Neurocomputing},
  title        = {Spiking neural predictive coding for continually learning from data streams},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online reinforcement learning control of nonlinear dynamic
systems: A state-action value function based solution. <em>NEUCOM</em>,
<em>544</em>, 126291. (<a
href="https://doi.org/10.1016/j.neucom.2023.126291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an online reinforcement learning-based solution to the optimal control problem of continuous-time nonlinear input-affine systems. The proposed approach contains a concurrent identifier that estimates time derivatives of states of the system in some arbitrary points. The identifier is utilized to simulate a so-called Bellman error in some unvisited points. The simulated errors together with errors obtained along the trajectory of the system are used to estimate the state-action value function, which is then employed to derive the estimated optimal controller. The designed approach does not explicitly require the input dynamics, which is hard to segregate it from the drift dynamics in optimal regulation problems. In addition, the simulated Bellman errors relax the confining persistence of excitation condition, which is needed for convergence in deterministic systems. A Lyapunov-based analysis was conducted to derive convergence conditions. Simulation studies demonstrated the effectiveness of the developed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Hamed Jabbari Asl and Eiji Uchibe},
  doi          = {10.1016/j.neucom.2023.126291},
  journal      = {Neurocomputing},
  pages        = {126291},
  shortjournal = {Neurocomputing},
  title        = {Online reinforcement learning control of nonlinear dynamic systems: A state-action value function based solution},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A convolutional autoencoder and a neural gas model based on
bregman divergences for hierarchical color quantization.
<em>NEUCOM</em>, <em>544</em>, 126288. (<a
href="https://doi.org/10.1016/j.neucom.2023.126288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color quantization (CQ) is one of the most common and important procedures to be performed on digital images. In this paper, a new approach to hierarchical color quantization is described, presenting a novel neural network architecture integrated by a convolutional autoencoder and a Growing Hierarchical Bregman Neural Gas (GHBNG). GHBNG is a CQ algorithm that allows the compression of an image by choosing a reduced set of the most representative colors to generate a high-quality reproduction of the original image. In the technique proposed here, an autoencoder is used to translate the image into a latent representation with higher per-pixel dimensionality but reduced resolution, and GHBNG is then used to quantize it. Experimental results confirm the performance of this technique and its suitability for tasks related to color quantization.},
  archive      = {J_NEUCOM},
  author       = {José David Fernández-Rodríguez and Esteban J. Palomo and Jesús Benito-Picazo and Enrique Domínguez and Ezequiel López-Rubio and Francisco Ortega-Zamorano},
  doi          = {10.1016/j.neucom.2023.126288},
  journal      = {Neurocomputing},
  pages        = {126288},
  shortjournal = {Neurocomputing},
  title        = {A convolutional autoencoder and a neural gas model based on bregman divergences for hierarchical color quantization},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AID-RL: Active information-directed reinforcement learning
for autonomous source seeking and estimation. <em>NEUCOM</em>,
<em>544</em>, 126281. (<a
href="https://doi.org/10.1016/j.neucom.2023.126281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an active information-directed reinforcement learning (AID-RL) framework for autonomous source seeking and estimation problem. Source seeking requires the search agent to move towards the true source, and source estimation demands the agent to maintain and update its knowledge regarding the source properties such as release rate and source position. These two objectives give rise to the newly developed framework, namely, dual control for exploration and exploitation. In this paper, the greedy RL forms an exploitation search strategy that navigates the agent to the source position, while the information-directed search commands the agent to explore most informative positions to reduce belief uncertainty. Extensive results are presented using a high-fidelity dataset for autonomous search, which validates the effectiveness of the proposed AID-RL and highlights the importance of active exploration in improving sampling efficiency and search performance.},
  archive      = {J_NEUCOM},
  author       = {Zhongguo Li and Wen-Hua Chen and Jun Yang and Yunda Yan},
  doi          = {10.1016/j.neucom.2023.126281},
  journal      = {Neurocomputing},
  pages        = {126281},
  shortjournal = {Neurocomputing},
  title        = {AID-RL: Active information-directed reinforcement learning for autonomous source seeking and estimation},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A spatial correlation prediction model of urban PM2.5
concentration based on deconvolution and LSTM. <em>NEUCOM</em>,
<em>544</em>, 126280. (<a
href="https://doi.org/10.1016/j.neucom.2023.126280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise prediction of air pollutants can effectively reducre the occurrence of heavy pollution incidents. With the current surge of massive data, deep learning appears to be a promising technique to achieve dynamic prediction of air pollutant concentration from both the spatial and temporal dimensions. This paper presents Dev-LSTM, a prediction model building on deconvolution and LSTM . The novelty of Dev-LSTM lies in its capability to fully extract the spatial feature correlation of air pollutant concentration data, preventing the excessive loss of information caused by traditional convolution. At the same time, the feature associations in the time dimension are mined to produce accurate prediction results. Experimental results show that Dev-LSTM outperforms traditional prediction models on a variety of indicators.},
  archive      = {J_NEUCOM},
  author       = {Bo Zhang and Yuan Liu and RuiHan Yong and Guojian Zou and Ru Yang and Jianguo Pan and Maozhen Li},
  doi          = {10.1016/j.neucom.2023.126280},
  journal      = {Neurocomputing},
  pages        = {126280},
  shortjournal = {Neurocomputing},
  title        = {A spatial correlation prediction model of urban PM2.5 concentration based on deconvolution and LSTM},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Progressive graph convolution network for EEG emotion
recognition. <em>NEUCOM</em>, <em>544</em>, 126262. (<a
href="https://doi.org/10.1016/j.neucom.2023.126262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies in the area of neuroscience have revealed the relationship between emotional patterns and brain functional regions, demonstrating that the dynamic relationship between different brain regions is an essential factor affecting emotion recognition determined through electroencephalography (EEG). Moreover, in EEG emotion recognition, we can observe that clearer boundaries exist between coarse-grained emotions than those between fine-grained emotions, based on the same EEG data; this indicates the concurrence of large coarse- and small fine-grained emotion variations. The progressive classification process from coarse- to fine-grained categories may be helpful for EEG emotion recognition. Consequently, in this study, we proposed a progressive graph convolution network (PGCN) for capturing this inherent characteristic in EEG emotional signals and progressively learning the discriminative EEG features. To fit different EEG patterns, we constructed a dual-graph module to characterize the intrinsic relationship between different EEG channels, containing the dynamic functional connections and static spatial proximity information of brain regions from neuroscience research. Moreover, motivated by the observation of the relationship between coarse- and fine-grained emotions, we adopted a dual-head module that enabled the PGCN to progressively learn more discriminative EEG features, from coarse-grained (easy) to fine-grained categories (difficult), referring to the hierarchical characteristics of emotion. To verify the performance of our model, extensive experiments are conducted on three public datasets: SEED-IV, SEED-V, and MPED. The experiment results show that the PGCN achieves a state-of-the-art performance. Furthermore, we explored the effect of different frequency bands based on our model and visualized the activated brain regions. The experiment results reveal the relationship between human emotion and high-frequency EEG signals, as well as the importance of the frontal and temporal lobes for emotion expression.},
  archive      = {J_NEUCOM},
  author       = {Yijin Zhou and Fu Li and Yang Li and Youshuo Ji and Guangming Shi and Wenming Zheng and Lijian Zhang and Yuanfang Chen and Rui Cheng},
  doi          = {10.1016/j.neucom.2023.126262},
  journal      = {Neurocomputing},
  pages        = {126262},
  shortjournal = {Neurocomputing},
  title        = {Progressive graph convolution network for EEG emotion recognition},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural adaptive optimal control for nonlinear multiagent
systems with full-state constraints and immeasurable states.
<em>NEUCOM</em>, <em>544</em>, 126259. (<a
href="https://doi.org/10.1016/j.neucom.2023.126259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a neural adaptive optimal control strategy is proposed for strict-feedback nonlinear multiagent systems (MASs) with full-state constraints and immeasurable states. In order to solve the Hamilton–Jacobi-Bellman (HJB) equation, the reinforcement learning (RL) is employed with the actor-critic architecture. Different from the existing results for the optimized backstepping technique, by introducing the command filter technique into the value function, the condition that the derivative of the virtual controller is bounded by a constant can be released. Moreover, in the case of considering full-state constraints and immeasurable states, the tracking control problem of MASs can be solved without violating constraints, and the resource consumption can be reduced. We estimate and limit the states of MASs by employing the state observer and the novel mapping function, respectively. By using the Lyapunov stability theorem, it verifies that all signals in the closed-loop system are uniformly ultimately bounded (UUB) and the tracking error converges to a small neighborhood of the origin. Finally, a simulation example is given to illustrate the validity of the proposed control strategy.},
  archive      = {J_NEUCOM},
  author       = {Bingjie Ding and Yingnan Pan and Qing Lu},
  doi          = {10.1016/j.neucom.2023.126259},
  journal      = {Neurocomputing},
  pages        = {126259},
  shortjournal = {Neurocomputing},
  title        = {Neural adaptive optimal control for nonlinear multiagent systems with full-state constraints and immeasurable states},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep adversarial reinforcement learning based incentive
mechanism for content delivery in D2D-enabled mobile networks.
<em>NEUCOM</em>, <em>544</em>, 126258. (<a
href="https://doi.org/10.1016/j.neucom.2023.126258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of mobile devices at the edge of mobile networks, the amount of content that needs to be transmitted is exploded. As it takes resources (cache, bandwidth, and power) for the edge server and nearby devices to deliver content, the incentive mechanism with the optimal pricing and content delivery strategy needs to be studied without relying on the knowledge of network parameters in a competitive environment. In this paper, built on the framework of content delivery with the Stackelberg game , we have proposed a robust deep reinforcement learning method based on adversarial training to learn price strategy for lack of knowledge of private information. Specifically, the Stackelberg game is constructed to describe the interaction between different service providers and service demanders, and a deep adversarial reinforcement learning method is proposed to approximate the opponent’s decision in the worst case, where the price strategy can be trained end-to-end in the competitive environment. The simulation results show that the proposed algorithm can form an effective price strategy and improve the utility of service providers.},
  archive      = {J_NEUCOM},
  author       = {Jing Zhang and Jian Wang},
  doi          = {10.1016/j.neucom.2023.126258},
  journal      = {Neurocomputing},
  pages        = {126258},
  shortjournal = {Neurocomputing},
  title        = {Deep adversarial reinforcement learning based incentive mechanism for content delivery in D2D-enabled mobile networks},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bandit interpretability of deep models via confidence
selection. <em>NEUCOM</em>, <em>544</em>, 126250. (<a
href="https://doi.org/10.1016/j.neucom.2023.126250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability of black-box deep models is yet challenging because existing model-agnostic methods mainly locally explain the behavior of the classifier by learning a linear proxy around the instance being predicted. The explanation can be faithful locally, but may not be accurate globally. In this paper, we for the first time formulate the interpretation of classifiers as a bandit problem and introduce a Bandit Interpretation method via Confidence Selection (BICS). We statistically impose disturbances on different arms (image regions) and examine non-linear changes of the model’s output to fairly select important regions via Upper Confidence Bounds (UCB). Unlike previous model-agnostic methods that directly occlude super-pixels, our method softly applies perturbations at a pixel level and thus can fully explore more regions with multiple granularities, leading to a more precise and robust interpretation. Quantitative and qualitative experimental results demonstrate that our approach provides reasonable and precise explanations for various image recognition tasks on different models.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyue Duan and Hong Li and Panpan Wang and Tiancheng Wang and Boyu Liu and Baochang Zhang},
  doi          = {10.1016/j.neucom.2023.126250},
  journal      = {Neurocomputing},
  pages        = {126250},
  shortjournal = {Neurocomputing},
  title        = {Bandit interpretability of deep models via confidence selection},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Infrared and visible image fusion based on a two-stage class
conditioned auto-encoder network. <em>NEUCOM</em>, <em>544</em>, 126248.
(<a href="https://doi.org/10.1016/j.neucom.2023.126248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing auto-encoder based infrared and visible image fusion methods typically utilize a shared encoder to extract features from different modalities and adopt a handcrafted fusion strategy to fuse the extracted features into intermediate representation before the decoder part. In this paper, we present a novel two-stage class conditioned auto-encoder framework for high-quality multispectral fusion tasks. In the first training stage, we introduce a class embedding sub-branch to the encoder network for modeling the characteristics of different modalities and adaptively scaling the intermediate features based on the input modality. Moreover, we design a cross-transfer residual block to promote the content and texture information flow in the encoder for generating more representative features. In the second training stage, we insert a learnable fusion module between the pre-trained class conditioned encoder and decoder parts to replace the handcrafted fusion strategy. Specific intensity and gradient loss functions are utilized to tune the model for the fusion of distinctive deep features in a data-driven manner. With the important designs including the class conditioned auto-encoder and the two-stage training strategy, our proposed TS-ClassFuse can better preserve distinctive information/features from the source images and decrease the training difficulty for simultaneously extracting informative features and determining the optimal fusion scheme. Experimental results verify the effectiveness of our method in terms of both qualitative and quantitative evaluations .},
  archive      = {J_NEUCOM},
  author       = {Yanpeng Cao and Xing Luo and Xi Tong and Jiangxin Yang and Yanlong Cao},
  doi          = {10.1016/j.neucom.2023.126248},
  journal      = {Neurocomputing},
  pages        = {126248},
  shortjournal = {Neurocomputing},
  title        = {Infrared and visible image fusion based on a two-stage class conditioned auto-encoder network},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic threshold integrate and fire neuron model for low
latency spiking neural networks. <em>NEUCOM</em>, <em>544</em>, 126247.
(<a href="https://doi.org/10.1016/j.neucom.2023.126247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) operate with asynchronous discrete events which enable lower power and greater computational efficiency on event-driven hardware than Artificial Neural Networks (ANNs). Conventional ANN-to-SNN conversion methods usually employ Integrate and Fire (IF) neuron model with a fixed threshold to act as Rectified Linear Unit (ReLU). However, there is a large demand for the input spikes to reach the fixed threshold and fire, which leads to high inference latency. In this work, we propose a Dynamic Threshold Integrate and Fire (DTIF) neuron model by exploiting the biological neuron threshold variability, where the threshold is inversely related to the neuron input. The spike activity is increased by dynamically adjusting the threshold at each simulation time-step to reduce the latency. Compared to the state-of-the-art conversion methods, the ANN-to-SNN conversion using DTIF model has lower latency with competitive accuracy, which has been verified by deep architecture on image classification tasks including MNIST, CAIFAR-10, and CIFAR-100 datasets. Moreover, it achieves 7.14 × faster inference under 0.44 × energy consumption than the typical method of maximum normalization.},
  archive      = {J_NEUCOM},
  author       = {Xiyan Wu and Yufei Zhao and Yong Song and Yurong Jiang and Yashuo Bai and Xinyi Li and Ya Zhou and Xin Yang and Qun Hao},
  doi          = {10.1016/j.neucom.2023.126247},
  journal      = {Neurocomputing},
  pages        = {126247},
  shortjournal = {Neurocomputing},
  title        = {Dynamic threshold integrate and fire neuron model for low latency spiking neural networks},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Electrical activity and synchronization of memristor
synapse-coupled HR network based on energy method. <em>NEUCOM</em>,
<em>544</em>, 126246. (<a
href="https://doi.org/10.1016/j.neucom.2023.126246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrical synapses and external stimuli can affect the exchange and propagation of field energy between neurons, and thus induce a variety of dynamics and electricity activities of the nervous system . This paper introduces a memristor synapse-coupled bi-HR neural network and investigates its discharge oscillation and phase synchronization based on energy method. It finds that the bi-HR network presents strong nonlinear phenomena such as anti-monotonicity and transient dynamics. And the bi-HR network shows complex electricity activities such as mixed-mode discharge and bursting discharge, which are demonstrated by the time evolution of membrane potential and Hamilton energy spectrum. Moreover, phase synchronization of the coupled neurons is studied and the synchronization characteristic relying on memristive synapse, magnetic field and external stimulus is explored by calculating Hamilton energy error, which coincides with phase difference and synchronization factor. Therefore, Hamiltonian energy is effective for investigating the firing pattern of neural system and the synchronization behavior of electrically coupled neurons.},
  archive      = {J_NEUCOM},
  author       = {Yingchun Lu and Hongmin Li and Chunlai Li},
  doi          = {10.1016/j.neucom.2023.126246},
  journal      = {Neurocomputing},
  pages        = {126246},
  shortjournal = {Neurocomputing},
  title        = {Electrical activity and synchronization of memristor synapse-coupled HR network based on energy method},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DADRnet: Cross-domain image dehazing via domain adaptation
and disentangled representation. <em>NEUCOM</em>, <em>544</em>, 126242.
(<a href="https://doi.org/10.1016/j.neucom.2023.126242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed remarkable progress of learning-based methods in single image dehazing. Among them, dehazing methods trained on the synthetic images cannot adapt to real hazy ones due to the domain gap, and domain adaptation methods only concentrate on creating a mapping or extracting shared features regardless of representations of deep features. In this paper, we propose an innovative cross-domain dehazing architecture that integrates domain adaptation and disentangled representation. Specifically, we first construct a shared encoder to map synthetic and real hazy images to a latent space and narrow their domain gap at the feature level. Then we utilize a separator to separate the hazy image features into haze-free representations and haze ones. We introduce feature consistency loss and orthogonal loss to further guide the disentanglement process. And then, we utilize a decoder to produce clean images from haze-free features and introduce both supervised and unsupervised losses to guide the training process. Moreover, we also propose to reconstruct the images from both domains by recombining the separated features, which guarantees information completeness. Experiments demonstrate that our method is on par with state-of-the-art methods. Codes are available at https://github.com/lixiaopeng123456/DADRnet.},
  archive      = {J_NEUCOM},
  author       = {Xiaopeng Li and Hu Yu and Chen Zhao and Cien Fan and Lian Zou},
  doi          = {10.1016/j.neucom.2023.126242},
  journal      = {Neurocomputing},
  pages        = {126242},
  shortjournal = {Neurocomputing},
  title        = {DADRnet: Cross-domain image dehazing via domain adaptation and disentangled representation},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian network parameter learning using fuzzy constraints.
<em>NEUCOM</em>, <em>544</em>, 126239. (<a
href="https://doi.org/10.1016/j.neucom.2023.126239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior knowledge effectively mitigates low modeling accuracy when insufficient data exist. This idea has been confirmed in many fields, especially the transformation of prior knowledge into constraints, widely employed in Bayesian network (BN) parameter learning. The role of constraints in parameter learning is the focus of this study. If parameter learning results are blindly biased toward constraints, underfitting occurs, whereas the effectiveness of the constraint intervention is weak and can not mitigate overfitting by insufficient data. Therefore, fuzzy theory is introduced in parameter learning. The fuzzy membership function is applied to measure the interference effects of constraints and improve the interpretability and accuracy of the constraint usage. For the maximum a posteriori method, hyperparameters are utilized as virtual samples to realize the intervention of parameter learning. This study proposes a fuzzy maximum a posteriori (FMAP) method, in which the hyperparameter is adjusted to a suitable value using a fuzzy membership function . For the data extension method, a proper extension function is critical to the quality of the extended data. Therefore, this paper proposes a fuzzy bootstrap (FB) method that uses a fuzzy membership function to determine the distribution of the expansion parameters. The two algorithms presented in this paper are verified on 12 standard networks. The experimental results show that the proposed methods effectively improve the accuracy of parameter learning.},
  archive      = {J_NEUCOM},
  author       = {Xinxin Ru and Xiaoguang Gao and Zidong Wang and Yangyang Wang and Xiaohan Liu},
  doi          = {10.1016/j.neucom.2023.126239},
  journal      = {Neurocomputing},
  pages        = {126239},
  shortjournal = {Neurocomputing},
  title        = {Bayesian network parameter learning using fuzzy constraints},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ToFFi – toolbox for frequency-based fingerprinting of brain
signals. <em>NEUCOM</em>, <em>544</em>, 126236. (<a
href="https://doi.org/10.1016/j.neucom.2023.126236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral fingerprints (SFs) are unique power spectra signatures of human brain regions of interest (ROIs, Keitel &amp; Gross, 2016). SFs allow for accurate ROI identification and can serve as biomarkers of differences exhibited by non-neurotypical groups. At present, there are no open-source, versatile tools to calculate spectral fingerprints. We have filled this gap by creating a modular, highly-configurable MATLAB Toolbox for Frequency-based Fingerprinting (ToFFi). It can transform magnetoencephalographic and electroencephalographic signals into unique spectral representations using ROIs provided by anatomical (AAL, Desikan-Killiany), functional (Schaefer), or other custom volumetric brain parcellations. Toolbox design supports reproducibility and parallel computations.},
  archive      = {J_NEUCOM},
  author       = {Michał K. Komorowski and Krzysztof Rykaczewski and Tomasz Piotrowski and Katarzyna Jurewicz and Jakub Wojciechowski and Anne Keitel and Joanna Dreszer and Włodzisław Duch},
  doi          = {10.1016/j.neucom.2023.126236},
  journal      = {Neurocomputing},
  pages        = {126236},
  shortjournal = {Neurocomputing},
  title        = {ToFFi – toolbox for frequency-based fingerprinting of brain signals},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Batch normalization-free weight-binarized SNN based on
hardware-saving IF neuron. <em>NEUCOM</em>, <em>544</em>, 126234. (<a
href="https://doi.org/10.1016/j.neucom.2023.126234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic computing realizes low-latency and low-power computing by emulating the neural structure and operation of the human brain, and is considered a key research area for third-generation artificial intelligence . However, current neuromorphic computing faces the problems of huge synaptic memory consumption and complex neuron calculations. This paper proposes a batch normalization (BN)-free weight-binarized SNN based on hardware-saving IF neurons to reduce storage requirements and improve the computational efficiency of neuromorphic computing. Hardware-friendly backpropagation through time (BPTT)-based algorithm and SG function are proposed to calculate the gradients of the “integrate” process and “fire” process of IF neuron, respectively. Weight binarization is carried out during training to reduce storage requirements, and spatio-temporal batch normalization (BN) operations are introduced to ensure high performance. During inference, a simple adaptive-threshold IF neuron model is proposed to achieve the effect equivalent to the computationally expensive spatio-temporal BN operation without any performance loss. The proposed BN-free binarized SNNs based on hardware-saving IF neuron achieves competitive accuracies of 99.36\%, 94.79\%, 90.39\%, and 67.10\% on the N-MNIST, DvsGesture, N-TIDIGITS18, and DVS-CIFAR10 datasets, respectively, which are comparable to full-precision SNNs, but the weight sizes are significantly reduced by ∼ 97\%. Furthermore, robustness experiments show that the binary SNN is more robust to weight noise than the full-precision SNN. This paper presents an efficient algorithm-hardware co-design paradigm for hardware-friendly and high-performance neuromorphic computing.},
  archive      = {J_NEUCOM},
  author       = {G.C. Qiao and N. Ning and Y. Zuo and P.J. Zhou and M.L. Sun and S.G. Hu and Q. Yu and Y. Liu},
  doi          = {10.1016/j.neucom.2023.126234},
  journal      = {Neurocomputing},
  pages        = {126234},
  shortjournal = {Neurocomputing},
  title        = {Batch normalization-free weight-binarized SNN based on hardware-saving IF neuron},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complex image classification by feature inference.
<em>NEUCOM</em>, <em>544</em>, 126231. (<a
href="https://doi.org/10.1016/j.neucom.2023.126231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification is a fundamental task in image processing . Despite the long time research, there are still many challenging problems to be solved. In this study, we introduce the problem of complex image classification. Images in realistic scenarios are complex and classifying samples directly are not always the right way even the performance is high. To address the issue, we propose a novel classification schema where classification is combined with image inpainting . There are two models including one inference network and one classification network in the proposed schema. The masked content that is specified as occlusions and interferences is inpainted by feature inference. The inference network inpaint the image with a mask and the network classifies the inferred image. We apply the proposed schema to existing classification models including AlexNet, GoogleNet, Inceptionv3, ResNet50 , and EfficientNetb7 and specific datasets including ImageNet, PlantCLEF, and CUB-200. Despite the simplicity, experimental results show that it significantly improves the performance of complex classifications.},
  archive      = {J_NEUCOM},
  author       = {Qingguo Xiao and Guangyao Li and Qiaochuan Chen},
  doi          = {10.1016/j.neucom.2023.126231},
  journal      = {Neurocomputing},
  pages        = {126231},
  shortjournal = {Neurocomputing},
  title        = {Complex image classification by feature inference},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-step histogram based outlier scores for unsupervised
anomaly detection: ArcelorMittal engineering dataset case of study.
<em>NEUCOM</em>, <em>544</em>, 126228. (<a
href="https://doi.org/10.1016/j.neucom.2023.126228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is the task of detecting samples that behave differently from the rest of the data or that include abnormal values. Unsupervised anomaly detection is the most common scenario, which implies that the algorithms cannot train with a labeled input and do not know the anomaly behavior beforehand. Histogram-based methods are one of the most approaches in unsupervised anomaly detection, remarking a good performance and a low runtime. Despite the good performance, histogram-based anomaly detectors are not capable of processing data flows while updating their knowledge and cannot deal with a high amount of samples. In this paper, we propose a new histogram-based approach for addressing the aforementioned problems by introducing the ability to update the information inside a histogram. We have applied these strategies to design a new algorithm called Multi-step Histogram Based Outlier Scores (MHBOS), including five new histogram update mechanisms. The results have shown the performance and validity of MHBOS as well as the proposed strategies in terms of performance and computing times.},
  archive      = {J_NEUCOM},
  author       = {Ignacio Aguilera-Martos and Marta García-Barzana and Diego García-Gil and Jacinto Carrasco and David López and Julián Luengo and Francisco Herrera},
  doi          = {10.1016/j.neucom.2023.126228},
  journal      = {Neurocomputing},
  pages        = {126228},
  shortjournal = {Neurocomputing},
  title        = {Multi-step histogram based outlier scores for unsupervised anomaly detection: ArcelorMittal engineering dataset case of study},
  volume       = {544},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gaussian similarity-based adaptive dynamic label assignment
for tiny object detection. <em>NEUCOM</em>, <em>543</em>, 126285. (<a
href="https://doi.org/10.1016/j.neucom.2023.126285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the advanced deep learning techniques, significant achievements have been made in generic object detection. Tiny object detection (TOD) is a challenging task in computer vision due to the low resolution, insufficient geometric cues, and high noise levels. A recent trend for detectors is introducing more granular label assignment strategies to provide promising supervision information for classification and regression. However, most previous Intersection-Over-Union (IoU) based methods suffer from two main drawbacks, including (1) low tolerance of IoU for bounding box deviations in tiny objects and (2) deficient guidance for optimization caused by inter-sample and intra-sample imbalance. We propose two novel components to address these problems: the Gaussian probabilistic distribution-based fuzzy similarity metric (GPM) and the adaptive dynamic anchor mining strategy (ADAS). GPM aims to address the issue of inaccurate similarity measurement between small bounding boxes and pre-defined anchors, providing a more accurate basis for label assignment. ADAS adopts a dynamically adjusted strategy for label assignment to address the distribution bias between positive and negative samples, ensuring that the label assignment is consistent with the distribution of objects in the image. Extensive experiments are conducted on AI-TODv2 and other tiny object detection datasets to evaluate the proposed ADAS-GPM method’s performance. The results demonstrate that incorporating ADAS-GPM into an anchor-based object detector yields significant outperformance over state-of-the-art methods on the challenging AI-TODv2 benchmark. The proposed ADAS-GPM method exhibits good results, clearly demonstrating its validity and potential.},
  archive      = {J_NEUCOM},
  author       = {Ronghao Fu and Chengcheng Chen and Shuang Yan and Ali Asghar Heidari and Xianchang Wang and José Escorcia-Gutierrez and Romany F. Mansour and Huiling Chen},
  doi          = {10.1016/j.neucom.2023.126285},
  journal      = {Neurocomputing},
  pages        = {126285},
  shortjournal = {Neurocomputing},
  title        = {Gaussian similarity-based adaptive dynamic label assignment for tiny object detection},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy logic nonzero-sum game-based distributed approximated
optimal control of modular robot manipulators with human-robot
collaboration. <em>NEUCOM</em>, <em>543</em>, 126276. (<a
href="https://doi.org/10.1016/j.neucom.2023.126276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a fuzzy logic nonzero-sum game-based distributed approximated optimal control scheme is presented for modular robot manipulators (MRMs) with human-robot collaboration (HRC) tasks. The MRM dynamic model is formulated by using joint torque feedback (JTF) technique. Based on the differential game strategy, the optimal control problem of HRC task-oriented MRM systems is transformed into a nonzero-sum game problem of multiple robotic subsystems. By taking advantage of the adaptive dynamic programming (ADP) algorithm, the distributed approximate optimal control policy under HRC tasks is developed by a novel fuzzy logic nonzero-sum game manner for solving the coupled Hamilton–Jacobian (HJ) equation. The trajectory tracking error under HRC task of the closed-loop MRM system is proved to be ultimately uniformly bounded (UUB) using the Lyapunov theory . Finally, experiment results have been presented, which demonstrate the advantage and effectiveness of the developed method.},
  archive      = {J_NEUCOM},
  author       = {Tianjiao An and Xinye Zhu and Mingchao Zhu and Bing Ma and Bo Dong},
  doi          = {10.1016/j.neucom.2023.126276},
  journal      = {Neurocomputing},
  pages        = {126276},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy logic nonzero-sum game-based distributed approximated optimal control of modular robot manipulators with human-robot collaboration},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EPT-GCN: Edge propagation-based time-aware graph convolution
network for POI recommendation. <em>NEUCOM</em>, <em>543</em>, 126272.
(<a href="https://doi.org/10.1016/j.neucom.2023.126272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In location-based social networks (LBSNs), point-of-interest (POI) recommendation systems help users identify unvisited POIs by filtering large amounts of information. Accurate POI recommendations can effectively improve user satisfaction and save time in finding POIs. In recent years, the graph convolution network (GCN) technique, which enhances the representational ability of neural networks by learning the embeddings of users and items, has been widely adopted in recommendation systems to improve accuracy. Combining GCN with various information, such as time and geographical information , can further improve recommendation performance. However, existing GCN-based techniques simply adopt time information by modeling users’ check-in sequences, which is insufficient and ignores users’ time-based high-order connectivity. Note that time-based high-order connectivity refers to the relationship between indirect neighbors with similar preferences in the same time slot. In this paper, we propose a new time-aware GCN model to extract rich collaborative signals contained in time information. Our work is the first to divide user check-ins into multiple subgraphs, i.e., time slots, based on time information. We further propose an edge propagation module to adjust edge affiliation, where edges represent check-ins, to propagate user’s time-based preference to multiple time slots. The propagation module is based on an unsupervised learning algorithm and does not require additional ground-truth labels. Experimental results confirm that our method outperforms state-of-the-art GCN models in all baselines, improving Recall @ 5 Recall@5 from 0.0803 to 0.0874 (8.84\%) on the Gowalla dataset and from 0.0360 to 0.0388 (7.78\%) on the New York dataset. The proposed subgraph mining technique and novel edge-based propagation module have high scalability and can be applied to other subgraph construction models.},
  archive      = {J_NEUCOM},
  author       = {Fan Mo and Hayato Yamana},
  doi          = {10.1016/j.neucom.2023.126272},
  journal      = {Neurocomputing},
  pages        = {126272},
  shortjournal = {Neurocomputing},
  title        = {EPT-GCN: Edge propagation-based time-aware graph convolution network for POI recommendation},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Feature selection with multi-class logistic regression.
<em>NEUCOM</em>, <em>543</em>, 126268. (<a
href="https://doi.org/10.1016/j.neucom.2023.126268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection can help to reduce data redundancy and improve algorithm performance in actual tasks. Most of the embedded feature selection models are constructed based on square loss and hinge loss. However, these models based on the square loss cannot directly evaluate the discriminability of the samples in the feature subspace, and these methods based on the hinge loss are difficult to solve due to their complex objective functions. To deal with these problems, a Feature Selection method with Multi-class Logistic Regression (FSMLR) is proposed in this paper. Firstly, we construct a linear function to measure the difference between the distance from samples to their regression hyperplane and the distance from these samples to regression hyperplanes of other classes, which could be used to strengthen the discriminant property of the embedded model. Then, we design a re-weighting matrix with a ℓ 2 , 0 ℓ2,0 -norm sparse condition as well as a discrete condition, which is used to select features in the subspace. Considering that it is difficult to solve the re-weighting matrix with the discrete and sparse conditions in an optimization problem , we relax these two conditions and present a feature selection model via a re-weighted multi-class logistic regression with the two relaxed constraints. Finally, we add the F -norm regularization in our model to avoid overfitting, and its unconstrained equivalent transformation with ℓ 2 , p ℓ2,p -norm regularization is derived to explore the function of the re-weighting matrix. The gradient descent algorithm could be used to solve the FSMLR. Especially, when the regularization term in the equivalence problem is set to ℓ 2 , 1 ℓ2,1 -norm, the global optimal solution can be obtained. Extensive experiments on multiple public data sets prove that FSMLR outperforms other competitors.},
  archive      = {J_NEUCOM},
  author       = {Jingyu Wang and Hongmei Wang and Feiping Nie and Xuelong Li},
  doi          = {10.1016/j.neucom.2023.126268},
  journal      = {Neurocomputing},
  pages        = {126268},
  shortjournal = {Neurocomputing},
  title        = {Feature selection with multi-class logistic regression},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic-agnostic progressive subtractive network for image
manipulation detection and localization. <em>NEUCOM</em>, <em>543</em>,
126263. (<a href="https://doi.org/10.1016/j.neucom.2023.126263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new detection and localization framework capable of detecting suspicious forgeries using the Semantic-Agnostic Progressive Subtractive Network (SAPS-Net). Our approach is based on the key observation that fluctuations in image content severely interfere with the capture of general manipulations by existing convolutional architecture. Distinct from the aggregation attention employed by traditional methods, we design the Semantic-Agnostic Manipulation Attention (SAMA) based on subtractive operation for mitigating the effect of rich image semantics on manipulation extraction. Initially, the Multi-Scale feature Iterative Fusion Block (MSIFB) and Multi-Kernel feature Fusion Residual Block (MKFRB) are designed to iteratively crawl potential semantic associations of different hierarchical feature mappings. Then, we further devise the subtractive operation to effectively remove the semantic associations as distractors and promote the network to adaptively learn general forgery. Notably, these semantic associations based on image content may be fundamentally different from the manipulation traces that alter the internal patterns of images. By progressively utilizing SAMAs, the network remains robust to image content manipulation with rich semantics. Extensive experiments on six challenge datasets show that our approach has more than 3.03\% pixel-level AUC gains and 3.70\% image-level AUC gains in cross-dataset scenarios compared to state-of-the-art methods, especially on the IMD20 dataset (pixel-level AUC: 0.859) and Wild dataset (pixel-level AUC: 0.821) with realistic scenarios.},
  archive      = {J_NEUCOM},
  author       = {Dengyun Xu and Xuanjing Shen and Zenan Shi and Na Ta},
  doi          = {10.1016/j.neucom.2023.126263},
  journal      = {Neurocomputing},
  pages        = {126263},
  shortjournal = {Neurocomputing},
  title        = {Semantic-agnostic progressive subtractive network for image manipulation detection and localization},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered delayed impulsive control for
synchronization of stochastic complex networks under deception attacks.
<em>NEUCOM</em>, <em>543</em>, 126256. (<a
href="https://doi.org/10.1016/j.neucom.2023.126256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes a class of stochastic complex networks (SCNs) subjected to deception attacks via the event- triggered delayed impulsive control (ETDIC) strategy. Noting the universality of delay, we consider the delay in impulsive control. The impulse is combined with the event-triggered mechanism (ETM), that is, the impulsive instant is determined by the ETM, which is defined by the network topology and the Lyapunov function . Based on this ETM, through a combination of the Lipschitz-Razumikhin method and graph theory, we obtain the conditions to avoid Zeno behavior and give some criteria of p th moment exponential synchronization (PMES) for SCNs under deception attacks. The criteria are related to the topology of the network, the event-triggered parameters, and the attack signals sent by the enemy. Finally, we analyze a class of coupling Chua’s circuits subjected to deception attacks and present numerical examples to verify the validity and practicability of our theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Ni Yang and Renjie Ji and Huan Su},
  doi          = {10.1016/j.neucom.2023.126256},
  journal      = {Neurocomputing},
  pages        = {126256},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered delayed impulsive control for synchronization of stochastic complex networks under deception attacks},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph attention network utilizing multi-granular
information for emotion-cause pair extraction. <em>NEUCOM</em>,
<em>543</em>, 126252. (<a
href="https://doi.org/10.1016/j.neucom.2023.126252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion-cause pair extraction (ECPE) aims to extract emotion and cause clauses underlying a text and pair them. Most of the recent approaches to this problem adopt deep neural networks to model the inter-clause dependency, without making full use of information at word level and document level. In this paper, we propose a model that utilizes multi-granular information, including word-level, clause-level, and document-level information, to facilitate emotion-cause pair extraction. Our model consists of two fully-connected clause graphs, including emotion graph and cause graph, and graph attention is applied to learn emotion-specific and cause-specific representations which are then used to generate document-level representations. To exploit the mutual indication between emotion and cause, a cross-graph co-attention mechanism is proposed. Moreover, external knowledge of emotional and causal cues is incorporated to provide word-level indicative information for emotion-cause pair extraction. The proposed model is tested on both Chinese [1] and English [2] datasets, and the results show that our model achieves the state-of-the-art performance on both datasets.},
  archive      = {J_NEUCOM},
  author       = {Siyuan Chen and Kezhi Mao},
  doi          = {10.1016/j.neucom.2023.126252},
  journal      = {Neurocomputing},
  pages        = {126252},
  shortjournal = {Neurocomputing},
  title        = {A graph attention network utilizing multi-granular information for emotion-cause pair extraction},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From detection to understanding: A survey on representation
learning for human-object interaction. <em>NEUCOM</em>, <em>543</em>,
126243. (<a href="https://doi.org/10.1016/j.neucom.2023.126243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-Object Interaction (HOI) detection is a critical topic in the visual understanding field. With the development of deep learning models , the research of HOI detection has been profoundly reshaped. Deep convolutional neural networks increased the object recognition accuracy of static images and induced a detection-based HOI detection stream. The detection-based models resolve the HOI detection problem from a classification perspective. Another stream of HOI detection methods seeks a deeper understanding of the information shown in images, and they are named HOI understanding methods in this survey paper. HOI understanding methods usually acquire external linguistic data to enable the deep models to learn more about the images. Additionally, some of the HOI understanding methods exploit graph neural networks (GNN) to increase the inference accuracy of the model.},
  archive      = {J_NEUCOM},
  author       = {Tianlun Luo and Steven Guan and Rui Yang and Jeremy Smith},
  doi          = {10.1016/j.neucom.2023.126243},
  journal      = {Neurocomputing},
  pages        = {126243},
  shortjournal = {Neurocomputing},
  title        = {From detection to understanding: A survey on representation learning for human-object interaction},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Day-ahead to intraday energy scheduling operation
considering extreme events using risk-based approaches. <em>NEUCOM</em>,
<em>543</em>, 126229. (<a
href="https://doi.org/10.1016/j.neucom.2023.126229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demand response programs, energy storage systems, electric vehicles, and local electricity markets are appropriate solutions to offset the uncertainty associated with the high penetration of distributed energy resources. It aims to enhance efficiency by adding such technologies to the energy resource management problem while also addressing current concerns using smart grid technologies and optimization methodologies. This paper presents an efficient intraday energy resource management starting from the day-ahead time horizon, which considers the uncertainty associated with load consumption, renewable generation, electric vehicles, electricity market prices, and the existence of extreme events in a 13-bus distribution network with high integration of renewables and electric vehicles. A risk analysis is implemented through conditional value-at-risk to address these extreme events. In the intraday model, we assume that an extreme event will occur to analyze the outcome of the developed solution. We analyze the solution’s impact departing from the day-ahead, considering different risk aversion levels. Multiple metaheuristics optimize the day-ahead problem, and the best-performing algorithm is used for the intraday problem. Results show that HyDE gives the best day-ahead solution compared to the other algorithms, achieving a reduction of around 37\% in the cost of the worst scenarios. For the intraday model, considering risk aversion also reduces the impact of the extreme scenarios.},
  archive      = {J_NEUCOM},
  author       = {José Almeida and Joao Soares and Bruno Canizes and Iván Razo-Zapata and Zita Vale},
  doi          = {10.1016/j.neucom.2023.126229},
  journal      = {Neurocomputing},
  pages        = {126229},
  shortjournal = {Neurocomputing},
  title        = {Day-ahead to intraday energy scheduling operation considering extreme events using risk-based approaches},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Do we really need a new theory to understand
over-parameterization? <em>NEUCOM</em>, <em>543</em>, 126227. (<a
href="https://doi.org/10.1016/j.neucom.2023.126227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This century saw an unprecedented increase of public and private investments in Artificial Intelligence (AI) and especially in (Deep) Machine Learning (ML). This led to breakthroughs in their practical ability to solve complex real-world problems impacting research and society at large. Instead, our ability to understand the fundamental mechanism behind these breakthroughs has slowed down because of their increased complexity, while in the past breakthroughs often emerged from foundational research. This questioned researchers about the necessity for a new theoretical framework able to help researchers catch up on this lag. One of the still not well understood mechanisms is the so-called over-parametrization, namely the ability of certain models to increase their generalization performance (reduce test error) when the number of parameters is above the interpolating threshold (zero training error). In this paper we will show that this phenomenon can be better understood using both known theories (surveying them in the process) and empirical evidences for both shallow and deep learning algorithms.},
  archive      = {J_NEUCOM},
  author       = {Luca Oneto and Sandro Ridella and Davide Anguita},
  doi          = {10.1016/j.neucom.2023.126227},
  journal      = {Neurocomputing},
  pages        = {126227},
  shortjournal = {Neurocomputing},
  title        = {Do we really need a new theory to understand over-parameterization?},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LIAAD: Lightweight attentive angular distillation for
large-scale age-invariant face recognition. <em>NEUCOM</em>,
<em>543</em>, 126198. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disentangled representations have been commonly adopted to Age-invariant Face Recognition (AiFR) tasks. However, these methods have reached some limitations with (1) the requirement of large-scale face recognition (FR) training data with age labels, which is limited in practice; (2) heavy deep network architectures for high performance; and (3) their evaluations are usually taken place on age-related face databases while neglecting the standard large-scale FR databases to guarantee robustness. This work presents a novel Lightweight Attentive Angular Distillation (LIAAD) approach to Large-scale Lightweight AiFR that overcomes these limitations. Given two high-performance heavy networks as teachers with different specialized knowledge, LIAAD introduces a learning paradigm to efficiently distill the age-invariant attentive and angular knowledge from those teachers to a lightweight student network making it more powerful with higher FR accuracy and robust against age factor. Consequently, LIAAD approach is able to take the advantages of both FR datasets with and without age labels to train an AiFR model. Far apart from prior distillation methods mainly focusing on accuracy and compression ratios in closed-set problems, our LIAAD aims to solve the open-set problem, i.e. large-scale face recognition. Evaluations on LFW, IJB-B and IJB-C Janus, AgeDB and MegaFace-FGNet with one million distractors have demonstrated the efficiency of the proposed approach on light-weight structure. This work also presents a new longitudinal face aging (LogiFace) database 1 for further studies in age-related facial problems in future.},
  archive      = {J_NEUCOM},
  author       = {Thanh-Dat Truong and Chi Nhan Duong and Kha Gia Quach and Ngan Le and Tien D. Bui and Khoa Luu},
  doi          = {10.1016/j.neucom.2023.03.059},
  journal      = {Neurocomputing},
  pages        = {126198},
  shortjournal = {Neurocomputing},
  title        = {LIAAD: Lightweight attentive angular distillation for large-scale age-invariant face recognition},
  volume       = {543},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-domain clustering pruning: Exploring space and
frequency similarity based on GAN. <em>NEUCOM</em>, <em>542</em>,
126279. (<a href="https://doi.org/10.1016/j.neucom.2023.126279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network compression plays an important role in accelerating deep neural networks , especially in the application of edge devices such as unmanned cars and drones. Recently, pruning-based methods have been improved significantly, but they still suffer from low efficiency because most of them only pay attention to feature similarities in the space domain. In this paper, we propose a multi-domain structured pruning method based on clustering (MDCP) which seamlessly integrates sufficient information extraction and knowledge distillation within a GAN-based framework, to address these aforementioned limitations. Specifically, 1) to exhaustively analyze the features for reasonable pruning, we perform pruning taking both space and frequency information into account, which considering the spectral statistics to produce a more accurate pruning map; 2) to tackle the distance distortion problem caused by feature insufficiency, we further propose a clustering-based measurement mechanism to acquire pruning guidance under extreme conditions; 3) to avoid the dependence on labels and fine-tuning in previous works, a generative adversarial mechanism with two label-level losses is introduced, which further ensures the pruning efficiency and accuracy. Such a multi-domain clustering-based framework along with an adversarial and contrastive learning pattern significantly improves the pruning quality. Comprehensive experiments conducted on four benchmarks demonstrate that our MDCP method performs favorably against existing competitors. Notably, for CIFAR-10 dataset, our method on ResNet-110 outperforms the former state-of-the-art method (94.33\%) in terms of top-1 accuracy (94.61\%) and achieves a maximum parameter pruning rate (73.33\%).},
  archive      = {J_NEUCOM},
  author       = {Junsan Zhang and Yeqi Feng and Chao Wang and Mingwen Shao and Yujie Jiang and Jian Wang},
  doi          = {10.1016/j.neucom.2023.126279},
  journal      = {Neurocomputing},
  pages        = {126279},
  shortjournal = {Neurocomputing},
  title        = {Multi-domain clustering pruning: Exploring space and frequency similarity based on GAN},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining global receptive field and spatial spectral
information for single-image hyperspectral super-resolution.
<em>NEUCOM</em>, <em>542</em>, 126277. (<a
href="https://doi.org/10.1016/j.neucom.2023.126277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-image hyperspectral super-resolution has poorer reconstruction performance in the spatial dimension than fused-image hyperspectral super-resolution due to the lack of auxiliary images. Some studies have attempted to use 3D convolution to explore hidden features between spatial spectra to enhance spatial details. However, either 2D or 3D convolution, the obtained receptive fields are limited, ignoring the effect of global spatial information on hyperspectral image reconstruction, and cannot be used for long-range dependent modeling. Therefore, we make the first attempt to combine Transformer with 3D convolution in single-image hyperspectral super-resolution and propose a 3D convolution and Transformer hyperspectral super-resolution (3D-THSR) network, which explores the hidden information between space and spectra while obtaining the global receptive field of space. Specifically, the Transformer module is used for feature extraction to enhance the learning ability of global spatial information and long-distance features. In addition, the 3D convolution module is embedded in the Transformer module to extract the information between different spectral bands by fusing the spectral and spatial dimensions. Finally, we design to train the network by using three loss functions to reduce the distortion spectrum and ensure the spectral band purity. Compared with other single-image hyperspectral methods by six hyperspectral evaluation metrics , spatial detail image, spectral error line map, and ablation study, it is proved that the proposed method achieves better hyperspectral super-resolution reconstruction performance.},
  archive      = {J_NEUCOM},
  author       = {Yiming Wu and Ronghui Cao and Yikun Hu and Jin Wang and Kenli Li},
  doi          = {10.1016/j.neucom.2023.126277},
  journal      = {Neurocomputing},
  pages        = {126277},
  shortjournal = {Neurocomputing},
  title        = {Combining global receptive field and spatial spectral information for single-image hyperspectral super-resolution},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel fixed-time stability result and its application to
synchronization of delayed multidirectional associative memory neural
networks with discontinuous activations. <em>NEUCOM</em>, <em>542</em>,
126275. (<a href="https://doi.org/10.1016/j.neucom.2023.126275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, in order to realize time-saving and low-consumption secure communication based on fixed-time (FXT) synchronization, some new FXT stability results and a smaller upper bound of settling time are obtained by using inequality techniques, variable substitution method and some special functions, including beta function and incomplete beta function. Moreover, the FXT synchronization of delayed multidirectional associative memory (MAM) neural networks with discontinuous activations is investigated by employing the differential inclusion theory, the improved FXT stability theorem and a simple delay-independent nonlinear controller. Finally, a numerical simulation is given to verify the correctness of the theoretical results and the effectiveness of FXT synchronization in secure communication. The results show that the upper bound estimation of settling time in this paper is indeed smaller than that in some previous researches. In addition, the encrypted signals can be quickly decrypted based on the improved FXT stability results, but may not be decrypted by the existing FXT stability results.},
  archive      = {J_NEUCOM},
  author       = {Hongyun Yan and Yuanhua Qiao and Zhihua Ren and Lijuan Duan and Jun Miao},
  doi          = {10.1016/j.neucom.2023.126275},
  journal      = {Neurocomputing},
  pages        = {126275},
  shortjournal = {Neurocomputing},
  title        = {A novel fixed-time stability result and its application to synchronization of delayed multidirectional associative memory neural networks with discontinuous activations},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic-based event-triggered neural network control for
p-normal interconnected time-delay systems with asymmetric constraints.
<em>NEUCOM</em>, <em>542</em>, 126266. (<a
href="https://doi.org/10.1016/j.neucom.2023.126266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A decentralized dynamic event-triggered tracking control problem is investigated for a class of p -normal interconnected time-delay nonlinear systems with asymmetric constraints. First, a new event-triggered mechanism (ETM) is constructed by designing a dynamic variable law, which effectively reduces the number of controller updates. The introduced constants provide an obvious solution for the proof of Zeno phenomenon. Second, a barrier Lyapunov function (BLF) is constructed with the help of sign functions to achieve time-varying asymmetric constraints. Meanwhile, we improve the previous neural networks (NNs) approximation scheme and dynamic gain technique in order to handle unknown interconnection functions and time-delay signals, respectively. Then, it is rigorously proved that all signals in the system are bounded, and the error signals are constrained within the time-varying asymmetric bounds. Finally, the feasibility of the scheme is verified by simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Qidong Li and Changchun Hua and Kuo Li and Rui Meng},
  doi          = {10.1016/j.neucom.2023.126266},
  journal      = {Neurocomputing},
  pages        = {126266},
  shortjournal = {Neurocomputing},
  title        = {Dynamic-based event-triggered neural network control for p-normal interconnected time-delay systems with asymmetric constraints},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequency-based pseudo-domain generation for domain
generalizable object detection. <em>NEUCOM</em>, <em>542</em>, 126265.
(<a href="https://doi.org/10.1016/j.neucom.2023.126265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalizable object detection (DGOD) aims to train a detector that performs well on multiple unseen target domains, which is crucial for deploying the detector in practice. Recent methods for DGOD typically inherit the idea from domain adaptation to align or disentangle features, but these methods struggle to handle unknown target distributions. In this paper, we propose a unified framework to tackle the DGOD task from a novel pseudo-domain generation perspective. Our framework comprises two stages: distribution diversification and domain-invariant feature learning. In the distribution diversification stage, we design a Frequency-based Pseudo-domain Generator (FPG) to construct the pseudo domain via excavating latent style information and enhancing semantic information in frequency space. The generated pseudo domain can provide diverse training distributions, which enhances generalization performance. In the domain-invariant feature learning stage, we introduce Rotation Prediction and Semantic Consistency (RPSC) learning, including an auxiliary self-supervised task rotation prediction to encourage generalized feature learning and a semantic consistency loss to enforce the detector to be invariant of domain shifts. Extensive experiments are conducted on various object detection benchmarks, demonstrating the superiority of our approach over state-of-the-art methods in both single-source and multi-source settings.},
  archive      = {J_NEUCOM},
  author       = {Siqi Zhang and Lu Zhang and Zhi-Yong Liu},
  doi          = {10.1016/j.neucom.2023.126265},
  journal      = {Neurocomputing},
  pages        = {126265},
  shortjournal = {Neurocomputing},
  title        = {Frequency-based pseudo-domain generation for domain generalizable object detection},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stabilization control of quaternion-valued fractional-order
discrete-time memristive neural networks. <em>NEUCOM</em>, <em>542</em>,
126255. (<a href="https://doi.org/10.1016/j.neucom.2023.126255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stabilization control of the memristive neural networks with discrete-time terms and fractional derivative is proposed. By employing the Lyapunov functional method and fully considering the integrity of the quaternion system, some sufficient criteria are derived based on nonlinear scalarization approach and several inequality techniques. The stabilization criteria are established in the form of algebraic inequality, which can be directly resolved by a simple calculation. Finally, two numerical examples are proposed to demonstrate the validity of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Ruoxia Li and Jinde Cao and Ning Li},
  doi          = {10.1016/j.neucom.2023.126255},
  journal      = {Neurocomputing},
  pages        = {126255},
  shortjournal = {Neurocomputing},
  title        = {Stabilization control of quaternion-valued fractional-order discrete-time memristive neural networks},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FACapsnet: A fusion capsule network with congruent attention
for cyberbullying detection. <em>NEUCOM</em>, <em>542</em>, 126253. (<a
href="https://doi.org/10.1016/j.neucom.2023.126253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an extension of bullying on social networks, cyberbullying has seriously affected the security of the online social environment and infringed on mental health. Taking appropriate measures to detect online bullying reviews is crucial. Existing studies usually classify the whole content as cyberbullying and non-cyberbullying. However, they do not fully exploit the interaction of multi-dimensional features and precisely distinguish the types of cyberbullying. To automatically extract features of bullying words and further identify fine-grained types of cyberbullying better, we propose a fusion capsule network with congruent attention for cyberbullying detection. In the proposed algorithm, a novel similarity weighting scheme based on word2vec is designed to soft highlight bullying features in word embeddings. Meanwhile, to leverage the respective advantages of extracted multiple subspace features, we construct a novel extensible congruent attention to balance the fusion of complex correlations between different subspace representations and retain the independence of context features. The fused features are updated iteratively with dynamic routing to aggregate and generate fine-grained category capsules for cyberbullying prediction. A series of experiments on the tweets cyberbullying benchmark demonstrate that our architecture matches or exceeds the performance of the compared baseline models and the results of extensive experiments prove the effectiveness of different strategies.},
  archive      = {J_NEUCOM},
  author       = {Fan Wu and Bin Gao and Xiaoou Pan and Zelong Su and Yu Ji and Shutian Liu and Zhengjun Liu},
  doi          = {10.1016/j.neucom.2023.126253},
  journal      = {Neurocomputing},
  pages        = {126253},
  shortjournal = {Neurocomputing},
  title        = {FACapsnet: A fusion capsule network with congruent attention for cyberbullying detection},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TANGO: A temporal spatial dynamic graph model for event
prediction. <em>NEUCOM</em>, <em>542</em>, 126249. (<a
href="https://doi.org/10.1016/j.neucom.2023.126249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The event prediction task learns the dynamic changes of past events and infers the upcoming ones. This task helps people to understand how events evolve in our real world and make rapid, accurate, and efficient reactions in emergencies. The complex relation of events and entities (events participants) changes dynamically over time. The current solutions of event prediction have not fully exploited such event temporal dependency and entity relation dependency . In addition, an event may relate to a considerable number of entities. Among such related entities, only a few of them are the key participants in driving the evolution of the event. Previous works fail to emphasize such key entities and limit the non-related entities. In this paper, we introduce a novel gating and attention mechanism and propose a novel T emporal sp A tial dy N amic G raph m O del ( TANGO ) that is composed of a graph model (based on Graph Convolutional Network with gated and attention mechanisms) and a sequential model (based on Temporal Convolutional Network). TANGO is able to model the event temporal dependency and entity relation dependency simultaneously; learn the representation of events relations; control the aggregation of relational information among entities with varying degrees of mutual influence; support long effective historical sizes. We demonstrate the validity and effectiveness of our approach on three different datasets (i.e., ICEWS18, GDELT, and ICEWS14). The result shows almost 6.2\% MRR improvement and 3.9\% Hits@10 improvement over the previous state-of-the-art.},
  archive      = {J_NEUCOM},
  author       = {Zhihao Wang and Ding Ding and Min Ren and Mauro Conti},
  doi          = {10.1016/j.neucom.2023.126249},
  journal      = {Neurocomputing},
  pages        = {126249},
  shortjournal = {Neurocomputing},
  title        = {TANGO: A temporal spatial dynamic graph model for event prediction},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep neural architecture for harmonizing 3-d input data
analysis and decision making in medical imaging. <em>NEUCOM</em>,
<em>542</em>, 126244. (<a
href="https://doi.org/10.1016/j.neucom.2023.126244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harmonizing the analysis of data , especially of 3-D image volumes, consisting of different number of slices and annotated per volume, is a significant problem in training and using deep neural networks in various applications, including medical imaging . Moreover, unifying the decision making of the networks over different input datasets is crucial for the generation of rich data-driven knowledge and for trusted usage in the applications. This paper presents a new deep neural architecture, named RACNet, which includes routing and feature alignment steps and effectively handles different input lengths and single annotations of the 3-D image inputs, whilst providing highly accurate decisions. In addition, through latent variable extraction from the trained RACNet, a set of anchors are generated providing further insight on the network’s decision making. These can be used to enrich and unify data-driven knowledge extracted from different datasets. An extensive experimental study illustrates the above developments, focusing on COVID-19 diagnosis through analysis of 3-D chest CT scans from databases generated in different countries and medical centers.},
  archive      = {J_NEUCOM},
  author       = {Dimitrios Kollias and Anastasios Arsenos and Stefanos Kollias},
  doi          = {10.1016/j.neucom.2023.126244},
  journal      = {Neurocomputing},
  pages        = {126244},
  shortjournal = {Neurocomputing},
  title        = {A deep neural architecture for harmonizing 3-D input data analysis and decision making in medical imaging},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spike-driven multi-scale learning with hybrid mechanisms of
spiking dendrites. <em>NEUCOM</em>, <em>542</em>, 126240. (<a
href="https://doi.org/10.1016/j.neucom.2023.126240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural dendrites play a critical role in various cognitive functions, including spatial navigation, sensory processing , adaptive learning, and perception. The spatial layout , signal processing, and nonlinear dynamics of dendrites endow them with these abilities. However, designing an efficient learning mechanism with spiking dendrites remains a challenging problem. In this article, a novel biologically plausible learning method is developed to address this challenge. The method uses a multi-scale learning rule with dendritic predictive characteristics. A two-phase learning mechanism based on burst-related plateau potential dynamics of spiking dendrites is utilized to achieve global learning of the spiking model. Experimental results demonstrate that the proposed algorithm can improve the learning accuracy and reduce the synaptic operations compared to the previous dendritic learning rule without dendritic predictive mechanism. It effectively reduces both the synaptic operations and the spike number in the output layer, leading to a reduction of power consumption on neuromorphic hardware. This suggests the multi-scale combination of the three-factor dendritic prediction principle and two-phase plateau potential activities can enhance the learning capability and sparsity within a single neuron. Besides, our learning method enhances the robustness and improves the learning convergence speed. We also explore different model variation formations of our learning model. The proposed study can contribute to spike-based machine learning and neuromorphic computing. It is also meaningful for a deeper understanding of the dendritic roles on biologically plausible credit assignment in the brain cortex.},
  archive      = {J_NEUCOM},
  author       = {Shuangming Yang and Yanwei Pang and Haowen Wang and Tao Lei and Jing Pan and Jian Wang and Yaochu Jin},
  doi          = {10.1016/j.neucom.2023.126240},
  journal      = {Neurocomputing},
  pages        = {126240},
  shortjournal = {Neurocomputing},
  title        = {Spike-driven multi-scale learning with hybrid mechanisms of spiking dendrites},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multivariate time series data imputation using
attention-based mechanism. <em>NEUCOM</em>, <em>542</em>, 126238. (<a
href="https://doi.org/10.1016/j.neucom.2023.126238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the widely deployment of different sensors and Internet of Things , a large volume of multivariate time series has been collected. However, there are many missing values in the multivariate time series due to different reasons, such as sensor damage, environmental intrusion and machine failure. These missing values bring challenges to further analysis of multivariate time series. The existing methods for multivariate time series imputation either destroy the properties of the original data or fail to capture the correlations of the data effectively. In order to solve the problems in existing methods, we propose a novel imputation method for multivariate time series based on Generative Adversarial Networks ( GAN ). Specifically, we use Auto-Encoder ( AE ) as the generator ( G G ), Recurrent Neural Networks ( RNN ) as the discriminator ( D D ). Taking advantages of generative adversarial networks to impute the incomplete multivariate time series data. In addition, Attention Mechanism is integrated to the structure of the Encoder and Decoder to keep the correlations among data. By integrating the advantages of Attention Mechanism , it enables the generator to take advantage of the internal features of the original data when imputing the data. Therefore, the imputed multivariate time series are more reasonable and reliable. Furthermore, we also improve our model by integrating Self-Attention Mechanism to improve the accuracy for multivariate time series imputation. Experimental results on real datasets demonstrate that the performance of the proposed model exceeds existing models and achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Jingqi Zhao and Chuitian Rong and Chunbin Lin and Xin Dang},
  doi          = {10.1016/j.neucom.2023.126238},
  journal      = {Neurocomputing},
  pages        = {126238},
  shortjournal = {Neurocomputing},
  title        = {Multivariate time series data imputation using attention-based mechanism},
  volume       = {542},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimization based framework for region wise optimal
clusters in MR images using hybrid objective. <em>NEUCOM</em>,
<em>541</em>, 126286. (<a
href="https://doi.org/10.1016/j.neucom.2023.126286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm Intelligence based methods are amongst the highly efficient approaches for optimization in image clustering. Optimal clustering has been studied in many real-world applications, such as medical and aerial image segmentation . Region wise clustering is a class of challenges in image region segmentation. Uncertain convergence and high computational load are critical issues in the region-wise image clustering due to local optimum and the NP-hard cluster computation. Meta-heuristics approaches are efficient to achieve global optimum by including better search space exploration techniques. This paper develops a framework for cluster optimization by selecting the seeds in pathological medical resonance (MR) images using a variant of firefly optimization. The heuristics based method uses Gaussian random walk for convergence that occasionally results in local optima; therefore, we have investigated the firefly method with more search space exploration techniques and improved region-wise objective. Our framework applies the levy flights for exploration and compared with other search spaces like Cauchy, and Gaussian random walk. The intra-cluster and inter-cluster-based hybrid objective is converged swiftly. The framework has been compared with two of its variants and three other meta-heuristic-based methods, namely simulated annealing, PSO , and Cuckoo search . The MSE, PSNR , structural similarity(SSIM), and feature similarity(FSIM) based evaluation indices are measured for normal and abnormal MR images and listed in table-5, 6. Reported indices values for our frame work are better than existing methods. Figure-9, 10, 11 compares the stochastic search spaces among Levy flights, Cauchy random walk, Gaussian random walk and observed Levy flights as better search space. In section-3.5, The convergence for proposed framework is shown for multi-objective function against the single objective in two normal and abnormal images. Single objective converged from 188 to 119 and multi-objective converged from 196 to 117 for first image. For second image, the single objective converged from 168 to 94 and multi-objective converged from 183 to 93. Finally, we have illustrated the convergence criteria and computation complexity on publicly available MR data sets.},
  archive      = {J_NEUCOM},
  author       = {Vishal Srivastava and Bhaskar Biswas},
  doi          = {10.1016/j.neucom.2023.126286},
  journal      = {Neurocomputing},
  pages        = {126286},
  shortjournal = {Neurocomputing},
  title        = {An optimization based framework for region wise optimal clusters in MR images using hybrid objective},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Adaptive event-based fixed-time tracking design for
strict-feedback nonlinear systems with unknown control coefficients.
<em>NEUCOM</em>, <em>541</em>, 126278. (<a
href="https://doi.org/10.1016/j.neucom.2023.126278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel Nussbaum-type design to cope with the problem in nonlinear dynamical systems with unknown control directions. First, a Nussbaum-based Lyapunov analysis for fixed-time stability is investigated to lay the theoretical foundation. On this basis, the Nussbaum-type adaptive backstepping control is designed with dynamic surface filters to avoid repeated differentiation. To further reduce the computational complexity , an event-triggered mechanism is combined with the Nussbaum-type gain design. With the above design schemes, the practical fixed-time stability of the overall feedback systems can be guaranteed with theoretical discussion. Finally, the feasibility of the presented design is validated by two simulation examples made in the end.},
  archive      = {J_NEUCOM},
  author       = {Guilong Liu and Yongliang Yang and Da-Wei Ding and Qing Li},
  doi          = {10.1016/j.neucom.2023.126278},
  journal      = {Neurocomputing},
  pages        = {126278},
  shortjournal = {Neurocomputing},
  title        = {Adaptive event-based fixed-time tracking design for strict-feedback nonlinear systems with unknown control coefficients},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple visual relationship forecasting and arrangement in
videos. <em>NEUCOM</em>, <em>541</em>, 126274. (<a
href="https://doi.org/10.1016/j.neucom.2023.126274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual relationships in videos are often causally connected and time-dependent. The complicated temporal dependency between visual relationships is overlooked in visual relationship modeling. To explore the realistic interactions and model the causality between visual relationships in videos, we propose a new task named Multiple Visual Relation Forecasting and Arrangement (MVRFA). Given a series of frames focusing on a   pair, MVRFA aims to forecast the future visual relationships and their arrangement which reflects their temporal interrelationship. To evaluate the MVRFA task, we build a video dataset consisting of 1195 videos with 2666 visual relationships and corresponding arrangements annotated by 5 temporal relational classes. In addition, we present a Multi-task Relationship-centric Transformer model as a baseline, which applies graph convolution to aggregate subject-relationship-object information and uses the relationship multi-query transformer to predict the visual relationships with their arrangement. Experiments on the proposed dataset demonstrate that the proposed baseline achieves superior performance and can better handle the MVRFA task than related models.},
  archive      = {J_NEUCOM},
  author       = {Wanping Ouyang and Yaosi Hu and Yangjun Ou and Zhenzhong Chen},
  doi          = {10.1016/j.neucom.2023.126274},
  journal      = {Neurocomputing},
  pages        = {126274},
  shortjournal = {Neurocomputing},
  title        = {Multiple visual relationship forecasting and arrangement in videos},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble of 6 DoF pose estimation from state-of-the-art deep
methods. <em>NEUCOM</em>, <em>541</em>, 126270. (<a
href="https://doi.org/10.1016/j.neucom.2023.126270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have revolutionized computer vision since the appearance of AlexNet in 2012. Nevertheless, 6 degrees of freedom pose estimation is still a difficult task to perform precisely. Therefore, we propose 2 ensemble techniques to refine poses from different deep learning 6DoF pose estimation models. The first technique, merge ensemble, combines the outputs of the base models geometrically. In the second, stacked generalization, a machine learning model is trained using the outputs of the base models and outputs the refined pose. The merge method improves the performance of the base models on LMO and YCB-V datasets and performs better on the pose estimation task than the stacking strategy.},
  archive      = {J_NEUCOM},
  author       = {Ibon Merino and Jon Azpiazu and Anthony Remazeilles and Basilio Sierra},
  doi          = {10.1016/j.neucom.2023.126270},
  journal      = {Neurocomputing},
  pages        = {126270},
  shortjournal = {Neurocomputing},
  title        = {Ensemble of 6 DoF pose estimation from state-of-the-art deep methods.},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient distribution-aware INT8 training for neural
networks. <em>NEUCOM</em>, <em>541</em>, 126269. (<a
href="https://doi.org/10.1016/j.neucom.2023.126269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, low bit-width quantization (e.g., INT8) has been commonly used in deep neural network inference acceleration, but fewer researchers have focused on low-precision training quantization techniques. Considering that the backward propagation in deep neural network training is more computationally intensive and has a heavier energy overhead than the inference process, the quantization of backward propagation is of great interest for the training of very large-scale neural networks as well as for low-power devices with online training requirements. However, the shape specificity and continuous variability of the gradient distribution make gradient quantization difficult, and many studies propose various complex quantization methods for the gradient to reduce training accuracy loss. In this paper, we propose two innovative techniques mainly for INT8 quantization training, including the Data-aware Dynamic Segmentation Quantization scheme to quantize various special gradient distributions and the Update Direction Periodic Search strategy to achieve lower quantization errors . Then, we build a distribution-aware INT8 quantization training framework based on these two methods and conduct experiments on various models and tasks. Experimental results show that our proposed INT8 quantization training method achieves a negligible loss in final training accuracy compared to the full-precision floating-point counterpart on different models, including ResNet , MobileNetV2 , VGG, AlexNet, and LSTM . By replacing floating-point computing with 8-bit integer computing for network training, this INT8 quantization training framework provides the possibility of deploying online training directly on low-power devices in the future.},
  archive      = {J_NEUCOM},
  author       = {Shuai Wang and Yi Kang},
  doi          = {10.1016/j.neucom.2023.126269},
  journal      = {Neurocomputing},
  pages        = {126269},
  shortjournal = {Neurocomputing},
  title        = {Gradient distribution-aware INT8 training for neural networks},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-focus transfer network for zero-shot learning.
<em>NEUCOM</em>, <em>541</em>, 126264. (<a
href="https://doi.org/10.1016/j.neucom.2023.126264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning aims to recognize image categories which are “unseen” in the training phase of image classification models. The key to this task is to transfer the learned knowledge from “seen” classes to “unseen” classes. In order to make the knowledge transfer process more effective, we propose to exploit both the visual and semantic attention mechanisms simultaneously in zero-shot learning tasks. Specifically, a dual-focus transfer network (DFTN) model is proposed to implement attention mechanisms from both the visual and semantic ends in a mapping based zero-shot learning framework with a visual focus transfer (VFT) module and a semantic focus transfer (SFT) module. The VFT module is composed by multi-head self-attention networks, which endows salient parts of images with greater weights at different resolutions of the feature maps. The SFT module generates semantic weights to re-weight semantic attribute features with the guidance of visual representations, where the semantic attributes corresponding to more visual discrimination capability will obtain greater weights. Extensive experiments of zero-shot learning and generalized zero-shot learning on five representative benchmarks demonstrate the superiority of the proposed DFTN model, compared to other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zhen Jia and Zhang Zhang and Caifeng Shan and Liang Wang and Tieniu Tan},
  doi          = {10.1016/j.neucom.2023.126264},
  journal      = {Neurocomputing},
  pages        = {126264},
  shortjournal = {Neurocomputing},
  title        = {Dual-focus transfer network for zero-shot learning},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An explainable intelligence fault diagnosis framework for
rotating machinery. <em>NEUCOM</em>, <em>541</em>, 126257. (<a
href="https://doi.org/10.1016/j.neucom.2023.126257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are considered black boxes due to their robust nonlinear fitting capability. In the context of fault diagnosis for rotating machinery, it may happen that a standard CNN makes a final decision based on a mixture of significant and insignificant features, therefore, it is required to establish a trustworthy intelligence fault diagnosis model with the controllable feature learning capability to identify fault types. In this paper, an explainable intelligence fault diagnosis framework is proposed to recognize the fault signals, using data obtained through short-time Fourier transformation, which is easily modified from a standard CNN. The post hoc explanation method is used to visualize the features the model learned from a signal. The experimental results show that the proposed explainable intelligence fault diagnosis framework provides 100\%\% testing accuracy and visualizations, the Average Drop and the Average Increase from a classification activation mappings method demonstrate the interpretability of the proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Daoguang Yang and Hamid Reza Karimi and Len Gelman},
  doi          = {10.1016/j.neucom.2023.126257},
  journal      = {Neurocomputing},
  pages        = {126257},
  shortjournal = {Neurocomputing},
  title        = {An explainable intelligence fault diagnosis framework for rotating machinery},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An edge guided coarse-to-fine generative network for image
outpainting. <em>NEUCOM</em>, <em>541</em>, 126254. (<a
href="https://doi.org/10.1016/j.neucom.2023.126254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning based generative models have achieved outstanding performance in various image processing tasks. This paper introduces a method to address the problem of extrapolating or outpainting visual context. When the input size is a small proportion of the output size, a limited amount of information is present to regenerate a semantically coherent image. This task is challenging because the missing region of the original image may include crucial semantic and spatial structural information, which is difficult to predict from the input. We propose a three-stage edge-guided coarse-to-fine generative network model, consisting of a contextual inference network, structural edge map generator and edge enhanced network, to synthesise semantically consistent output from small picture inputs. Our model adopts a gradual growth inference strategy in the contextual inference network so that the generated image can present a more coherent structure, and this result can support the structural edge map generator to generate a reasonable edge map in a large missing area. Combining the contextual inference network and structural edge map generator outputs enables the edge enhanced network to generate more convincing images. We evaluate our model using four public datasets: CelebA, Places2, Oxford Flower102and CUB200. Our experimental results demonstrate that the proposed image outpainting network can successfully regenerate high-quality images with a large missing region even when some structural features are lost in the input images.},
  archive      = {J_NEUCOM},
  author       = {Yiwen Xu and Maurice Pagnucco and Yang Song},
  doi          = {10.1016/j.neucom.2023.126254},
  journal      = {Neurocomputing},
  pages        = {126254},
  shortjournal = {Neurocomputing},
  title        = {An edge guided coarse-to-fine generative network for image outpainting},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AID-purifier: A light auxiliary network for boosting
adversarial defense. <em>NEUCOM</em>, <em>541</em>, 126251. (<a
href="https://doi.org/10.1016/j.neucom.2023.126251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose AID-purifier that can boost the robustness of adversarially-trained networks by purifying their inputs. AID-purifier is an auxiliary network that works as an add-on to an already trained main classifier. To keep it computationally light, it is trained as a discriminator with a binary cross-entropy loss. To obtain additionally useful information from the adversarial examples , the architecture design is closely related to the information maximization principle where two layers of the main classification network are piped into the auxiliary network. To assist the iterative optimization procedure of purification, the auxiliary network is trained with AVmixup. AID-purifier can be also used together with other purifiers such as PixelDefend for an extra enhancement. Because input purification has been studied relative less when compared to adversarial training or gradient masking, we conduct extensive attack experiments to validate AID-purifier’s robustness. The overall results indicate that the best performing adversarially-trained networks can be enhanced further with AID-purifier. The code is available in https://github.com/yelobean/AIDPurifier.},
  archive      = {J_NEUCOM},
  author       = {Duhun Hwang and Eunjung Lee and Wonjong Rhee},
  doi          = {10.1016/j.neucom.2023.126251},
  journal      = {Neurocomputing},
  pages        = {126251},
  shortjournal = {Neurocomputing},
  title        = {AID-purifier: A light auxiliary network for boosting adversarial defense},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wasserstein adversarially regularized graph autoencoder.
<em>NEUCOM</em>, <em>541</em>, 126235. (<a
href="https://doi.org/10.1016/j.neucom.2023.126235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Wasserstein Adversarially Regularized Graph Autoencoder (WARGA), an implicit generative algorithm that directly regularizes the latent distribution of node embedding to a target distribution via the Wasserstein metric. To ensure the Lipschitz continuity, we propose two approaches: WARGA-WC that uses weight clipping method and WARGA-GP that uses gradient penalty method. The proposed models have been validated by link prediction and node clustering on real-world graphs with visualizations of node embeddings, in which WARGA generally outperforms other state-of-the-art models based on Kullback–Leibler (KL) divergence and typical adversarial framework.},
  archive      = {J_NEUCOM},
  author       = {Huidong Liang and Junbin Gao},
  doi          = {10.1016/j.neucom.2023.126235},
  journal      = {Neurocomputing},
  pages        = {126235},
  shortjournal = {Neurocomputing},
  title        = {Wasserstein adversarially regularized graph autoencoder},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A high-efficiency spaceborne processor for hybrid neural
networks. <em>NEUCOM</em>, <em>541</em>, 126230. (<a
href="https://doi.org/10.1016/j.neucom.2023.126230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Featuring with characteristics of convolutional neural network (CNN) and recurrent neural network (RNN), hybrid neural network (H-NN) has been widely applied within the field of remote sensing. In order to satisfy de mands of on-orbit processing that requires high throughput with restriction on power consumption, designing specific heterogeneous array processor therefore becomes one of the most effective ways fulfilling various tasks engaged in the above field. In this paper, a heterogeneous array architecture is proposed to support the hybrid neural network, based on the characteristics of various computation types in between different neural network module types and of dynamic computation burden among different layers. Firstly, a heterogeneous array structure consisting of different PE, PPE, RPE and LPE units is proposed, enabling strong flexibility and high throughput . Four types of operation units are used for operations of MAC, ReLU, pooling and nonlinear lookup-table. Secondly, a multi-level on-chip memory structure and access strategy supporting different access modes are proposed to reduce the bandwidth requirements of off-chip data access and to improve the computation efficiency. Thirdly, a management strategy of heterogeneous computing array is designed, which combines pipelining and parallel processing to support efficient mapping of different types of hybrid neural networks. The hybrid neural network processor based on 65 nm CMOS technique has a peak throughput of up to 1.96 TOPS. The implementation on models of AlexNet, LRCN, VGG19-LSTM and CLDNN can achieve the throughput of 1.92 TOPS, 1.89 TOPS, 1.93 TOPS and 1.84 TOPS, respectively. Compared with the similar neural network processor that is based on the same technology, the throughput of AlexNet model is increased by 76.4\%. The peak power consumption of a single processor core is 824mW, to which the power consumption restriction of on-orbit AI platform is satisfied.},
  archive      = {J_NEUCOM},
  author       = {Shiyu Wang and Shengbing Zhang and Xiaoping Huang and Libo Chang},
  doi          = {10.1016/j.neucom.2023.126230},
  journal      = {Neurocomputing},
  pages        = {126230},
  shortjournal = {Neurocomputing},
  title        = {A high-efficiency spaceborne processor for hybrid neural networks},
  volume       = {541},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level uncertainty aware learning for semi-supervised
dental panoramic caries segmentation. <em>NEUCOM</em>, <em>540</em>,
126208. (<a href="https://doi.org/10.1016/j.neucom.2023.03.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dental caries segmentation based on oral panoramic medical images is a demanding medical task. However, it is challenging to determine imaging diagnosis results as the actual pathological changes under certain conditions, especially in the suspected pathological locations that distinguish the artifacts from the lesions. This paper proposes introducing the semi-supervised learning framework to redistribute the collected cases to set up exact lesion areas and divide suspected areas with uncertainties into unlabeled data instead of reducing dataset labeling costs. Consistent regularization learning allows us to exploit the feature of ambiguous lesions to optimize decision boundaries. Unfortunately, the labels generated by the general SSL method for fuzzy regions are volatile, especially encountering no specific morphological rules and various scales that fluctuate more seriously, making a devastating impact on the regularization training relying on steady prediction. For such a challenge, we consider places that always form stable predictions under various disorders are often highly deterministic. Therefore, we propose introducing multi-level disturbances, including noise, iterative, and multi-scale disturbances. We simultaneously present in-depth supervision training on the multi-layer decoder to form stable and consistent multi-scale intermediate predictions, which significantly enrich the number of samples gathered in the following integration process. Then, Monte Carlo sampling is applied to integrate multi-level prediction results to assemble a more robust uncertainty mask map, which gradually clarifies the inter-class feature representation of actual lesions and artifacts. The extended experiment shows that we have successfully and effectively improved the performance of the caries segmentation task by using such uncertain lesion sample features. The dataset is now public, and the code is available at https://github.com/Zzz512/MLUA.},
  archive      = {J_NEUCOM},
  author       = {Xianyun Wang and Sizhe Gao and Kaisheng Jiang and Huicong Zhang and Linhong Wang and Feng Chen and Jun Yu and Fan Yang},
  doi          = {10.1016/j.neucom.2023.03.069},
  journal      = {Neurocomputing},
  pages        = {126208},
  shortjournal = {Neurocomputing},
  title        = {Multi-level uncertainty aware learning for semi-supervised dental panoramic caries segmentation},
  volume       = {540},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hunger games search algorithm with opposition-based
learning for solving multimodal medical image registration.
<em>NEUCOM</em>, <em>540</em>, 126204. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal medical image registration involves multiple pieces of medical equipment collecting complementary information on the same content, resulting in information fusion. Beyond its theoretical significance, it has practical applications in areas such as disease diagnosis, patient follow-up, surgical navigation, and radiology. Determining the optimal geometric-space transformation parameters is a major challenge in this field. To address this, we propose the opposition-based Hunger Games Search (OHGS) algorithm, an improved version of the Hunger Games Search (HGS) algorithm. The OHGS algorithm aims to find the optimal translation, scaling, and shearing parameters that result in the highest similarity value between the images being registered. By incorporating opposition-based learning (OBL) and dynamically adjusting mutation criteria, the OHGS algorithm has improved exploration capabilities and the ability to escape local optima. In this study, OHGS was compared with 9 other algorithms developed in recent years on 23 well-known benchmark functions and 10 single-objective optimization functions from IEEE CEC2020. Furthermore, to achieve better registration accuracy and optimal alignment of the geometric space in multimodal medical images, OHGS and 8 other algorithms were tested using RIRE and BraTS datasets, optimizing the two similarity measures of Normalized Mutual Information (NMI) and Structural Similarity Index Measure (SSIM). The results showed that OHGS significantly improved performance on benchmark functions and multimodal medical image registration problems, thereby expanding the application range of the HGS algorithm.},
  archive      = {J_NEUCOM},
  author       = {Xiaolei Luo and Bo Du and Peng Gui and Dengyi Zhang and Wei Hu},
  doi          = {10.1016/j.neucom.2023.03.065},
  journal      = {Neurocomputing},
  pages        = {126204},
  shortjournal = {Neurocomputing},
  title        = {A hunger games search algorithm with opposition-based learning for solving multimodal medical image registration},
  volume       = {540},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-scale graph embedding method via multiple corpora.
<em>NEUCOM</em>, <em>540</em>, 126192. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding aims at learning continuous vector representations for graphs which is crucial for graph analytics. Natural Language Process (NLP)-based graph embedding methods build corpus for graph data by treating substructures as words and then use NLP models to learn graph embeddings. However, the size difference and data redundancy among substructures are less explored in the built corpora. To mitigate this problem, we propose an unsupervised multi-scale graph embedding method. To be a specific, we first build multiple graph corpora for a graph dataset, where each corpus only contains substructures of specific granularity . Then, we extend a document embedding model to each graph corpus to obtain graph embeddings of different scales. At last, we obtain the final multi-scale embedding of a graph by pooling its multiple embeddings. Comprehensive experiments on real graph datasets indicate that the proposed method obtains competitive results with state-of-the-arts, and is superior to some classic graph kernels and graph embedding methods on six out of ten benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Zhigang Sun and Li-e Wang and Jinyong Sun},
  doi          = {10.1016/j.neucom.2023.03.053},
  journal      = {Neurocomputing},
  pages        = {126192},
  shortjournal = {Neurocomputing},
  title        = {A multi-scale graph embedding method via multiple corpora},
  volume       = {540},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Layer-wise regularized adversarial training using layers
sustainability analysis framework. <em>NEUCOM</em>, <em>540</em>,
126182. (<a href="https://doi.org/10.1016/j.neucom.2023.03.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network models are used today in various applications of artificial intelligence, the strengthening of which, in the face of adversarial attacks is of particular importance. An appropriate solution to adversarial attacks is adversarial training , which reaches a trade-off between robustness and generalization. This paper introduces a novel framework (Layer Sustainability Analysis (LSA)) for the analysis of layer vulnerability in an arbitrary neural network in the scenario of adversarial attacks. LSA can be a helpful toolkit to assess deep neural networks and to extend the adversarial training approaches towards improving the sustainability of model layers via layer monitoring and analysis. The LSA framework identifies a list of Most Vulnerable Layers (MVL list) of the given network. The relative error, as a comparison measure, is used to evaluate representation sustainability of each layer against adversarial inputs. The proposed approach for obtaining robust neural networks to fend off adversarial attacks is based on a layer-wise regularization (LR) over LSA proposal(s) for adversarial training (AT). This means that the AT-LR procedure could be used with any benchmark adversarial attack to reduce the vulnerability of network layers and to improve conventional adversarial training approaches. The proposed idea performs well theoretically and experimentally for state-of-the-art multilayer perceptron and convolutional neural network architectures. Additionally, a measure named robustness and generalization score or R&amp;G score is defined to better evaluate each adversarially trained model over a variety of significant perturbations. Compared with the AT-LR and its corresponding base adversarial training, the R&amp;G score on Moon, MNIST, and CIFAR-10 benchmark datasets was increased by 56.52\%, 75.82\%, and 6.54\%, respectively for more significant perturbations. The LSA framework is available and published at https://github.com/khalooei/LSA .},
  archive      = {J_NEUCOM},
  author       = {Mohammad Khalooei and Mohammad Mehdi Homayounpour and Maryam Amirmazlaghani},
  doi          = {10.1016/j.neucom.2023.03.043},
  journal      = {Neurocomputing},
  pages        = {126182},
  shortjournal = {Neurocomputing},
  title        = {Layer-wise regularized adversarial training using layers sustainability analysis framework},
  volume       = {540},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonfragile extended dissipativity state estimator design for
discrete-time neural networks with time-varying delay. <em>NEUCOM</em>,
<em>539</em>, 126206. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the issue of nonfragile extended dissipativity state estimator design for discrete-time neural networks with time-varying delay. Firstly, a class of nonfragile proportional-integral state estimator with exponential type linear polynomial on time-varying delay is presented, which unifies the Arcak state estimator and the Luenberger state estimator as its special cases. Since the exponential type linear polynomial on time-varying delay is considered, more information of time delay can be utilized and the estimation error convergence rate can be adjusted. Secondly, an augmented Lyapunov–Krasovskii functional tailored for delayed discrete-time neural networks is presented, in which the double summation terms of the state vector and the information of the output estimation error are fully considered in the corresponding augmented vector, then a sufficient criterion that guarantees the nonfragile extended dissipativity state estimation for delayed discrete-time neural networks is derived. Furthermore, since an extended dissipativity performance level is introduced, the issues of passitivity state estimation, H ∞ H∞ state estimation, L 2 - L ∞ L2-L∞ state estimation, and ( Q , S , R ) (Q,S,R) - γ γ dissipativity state estimation can be solved in a unified framework. Finally, simulation results are given to demonstrate the advantage of the presented method.},
  archive      = {J_NEUCOM},
  author       = {Guoqiang Tan and Zhanshan Wang and Shasha Xiao},
  doi          = {10.1016/j.neucom.2023.03.067},
  journal      = {Neurocomputing},
  pages        = {126206},
  shortjournal = {Neurocomputing},
  title        = {Nonfragile extended dissipativity state estimator design for discrete-time neural networks with time-varying delay},
  volume       = {539},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LabanFormer: Multi-scale graph attention network and
transformer with gated recurrent positional encoding for labanotation
generation. <em>NEUCOM</em>, <em>539</em>, 126203. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Labanotation is a widely-used notation system for recording human dance movements. Automatically generating Labanotation scores from motion capture data can save significant manual effort and help the preservation of old folk dances in protecting intangible cultural heritages. Existing Labanotation generation methods have limited ability to capture the flexible limb movements as well as the rich periodic, symmetric, or repeated dance steps. In this paper, we present a novel LabanFormer model including a Multi-Scale Graph Attention network (MS-GAT) and a transformer model with Gated Recurrent Positional Encoding (GRPE) to achieve more effective Labanotation generation. First, the proposed MS-GAT can capture flexible limb movements by learning feature correlations between every two joints and aggregating features of neighboring joints over multiple scales. Second, we propose a new GRPE-based transformer to learn global temporal dependencies in the output feature sequences of MS-GAT. The novel GRPE module can encode position information with learnable parameters while handling various sequence lengths. As such, the periodic, symmetric, or repeated steps in dances can be accurately captured. Finally, the corresponding Laban symbols are generated by the decoder of the GRPE-based transformer. Extensive experiments on two real-world datasets show that the proposed LabanFormer model obtains remarkable performance compared with state-of-the-art approaches on the automatic Labanotation generation task.},
  archive      = {J_NEUCOM},
  author       = {Min Li and Zhenjiang Miao and Yuanyao Lu},
  doi          = {10.1016/j.neucom.2023.03.064},
  journal      = {Neurocomputing},
  pages        = {126203},
  shortjournal = {Neurocomputing},
  title        = {LabanFormer: Multi-scale graph attention network and transformer with gated recurrent positional encoding for labanotation generation},
  volume       = {539},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anchor-based knowledge embedding for image aesthetics
assessment. <em>NEUCOM</em>, <em>539</em>, 126197. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have shown their advantage in image aesthetics assessment (IAA). However, the current deep IAA models largely work in a data-driven manner, but the ambiguity of aesthetics poses huge challenge. When judging image aesthetics, people usually take advantage of commonsense knowledge . Further, people are good at making relative comparison instead of absolute scoring. Motivated by the above facts, this paper presents a new ANchor-based Knowledge Embedding (ANKE) approach for generic image aesthetics assessment, which makes predictions based on a universal aesthetic knowledge base. First, the knowledge base is built by extracting aesthetic features from anchor images with diversified visual contents and aesthetic levels, which can provide rich reference information for aesthetics assessment. Then, given an image, the model is trained to dynamically pick up the most informative anchors from the knowledge base and adaptively weight the difference features to produce the final aesthetic prediction. Experimental results demonstrate that, with a universally built aesthetic knowledge base, the proposed ANKE model achieves the state-of-the-art performance on three public IAA databases.},
  archive      = {J_NEUCOM},
  author       = {Leida Li and Tianwu Zhi and Guangming Shi and Yuzhe Yang and Liwu Xu and Yaqian Li and Yandong Guo},
  doi          = {10.1016/j.neucom.2023.03.058},
  journal      = {Neurocomputing},
  pages        = {126197},
  shortjournal = {Neurocomputing},
  title        = {Anchor-based knowledge embedding for image aesthetics assessment},
  volume       = {539},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revealing concealed spontaneous facial micro-expression: Are
we a step closer to unveil real-life behavioral expressions?
<em>NEUCOM</em>, <em>539</em>, 126194. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial micro-expression (ME) expression analysis has aroused interdisciplinary attention from the realms of computer vision and psychology due to its advantages of divulging nonverbal emotion via subtle involuntary facial muscle changes. However, developing and commercializing ME recognition relevant products has been hindered in current progress due to the scarcity of databases depicting real-world conditions. This paper aims to give a strong impetus to facilitating the advancement of ME recognition systems, particularly in in-the-wild applications. Succinctly, an efficient recognition system is introduced herein, which incorporates the core processes like 3D facial reconstruction, apex spotting, and emotion recognition tasks. Concretely, all faces are first rendered into 3D point cloud form for the brevity of face alignment along the video. Then, the optical flow-guided components are employed as the primary features to represent the motion details. Subsequently, a 3-Stream channel based on 3-Dimensional faces Network (3T3D-Net) with skip connection via multiplication is tailored to cope with the small-size input image. As a result, pleasing recognition performance is yielded via the suite of novel techniques devised, by producing a UAR of 69.44\% and UF1 of 70.71\%, when evaluated on the in-the-wild ME dataset, viz, MEVIEW. In addition, extensive studies and analyses are presented to verify the contribution of each component of the proposed pipeline. It is envisioned that the remarkable result attained by casting an invigorating perspective will shed light and pave a new prospect for analysis in ME applications.},
  archive      = {J_NEUCOM},
  author       = {Y.S. Gan and Gen-Bing Liong and Kun-Hong Liu and Sze-Teng Liong},
  doi          = {10.1016/j.neucom.2023.03.055},
  journal      = {Neurocomputing},
  pages        = {126194},
  shortjournal = {Neurocomputing},
  title        = {Revealing concealed spontaneous facial micro-expression: Are we a step closer to unveil real-life behavioral expressions?},
  volume       = {539},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered optimal decentralized control for stochastic
interconnected nonlinear systems via adaptive dynamic programming.
<em>NEUCOM</em>, <em>539</em>, 126163. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an event-triggered adaptive dynamic programming (ETADP) algorithm to study the optimal decentralized control issue of interconnected nonlinear systems subject to stochastic dynamics. By developing a performance index function for augmented auxiliary subsystem, the primordial control issue is converted into deriving an array of optimal control policies sampling in an aperiodic pattern. Then, an ETADP algorithm is introduced under an identifier-actor-critic network framework, where the identifier aims to determine the stochastic dynamic, the critic aims to assess the system performance and the actor aims to implement the control action. A remarkable feature is that the actor-critic updating laws are constructed through the negative gradient method of a positive function, which is designed in the light of the partial derivative of a Hamilton–Jacobi-Bellman equation. Under the provided weight tuning rule, the traditional ADP algorithm can be significantly simplified. The stability of the close-loop system is verified through direct Lyapunov theory , and a numerical simulation is given to confirm the effectiveness of the optimal control scheme.},
  archive      = {J_NEUCOM},
  author       = {Yanwei Zhao and Ben Niu and Guangdeng Zong and Ning Xu and Adil M. Ahmad},
  doi          = {10.1016/j.neucom.2023.03.024},
  journal      = {Neurocomputing},
  pages        = {126163},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered optimal decentralized control for stochastic interconnected nonlinear systems via adaptive dynamic programming},
  volume       = {539},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model validation using mutated training labels: An
exploratory study. <em>NEUCOM</em>, <em>539</em>, 126116. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce an exploratory study on Mutation Validation (MV), a model validation method using mutated training labels for supervised learning. MV mutates training data labels, retrains the model against the mutated data, and then uses the metamorphic relation that captures the consequent training performance changes to assess model fit. It does not use a validation set or test set. The intuition underpinning MV is that overfitting models tend to fit noise in the training data. MV does not aim to replace out-of-sample validation. Instead, we provide the first exploratory study on the possibility of using MV as a complement of out-of-sample validation. We explore 8 different learning algorithms, 18 datasets, and 5 types of hyperparameter tuning tasks. Our results demonstrate that MV complements well cross-validation and test accuracy in model selection and hyperparameter tuning tasks. MV deserves more attention from developers when simplicity, sustainaiblity, security (e.g., defending training data attack), and interpretability of the built models are required.},
  archive      = {J_NEUCOM},
  author       = {Jie M. Zhang and Mark Harman and Benjamin Guedj and Earl T. Barr and John Shawe-Taylor},
  doi          = {10.1016/j.neucom.2023.02.042},
  journal      = {Neurocomputing},
  pages        = {126116},
  shortjournal = {Neurocomputing},
  title        = {Model validation using mutated training labels: An exploratory study},
  volume       = {539},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive gaussian process based manifold transfer
learning to expensive dynamic multi-objective optimization.
<em>NEUCOM</em>, <em>538</em>, 126212. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expensive dynamic multi-objective optimization problems (EDMOPs) is one kind of DMOPs where the objectives change over time and the function evaluations commonly involve computationally intensive simulations or costly physical experiments. Hence, the key to solve EDMOPs is to quickly and accurately track the time-varying Pareto optimal fronts under the limit of small number of function evaluations, in which how to augment enough training data to build informative surrogate models and manage the models during the search process. To overcome the issue, we propose a transfer learning based surrogate assisted evolutionary algorithm (TrSA-DMOEA) to efficiently solve EDMOPs. Specifically, when a change occurs, we propose a knee point-based manifold transfer learning method based on geodesic flow kernel, which exploits the knowledge from previous high-quality knee solutions to augment the training data for building Gaussian process models , thereby improving the computational complexity and the quality of solutions. Moreover, to efficiently find the optima with limited budget of function evaluations, a novel surrogate-assisted mechanism based on an adaptive acquisition function is introduced, which achieves a balance between convergence and diversity by adaptively adjusting the weights of the angle-penalized distance and average uncertainty at different search stages. By comparing with state-of-the-art algorithms on widely used test problems, the experimental results demonstrate that the proposed method outperforms others and is able to efficiently solve EDMOPs.},
  archive      = {J_NEUCOM},
  author       = {Xi Zhang and Guo Yu and Yaochu Jin and Feng Qian},
  doi          = {10.1016/j.neucom.2023.03.073},
  journal      = {Neurocomputing},
  pages        = {126212},
  shortjournal = {Neurocomputing},
  title        = {An adaptive gaussian process based manifold transfer learning to expensive dynamic multi-objective optimization},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CyTran: A cycle-consistent transformer with multi-level
consistency for non-contrast to contrast CT translation.
<em>NEUCOM</em>, <em>538</em>, 126211. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel approach to translate unpaired contrast computed tomography (CT) scans to non-contrast CT scans and the other way around. Solving this task has two important applications: (i) to automatically generate contrast CT scans for patients for whom injecting contrast substance is not an option, and (ii) to enhance the alignment between contrast and non-contrast CT by reducing the differences induced by the contrast substance before registration. Our approach is based on cy cle-consistent generative adversarial convolutional tran sformers, for short, CyTran . Our neural model can be trained on unpaired images, due to the integration of a multi-level cycle-consistency loss. Aside from the standard cycle-consistency loss applied at the image level, we propose to apply additional cycle-consistency losses between intermediate feature representations, which enforces the model to be cycle-consistent at multiple representations levels, leading to superior results. To deal with high-resolution images, we design a hybrid architecture based on convolutional and multi-head attention layers. In addition, we introduce a novel data set, Coltea-Lung-CT-100W , containing 100 3D triphasic lung CT scans (with a total of 37,290 images) collected from 100 female patients (there is one examination per patient). Each scan contains three phases (non-contrast, early portal venous, and late arterial), allowing us to perform experiments to compare our novel approach with state-of-the-art methods for image style transfer. Our empirical results show that CyTran outperforms all competing methods. Moreover, we show that CyTran can be employed as a preliminary step to improve a state-of-the-art medical image alignment method. We release our novel model and data set as open source at: https://github.com/ristea/cycle-transformer . Our qualitative and subjective human evaluations reveal that CyTran is the only approach that does not introduce visual artifacts during the translation process. We believe this is a key advantage in our application domain, where medical images need to precisely represent the scanned body parts.},
  archive      = {J_NEUCOM},
  author       = {Nicolae-Cătălin Ristea and Andreea-Iuliana Miron and Olivian Savencu and Mariana-Iuliana Georgescu and Nicolae Verga and Fahad Shahbaz Khan and Radu Tudor Ionescu},
  doi          = {10.1016/j.neucom.2023.03.072},
  journal      = {Neurocomputing},
  pages        = {126211},
  shortjournal = {Neurocomputing},
  title        = {CyTran: A cycle-consistent transformer with multi-level consistency for non-contrast to contrast CT translation},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UNCER: A framework for uncertainty estimation and reduction
in neural decoding of EEG signals. <em>NEUCOM</em>, <em>538</em>,
126210. (<a href="https://doi.org/10.1016/j.neucom.2023.03.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG decoding systems based on deep neural networks have been widely used in the decision-making of brain-computer interfaces (BCI). Their predictions, however, can be unreliable given the significant variance and noise in EEG signals. Previous works on EEG analysis mainly focus on the exploration of noise patterns in the source signal, while the uncertainty during the decoding process is largely unexplored. Automatically detecting and reducing such decoding uncertainty is important for BCI motor imagery applications such as robotic arm control etc. In this work, we proposed an uncertainty estimation and reduction model (UNCER) to quantify and mitigate the uncertainty during the EEG decoding process. It utilized a combination of dropout oriented method and Bayesian neural network for uncertainty estimation to incorporate both the uncertainty in the input signal and the uncertainty in the model parameters. We further proposed an adaptive data augmentation-based approach for uncertainty reduction. The model can be integrated into the current widely used EEG neural decoders without change of the architecture. We performed extensive experiments for uncertainty estimation and its reduction in both intra-subject EEG decoding and cross-subject EEG decoding on two public motor imagery datasets, where the proposed model achieves significant improvement both in the quality of estimated uncertainty and the effectiveness of uncertainty reduction.},
  archive      = {J_NEUCOM},
  author       = {Tiehang Duan and Zhenyi Wang and Sheng Liu and Yiyi Yin and Sargur N. Srihari},
  doi          = {10.1016/j.neucom.2023.03.071},
  journal      = {Neurocomputing},
  pages        = {126210},
  shortjournal = {Neurocomputing},
  title        = {UNCER: A framework for uncertainty estimation and reduction in neural decoding of EEG signals},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Prototype-guided instance matching for multiple pedestrian
tracking. <em>NEUCOM</em>, <em>538</em>, 126207. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple pedestrian tracking is a critical yet challenging to understand human behavior . Although existing tracking methods have achieved great advances through adopting the tracking-by-detection paradigm, they give insufficient consideration on how to improve the instance matching capability in the cluttered and crowded environment. Motivated by our observations on tracking persons that the similarity of the same target is larger than that of other persons along sequence frames, in this work, we propose a novel Prototype-guided Instance Matching (PIM) method to boost the performance of multiple pedestrian tracking task. The whole PIM framework mainly consists of a detector net, an appearance embedding module, and a self-adaptive prototype dictionary. Given the current frame as the input sample, we first adopt a classic detector to select a set of positive candidates, and their corresponding multi-scale convolutional features are then fed into the appearance embedding module for obtaining the robust instance-wise feature representation. We perform the prototype-guided instance matching optimization between the learned instance-wise feature embeddings and the prototype dictionary, where its aim is to enlarge the separability of different instances and make the distance between the same instances more compact. Here object detection and appearance embedding are jointly optimized in an end-to-end fashion. Furthermore, we maintain a self-adaptive prototype dictionary to store instance-wise prototypes, which can be adaptively updated to adapt the appearance variations of all tracked targets over time. The instance matching and prototype dictionary update are modeled into an interactive optimization process so that they can be gradually improved for each other. Comprehensive evaluations on three benchmark datasets (i.e., MOT16, MOT17, and MOT20) demonstrate the effectiveness of our proposed PIM when compared with the state-of-the-art methods for the multiple pedestrian tracking task.},
  archive      = {J_NEUCOM},
  author       = {Qiang Wang and Wenkang Zhang and Wankou Yang and Chunyan Xu and Zhen Cui},
  doi          = {10.1016/j.neucom.2023.03.068},
  journal      = {Neurocomputing},
  pages        = {126207},
  shortjournal = {Neurocomputing},
  title        = {Prototype-guided instance matching for multiple pedestrian tracking},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Texture based prototypical network for few-shot semantic
segmentation of forest cover: Generalizing for different geographical
regions. <em>NEUCOM</em>, <em>538</em>, 126201. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forest plays a vital role in reducing greenhouse gas emissions and mitigating climate change, besides maintaining the world’s biodiversity. The existing satellite-based forest monitoring system utilizes supervised learning approaches limited to a particular region and depends on manually annotated data to identify forest. This work envisages forest identification as a few-shot semantic segmentation task to achieve generalization across different geographical regions. The proposed few-shot segmentation approach incorporates a texture attention module in the prototypical network to highlight the texture features of the forest. Indeed, the forest exhibits a characteristic texture different from other classes, such as road, water, etc. In this work, the proposed approach is trained for identifying tropical forests of South Asia and adapted to determine the temperate forest of Central Europe with the help of a few (one image for 1-shot) manually annotated support images of the temperate forest. An IoU of 0.62 for forest class (1-way 1-shot) was obtained using the proposed method, which is significantly higher (0.46 for PANet) than the existing few-shot semantic segmentation approach. Besides, the experimental results demonstrate that the inclusion of the texture attention module in the existing prototypical few-shot segmentation methods (PFENet and ASGNet) results in a more accurate forest identification. These results indicate that the proposed approach can generalize across geographical regions for forest identification, creating an opportunity to develop a global forest cover identification tool.},
  archive      = {J_NEUCOM},
  author       = {Gokul Puthumanaillam and Ujjwal Verma},
  doi          = {10.1016/j.neucom.2023.03.062},
  journal      = {Neurocomputing},
  pages        = {126201},
  shortjournal = {Neurocomputing},
  title        = {Texture based prototypical network for few-shot semantic segmentation of forest cover: Generalizing for different geographical regions},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Let’s do it right the first time: Survey on security
concerns in the way to quantum software engineering. <em>NEUCOM</em>,
<em>538</em>, 126199. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing is no longer a promise of the future but a rapidly evolving reality. Advances in quantum hardware are making it possible to make tangible a computational reality that until now was only theoretical. The proof of this is that development languages and platforms are appearing that bring physical principles closer to developers, making it feasible to begin to propose, in different areas of society, solutions to problems that until now were unsolvable. However, security vulnerabilities are also emerging that could hinder the progress of quantum computing, as well as its transition and development in industry. For this reason, this article proposes a review of some of the first artefacts that are emerging in the field of quantum computing. From this analysis, we begin to identify possible security issues that could become potential vulnerabilities in the quantum software of tomorrow. Likewise, and following the experience in classical software development, the testing technique is analysed as a possible candidate for improving security in quantum software development. Following the principles of Quantum Software Engineering, we are aware of the lack of tools, techniques and knowledge necessary to guarantee the development of quantum software in the immediate future. Therefore, this article aims to offer some first clues on what would be a roadmap to guarantee secure quantum software development.},
  archive      = {J_NEUCOM},
  author       = {Danel Arias and Ignacio García Rodríguez de Guzmán and Moisés Rodríguez and Erik B. Terres and Borja Sanz and José Gaviria de la Puerta and Iker Pastor and Agustín Zubillaga and Pablo García Bringas},
  doi          = {10.1016/j.neucom.2023.03.060},
  journal      = {Neurocomputing},
  pages        = {126199},
  shortjournal = {Neurocomputing},
  title        = {Let’s do it right the first time: Survey on security concerns in the way to quantum software engineering},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient text-image semantic search: A multi-modal
vision-language approach for fashion retrieval. <em>NEUCOM</em>,
<em>538</em>, 126196. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of multi-modal retrieval of fashion products. State-of-the-art (SOTA) works proposed in literature use vision-and-language transformers to assign similarity scores to joint text-image pairs, then used for sorting the results during a retrieval phase. However, this approach is inefficient since it requires coupling a query with every record in the dataset and computing a forward pass for each sample at runtime, precluding scalability to large-scale datasets. We thus propose a solution that overcomes the above limitation by combining transformers and deep metric learning to create a latent space where texts and images are separately embedded, and their spatial proximity translates into semantic similarity. Our architecture does not use convolutional neural networks to process images, allowing us to test different levels of image-processing details and metric learning losses. We vastly improve retrieval accuracy results on the FashionGen benchmark (+18.71\% and +9.22\% Rank@1 on Image-to-Text and Text-to-Image, respectively) while being up to 512x faster. Finally, we analyze the speed-up obtainable by different approximate nearest neighbor retrieval strategies—an optimization precluded to current SOTA contributions. We release our solution as a web application available at https://disi-unibo-nlp.github.io/projects/fashion_retrieval/.},
  archive      = {J_NEUCOM},
  author       = {Gianluca Moro and Stefano Salvatori and Giacomo Frisoni},
  doi          = {10.1016/j.neucom.2023.03.057},
  journal      = {Neurocomputing},
  pages        = {126196},
  shortjournal = {Neurocomputing},
  title        = {Efficient text-image semantic search: A multi-modal vision-language approach for fashion retrieval},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CAGCN: Causal attention graph convolutional network against
adversarial attacks. <em>NEUCOM</em>, <em>538</em>, 126187. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Have you ever been exposed to advertising accounts on social networks or distributed denial-of-service (DDoS) attacks? These attacks occur as intrusions in a network. Recently, several studies have demonstrated the vulnerability of graph convolutional networks (GCNs). In other words, given an abnormal graph with perturbations from a normal graph, the performance of GCNs drops significantly. To solve this problem, we propose a causal attention graph convolutional network (CAGCN). We design a causal graph where given data are affected by an attack and utilize the causal mechanism on GCNs to cut off the bias. Specifically, we use two types of attention, node attention (NoA) and neighbor attention (NeA), and demonstrate the robustness of our model, which does not significantly degrade the performance of the model as the attack becomes stronger. In addition, to show that the causal mechanism works well for robust learning, we apply the causal mechanism to the previous study and compared it.},
  archive      = {J_NEUCOM},
  author       = {Yeji Lee and Sung Won Han},
  doi          = {10.1016/j.neucom.2023.03.048},
  journal      = {Neurocomputing},
  pages        = {126187},
  shortjournal = {Neurocomputing},
  title        = {CAGCN: Causal attention graph convolutional network against adversarial attacks},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep feature screening: Feature selection for ultra
high-dimensional data via deep neural networks. <em>NEUCOM</em>,
<em>538</em>, 126186. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The applications of traditional statistical feature selection methods to high-dimension, low-sample-size data often struggle and encounter challenging problems, such as overfitting, curse of dimensionality, computational infeasibility, and strong model assumptions. In this paper, we propose a novel two-step nonparametric approach called Deep Feature Screening (DeepFS) that can overcome these problems and identify significant features with high precision for ultra high-dimensional, low-sample-size data. This approach first extracts a low-dimensional representation of input data and then applies feature screening on the original input feature space based on multivariate rank distance correlation recently developed by Deb and Sen (2021). This approach combines the strengths of both deep neural networks and feature screening, thereby having the following appealing features in addition to its ability of handling ultra high-dimensional data with small number of samples: (1) it is model free and distribution free; (2) it can be used for both supervised and unsupervised feature selection; and (3) it is capable of recovering the original input data. The superiority of DeepFS is demonstrated via extensive simulation studies and real data analyses .},
  archive      = {J_NEUCOM},
  author       = {Kexuan Li and Fangfang Wang and Lingli Yang and Ruiqi Liu},
  doi          = {10.1016/j.neucom.2023.03.047},
  journal      = {Neurocomputing},
  pages        = {126186},
  shortjournal = {Neurocomputing},
  title        = {Deep feature screening: Feature selection for ultra high-dimensional data via deep neural networks},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PKRT-net: Prior knowledge-based relation transformer network
for optic cup and disc segmentation. <em>NEUCOM</em>, <em>538</em>,
126183. (<a href="https://doi.org/10.1016/j.neucom.2023.03.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma causes irreversible vision loss, and early detection of glaucoma is essential to protect the vision of patients. The optic cup (OC) and optic disc (OD) are two critical anatomical structures for glaucoma diagnosis. Methods based on convolutional neural networks (CNNs) have been proposed to extract OC and OD, in which OC extraction is very challenging. However, the clinical prior knowledge is not fully utilized in existing CNN methods, which limits the performance of extracting OC and OD. Besides, CNN methods cannot learn long-range semantic information interaction well due to the intrinsic locality of convolution operations . In this paper, we propose a P rior K nowledge-based R elation T ransformer N etwork (PKRT-Net), which employs the clinical prior knowledge to assist OC segmentation and model efficient long-range relation of spatial features by the transformer. PKRT-Net consists of a dual-branch module, a relation transformer fusion module, and a decoder with weighted fusion. Dual-branch module decouples the fundus image into the vessel feature space and general local feature space; the relation transformer fusion module fuses the clinical prior information with local features to obtain more representative features; the weighted fusion module fuses the multi-scale side-outputs from the decoder with the representation of relation transformer module to improve the segmentation performance . We evaluate our proposed PKRT-Net on three public available OC and OD segmentation datasets ( i.e. , Drishti-GS, RIM-ONE(r3), and REFUGE). The experimental results demonstrate that our proposed PKRT-Net framework achieves state-of-the-art OC and OD segmentation results on these three public datasets.},
  archive      = {J_NEUCOM},
  author       = {Shuai Lu and He Zhao and Hanruo Liu and Huiqi Li and Ningli Wang},
  doi          = {10.1016/j.neucom.2023.03.044},
  journal      = {Neurocomputing},
  pages        = {126183},
  shortjournal = {Neurocomputing},
  title        = {PKRT-net: Prior knowledge-based relation transformer network for optic cup and disc segmentation},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A selection-pattern-aware recommendation model with
colored-motif attention network. <em>NEUCOM</em>, <em>538</em>, 126178.
(<a href="https://doi.org/10.1016/j.neucom.2023.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information networks (HIN) based models are now widely used to fuse auxiliary information for personalized recommendation. However, existing works mainly focus on capturing high-order connections between heterogeneous nodes through predefined pattern (such as meta-path, etc.), which depends on relevant domain knowledge and ignores the statistical characteristics of the substructures in HIN. How to capture meaningful personalized behavior patterns, especially the selection patterns (i.e. how a user select an item), and incorporate them into the preference model is still a challenge in the research of HIN-based recommendation. Therefore, in this paper, a specifically-designed Colored-Motif Attention Network (CMoAN) is proposed to deal with this problem. In the proposed CMoAN, colored motif are used as the elemental building blocks to represent context-based selection patterns, and then by constructing a motif-based adjacency matrix to capture higher-order semantic association between nodes in HIN. Besides, an attentive graph neural network is designed to efficiently model the semantics and high-order relations information. Extensive experiments on three real-world datasets demonstrate that CMoAN consistently outperforms state-of-the-art methods. Furthermore, experimental results also verify the effectiveness of using colored motif for capturing users’selection patterns.},
  archive      = {J_NEUCOM},
  author       = {Zhifeng Hao and Junbin Chen and Wen Wen and Biao Wu and Ruichu Cai},
  doi          = {10.1016/j.neucom.2023.03.039},
  journal      = {Neurocomputing},
  pages        = {126178},
  shortjournal = {Neurocomputing},
  title        = {A selection-pattern-aware recommendation model with colored-motif attention network},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural-adaptive specified-time constrained consensus
tracking control of high-order nonlinear multi-agent systems with
unknown control directions and actuator faults. <em>NEUCOM</em>,
<em>538</em>, 126168. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a specified-time neural-adaptive control algorithm is developed to solve the consensus tracking control problem of high-order nonlinear multi-agent systems with full-state constraints, unknown control directions, and actuator faults , which is intrinsically challenging due to the existence of high-order (positive odd integers greater than one) terms. More precisely, a novel specified-time performance function (STPF) is skillfully incorporated into the time-varying high-order log-type barrier Lyapunov function (BLF) to guarantee that the tracking errors remain under time-varying constraints within specified time. To handle the mixed unknown control directions, the hybrid Nussbaum function is innovatively employed in the distributed high-order nonlinear multi-agent scenario. By combining radial basis function neural networks (RBFNNs) with the adding-one-power-integrator technique, an adaptive approximation policy is introduced to derive the neural adaptive controllers. Moreover, actuator faults are also considered in this work. The variable-separable lemma is exploited to extract the fault signals in a “linear-like” manner. Comparative simulations are provided to demonstrate the effectiveness of the designed control framework.},
  archive      = {J_NEUCOM},
  author       = {Chuhan Zhou and Ying Wang and Maolong Lv and Ning Wang},
  doi          = {10.1016/j.neucom.2023.03.029},
  journal      = {Neurocomputing},
  pages        = {126168},
  shortjournal = {Neurocomputing},
  title        = {Neural-adaptive specified-time constrained consensus tracking control of high-order nonlinear multi-agent systems with unknown control directions and actuator faults},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balanced image captioning with task-aware decoupled learning
and fusion. <em>NEUCOM</em>, <em>538</em>, 126159. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning aims to generate natural language descriptions for images. Word occurrences usually obey Zipf’s Law, the imbalance phenomenon makes the conventional training bias to majority data. However, this imbalance distribution has not been considered adequately in captioning works. In this paper, we match the imbalance learning methods in classification with image captioning, making the empirical study. We also propose a Task-aware Decoupled Learning and Fusion (TDLF) approach, which outperforms the former. Image captioning differs from classification in three main aspects: 1) captions are sequential labels that exist co-occurrence, 2) the generation methods usually follow the autoregressive manner, 3) the imbalance ratio is extremely large. To deal with these problems, our TDLF method introduces multi-task learning into the re-balancing approach. The model is composed of a shared autoregressor and two task classifiers, i.e. , a conventional training classifier, and a balance-training classifier. The model is further equipped with a task-aware decoupling strategy, we propose the Task Perception Indication (TPI) to measure whether the conventional training is shifted. The balance-training classifier is trained by the biased data separately and the generations of two tasks are fused according to the TPI. Experiments on the MSCOCO database show that our model outperforms the state-of-the-art methods on generation accuracy and word diversity, demonstrating the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yuxuan Ding and Lingqiao Liu and Chunna Tian and Xiangnan Zhang and Xilan Tian},
  doi          = {10.1016/j.neucom.2023.03.020},
  journal      = {Neurocomputing},
  pages        = {126159},
  shortjournal = {Neurocomputing},
  title        = {Balanced image captioning with task-aware decoupled learning and fusion},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MIFNet: Multiple instances focused temporal action proposal
generation. <em>NEUCOM</em>, <em>538</em>, 126025. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal action proposal generation (TAPG) serves as a promising solution for video analysis. However, the performance of existing methods is still far from satisfactory for real-world applications. We attribute it to a crucial issue, i.e., hard multiple instances. In this paper, we investigate why this is the case. We discover that when processing multiple instances videos, mainstream approaches always recognize multiple instances as one instance due to boundary ambiguity or ignoring insignificant backgrounds between these instances. To address this problem, we propose a M ultiple I nstances F ocused Net work (MIFNet) that improves the quality of action proposals by considering boundary correlations and fusing multi-scale proposals. In particular, we first propose a pure boundary embedding module named Boundary Constraint Module (BCM) for suppressing the generation of hard negatives proposal by evaluating boundary correlation. The BCM introduces a boundary contrastive learning strategy that can pull the positive boundary pairs’ representation closer and push the negative pairs’ representation away. Then, a Proposal Blending Module (PBM) is proposed, which augments the proposal-level representation by modeling information among multi-scale proposals so that proposals can be complemented with local details as well as global information. The experimental results on the ActivityNet-v1.3 and THUMOS14 benchmarks demonstrate that MIFNet outperforms the state-of-the-arts.},
  archive      = {J_NEUCOM},
  author       = {Lining Wang and Hongxun Yao and Haosen Yang and Sibo Wang and Sheng jin},
  doi          = {10.1016/j.neucom.2023.01.045},
  journal      = {Neurocomputing},
  pages        = {126025},
  shortjournal = {Neurocomputing},
  title        = {MIFNet: Multiple instances focused temporal action proposal generation},
  volume       = {538},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A step-by-step training method for multi generator GANs with
application to anomaly detection and cybersecurity. <em>NEUCOM</em>,
<em>537</em>, 296–308. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber attacks and anomaly detection are problems where the data is often highly unbalanced towards normal observations. Furthermore, the anomalies observed in real applications may be significantly different from the ones contained in the training data. It is, therefore, desirable to study methods that are able to detect anomalies only based on the distribution of the normal data. To address this problem, we propose a novel objective function for generative adversarial networks (GANs), referred to as STEP-GAN. STEP-GAN simulates the distribution of possible anomalies by learning a modified version of the distribution of the task-specific normal data. It leverages multiple generators in a step-by-step interaction with a discriminator in order to capture different modes in the data distribution. The discriminator is optimized to distinguish not only between normal data and anomalies but also between the different generators, thus encouraging each generator to model a different mode in the distribution. This reduces the well-known mode collapse problem in GAN models considerably. We tested our method in the areas of power systems and network traffic control systems (NTCSs) using two publicly available highly imbalanced datasets, ICS (Industrial Control System) security dataset and UNSW-NB15, respectively. In both application domains, STEP-GAN outperforms the state-of-the-art systems as well as the two baseline systems we implemented as a comparison. In order to assess the generality of our model, additional experiments were carried out on seven real-world numerical datasets for anomaly detection in a variety of domains. In all datasets, the number of normal samples is significantly more than that of abnormal samples. Experimental results show that STEP-GAN outperforms several semi-supervised methods while being competitive with supervised methods.},
  archive      = {J_NEUCOM},
  author       = {Mohammad Adiban and Sabato Marco Siniscalchi and Giampiero Salvi},
  doi          = {10.1016/j.neucom.2023.03.056},
  journal      = {Neurocomputing},
  pages        = {296-308},
  shortjournal = {Neurocomputing},
  title        = {A step-by-step training method for multi generator GANs with application to anomaly detection and cybersecurity},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LLP-AAE: Learning from label proportions with adversarial
autoencoder. <em>NEUCOM</em>, <em>537</em>, 282–295. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an effective weakly supervised learning algorithm LLP-AAE to leverage the adversarial autoencoder (AAE) for learning from label proportions (LLP), in which only the bag-level proportional information is available. Our LLP-AAE utilizes an autoencoder backbone and performs adversarial training in latent space to match the aggregated posterior distribution of hidden coding with the prior distributions. In this way, apart from the reconstruction task, the encoder is also dedicated to producing fake samples, in order to deceive discriminators as far as possible. Ultimately, the encoder is employed as a competent label predictor for unseen data. In addition to the LLP classifier, our model can also achieve controllable samples generation by feeding the decoder with gradually changing latent code, which is proven to be useful for a better LLP performance. We also provide a panoramic explanation for LLP-AAE by regarding the LLP problem as an alternative learning procedure between proportion-based pseudo label generation and discriminative reconstruction. Experiments on six benchmark image datasets demonstrate the advantage of our method both in style manipulation with the latent feature representation and comparable multi-class LLP performance with the state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Bo Wang and Yingte Sun and Qiang Tong},
  doi          = {10.1016/j.neucom.2023.03.019},
  journal      = {Neurocomputing},
  pages        = {282-295},
  shortjournal = {Neurocomputing},
  title        = {LLP-AAE: Learning from label proportions with adversarial autoencoder},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive regularized warped gradient descent enhances model
generalization and meta-learning for few-shot learning. <em>NEUCOM</em>,
<em>537</em>, 271–281. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Warped Gradient descent (WarpGrad) is a remarkable meta-learning method for gradient transformation by inserting warp-layers. However, the task-shared initialization provided by WarpGrad is difficult to be adaptive to each task. Moreover, transforming gradients with meta-learned warp-layers ignores the local geometric features or task-specific knowledge, and may lead to a significant risk of overfitting caused by the increase of parameters. In this paper, we propose ARWarpGrad to guarantee better generalization performance with faster convergence speed by modeling both the cross-task and task-specific knowledge. We introduce Initialization Modulation (IM) to meta-learn to initialize the task-learner specifically. Furthermore, the Mixed Gradient Preprocessing (MGP), which includes the Adaptive Learning Rates (ALR) and the Gaussian Momentum Dropout (GMD), is put forward to provide better adaptive optimization direction and length for task adaptation based on the feature of local geometries. In addition, Memory Regularization (MR) is provided to alleviate the overfitting problem effectively with the use of parameter memory. Ultimately, extensive experiments on three settings demonstrate that ARWarpGrad achieves state-of-the-art performance with convergence acceleration and overfitting prevention characteristics.},
  archive      = {J_NEUCOM},
  author       = {Shuzhen Rao and Jun Huang and Zengming Tang},
  doi          = {10.1016/j.neucom.2023.03.042},
  journal      = {Neurocomputing},
  pages        = {271-281},
  shortjournal = {Neurocomputing},
  title        = {Adaptive regularized warped gradient descent enhances model generalization and meta-learning for few-shot learning},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive survey on ear recognition: Databases,
approaches, comparative analysis, and open challenges. <em>NEUCOM</em>,
<em>537</em>, 236–270. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic identity recognition from ear images is an active research topic in the biometric community. The ability to secretly acquire images of the ear remotely and the stability of the ear shape over time make this technology a promising alternative for surveillance, authentication , and forensic applications . In recent years, significant research has been conducted in this area. Nevertheless, challenges remain that limit the commercial use of this technology. Several phases of the ear recognition system have been studied in the literature, from ear detection, normalization, and feature extraction to classification. This paper reviews the most recent methods used to describe and classify biometric features of the ear. We propose a first taxonomy to group existing approaches to ear recognition, including 2D, 3D, and combined 2D and 3D methods, as well as an overview of historical advances in this field. It is well known that data and algorithms are the essential components in biometrics, particularly in-ear recognition. However, early ear recognition datasets were very limited and collected in laboratory with controlled environments. With the wider use of deep neural networks , a considerable amount of training data has become necessary if acceptable ear recognition performance is to be achieved. As a consequence, current ear recognition datasets have increased significantly in size. This paper gives an overview of the chronological evolution of ear recognition datasets and compares the performance of conventional vs. deep learning methods on several datasets. We proposed a second taxonomy to classify the existing databases, including 2D, 3D, and video ear datasets. Finally, some open challenges and trends are debated for future research.},
  archive      = {J_NEUCOM},
  author       = {Amir Benzaoui and Yacine Khaldi and Rafik Bouaouina and Nadia Amrouni and Hammam Alshazly and Abdeldjalil Ouahabi},
  doi          = {10.1016/j.neucom.2023.03.040},
  journal      = {Neurocomputing},
  pages        = {236-270},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive survey on ear recognition: Databases, approaches, comparative analysis, and open challenges},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning for multivariate time series with the r
package mlmts. <em>NEUCOM</em>, <em>537</em>, 210–235. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data are ubiquitous nowadays. Whereas most of the literature on the topic deals with univariate time series, multivariate time series have typically received much less attention. However, the development of machine learning algorithms for the latter objects has substantially increased in recent years. The R package mlmts attempts to provide a set of widespread data mining techniques for multivariate series. Several functions allowing the execution of clustering, classification, outlier detection and forecasting methods, among others, are included in the package. mlmts also incorporates a collection of multivariate time series datasets often used to test the performance of new classification algorithms. The main characteristics of the package are described and its use is illustrated through various examples. Practitioners from a wide variety of fields could benefit from the general framework provided by mlmts .},
  archive      = {J_NEUCOM},
  author       = {Ángel López-Oriona and José A. Vilar},
  doi          = {10.1016/j.neucom.2023.02.048},
  journal      = {Neurocomputing},
  pages        = {210-235},
  shortjournal = {Neurocomputing},
  title        = {Machine learning for multivariate time series with the r package mlmts},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Focalized contrastive view-invariant learning for
self-supervised skeleton-based action recognition. <em>NEUCOM</em>,
<em>537</em>, 198–209. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning view-invariant representation is a key to improving feature discrimination power for skeleton-based action recognition. Existing approaches cannot effectively remove the impact of viewpoint due to the implicit view-dependent representations. In this work, we propose a self-supervised framework called Focalized Contrastive View-invariant Learning (FoCoViL), which significantly suppresses the view-specific information on the representation space where the viewpoints are coarsely aligned. By maximizing mutual information with an effective contrastive loss between multi-view sample pairs, FoCoViL associates actions with common view-invariant properties and simultaneously separates the dissimilar ones. We further propose an adaptive focalization method based on pairwise similarity to enhance contrastive learning for a clearer cluster boundary in the learned space. Different from many existing self-supervised representation learning work that rely heavily on supervised classifiers, FoCoViL performs well on both unsupervised and supervised classifiers with superior recognition performance. Extensive experiments also show that the proposed contrastive-based focalization generates a more discriminative latent representation.},
  archive      = {J_NEUCOM},
  author       = {Qianhui Men and Edmond S.L. Ho and Hubert P.H. Shum and Howard Leung},
  doi          = {10.1016/j.neucom.2023.03.070},
  journal      = {Neurocomputing},
  pages        = {198-209},
  shortjournal = {Neurocomputing},
  title        = {Focalized contrastive view-invariant learning for self-supervised skeleton-based action recognition},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered near-optimal tracking control based on
adaptive dynamic programming for discrete-time systems. <em>NEUCOM</em>,
<em>537</em>, 187–197. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent state monitoring and controller updates can enhance the precision of tracking control , while simultaneously overburdening the communication network transmission. In this paper, For the purpose of saving communication costs, we propose event-triggered control algorithms for the optimal tracking control problem. First, we reconstruct the discrete-time nonlinear system into a converted system. Then, the adaptive dynamic programming algorithm is employed to find the optimal controller off-line, and the event-triggered scheme is used to reduce the communication costs online. Novel triggering conditions with fewer assumptions are designed to implement the event-triggered scheme. Different from existing works, the event-triggered scheme can be introduced not only into the converted system but also into the actual system, which is more practical because the actual controller is what one can only access in practice. In addition, with the developed algorithms, the tracking error can be proved to be stable at the origin, in other words, the actual system can be guaranteed to track the desired trajectory . Algorithms developed in this paper are implemented by three neural networks , the model network, the action network and the critic network. Finally, examples are presented to verify the effectiveness and rationality of the algorithms.},
  archive      = {J_NEUCOM},
  author       = {Ziyang Wang and Joonhyup Lee and Qinglai Wei and Anting Zhang},
  doi          = {10.1016/j.neucom.2023.03.045},
  journal      = {Neurocomputing},
  pages        = {187-197},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered near-optimal tracking control based on adaptive dynamic programming for discrete-time systems},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformer for skeleton-based action recognition: A review
of recent advances. <em>NEUCOM</em>, <em>537</em>, 164–186. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition has rapidly become one of the most popular and essential research topics in computer vision. The task is to analyze the characteristics of human joints and accurately classify their behaviors through deep learning technology. Skeleton provides numerous unique advantages over other data modalities, such as robustness, compactness, noise immunity, etc. In particular, the skeleton modality is extremely lightweight, which is especially beneficial for deep learning research in low-resource environments. Due to the non-European nature of skeleton data, Graph Convolution Network (GCN) has become mainstream in the past few years, leveraging the benefits of processing topological information. However, with the explosive development of transformer methods in natural language processing and computer vision, many works have applied transformer into the field of skeleton action recognition, breaking the accuracy monopoly of GCN. Therefore, we conduct a survey using transformer method for skeleton-based action recognition, forming of a taxonomy on existing works. This paper gives a comprehensive overview of the recent transformer techniques for skeleton action recognition, proposes a taxonomy of transformer-style techniques for action recognition, conducts a detailed study on benchmark datasets, compares the algorithm accuracy of standard methods, and finally discusses the future research directions and trends. To the best of our knowledge, this study is the first to describe skeleton-based action recognition techniques in the style of transformers and to suggest novel recognition taxonomies in a review. We are confident that Transformer-based action recognition technology will become mainstream in the near future, so this survey aims to help researchers systematically learn core tasks, select appropriate datasets, understand current challenges, and select promising future directions.},
  archive      = {J_NEUCOM},
  author       = {Wentian Xin and Ruyi Liu and Yi Liu and Yu Chen and Wenxin Yu and Qiguang Miao},
  doi          = {10.1016/j.neucom.2023.03.001},
  journal      = {Neurocomputing},
  pages        = {164-186},
  shortjournal = {Neurocomputing},
  title        = {Transformer for skeleton-based action recognition: A review of recent advances},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Unbiased feature position alignment for human pose
estimation. <em>NEUCOM</em>, <em>537</em>, 152–163. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scale feature fusion is a commonly-used module in existing deep-learning models, and feature misalignment occurs in the process of feature fusion. The spatial misalignment hinders the learning of semantic representation with multi-scale levels, but which has not received much attention. This misalignment problem is caused by the feature position shift after using the convolution and interpolation operation in feature fusion. To solve the misalignment problem, this paper formulates the shift error mathematically and proposes a plug-and-play unbiased feature position alignment strategy to align convolution with interpolation. As a model-agnostic approach, unbiased feature position alignment can boost the performance of different models without introducing extra parameters. Furthermore, the unbiased feature position alignment is applied to build an unbiased human pose estimation method. Experimental results have demonstrated the effectiveness of the proposed unbiased pose model in comparison to the state-of-the-arts, especially in the low-resolution field. The codes are shared at https://github.com/WangChen100/Unbiased-Feature-Position-Alignment-for-Human-Pose-Estimation .},
  archive      = {J_NEUCOM},
  author       = {Chen Wang and Yanghong Zhou and Feng Zhang and P.Y. Mok},
  doi          = {10.1016/j.neucom.2023.03.063},
  journal      = {Neurocomputing},
  pages        = {152-163},
  shortjournal = {Neurocomputing},
  title        = {Unbiased feature position alignment for human pose estimation},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Action decoupled SAC reinforcement learning with
discrete-continuous hybrid action spaces. <em>NEUCOM</em>, <em>537</em>,
141–151. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing Deep Reinforcement Learning (DRL) algorithms solely apply to discrete action or continuous action spaces. However, the agent often has both continuous and discrete action space, named hybrid action space. This paper proposes an action-decoupled algorithm for hybrid action space. Specifically, the hybrid action is decoupled, and then the original agent in the hybrid action space is abstracted into two agents. Each agent contains only discrete or continuous action space. The discrete and continuous actions are independent of each other to be executed simultaneously. We use the Soft Actor-Critic (SAC) algorithm as the optimization method and name our proposed algorithm Action Decoupled SAC (AD-SAC). We handle multi-agent problems using a framework of Centralized Training Decentralized Execution (CTDE) and then reduce the concatenation of partial agent observations to avoid the interference of redundant observations. We design a hybrid action space environment for Unmanned Aerial Vehicles (UAVs) path planning and gimbal scanning using AirSim. The results show that our algorithm has better convergence and robustness than the discretization , relaxation, and the Parametrized Deep Q-Networks Learning (P-DQN) algorithms. Finally, we carried out a Hardware in the Loop (HITL) simulation experiment based on Pixhawk to verify the feasibility of our algorithm.},
  archive      = {J_NEUCOM},
  author       = {Yahao Xu and Yiran Wei and Keyang Jiang and Li Chen and Di Wang and Hongbin Deng},
  doi          = {10.1016/j.neucom.2023.03.054},
  journal      = {Neurocomputing},
  pages        = {141-151},
  shortjournal = {Neurocomputing},
  title        = {Action decoupled SAC reinforcement learning with discrete-continuous hybrid action spaces},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial patch attacks against aerial imagery object
detectors. <em>NEUCOM</em>, <em>537</em>, 128–140. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Deep Neural Networks (DNNs)-based object detectors are widely used in various fields, especially on aerial imagery object detections, it has been observed that a small elaborately designed patch attached to the images can mislead the DNNs-based detectors into producing erroneous output. However, the target detectors being attacked are quite simple, and the attack efficiency is relatively low in previous works, making it not practicable in real scenarios. To address these limitations, a new adversarial patch attack algorithm is proposed in this paper. Firstly, we designed a novel loss function using the intermediate outputs of the models rather than the model’s final outputs interpreted by the detection head to optimize adversarial patches. The experiments conducted on the DOTA, RSOD, and NWPU VHR-10 datasets demonstrate that our method can significantly degrade the performance of the detectors. Secondly, we conducted intensive experiments to investigate the impact of different outputs of the detection model on generating adversarial patches, demonstrating the class score is not as effective as the objectness score. Thirdly, we comprehensively analyzed the attack transferability across different aerial imagery datasets, verifying that the patches generated on one dataset are also effective in attacking another. Moreover, we proposed ensemble training to boost the attack’s transferability across models. Our work alarms the application of DNNs-based object detectors in aerial imagery.},
  archive      = {J_NEUCOM},
  author       = {Guijian Tang and Tingsong Jiang and Weien Zhou and Chao Li and Wen Yao and Yong Zhao},
  doi          = {10.1016/j.neucom.2023.03.050},
  journal      = {Neurocomputing},
  pages        = {128-140},
  shortjournal = {Neurocomputing},
  title        = {Adversarial patch attacks against aerial imagery object detectors},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RSBNet: One-shot neural architecture search for a backbone
network in remote sensing image recognition. <em>NEUCOM</em>,
<em>537</em>, 110–127. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a massive number of deep learning-based approaches have been successfully applied to various remote sensing image (RSI) recognition tasks. However, most existing advances of deep learning methods in the RSI field heavily rely on the features extracted by the manually designed backbone network , which severely hinders the potential of deep learning models due to the complexity of RSI and the limitation of prior knowledge. In this paper, we research a new design paradigm for the backbone architecture in RSI recognition tasks, including scene classification, land-cover classification and object detection. A novel one-shot architecture search framework based on a weight-sharing strategy and an evolutionary algorithm is proposed, called RSBNet, which consists of three stages: Firstly, a supernet constructed in a layer-wise search space is pretrained on a self-assembled large-scale RSI dataset based on an ensemble single-path training strategy. Next, the pre-trained supernet is equipped with different recognition heads through the switchable recognition module and respectively fine-tuned on the target dataset to obtain task-specific supernet. Finally, we search for the optimal backbone architecture for different recognition tasks based on the evolutionary algorithm without any network training. Extensive experiments have been conducted on five benchmark datasets for different recognition tasks, the results show the effectiveness of the proposed search paradigm and demonstrate that the searched backbone is able to flexibly adapt different RSI recognition tasks and achieve impressive performance.},
  archive      = {J_NEUCOM},
  author       = {Cheng Peng and Yangyang Li and Ronghua Shang and Licheng Jiao},
  doi          = {10.1016/j.neucom.2023.03.046},
  journal      = {Neurocomputing},
  pages        = {110-127},
  shortjournal = {Neurocomputing},
  title        = {RSBNet: One-shot neural architecture search for a backbone network in remote sensing image recognition},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Haze removal for single image: A comprehensive review.
<em>NEUCOM</em>, <em>537</em>, 85–109. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image dehazing is always a hot topic in the field of computer vision since haze has significant impact on the imaging quality of camera. Therefore, many image dehazing methods have been proposed for the past decades. To help researchers who are new to this field quickly figure out the development history as well as the current status of image dehazing, this review analyzes some representative dehazing methods, evaluates their advantages and disadvantages, and most importantly, points out the best dehazing method from different viewpoints. A large quantity of experiments show that AECR-Net can be generally considered to be the best dehazing algorithm and Tarel method can be regarded as the best real-time dehazing method. Besides, the mainstream benchmark, metrics, challenges and opportunities for image dehazing are also discussed in this review.},
  archive      = {J_NEUCOM},
  author       = {Fan Guo and Jianan Yang and Zhuoqun Liu and Jin Tang},
  doi          = {10.1016/j.neucom.2023.03.061},
  journal      = {Neurocomputing},
  pages        = {85-109},
  shortjournal = {Neurocomputing},
  title        = {Haze removal for single image: A comprehensive review},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Textual tag recommendation with multi-tag topical attention.
<em>NEUCOM</em>, <em>537</em>, 73–84. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tagging can be regarded as the action of connecting relevant user-defined keywords to an item, indirectly improving the quality of the information retrieval services that rely on tags as data sources. Tag recommendation dramatically enhances the quality of tags by assisting users in tagging. Although there exist many studies on tag recommendation for textual content, few of them consider two characteristics in real applications, i.e., the long-tail distribution of tags and the topic-tag correlation. In this paper, we propose a Topic-Guided Tag Recommendation (TGTR) model to recommend tags by jointly incorporating dynamic neural topic. Specifically, TGTR first generates dynamic neural topic that would indicate the tags by a neural topic generator. Then, a sequence encoder is used to distill indicative features from the post. To effectively leverage the topic and alleviate the data imbalance, we design a multi-tag topical attention mechanism to get a tag-specific post representation for each tag with the help of dynamic neural topic. These three modules are seamlessly joined together via an end-to-end multi-task learning model, which is helpful for the three parts to enhance each other and balance the effects of topics and tags. Extensive experiments have been conducted on four real-world datasets and demonstrate that our model outperforms the state-of-the-art approaches by a large margin, especially on tail-tags. The code, data and hyper-parameter settings are publicly released for reproducibility.},
  archive      = {J_NEUCOM},
  author       = {Pengyu Xu and Mingxuan Xia and Lin Xiao and Huafeng Liu and Bing Liu and Liping Jing and Jian Yu},
  doi          = {10.1016/j.neucom.2023.03.051},
  journal      = {Neurocomputing},
  pages        = {73-84},
  shortjournal = {Neurocomputing},
  title        = {Textual tag recommendation with multi-tag topical attention},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TransAM: Transformer appending matcher for few-shot
knowledge graph completion. <em>NEUCOM</em>, <em>537</em>, 61–72. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot knowledge graph completion (FSKGC) refers to predicting new facts for a new relation with only few-shot observed entity pairs (triples) as support set. Existing solutions to FSKGC mainly conduct the matching process over entity pair representations. Although effective, a major concern of these models is that the entity interactions are not fully explored, based on the observation that they usually generate the pair representation before the matching stage. Such a design inherently overlooks the fine-grained information from entity interactions, leading to performance decrements in one or three shot, which require matching models to capture more sufficient semantic meanings for prediction. To remedy this issue, in this paper, we explore the entity interactions within and between different instances, i.e. , the co-occurrence of two entities, for FSKGC and propose our model named TransAM, Trans former A ppending M atcher. TransAM solves the FSKGC problem by computing the probability of entity sequence with a well-designed transformer matching network. Specifically, TransAM appends query entity pair to serialized reference entity sequence and utilizes transformer to calculate the probability by capturing intra- and inter- triple entity interactions. To bridge the gap between transformer and the triple structure, TransAM introduces rotary operation to preserve the head and tail roles of entity within the triple and distinguishes different triples by a separated triple position encoding. Empirical studies on two public benchmark datasets NELL-One and Wiki-One show that TransAM outperforms existing metric-learning solutions in MRR and Hits@1 with both one- and three- shot settings, and achieves comparable results on five-shot setting. Datasets and code will be public available at https://github.com/gawainx/TransAM.},
  archive      = {J_NEUCOM},
  author       = {Yi Liang and Shuai Zhao and Bo Cheng and Hao Yang},
  doi          = {10.1016/j.neucom.2023.03.049},
  journal      = {Neurocomputing},
  pages        = {61-72},
  shortjournal = {Neurocomputing},
  title        = {TransAM: Transformer appending matcher for few-shot knowledge graph completion},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Data hiding during image processing using capsule networks.
<em>NEUCOM</em>, <em>537</em>, 49–60. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In daily life, some conventional image processing operations, e.g., histogram equalization , and filtering, are widely used to improve the visual quality of digital images. This paper designs an image processing network based on CapsNets (capsule networks), in which additional data can be carried in the processed image. Given an image to be processed, the proposed network is able to achieve some conventional image processing operations with satisfactory results. Meanwhile, additional data can be embedded into the processed image during the process of training, and the existence of additional data cannot be discovered. In this way, additional data can be transmitted secretly via the processed image, which looks normal. Compared with existing data hiding algorithms that embed data by modifying image content, the proposal to embed data during the process of training is more secure. Experimental results verify the effectiveness of the proposed network, including the quality of the processed image, embedding capacity, and security.},
  archive      = {J_NEUCOM},
  author       = {Zichi Wang and Guorui Feng and Hanzhou Wu and Xinpeng Zhang},
  doi          = {10.1016/j.neucom.2023.03.041},
  journal      = {Neurocomputing},
  pages        = {49-60},
  shortjournal = {Neurocomputing},
  title        = {Data hiding during image processing using capsule networks},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mutual mentor: Online contrastive distillation network for
general continual learning. <em>NEUCOM</em>, <em>537</em>, 37–48. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of General Continual Learning (GCL) is to preserve learned knowledge and learn new knowledge with constant memory from infinite data stream where task boundaries are blurry. Distilling the model’s response of reserved samples between the old and new models is an effective way to achieve promising performance on GCL. However, it accumulates the inherent old model’s response bias and is not robust to model changes. To this end, we propose a M utual M entor G eneral C ontinual L earning ( MMGCL ) framework to tackle these problems, which explores a training process in which the student and teacher models mentor each other. Concretely, the student model consolidates the learned knowledge by respectively aligning the relation and adaptive responses with those of the teacher model while the teacher model updates its parameters by integrating the parameters of the student model to accumulate new knowledge. To further improve the effectiveness of the mutual mentor, we integrate the inter-instance knowledge to optimize the outputs of the teacher model, which can not only supervise the student model but also indirectly optimize the teacher model. Extensive experiments on six benchmark datasets demonstrate that our MMGCL significantly outperforms state-of-the-art approaches under diverse continual learning settings with various buffer sizes.},
  archive      = {J_NEUCOM},
  author       = {Qiang Wang and Zhong Ji and Jin Li and Yanwei Pang},
  doi          = {10.1016/j.neucom.2023.03.066},
  journal      = {Neurocomputing},
  pages        = {37-48},
  shortjournal = {Neurocomputing},
  title        = {Mutual mentor: Online contrastive distillation network for general continual learning},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A lightweight backdoor defense framework based on image
inpainting. <em>NEUCOM</em>, <em>537</em>, 22–36. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have been shown to be vulnerable to backdoor attacks during training. Most of the existing backdoor defense methods are designed for specific types of backdoor attacks, and the work of detecting backdoors and mitigating backdoors is mostly separate. Currently, few general and complete defense frameworks have been developed. In this paper, we propose a lightweight, general, and complete defense framework against three main types of backdoor attacks. It can efficiently detect poisoned images and remove trigger patterns on poisoned images without costly retraining of the backdoor model. First, we use the feature difference between clean samples and poisoned samples in the middle layer of the model to distinguish them. Then, we remove the backdoor using image inpainting algorithm to remove the backdoor triggering pattern on the poisoned samples. We deploy three of the most popular backdoor attacks on three datasets to test the effectiveness of our defenses. Extensive experimental results show that our method can effectively defend against various backdoor attacks with a relatively small cost. In particular, we reduce the attack success rate of the more stealthy clean-label poisoning attack from 94.9\% to 0.02\% with little impact on the classification accuracy of the inpainted images.},
  archive      = {J_NEUCOM},
  author       = {Yier Wei and Haichang Gao and Yufei Wang and Yipeng Gao and Huan Liu},
  doi          = {10.1016/j.neucom.2023.03.052},
  journal      = {Neurocomputing},
  pages        = {22-36},
  shortjournal = {Neurocomputing},
  title        = {A lightweight backdoor defense framework based on image inpainting},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic piecewise convolutional neural network with
adaptive negative training for distantly supervised relation extraction.
<em>NEUCOM</em>, <em>537</em>, 12–21. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distantly Supervised Relation Extraction (DSRE) aligns existing knowledge bases with unstructured text to extract relation facts, and its automatically generated training data is inevitably noisy. Most existing works identify and reduce the impact of noise by enhancing semantic features . However, they only consider the semantic information in a single instance and ignore the semantic information between different instances. In this work, we propose a Semantic Piecewise Convolutional Neural Network (SPCNN), which uses the similarity between different entity pairs as semantic information to improve relation extraction. Specifically, to learn better semantic vector representations, we combine position features with entity pair features and entity similarity features in a high-dimensional space respectively, and generating two different semantic-aware representations. Then we unify these two representations to form a high-quality bag representation for training. Moreover, we design an Adaptive Negative Training (ANT) strategy, which facilitates the network to further exploit the rich semantic features to reduce the interference of noisy labels. Extensive experimental results on a large-scale benchmark dataset show that our method significantly outperforms other baselines.},
  archive      = {J_NEUCOM},
  author       = {Mei Yu and Yunke Chen and Mankun Zhao and Tianyi Xu and Jian Yu and Ruiguo Yu and Hongwei Liu and Xuewei Li},
  doi          = {10.1016/j.neucom.2023.03.005},
  journal      = {Neurocomputing},
  pages        = {12-21},
  shortjournal = {Neurocomputing},
  title        = {Semantic piecewise convolutional neural network with adaptive negative training for distantly supervised relation extraction},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite-time stability of solutions for non-instantaneous
impulsive systems and application to neural networks. <em>NEUCOM</em>,
<em>537</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work extends the finite-time stability (FTS) results to non-instantaneous impulsive time-varying systems on the basis of general impulsive systems via Lyapunov theory . The impacts of impulse numbers, impulse time sequences and impulse amplitudes on FTS and settling-time estimation are discussed. The effects of different types of impulses on settling-time are discussed when the impulse number is known or pre-given. The average impulsive interval is introduced to extend the above results to the case when the impulse number is unknown, and the derivative of Lyapunov function is allowed to be indefinite instead of being negative definite or semi-negative definite. Moreover, the theoretical results are applied to non-instantaneous impulsive neural networks . Finally, we provide two numerical examples to demonstrate the effectiveness and feasibility of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Hao Deng and Chuandong Li and Yinuo Wang and Hongjuan Wu},
  doi          = {10.1016/j.neucom.2023.02.056},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Finite-time stability of solutions for non-instantaneous impulsive systems and application to neural networks},
  volume       = {537},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal transformer with language query for referring
image segmentation. <em>NEUCOM</em>, <em>536</em>, 191–205. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring image segmentation (RIS) aims to predict a segmentation mask for a target specified by a natural language expression. However, the existing methods failed to implement deep interaction between vision and language is needed in RIS, resulting inaccurate segmentation. To address the problem, a cross-modal transformer (CMT) with language queries for referring image segmentation is proposed. First, a cross-modal encoder of CMT is designed for intra-modal and inter-modal interaction, capturing context-aware visual features. Secondly, to generate compact visual-aware language queries , a language-query encoder (LQ) embeds key visual cues into linguistic features. In particular, the combination of the cross-modal encoder and language query encoder realizes the mutual guidance of vision and language. Finally, the cross-modal decoder of CMT is constructed to learn multimodal features of the referent from the context-aware visual features and visual-aware language queries. In addition, a semantics-guided detail enhancement (SDE) module is constructed to fuse the semantic-rich multimodal features with detail-rich low-level visual features, which supplements the spatial details of the predicted segmentation masks. Extensive experiments on four referring image segmentation datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Zhang and Quange Tan and Pengxin Li and Qi Zhang and Rong Wang},
  doi          = {10.1016/j.neucom.2023.03.011},
  journal      = {Neurocomputing},
  pages        = {191-205},
  shortjournal = {Neurocomputing},
  title        = {Cross-modal transformer with language query for referring image segmentation},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disentangle irrelevant and critical representations for face
anti-spoofing. <em>NEUCOM</em>, <em>536</em>, 175–190. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition systems have been widely applied in security-related areas of our daily life. However, they are vulnerable to face spoofing attacks. Specifically, an attacker can fool a face recognition system into making false decisions, by presenting spoof face information (such as printed photos, replayed videos, etc.), rather than live face, to the face recognition system. Therefore, Face Anti-Spoofing (FAS) is critical for the security operation of a face recognition system. Deep learning-based FAS approaches show the best performance among existing FAS approaches. The basic idea of deep learning-based FAS approaches is to learn statistical representations capable of distinguishing spoof faces from live ones, and then leverage the learned representations for live and spoof face classifications. Therefore, the learned representations play a key role in the performance of FAS. However, most existing approaches learn representations from representation-entangled spaces, in which critical and irrelevant representations for live and spoof face classifications are entangled with each other, thereby bringing a negative influence on the performance of a FAS system. To address the issue, we introduced a Twin Autoencoder Disentanglement (TAD) framework. Our TAD framework utilizes adversarial learning and a reconstruction strategy to disentangle both critical and irrelevant representations into two mutually independent representation spaces. In addition, to further suppress irrelevant representations that may remain in the critical representation space, we design a multi-branch supervision architecture (MSA) and embed it into TAD. MSA achieves the goal via imposing depth supervision and pattern supervision to the critical representation space. i.e., learning spatial representation (face depth information) and texture representation (face spoof pattern information). Experimental results on four typical public datasets, OULU-NPU, SiW, Replay-Attack, and CASIA-MFSD, demonstrate that our proposed TAD approach successfully disentangles critical and irrelevant representations, and the two disentangled representations are more interpretable than state-of-the-art FAS methods. The codes are available at https://github.com/TAD-FAS/TAD.},
  archive      = {J_NEUCOM},
  author       = {Shikun Zhao and Wei Chen and Fan Zhang and Xiaoli Liu},
  doi          = {10.1016/j.neucom.2023.03.018},
  journal      = {Neurocomputing},
  pages        = {175-190},
  shortjournal = {Neurocomputing},
  title        = {Disentangle irrelevant and critical representations for face anti-spoofing},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anti-aliasing deep image classifiers using novel depth
adaptive blurring and activation function. <em>NEUCOM</em>,
<em>536</em>, 164–174. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional networks are vulnerable to image translation or shift, partly due to common down-sampling layers, e.g., max-pooling and strided convolution. These operations violate the Nyquist sampling rate and cause aliasing . The textbook solution is low-pass filtering (blurring) before down-sampling, which can benefit deep networks as well. Even so, non-linearity units, such as ReLU, often re-introduce the problem, suggesting that blurring alone may not suffice. In this work, first, we analyse deep features with Fourier transform and show that Depth Adaptive Blurring is more effective, as opposed to monotonic blurring. To this end, we propose a novel Depth Adaptive Blur-pool (DAB-pool) module to replace existing down-sampling methods. Second, we introduce a novel activation function – with a built-in low pass filter, as an additional measure, to keep the problem from reappearing. From experiments, we observe generalisation on other forms of transformations and corruptions as well, e.g., rotation, scale, and noise. We evaluate our method under three challenging settings: (1) a variety of image translations; (2) adversarial attacks – both ℓ p bounded and unbounded; and (3) data corruptions and perturbations. In each setting, our method achieves state-of-the-art results and improves clean accuracy on various benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Md Tahmid Hossain and Shyh Wei Teng and Guojun Lu and Mohammad Arifur Rahman and Ferdous Sohel},
  doi          = {10.1016/j.neucom.2023.03.023},
  journal      = {Neurocomputing},
  pages        = {164-174},
  shortjournal = {Neurocomputing},
  title        = {Anti-aliasing deep image classifiers using novel depth adaptive blurring and activation function},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Graph context-attention network via low and high order
aggregation. <em>NEUCOM</em>, <em>536</em>, 152–163. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph attention networks (GATs) have been shown effectively for representation learning . However, existing GATs only employ the first-order attention mechanism and thus fail to fully exploit and learn node’s contextual feature representations. To address this issue, we propose a novel Graph Context-Attention Network (GCAN) via low and high order aggregation for representation learning . The proposed model fully exploits both low-order and high-order information of nodes for representation learning by employing high-order attention mechanism and adversary regularization constraints. The main benefit of the proposed method is that it can effectively capture the discriminative feature differences among node representations while enhancing the diversity and richness of node features. Thus it can alleviate the issue of over-smoothing in the network learning. We perform extensive experiments on nine datasets and the experimental results demonstrate the effectiveness and better performance of our approach.},
  archive      = {J_NEUCOM},
  author       = {Haiyun Xu and Shaojie Zhang and Bo Jiang and Jin Tang},
  doi          = {10.1016/j.neucom.2023.03.030},
  journal      = {Neurocomputing},
  pages        = {152-163},
  shortjournal = {Neurocomputing},
  title        = {Graph context-attention network via low and high order aggregation},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Where to look: Multi-granularity occlusion aware for video
person re-identification. <em>NEUCOM</em>, <em>536</em>, 137–151. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video person re-identification(re-ID) plays an important role in intelligent video surveillance, which can automatically match the same person across video clips under non-overlapping cameras. Despite great progress in re-ID, the performance of most existing methods still is corrupted severely under partial occlusion. Although some multi-granularity methods have alleviated this dilemma, these methods still suffer from weak diversity of features and conflict between rigid horizontal partition and vertical occlusion. In this paper, we propose a novel video person re-ID framework, called Multi-Granularity Occlusion Aware (MGOA), which extracts multi-granularity features by precisely erasing the occlusion. Different from previous works based on multiple granularities, the proposed MGOA predicts the partial occlusion in a coarse-to-fine manner instead of erasing the occlusion in video clips by one step. Specifically, we first propose the multi-granularity feature extraction to obtain diverse features at different levels of feature maps, which is beneficial for the fine erasure of the occlusion. Moreover, to avoid the limitation of horizontal stripes that cannot handle vertical occlusion, we design Attention-Aware Occlusion Erasure (AA-OE) that can obtain the attention maps with coarse occlusion erasure in the coarse-grained branch and the attention maps with fine occlusion erasure in the fine-grained branch. It is worth noting that each granularity in our network is not independent but relevant through the top-down information transmission between granularities, which transfers the erased occlusion feature maps of the current branch to the next finer-grained branch for guiding AA-OE to obtain more discriminative features . Extensive experiments on three challenging public benchmarks show that our MGOA can deal well with occlusion and achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Jiaxu Leng and Haitao Wang and Xinbo Gao and Yan Zhang and Ye Wang and Mengjingcheng Mo},
  doi          = {10.1016/j.neucom.2023.03.003},
  journal      = {Neurocomputing},
  pages        = {137-151},
  shortjournal = {Neurocomputing},
  title        = {Where to look: Multi-granularity occlusion aware for video person re-identification},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust h∞ optimal safety control for WMR system with
disturbances and actuator attack under event conditions.
<em>NEUCOM</em>, <em>536</em>, 125–136. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops an optimal control strategy for a class of wheeled mobile robot （WMR) systems in the occurrence of actuator attack and disturbance. A novel event-based sliding mode safety control (SMSC) approach is designed with two event conditions. We establish the robot system model with disturbance and attack first. By utilizing the output of the robot system, a novel sliding mode manifold is designed and a discontinuous control part is constructed with event conditions to guarantee the system states would move onto the manifold, and the Zeno performance is verified. Moreover, a robust H ∞ H∞ optimal control problem is established to degrade the influence of the disturbance to an acceptable level. In addition, the neural network (NN)-based technology is addressed to approximate the unknown function and the data learning-based optimal control part. The closed robot system is proved to be stable and the convergence performance of the weight vector can be ensured. The application results verify the compensation abilities of the optimal control approach.},
  archive      = {J_NEUCOM},
  author       = {Bin Guo and Song-yi Dian and Tao Zhao},
  doi          = {10.1016/j.neucom.2023.03.033},
  journal      = {Neurocomputing},
  pages        = {125-136},
  shortjournal = {Neurocomputing},
  title        = {Robust h∞ optimal safety control for WMR system with disturbances and actuator attack under event conditions},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple target data-association algorithm based on
takagi–sugeno intuitionistic fuzzy model. <em>NEUCOM</em>, <em>536</em>,
114–124. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem of data association in multiple target tracking in a densely cluttered environment, a multiple target data association algorithm based on Takagi–Sugeno (T-S) intuitionistic fuzzy model is proposed. In the proposed algorithm, the new multiple target T-S intuitionistic fuzzy model (MTTS-IFM) is constructed by incorporating intuitionistic fuzzy sets and intuitionistic fuzzy numbers. To identify the premise parameters for MTTS-IFM, a new intuitionistic index is defined and a modified form of the intuitionistic fuzzy C-means clustering algorithm is proposed. Furthermore, to solve the multiple target data association for the MTTS-IFM approach, the input variables of MTTS-IFM are defined using the maximum intuitionistic fuzzy entropy, and a data association approach is proposed to deal with the uncertainty between targets and measurements. Finally, simulation results show that the performance of the proposed algorithm is better than that of algorithms designed for multiple target tracking in either a clutter-free or cluttered environment. Moreover, the real-time performance was clearly better than that of the joint probabilistic data association filter (JPDAF) and slightly better than that of maximum entropy fuzzy (MEF-JPDAF), Fitzgerald-JPDAF, and a T-S intuitionistic fuzzy model (TS-FM).},
  archive      = {J_NEUCOM},
  author       = {Chu-Yun Zhang and Liang-Qun Li and Shuai Huang},
  doi          = {10.1016/j.neucom.2023.03.021},
  journal      = {Neurocomputing},
  pages        = {114-124},
  shortjournal = {Neurocomputing},
  title        = {Multiple target data-association algorithm based on Takagi–Sugeno intuitionistic fuzzy model},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Land use and land cover classification with hyperspectral
data: A comprehensive review of methods, challenges and future
directions. <em>NEUCOM</em>, <em>536</em>, 90–113. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many efforts have been concentrated on land use land cover (LULC) classification due to rapid urbanization, environmental pollution, agriculture drought, frequent floods, and climate change. However, various aspects have attracted hyperspectral imaging due to there being informative discriminative features , such as spectral-spatial features. To this end, this paper is a comprehensive and systematic review of LULC classification using hyperspectral images by reviewing four significant research investigations. Moreover, the four investigations have addressed the following points: (1) the main components of the hyperspectral imaging , the modes of hyperspectral imaging with data acquisition methods, and the intrinsic differences between hyperspectral image and multispectral image , (2) the role of machine learning in LULC classification, and the standard deep learning methods : Convolution Neural Network (CNN), Stacked Autoencoder (SAE), Deep Belief Network (DBN), Recurrent Neural Network (RNN), and Generative Adversarial Network (GAN), (3) the standard benchmark hyperspectral datasets and the evaluation criteria, (4) the main challenges of LULC classification with the possible solutions for the limited training samples issue, the promising future directions, and finally the recent applications for LULC classification.},
  archive      = {J_NEUCOM},
  author       = {Mohammed Abdulmajeed Moharram and Divya Meena Sundaram},
  doi          = {10.1016/j.neucom.2023.03.025},
  journal      = {Neurocomputing},
  pages        = {90-113},
  shortjournal = {Neurocomputing},
  title        = {Land use and land cover classification with hyperspectral data: A comprehensive review of methods, challenges and future directions},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Three-dimensional magneto-acousto-electrical tomography (3D
MAET) with single-element ultrasound transducer and coded excitation: A
phantom validation study. <em>NEUCOM</em>, <em>536</em>, 80–89. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magneto-acousto-electrical tomography (MAET) is a hybrid imaging modality combining the merits of high contrast and high resolution. Current studies in MAET mainly focus on two-dimensional (2D) imaging. In practice, an object&#39;s conductivity is usually three-dimensional inhomogeneous. Therefore, three-dimensional MAET (3D MAET) may provide a more comprehensive understanding of the conductivity distribution of an object. The basic idea of realizing 3D MAET is to move the ultrasound transducer mechanically to accomplish the 3D scanning . However, this mechanical scanning procedure is time-consuming. Moreover, due to the weak MAE signal, traditional MAET based on single-pulse excitation requires thousands of signal averaging operations to improve the signal-to-noise ratio (SNR) of imaging, which may further increase the time burden of 3D MAET. This study aims to investigate the feasibility of 3D MAET based on a 1D ultrasound transducer and coded-excitation technology. A 13-bit Barker code was used as the excitation code, and two 3D biological phantoms were used to validate the imaging accuracy. The experimental results show that the imaging results of this method can reflect the change of conductivity in 3D space. The average relative errors of the measured slope of the conductivity distribution in Phantom 1 and Phantom 2 are 6.72\% and 2.02\%, respectively. Moreover, compared with the short-pulse excitation method , the Barker-coded excitation method can obtain comparative imaging SNR with about a quarter average, thus demonstrating the feasibility of 3D MAET with a single-element ultrasound transducer and coded excitation.},
  archive      = {J_NEUCOM},
  author       = {Tong Sun and Linguo Yu and Dingqian Deng and Mengmeng Yu and Yi Chen and Chunqi Chang and Mian Chen and Siping Chen and Xin Chen and Haoming Lin},
  doi          = {10.1016/j.neucom.2023.02.055},
  journal      = {Neurocomputing},
  pages        = {80-89},
  shortjournal = {Neurocomputing},
  title        = {Three-dimensional magneto-acousto-electrical tomography (3D MAET) with single-element ultrasound transducer and coded excitation: A phantom validation study},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed finite-time optimization algorithms with a
modified newton–raphson method. <em>NEUCOM</em>, <em>536</em>, 73–79.
(<a href="https://doi.org/10.1016/j.neucom.2023.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a distributed finite-time optimization protocol for single-integrator continuous-time multi-agent systems, which utilizes a modified Newton–Raphson method. The inverse of Hessian matrix , sign function and the gradient are adopted for the design of the algorithms. The proposed algorithms make agents converge to the network optimizer under any initial state and finite time, respectively. Lyapunov method and the properties of sign function are employed to verify the convergence of the proposed algorithms. Besides, the adaptive method is also considered to avoid complex parameter conditions and centralized parameters. Finally, numerical simulations are provided to testify the presented results.},
  archive      = {J_NEUCOM},
  author       = {Dong Wang and Zhenzhen Gao and Dong Wang},
  doi          = {10.1016/j.neucom.2023.03.027},
  journal      = {Neurocomputing},
  pages        = {73-79},
  shortjournal = {Neurocomputing},
  title        = {Distributed finite-time optimization algorithms with a modified Newton–Raphson method},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Serial-parallel multi-scale feature fusion for
anatomy-oriented hand joint detection. <em>NEUCOM</em>, <em>536</em>,
59–72. (<a href="https://doi.org/10.1016/j.neucom.2023.02.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate hand joints detection from images is a fundamental topic that is essential for many applications in computer vision and human–computer interaction. This paper presents a two-stage network for hand joints detection from a single unmarked image by using serial-parallel multi-scale feature fusion . In stage I, the hand regions are located by an encoder-decoder network, and the features of each detected hand region are extracted by a shallow spatial hand features representation module. The extracted hand features are then fed into stage II, which consists of serially connected feature extraction modules with similar structures, called “multi-scale feature fusion” (MSFF). An MSFF contains parallel multi-scale feature extraction branches, which generate initial hand joint heatmaps. The initial heatmaps are then mutually reinforced by the anatomic relationship between hand joints. The hand joint detection accuracy shows that the proposed network overperforms the state-of-the-art methods on current datasets, 1) RHD, 2) HS, 3) MPII &amp; NZSL, 4) DCD8-6000, with the PCK@0.2 of 0.94, 0.92, 0.84, 0.97. Meanwhile, one hand in the image takes between 24 and 37 ms to process, which is adequate for supporting many real-time applications.},
  archive      = {J_NEUCOM},
  author       = {Bin Li and Ruimin Li and Wendi Wang and Hong Fu},
  doi          = {10.1016/j.neucom.2023.02.046},
  journal      = {Neurocomputing},
  pages        = {59-72},
  shortjournal = {Neurocomputing},
  title        = {Serial-parallel multi-scale feature fusion for anatomy-oriented hand joint detection},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Expert-guided contrastive learning for video-text retrieval.
<em>NEUCOM</em>, <em>536</em>, 50–58. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers with collaborative experts have become a powerful framework for video-text retrieval. In specific, experts understand the specialized property of each domain ( e.g. , appearance, motion, and audio) from videos and the video encoder aggregates those expertise features. However, previous works implicitly guide the video transformer by solving auxiliary video-text tasks with expertise features, since concatenation for the video transformer is the only effort to exploit the knowledge of experts. In this paper, we propose an expert-guided contrastive loss in order to fully exploit expert knowledge from videos. In detail, we sample a positive bag using an expert-wise similarity matrix to learn text encoder and decompose text representation into dynamic and static factors from given videos. Through extensive experiments, we verify the effectiveness of the proposed methods. Notably, we also demonstrate that our method brings significant improvements under the expert-based framework and it can collaborate with CLIP-based architectures for further performance boosts.},
  archive      = {J_NEUCOM},
  author       = {Jewook Lee and Pilhyeon Lee and Sungho Park and Hyeran Byun},
  doi          = {10.1016/j.neucom.2023.03.022},
  journal      = {Neurocomputing},
  pages        = {50-58},
  shortjournal = {Neurocomputing},
  title        = {Expert-guided contrastive learning for video-text retrieval},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient fine-grained vehicle recognition method based
on part-level feature optimization. <em>NEUCOM</em>, <em>536</em>,
40–49. (<a href="https://doi.org/10.1016/j.neucom.2023.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an effective method for strengthening the discriminative ability of high-level deep features by enhancing and aggregating discriminative part-level features for the fine-grained vehicle recognition task. In general, the task of visual recognition concentrates more on the visual differences at the object level. However, for fine-grained object recognition, the visual differences between target objects typically exist in local discriminative areas, so it is more concerned about extracting fine-grained features from these part regions. In this context, we propose solving this issue with a novel feature extraction method from two perspectives: the generation of more feature descriptors of part regions through the learning process of deep networks and the aggregation of part-level discriminative features . This approach is designed to improve the backbone networks to generate finer-level part features through a part-level feature enhancement module and to investigate the intrinsic part-level features of the backbone networks with the help of a feature aggregation module. The enhancement module efficiently finds the finer features highly correlated to the part regions. Then the feature aggregation module builds correlations of similar part features through feature grouping and fusion. Moreover, our proposed method does not require additional parts annotations and achieves comparable performance on two widely-used benchmarks for recognizing fine-grained vehicle types. Experimental results and explainable visualizations demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Lei Lu and Yancheng Cai and Hua Huang and Ping Wang},
  doi          = {10.1016/j.neucom.2023.03.035},
  journal      = {Neurocomputing},
  pages        = {40-49},
  shortjournal = {Neurocomputing},
  title        = {An efficient fine-grained vehicle recognition method based on part-level feature optimization},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual-semantic consistency matching network for generalized
zero-shot learning. <em>NEUCOM</em>, <em>536</em>, 30–39. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot learning aims to classify samples of seen and unseen classes by providing only the labels of seen classes. Most GZSL methods directly associate seen classes’ visual features with semantic information or leverage semantic information to synthesize samples of unseen classes to transfer the knowledge of seen classes to unseen classes. However, existing generative methods simply employ visual features extracted from the per-trained CNN backbone, which overlooks that the visual features of similar categories have significant similarities and lack enough discriminating information, leading to poor classification performance when generalizing the knowledge of seen classes to unseen classes. To mitigate this issue, we present a Visual-Semantic Consistency Matching Network (VSCM) for generalized zero-shot learning. Our proposed method employs a conditional VAE to generate the visual features of unseen classes and utilizes a visual-semantic consistency matching network that aligns visual space with semantic space to obtain visual-semantic consistency features. Specifically, we propose a semantic chunking network that teams up with semantic attention and a semantic encoder to guide the visual-semantic consistency matching network to get synthetic semantic information aligned with factual semantic information. The semantic relation network guarantees the consistency between the factual semantic information and the block features, while the semantic independence network measures the independence of the blocks. Finally, we concatenate visual features and synthetic semantic information as visual-semantic consistency features to improve the separability between categories. Extensive experiments on five GZSL benchmark datasets demonstrate the significant generalization performance of our proposed method over the state-of-the-art methods. Our codes have been available at: https://github.com/zzq158/VSCM-GZSL .},
  archive      = {J_NEUCOM},
  author       = {Zhenqi Zhang and Wenming Cao},
  doi          = {10.1016/j.neucom.2023.03.007},
  journal      = {Neurocomputing},
  pages        = {30-39},
  shortjournal = {Neurocomputing},
  title        = {Visual-semantic consistency matching network for generalized zero-shot learning},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network model based on global and local features for
multi-view mammogram classification. <em>NEUCOM</em>, <em>536</em>,
21–29. (<a href="https://doi.org/10.1016/j.neucom.2023.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mammography is an important screening criterion for breast cancer, one of the major diseases causing numerous deaths among female patients. Meanwhile, manual diagnosis of mammography is a time-consuming and labor-consuming job. Mammogram classification based on deep learning plays a vital role in computer-aided diagnosis (CAD) systems to mitigate the pressure on physicians. This paper proposes a learning-based multi-view mammogram classification model that captures long-distance dependence and extracts features of multiple receptive fields. Our model considers global and local features of mammography images using Transformer for global features and the proposed multiplex convolutions module for local features . We evaluate our proposed method on a dataset of mammography images obtained from a hospital in China. The proposed method achieves 90.57\% accuracy and 94.86\% AUC in benign or malignant classification tasks and outperforms other advanced methods for mammogram classification. It is worth noting that the proposed method only requires image-level labels and acts on the whole raw mammogram, which has clinical significance.},
  archive      = {J_NEUCOM},
  author       = {Lili Xia and Jianpeng An and Chao Ma and Hongjun Hou and Yanpeng Hou and Linyang Cui and Xuheng Jiang and Wanqing Li and Zhongke Gao},
  doi          = {10.1016/j.neucom.2023.03.028},
  journal      = {Neurocomputing},
  pages        = {21-29},
  shortjournal = {Neurocomputing},
  title        = {Neural network model based on global and local features for multi-view mammogram classification},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Hessian regularization of deep neural networks: A novel
approach based on stochastic estimators of hessian trace.
<em>NEUCOM</em>, <em>536</em>, 13–20. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a novel regularization method for deep neural networks by penalizing the trace of Hessian. This regularizer is motivated by a recent guarantee bound of the generalization error . We explain its benefits in finding flat minima and avoiding Lyapunov stability in dynamical systems . We adopt the Hutchinson method as a classical unbiased estimator for the trace of a matrix and further accelerate its calculation using a Dropout scheme. Experiments demonstrate that our method outperforms existing regularizers and data augmentation methods, such as Jacobian, Confidence Penalty, Label Smoothing, Cutout, and Mixup. The code is available at https://github.com/Dean-lyc/Hessian-Regularization.},
  archive      = {J_NEUCOM},
  author       = {Yucong Liu and Shixing Yu and Tong Lin},
  doi          = {10.1016/j.neucom.2023.03.017},
  journal      = {Neurocomputing},
  pages        = {13-20},
  shortjournal = {Neurocomputing},
  title        = {Hessian regularization of deep neural networks: A novel approach based on stochastic estimators of hessian trace},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive structure and texture fusion for image
inpainting. <em>NEUCOM</em>, <em>536</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most recent U-Net based models have shown promising results for the challenging tasks in image inpainting field. However, they often generate content with blurred textures and distorted structures due to the lack of semantic consistency and texture continuity in the missing regions. In this paper, we propose to restore the missing areas at both structural and textural levels. Our method is built upon a U-Net structure, which repairs images by extracting semantic information from high to low resolution and then decoding it back to the original image. Specifically, we utilize the high-level semantic features learned in encoder to guide the inpainting of structure-aware features of its adjacent low-level feature map. Meanwhile, low-level feature maps have clearer texture compared with high-level ones, which can be used as a prior for textural repair of high-level feature maps. subsequently, a module is used to fuse the two repaired feature maps (i.e., structure-aware and texture-aware features) reasonably and obtain a feature map with reasonable semantics. Moreover, in order to learn more representative high-level semantics feature, we design the model as a siamese network for contrastive learning . Experiments on practical data show that our method outperforms other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Long Chen and Changan Yuan and Xiao Qin and Wei Sun and Xiaofeng Zhu},
  doi          = {10.1016/j.neucom.2023.03.014},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Contrastive structure and texture fusion for image inpainting},
  volume       = {536},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepONet-grid-UQ: A trustworthy deep operator framework for
predicting the power grid’s post-fault trajectories. <em>NEUCOM</em>,
<em>535</em>, 166–182. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel data-driven method for the reliable prediction of the power grid’s post-fault trajectories, i.e., the power grid’s dynamic response after a disturbance or fault. The proposed method is based on the recently proposed concept of Deep Operator Networks (DeepONets). Unlike traditional neural networks that learn to approximate functions, DeepONets are designed to approximate nonlinear operators, i.e., mappings between infinite-dimensional spaces. Under this operator framework, we design a novel and efficient DeepONet that (i) takes as inputs the trajectories collected before and during the fault and (ii) outputs the predicted post-fault trajectories. In addition, we endow our method with the much-needed ability to balance efficiency with reliable/trustworthy predictions via uncertainty quantification. To this end, we propose and compare two novel methods that enable quantifying the predictive uncertainty. First, we propose a Bayesian DeepONet (B-DeepONet) that uses stochastic gradient Hamiltonian Monte-Carlo to sample from the posterior distribution of the DeepONet trainable parameters. Then, we design a Probabilistic DeepONet (Prob-DeepONet) that uses a probabilistic training strategy to enable quantifying uncertainty at virtually no extra computational cost. Finally, we validate the proposed methods’ predictive power and uncertainty quantification capability using the New York-New England power grid model.},
  archive      = {J_NEUCOM},
  author       = {Christian Moya and Shiqi Zhang and Guang Lin and Meng Yue},
  doi          = {10.1016/j.neucom.2023.03.015},
  journal      = {Neurocomputing},
  pages        = {166-182},
  shortjournal = {Neurocomputing},
  title        = {DeepONet-grid-UQ: A trustworthy deep operator framework for predicting the power grid’s post-fault trajectories},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Universal feature selection tool (UniFeat): An open-source
tool for dimensionality reduction. <em>NEUCOM</em>, <em>535</em>,
156–165. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Universal Feature Selection Tool (UniFeat) is an open-source tool developed entirely in Java for performing feature selection processes in various research areas. It provides a set of well-known and advanced feature selection methods within its significant auxiliary tools. This allows users to compare the performance of feature selection methods. Moreover, due to the open-source nature of UniFeat, researchers can use and modify it in their research, which facilitates the rapid development of new feature selection algorithms.},
  archive      = {J_NEUCOM},
  author       = {Sina Tabakhi and Parham Moradi},
  doi          = {10.1016/j.neucom.2023.03.037},
  journal      = {Neurocomputing},
  pages        = {156-165},
  shortjournal = {Neurocomputing},
  title        = {Universal feature selection tool (UniFeat): An open-source tool for dimensionality reduction},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental label propagation for data sets with imbalanced
labels. <em>NEUCOM</em>, <em>535</em>, 144–155. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Propagation (LP) is a popular graph-based semi-supervised learning algorithm. However, the imbalanced label distribution of labeled data affects the performance of LP, which makes it prefer to allocate more points for the class with majority labels. To get rid of this deficiency, we propose an Incremental Label Propagation (ILP) framework. The ILP framework includes an incremental balance strategy and a multiple results integration method to reduce the uncertainty of balancing labeled data. The incremental balance strategy can gradually add trusted pseudo labels to balance the label distribution so as to reduce the uncertainty caused by pseudo labels. Then, the integration method evaluates the quality of the balanced propagation results obtained from the incremental balance strategy and combines them with different weights to generate a robust outcome. The experimental results show that the proposed framework can combine with different LP methods and effectively solve the performance degradation of the LP algorithm caused by imbalanced labels.},
  archive      = {J_NEUCOM},
  author       = {Yaoxing Li and Liang Bai and Zhuomin Liang and Hangyuan Du},
  doi          = {10.1016/j.neucom.2023.03.016},
  journal      = {Neurocomputing},
  pages        = {144-155},
  shortjournal = {Neurocomputing},
  title        = {Incremental label propagation for data sets with imbalanced labels},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An h∞/h∞ optimization technique to distributed fault
detection for multi-agent systems based on event-triggered mechanism.
<em>NEUCOM</em>, <em>535</em>, 134–143. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an H ∞ / H ∞ H∞/H∞ optimization technique to distributed fault detection (FD) for multi-agent systems (MASs). To simultaneously consider the effects of unknown disturbances and faults in the MASs and event-triggered transmission errors (ETTEs) on the residual signal , a residual generator related to the event-triggered threshold coefficient is designed. The generated residuals achieve the best compromise between robustness to unknown disturbances and sensitivity to faults. The obtained results have a better detection performance by using H ∞ / H ∞ H∞/H∞ optimization technique compared with other optimized schemes. In addition, the applicability of the proposed H ∞ / H ∞ H∞/H∞ optimized distributed FD scheme is verified by the simulation of a vehicle lateral dynamic system.},
  archive      = {J_NEUCOM},
  author       = {Hao Jia and Wenchengyu Ji and Xiangpeng Xie and Shenquan Wang},
  doi          = {10.1016/j.neucom.2023.03.026},
  journal      = {Neurocomputing},
  pages        = {134-143},
  shortjournal = {Neurocomputing},
  title        = {An H∞/H∞ optimization technique to distributed fault detection for multi-agent systems based on event-triggered mechanism},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Field-matching attention network for object detection.
<em>NEUCOM</em>, <em>535</em>, 123–133. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature pyramid network (FPN) is widely used in object detection in order to divide and conquer objects of different scales and to fuse high and low-level features, and it has achieved encouraging achievements in multi-scale object processing. However, due to the mismatch between receptive fields at different stages, the direct fusion of the two features from different receptive fields may be unable to achieve satisfactory results. Moreover, simple lateral connections in FPN may lead to loss of spatial relationships and details. To alleviate these problems, in this paper we propose a field-matching attention network (FMANet) for object detection. Particularly, we first propose a receptive field dilated module (RFDM), which is used to normalize receptive fields between features at different stages to the same scale. Furthermore, to capture the spatial informations and details, we build a dual attention module (DAM) by employing the spatial attention and channel attention. Utilizing both spatial and channel attention mechanisms simultaneously improves performance while maintaining speed. Finally, experimental results reveal that our proposed FMANet with DSPDarkNet-53 as backbone achieves a competitive detection performance.},
  archive      = {J_NEUCOM},
  author       = {Yongsheng Dong and Longchao Shen and Yuanhua Pei and Haotian Yang and Xuelong Li},
  doi          = {10.1016/j.neucom.2023.03.034},
  journal      = {Neurocomputing},
  pages        = {123-133},
  shortjournal = {Neurocomputing},
  title        = {Field-matching attention network for object detection},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive graph regularization and self-expression for
noise-aware feature selection. <em>NEUCOM</em>, <em>535</em>, 107–122.
(<a href="https://doi.org/10.1016/j.neucom.2023.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many traditional unsupervised feature selection algorithms utilize manifold information to mine the local structure of the data. However, the noise existing in the raw data reduces the accuracy of the manifold information of data, which affects the learning effect of the entire algorithm. In order to solve the above problems and more fully find the internal structure inside the data, this paper proposes an adaptive graph regularization and self-expression for noise-aware feature selection (ASNFS). Firstly, the algorithm adopts non-negative matrix factorization to decompose the raw data matrix, and utilizes the low-dimensional matrix generated after decomposition to replace the raw high-dimensional data matrix. This allows the algorithm to reveal some internal structural information of the raw data while reducing the dimensionality of the data. ASNFS also introduces the orthogonal basis clustering with excellent clustering effect, and the interpretability of the algorithm is enhanced. Secondly, in addition to preserving the manifold information in the low-dimensional projection subspace , the algorithm also preserves the manifold information in the non-negative matrix factorization subspace. Meanwhile, the adaptive graph regularization term added to the objective function enables the algorithm to continuously update the similarity matrix . It can effectively remove the noise inside the raw data, and prevent the occurrence of over-fitting phenomenon of the experimental results caused by the fixed similarity matrix . Finally, the similarity matrix retains the local structure information of the data with each iteration, and the results of the feature selection are reused for the construction of the similarity matrix. ASNFS adopts an alternate iterative method to optimize the objective function, which is simple and effective. Then, the algorithm complexity and convergence are analyzed. ASNFS is compared with seven feature selection algorithms on nine datasets, and the experimental results reflect the effectiveness of ASNFS in feature selection.},
  archive      = {J_NEUCOM},
  author       = {Ronghua Shang and Haijing Chi and Yangyang Li and Licheng Jiao},
  doi          = {10.1016/j.neucom.2023.03.036},
  journal      = {Neurocomputing},
  pages        = {107-122},
  shortjournal = {Neurocomputing},
  title        = {Adaptive graph regularization and self-expression for noise-aware feature selection},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Direct approach on fixed-time stabilization and projective
synchronization of inertial neural networks with mixed delays.
<em>NEUCOM</em>, <em>535</em>, 97–106. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article mainly addresses the problems of fixed-time stabilization(FTS) and fixed-time projective synchronization(FTPS) for the chaotic inertial neural networks(INNs) with mixed delays. Unlike the previous works, the results of FTS and FTPS are constructed for the chaotic INNs by means of direct approach instead of reduced-order way, which are more intuitive and concise. Furthermore, by designing effective Lyapunov functionals and novel feedback controllers , we obtain sufficient condition to respectively ensure FTS and FTPS of the delayed chaotic INNs, which settling times of FTS and FTPS do not depend on any initial values of the investigated systems. Until now, very few works are reported on FTS and FTPS for the delayed chaotic INNs via non-reduced-order way. In addition, the proposed FTPS are more generalized than the conventional synchronization and anti-synchronization. At last, some simulation results and applications are listed to expound the correctness of the derived criteria.},
  archive      = {J_NEUCOM},
  author       = {Jing Han and Guici Chen and Leimin Wang and Guodong Zhang and Junhao Hu},
  doi          = {10.1016/j.neucom.2023.03.038},
  journal      = {Neurocomputing},
  pages        = {97-106},
  shortjournal = {Neurocomputing},
  title        = {Direct approach on fixed-time stabilization and projective synchronization of inertial neural networks with mixed delays},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient-coupled cross-patch attention map for weakly
supervised semantic segmentation. <em>NEUCOM</em>, <em>535</em>, 83–96.
(<a href="https://doi.org/10.1016/j.neucom.2023.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most advanced weakly supervised semantic segmentation studies have explored various strategies for refining the class activation mapping (CAM) maps and thus producing pixelwise pseudomasks for training segmentation networks. However, CAM-based approaches suffer from the limited receptive fields of convolutional neural networks (CNNs) when exploring long-range feature dependencies, resulting in incomplete object region detection and inferior segmentation performance. On the other hand, the self-attention mechan ism has proven to be effective in modeling global contexts, providing a potential perspective for producing integral activation maps. Nevertheless, the use of self-attention maps to generate pseudomasks faces significant obstacles, as the attention activations are class-agnostic, locally inconsistent and noisy. To address these issues, we propose a novel end-to-end transformer-based framework, namely the g radient-coupled c ross- p atch a ttention m ap (GC-PAM) . First, the classification score gradients are backpropagated to recover the semantic knowledge of the attention map, which is then used to retrieve the object-relevant patches and object-irrelevant patches. Next, the corresponding object patch attention maps are aggregated through content-adaptive cross-patch coupling to construct comprehensive activation maps, whereas the object-irrelevant maps are employed to suppress the background noise. Subsequently, the resulting object activation maps are used to generate pseudolabels to supervise the segmentation branch. Extensive experiments are conducted to demonstrate the effectiveness of the proposed GC-PAM. Despite its simplicity and computational efficiency, the GC-PAM with the DeiT-S backbone surpasses the existing state-of-the-art approaches on the PASCAL VOC 2012 benchmark (75.3\% val , 74.6\% test ). The results also demonstrate that the GC-PAM is a feasible alternative to CNN-based architectures.},
  archive      = {J_NEUCOM},
  author       = {Zhiyuan Cao and Jiacai Zhang},
  doi          = {10.1016/j.neucom.2023.03.031},
  journal      = {Neurocomputing},
  pages        = {83-96},
  shortjournal = {Neurocomputing},
  title        = {Gradient-coupled cross-patch attention map for weakly supervised semantic segmentation},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-informed neural network algorithm for solving
forward and inverse problems of variable-order space-fractional
advection–diffusion equations. <em>NEUCOM</em>, <em>535</em>, 64–82. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new physics-informed neural network (PINN) algorithm is proposed to solve variable-order space-fractional partial differential equations (PDEs). For the forward problem, PINN algorithm based on a power series expansion is established to solve the space-fractional advection–diffusion equations with variable coefficients in one and two dimensions. The loss function is constructed by taking the coefficients in the power series expansion as the output of the network. The learning rate range is also analyzed to ensure that the error is reduced with respect to the training time. For the inverse problem , a novel dual-network architecture based on neural network parallelism is designed to estimate the order of variable fractional operator. One of the networks outputs the coefficients of the power series expansion, which is a function that depends only on time variables, and the other is fitted to the order of variable fractional operator, which is a function that is related to both space and time variables. Compared with the forward problem, we make more comparisons between the approximated solution and the exact solution at some interior points when constructing the loss function to improve the fitting ability of the inverse problem . The exact solutions are easy to find and can be readily obtained with a fine mesh. Several numerical examples are illustrated with graphs. These results confirm the effectiveness of our method in solving variable-order space-fractional partial differential equations .},
  archive      = {J_NEUCOM},
  author       = {Shupeng Wang and Hui Zhang and Xiaoyun Jiang},
  doi          = {10.1016/j.neucom.2023.03.032},
  journal      = {Neurocomputing},
  pages        = {64-82},
  shortjournal = {Neurocomputing},
  title        = {Physics-informed neural network algorithm for solving forward and inverse problems of variable-order space-fractional advection–diffusion equations},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-stage context refinement network for semantic
segmentation. <em>NEUCOM</em>, <em>535</em>, 53–63. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks have been widely used in image semantic segmentation . However, continuous downsampling operations in convolutional neural networks (such as pooling or convolution with step size) reduce the initial image resolution and lose the spatial details of the image, resulting in blurred image segmentation results. To alleviate this problem, in this paper we propose a multi-stage context refinement network (MCRNet) for semantic segmentation . Specifically, we first construct a Lowest-resolution Chain Context Aggregation (LCCA) module to encode rich semantic information. For obtaining more spatial detail information, we further build a High-resolution Context Attention Refinement (HCAR) module consisting of context feature extraction and context feature refinement. Finally, MCRNet fuses the context information generated by LCCA and HCAR for pixel prediction. Experimental results on three challenging semantic segmentation datasets, namely PASCAL VOC2012, ADE20K and Cityscapes, reveals that our proposed MCRNet is effective.},
  archive      = {J_NEUCOM},
  author       = {Qing Liu and Yongsheng Dong and Xuelong Li},
  doi          = {10.1016/j.neucom.2023.03.006},
  journal      = {Neurocomputing},
  pages        = {53-63},
  shortjournal = {Neurocomputing},
  title        = {Multi-stage context refinement network for semantic segmentation},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised multiple evidence fusion for brain tumor
segmentation. <em>NEUCOM</em>, <em>535</em>, 40–52. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of deep learning-based methods depends mainly on the availability of large-scale labeled learning data. However, obtaining precisely annotated examples is challenging in the medical domain. Although some semi-supervised deep learning methods have been proposed to train models with fewer labels, only a few studies have focused on the uncertainty caused by the low quality of the images and the lack of annotations. This paper addresses the above issues using Dempster-Shafer theory and deep learning : 1) a semi-supervised learning algorithm is proposed based on an image transformation strategy; 2) a probabilistic deep neural network and an evidential neural network are used in parallel to provide two sources of segmentation evidence; 3) Dempster’s rule is used to combine the two pieces of evidence and reach a final segmentation result. Results from a series of experiments on the BraTS2019 brain tumor dataset show that our framework achieves promising results when only some training data are labeled.},
  archive      = {J_NEUCOM},
  author       = {Ling Huang and Su Ruan and Thierry Denœux},
  doi          = {10.1016/j.neucom.2023.02.047},
  journal      = {Neurocomputing},
  pages        = {40-52},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised multiple evidence fusion for brain tumor segmentation},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The coming of age of interpretable and explainable machine
learning models. <em>NEUCOM</em>, <em>535</em>, 25–39. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine-learning-based systems are now part of a wide array of real-world applications seamlessly embedded in the social realm. In the wake of this realization, strict legal regulations for these systems are currently being developed, addressing some of the risks they may pose. This is the coming of age of the concepts of interpretability and explainability in machine-learning-based data analysis, which can no longer be seen just as an academic research problem. In this paper, we discuss explainable and interpretable machine learning as post hoc and ante-hoc strategies to address regulatory restrictions and highlight several aspects related to them, including their evaluation and assessment and the legal boundaries of application.},
  archive      = {J_NEUCOM},
  author       = {P.J.G. Lisboa and S. Saralajew and A. Vellido and R. Fernández-Domenech and T. Villmann},
  doi          = {10.1016/j.neucom.2023.02.040},
  journal      = {Neurocomputing},
  pages        = {25-39},
  shortjournal = {Neurocomputing},
  title        = {The coming of age of interpretable and explainable machine learning models},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Positive–negative equal contrastive loss for semantic
segmentation. <em>NEUCOM</em>, <em>535</em>, 13–24. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contextual information is critical for various computer vision tasks , previous works commonly design plug-and-play modules and structural losses to effectively extract and aggregate the global context. These methods utilize fine-label to optimize the model but ignore that fine-trained features are also precious training resources, which can introduce preferable distribution to hard pixels (i.e., misclassified pixels). Inspired by contrastive learning in unsupervised paradigm, we apply the contrastive loss in a supervised manner and re-design the loss function to cast off the stereotype of unsupervised learning (e.g., imbalance of positives and negatives, confusion of anchors computing). To this end, we propose P ositive- N egative E qual contrastive loss (PNE loss), which increases the latent impact of positive embedding on the anchor and treats the positive as well as negative sample pairs equally. The PNE loss can be directly plugged right into existing semantic segmentation frameworks and leads to excellent performance with neglectable extra computational costs. We utilize a number of classic segmentation methods (e.g., DeepLabV3, HRNetV2, OCRNet, UperNet) and backbone (e.g., ResNet , HRNet, Swin Transformer) to conduct comprehensive experiments and achieve state-of-the-art performance on three benchmark datasets (e.g., Cityscapes, COCO-Stuff and ADE20K). Our code will be publicly available at https://github.com/jingw193/PNE_Loss .},
  archive      = {J_NEUCOM},
  author       = {Jing Wang and Jiangyun Li and Wei Li and Lingfei Xuan and Tianxiang Zhang and Wenxuan Wang},
  doi          = {10.1016/j.neucom.2023.02.028},
  journal      = {Neurocomputing},
  pages        = {13-24},
  shortjournal = {Neurocomputing},
  title        = {Positive–negative equal contrastive loss for semantic segmentation},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view inter-modality representation with progressive
fusion for image-text matching. <em>NEUCOM</em>, <em>535</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, image-text matching has been intensively explored to bridge vision and language. Previous methods explore an inter-modality relationship between an image-text pair from the single-view feature. However, it is difficult to discover all the abundant information based on a single inter-modality relationship. In this paper, a novel Multi-View Inter-Modality Representation with Progressive Fusion (MIRPF) is developed to explore inter-modality relationships from multi-view features. The multi-view strategy provides more complementary and global semantic clues than single-view approaches. In particular, the multi-view inter-modality representation network is constructed to generate multiple inter-modality representations, which provide diverse views to discover the latent image-text relationships. Furthermore, the progressive fusion module is performed to fuse inter-modality features stepwise, which fully uses the inherent complementary between different views. Extensive experiments on Flickr30K and MSCOCO verify the superiority of MIRPF compared with several existing approaches. The code is available at: https://github.com/jasscia18/MIRPF.},
  archive      = {J_NEUCOM},
  author       = {Jie Wu and Leiquan Wang and Chenglizhao Chen and Jing Lu and Chunlei Wu},
  doi          = {10.1016/j.neucom.2023.02.043},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Multi-view inter-modality representation with progressive fusion for image-text matching},
  volume       = {535},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributional reinforcement learning with unconstrained
monotonic neural networks. <em>NEUCOM</em>, <em>534</em>, 199–219. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributional reinforcement learning (RL) approach advocates for representing the complete probability distribution of the random return instead of only modelling its expectation. A distributional RL algorithm may be characterised by two main components, namely the representation of the distribution together with its parameterisation and the probability metric defining the loss. The present research work considers the unconstrained monotonic neural network (UMNN) architecture, a universal approximator of continuous monotonic functions which is particularly well suited for modelling different representations of a distribution. This property enables the efficient decoupling of the effect of the function approximator class from that of the probability metric. The research paper firstly introduces a methodology for learning different representations of the random return distribution (PDF, CDF and QF). Secondly, a novel distributional RL algorithm named unconstrained monotonic deep Q-network (UMDQN) is presented. To the authors’ knowledge, it is the first distributional RL method supporting the learning of three , valid and continuous representations of the random return distribution. Lastly, in light of this new algorithm, an empirical comparison is performed between three probability quasi-metrics, namely the Kullback–Leibler divergence, Cramer distance, and Wasserstein distance. The results highlight the main strengths and weaknesses associated with each probability metric together with an important limitation of the Wasserstein distance.},
  archive      = {J_NEUCOM},
  author       = {Thibaut Théate and Antoine Wehenkel and Adrien Bolland and Gilles Louppe and Damien Ernst},
  doi          = {10.1016/j.neucom.2023.02.049},
  journal      = {Neurocomputing},
  pages        = {199-219},
  shortjournal = {Neurocomputing},
  title        = {Distributional reinforcement learning with unconstrained monotonic neural networks},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic mixed impulsive control and stability for
stochastic functional differential systems with semi-markov jump.
<em>NEUCOM</em>, <em>534</em>, 187–198. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of stochastic mixed impulsive control and stability for stochastic functional differential systems with semi-Markov jump. A new definition of average stochastic impulsive gain is formulated to estimate the stochastic mixed impulsive intensity. Functional systems states are referred to the historical system states in the past time interval rather than in the past time instant of the current time instant. The stability analysis is carried out based on the constructed appropriate Lyapunov functional, Dupire functional Itô’s formula, stochastic analysis theory and graph theory techniques. Moreover, we provide some exponential stability criteria for the investigated systems, which have close relation to not only the topological structures and semi-Markov jump of the functional systems but also average stochastic impulsive gain and stochastic disturbance intensity. Further we put it into practice of a new class of stochastic oscillators systems with semi-Markov jump and the corresponding numerical simulations results are on show to demonstrate the validity of the derived theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Ning Zhang and Huiyu Chen and Wenxue Li},
  doi          = {10.1016/j.neucom.2023.03.010},
  journal      = {Neurocomputing},
  pages        = {187-198},
  shortjournal = {Neurocomputing},
  title        = {Stochastic mixed impulsive control and stability for stochastic functional differential systems with semi-markov jump},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low rank tensor recovery by schatten capped p norm and
plug-and-play regularization. <em>NEUCOM</em>, <em>534</em>, 171–186.
(<a href="https://doi.org/10.1016/j.neucom.2023.02.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low rank tensor recovery (LRTR) problem has attracted wide attentions and researches, and has been applied to various fields. In this paper, we mainly consider the nonconvex relaxtion methods for LRTR. Firstly, we newly propose the tensor schatten capped p ( SC p SCp ) norm as a nonconvex surrogate of the tensor tubal rank, which can provide a closer approximation of the tubal rank compared with some existing nonconvex approximations. Secondly, we introduce an implicit Plug-and-Play (PnP)-based regularization into the nonconvex model to further improve the recovered performance. The proposed model is abbreviated as SC p SCp -PnP. Based on the alternating direction method of multipliers , we propose an efficient algorithm to solve SC p SCp -PnP. The convergence of this algorithm is also provided. Finally, extensive experiments on different kinds of datasets show that our method significantly outperforms several state-of-the-art LRTR methods in terms of both quality metrics and visual effects.},
  archive      = {J_NEUCOM},
  author       = {Lulu Guo and Kaixin Gao and Zheng-Hai Huang},
  doi          = {10.1016/j.neucom.2023.02.052},
  journal      = {Neurocomputing},
  pages        = {171-186},
  shortjournal = {Neurocomputing},
  title        = {Low rank tensor recovery by schatten capped p norm and plug-and-play regularization},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-weight susceptible-infected model for predicting
COVID-19 in china. <em>NEUCOM</em>, <em>534</em>, 161–170. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mutant strains of COVID-19 caused a global explosion of infections, including many cities of China. In 2020, a hybrid AI model was proposed by Zheng et al., which accurately predicted the epidemic in Wuhan. As the main part of the hybrid AI model, ISI method makes two important assumptions to avoid over-fitting. However, the assumptions cannot be effectively applied to new mutant strains. In this paper, a more general method, named the multi-weight susceptible-infected model (MSI) is proposed to predict COVID-19 in Chinese Mainland. First, a Gaussian pre-processing method is proposed to solve the problem of data fluctuation based on the quantity consistency of cumulative infection number and the trend consistency of daily infection number. Then, we improve the model from two aspects: changing the grouped multi-parameter strategy to the multi-weight strategy, and removing the restriction of weight distribution of viral infectivity. Experiments on the outbreaks in many places in China from the end of 2021 to May 2022 show that, in China, an individual infected by Delta or Omicron strains of SARS-CoV-2 can infect others within 3–4 days after he/she got infected. Especially, the proposed method effectively predicts the trend of the epidemics in Xi’an, Tianjin, Henan, and Shanghai from December 2021 to May 2022.},
  archive      = {J_NEUCOM},
  author       = {Jun Zhang and Nanning Zheng and Mingyu Liu and Dingyi Yao and Yusong Wang and Jianji Wang and Jingmin Xin},
  doi          = {10.1016/j.neucom.2023.02.065},
  journal      = {Neurocomputing},
  pages        = {161-170},
  shortjournal = {Neurocomputing},
  title        = {Multi-weight susceptible-infected model for predicting COVID-19 in china},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PseudoBound: Limiting the anomaly reconstruction capability
of one-class classifiers using pseudo anomalies. <em>NEUCOM</em>,
<em>534</em>, 147–160. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rarity of anomalous events, video anomaly detection is typically approached as one-class classification (OCC) problem. Typically in OCC, an autoencoder (AE) is trained to reconstruct the normal only training data with the expectation that, in test time, it can poorly reconstruct the anomalous data. However, previous studies have shown that, even trained with only normal data, AEs can often reconstruct anomalous data as well, resulting in a decreased performance. To mitigate this problem, we propose to limit the anomaly reconstruction capability of AEs by incorporating pseudo anomalies during the training of an AE. Extensive experiments using five types of pseudo anomalies show the robustness of our training mechanism towards any kind of pseudo anomaly. Moreover, we demonstrate the effectiveness of our proposed pseudo anomaly based training approach against several existing state-of-the-art (SOTA) methods on three benchmark video anomaly datasets, outperforming all the other reconstruction-based approaches in two datasets and showing the second best performance in the other dataset.},
  archive      = {J_NEUCOM},
  author       = {Marcella Astrid and Muhammad Zaigham Zaheer and Seung-Ik Lee},
  doi          = {10.1016/j.neucom.2023.03.008},
  journal      = {Neurocomputing},
  pages        = {147-160},
  shortjournal = {Neurocomputing},
  title        = {PseudoBound: Limiting the anomaly reconstruction capability of one-class classifiers using pseudo anomalies},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decoupled spatiotemporal adaptive fusion network for
self-supervised motion estimation. <em>NEUCOM</em>, <em>534</em>,
133–146. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical flow estimation searches for correspondence between two images. In the unsupervised approach, most networks use the feature correlation volume to track the flow, and unsupervised training is achieved through a photometric loss function. However, various complex situations in the natural environment, such as object occlusion, motion blur, the camera being out-of-focus, limited perspective, and variation in lighting conditions, make it challenging to find correspondence accurately, thus complicating unsupervised optical flow estimation. This study decouples the problem into two sub-tasks: one is to search for determined correspondence within a pair of frames, and the other is to cope with mismatched regions due to occlusion, blur, light variation, etc., by introducing more spatial and temporal context information. We propose a multi-frame temporal dynamic model that recursively infers optical flow over causal sequences of arbitrary-length. Our innovative approach introduces information entropy and forward–backward consistency checks to measure the confidence regarding the matching of image pairs. To compensate for low-confidence regions, the proposed network adaptively identifies regions with correspondence confidence and utilizes temporal and spatial smoothness assumptions for motion re-prediction. Paired with well-designed simulation of dynamic occlusion pseudo-labels and scene variation, our model can learn a variety of complex scenes in a multi-frame environment to optimize low-confidence regions efficiently. Experimental results demonstrate that the proposed model is able to run at high speed in real-time tasks while maintaining high accuracy, thus achieving state-of-the-art results on Sintel Clean and Final benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Zitang Sun and Zhengbo Luo and Shin’ya Nishida},
  doi          = {10.1016/j.neucom.2023.03.012},
  journal      = {Neurocomputing},
  pages        = {133-146},
  shortjournal = {Neurocomputing},
  title        = {Decoupled spatiotemporal adaptive fusion network for self-supervised motion estimation},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wind power prediction based on periodic characteristic
decomposition and multi-layer attention network. <em>NEUCOM</em>,
<em>534</em>, 119–132. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the wind power characteristics of temporality, periodicity and complexity, the periodic law of short-term and long-term repetitive patterns is studied, and an integrated dual-channel prediction model is proposed. A practical periodic characteristic extracting strategy is designed to show the hidden periodic law of the original signal. Combining the grid search algorithm with the variation trend of amplitude/period, the optimal periodic step is determined. Based on the above analysis, the original signal is decomposed into temporal and periodic components. Then the temporal attention network and the encoder-decoder attention network are schemed out to dispose the two components respectively. Finally, the linear regression attention network is adopted to realize data fitting. The integrated forecasting framework can deal with the long-term and short-term dependencies of the original data at the same time, and ensure the rapid convergence of training process, thereby improve the prediction accuracy and stability. The multi-dimensional experimental verification is carried out through the comparison of evaluation indicators, prediction trends, scatter plots and box plots.},
  archive      = {J_NEUCOM},
  author       = {Xuechao Liao and Zhenxing Liu and Xiujuan Zheng and Zuowei Ping and Xin He},
  doi          = {10.1016/j.neucom.2023.02.061},
  journal      = {Neurocomputing},
  pages        = {119-132},
  shortjournal = {Neurocomputing},
  title        = {Wind power prediction based on periodic characteristic decomposition and multi-layer attention network},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human attention based movie summarization: Dataset and
baseline model. <em>NEUCOM</em>, <em>534</em>, 106–118. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A movie summarization model can automatically edit a condensed version of a movie by selecting keyframes. Some previous works have proposed some movie summarizers based on traditional methods or recent neural networks and achieved some progress. Despite the demonstrated successes, there are some limitations: (1) previous works mainly resort to hand-crafted heuristics and most of them are unsupervised; (2) currently there is no publicly suitable dataset available for the supervised movie summarization; (3) existing works only focus on the movies themselves while neglecting the audiences, who have the most to say in which part of the movie is more attractive. To break through the aforementioned limitations, we establish a movie summarization dataset Movie50 and propose a novel human attention based annotation pipeline. Furthermore, we propose the A/V-MSNet, an audiovisual neural network that takes advantage of spatio-temporal visual and auditory information to better simulate human attention as well as exploit more plentiful information. The network is designed, trained end-to-end, and evaluated on the public dataset and our dataset. Extensive experiments demonstrate the superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Defang Zhao and Dandan Zhu and Xiongkuo Min and Jiaomin Yue and Kaiwei Zhang and Qiangqiang Zhou and Guangtao Zhai and Xiaokang Yang},
  doi          = {10.1016/j.neucom.2023.03.013},
  journal      = {Neurocomputing},
  pages        = {106-118},
  shortjournal = {Neurocomputing},
  title        = {Human attention based movie summarization: Dataset and baseline model},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving proximal policy optimization with alpha
divergence. <em>NEUCOM</em>, <em>534</em>, 94–105. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proximal policy optimization (PPO) is a recent advancement in reinforcement learning, which is formulated as an unconstrained optimization problem including two terms: accumulative discount return and Kullback–Leibler (KL) divergence. Currently, there are three PPO versions: primary, adaptive, and clipping. The most widely used PPO algorithm is the clipping version, in which the KL divergence is replaced by a clipping function to measure the difference between two policies indirectly. In this paper, we revisit this primary PPO and improve it in two aspects. One is to reformulate it as a linearly combined form to control the trade-off between two terms. The other is to substitute a parametric alpha divergence for KL divergence to measure the difference of two policies more effectively. This novel PPO variant is referred to as alphaPPO in this paper. Experiments on six benchmark environments verify the effectiveness of our alphaPPO, compared with clipping and combined PPOs.},
  archive      = {J_NEUCOM},
  author       = {Haotian Xu and Zheng Yan and Junyu Xuan and Guangquan Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2023.02.008},
  journal      = {Neurocomputing},
  pages        = {94-105},
  shortjournal = {Neurocomputing},
  title        = {Improving proximal policy optimization with alpha divergence},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep domain-invariant learning for facial age estimation.
<em>NEUCOM</em>, <em>534</em>, 86–93. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies in facial age estimation can achieve promising performance when the training and test sets have a similar condition. However, these methods often fail to maintain performance and show significant degradation when encountering unseen domains. Therefore, we propose a novel method named Deep Domain-Invariant Learning (DDIL) to solve the Out-of-Distribution (OOD) generalization problem for facial age estimation. The proposed DDIL consists of the domain-invariant and style-invariant modules. The former extracts domain-specific features and trains a domain-invariant feature extractor by reducing the covariance discrepancy among features from different domains, while the latter leverages style randomization to overcome CNN’s induction bias towards styles. Consolidating these two modules, our DDIL can effectively decrease the influence of domain discrepancy. Extensive experiments on multiple age benchmark datasets under the Leave-One-Domain-Out Cross-Validation setting indicate superior performance in tackling age estimation generalization.},
  archive      = {J_NEUCOM},
  author       = {Zenghao Bao and Yutian Luo and Zichang Tan and Jun Wan and Xibo Ma and Zhen Lei},
  doi          = {10.1016/j.neucom.2023.02.037},
  journal      = {Neurocomputing},
  pages        = {86-93},
  shortjournal = {Neurocomputing},
  title        = {Deep domain-invariant learning for facial age estimation},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph over-parameterization: Why the graph helps the
training of deep graph convolutional network. <em>NEUCOM</em>,
<em>534</em>, 77–85. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies show that gradient descent can train a deep neural network (DNN) to achieve small training and test errors when the DNN is sufficiently wide. This result applies to various over-parameterized neural network models including fully-connected neural networks and convolutional neural networks. However, existing theory does not apply to graph convolutional networks (GCNs), as GCNs is built according to the topological structures of the data. It has been empirically observed that GCNs can outperform vanilla neural networks when the underlying graph captures geometric information of the data. However, there is few theoretical justification of such observation. In this paper, we establish theoretical guarantees of the high-probability convergence of gradient descent for training over-parameterized GCNs. Specifically, we introduce a novel measurement of the relation between the graph and the data, called the “graph disparity coefficient”, and show that the convergence of GCN is faster when the graph disparity coefficient is smaller. Our analysis provides novel insights into how the graph convolution operation in a GCN helps training, and provides useful guidance for GCN training in practice.},
  archive      = {J_NEUCOM},
  author       = {Yucong Lin and Silu Li and Jiaxing Xu and Jiawei Xu and Dong Huang and Wendi Zheng and Yuan Cao and Junwei Lu},
  doi          = {10.1016/j.neucom.2023.02.054},
  journal      = {Neurocomputing},
  pages        = {77-85},
  shortjournal = {Neurocomputing},
  title        = {Graph over-parameterization: Why the graph helps the training of deep graph convolutional network},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Commonsense knowledge graph-based adapter for aspect-level
sentiment classification. <em>NEUCOM</em>, <em>534</em>, 67–76. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention- and graph-based models are widely applied to existing aspect-level sentiment classification (ALSC) tasks. In spite of the effectiveness, most of these studies ignore commonsense knowledge of aspects. When sentences have the same syntactic structures and opinion words, the sentiment polarities toward aspects can be different. Moreover, no easy and flexible method has been proposed to infuse knowledge into existing ALSC models. For these reasons, we propose a novel commonsense knowledge graph-based adapter (CKGA) for ALSC. Firstly, we link aspects to a knowledge graph end extract an aspect-related sub-graph. Then, a pre-trained language model and the knowledge graph embedding are utilized to encode the commonsense knowledge of entities based on which the corresponding knowledge is extracted with a graph convolutional networks. Specifically, CKGA is an adapter-based model which can be added to existing models in a simple way without modifying the original models. Experimental results on three benchmark datasets illustrate that state-of-the-art ALSC models can be significantly improved with CKGA. Thus, CKGA can leverage external knowledge to enhance the sentiment delivery on the task of ALSC.},
  archive      = {J_NEUCOM},
  author       = {Guojun Lu and Haibo Yu and Zehao Yan and Yun Xue},
  doi          = {10.1016/j.neucom.2023.03.002},
  journal      = {Neurocomputing},
  pages        = {67-76},
  shortjournal = {Neurocomputing},
  title        = {Commonsense knowledge graph-based adapter for aspect-level sentiment classification},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implicit and explicit attention mechanisms for zero-shot
learning. <em>NEUCOM</em>, <em>534</em>, 55–66. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-Shot Learning (ZSL) aims to recognise unseen object classes which are not observed during the training phase. Most of the existing methods on ZSL focus on learning a compatibility function between the image representation and class semantic information. Few others concentrate on learning image representation by combining local and global features. However, the existing approaches still fail to address the bias issue towards the seen classes. This paper proposes implicit and explicit attention mechanisms to address the existing bias problem in generalised ZSL models. We formulate the implicit attention mechanism with a self-supervised image angle rotation task, which focuses on specific image features aiding in solving the task. On the other hand, the explicit attention mechanism is composed via the consideration of a multi-headed self-attention mechanism in the Vision Transformer model, which learns to attend important image locations and map global image features to semantic space during the training stage. We have conducted comprehensive experiments on three popular benchmarks: AWA2, CUB and SUN, where the effectiveness of our proposed attention mechanisms is shown in both discriminative and generative settings. Our extensive experiments show that our method has achieved state-of-the-art performance obtaining the highest harmonic mean on all three datasets, which is very encouraging to consider the ViT-based attention mechanisms for ZSL tasks in the future.},
  archive      = {J_NEUCOM},
  author       = {Faisal Alamri and Anjan Dutta},
  doi          = {10.1016/j.neucom.2023.03.009},
  journal      = {Neurocomputing},
  pages        = {55-66},
  shortjournal = {Neurocomputing},
  title        = {Implicit and explicit attention mechanisms for zero-shot learning},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view clustering via matrix factorization assisted
k-means. <em>NEUCOM</em>, <em>534</em>, 45–54. (<a
href="https://doi.org/10.1016/j.neucom.2023.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization based multi-view clustering algorithms has attracted much attention in recent years due to the strong interpretability and efficient implementation. In general, these approaches firstly compute the coefficient matrices of each data views, and learn a consensus matrix simultaneously. By applying the classical clustering techniques , such as k -means, on the consensus matrix, the final partition can be easily obtained. However, most of previous models work in a “step-by-step” manner, which cannot perform multi-view matrix factorization and clustering label generation simultaneously, leading to degenerated performance. In this paper, we propose a novel “one-pass” method, which integrates matrix factorization and k -means into a unified framework, named multi-view clustering via matrix factorization assisted k -means (MFK). In MFK, the generation of cluster indicator matrix and coefficient matrix learning can boost each other, leading to final improved clustering performance. Furthermore, we adopt a graph Laplacian regularization on the indicator matrix in order to capture the intrinsic geometric structure of original data. An alternating optimization strategy is designed to solve the resultant optimization problem and extensive experiments on six publicly datasets are conducted to demonstrate the superiority and effectiveness of the proposed MFK model.},
  archive      = {J_NEUCOM},
  author       = {Xiao Zheng and Chang Tang and Xinwang Liu and En Zhu},
  doi          = {10.1016/j.neucom.2023.03.004},
  journal      = {Neurocomputing},
  pages        = {45-54},
  shortjournal = {Neurocomputing},
  title        = {Multi-view clustering via matrix factorization assisted k-means},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An anti-interference dynamic integral neural network for
solving the time-varying linear matrix equation with periodic noises.
<em>NEUCOM</em>, <em>534</em>, 29–44. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve a time-varying linear matrix equation with periodic noises, an anti-interference dynamic integral neural network (AI-DINN) is proposed. Based on an indefinite unbounded vector/matrix-type error function, the proposed AI-DINN includes an integral structure, a recursive structure , and an adjustment module. It has the excellent ability to overcome the interference of periodic noises. This paper theoretically proves the convergence and robustness of the proposed AI-DINN for solving the time-varying linear matrix equation with the interference of periodic noises. Computer simulation results verify that the proposed AI-DINN method based on different activation functions can achieve convergence within limited time with the interferences of different periodic noises. In addition, the proposed AI-DINN with different activation functions has its own advantages with the interference of different types of periodic noises. Furthermore, comparative simulation experiments verify that the proposed AI-DINN has better convergence and anti-interference performance compared with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Zhang and Lihang Ye and Bozhao Chen and Yamei Luo},
  doi          = {10.1016/j.neucom.2023.02.033},
  journal      = {Neurocomputing},
  pages        = {29-44},
  shortjournal = {Neurocomputing},
  title        = {An anti-interference dynamic integral neural network for solving the time-varying linear matrix equation with periodic noises},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Determination of influential nodes based on the communities’
structure to maximize influence in social networks. <em>NEUCOM</em>,
<em>534</em>, 18–28. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing development of social networks, they have turned into important research platforms. Influence maximization is one of the most important research issues in the field of social networks. This problem detects influential k-node with the greatest influence spread. The influence maximization faces two important challenges, time efficiency and optimal selection of seed nodes. In order to solve such challenges, we propose an algorithm based on optimal pruning and scoring adjustment, which is called IMBC for short. The IMBC (Influence Maximization Based on Community structure) algorithm uses optimal pruning and a minimum of dominating nodes to improve time efficiency. In addition, for optimal selection of seed nodes, the IMBC algorithm modulates the scores of nodes with a high Rich-Club coefficient. In order to select influential nodes , we first select an optimal set using the minimum dominating nodes and node scores, with the aim of optimal pruning in influence spread calculations. Because large-scale social networks have many nodes, optimal pruning reduces computational overhead. Then, the seed nodes are selected based on the scoring adjustment. Scoring adjustment is done to avoid the Rich Club phenomenon because avoiding this phenomenon causes a large amount of diffusion in social networks. The experimental results show that the proposed algorithm performs better than the algorithms presented in recent years in influence spread and runtime. Therefore, the IMBC algorithm is a balance between quality and efficiency. Also, in the PGP dataset results, the PHG algorithm with as much as a 5.08\% increase in influence spread, and the runtime has decreased by 97\%.},
  archive      = {J_NEUCOM},
  author       = {Farzaneh Kazemzadeh and Ali Asghar Safaei and Mitra Mirzarezaee and Sanaz Afsharian and Houman Kosarirad},
  doi          = {10.1016/j.neucom.2023.02.059},
  journal      = {Neurocomputing},
  pages        = {18-28},
  shortjournal = {Neurocomputing},
  title        = {Determination of influential nodes based on the communities’ structure to maximize influence in social networks},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bounding information leakage in machine learning.
<em>NEUCOM</em>, <em>534</em>, 1–17. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, it has been shown that Machine Learning models can leak sensitive information about their training data. This information leakage is exposed through membership and attribute inference attacks. Although many attack strategies have been proposed, little effort has been made to formalize these problems. We present a novel formalism, generalizing membership and attribute inference attack setups previously studied in the literature and connecting them to memorization and generalization. First, we derive a universal bound on the success rate of inference attacks and connect it to the generalization gap of the target model. Second, we study the question of how much sensitive information is stored by the algorithm about its training set and we derive bounds on the mutual information between the sensitive attributes and model parameters. Experimentally, we illustrate the potential of our approach by applying it to both synthetic data and classification tasks on natural images. Finally, we apply our formalism to different attribute inference strategies, with which an adversary is able to recover the identity of writers in the PenDigits dataset.},
  archive      = {J_NEUCOM},
  author       = {Ganesh Del Grosso and Georg Pichler and Catuscia Palamidessi and Pablo Piantanida},
  doi          = {10.1016/j.neucom.2023.02.058},
  journal      = {Neurocomputing},
  pages        = {1-17},
  shortjournal = {Neurocomputing},
  title        = {Bounding information leakage in machine learning},
  volume       = {534},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed nash equilibrium seeking over strongly connected
switching networks. <em>NEUCOM</em>, <em>533</em>, 206–213. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Nash equilibrium seeking over networks of N players has been studied under the assumption that the network is static and strongly connected or switching and every time strongly connected. In this paper, we further consider the case where the network is jointly strongly connected. Since a jointly strongly connected network can be disconnected at any time instant, the existing approach cannot handle such a case. Like the literature, assuming the pseudogradient dynamics has a globally exponentially stable Nash equilibrium , we first establish a distributed estimator for actions of all players over jointly strongly connected networks. Then we compose the pseudogradient dynamics with the distributed estimator to obtain an extended gradient system with N + 1 N+1 subsystems. Under the assumption that the pseudogradient of the game is strongly monotone and Lipschitz continuous, we show that, starting from any initial condition, the state of every subsystem of the extended gradient system will exponentially converge to the Nash equilibrium of the game concerned.},
  archive      = {J_NEUCOM},
  author       = {Xiongnan He and Jie Huang},
  doi          = {10.1016/j.neucom.2023.02.064},
  journal      = {Neurocomputing},
  pages        = {206-213},
  shortjournal = {Neurocomputing},
  title        = {Distributed nash equilibrium seeking over strongly connected switching networks},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). SOR-TC: Self-attentive octave ResNet with temporal
consistency for compressed video action recognition. <em>NEUCOM</em>,
<em>533</em>, 191–205. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling and recognizing video activities from videos are key parts of many promising applications such as visual surveillance, human–computer interaction, and video summarization. However, current approaches mainly suffer from two issues: (a) Short-term local and global spatial features are not well represented. The spatial redundancy and dependency have not been well considered on CNN-based action recognition, which may result in a further increase in both memory and computation cost. (b) Long-term temporal consistency is not well captured. The action consistency across multiple clips has been ignored in video-level action recognition approaches. To address these two issues, we propose a S elf-Attentive O ctave R esNet with T emporal C onsistency (SOR-TC) for compressed video action recognition to better capture the short-term and long-term features in video and improve the efficiency and effectiveness of action recognition. In addition, this paper introduces a consistency hypothesis that adjacent clips should predict similar actions. So the consistency loss function is designed to learn the correlation of clips. Finally, extensive experimental results on two benchmark datasets HMDB-51 and UCF-101 verify the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Junsan Zhang and Xiaomin Wang and Yao Wan and Leiquan Wang and Jian Wang and Philip S. Yu},
  doi          = {10.1016/j.neucom.2023.02.045},
  journal      = {Neurocomputing},
  pages        = {191-205},
  shortjournal = {Neurocomputing},
  title        = {SOR-TC: Self-attentive octave ResNet with temporal consistency for compressed video action recognition},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CAML: Contextual augmented meta-learning for cold-start
recommendation. <em>NEUCOM</em>, <em>533</em>, 178–190. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of recommendation engines is challenged by the cold-start issues. Classical recommendation techniques have limited capability to address this problem because the underlying machine learning models are data-thirsty. Conversely, the recent success of meta-learning attracted a lot of attention due to few-shot learning capabilities which can be employed to accommodate new tasks even when there are few data samples for training. Most of the meta-learning recommendation models adopt model-agnostic meta-learning to initialize parameters that may lead to stuck into local optima instead of global optima for some users. To leverage the learning process, we propose a Contextually Augmented Meta-Learning recommender system (CAML). The proposed method augments the contextual features into a meta-learning model which considerably improves the tasks adaptation capability. We constructed a Data Augmentation Unit (DAU) that used a hybrid similarity to augment data samples of similar neighbors. The augmented samples are then forwarded to a Meta-Learner (MetaL) to learn user preferences and generate relevant recommendations. Additionally, we highlighted that the proposed method is generalized and can be adapted for various meta-learning-based recommendation models. We validate our proposal on three benchmark datasets for both ranking and rating prediction perspectives. The experimental outcomes prove the significance of our proposal over the state-of-the-art recommendation methods.},
  archive      = {J_NEUCOM},
  author       = {Israr ur Rehman and Waqar Ali and Zahoor Jan and Zulfiqar Ali and Hui Xu and Jie Shao},
  doi          = {10.1016/j.neucom.2023.02.051},
  journal      = {Neurocomputing},
  pages        = {178-190},
  shortjournal = {Neurocomputing},
  title        = {CAML: Contextual augmented meta-learning for cold-start recommendation},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph representation learning via redundancy reduction.
<em>NEUCOM</em>, <em>533</em>, 161–177. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, self-supervised learning methods based on mutual information maximization have achieved remarkable success on graph data tasks. However, most of them heavily rely on a large number of negative samples, which is computationally expensive. These methods also fail to extract the semantic cluster information of the data. To overcome these problems, we propose a novel self-supervised approach called G raph R epresentation Learing via R edundancy R eduction (GRRR) to learn node representations based on the redundancy-reduction principle . The proposed GRRR preserves as much topological information of the graph as possible, and minimizes the redundancy of representation in terms of node instance and semantic cluster information. Specifically, we first design three graph data augmentation strategies to construct two augmented views. Then, to filter the redundant information in each augmented view, we propose the self-redundancy reduction module which implements the structural reconstruction. Finally, we propose the joint redundancy reduction module to further filter undesirable information via a cross-view approach. It preserves the most essential instance features and semantic cluster information by maximizing the agreement across different views not only on node instance features but also on cluster assignments. Results on several benchmark datasets show that GRRR outperforms state-of-the-art methods in downstream node classification , link prediction, and node clustering tasks .},
  archive      = {J_NEUCOM},
  author       = {Mengyao He and Qingqing Zhao and Han Zhang and Chuanze Kang and Wei Li and Mingjing Han},
  doi          = {10.1016/j.neucom.2023.02.062},
  journal      = {Neurocomputing},
  pages        = {161-177},
  shortjournal = {Neurocomputing},
  title        = {Graph representation learning via redundancy reduction},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introducing multi-dimensional hierarchical classification:
Characterization, solving strategies and performance measures.
<em>NEUCOM</em>, <em>533</em>, 141–160. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification problems where there exist multiple class variables that need to be jointly predicted are known as Multi-dimensional classification problems. If the labels of these class variables are organized as hierarchies, we can take advantage of specific strategies designed for the Hierarchical classification paradigm. In this paper we present the Multi-dimensional hierarchical classification (MDHC) paradigm, a result of the combination of Multi-dimensional and Hierarchical classification paradigms. We propose four MDHC learning strategies which are designed to exploit the particularities of this new paradigm, combining characteristics of Multi-dimensional and Hierarchical classification strategies. Along with these strategies, we present a framework for classifier comparison in which we use a set of performance measures specifically designed for MDHC, and a procedure to create MDHC synthetic scenarios. Using this framework and the performance measures presented, we study how characteristics of the MDHC problems influence the performance of the different MDHC strategies proposed, and compare them to other non-MDHC strategies.},
  archive      = {J_NEUCOM},
  author       = {C. Montenegro and R. Santana and J.A. Lozano},
  doi          = {10.1016/j.neucom.2023.02.050},
  journal      = {Neurocomputing},
  pages        = {141-160},
  shortjournal = {Neurocomputing},
  title        = {Introducing multi-dimensional hierarchical classification: Characterization, solving strategies and performance measures},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial relationship recognition via heterogeneous
representation: A review. <em>NEUCOM</em>, <em>533</em>, 116–140. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial relationship between objects in an image can help to gain a deep understanding of the image. At present, spatial relationship recognition has received more and more attentions and has been applied to many computer vision tasks . Although many substantial studies have been continuing, there is few review for investigating spatial relationship recognition. Therefore, we make this comprehensive survey that covers major literatures in spatial relationship recognition. Especially, we focus on spatial description which occurs in forms of spatial descriptors, definitional descriptions, probabilistic descriptions, and model descriptions. We analyse its impacts on the state-of-the-art research on spatial relationship recognition in recent years. In this survey, we introduce a classification of methodologies, and show strengths and weaknesses of methods in each category. Besides, we compare the performance of methods and algorithms most of which are learning styled and based on popular public datasets. In addition, many future research directions are also discussed, such as technology trends, and dataset creation, etc.},
  archive      = {J_NEUCOM},
  author       = {Yang Wang and Huilin Peng and Yiwei Xiong and Haitao Song},
  doi          = {10.1016/j.neucom.2023.02.053},
  journal      = {Neurocomputing},
  pages        = {116-140},
  shortjournal = {Neurocomputing},
  title        = {Spatial relationship recognition via heterogeneous representation: A review},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VS-CAM: Vertex semantic class activation mapping to
interpret vision graph neural network. <em>NEUCOM</em>, <em>533</em>,
104–115. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional neural network (GCN) has drawn increasing attention and attained good performance in various computer vision tasks , however, there is a lack of a clear interpretation of GCN’s inner mechanism. For standard convolutional neural networks (CNNs), class activation mapping (CAM) methods are commonly used to visualize the connection between CNN’s decision and image region by generating a heatmap. Nonetheless, such heatmap usually exhibits semantic-chaos when these CAMs are applied to GCN directly. In this paper, we proposed a novel visualization method particularly applicable to GCN, Vertex Semantic Class Activation Mapping (VS-CAM). VS-CAM includes two independent pipelines to produce a set of semantic-probe maps and a semantic-base map, respectively. Semantic-probe maps are used to detect the semantic information from the semantic-base map to aggregate a semantic-aware heatmap. Qualitative results show that VS-CAM can obtain heatmaps where the highlighted regions match the objects much more precisely than CNN-based CAM. The quantitative evaluation further demonstrates the superiority of VS-CAM.},
  archive      = {J_NEUCOM},
  author       = {Zhenpeng Feng and Xiyang Cui and Hongbing Ji and Mingzhe Zhu and Ljubiša Stanković},
  doi          = {10.1016/j.neucom.2023.02.057},
  journal      = {Neurocomputing},
  pages        = {104-115},
  shortjournal = {Neurocomputing},
  title        = {VS-CAM: Vertex semantic class activation mapping to interpret vision graph neural network},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ContextAVO: Local context guided and refining poses for deep
visual odometry. <em>NEUCOM</em>, <em>533</em>, 86–103. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based monocular visual odometry (VO) has lately drawn significant attention for its robustness to camera parameters and environmental variations. The correlation of ego-motion in the local time dimension, denoted as the local context, is crucial for alleviating accumulated errors of VO problems. Unlike most current learning-based methods, our approach, called ContextAVO, focuses on the effectiveness of local contexts to improve the estimation recovered from consecutive multiple optical flow snippets. To retain the pose consistency in the temporal domain, we design the Context-Attention Refining component to adaptively ameliorate current inference by exploiting the continuity of camera motions and aligning corresponding observations with local contexts. Besides, we employ the multi-length window to make ContextAVO more suitable for general scenarios and less dependent on the fixed length of the input snippet. Extensive experiments on outdoor KITTI, Malaga, ApolloScape, and indoor TUM RGB-D datasets have demonstrated that our approach efficiently produces competitive results against classic algorithms. It outperforms state-of-the-art methods by large margins, improving up to 7.40\% and 48.56\% for translational and rotational estimation, respectively.},
  archive      = {J_NEUCOM},
  author       = {Rujun Song and Ran Zhu and Zhuoling Xiao and Bo Yan},
  doi          = {10.1016/j.neucom.2023.02.014},
  journal      = {Neurocomputing},
  pages        = {86-103},
  shortjournal = {Neurocomputing},
  title        = {ContextAVO: Local context guided and refining poses for deep visual odometry},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A metric-learning method for few-shot cross-event rumor
detection. <em>NEUCOM</em>, <em>533</em>, 72–85. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of social media, quickly detecting rumors on social media has become vitally crucial. However, there exists the following challenges. 1) Rumors are always flooded with time-critical events, where large-scale labeled datasets are difficult to obtain. 2) Although historic events have sufficient labels, the performance of models tends to degrade on the newly emergent events due to event difference shift. Facing these challenges, in this study, we attempt to leverage the idea of few-shot learning which aims to quickly acquire knowledge on unseen events with a few labeled samples by sufficiently learning from old events with a number of verified samples. Different from few-shot learning tasks in the literature, rumors in the same class of different events (no matter historical events or new events) are likely to contain coincident features in their embedding space. Therefore, we validate two classical metric learning methods, the prototypical network (PN) and the relation network (RN) which are able to capture the class-level representations in few-shot learning settings, to explore the effectiveness of metric learning methods for cross-event rumor detection. Our proposed model contains two stages corresponding to Base-Classifier pre-trained module and Base-Meta training module . The Base-Classifier pre-trained module is a classification model trained on old events. Then its last layer for class prediction is removed and the remains of the module is viewed as an encoder. The Base-Meta training module fine-tunes the encoder, meanwhile trains a selected metric learning model with episodic training strategies on old events. Empirical tests on novel events have showed that our model can outperform the state-of-the-art baseline models on the benchmark cross-event rumor datasets PHEME5 and PHEME9. What’s more, the model can improve the performance of cross-data rumor detection, where the model is trained on Twitter15, but tested on Twitter16.},
  archive      = {J_NEUCOM},
  author       = {Hongyan Ran and Caiyan Jia and Jian Yu},
  doi          = {10.1016/j.neucom.2023.02.044},
  journal      = {Neurocomputing},
  pages        = {72-85},
  shortjournal = {Neurocomputing},
  title        = {A metric-learning method for few-shot cross-event rumor detection},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An active memristor based rate-coded spiking neural network.
<em>NEUCOM</em>, <em>533</em>, 61–71. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic computing is a novel computing paradigm that aims to mimic the behavior of biological neural networks for efficiently solving complex problems. While CMOS based neurons and synapses have been developed, they are limited in their ability to demonstrate bio-realistic dynamics. This, coupled with the fact that a huge number of these individual devices are required to build neurons and synapses, limits the scaling and power efficiency of such systems. A viable answer to this problem is neuromemristive systems that are based on memristor devices. These devices exhibit physical behaviors that can be related to the bio-physical dynamics of synapses and neurons. In this paper, a rate-coded all memristive “spiking neural network” (SNN) is presented. The proposed SNN is built with an active memristor neuron based on vanadium dioxide (VO 2 ) coupled with a non-volatile memristor synapse. The results are validated by first simulating spiking versions of two Boolean functions viz., AND and XOR gates in SPICE. With features extracted from the small neural nets, a large-scale 3-layer spiking neural network is then simulated in Python which yields a validation accuracy of 87\% on the MNIST dataset of handwritten digits. One of the prime features of this work is the realization of the XOR function using a single neuron which is not possible without the use of 2-layers of neurons in traditional neural networks. Another significant contribution is the utilization of a gradient-based learning approach for online training of a large-scale SNN. For this, we use the inherent activation function (Sigmoid/ReLU) of the proposed neuron design.},
  archive      = {J_NEUCOM},
  author       = {Aabid Amin Fida and Farooq A. Khanday and Sparsh Mittal},
  doi          = {10.1016/j.neucom.2023.02.038},
  journal      = {Neurocomputing},
  pages        = {61-71},
  shortjournal = {Neurocomputing},
  title        = {An active memristor based rate-coded spiking neural network},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic heterogeneous graph representation learning with
neighborhood type modeling. <em>NEUCOM</em>, <em>533</em>, 46–60. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning aims to learn the representations of graph structured data in low-dimensional space, and has a wide range of applications in graph analysis tasks. Real-world networks are generally heterogeneous and dynamic, which contain multiple types of nodes and edges, and the graph may evolve at a high speed over time. The complex heterogeneous properties and rapidly evolving graph structures make it difficult to learn high-quality graph representations for dynamic heterogeneous graphs. Currently, studies concentrated on representation learning of temporal heterogeneous networks are insufficient. Existing methods either rely on meta-paths where the embedding quality heavily depending on experts’ selection, or use network snapshots where the fine-grained temporal information cannot be captured. In this paper, we propose a novel graph neural network model–node signature based T emporal H eterogeneous G raph At tention Network, termed as THGAT , for learning the representations of dynamic heterogeneous networks . THGAT improves the aggregation way of neighborhood information, and pays attention to the enlightenment of the importance of neighbor nodes by heterogeneous information and temporal information that cannot be ignored in the network. We also innovatively propose three node signature methods for encoding the heterogeneous information of the nodes and use the time encoding technique suitable for real-time networks to directly represent the temporal information, so as to overcome the limitations of existing methods. We conduct experiments on four real-world datasets, and the results demonstrate that THGAT improves the representation learning quality significantly, in aspects of link prediction, node classification , and node clustering, compared to the state-of-the-art methods. To make the work more complete, we also analyze the applicable scenarios of the three node signature methods through experiments, respectively.},
  archive      = {J_NEUCOM},
  author       = {Lin Zhang and Jiawen Guo and Qijie Bai and Chunyao Song},
  doi          = {10.1016/j.neucom.2023.02.060},
  journal      = {Neurocomputing},
  pages        = {46-60},
  shortjournal = {Neurocomputing},
  title        = {Dynamic heterogeneous graph representation learning with neighborhood type modeling},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consecutive layer collaborative filter similarity for
differentiable neural network pruning. <em>NEUCOM</em>, <em>533</em>,
35–45. (<a href="https://doi.org/10.1016/j.neucom.2023.02.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning is proven to be an effective strategy in model compression . However, convolutional filter pruning methods usually pay all attention to evaluating filters’ importance at a single layer, ignoring their collaborative relationship with corresponding filters of the next layer. In this paper, we propose novel consecutive layer collaborative filter similarity (CLCS) to make full use of the complete filter information and learn binary selection vectors to prune the redundant filters automatically. With learned selection vectors, the pruning ratio of each layer can be determined, and we can also calculate the FLOPs of the candidate pruned network at the current stage. Under the accuracy constraint and the FLOPs constraint, the selection vectors of each layer can be optimized to achieve a better trade-off between accuracy and efficiency. Extensive experiments on CIFAR-10 and ImageNet with multiple networks demonstrate the effectiveness of our proposed method. Specifically, we obtain 54.29\% and 67.33\% FLOPs reduction with 0.01\% and 0.09\% accuracy improvement for ResNet-56 and ResNet-110 on CIFAR-10, respectively. On ImageNet, we reduce FLOPs by nearly half compared to the ResNet-50 baseline with almost no loss of accuracy. Compared with state-of-the-art filter pruning methods, our approach also achieves superior results.},
  archive      = {J_NEUCOM},
  author       = {Xuan Zu and Yun Li and Baoqun Yin},
  doi          = {10.1016/j.neucom.2023.02.063},
  journal      = {Neurocomputing},
  pages        = {35-45},
  shortjournal = {Neurocomputing},
  title        = {Consecutive layer collaborative filter similarity for differentiable neural network pruning},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale latent feature-aware network for logical
partition based 3D voxel reconstruction. <em>NEUCOM</em>, <em>533</em>,
22–34. (<a href="https://doi.org/10.1016/j.neucom.2023.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although prior methods have achieved promising performance for recovering the 3D geometry from a single depth image, they tend to produce incomplete 3D shapes with noise. To this end, we propose Multi-Scale Latent Feature-Aware Network (MLANet) to recover the full 3D voxel grid from a single depth view of an object. MLANet logically represents a 3D voxel grid as visible voxels, occluded voxels and non-object voxels, and aims to the reconstruction of the latter two. Thus MLANet first introduces Multi-Scale Latent Feature-Aware (MLFA) based AutoEncoder (MLFA-AE) and a logical partition module to predict an occluded voxel grid ( OccVoxGd ) and a non-object voxel grid ( NonVoxGd ) from the visible voxel grid ( VisVoxGd ) corresponding to the input. MLANet then introduces MLFA based Generative Adversarial Network (MLFA-GAN) to refine the OccVoxGd and the NonVoxGd , and combines them with the VisVoxGd to generate a target 3D occupancy grid. MLFA shows a strong ability of learning multi-scale features of an object effectively and can be considered as a plug-and-play component to promote existing networks. The logical partition helps suppress NonVoxGd noise and improve OccVoxGd accuracy under adversarial constraints. Experimental studies on both synthetic and real-world data show that MLANet outperforms the state-of-the-art methods, and especially reconstructs unseen object categories with a higher accuracy.},
  archive      = {J_NEUCOM},
  author       = {Caixia Liu and Dehui Kong and Shaofan Wang and Qianxing Li and Jinghua Li and Baocai Yin},
  doi          = {10.1016/j.neucom.2023.02.041},
  journal      = {Neurocomputing},
  pages        = {22-34},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale latent feature-aware network for logical partition based 3D voxel reconstruction},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite-time adaptive neural network event-triggered output
feedback control for PMSMs. <em>NEUCOM</em>, <em>533</em>, 10–21. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the finite-time adaptive neural network event-triggered output feedback control for the permanent magnet synchronous motor (PMSM) systems. The addressed PMSM systems include unknown nonlinear dynamics and immeasurable states. The neural networks are utilized to approximate the unknown nonlinear dynamics and an equivalent control design model is established, by which a neural network state observer is given to estimate the immeasurable states. By constructing an event-triggered mechanism and under the framework of adaptive backstepping control design technique and finite-time stability theory, a finite-time adaptive event-triggered output feedback control scheme is developed. It is proved that the proposed control scheme ensures the closed-loop system to be stable and the angular velocity , stator current and other state variables remain bounded in a finite time. Finally, the computer simulation is provided to confirm the effectiveness of the presented controllers.},
  archive      = {J_NEUCOM},
  author       = {Sihui Zhou and Yongming Li and Shaocheng Tong},
  doi          = {10.1016/j.neucom.2023.02.039},
  journal      = {Neurocomputing},
  pages        = {10-21},
  shortjournal = {Neurocomputing},
  title        = {Finite-time adaptive neural network event-triggered output feedback control for PMSMs},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Initialization-free distributed prescribed-time consensus
based algorithm for economic dispatch problem over directed network.
<em>NEUCOM</em>, <em>533</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To minimize the overall generation cost under the restrictions of supply and demand balance and individual generator capacity, the economic dispatch problem (EDP) over directed communication network is considered in this research. This article develops a distributed consensus-based algorithm to solve the EDP that can uniformly pre-assign the settling time. Different from the work with finite-time/fixed-time control, the proposed one allows the settling time to be a user-defined parameter independent of the initial states and other parameters. Moreover, the algorithm does not require initialization and allows the online changes of participating nodes and load demand, it can handle dynamic changes with a pre-arranged convergence time according to the need of the application. In addition, only a dual variable is exchanged with neighboring nodes, and no private information of the node is disclosed. Finally, the simulation results verify the effectiveness of our algorithm.},
  archive      = {J_NEUCOM},
  author       = {Lianghao Ji and Linhua Yu and Cuijuan Zhang and Xing Guo and Huaqing Li},
  doi          = {10.1016/j.neucom.2023.02.024},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {Initialization-free distributed prescribed-time consensus based algorithm for economic dispatch problem over directed network},
  volume       = {533},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RIME: A physics-based optimization. <em>NEUCOM</em>,
<em>532</em>, 183–214. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an efficient optimization algorithm based on the physical phenomenon of rime-ice, called the RIME. The RIME algorithm implements the exploration and exploitation behaviors in the optimization methods by simulating the soft-rime and hard-rime growth process of rime-ice and constructing a soft-rime search strategy and a hard-rime puncture mechanism. Meanwhile, the greedy selection mechanism in the algorithm is improved, and the population is updated in the stage of selecting the optimal solution to enhance the exploitation capability of the RIME. In the experimental, this paper conducts qualitative analysis experiments on the RIME to clarify the characteristics of the algorithm in the process of finding the optimal solution. The performance of RIME is then tested on a total of 42 functions in the classic IEEE CEC2017 and the latest IEEE CEC2022 test sets. The proposed algorithm is compared with 10 well-established algorithms and 10 latest improved algorithms to verify its performance advantage. In addition, this paper designs experiments for the parametric analysis of RIME to discuss the potential of the algorithm in running different parameters and handling different problems. Finally, this paper applies RIME to five practical engineering problems to verify its effectiveness and superiority in real-world problems. The statistical and comparison results show that the RIME is a strong and competitive algorithm. The source code of the RIME 1 algorithm and associated files are publicly accessible at https://aliasgharheidari.com/RIME.html .},
  archive      = {J_NEUCOM},
  author       = {Hang Su and Dong Zhao and Ali Asghar Heidari and Lei Liu and Xiaoqin Zhang and Majdi Mafarja and Huiling Chen},
  doi          = {10.1016/j.neucom.2023.02.010},
  journal      = {Neurocomputing},
  pages        = {183-214},
  shortjournal = {Neurocomputing},
  title        = {RIME: A physics-based optimization},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast density estimation for density-based clustering
methods. <em>NEUCOM</em>, <em>532</em>, 170–182. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-based clustering algorithms are widely used for discovering clusters in pattern recognition and machine learning . They can deal with non-hyperspherical clusters and are robust to outliers. However, the runtime of density-based algorithms is heavily dominated by neighborhood finding and density estimation which is time-consuming. Meanwhile, the traditional acceleration methods using indexing techniques such as KD-tree may not be effective when the dimension of the data increases. To address these issues, this paper proposes a fast range query algorithm, called Fast Principal Component Analysis Pruning (FPCAP), with the help of the fast principal component analysis technique in conjunction with geometric information provided by the principal attributes of the data. Based on FPCAP, a framework for accelerating density-based clustering algorithms is developed and successfully applied to accelerate the Density Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm and the BLOCK-DBSCAN algorithm, and improved DBSCAN (called IDBSCAN) and improved BLOCK-DBSCAN (called BLOCK-IDBSCAN) are then obtained, respectively. IDBSCAN and BLOCK-IDBSCAN preserve the advantage of DBSCAN and BLOCK-DBSCAN, respectively, while greatly reducing the computation of redundant distances. Experiments on seven benchmark datasets demonstrate that the proposed algorithm improves the computational efficiency significantly.},
  archive      = {J_NEUCOM},
  author       = {Difei Cheng and Ruihang Xu and Bo Zhang and Ruinan Jin},
  doi          = {10.1016/j.neucom.2023.02.035},
  journal      = {Neurocomputing},
  pages        = {170-182},
  shortjournal = {Neurocomputing},
  title        = {Fast density estimation for density-based clustering methods},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An overview of data-driven battery health estimation
technology for battery management system. <em>NEUCOM</em>, <em>532</em>,
152–169. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Battery degradation, caused by multiple coupled degradation mechanisms, severely affects the safety and sustainability of a battery management system (BMS). The battery state of health (SOH) is a commonly-adopted metric to evaluate a battery’s degradation condition, which should be carefully modeled to facilitate the safety and reliability of a BMS. Recently, owing to the rapid progress of data science-related techniques, data-driven models for battery SOH estimation have attracted great attentions from both academia and industry communities. This paper aims to provide the scientists and engineers with a general overview of data-driven battery SOH estimation technology for BMSs. State-of-the-art models published during 2018–2022 are reviewed with care, including a) feature extraction and selection methods; b) benchmarks, variants and extensions of data-driven SOH estimation models; and c) publicly-available battery SOH datasets. Afterwards, experiments are conducted and analyzed on the Toyota &amp; Stanford-MIT battery SOH datasets for benchmark study. Finally, existing challenges and feature trends are summarized.},
  archive      = {J_NEUCOM},
  author       = {Minzhi Chen and Guijun Ma and Weibo Liu and Nianyin Zeng and Xin Luo},
  doi          = {10.1016/j.neucom.2023.02.031},
  journal      = {Neurocomputing},
  pages        = {152-169},
  shortjournal = {Neurocomputing},
  title        = {An overview of data-driven battery health estimation technology for battery management system},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Video anomaly detection based on spatio-temporal
relationships among objects. <em>NEUCOM</em>, <em>532</em>, 141–151. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection is to automatically identify predefined anomalous contents (e.g. abnormal objects, behaviors and scenes) in videos. The performance of video anomaly detection can be effectively improved by making the model focus more on the anomalous objects in videos. However, such existing approaches usually rely on pre-trained models, which not only require additional auxiliary information but also face the challenge of anomaly diversity in the real world. In this paper, we propose a new video anomaly detection method based on spatio-temporal relationships among objects. Concretely, we use a fully convolutional encoder-decoder network with symmetric skip connections as the backbone network, which can effectively extract features from the object regions at different scales. In the encoding stage, an attention mechanism is used to enhance the model’s understanding of the spatio-temporal relationships among various types of objects in the video. In the decoding stage, a dynamic pattern generator is designed to memorize the inter-object spatio-temporal relationships, which thus enhances the reconstructions of normal samples while making the reconstructions of abnormal samples more difficult. We conduct extensive experiments on three widely used video anomaly detection datasets CUHK Avenue , ShanghaiTech Campus and UCSD Ped2 , and the experimental results show that our proposed method can significantly improve the performance, and achieves state-of-the-art overall performance (considering both effectiveness and efficiency). In particular, our method achieves a state-of-the-art AUC of 98.4\% on the UCSD Ped2 dataset that consists of various anomalies in real-world scenarios.},
  archive      = {J_NEUCOM},
  author       = {Yang Wang and Tianying Liu and Jiaogen Zhou and Jihong Guan},
  doi          = {10.1016/j.neucom.2023.02.027},
  journal      = {Neurocomputing},
  pages        = {141-151},
  shortjournal = {Neurocomputing},
  title        = {Video anomaly detection based on spatio-temporal relationships among objects},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Software-hardware co-design for accelerating large-scale
graph convolutional network inference on FPGA. <em>NEUCOM</em>,
<em>532</em>, 129–140. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by convolutional neural networks , graph convolutional networks (GCNs) have been proposed for processing non-Euclidean graph data and successfully been applied in recommendation systems, smart traffic, etc. However, subject to the sparsity and irregularity of GCN models, the complex execution pattern of large-scale GCN poses huge challenges to the efficient inference on general purpose CPUs and GPUs, such as workload imbalance and irregular memory access. Therefore, we propose a software-hardware co-design framework for low-latency GCN inference on field programmable gate array . Specifically, at the algorithm level, we propose an attention-mechanism-based graph sparsification approach to reduce the redundant relation in the graph structure and alleviate irregularity without losing accuracy. Then, at the hardware design level, based on the sparsified graph, we propose a two-stage hardware architecture that supports the two phases with a distinct execution mode in the GCN. In order to achieve low-latency computation, edge-level and feature-level parallelism are exploited in the aggregation phase. In addition, a graph partition strategy is exploited to efficiently improve data reuse. The experimental results demonstrate that our proposed framework can achieve 739 × × speedup compared to CPU, 13.7 × × speedup compared to GPU on average and 6.8 × × speedup compared to state-of-the-art accelerators.},
  archive      = {J_NEUCOM},
  author       = {Shaolin Ran and Beizhen Zhao and Xing Dai and Cheng Cheng and Yong Zhang},
  doi          = {10.1016/j.neucom.2023.02.032},
  journal      = {Neurocomputing},
  pages        = {129-140},
  shortjournal = {Neurocomputing},
  title        = {Software-hardware co-design for accelerating large-scale graph convolutional network inference on FPGA},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid-triggered and fault-tolerant observer-based control
for neural networks under malicious attacks. <em>NEUCOM</em>,
<em>532</em>, 114–128. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based upon hybrid-triggered mechanism, this article inspects fault-tolerant issue based ( Q , S , R ) (Q,S,R) dissipative control for neural networks system along with malcious attacks and external disturbances. To be precious, conventional Luenberger observer is employed to estimate the system state and malicious attack signal, whereas the presence of smoothed signal of malicious attack in the system state will not allow the augmented state to be precisely estimate. Moreover, the hybrid-triggered mechanism which incorporates both time- and event-triggered scheme is initiated to mitigate the redundancy of network transmission and secures the network resources. Preciously, the stochastic switching within the mechanism satisfies the Bernoulli distribution . The main intention of this study is to develop a hybrid-triggered scheme and a fault-tolerant controller for ensuring the mean-square asymptotic stability for the desired neural networks with ( Q , S , R ) (Q,S,R) dissipative performance index. Assisted by Lyapunov stability theory and some inequality techniques, an adequate criterion has been attained in the configuration of linear matrix inequalities (LMIs) to guarantee the asymptotic stability of the neural networks system. Further, the anticipated gain matrices are attained with the strength of obtained LMIs. In the final analysis, the applicability and efficacity of the proposed control model are reflected through two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {S.A. Karthick and Bor-Sen Chen},
  doi          = {10.1016/j.neucom.2023.02.009},
  journal      = {Neurocomputing},
  pages        = {114-128},
  shortjournal = {Neurocomputing},
  title        = {Hybrid-triggered and fault-tolerant observer-based control for neural networks under malicious attacks},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fixed-time gradient algorithm for distributed optimization
with inequality constraints. <em>NEUCOM</em>, <em>532</em>, 106–113. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed fixed time gradient algorithm for neurodynamic systems is proposed for solving optimization problems with local inequality constraints . The algorithm is designed using fixed time theory and sliding model control techniques, where each agent has a local objective function known only to itself, and the optimal solution of each local objective function sum can be obtained in a fixed time by the information interaction between neighbors under the condition of local inequality constraints . In addition, the upper bound of the fixed time can be obtained and it is proved theoretically that the upper bound of the fixed time is independent of the initial value. Finally, the stability and effectiveness of the algorithm are verified by numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Xing He and Boyu Wei and Hui Wang},
  doi          = {10.1016/j.neucom.2023.02.022},
  journal      = {Neurocomputing},
  pages        = {106-113},
  shortjournal = {Neurocomputing},
  title        = {A fixed-time gradient algorithm for distributed optimization with inequality constraints},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cluster-aware multiplex InfoMax for unsupervised graph
representation learning. <em>NEUCOM</em>, <em>532</em>, 94–105. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised graph learning aims to learn an encoder that embeds high-dimensional nodes into compact continuous vectors and preserves the topological and semantic features simultaneously without using any label information. Recently, contrastive learning (CL) on graph learning revives the traditional InfoMax principle and generates two views of the input graph randomly and then maximizes the agreements between them. However, the stochastic augmentation of a graph leads to two problems that need to be solved. Firstly, it ignores the role of some essential nodes and discriminating feature dimensions on the graph and may decrease the informativeness of the generated view by removing these crucial edges. Secondly, there are multi-level substructures of a graph that can be exploited and utilized for the network encoder’s topological learning. This paper proposes Cluster-Aware Multiplex InfoMax (CAMI) for unsupervised graph representation learning . We apply an adaptive graph augmentation scheme on both topological and feature dimensions to generate graph views without damaging the vital graph structure. To encourage the network encoder to capture more underlying node interactions, we additionally increase a mutual information maximization constraint between the node’s representation and multi-level graph summaries. Extensive experimental results on seven realistic datasets with different tasks prove the CAMI framework’s effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Xin Xu and Junping Du and Jie Song and Zhe Xue and Ang Li and Zeli Guan},
  doi          = {10.1016/j.neucom.2023.02.036},
  journal      = {Neurocomputing},
  pages        = {94-105},
  shortjournal = {Neurocomputing},
  title        = {Cluster-aware multiplex InfoMax for unsupervised graph representation learning},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Formal convergence analysis on deterministic
ℓ1-regularization based mini-batch learning for RBF networks.
<em>NEUCOM</em>, <em>532</em>, 77–93. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional convergence analysis on mini-batch learning is usually based on the stochastic gradient concept, in which we assume that the training data are presented in a random order. Also, some convergence results require that the learning rate should decrease with the number of training cycles, and that the objective function is a smooth function. Practically speaking, a deterministic presentation scheme with a fixed learning rate is more preferable. Hence, there is a gap between theoretical results and actual implementation. This paper aims at filling the gap. We use the radial basis function (RBF) model for nonlinear regression problems as an example to analyze the convergence properties of mini-batch learning. This paper considers a nonsmooth objective function, which consists of three terms. The coexistence of these three terms is able to handle a number of situations. The first term is a conventional training set error. The second term is a quadratic term which is used to suppress the effect of imperfections in the implementation. The last term is an ℓ 1 ℓ1 -norm term which is used to select important RBF nodes for the resultant network. Note that the ℓ 1 ℓ1 -norm term is a nonsmooth function. Although a nonsmooth ℓ 1 ℓ1 -norm is included and the mini-batch algorithm is deterministic, we are still able to derive the convergence properties , including the sufficient conditions for convergence and range of learning rate. With our results, we have a better theoretical understanding on the behaviour of mini-batch learning and obtain some guidelines on choosing the learning rate. The analysis results can be extended to other flat structural neural network models and other objective functions, which are with quadratic terms and ℓ 1 ℓ1 -norm.},
  archive      = {J_NEUCOM},
  author       = {Zhaofeng Liu and Chi-Sing Leung and Hing Cheung So},
  doi          = {10.1016/j.neucom.2023.02.012},
  journal      = {Neurocomputing},
  pages        = {77-93},
  shortjournal = {Neurocomputing},
  title        = {Formal convergence analysis on deterministic ℓ1-regularization based mini-batch learning for RBF networks},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph learning for latent-variable gaussian graphical models
under laplacian constraints. <em>NEUCOM</em>, <em>532</em>, 67–76. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, graph learning for smooth signals under Laplacian constraints has attracted increasing attention due to the wide application of graph Laplacian matrix in spectral graph theory, machine learning, and graph signal processing tasks. Standard graph learning methods usually assume that graphs are sparse, but the correlation between real-world entities is only sometimes sparse because of some common and potential effects. In this paper, we model these common effects as latent variables and assume that the Gaussian graphical model (GGM) under Laplacian constraints is conditionally sparse given latent variables but marginally non-sparse. Based on this assumption, the graph learning problem is formulated in a regularized maximum marginal likelihood (MML) framework with a sparse plus low-rank decomposition form. The specialized algorithm is developed to solve the proposed graph learning problem by incorporating Laplacian constraints into a multi-block alternating direction method of multipliers (ADMM) with proximal regularization terms. The experiments conducted on synthetic and real-world data sets demonstrate that the proposed graph learning method outperforms the standard method in inferring the sparsity pattern of the conditional graphical model of observed variables with the presence of latent variables.},
  archive      = {J_NEUCOM},
  author       = {Ran Li and Jiming Lin and Hongbing Qiu and Wenhui Zhang and Junyi Wang},
  doi          = {10.1016/j.neucom.2023.02.007},
  journal      = {Neurocomputing},
  pages        = {67-76},
  shortjournal = {Neurocomputing},
  title        = {Graph learning for latent-variable gaussian graphical models under laplacian constraints},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Depth-2 neural networks under a data-poisoning attack.
<em>NEUCOM</em>, <em>532</em>, 56–66. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the possibility of defending against data-poisoning attacks while training a shallow neural network in a regression setup. We focus on doing supervised learning with realizable labels for a class of depth-2 finite-width neural networks, which includes single-filter convolutional networks . In this class of networks, we attempt to learn the true network weights generating the labels in the presence of a malicious oracle doing stochastic, bounded and additive adversarial distortions on the true labels, during training. For the gradient-free stochastic algorithm that we construct, we prove worst-case near-optimal trade-offs among the magnitude of the adversarial attack , the weight approximation accuracy, and the confidence achieved by the proposed algorithm. As our algorithm uses mini-batching, we analyze how the mini-batch size affects convergence. We also show how to utilize the scaling of the outer layer weights to counter data-poisoning attacks on true labels depending on the probability of attack. Lastly, we give experimental evidence demonstrating how our algorithm outperforms stochastic gradient descent under different input data distributions, including instances of heavy-tailed distributions.},
  archive      = {J_NEUCOM},
  author       = {Sayar Karmakar and Anirbit Mukherjee and Theodore Papamarkou},
  doi          = {10.1016/j.neucom.2023.02.034},
  journal      = {Neurocomputing},
  pages        = {56-66},
  shortjournal = {Neurocomputing},
  title        = {Depth-2 neural networks under a data-poisoning attack},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-task feature and structure learning for
user-preference based knowledge-aware recommendation. <em>NEUCOM</em>,
<em>532</em>, 43–55. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data sparsity and long-tail items recommendation, two typical problems of recommender systems , can be effectively alleviated by leveraging user-side information and item-side information. Knowledge graph (KG) is a source of side information. Due to the specificity of data distribution, the current KG-enhanced recommendation algorithms have the problem of weak generalization and robustness (the performance varies greatly in multiple data sets). Moreover, the previous knowledge-aware recommendation models are insufficient to distill the collaborative signal and personal features from the collective behaviors of users while simultaneously distilling the connectivity and exclusive entity features from the knowledge graph on the item-side. In this paper, we propose a multi-task framework Multi-Rec with high flexibility and adaptability based on alternating learning, which consists of a recommender system (RS) task and a knowledge graph embedding (KGE) task. The RS task consists of user feature learning and user structure learning modules. Correspondingly, the KGE task consists of knowledge graph feature learning and knowledge graph structure learning modules. The correlation between each sub-learning task is carried out by designed cross units and exchange units. Through the end-to-end framework, our model generates high-efficiency node embeddings for downstream recommender tasks and outperforms several state-of-the-art baselines on four real-world datasets through extensive experiments.},
  archive      = {J_NEUCOM},
  author       = {Hang Shu and Jun Huang},
  doi          = {10.1016/j.neucom.2023.02.023},
  journal      = {Neurocomputing},
  pages        = {43-55},
  shortjournal = {Neurocomputing},
  title        = {Multi-task feature and structure learning for user-preference based knowledge-aware recommendation},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BiSeNet v3: Bilateral segmentation network with coordinate
attention for real-time semantic segmentation. <em>NEUCOM</em>,
<em>532</em>, 33–42. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the semantic segmentation task, spatial information and the receptive field are indispensable. For semantic segmentation to be practically applicable, it must have real-time inference speed. However, most of today’s methods almost choose to compromise the spatial resolution and low-level detail information, which leads to a significant decrease in accuracy. In this paper, we propose a new architecture based on Bilateral Segmentation Network (BiSeNet) called BiSeNet V3. It introduces a new feature refinement module to optimize the feature map and a feature fusion module to combine the features efficiently. An attention mechanism is introduced to assist the model in capturing contextual information. We also use edge detection to enhance features for boundaries. Extensive experiments on the Cityscapes dataset show that our proposed approach achieves an excellent performance between segmentation accuracy and inference speed. Specifically, for a 768 × 1536 input, BiSeNet V3 achieved 79.0\% mIoU on the Cityscapes test set with a speed of 93.8 FPS on an NVIDIA GTX 1080Ti. For a 720 × 960 input, BiSeNet V3 achieved 76.6\% mIoU on the CamVid dataset with a speed of 147.6 FPS on an NVIDIA GTX 1080Ti. The result is significantly better than the other methods.},
  archive      = {J_NEUCOM},
  author       = {Tsung-Han Tsai and Yu-Wei Tseng},
  doi          = {10.1016/j.neucom.2023.02.025},
  journal      = {Neurocomputing},
  pages        = {33-42},
  shortjournal = {Neurocomputing},
  title        = {BiSeNet v3: Bilateral segmentation network with coordinate attention for real-time semantic segmentation},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based visual detection of marine organisms: A
survey. <em>NEUCOM</em>, <em>532</em>, 1–32. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most recently, deep learning-based visual detection has attracted rapidly increasing attention paid to marine organisms, thereby expecting to significantly benefit ocean ecology. Suffering from underwater visual degradation including low contrast, color distortion and blur, etc. , both advances and challenges on visual detection of marine organisms (VDMO) co-exist in the literature. In this survey, deep learning-based VDMO techniques are comprehensively revisited from a systematic viewpoint covering advances in underwater image preprocessing, deep learning-based detection approaches, benchmark dataset and intensively quantitative comparisons . Furthermore, in terms of inherent features of marine organisms and complexity of underwater visual environments, underlying challenges are unfolded in depth. Such a self-contained survey is expected to exploit potential breakthroughs and explore probable trends in deep learning-based VDMO techniques.},
  archive      = {J_NEUCOM},
  author       = {Ning Wang and Tingkai Chen and Shaoman Liu and Rongfeng Wang and Hamid Reza Karimi and Yejin Lin},
  doi          = {10.1016/j.neucom.2023.02.018},
  journal      = {Neurocomputing},
  pages        = {1-32},
  shortjournal = {Neurocomputing},
  title        = {Deep learning-based visual detection of marine organisms: A survey},
  volume       = {532},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta neurons improve spiking neural networks for efficient
spatio-temporal learning. <em>NEUCOM</em>, <em>531</em>, 217–225. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) have incorporated many biologically-plausible structures and learning principles, and hence are playing critical roles in bridging the gap between artificial and natural neural networks . The spike is a sparse membrane-potential signal describing the above-threshold event-based firing and under-threshold dynamic integration, which might be considered an alternative uniformed and efficient way of spatio-temporal information representation and computation. Nowadays, most SNNs have selected the leaky integrated-and-fire (LIF) neuron with 1st-order dynamics as a key feature of membrane potential integration. The LIF neuron is efficient in dynamic coding but still too simple compared to its biological counterpart, which could generate various types of firing patterns. Here we run further by defining some “meta” neuron models that contain 1st- or 2nd-order dynamics and a recovery variable to simulate the hyperpolarization. Both shallow and deep SNNs were used to test the efficiency and flexibility of meta neuron models in various benchmark machine learning tasks, containing spatial learning (e.g., MNIST, Fashion-MNIST, NETtalk, Cifar-10), temporal learning (e.g., TIDigits, TIMIT), and spatio-temporal learning (e.g., N-MNIST). SNNs using these meta neurons were optimized by backpropagation with approximate gradient, and achieved markedly higher spatio-temporal capability without affecting accuracy, compared to those using regular LIF models.},
  archive      = {J_NEUCOM},
  author       = {Xiang Cheng and Tielin Zhang and Shuncheng Jia and Bo Xu},
  doi          = {10.1016/j.neucom.2023.02.029},
  journal      = {Neurocomputing},
  pages        = {217-225},
  shortjournal = {Neurocomputing},
  title        = {Meta neurons improve spiking neural networks for efficient spatio-temporal learning},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning and deep learning for sentiment analysis
across languages: A survey. <em>NEUCOM</em>, <em>531</em>, 195–216. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inception and rapid growth of the Web, social media, and other online forums have resulted in the continuous and rapid generation of opinionated textual data. Several real-world applications have been focusing on determining the sentiments expressed in these data. Owing to the multilinguistic nature of the generated data, there exists an increasing need to perform sentiment analysis on data in diverse languages. This study presents an overview of the methods used to perform sentiment analysis across languages. We primarily focus on multilingual and cross-lingual approaches. This survey covers the early approaches and current advancements that employ machine learning and deep learning models . We categorize these methods and techniques and provide new research directions. Our findings reveal that deep learning techniques have been widely used in both approaches and yield the best results. Additionally, the scarcity of multilingual annotated datasets limits the progress of multilingual and cross-lingual sentiment analyses, and therefore increases the complexity in comparing these techniques and determining the ones with the best performance.},
  archive      = {J_NEUCOM},
  author       = {El Mahdi Mercha and Houda Benbrahim},
  doi          = {10.1016/j.neucom.2023.02.015},
  journal      = {Neurocomputing},
  pages        = {195-216},
  shortjournal = {Neurocomputing},
  title        = {Machine learning and deep learning for sentiment analysis across languages: A survey},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-adaptive logit balancing for deep neural network
robustness: Defence and detection of adversarial attacks.
<em>NEUCOM</em>, <em>531</em>, 180–194. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread applications of Deep Neural Networks (DNNs), the safety of DNNs has become a significant issue. The vulnerability of the neural networks against adversarial examples deepens concerns about the safety of DNNs applications. This paper proposed a novel defence method to improve the adversarial robustness of DNN classifiers without using adversarial training . This method introduces two new loss functions. First, a zero-cross-entropy loss is used to punish overconfidence and find the appropriate confidence for different instances. Second, a logit balancing loss is proposed to protect DNNs from non-targeted attacks by regularising incorrect classes’ logits distribution. This method achieved competitive adversarial robustness compared to advanced adversarial training methods. Meanwhile, a novel robustness diagram is proposed to analyse, interpret and visualise the robustness of DNN classifiers against adversarial attacks. Furthermore, a Log-Softmax-pattern-based adversarial attack detection method is proposed. This detection method can distinguish clean inputs and multiple adversarial attacks via one multi-classification MLP . In particular, it is state-of-the-art in identifying white-box gradient-based attacks; it achieved at least 95.5\% accuracy for classifying four white-box gradient-based attacks with maximum 0.1\% false positive ratio.},
  archive      = {J_NEUCOM},
  author       = {Jiefei Wei and Luyan Yao and Qinggang Meng},
  doi          = {10.1016/j.neucom.2023.02.013},
  journal      = {Neurocomputing},
  pages        = {180-194},
  shortjournal = {Neurocomputing},
  title        = {Self-adaptive logit balancing for deep neural network robustness: Defence and detection of adversarial attacks},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning rules in spiking neural networks: A survey.
<em>NEUCOM</em>, <em>531</em>, 163–179. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are a promising energy-efficient alternative to artificial neural networks (ANNs) due to their rich dynamics, capability to process spatiotemporal patterns, and low-power consumption. The complex intrinsic properties of SNNs give rise to a diversity of their learning rules which are essential to functional SNNs. This paper is aimed at presenting a comprehensive overview of learning rules in SNNs. Firstly, we introduce the basic concepts of SNNs and commonly used neuromorphic datasets. Then, guided by a hierarchical classification of SNN learning rules, we present a comprehensive survey of these rules with discussions on their characteristics, advantages, limitations, and performance on several datasets. Moreover, we review practical applications of SNNs, including event-based vision and audio signal processing . Finally, we conclude this survey with a discussion on challenges and promising future research directions in this area.},
  archive      = {J_NEUCOM},
  author       = {Zexiang Yi and Jing Lian and Qidong Liu and Hegui Zhu and Dong Liang and Jizhao Liu},
  doi          = {10.1016/j.neucom.2023.02.026},
  journal      = {Neurocomputing},
  pages        = {163-179},
  shortjournal = {Neurocomputing},
  title        = {Learning rules in spiking neural networks: A survey},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bidirectional spatial–temporal traffic data imputation via
graph attention recurrent neural network. <em>NEUCOM</em>, <em>531</em>,
151–162. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal traffic data is increasingly important in transportation services with the development of intelligent transportation system (ITS). However, due to various unpredictable disruptions in the data collection and storage process, traffic data is often incomplete which will seriously hinder downstream tasks if not handled properly. Most existing methods for traffic data imputation either impose too strong assumptions on the data distribution or almost ignore the interdependencies across time steps and the information expressed by missingness. In this article, we propose a graph attention recurrent neural network (GARNN) for traffic data imputation. In our model, we impute data from both temporal and spatial perspectives. First, we model the observations and missingness separately via two LSTMs to treat the missingness of data as another special information distinct from observations. Then, a decay mechanism and graph attention network (GAT) are applied to learn the interdependencies across time steps and capture the spatial correlations respectively to generate temporal estimation and spatial estimation. Finally, those two estimations are integrated into the ultimate imputation. The whole process is in a bidirection. The proposed method is evaluated on two public datasets under three different missing scenarios. Experimental results show the effectiveness of the proposed model compared with other baselines.},
  archive      = {J_NEUCOM},
  author       = {Guojiang Shen and Wenfeng Zhou and Wenyi Zhang and Nali Liu and Zhi Liu and Xiangjie Kong},
  doi          = {10.1016/j.neucom.2023.02.017},
  journal      = {Neurocomputing},
  pages        = {151-162},
  shortjournal = {Neurocomputing},
  title        = {Bidirectional spatial–temporal traffic data imputation via graph attention recurrent neural network},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring attribute localization and correlation for
pedestrian attribute recognition. <em>NEUCOM</em>, <em>531</em>,
140–150. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian Attribute Recognition (PAR) is currently an emerging research topic in the field of video surveillance. For PAR, it usually needs to analyze dozens of attributes simultaneously, e.g., age, gender and Clothing type. However, different attributes may focus on different image regions, which makes it difficult to concurrently extract exhaustive features over all attributes. Moreover, some of these attributes are highly correlated, which is the other challenge for pedestrian attribute recognition. To remedy the aforementioned two issues, we propose two novel modules, namely Attribute Localization Module (ALM) and Attribute Correlation Module (ACM). For ALM, it is constructed based on a multi-stream architecture with each stream processing a specific attribute individually. More specifically, an attention mechanism is employed to discover and enhance the attribute-related features while suppressing less important regions. For ACM, the Transformer structure is employed to effectively explore the correlations among different attributes. In particular, we place the Transformer blocks behind the ALM module, with regarding each attribute-specific feature as an input token. The ALM and ACM modules focus on different aspects, which exploits the interrelated and complementary information. We combine the proposed modules to form a unified network with Exploring Attribute Localization and Correlation (abbreviated as EALC). Our approach is validated on five large-scale pedestrian attribute datasets, including PETA, RAP, PA-100 K, Market-1501 and Duke attribute datasets. Experiments demonstrate the effectiveness and advancement of the proposed EALC.},
  archive      = {J_NEUCOM},
  author       = {Dunfang Weng and Zichang Tan and Liwei Fang and Guodong Guo},
  doi          = {10.1016/j.neucom.2023.02.019},
  journal      = {Neurocomputing},
  pages        = {140-150},
  shortjournal = {Neurocomputing},
  title        = {Exploring attribute localization and correlation for pedestrian attribute recognition},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Open set domain adaptation with latent structure discovery
and kernelized classifier learning. <em>NEUCOM</em>, <em>531</em>,
125–139. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous visual domain adaptation methods have been proposed for transferring knowledge from a well-labeled source domain to an unlabeled but related target domain. Most of existing works are only geared to closed set domain adaptation, where an identical label space is shared between two domains. In this paper, we focus on a more realistic but challenging scenario, open set domain adaptation, where the target domain contains unknown classes that do not appear in the label space of source domain. The main task of open set domain adaptation is to simultaneously recognize the target images of known classes and those of unknown classes correctly. To achieve this goal, in this paper, we propose a novel open set domain adaptation method, which consists of two parts: latent structure discovery and kernelized classifier learning. In the first part, we employ an adaptive discriminative graph learning strategy to capture the intrinsic manifold structure of the source and target domain data in the latent feature space, such that the boundaries among all classes will be delineated more clearly. In the second part, the samples from the latent feature space are mapped into a high-dimensional kernel space to make them linearly separable, and a linear classifier is learned by jointly operating unknown target samples separating, known samples matching and local structure preserving. As the optimization problem is not convex with all variables, we devise an efficient iterative algorithm to solve it. The extensive experimental results on five image datasets confirm the superiority of the proposed method compared with the state-of-the-art traditional and deep competitors.},
  archive      = {J_NEUCOM},
  author       = {Yongqiang Tang and Lei Tian and Wensheng Zhang},
  doi          = {10.1016/j.neucom.2023.02.030},
  journal      = {Neurocomputing},
  pages        = {125-139},
  shortjournal = {Neurocomputing},
  title        = {Open set domain adaptation with latent structure discovery and kernelized classifier learning},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). TSNN: A topic and structure aware neural network for rumor
detection. <em>NEUCOM</em>, <em>531</em>, 114–124. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting rumors on social media and preventing its spread play a critical role for politics, economy, etc. Conventional studies mainly focus on exploiting the content or context of the source post, while they always ignore the rich topic information within the source post. To tackle this issue, in this paper, we propose a Topic and Structure Aware Neural Network (TSNN) for rumor detection. To be specific, we explore two kinds of topic signals, including a coarse-grained topic signal (i.e., topic credibility) and a fine-grained topic signal (i.e., latent topic representation), and tailor them to the task of rumor detection. Moreover, we introduce a new auxiliary task, i.e., topic credibility prediction, in order to effectively leverage the rich topic information within source posts. Finally, we develop a multi-task learning strategy that helps improve rumor detection performance by jointly learning the task of topic credibility prediction and user credibility prediction. Extensive experiments on three real-world datasets demonstrate that the proposed approach TSNN is superior to the state-of-the-art baseline methods.},
  archive      = {J_NEUCOM},
  author       = {Zhuomin Chen and Li Wang and Xiaofei Zhu and Stefan Dietze},
  doi          = {10.1016/j.neucom.2023.02.016},
  journal      = {Neurocomputing},
  pages        = {114-124},
  shortjournal = {Neurocomputing},
  title        = {TSNN: A topic and structure aware neural network for rumor detection},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast orthogonal locality-preserving projections for
unsupervised feature selection. <em>NEUCOM</em>, <em>531</em>, 100–113.
(<a href="https://doi.org/10.1016/j.neucom.2023.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based sparsity learning is one of the most successful unsupervised feature selection methods that has been widely adopted in many real-world applications. However, traditional graph-based unsupervised feature selection methods have several drawbacks: (1) being time-consuming and unable to deal with large-scale problems; (2) having difficulty tuning the regularization parameter with the sparsity regularization term ; and (3) being unable to find explicit solutions owing to the limitation of sparsity, that is, feature selection with the ℓ 2 , 1 ℓ2,1 -norm constrained problem. Thus, this paper proposes OLPPFS, a method to preserve the local geometric structure within the feature subspace by imposing the ℓ 2 , 0 ℓ2,0 -norm constraint. First, the linear mapping capability of the proposed model is enhanced using locality-preserving projections (LPPs), whichpreserve the local and global geometric manifold structure of the data while enhancing the ability to reconstruct data. Second, the graph-embedding learning method can accelerate the construction of a sparsity affinity graph and describe the intrinsic structure of the dataset well. More importantly, we propose a method for solving a projection matrix with the ℓ 2 , 0 ℓ2,0 -norm constrained, which can accurately select a explicit group of discriminative feature subsets. This method can yield a more accurate sparse projection matrix than the ℓ 2 , 1 ℓ2,1 -norm. We also adopt FOLPPFS, an effective anchor-based strategy to further accelerate our model with two flexible options. Extensive experiments on eight datasets demonstrate that the proposed method is superior to the other methods and can preserve a better local geometric structure of the dataset with less time consumption.},
  archive      = {J_NEUCOM},
  author       = {Jianyong Zhu and Jingwei Chen and Bin Xu and Hui Yang and Feiping Nie},
  doi          = {10.1016/j.neucom.2023.02.021},
  journal      = {Neurocomputing},
  pages        = {100-113},
  shortjournal = {Neurocomputing},
  title        = {Fast orthogonal locality-preserving projections for unsupervised feature selection},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated learning by employing knowledge distillation on
edge devices with limited hardware resources. <em>NEUCOM</em>,
<em>531</em>, 87–99. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a federated learning approach based on utilizing computational resources of the IoT edge devices for training deep neural networks . In this approach, the edge devices and the cloud server collaborate in the training phase while preserving the privacy of the edge device data . Owing to the limited computational power and resources available to the edge devices, instead of the original neural network (NN), we suggest to use a smaller NN generated using a proposed heuristic method . In the proposed approach, the smaller model, which is trained on the edge device, is generated from the main NN model. By the exploiting Knowledge Distillation (K D ) approach, the learned knowledge in the server and the edge devices can be exchanged, leading to lower required computation on the server and preserving data privacy of the edge devices. Also, to reduce the knowledge transfer overhead on the communication links between the server and the edge devices, a method for selecting the most valuable data to transfer the knowledge is introduced. The effectiveness of this method is assessed by comparing it to state-of-the-art methods. The results show that the proposed method lowers the communication traffic by up to 250 × and increases the learning accuracy by an average of 8.9\% in the cloud compared to the prior K D -based distributed training approaches in CIFAR-10 dataset.},
  archive      = {J_NEUCOM},
  author       = {Ehsan Tanghatari and Mehdi Kamal and Ali Afzali-Kusha and Massoud Pedram},
  doi          = {10.1016/j.neucom.2023.02.011},
  journal      = {Neurocomputing},
  pages        = {87-99},
  shortjournal = {Neurocomputing},
  title        = {Federated learning by employing knowledge distillation on edge devices with limited hardware resources},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A swarm of unmanned vehicles in the shallow ocean: A survey.
<em>NEUCOM</em>, <em>531</em>, 74–86. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of offshore exploration, autonomous underwater vehicles (AUVs) have come in great diversities depending on their particular specifications in civil and military practices. We focus on AUV swarms in the shallow ocean for their potentialities in economic and military uses as well as in scientific investigations. Nowadays, the advanced technologies of perception, communication, and control in underwater environment give the AUV abilities to perform certain tasks in the shallow ocean. Still, many missions require the large-scale AUV swarms due to the complexities of the tasks and the uncertainties of the environment. In this paper, we start with the introduction of underwater technologies in AUVs. Then we induce the AUV swarms and present several key methods to form swarms and to keep collaboration. Finally, we propose some necessitates technological advances that can facilitate the application of the AUV swarms in the shallow ocean.},
  archive      = {J_NEUCOM},
  author       = {Gaoxiang Liu and Lei Chen and Kexin Liu and Ying Luo},
  doi          = {10.1016/j.neucom.2023.02.020},
  journal      = {Neurocomputing},
  pages        = {74-86},
  shortjournal = {Neurocomputing},
  title        = {A swarm of unmanned vehicles in the shallow ocean: A survey},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep external and internal learning for noisy compressive
sensing. <em>NEUCOM</em>, <em>531</em>, 61–73. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing natural image from its corresponding compressive sensing (CS) measurements is an ill-posed problem. Learning accurate prior of desirable image is essential to solve this inverse problem in high quality, especially for CS reconstruction from noisy measurements. The existing learning-based methods cannot effectively simulate whole potential noise in the testing data during external learning, and cannot effectively exploit the information from internal testing data. In this paper, we present an effective convolutional neural network (CNN) based method for CS reconstruction from noisy measurements, which learns the deep prior from an external dataset and internal noisy testing data with Stein’s unbiased risk estimator (SURE). Specifically, we first pre-train an arbitrary CNN for CS reconstruction with an external dataset to learn a common prior. Then, we utilize meta learning to find a generic initial parameter that is suitable for fast internal learning and adaption to various noisy measurements. Finally, we customize the learned network to learn a specific prior for each internal testing data under Gaussian noise or more general mixed Poisson-Gaussian noise. Experimental results show that the proposed method outperforms the state-of-the-art methods under both comprehensively quantitative metrics and perceptive quality.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhang and Ying Fu and Debing Zhang and Chun Hu},
  doi          = {10.1016/j.neucom.2023.01.092},
  journal      = {Neurocomputing},
  pages        = {61-73},
  shortjournal = {Neurocomputing},
  title        = {Deep external and internal learning for noisy compressive sensing},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning based object detection for resource
constrained devices: Systematic review, future trends and challenges
ahead. <em>NEUCOM</em>, <em>531</em>, 34–60. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are widely being employed for object detection due to their high performance. However, the majority of applications that require object detection are functioning on resource-constrained edge devices. In the present era, there is a need for deep learning-based object detectors that are lightweight and perform well on these constrained edge devices. Objective: The research aims to identify current trends in resource-constrained applications for deep learning-based object detectors in terms of the technique used to create the model, the type of input image involved, the type of device used, and the type of application addressed by the model. Method: To achieve the objective of our research, a systematic literature review was carried out that yielded 167 studies. The models or techniques employed in the studies were grouped to better understand the research problem at hand. This review carefully reports every decision and provides many visualizations of the final studies in order to draw clear conclusions. Conclusion: The conclusion discussed the gaps, possibilities, and future perspectives discovered throughout the research process, implying that this field of study has grown profoundly in the last decade.},
  archive      = {J_NEUCOM},
  author       = {Vidya Kamath and Renuka A.},
  doi          = {10.1016/j.neucom.2023.02.006},
  journal      = {Neurocomputing},
  pages        = {34-60},
  shortjournal = {Neurocomputing},
  title        = {Deep learning based object detection for resource constrained devices: Systematic review, future trends and challenges ahead},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A transformer–convolution model for enhanced session-based
recommendation. <em>NEUCOM</em>, <em>531</em>, 21–33. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation aims to predict a user’s next action based on a series of anonymous sequences and plays an essential role in various online applications, such as e-commerce and music applications. Recently, transformer-based models have obtained results that are competitive with or even surpass those of recurrent neural networks , because of the good performance of transformer models in capturing long-distance dependencies. However, a transformer has a limited ability to mine local contextual information, which can be regarded as collective features. Researchers are seeking to address this limitation by augmenting the contextual transition to boost session representation learning . Accordingly, in this paper, we enhance the capabilities of a transformer in a session-based recommendation task by introducing convolutional neural networks (CNNs) at the stage of aggregating the item features with long- and short-distance dependencies. We first borrow a self-attention module from the classic transformer model to explore the long-distance dependencies. We next propose horizontal and vertical convolutions for enhancing the local collective information and then obtain a session representation by integrating the two types of features. Extensive experiments on real-world datasets show that our method outperforms those that rely on a transformer or a CNN alone.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Wang and Haoran Xie and Fu Lee Wang and Lap-Kei Lee},
  doi          = {10.1016/j.neucom.2023.01.083},
  journal      = {Neurocomputing},
  pages        = {21-33},
  shortjournal = {Neurocomputing},
  title        = {A transformer–convolution model for enhanced session-based recommendation},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pre-stimulus network responses affect information coding in
neural variability quenching. <em>NEUCOM</em>, <em>531</em>, 1–20. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural responding variability to the same stimulus typically decreases after a stimulus presented. During neural variability quenching, the pre-stimulus neural activities interact with the post-stimulus neural responses. However, whether these interactions have influences on information coding remains unclear. In this paper, we construct a two-layer k-winner-take-all (k-WTA) spiking network which simulates primary visual cortical neural responses through probabilistic inference. Generating the phenomenon of neural variability quenching, the network could reflect interactions between pre- and post-stimulus neural responses consistent with experimental observations. During neural variability quenching, pre-stimulus neural responding variability and complexity are considered as factors for the post-stimulus neural responses. Simulations to given stimuli are classified with each varying factor, respectively. Neural responding dimensionality measures the capacity of information coding to given stimuli. Over classified simulations, both of two factors could modify interactions between pre- and post-stimulus neural responses, leading to different neural responding dimensionalities. During neural variability quenching, the temporal structure of stimuli performs as another factor which also could modify neural interactions and induce the varying neural responding dimension. Our model provides the possible interpretation to how the pre-stimulus neural responses participate in neural variability quenching and affect the information coding.},
  archive      = {J_NEUCOM},
  author       = {Weisi Liu and Xinsheng Liu},
  doi          = {10.1016/j.neucom.2023.02.003},
  journal      = {Neurocomputing},
  pages        = {1-20},
  shortjournal = {Neurocomputing},
  title        = {Pre-stimulus network responses affect information coding in neural variability quenching},
  volume       = {531},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Over-relaxed multi-block ADMM algorithms for doubly
regularized support vector machines. <em>NEUCOM</em>, <em>530</em>,
188–204. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a classical machine learning model, support vector machine (SVM) has attracted much attention due to its rigorous theoretical foundation and powerful discriminative performance. The doubly regularized SVM (DRSVM) is an important variant of SVM based on elastic-net regularization , which considers both the sparsity and stability of the model. To tackle the problems of explosive increases in data dimensions and data volume, the alternating direction method of multipliers (ADMM) algorithm can be used to train the DRSVM model. ADMM is an effective iterative algorithm for solving convex optimization problems by decomposing a large issue into a series of solvable subproblems, which is also well suited for distributed computing . However, lack of guaranteed convergence and slow convergence rate are two critical limitations of ADMM. In this paper, a 3-block ADMM algorithm based on the over-relaxation technique is proposed to accelerate DRSVM training, namely, the over-relaxed DRSVM (O-RDRSVM). The main strategy of the over-relaxation technique is to further append the information from the previous iteration to the next iteration to improve the convergence of ADMM. We also propose a distributed version of O-RDRSVM to handle parallel and distributed computing faster, termed DO-RDRSVM. Moreover, we develop a fast O-RDRSVM algorithm (FO-RDRSVM) and a fast DO-RDRSVM algorithm (FDO-RDRSVM), which further reduce the computational cost of O-RDRSVM and DO-RDRSVM by employing the matrix inversion lemma . The convergence analyses ensure the effectiveness of our algorithms for DRSVM training. Finally, extensive experiments on public datasets demonstrate the advantages of our algorithms in terms of convergence rate and training time while maintaining accuracy and sparsity comparable to those of previous works.},
  archive      = {J_NEUCOM},
  author       = {Yunwei Dai and Yuao Zhang and Qingbiao Wu},
  doi          = {10.1016/j.neucom.2023.01.082},
  journal      = {Neurocomputing},
  pages        = {188-204},
  shortjournal = {Neurocomputing},
  title        = {Over-relaxed multi-block ADMM algorithms for doubly regularized support vector machines},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty-aware transfer across tasks using hybrid
model-based successor feature reinforcement learning☆. <em>NEUCOM</em>,
<em>530</em>, 165–187. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sample efficiency, which refers to the number of samples required for a learning agent to attain a specific level of performance, is central to developing practical reinforcement learning (RL) for complex and large-scale decision-making problems. The ability to transfer and generalize knowledge gained from previous experiences to downstream tasks can significantly improve sample efficiency. Recent research indicates that successor feature (SF) RL algorithms enable knowledge generalization between tasks with different rewards but identical transition dynamics. It has recently been hypothesized that combining model-based (MB) methods with SF algorithms can alleviate the limitation of fixed transition dynamics. Furthermore, uncertainty-aware exploration is widely recognized as another appealing approach for improving sample efficiency. An agent can efficiently explore to better understand an environment by tracking uncertainty about the value of each available action. Putting together two ideas of hybrid model-based successor feature (MB-SF) and uncertainty leads to an approach to the problem of sample efficient uncertainty-aware knowledge transfer across tasks with different transition dynamics or/and reward functions. In this paper, the uncertainty of the value of each action is approximated by a Kalman filter (KF)-based multiple-model adaptive estimation. This KF-based framework treats the parameters of a model as random variables. To the best of our knowledge, this is the first attempt at formulating a hybrid MB-SF algorithm capable of generalizing knowledge across large or continuous state space tasks with various transition dynamics while requiring less computation at decision time than MB methods. We highlight why previous SF-based methods are constrained to knowledge generalization across same transition dynamics, present our novel approach on a firm theoretical foundation, and design a set of demonstration tasks to empirically validate the effectiveness of our proposed approach. The number of samples required to learn the tasks was compared to recent SF and MB baselines. The results show that our algorithm generalizes its knowledge across different transition dynamics, learns downstream tasks with significantly fewer samples than starting from scratch, and outperforms existing approaches. We believe that our proposed framework can account for the computationally efficient behavioural flexibilities observed in the empirical literature and can also serve as a solid theoretical foundation for future experimental work.},
  archive      = {J_NEUCOM},
  author       = {Parvin Malekzadeh and Ming Hou and Konstantinos N. Plataniotis},
  doi          = {10.1016/j.neucom.2023.01.076},
  journal      = {Neurocomputing},
  pages        = {165-187},
  shortjournal = {Neurocomputing},
  title        = {Uncertainty-aware transfer across tasks using hybrid model-based successor feature reinforcement learning☆},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boosting r-CNN: Reweighting r-CNN samples by RPN’s error for
underwater object detection. <em>NEUCOM</em>, <em>530</em>, 150–164. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complicated underwater environments bring new challenges to object detection, such as unbalanced light conditions, low contrast, occlusion, and mimicry of aquatic organisms. Under these circumstances, the objects captured by the underwater camera will become vague, and the generic detectors often fail on these vague objects. This work aims to solve the problem from two perspectives: uncertainty modeling and hard example mining. We propose a two-stage underwater detector named boosting R-CNN, which comprises three key components. First, a new region proposal network named RetinaRPN is proposed, which provides high-quality proposals and considers objectness and IoU prediction for uncertainty to model the object prior probability. Second, the probabilistic inference pipeline is introduced to combine the first-stage prior uncertainty and the second-stage classification score to model the final detection score. Finally, we propose a new hard example mining method named boosting reweighting. Specifically, when the region proposal network miscalculates the object prior probability for a sample, boosting reweighting will increase the classification loss of the sample in the R-CNN head during training, while reducing the loss of easy samples with accurately estimated priors. Thus, a robust detection head in the second stage can be obtained. During the inference stage, the R-CNN has the capability to rectify the error of the first stage to improve the performance. Comprehensive experiments on two underwater datasets and two generic object detection datasets demonstrate the effectiveness and robustness of our method. The link of code: https://github.com/mousecpn/Boosting-R-CNN .},
  archive      = {J_NEUCOM},
  author       = {Pinhao Song and Pengteng Li and Linhui Dai and Tao Wang and Zhan Chen},
  doi          = {10.1016/j.neucom.2023.01.088},
  journal      = {Neurocomputing},
  pages        = {150-164},
  shortjournal = {Neurocomputing},
  title        = {Boosting R-CNN: Reweighting R-CNN samples by RPN’s error for underwater object detection},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vote or not? How language mimicry affect peer recognition in
an online social q&amp;a community. <em>NEUCOM</em>, <em>530</em>,
139–149. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Q&amp;A Communities become not only a source of information, but an interaction platform where people gain social recognition, the research into factors impacting viewers’ peer recognition of online contribution helps identify an effective model for such interaction. This study focuses on finding the connection between language mimicry and the peer recognition of online contributions. We collected a total of 13,109 contributions from Fluther , an online Q&amp;A community. Language features including linguistic similarity, text resemblance and peer recognition of online contributions were analysed, with the contributors’ followers and past responses serving as moderators. Linear regression was adopted to provide empirical evidence. This study demonstrates that language mimicry between the contributor and the information seeker has significant positive effect on the peer recognition of online contributions by the viewers. Moreover, the number of contributors’ past expertise mitigates the positive influence of linguistic similarity and text resemblance while their popularity strengthens the influence. It is a novel direction as prior language mimicry studies mainly focused on dyadic communication, whereas this research study aims to examine the influence of language mimicry on peer recognition of online contribution. The study extends the literature on language mimicry and provides practical implications.},
  archive      = {J_NEUCOM},
  author       = {Lijuan Luo and Jiarui Liu and Hanyi Shen and Yuping Lai},
  doi          = {10.1016/j.neucom.2023.01.086},
  journal      = {Neurocomputing},
  pages        = {139-149},
  shortjournal = {Neurocomputing},
  title        = {Vote or not? how language mimicry affect peer recognition in an online social Q&amp;A community},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). W-NetPan: Double-u network for inter-sensor self-supervised
pan-sharpening. <em>NEUCOM</em>, <em>530</em>, 125–138. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing availability of remote sensing data allows dealing with spatial-spectral limitations by means of pan-sharpening methods. However, fusing inter-sensor data poses important challenges, in terms of resolution differences, sensor-dependent deformations and ground-truth data availability, that demand more accurate pan-sharpening solutions. In response, this paper proposes a novel deep learning-based pan-sharpening model which is termed as the double-U network for self-supervised pan-sharpening (W-NetPan). In more details, the proposed architecture adopts an innovative W-shape that integrates two U-Net segments which sequentially work for spatially matching and fusing inter-sensor multi-modal data. In this way, a synergic effect is produced where the first segment resolves inter-sensor deviations while stimulating the second one to achieve a more accurate data fusion. Additionally, a joint loss formulation is proposed for effectively training the proposed model without external data supervision. The experimental comparison, conducted over four coupled Sentinel-2 and Sentinel-3 datasets, reveals the advantages of W-NetPan with respect to several of the most important state-of-the-art pan-sharpening methods available in the literature. The codes related to this paper will be available at https://github.com/rufernan/WNetPan.},
  archive      = {J_NEUCOM},
  author       = {Ruben Fernandez-Beltran and Rafael Fernandez and Jian Kang and Filiberto Pla},
  doi          = {10.1016/j.neucom.2023.02.002},
  journal      = {Neurocomputing},
  pages        = {125-138},
  shortjournal = {Neurocomputing},
  title        = {W-NetPan: Double-U network for inter-sensor self-supervised pan-sharpening},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Filter pruning with uniqueness mechanism in the frequency
domain for efficient neural networks. <em>NEUCOM</em>, <em>530</em>,
116–124. (<a
href="https://doi.org/10.1016/j.neucom.2023.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning has drawn extensive attention due to its advantage in reducing computational costs and memory requirements of deep convolutional neural networks . However, most existing methods only prune filters based on their intrinsic properties or spatial feature maps, ignoring the correlation between filters. In this paper, we suggest the correlation is valuable and consider it from a novel view: the frequency domain. Specifically, we first transfer features to the frequency domain by Discrete Cosine Transform (DCT). Then, for each feature map, we compute a uniqueness score, which measures its probability of being replaced by others. This way allows to prune the filters corresponding to the low-uniqueness maps without significant performance degradation . Compared to the methods focusing on intrinsic properties, our proposed method introduces a more comprehensive criterion to prune filters, further improving the network compactness while preserving good performance. In addition, our method is more robust against noise than the spatial ones since the critical clues for pruning are more concentrated after DCT. Experimental results demonstrate the superiority of our method. To be specific, our method outperforms the baseline ResNet-56 by 0.38\% 0.38\% on CIFAR-10 while reducing the floating-point operations (FLOPs) by 47.4\% 47.4\% . In addition, a consistent improvement can be observed when pruning the baseline ResNet-110: 0.23\% 0.23\% performance increase and up to 71\% 71\% FLOPs drop. Finally, on ImageNet, our method reduces the FLOPs of the baseline ResNet-50 by 48.7\% 48.7\% with only 0.32\% 0.32\% accuracy loss.},
  archive      = {J_NEUCOM},
  author       = {Shuo Zhang and Mingqi Gao and Qiang Ni and Jungong Han},
  doi          = {10.1016/j.neucom.2023.02.004},
  journal      = {Neurocomputing},
  pages        = {116-124},
  shortjournal = {Neurocomputing},
  title        = {Filter pruning with uniqueness mechanism in the frequency domain for efficient neural networks},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient data-driven behavior identification based on
vision transformers for human activity understanding. <em>NEUCOM</em>,
<em>530</em>, 104–115. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of computer vision, the research on human activity understanding has been greatly promoted. The recognition algorithm based on vision transformer has made some achievements in a large number of computer vision tasks, but it still needs to be driven by a large amount of data. How to get rid of the constraints of large amounts of data is crucial for human behavior recognition based on vision transformer. This paper focuses on solving the dilemma of big data, and tries to achieve a high-performance model through a small amount of high information human activity data. The advantage of our work is that by studying feature distribution, we proposed a core weight entropy data information evaluation method for obtaining high information data, and through redundant information elimination strategy, we can avoid introducing similar data. A large number of experimental results show the effectiveness of the proposed method. Compared with existing methods, our method reduces the data consumption by 5\% to 30\%, and can achieve the performance of using only 50\% of 100\% data. More importantly, the data our method selected has no redundancy, which is not available in other methods. In addition, we carried out a large number of ablation experiments to prove the rationality of the method. The work of this paper solves the challenge of relying on a large amount of data when using the visual converter to recognize human behavior, which is of practical significance for realizing efficient human activity understanding research with low data.},
  archive      = {J_NEUCOM},
  author       = {Jiachen Yang and Zhuo Zhang and Shuai Xiao and Shukun Ma and Yang Li and Wen Lu and Xinbo Gao},
  doi          = {10.1016/j.neucom.2023.01.067},
  journal      = {Neurocomputing},
  pages        = {104-115},
  shortjournal = {Neurocomputing},
  title        = {Efficient data-driven behavior identification based on vision transformers for human activity understanding},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Content-based fake news detection with machine and deep
learning: A systematic review. <em>NEUCOM</em>, <em>530</em>, 91–103.
(<a href="https://doi.org/10.1016/j.neucom.2023.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news, which can be defined as intentionally and verifiably false news, has a strong influence on critical aspects of our society. Manual fact-checking is a widely adopted approach used to counteract the negative effects of fake news spreading. However, manual fact-checking is not sufficient when analysing the huge volume of newly created information. Moreover, the number of labeled datasets is limited, humans are not particularly reliable labelers and databases are mostly in English and focused on political news. To solve these issues state-of-the-art machine learning models have been used to automatically identify fake news. However, the high amount of models and the heterogeneity of features used in literature often represents a boundary for researchers trying to improve model performances. For this reason, in this systematic review, a taxonomy of machine learning and deep learning models and features adopted in Content-Based Fake News Detection is proposed and their performance is compared over the analysed works. To our knowledge, our contribution is the first attempt at identifying, on average, the best-performing models and features over multiple datasets/topics tested in all the reviewed works. Finally, challenges and opportunities in this research field are described with the aim of indicating areas where further research is needed.},
  archive      = {J_NEUCOM},
  author       = {Nicola Capuano and Giuseppe Fenza and Vincenzo Loia and Francesco David Nota},
  doi          = {10.1016/j.neucom.2023.02.005},
  journal      = {Neurocomputing},
  pages        = {91-103},
  shortjournal = {Neurocomputing},
  title        = {Content-based fake news detection with machine and deep learning: A systematic review},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep semi-dense compression network for reinforcement
learning based on information theory. <em>NEUCOM</em>, <em>530</em>,
81–90. (<a href="https://doi.org/10.1016/j.neucom.2023.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although reinforcement learning (RL) can solve complex tasks after training, it’s difficult to extend trained agents to target environments with perturbations. This lack of generalization ability has caused the dilemma of large-scale application of RL. Rich neural networks have brought huge improvements to deep learning , but these aren’t adapted to RL and even bring negative effects. Therefore, RL algorithms have few choices of neural network, which greatly limits the representation and generalization ability of RL. To overcome these limitations, we propose a deep semi-dense compression network (DSCN) to improve RL generalization ability. First, we perform a structural extension on a general network model for RL. Then based on the information theory , we propose a semi-dense connection to enhance the neural information flow (NIF) of initial features. Finally, drawing on the ideas of course learning, we propose a channel compression approach to filter the redundant information of the deep network. In addition, we innovatively extend the experimental environment and evaluation metrics of the existing platform, which can fully evaluate the performance of DSCN. The experimental results show that our model achieves stable and significant generalization performance improvement.},
  archive      = {J_NEUCOM},
  author       = {Jiabao Wen and Meng Xi and Taiqiu Xiao and Jiachen Yang and Desheng Chen and Wen Lu and Xinbo Gao},
  doi          = {10.1016/j.neucom.2023.02.001},
  journal      = {Neurocomputing},
  pages        = {81-90},
  shortjournal = {Neurocomputing},
  title        = {A deep semi-dense compression network for reinforcement learning based on information theory},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neuro-adaptive control for searching generalized nash
equilibrium of multi-agent games: A two-stage design approach.
<em>NEUCOM</em>, <em>530</em>, 69–80. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the generalized Nash equilibrium searching problem of multi-agent games over weight-unbalanced directed networks. In this problem, the feasible action set of each agent is not only constrained by private convex sets and shared coupling equality, but also constrained by its own uncertain dynamics. Moreover, the local cost function is related to both his own actions and others, and each agent is only allowed access to neighbor information. To address this problem, we propose a neuro-adaptive control strategy based on two-stage design. In the first stage of design process, an approximator with adaptive-gain is designed to generate a virtual trajectory that converges to a necessary Nash equilibrium , the compensator based on consensus-tracking is used to obtain non-neighbor information and several auxiliary state variables are used to exchange information with local neighborhoods on a digraphs to deal with equality constraints. In the second stage of the strategy, we further developed a neuro-adaptive tracking controller based on one-step design for tracking the virtual trajectory. In the controller design, the virtual control variables and the actual control laws are obtained in a collective way, without repeating the design process. We introduce a variable called the minimum learning parameter to reduce the number of online learning parameters of the neural network . By using tools from variational inequality theory and Lyapunov stability theory , we prove that the proposed control strategy can drive all agents reach Nash equilibrium. Finally, the effectiveness of control strategy is verified by simulation example.},
  archive      = {J_NEUCOM},
  author       = {Qing Meng and Xiaohong Nian and Yong Chen and Zhao Chen},
  doi          = {10.1016/j.neucom.2023.01.077},
  journal      = {Neurocomputing},
  pages        = {69-80},
  shortjournal = {Neurocomputing},
  title        = {Neuro-adaptive control for searching generalized nash equilibrium of multi-agent games: A two-stage design approach},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph convolution network with subgraph embedding for
mutagenic prediction in aromatic hydrocarbons. <em>NEUCOM</em>,
<em>530</em>, 60–68. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An aromatic hydrocarbon refers to an organic material having a carbon ring such as benzene and a functional group in the carbon ring. As the industry develops, natural pollution becomes harsh, new compounds emerge, and the exposure to aromatic hydrocarbons is continuously increasing. Predicting mutagenicity is one of the crucial issues in reducing the risk because these organisms may have properties that penetrate the DNA of living things to cause mutations. Recently, the accuracy of mutation prediction has improved due to the power of deep learning. However, most conventional methods do not consider the characteristics of molecular aromatic hydrocarbons, which dilutes local information and results in a severe deterioration of the prediction performance. In this paper, we propose a method of exploiting subgraph convolution neural networks that enables the extraction of local information of a graph by partitioning it to maintain the detailed information. For extracting the features of molecules, we use the Girvan Newman algorithm to partition the graph according to the carbon ring and functional group and obtain the embedding vectors of the subgraphs as well as the original graph with graph convolution network (GCN). The embedding vectors are combined to represent the whole graph information and predict mutagenicity. Experiments with MUTAG, NCI1 and NCI109, datasets for predicting mutagenicity of molecules in graph structure, confirm that we successfully segment carbon rings and functional groups from molecular graphs and predict mutations using the partitioned graphs, leading to a 2\%p performance improvement. In addition, the proposed method has prevented about 15\%p of information dilution in GCN, and an analysis of the latent space of graphs reveals that the subgraphs extracted maintain the local information appropriately.},
  archive      = {J_NEUCOM},
  author       = {Hyung-Jun Moon and Seok-Jun Bu and Sung-Bae Cho},
  doi          = {10.1016/j.neucom.2023.01.091},
  journal      = {Neurocomputing},
  pages        = {60-68},
  shortjournal = {Neurocomputing},
  title        = {A graph convolution network with subgraph embedding for mutagenic prediction in aromatic hydrocarbons},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multiscale intrusion detection system based on pyramid
depthwise separable convolution neural network. <em>NEUCOM</em>,
<em>530</em>, 48–59. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the feature extraction problem in network intrusion detection , which is caused by large-scale high-dimensional traffic data, we propose a method based on variational Gaussian model (VGM) and one-dimensional Pyramid Depthwise Separable Convolution (PyDSC) neural network , called PyDSC-IDS. PyDSC-IDS uses VGM and OneHot encode technologies to preprocess the original dataset and decompose the complex feature into several simple ones. Pyramid convolution (PyConv) is selected for the processed multi-scale features and Depthwise Separable Convolution (DSC) is added to PyConv to reduce its network complexity. Finally, we verify the availability of the proposed method through experiments. The experimental results show that: 1) Data processed by VGM can effectively improve the detection accuracy; 2) Compared with the other three convolutional neural networks, PyDSC can significantly improve the detection accuracy at the cost of a slight increase in complexity, and PyDSC can effectively reduce the complexity of the PyConv.},
  archive      = {J_NEUCOM},
  author       = {Jiaxing He and Xiaodan Wang and Yafei Song and Qian Xiang},
  doi          = {10.1016/j.neucom.2023.01.072},
  journal      = {Neurocomputing},
  pages        = {48-59},
  shortjournal = {Neurocomputing},
  title        = {A multiscale intrusion detection system based on pyramid depthwise separable convolution neural network},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Gated region-refine pose transformer for human pose
estimation. <em>NEUCOM</em>, <em>530</em>, 37–47. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing the transformer for global fusion is a novel and efficient method for pose estimation. Although the computational complexity of modeling dense attention can be significantly reduced by pruning possible human tokens, the accuracy of pose estimation still suffers from the problem of high overlap of candidate regions and severe background noise. Moreover, the undifferentiated fusion of features from different views also leads to a sizeable effective information loss. To address these challenges, we propose a Gated Region-Refine Pose Transformer (GRRPT) for human pose estimation. The proposed GRRPT can obtain the general area of the human body from the coarse-grained tokens and then embed it into the fine-grained ones to extract more details of the joints. Experimental results on COCO demonstrate that performing the Multi-Resolution Attention mechanism learns more refined candidate regions and improves accuracy. Furthermore, we design a Fusion Gate module consisting of two gates to pixel-wise select valid information from the auxiliary views, which significantly alleviates information redundancy . Finally, we evaluate the effectiveness of our method on Human3.6M and our dataset FDU-Motion and achieve state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Tianfeng Wang and Xiaoxu Zhang},
  doi          = {10.1016/j.neucom.2023.01.090},
  journal      = {Neurocomputing},
  pages        = {37-47},
  shortjournal = {Neurocomputing},
  title        = {Gated region-refine pose transformer for human pose estimation},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identify influential nodes in social networks with graph
multi-head attention regression model. <em>NEUCOM</em>, <em>530</em>,
23–36. (<a href="https://doi.org/10.1016/j.neucom.2023.01.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying influential nodes in social networks is a fundamental task. Due to the development of Graph Neural Networks , Graph Convolution Network (GCN) based model has been introduced to solve this problem. Compared to traditional methods, the existing GCN-based models are more accurate in identifying influential nodes because they can better aggregate the multi-dimension features. However, the GCN-based method treats this problem as a binary classification task rather than a regression task , making it less practical. To make the GCN-based model more practical, we treat identifying influential nodes as a regression task . Moreover, when aggregating neighbor features, GCN ignores the difference in neighbor importance, which will affect the prediction performance of the GCN-based models. This paper proposes a graph multi-head attention regression model to address these problems. Vast experiments on twelve real-world social networks demonstrate that the proposed model significantly outperforms baseline methods . To the best of our knowledge, this is the first work to introduce the multi-head attention mechanism to identify influential nodes in social networks.},
  archive      = {J_NEUCOM},
  author       = {Jiangheng Kou and Peng Jia and Jiayong Liu and Jinqiao Dai and Hairu Luo},
  doi          = {10.1016/j.neucom.2023.01.078},
  journal      = {Neurocomputing},
  pages        = {23-36},
  shortjournal = {Neurocomputing},
  title        = {Identify influential nodes in social networks with graph multi-head attention regression model},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KVNet: An iterative 3D keypoints voting network for
real-time 6-DoF object pose estimation. <em>NEUCOM</em>, <em>530</em>,
11–22. (<a href="https://doi.org/10.1016/j.neucom.2023.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient object pose estimation holds the indispensable part of virtual/augmented reality (VR/AR) and many other applications. While previous works focus on directly regressing 6D pose from RGB and depth image and thus suffer from the non-linearity of rotation space, we propose an iterative 3D keypoints voting network, named as KVNet. Specifically, our method decouples the pose into separate translation and rotation branch, both estimated by Hough voting scheme. By treating the uncertainty of keypoints’ vote as the Lipschitz continuous function of seed points’ fused embedding feature, our method is able to adaptively select the optimal keypoints vote. In this way, we argue that KVNet bridges the gap between the non-linear rotation space and linear Euclidean space, which introduces inductive bias for our network to learn the intrinsic pattern and infer 6D pose from RGB and depth images. Furthermore, our model will refine the initial keypoints localization with iterative fashion. Experiments show that across three challenging benchmark datasets (LineMOD, YCB-Video and Occlusion LineMOD), our method exhibits excellent performance.},
  archive      = {J_NEUCOM},
  author       = {Fei Wang and Xing Zhang and Tianyue Chen and Ze Shen and Shangdong Liu and Zhenquan He},
  doi          = {10.1016/j.neucom.2023.01.036},
  journal      = {Neurocomputing},
  pages        = {11-22},
  shortjournal = {Neurocomputing},
  title        = {KVNet: An iterative 3D keypoints voting network for real-time 6-DoF object pose estimation},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inducing semantic hierarchy structure in empirical risk
minimization with optimal transport measures. <em>NEUCOM</em>,
<em>530</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cross-entropy (CE) loss is arguably the most important empirical risk minimization objective for deep discriminative models for classification, and has achieved notable success in numerous applications. Though the CE loss is widely adopted, it essentially ignores the correlation between categories. For example, predicting a shepherd dog to husky is more acceptable than a tiger for the subsequent decision processes, while these two misclassifications result in the same CE loss. Therefore, the usually used CE loss does not incorporate the risk of misclassification of different categories, which can be measured by the distance between the predicted category and ground-truth category in a semantic hierarchical tree (SHT). In this work, to explicitly take the SHT-defined risk-aware inter-categorical correlation into consideration, by proposing a discrete optimal transport (DOT) training framework via configuring its ground distance matrix . We are able to predefine ground distance matrix in optimal transport measurement following a priori of hierarchical semantic risk. Specifically, the tree-induced error (TIE) on SHT is adopted as our ground distance matrix. Furthermore, it can be extended to its increasing function from the optimization perspective. In addition, we can also adaptively learn the matrix following an alternative optimization scheme. The semantic similarity in each level of a tree is integrated with the information gain. We demonstrated the effectiveness of our framework in several benchmarks of large-scale image classification with the semantic tree structure, and showed superior performance in a plug-and-play manner. 1},
  archive      = {J_NEUCOM},
  author       = {Wanqing Xie and Yubin Ge and Site Li and Mingzhen Li and Xuyang Li and Zhenhua Guo and Jane You and Xiaofeng Liu},
  doi          = {10.1016/j.neucom.2023.01.093},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Inducing semantic hierarchy structure in empirical risk minimization with optimal transport measures},
  volume       = {530},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-path fusion based neural recommendation in
heterogeneous information networks. <em>NEUCOM</em>, <em>529</em>,
236–248. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful data modeling tool, Heterogeneous Information Network (HIN) has been successfully used in auxiliary information exploitation to boost recommendation performance. For HIN based recommendation, it is challenging to extract and fuse useful features of user preferences and item attributes under different semantic paths in HINs. Existing methods leverage a pre-defined fusion function to integrate different semantics for recommendation, which cannot characterize the complex nonlinear interactions between users and items. In this paper, we present a general framework named MNRec, short for Meta-path fusion based Neural Recommendation, to extract and fuse user and item embeddings under different meta-paths for recommendation. Under the framework, we propose an instantiation of MNRec with Multi-Layer Perceptron (MLP) structure. It consists of two major steps, i.e., meta-path based heterogeneous network embedding and deep learning based rating prediction. Concretely, appropriate meta-paths are first designed according to domain knowledge. Then the embeddings of users and items are obtained through a meta-path and commuting matrix based heterogeneous network embedding method. Finally, in light of the powerful nonlinear modeling capabilities of deep neural networks , the learned embeddings under different meta-paths are integrated into a two-pathway MLP structure for rating prediction. Experimental results on three real-world datasets demonstrate the superiority and effectiveness of MNRec compared with state-of-the-art baselines in rating prediction.},
  archive      = {J_NEUCOM},
  author       = {Lei Tan and Daofu Gong and Jinmao Xu and Zhenyu Li and Fenlin Liu},
  doi          = {10.1016/j.neucom.2023.01.070},
  journal      = {Neurocomputing},
  pages        = {236-248},
  shortjournal = {Neurocomputing},
  title        = {Meta-path fusion based neural recommendation in heterogeneous information networks},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving NeuCube spiking neural network for EEG-based
pattern recognition using transfer learning. <em>NEUCOM</em>,
<em>529</em>, 222–235. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) data are produced in quantity for measuring brain activity in response to external stimuli. With the rapid development of brain-inspired intelligence, spiking neural network (SNN) possesses the potential to handle EEG data by using spiking activity transmitted among spatially located synapses and neurons. As an original and unifying SNN architecture, NeuCube, is developed to model, recognize and understand EEG data. However, the NeuCube still faces some challenges for EEG-based pattern recognition, such as few labeled data and changes of data probability distribution. Hence, this paper proposes a novel method to improve the performance of the NeuCube for EEG-based pattern recognition by transfer learning . In the first place, the covariance matrix alignment of EEG data is implemented for every subject in the Euclidean space, which reduces the probability distribution discrepancy of EEG data between different subjects. Different estimation methods for reference covariance matrix are tested and the optimal one is selected for different subjects. Secondly, spatio-temporal features of EEG data are extracted based on the NeuCube reservoir. Since hyper-parameters of the NeuCube reservoir have a great impact on its spatio-temporal representation, an improved cuckoo search algorithm is proposed to discover the optimal hyper-parameters for obtaining the optimal spatio-temporal features. Last but not least, a weighted transfer support vector machine is proposed to improve the original output classifier of the NeuCube in order to make the model adaptive to the cross-domain variability of EEG data. The proposed method is tested on open dataset 2a from BCI competition IV 2008 and achieves good spatio-temporal pattern recognition results. Furthermore, the neuron connectivity and activation level associated with the process of mental tasks are illustrated.},
  archive      = {J_NEUCOM},
  author       = {Xuanyu Wu and Yixiong Feng and Shanhe Lou and Hao Zheng and Bingtao Hu and Zhaoxi Hong and Jianrong Tan},
  doi          = {10.1016/j.neucom.2023.01.087},
  journal      = {Neurocomputing},
  pages        = {222-235},
  shortjournal = {Neurocomputing},
  title        = {Improving NeuCube spiking neural network for EEG-based pattern recognition using transfer learning},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interurban charging station network: An evolutionary
approach. <em>NEUCOM</em>, <em>529</em>, 214–221. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a strong desire to meet the challenge of electrification of vehicles in order to achieve the decarbonization objective. However, as sales of electric vehicles have increased, there is a significant lack of infrastructure to support the charging of this type of vehicle. The infrastructural deficiencies are even more evident in the interurban environment, where the autonomy in kilometers of the battery is a critical issue. To minimize the substantial economic costs involved in installing sufficient charging points to ensure any interurban journey, it is necessary to establish mechanisms that evaluate appropriate locations to deploy the necessary stations. Accordingly, this paper proposes using an evolutionary approach to calculate the most suitable locations in an interurban environment for electric charging stations. For this purpose, different input information is taken into account in the allocation process. The proposed algorithm has been tested using real data from the USA. The results assess the current infrastructure and show the advantages of the locations proposed by the algorithm.},
  archive      = {J_NEUCOM},
  author       = {Jaume Jordán and Pasqual Martí and Javier Palanca and Vicente Julian and Vicente Botti},
  doi          = {10.1016/j.neucom.2023.01.068},
  journal      = {Neurocomputing},
  pages        = {214-221},
  shortjournal = {Neurocomputing},
  title        = {Interurban charging station network: An evolutionary approach},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual consistency semi-supervised nuclei detection via global
regularization and local adversarial learning. <em>NEUCOM</em>,
<em>529</em>, 204–213. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclei detection is a fundamental analytical step in digital histopathology image analysis. Since labeling the centroids for each nucleus in histopathology images is extremely time-consuming, researchers attempt to explore consistency-based approaches for efficient semi-supervised nuclei detection. However, existing methods can only be used for detection on small patches mostly containing one nucleus and contextual information among neighboring nuclei is not considered. On the contrary, using the whole image to achieve nuclei detection in a semi-supervised manner may suffer from a large amount of background noise and thus cannot yield optimal performance. To address these problems, we propose a novel semi-supervised learning method for nuclei detection on a full-size histopathology image via global consistency regularization and local consistency adversarial learning. Specifically, the proposed dual consistency semi-supervised learning can improve the efficiency in inference and learn the context-aware nuclei features by global consistency regularization. Meanwhile, local consistency adversarial learning is introduced to focus on nuclei regions and reinforce the local spatial contiguity of prediction maps. We have evaluated the proposed dual consistency semi-supervised method on public CRCHisto and collected SemiBCN datasets, and the results show that with the synergy of global consistency regularization and local consistency adversarial learning, our method delivers a significant improvement over the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Lei Su and Zhi Wang and Xiaoya Zhu and Gang Meng and Minghui Wang and Ao Li},
  doi          = {10.1016/j.neucom.2023.01.075},
  journal      = {Neurocomputing},
  pages        = {204-213},
  shortjournal = {Neurocomputing},
  title        = {Dual consistency semi-supervised nuclei detection via global regularization and local adversarial learning},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TextGuise: Adaptive adversarial example attacks on text
classification model. <em>NEUCOM</em>, <em>529</em>, 190–203. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples greatly compromise the security of deep learning models. The key to improving the robustness of a natural language processing (NLP) model is to study attacks and defenses involving adversarial text. However, the current adversarial attack methods still face problems, such as the low success rates of attacks on some datasets, and the existing defense methods can already successfully defend against some attack methods. As a result, such attacks are unable to dig deeper into the flaws of NLP models to inform further defense improvements. Hence, it is necessary to design an adversarial attack method with a wider attack range and stronger performance. Aiming at the advantages and disadvantages of existing methods, this paper proposes a new adaptive black-box text adversarial example generation scheme, TextGuise. First, we design a keyword selection method in which word scores are calculated by combining context semantics to select the appropriate keywords to modify. Second, to maintain semantics, new keyword substitution rules are designed in combination with the characteristics of text and popular text expressions. Finally, the best modification strategy is adaptively selected through a querying model to reduce the magnitudes of disturbances. TextGuise can automatically select replacement keywords and replacement strategies that efficiently generate adversarial examples with good readability for various text classification tasks. Attack experiments conducted with TextGuise on 5 datasets yield high attack success rates that can surpass 80\% when the perturbation ratio does not exceed 0.2. In addition, we present and discuss experiments focusing on defense, text similarity, query times, time consumption, etc., to test the attack performance of TextGuise. The results show that our attack method can achieve a good balance among various metrics.},
  archive      = {J_NEUCOM},
  author       = {Guoqin Chang and Haichang Gao and Zhou Yao and Haoquan Xiong},
  doi          = {10.1016/j.neucom.2023.01.071},
  journal      = {Neurocomputing},
  pages        = {190-203},
  shortjournal = {Neurocomputing},
  title        = {TextGuise: Adaptive adversarial example attacks on text classification model},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An entangled mixture of variational autoencoders approach to
deep clustering. <em>NEUCOM</em>, <em>529</em>, 182–189. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel deep clustering algorithm that utilizes a variational autoencoder (VAE) framework with an entangled multi encoder-decoder neural architecture. Our model enforces a complementary structure that guides the learned latent representations towards a better space arrangement. It differs from previous VAE-based clustering algorithms by employing a new generative model that uses multiple encoder-decoders that are entangled to provide a joint clustering decision. The optimal clustering is found by optimizing a lower bound of the model likelihood function. Both the reconstruction component and the regularization component of the ELBO objective function are explicitly involved in the clustering procedure. We show that this modeling results in both better clustering capabilities and improved data generation. The proposed method is evaluated on standard datasets and is shown to significantly outperform state-of-the-art deep clustering methods.},
  archive      = {J_NEUCOM},
  author       = {Avi Caciularu and Jacob Goldberger},
  doi          = {10.1016/j.neucom.2023.01.069},
  journal      = {Neurocomputing},
  pages        = {182-189},
  shortjournal = {Neurocomputing},
  title        = {An entangled mixture of variational autoencoders approach to deep clustering},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Class-aware tiny object recognition over large-scale 3D
point clouds. <em>NEUCOM</em>, <em>529</em>, 166–181. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although tremendous strides have been made in object recognition over large-scale 3D point clouds, one of the remaining open challenges is detecting tiny objects. The signal and appearance information of tiny objects are generally sparse and insufficient due to their tiny size, which makes the tiny object difficult to be detected with existing studies both in tiny 2D object recognition and general 3D object recognition since 3D topology relations are lost due to feature projection in tiny 2D object recognition and massive background may dominate the feature learner in general 3D object recognition. To the best of our knowledge, we explore tiny object recognition for the first time over large-scale 3D point clouds by designing deep neural network . To cope with this problem, a novel two-stage approach is proposed in this paper, which can effectively learn an informative and discriminative feature representation and efficiently process large-scale point clouds. Specifically, a class-aware filtering strategy is designed to dispense with the redundant background information. After that, we introduce a novel aggregating and sampling scheme in a supervised manner to progressively increase the receptive field for each 3D point, which can adaptively capture useful signals from tiny objects and learn complex geometric structures. Last, we propose a biased loss function that is inversely correlated to the number of tiny object points, thereby effectively handling the sparsity of tiny objects. Extensive experimental results over two real-world data sets validate the effectiveness and efficiency of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Jialin Li and Sarp Saydam and Yuanyuan Xu and Boge Liu and Binghao Li and Xuemin Lin and Wenjie Zhang},
  doi          = {10.1016/j.neucom.2023.01.094},
  journal      = {Neurocomputing},
  pages        = {166-181},
  shortjournal = {Neurocomputing},
  title        = {Class-aware tiny object recognition over large-scale 3D point clouds},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sonar image garbage detection via global despeckling and
dynamic attention graph optimization. <em>NEUCOM</em>, <em>529</em>,
152–165. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sonar is widely used in marine water cleaning tasks, so sonar images have become an effective tool for garbage detection and underwater scene analysis. However, it is an extremely difficult task to achieve fully supervised denoising and garbage detection for sonar images. This is because sonar images are weakly annotated samples that are susceptible to noise interference and have no reference clean image. To this end, we propose a sonar image garbage instance segmentation model via global despeckling and dynamic attention graph optimization(GD-DAGO). Specifically, a self-supervised blind spot network denoising structure is presented in this paper. The proposed denoising model overcomes the defects of information loss in the traditional blind spot network structure and performs global awareness speckle suppression for the noise characteristics of sonar images themselves. In addition, a novel dynamic attention structure is employed to improve the target region estimation in the instance segmentation module and does not require supervision beyond image-level category labeling. Finally, in order to enhance the cooperative ability between the two tasks, we adopt a local perceptual loss strategy based on mask proposals guided by the downstream task, so that the whole model takes more into account the characteristics of sonar images and better serves the sonar garbage detection task. Experimental results on ARACATI 2017 and marine-debris-fls-datasets (MDFD) show that the proposed algorithm achieves a performance gain of 0.4218 and 4.2\% in terms of denoising effect (ENL) and detection accuracy ( AP 25 AP25 ), respectively, compared with suboptimal algorithms.},
  archive      = {J_NEUCOM},
  author       = {Keyang Cheng and Liuyang Yan and Yi Ding and Hao Zhou and Maozhen Li and Humaira abdul Ghafoor},
  doi          = {10.1016/j.neucom.2023.01.081},
  journal      = {Neurocomputing},
  pages        = {152-165},
  shortjournal = {Neurocomputing},
  title        = {Sonar image garbage detection via global despeckling and dynamic attention graph optimization},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reconciliation of statistical and spatial sparsity for
robust visual classification. <em>NEUCOM</em>, <em>529</em>, 140–151.
(<a href="https://doi.org/10.1016/j.neucom.2023.01.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent image classification algorithms, by learning deep features from large-scale datasets, have achieved significantly better results comparing to the classic feature-based approaches. However, there are still various challenges of image classifications in practice, such as classifying noisy image or image-set queries, and training deep image classification models over the limited-scale dataset. Instead of applying generic deep features, the model-based approaches can be more effective and data-efficient for robust image and image-set classification tasks, as various image priors are exploited for modeling the inter- and intra-set data variations while preventing over-fitting. In this work, we propose a novel Joint Statistical and Spatial Sparse representation scheme, dubbed J3S , to model the image or image-set data for classification. J3S utilized joint sparse representation to reconcile both the local image structures and global Gaussian distribution mapped into Riemannian manifold. The learned J3S models are used for robust image and image-set classification tasks. Experiments show that the proposed J3S-based image classification scheme outperforms the popular or state-of-the-art competing methods over FMD, UIUC, ETH-80 and YTC databases.},
  archive      = {J_NEUCOM},
  author       = {Hao Cheng and Kim-Hui Yap and Bihan Wen},
  doi          = {10.1016/j.neucom.2023.01.084},
  journal      = {Neurocomputing},
  pages        = {140-151},
  shortjournal = {Neurocomputing},
  title        = {Reconciliation of statistical and spatial sparsity for robust visual classification},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deconfounded recommendation via causal intervention.
<em>NEUCOM</em>, <em>529</em>, 128–139. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommenders suffer from hidden confounding factors, leading to the spurious correlations between user/item profiles and user preference prediction, i.e., the confounding bias issue. Most works resort to only one confounding bias, which greatly block their applications on recommendations with mixture confounder, i.e., more than one bias. It is therefore of practical demand to empower the recommender with the capability of debiasing different biases from data. Moreover, the positive effect of bias is neglected in most previous works. We argue that confounding bias is actually beneficial for capturing users’ preferences in some recommendation scenarios. In this paper, we propose a novel deconfounded causal learning method called GCRec ( G raph C ausal Rec ommendetion) to debias two confounders: social network confounder and item group confounder. We employ Graph Neural Networks (GNNs) to aggregate user-user connections for social networks and user-item interactions for item groups in order to learn high-order representations that can efficiently debias these two confounders from a causal view. In the inference stage, we use symmetric Kullback–Leibler divergence to measure the user preference drift. If the divergence is large, we perform the causal intervention to alleviate the bias amplification caused by confounders on user preferences. Otherwise, we incorporate the user preferences that can potentially deliver a positive effect on favoring recommendation performance. Extensive experiments are conducted on two benchmark datasets to verify that GCRec outperforms state-of-the-art methods and achieves robust recommendations.},
  archive      = {J_NEUCOM},
  author       = {Dianer Yu and Qian Li and Xiangmeng Wang and Guandong Xu},
  doi          = {10.1016/j.neucom.2023.01.089},
  journal      = {Neurocomputing},
  pages        = {128-139},
  shortjournal = {Neurocomputing},
  title        = {Deconfounded recommendation via causal intervention},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparison of spiking neural networks with different
topologies based on anti-disturbance ability under external noise.
<em>NEUCOM</em>, <em>529</em>, 113–127. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on robustness of brain-like models contributes to promoting its neural information processing ability, and the understanding of bio-brain function. However, the biological rationality of the current brain-like models is inadequate. In addition, the effect of network topologies on the robustness of brain-like models has not been clarified. In this study, inspired by the topological characteristics of biological functional brain networks, we construct five kinds of spiking neural networks (SNNs), which have the same Izhikevich neuron model and the same synaptic plasticity model with time-delay, but different network topologies. Then, the robustness of the SNNs with different topologies is comparatively assessed based on the anti-disturbance ability under different noise. Further, by taking a speech recognition task as the case study, we investigate the anti-disturbance ability of these SNNs in application. Finally, the anti-disturbance mechanism of the SNNs is discussed. Our simulation consistently certifies that: (i) In terms of anti-disturbance indicators, the complex SNN outperforms the small-world SNN, the small-world SNN outperforms the scale-free SNN, and all of them outperform the random SNN and the regular SNN, which indicates that the SNNs with more biological rationality have the better anti-disturbance ability. (ii) In terms of speech recognition accuracy, the performance of SNNs with different topologies presents the consistent order with the anti-disturbance ability above. And the recognition accuracy of these SNNs under disturbance still remains almost the same, compared with these SNNs without disturbance. (iii) The evolution process of neural information is clarified, which hints that the synaptic plasticity is the intrinsic factor of anti-disturbance ability, and the network topology is a factor that affects the anti-disturbance ability at the level of performance. Our simulation results are conducive to the design of neuromorphic algorithms with robustness on analog or mixed-signal neuromorphic chips under complex noise environment.},
  archive      = {J_NEUCOM},
  author       = {Lei Guo and Dongzhao Liu and Youxi Wu and Guizhi Xu},
  doi          = {10.1016/j.neucom.2023.01.085},
  journal      = {Neurocomputing},
  pages        = {113-127},
  shortjournal = {Neurocomputing},
  title        = {Comparison of spiking neural networks with different topologies based on anti-disturbance ability under external noise},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DT-SNE: T-SNE discrete visualizations as decision tree
structures. <em>NEUCOM</em>, <em>529</em>, 101–112. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visualizations are powerful tools that are commonly used by data scientists to get more insights about their high dimensional data . One can for example cite t -SNE, which is probably one of the most famous and widely-used visualization techniques. However, t -SNE is a nonlinear and non-parametric technique that makes it suffer from a lack of interpretability . In this paper, we present a new technique inspired by t -SNE’s objective function that combines its ability to build nice visualizations with the interpretability of decision trees . This new visualization technique, called DT-SNE, can be seen as a discrete visualization technique where groups of instances are provided, as well as a ranking between them. The decision rules of the decision tree provide clear insights to interpret these different groups.},
  archive      = {J_NEUCOM},
  author       = {Adrien Bibal and Valentin Delchevalerie and Benoît Frénay},
  doi          = {10.1016/j.neucom.2023.01.073},
  journal      = {Neurocomputing},
  pages        = {101-112},
  shortjournal = {Neurocomputing},
  title        = {DT-SNE: T-SNE discrete visualizations as decision tree structures},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic instance shape reconstruction with sparse
LiDAR for monocular 3D object detection. <em>NEUCOM</em>, <em>529</em>,
92–100. (<a href="https://doi.org/10.1016/j.neucom.2023.01.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular 3D object detection aims to localize objects in 3D space from a single image. This is a difficult problem due to the lack of accurate depth measurements. Many methods predict depths upfront using a pre-trained vision-based depth estimator to assist in 3D object detection. However, the methods show limited improved performances because of the depth inaccuracy and the neglect of depth confidence. In this paper, we propose a new end-to-end 3D object detection framework by combining a monocular camera with a cheap 4-beam LiDAR. The minimal LiDAR signal is leveraged as an additional input to predict high-quality and dense depth maps from monocular images. Meanwhile, several 3D proposals are generated by a keypoint-based detector. The key challenge is encoding the depth confidence to capture the depth estimation uncertainty. Therefore, we propose probabilistic instance shape reconstruction to exploit instance shape information for box refinement. Our method employs a fully differentiable end-to-end framework, making it simple and efficient. The experimental results on the KITTI dataset demonstrate that the proposed method achieves state-of-the-art performance, thus validating the effectiveness of the sparse LiDAR data and the probabilistic instance shape reconstruction. Code is available at https://github.com/xjtuwh/SparseLiDAR_fusion .},
  archive      = {J_NEUCOM},
  author       = {Chaofeng Ji and Han Wu and Guizhong Liu},
  doi          = {10.1016/j.neucom.2023.01.080},
  journal      = {Neurocomputing},
  pages        = {92-100},
  shortjournal = {Neurocomputing},
  title        = {Probabilistic instance shape reconstruction with sparse LiDAR for monocular 3D object detection},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PTKE: Translation-based temporal knowledge graph embedding
in polar coordinate system. <em>NEUCOM</em>, <em>529</em>, 80–91. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding has received widespread attention in recent years. Most existing models represent time-independent facts as low dimensional embeddings. Nevertheless, knowledge graphs with temporal information provide more accurate and timely data. Hence, we propose P olar T emporal K nowledge Graph E mbedding (PTKE), a novel temporal knowledge graph (TKG) embedding model which belongs to the translation-based model family and embeds time-aware facts into polar coordinate system. PTKE defines time as a constraint of the entity and synchronously embeds the starting and ending timestamps. The fact is divided into the modulus and the angular parts to avoid generating similar time-constrained entities. We use the modulus part to distinguish different time-constrained entities, and the angular part to distinguish time-constrained entities with the same modulus. Experiments on the temporal datasets show that PTKE outperforms prior state-of-the-art static knowledge graph (SKG) embedding models and temporal knowledge graph (TKG) embedding models in the link prediction task and the relation prediction task. Furthermore, the analysis of different time units and semantic expressive ability test on time embeddings prove that PTKE has a great ability on time expression.},
  archive      = {J_NEUCOM},
  author       = {Ruinan Liu and Guisheng Yin and Zechao Liu and Liguo Zhang},
  doi          = {10.1016/j.neucom.2023.01.079},
  journal      = {Neurocomputing},
  pages        = {80-91},
  shortjournal = {Neurocomputing},
  title        = {PTKE: Translation-based temporal knowledge graph embedding in polar coordinate system},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient multi-metric learning method by partitioning
the metric space. <em>NEUCOM</em>, <em>529</em>, 56–79. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric learning has attracted significant attention due to its high effectiveness and efficiency for pattern recognition task. Traditional supervised metric learning algorithms attempt to seek a global distance metric with labeled samples. When data are represented with multimodal and only limited supervision information is available, these approaches are insufficient to obtain satisfactory results. In this paper, we develop a robust semi-supervised multi-metric learning method (RSMM) to improve classification performance. The proposed RSMM learns multiple local metrics and a background metric instead of a single global metric. Specifically, we divide the metric space into influential regions and background region, and then regulate the effectiveness of each local metric to be within the related regions. Simultaneously, a geometrically interpretable, symmetric distance is defined with local metrics and background metric. Based on the resultant learning bounds, we obtain the regularization term to improve the classifier’s generalization ability . Moreover, the manifold regularization term is introduced to preserve the supervision information as well as geometry structure. The substantial unlabeled samples may cause potential threats and large uncertainties, so the logarithmic loss function is utilized to enhance the robustness. An efficient gradient descent algorithm is exploited to solve the non-convex challenging problem. To further understand the proposed algorithm, we theoretically derive its robustness and generalization error bounds. Finally, numerical experiments on UCI datasets and image datasets demonstrate the feasibility and validity of the RSMM.},
  archive      = {J_NEUCOM},
  author       = {Chao Yuan and Liming Yang},
  doi          = {10.1016/j.neucom.2023.01.074},
  journal      = {Neurocomputing},
  pages        = {56-79},
  shortjournal = {Neurocomputing},
  title        = {An efficient multi-metric learning method by partitioning the metric space},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Output feedback q-learning for discrete-time finite-horizon
zero-sum games with application to the h∞ control. <em>NEUCOM</em>,
<em>529</em>, 48–55. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a Q-learning framework for solving finite-horizon zero-sum game problems involving the H ∞ H∞ control of linear system without knowing the dynamics. Research in the past mainly focused on solving problems in infinite horizon with completely measurable state. However, in the practical engineering, the system state is not always directly accessible, and it is difficult to solve the time-varying Riccati equation associated with the finite-horizon setting directly either. The main contribution of the proposed model-free algorithm is to determine the optimal output feedback policies without measurement state in finite-horizon setting. To achieve this goal, we first describe the Q-function caused by finite-horizon problems in the context of state feedback, then we parameterize the Q-functions as input–output vectors functions . Finally, the numerical examples on aircraft dynamics demonstrate the algorithm’s efficiency.},
  archive      = {J_NEUCOM},
  author       = {Mingxiang Liu and Qianqian Cai and Dandan Li and Wei Meng and Minyue Fu},
  doi          = {10.1016/j.neucom.2023.01.050},
  journal      = {Neurocomputing},
  pages        = {48-55},
  shortjournal = {Neurocomputing},
  title        = {Output feedback Q-learning for discrete-time finite-horizon zero-sum games with application to the h∞ control},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cluster consensus with first and higher-order antagonistic
interaction dynamics. <em>NEUCOM</em>, <em>529</em>, 33–47. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the cluster consensus problem for networks with antagonistic interactions modelled by adjacency matrices with negative weights. By introducing an extended digraph representation consisting of purely cooperative interactions with lifting approach, we relate the trajectories of the system to those of an extended system with a positive digraph . The behaviours of agents in a signed network are extracted from its extended digraph. Consequently, the number of clusters and the cluster members are explicitly determined for any signed digraph by using primary and secondary layer subgraph concepts. The relation between the dynamics of a signed system and its extended representation is investigated for first and higher-order systems. The conditions that make both systems stable are stated. Additionally, the control parameters to achieve cluster consensus are derived explicitly for first, second and third order systems. The obtained results for continuous-time networks are subsequently extended to discrete-time networks. Finally, theoretical results are illustrated via numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Ümit Develer and Onur Cihan and Mehmet Akar},
  doi          = {10.1016/j.neucom.2023.01.025},
  journal      = {Neurocomputing},
  pages        = {33-47},
  shortjournal = {Neurocomputing},
  title        = {Cluster consensus with first and higher-order antagonistic interaction dynamics},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data imputation in IoT using spatio-temporal variational
auto-encoder. <em>NEUCOM</em>, <em>529</em>, 23–32. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most Internet of Things (IoT) scenes, data missing can be unavoidable when huge number of smart devices are collecting data uninterruptedly. Therefore, data imputation can be an integral part of pre-processing before data mining. It is widely known that IoT time series show strong dependencies in both spatial and temporal dimension, and the spatial relation among the devices is in non-euclidean space. However, most machine-learning-based and deep-learning-based approaches either only take temporal features into account or only catch spatial features in euclidean space. In this paper, we propose a novel network as ST-VAE (Spatio-Temporal Variational Auto-Encoder) to address the problem above. Our architecture is mainly based on Variational Auto-Encoder (VAE). Specifically, two kinds of VAE are utilized. One is for calculating the adjacent matrix of device network which is the essential input of GCN , and the other is for data imputation task based on the spatial and temporal dependencies. Experiments conducted on different real-world and public datasets demonstrate that our ST-VAE can not only populate the missing spatio-temporal data accurately but also outperforms other state-of-art approaches from the whole.},
  archive      = {J_NEUCOM},
  author       = {Shuo Zhang and Jinyi Chen and Jiayuan Chen and Xiaofei Chen and Hejiao Huang},
  doi          = {10.1016/j.neucom.2023.01.022},
  journal      = {Neurocomputing},
  pages        = {23-32},
  shortjournal = {Neurocomputing},
  title        = {Data imputation in IoT using spatio-temporal variational auto-encoder},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Advancing 3D medical image analysis with variable dimension
transform based supervised 3D pre-training. <em>NEUCOM</em>,
<em>529</em>, 11–22. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulties in both data acquisition and annotation substantially restrict the sample sizes of training datasets for 3D medical imaging applications. Therefore, it is non-trivial to build well-performing 3D convolutional neural networks from scratch. Previous efforts on 3D pre-training have frequently relied on self-supervised approaches, which use either predictive or contrastive learning on unlabeled data to build invariant 3D representations. However, because of the unavailability of large-scale supervision information, obtaining semantically invariant and discriminative representations from these learning frameworks remains problematic. In this paper, we revisit an innovative yet simple fully-supervised 3D network pre-training framework to take advantage of semantic supervision from large-scale 2D natural image datasets. With a redesigned 3D network architecture , reformulated natural images are used to address the problem of data scarcity and develop powerful 3D representations. Comprehensive experiments on five benchmark datasets demonstrate that the proposed pre-trained models can effectively accelerate convergence while also improving accuracy for a variety of 3D medical imaging tasks such as classification, segmentation, and detection. In addition, as compared to training from scratch, it can save up to 60\% of annotation efforts. On the NIH DeepLesion dataset, it also achieves state-of-the-art detection performance, outperforming earlier self-supervised and fully-supervised pre-training approaches, as well as methods that do training from scratch. To facilitate further development of 3D medical models, our code and pre-trained model weights are publicly available at https://github.com/urmagicsmine/CSPR.},
  archive      = {J_NEUCOM},
  author       = {Shu Zhang and Zihao Li and Hong-Yu Zhou and Jiechao Ma and Yizhou Yu},
  doi          = {10.1016/j.neucom.2023.01.012},
  journal      = {Neurocomputing},
  pages        = {11-22},
  shortjournal = {Neurocomputing},
  title        = {Advancing 3D medical image analysis with variable dimension transform based supervised 3D pre-training},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GradCa: Generalizing to unseen domains via gradient
calibration. <em>NEUCOM</em>, <em>529</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In domain generalization (DG) problem, we hope to train a robust model from multiple source domains and generalize it to unseen domains. However, the trained model can not perform well in the unseen domain since the domain-invariant representation is hard to learn across multiple source domains. In this work, we propose a novel gradient optimization strategy named gradient calibration (GradCa) which optimizes the dominant gradients and conflicting gradients without learning extra parameters. The dominant gradients are suppressed for addressing to be inclined to the optimization directions of specific domains. Then two strategies (average and sign-mask) are designed for further alleviating the conflicting gradients. These types of gradients are effectively calibrated for improving the domain-invariant representation learning. Extension experiments on four benchmark datasets have shown the competitive results and the effectiveness of improving the model generalization with GradCa.},
  archive      = {J_NEUCOM},
  author       = {Yiguo Song and Zhenyu Liu and Ruining Tang and Guifang Duan and Jianrong Tan},
  doi          = {10.1016/j.neucom.2023.01.042},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {GradCa: Generalizing to unseen domains via gradient calibration},
  volume       = {529},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constrained event-driven policy iteration design for
nonlinear discrete time systems. <em>NEUCOM</em>, <em>528</em>, 226–236.
(<a href="https://doi.org/10.1016/j.neucom.2023.01.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies an adaptive critic design (ACD) solution based on the event-driven mechanism for the constrained state and input system with external disturbance. At first, the barrier function is presented to construct the transformation of the constrained state system, and then, a suitable value function with non-quadratic utility function is designed according to the auxiliary system to acquire the control sequence in the infinity domain. After that, the comprehensive problem is transited into solving the Hamilton–Jacobi-Isaacs (HJI) equation. Then, the optimal control policy pair is obtained by policy iteration (PI) via double event-driven scheme. The three critic, action and disturbance neural networks (NNs) are built up to manipulate the data online concurrently to approximate the control pair sequence, and the ultimately uniformly bounded (UUB) proof of the estimation error generated by NNs is given. The last but not least, two sets of contrast simulations are analyzed to demonstrate the effectiveness of the proposed algorithm, which makes the model reduce the data transmission density and decrease the update times of control policies under the premise of system stability and ideal performance.},
  archive      = {J_NEUCOM},
  author       = {Lu Liu and Ruizhuo Song and Lina Xia},
  doi          = {10.1016/j.neucom.2023.01.060},
  journal      = {Neurocomputing},
  pages        = {226-236},
  shortjournal = {Neurocomputing},
  title        = {Constrained event-driven policy iteration design for nonlinear discrete time systems},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anti-synchronization for markovian neural networks via
asynchronous intermittent control. <em>NEUCOM</em>, <em>528</em>,
217–225. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the anti-synchronization for master–slave Markovian neural networks (NNs), in which a more general Markovian chain with uncertain transition probability is introduced to the controller of slave NNs. An asynchronous intermittent control scheme is proposed to achieve the anti-synchronization, which not only overcomes the problem that the jumping information of the system mode is not available for the controller instantly, but also strikes a balance between control cost and accuracy. Then, sufficient conditions are established to guarantee the anti-synchronization of the master–slave Markovian NNs according to the Lyapunov stability method and the iteration method. Finally, the effectiveness of the proposed asynchronous intermittent control method is verified by means of simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Zijing Xiao and Yuru Guo and Jun-Yi Li and Chang Liu and Yumei Zhou},
  doi          = {10.1016/j.neucom.2023.01.066},
  journal      = {Neurocomputing},
  pages        = {217-225},
  shortjournal = {Neurocomputing},
  title        = {Anti-synchronization for markovian neural networks via asynchronous intermittent control},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Triple-BigGAN: Semi-supervised generative adversarial
networks for image synthesis and classification on sexual facial
expression recognition. <em>NEUCOM</em>, <em>528</em>, 200–216. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic recognition of facial images showing erotic expressions can help to understand our social interaction and to detect non-appropriate images even when there is no nakedness present in them. This paper contemplates, for the first time, to exploit facial cues applied to automatic Sexual Facial Expression Recognition (SFER). With this goal, we introduce a new dataset named Sexual Expression and Activity Faces (SEA-Faces-30k) for SFER, which contains 30k manually labeled images under three categories: erotic, suggestive-erotic, and non-erotic. Deep Convolutional Neural Networks require large-scale annotated image datasets with diversity and variations to be properly trained. Unfortunately, gathering such a massive amount of data is not feasible in this area. Therefore, we present a new semi-supervised GAN framework named Triple-BigGAN, which learns a generative model and a classifier simultaneously. It learns both tasks in an end-to-end fashion while using unlabeled or partially labeled data. The Triple-BigGAN framework shows promising classification performance for the SFER task (i.e., 93.59\% 93.59\% ) and other five benchmark datasets, i.e., FER-2013, CIFAR-10, Expression in-the-Wild (ExpW), Modified National Institute of Standards and Technology database (MNIST), and Street View House Numbers (SVHN). Next, we evaluated the quality of samples generated by Triple-BigGAN with a resolution of 256 × 256 256×256 pixels using Inception Score (IS) and Frechet Inception Distance (FID). Our approach obtained the best FID (i.e., 19.94\% 19.94\% ) and IS (i.e., 97.98\% 97.98\% ) scores on the SEA-Faces-30k dataset. Further, we empirically demonstrated that synthetic erotic face images generated by Triple-BigGAN could also help in improving the classification performance of deep supervised networks.},
  archive      = {J_NEUCOM},
  author       = {Abhishek Gangwar and Víctor González-Castro and Enrique Alegre and Eduardo Fidalgo},
  doi          = {10.1016/j.neucom.2023.01.027},
  journal      = {Neurocomputing},
  pages        = {200-216},
  shortjournal = {Neurocomputing},
  title        = {Triple-BigGAN: Semi-supervised generative adversarial networks for image synthesis and classification on sexual facial expression recognition},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PDBI: A partitioning davies-bouldin index for clustering
evaluation. <em>NEUCOM</em>, <em>528</em>, 178–199. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering validation and identifying the optimal number of clusters are crucial in expert and intelligent systems. However, the commonly used cluster validity indices (CVI) are not relevant enough to measure data structures . They do not embed the necessary mechanisms to be as effective as that of the clustering algorithm used to give the clustering results . This paper proposes a novel CVI called PDBI (Partitioning Davies-Bouldin Index) initially inspired from the native idea of the Davies-Bouldin Index (DBI). PDBI is based on a strategy that consists in dividing each cluster into sub-clusters that redefine the concepts of internal homogeneity and cluster separation via the integration of sophisticated mechanisms. This strategy makes it possible to process a relevant CVI even in the case of complex data structures and in presence of clusters with noisy patterns. PDBI is deterministic, runs independently of a given clustering algorithm and generates a normalized score between 0 and 1. Numerous tests were carried out using 2-dimensional benchmark data sets and data generated in higher dimensions with consistent ground truths. The experimental comparisons with the state-of-the-art validity indices demonstrate the efficiency of the proposal in discovering the true number of clusters and dealing with various sorts of data sets. The PDBI demonstration as well as illustrations can be found on the author’s website 1},
  archive      = {J_NEUCOM},
  author       = {Frédéric Ros and Rabia Riad and Serge Guillaume},
  doi          = {10.1016/j.neucom.2023.01.043},
  journal      = {Neurocomputing},
  pages        = {178-199},
  shortjournal = {Neurocomputing},
  title        = {PDBI: A partitioning davies-bouldin index for clustering evaluation},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards an ML-based semantic IoT for pandemic management: A
survey of enabling technologies for COVID-19. <em>NEUCOM</em>,
<em>528</em>, 160–177. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The connection between humans and digital technologies has been documented extensively in the past decades but needs to be evaluated through the current global pandemic. Artificial Intelligence(AI), with its two strands, Machine Learning (ML) and Semantic Reasoning, has proven to be a great solution to provide efficient ways to prevent, diagnose and limit the spread of COVID-19. IoT solutions have been widely proposed for COVID-19 disease monitoring, infection geolocation, and social applications. In this paper, we investigate the usage of the three technologies for handling the COVID-19 pandemic. For this purpose, we surveyed the existing ML applications and algorithms proposed during the pandemic to detect COVID-19 disease using symptom factors and image processing . The survey includes existing approaches including semantic technologies and IoT systems for COVID-19. Based on the survey result, we classified the main challenges and the solutions that could solve them. The study proposes a conceptual framework for pandemic management and discusses challenges and trends for future research.},
  archive      = {J_NEUCOM},
  author       = {Rita Zgheib and Ghazar Chahbandarian and Firuz Kamalov and Haythem El Messiry and Ahmed Al-Gindy},
  doi          = {10.1016/j.neucom.2023.01.007},
  journal      = {Neurocomputing},
  pages        = {160-177},
  shortjournal = {Neurocomputing},
  title        = {Towards an ML-based semantic IoT for pandemic management: A survey of enabling technologies for COVID-19},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quality-aware pattern diffusion for video object
segmentation. <em>NEUCOM</em>, <em>528</em>, 148–159. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, great progresses have been achieved under the support of memory mechanism when dealing with video object segmentation (VOS) problem. Despite its achievements, existing VOS approaches still suffer from abnormal samples, which derive from intrinsic video artifacts such as occlusion and motion blur. To mitigate the above issue, in this paper, we propose a quality-aware pattern diffusion (QPD) framework to boost the VOS performance . To achieve quality-aware pattern diffusion , a quality alignment mechanism is proposed, and it aims to promote the contributions of those normal samples while suppressing those abnormal ones during the feature propagation/diffusion processes. With our proposed quality alignment mechanism, the diffused instance features could be kept staying in the normal feature space, keeping from feature contamination caused by those low-quality samples. We first introduce a learnable quality evaluator to assess the sample qualities in both the temporal domain (i.e., across the historical frames), as well as the spatial domain (i.e., within the current frame). To achieve adaptive historical feature propagation into the current instance, a quality-aware long-term context propagation module is proposed, with which more stable instance representations could be achieved through the established quality-aware feature propagation process. A quality-aware pattern diffusion module is further introduced to address the spatial-domain abnormal samples, resulting in effective decoder feature refinement through building the quality-aware correspondence weights. Extensive experiments have demonstrated that our proposed quality alignment mechanism could boost the performance by a great margin over a strong baseline while achieving state-of-the-art performances on public VOS benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Chuanwei Zhou and Chunyan Xu and Jun Li and Zhen Cui and Jian Yang},
  doi          = {10.1016/j.neucom.2023.01.044},
  journal      = {Neurocomputing},
  pages        = {148-159},
  shortjournal = {Neurocomputing},
  title        = {Quality-aware pattern diffusion for video object segmentation},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust anchor-based multi-view clustering via spectral
embedded concept factorization. <em>NEUCOM</em>, <em>528</em>, 136–147.
(<a href="https://doi.org/10.1016/j.neucom.2023.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) often provides superior effectiveness to single-view clustering due to the integration of information from diverse views. Nonetheless, existing MVC methods are limited to large-scale real-world data by the drawbacks of low efficiency and poor robustness. To address these issues, we propose a novel robust anchor-based MVC model via spectral embedded concept factorization (RAMCSF). RAMCSF builds anchor graphs to approximate full-sample graphs and decomposes these anchor graphs by concept factorization (CF). To improve the clustering effectiveness, factor matrices of CF are constrained as orthogonal matrices to reduce the freedom of decomposition, and a novel small-scale anchor-based spectral embedding is designed to explore the high-order neighbor relationships. To restrain complex noises distributed in real-world data, we employ correntropy to measure the error between the original data and the learned representation. Moreover, RAMCSF can get a clustering indicator matrix directly, avoiding additional post-processing and ensuring that changes in data dimensions have a limited impact on efficiency. The model is then optimized by a novel fast half-quadratic-based optimization strategy that combines the orthogonal properties and the traces of matrices. Extensive experiments indicate that RAMCSF can achieve higher efficiency and robustness while maintaining comparable effectiveness to other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Ben Yang and Jinghan Wu and Xuetao Zhang and Zhiping Lin and Feiping Nie and Badong Chen},
  doi          = {10.1016/j.neucom.2023.01.028},
  journal      = {Neurocomputing},
  pages        = {136-147},
  shortjournal = {Neurocomputing},
  title        = {Robust anchor-based multi-view clustering via spectral embedded concept factorization},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An active contour model reinforced by convolutional neural
network and texture description. <em>NEUCOM</em>, <em>528</em>, 125–135.
(<a href="https://doi.org/10.1016/j.neucom.2023.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active contour models (ACMs) are popular and widely used for many image segmentation applications and obtain promising results. However, these methods are unable to achieve the highest performance in the presence of intensity inhomogeneity . To address this issue, this paper presents an ACM based on the combination of a convolutional neural network (CNN) and a texture descriptor approach. This study uses a CNN model to generate parameter maps more effectively for ACM. Compared to conventional global techniques, these parameter maps increase the speed of movement of the contour into the target. In this approach, the Local Word Directional Pattern (LWDP) is applied as the texture descriptor . LWDP is a texture descriptor that uses the angle between two gradients for exploring the texture structure inside the image. In the proposed method both the original image and the new image obtained by the LWDP texture descriptor (encoded image) are provided as inputs to the CNN. The experimental outcomes show that the proposed strategy consistently outperforms the state-of-the-art in accuracy and robustness for segmenting images with fuzzy boundaries and intensity inhomogeneity .},
  archive      = {J_NEUCOM},
  author       = {Mosayyeb Nouri and Yasser Baleghi},
  doi          = {10.1016/j.neucom.2023.01.047},
  journal      = {Neurocomputing},
  pages        = {125-135},
  shortjournal = {Neurocomputing},
  title        = {An active contour model reinforced by convolutional neural network and texture description},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VNGEP: Filter pruning based on von neumann graph entropy.
<em>NEUCOM</em>, <em>528</em>, 113–124. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To facilitate the deployment of convolutional neural networks on resource-limited devices, neural network pruning, especially filter pruning, has been shown to be a promising approach. Precise channel importance evaluation requires the extraction of global feature information. In this paper, we propose a novel filter pruning method, VNGEP, which combines intra- and inter-channel information to evaluate channel importance comprehensively. We describe the feature map correlation information from a graph perspective. The feature map tensor is converted into an undirected weighted graph , where the edge weights are the cosine distance between feature maps. To characterize the individual information of the feature maps, we present the feature map energy matrix and embed it into the above undirected weighted graph . Ultimately, the filter importance is measured by the von Neumann graph entropy, thus identifying filters that are less informative and more replaceable by other filters. Moreover, we systematically investigate the computational feasibility and data sensitivity of the proposed scheme. Pruning experimental results for several models on different datasets show the superiority of our approach. For example, with ResNet110, our method achieves a 48.3\% and 52.1\% reduction in model size and FLOPs , respectively, along with a 1.07\% improvement in accuracy over the baseline model on CIFAR10. With ResNet50 , we achieve an accuracy improvement of 0.25\% over the baseline model on ImageNet, while the model size and FLOPs are reduced by 40.8\% and 44.8\%, respectively.},
  archive      = {J_NEUCOM},
  author       = {Chaokun Shi and Yuexing Hao and Gongyan Li and Shaoyun Xu},
  doi          = {10.1016/j.neucom.2023.01.046},
  journal      = {Neurocomputing},
  pages        = {113-124},
  shortjournal = {Neurocomputing},
  title        = {VNGEP: Filter pruning based on von neumann graph entropy},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diverse single image generation with controllable global
structure. <em>NEUCOM</em>, <em>528</em>, 97–112. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image generation from a single image using generative adversarial networks is quite interesting due to the realism of generated images. However, recent approaches need improvement for such realistic and diverse image generation, when the global context of the image is important such as in face, animal, and architectural image generation. This is mainly due to the use of fewer convolutional layers for capturing the patch statistics and, thereby, not being able to capture global statistics well. The challenge, then, is to preserve the global structure, while retaining the diversity and quality of image generation. We solve this problem by using attention blocks at selected scales and feeding a random Gaussian blurred image to the discriminator for training. We use adversarial feedback to make the quality of the generation better. Our results are visually better than the state-of-the-art, particularly, in generating images that require global context. The diversity of our image generation, measured using the average standard deviation of pixels, is also better.},
  archive      = {J_NEUCOM},
  author       = {Sutharsan Mahendren and Chamira U.S. Edussooriya and Ranga Rodrigo},
  doi          = {10.1016/j.neucom.2023.01.011},
  journal      = {Neurocomputing},
  pages        = {97-112},
  shortjournal = {Neurocomputing},
  title        = {Diverse single image generation with controllable global structure},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A kernel-based intuitionistic weight fuzzy k-modes algorithm
using coupled chained p system combines DNA genetic rules for
categorical data. <em>NEUCOM</em>, <em>528</em>, 84–96. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A kernel-based intuitionistic weight fuzzy k-modes algorithm (KIWFKM) is proposed in this paper which can improve the clustering performance of categorical data . The current FKM algorithm which were proposed by researchers generally have three drawbacks. Firstly, the algorithms were easily limited to the local optimal solution . Secondly, most of algorithms were considering all attributes equally. Thirdly, most algorithms are sensitive to noise data points. So the intuitionistic fuzzy sets (IFS), kernel trick and weight concept are introduced into the objective function which can not only solve the problem of all attributes equally but also improve the robustness to noise. In addition, a coupled DCP (chained tissue-like P system combines DNA genetic rules) system is established which is used for realizing the KIWFKM algorithm (KIWFKM-DCP). The uncertainty and implicit parallelism of the DCP system can help the KIWFKM algorithm jump out of the local optimal solution and find better solution. Finally, we conduct experiments and compare experiment results with six state-of-the-art clustering methods . Experimental results conduct that the KIWFKM-DCP algorithm perform better than the other comparison clustering algorithms .},
  archive      = {J_NEUCOM},
  author       = {Zhenni Jiang and Xiyu Liu and Wenke Zang},
  doi          = {10.1016/j.neucom.2023.01.020},
  journal      = {Neurocomputing},
  pages        = {84-96},
  shortjournal = {Neurocomputing},
  title        = {A kernel-based intuitionistic weight fuzzy k-modes algorithm using coupled chained p system combines DNA genetic rules for categorical data},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Synchronization analysis of fractional delayed memristive
neural networks via event-based hybrid impulsive controllers.
<em>NEUCOM</em>, <em>528</em>, 75–83. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the asymptotic synchronization of Riemann–Liouville fractional delayed memristive neural networks is explored. Firstly, in order to achieve the control target more effectively and economically, a new type of event-based hybrid impulsive controller is designed. In addition, through inequality techniques and impulse analysis methods, some sufficient criteria for asymptotic synchronization are obtained by constructing new Lyapunov–Krasovskii functionals. At the same time, it is verified that Zeno behavior could be eliminated under the given trigger conditions in the error system. It should be noted that some results based on algebraic inequalities fill in the gaps of existing ones and our controller is more practical and energy-saving. Lastly, a simulation instance is depicted to verify the validity and correctness of the submitted conclusions.},
  archive      = {J_NEUCOM},
  author       = {Huiyu Wang and Shutang Liu and Xiang Wu},
  doi          = {10.1016/j.neucom.2023.01.064},
  journal      = {Neurocomputing},
  pages        = {75-83},
  shortjournal = {Neurocomputing},
  title        = {Synchronization analysis of fractional delayed memristive neural networks via event-based hybrid impulsive controllers},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic synchronization for semi-markovian complex
dynamic networks with partly unknown transition rates. <em>NEUCOM</em>,
<em>528</em>, 59–74. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the synchronization of complex dynamic networks with time-varying delay and general semi-Markovian jump. The general transition rates include completely unknown and uncertain but bounded as two special cases. First, by introducing auxiliary vectors with a few nonorthogonal polynomials, two free-matrix-based integral inequalities are developed, which encompass some existing ones as special cases. Second, an integral- based delay-product-type Lyapunov-Krasovskii functional is constructed, which fully considers the information of time delay . By utilizing a deley-dependent controller, two sufficient conditions are derived to realize the global stochastic mean-square synchronization by employing the established inequalities to evaluate the infinitesimal generator of the functional. This paper takes all possibilities into consideration and divides the general transition rates into five cases, which is never investigated before. Finally a numerical example is given to show the effectiveness and practicality of the presented method.},
  archive      = {J_NEUCOM},
  author       = {Yue Zhang and Cheng-De Zheng},
  doi          = {10.1016/j.neucom.2023.01.019},
  journal      = {Neurocomputing},
  pages        = {59-74},
  shortjournal = {Neurocomputing},
  title        = {Stochastic synchronization for semi-markovian complex dynamic networks with partly unknown transition rates},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incorporating NODE with pre-trained neural differential
operator for learning dynamics. <em>NEUCOM</em>, <em>528</em>, 48–58.
(<a href="https://doi.org/10.1016/j.neucom.2023.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning dynamics governed by differential equations is crucial for predicting and controlling the systems in science and engineering. Neural Ordinary Differential Equation (NODE), a deep learning model integrated with differential equations, is popular in learning dynamics recently due to its robustness to irregular samples and its flexibility to high-dimensional input. However, the training of NODE is sensitive to the precision of the numerical solver, which makes the convergence of NODE unstable, especially for ill-conditioned dynamical systems. In this paper, to reduce the reliance on the numerical solver, we propose to enhance the supervised signal in the training of NODE. Specifically, we pre-train a neural differential operator (NDO) to output an estimation of the derivatives to serve as an additional supervised signal. The NDO is pre-trained on a class of basis functions and learns the mapping between the trajectory samples of these functions to their derivatives. To leverage both the trajectory signal and the estimated derivatives from NDO, we propose an algorithm called NDO-NODE, in which the loss function contains two terms: the fitness on the true trajectory samples and the fitness on the estimated derivatives that are outputted by the pre-trained NDO. Experiments on various kinds of dynamics show that our proposed NDO-NODE can consistently improve the forecasting accuracy with one pre-trained NDO. Especially for the stiff ODEs, we observe that NDO-NODE can capture the transitions in the dynamics more accurately compared with other regularization methods.},
  archive      = {J_NEUCOM},
  author       = {Shiqi Gong and Qi Meng and Yue Wang and Lijun Wu and Wei Chen and Zhiming Ma and Tie-Yan Liu},
  doi          = {10.1016/j.neucom.2023.01.040},
  journal      = {Neurocomputing},
  pages        = {48-58},
  shortjournal = {Neurocomputing},
  title        = {Incorporating NODE with pre-trained neural differential operator for learning dynamics},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MG-MVSNet: Multiple granularities feature fusion network for
multi-view stereo. <em>NEUCOM</em>, <em>528</em>, 35–47. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of Multi-View Stereo is to reconstruct the 3D point cloud model from multiple views. With the development of deep learning , more and more learning-based research has achieved remarkable results. However, existing methods ignore the fine-grained features of the bottom layer, which leads to the poor quality of model reconstruction, especially in terms of completeness. Besides, current methods still rely on a large amount of consumed memory resources because of the application of 3D convolution. To this end, this paper proposes a Multiple Granularities Feature Fusion Network for Multi-View Stereo, an end-to-end depth estimation network combining global and local features , which is characterized by fine-granularity multi-feature fusion. Firstly, we propose a dense feature adaptive connection module, which can adaptively fuse the global and local features in the scene, provide a more complete and effective feature map for inferring a more detailed depth map, and make the ultimate model more complete. Secondly, in order to further improve the accuracy and completeness of the reconstructed point cloud, we introduce normal and edge loss futead of only using depth loss functions as in the existing methods, which makes the network more sensitive to small depth structures. Finally, we propose distributed 3D convolution instead of traditional 3D convolution, which reduces memory consumption. The experimental results on the DTU and Tanks &amp; Temples datasets demonstrate that the proposed method in this papaer achieves the state-of-the-art performance, which proves the accuracy and effectiveness of the MG-MVSNet proposed in this paper.},
  archive      = {J_NEUCOM},
  author       = {Xuedian Zhang and Fanzhou Yang and Min Chang and Xiaofei Qin},
  doi          = {10.1016/j.neucom.2023.01.062},
  journal      = {Neurocomputing},
  pages        = {35-47},
  shortjournal = {Neurocomputing},
  title        = {MG-MVSNet: Multiple granularities feature fusion network for multi-view stereo},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Achieving domain generalization for underwater object
detection by domain mixup and contrastive learning. <em>NEUCOM</em>,
<em>528</em>, 20–34. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of existing underwater object detection methods severely degrades when they face the domain shift caused by complicated underwater environments. Due to the limited domain diversity in collected data, deep detectors easily memorize a few seen domains, which leads to low generalization ability . There are two common ideas to improve the domain generalization performance . First, it can be inferred that the detector trained on as many domains as possible is domain-invariant. Second, their hidden features should be equivalent because the images with the same semantic content are in different domains. This paper further excavates these two ideas and proposes a domain generalization framework that learns how to generalize across domains from Domain Mixup and Contrastive Learning (DMCL). First, based on the formation of underwater images, an image in one kind of underwater environment is the linear transformation of another underwater environment. Therefore, a style transfer model, which outputs a linear transformation matrix instead of the whole image, is proposed to transform images from one source domain to another, enriching the domain diversity of the training data. Second, the Mixup operation interpolates different domains on the feature level, sampling new domains on the domain manifold. Third, a contrastive loss is selectively applied to features from different domains to force the model to learn domain-invariant features but retain the discriminative capacity. With our method, detectors will be robust to domain shift. Also, a domain generalization benchmark S-UODAC2020 for detection is set up to measure the performance of our method. Comprehensive experiments on S-UODAC2020 and two object recognition benchmarks (PACS and VLCS) demonstrate that the proposed method is able to learn domain-invariant representations and outperforms other domain generalization methods. The code is available in https://github.com/mousecpn/DMC-Domain-Generalization-for-Underwater-Object-Detection.git},
  archive      = {J_NEUCOM},
  author       = {Yang Chen and Pinhao Song and Hong Liu and Linhui Dai and Xiaochuan Zhang and Runwei Ding and Shengquan Li},
  doi          = {10.1016/j.neucom.2023.01.053},
  journal      = {Neurocomputing},
  pages        = {20-34},
  shortjournal = {Neurocomputing},
  title        = {Achieving domain generalization for underwater object detection by domain mixup and contrastive learning},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed quadratic optimization with terminal consensus
iterative learning strategy. <em>NEUCOM</em>, <em>528</em>, 12–19. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper applies a terminal learning strategy to study distributed quadratic optimization problems . Since the optimal state is unknown in advance, the tracking error information is generally unavailable. To achieve the optimal state without the tracking error information, the terminal consensus iterative learning scheme is used to solve the problem. And the terminal consensus state is obtained without the global information of network. On this basis, the optimal target is also achieved by choosing the proper initial state and learning parameters. And the optimization problem is studied with the constraints of state and control input. Results show that our approach is effective. Compared with existing distributed optimization methods, the learning strategy in this paper provides another effective analysis scheme. Last, a numerical example is presented to show the effective aspects of the method.},
  archive      = {J_NEUCOM},
  author       = {Zijian Luo and Wenjun Xiong and Tingwen Huang and Jiang Duan},
  doi          = {10.1016/j.neucom.2023.01.038},
  journal      = {Neurocomputing},
  pages        = {12-19},
  shortjournal = {Neurocomputing},
  title        = {Distributed quadratic optimization with terminal consensus iterative learning strategy},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An ongoing review of speech emotion recognition.
<em>NEUCOM</em>, <em>528</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User emotional status recognition is becoming a key feature in advanced Human Computer Interfaces (HCI). A key source of emotional information is the spoken expression, which may be part of the interaction between the human and the machine. Speech emotion recognition (SER) is a very active area of research that involves the application of current machine learning and neural networks tools. This ongoing review covers recent and classical approaches to SER reported in the literature.},
  archive      = {J_NEUCOM},
  author       = {Javier de Lope and Manuel Graña},
  doi          = {10.1016/j.neucom.2023.01.002},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {An ongoing review of speech emotion recognition},
  volume       = {528},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A systematic review and analysis of deep learning-based
underwater object detection. <em>NEUCOM</em>, <em>527</em>, 204–232. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater object detection is one of the most challenging research topics in computer vision technology . The complex underwater environment makes underwater images suffer from high noise, low visibility, blurred edges, low contrast and color deviation, which brings significant challenges to underwater object detection tasks. In underwater object detection tasks, traditional object detection methods often perform poorly in terms of accuracy and generalization capabilities. Underwater object detection requires accurate, stable, generalizable, real-time and lightweight detection models, for which many researchers have proposed various underwater object detection techniques based on deep learning . Although many outstanding results have been achieved on underwater object detection over the years, the research status of underwater object detection techniques are still lack of unified induction, and some existing problems need to be further probed from the latest perspective. In addition, previous reviews lack analysis on the relationship between underwater image enhancement and object detection. Therefore, this paper provides a comprehensive review of the current research challenges, future development trends, and potential applications of underwater object detection techniques. More importantly, this paper has explored the internal relationship between underwater image enhancement and object detection, and analyzed the possible implementation manners of underwater image enhancement in the object detection task in order to further enhance its benefits. The experiments show the performances of current underwater image enhancement and state-of-the-art object detection algorithms , point out their limitations, and indicate that there is not a strict positive correlation between underwater image enhancement and the accuracy improvement of object detection. The domain shift caused by underwater image enhancement cannot be ignored. This paper can be regarded as a guide for future works on underwater object detection.},
  archive      = {J_NEUCOM},
  author       = {Shubo Xu and Minghua Zhang and Wei Song and Haibin Mei and Qi He and Antonio Liotta},
  doi          = {10.1016/j.neucom.2023.01.056},
  journal      = {Neurocomputing},
  pages        = {204-232},
  shortjournal = {Neurocomputing},
  title        = {A systematic review and analysis of deep learning-based underwater object detection},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Canonical cortical graph neural networks and its application
for speech enhancement in audio-visual hearing aids. <em>NEUCOM</em>,
<em>527</em>, 196–203. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the recent success of machine learning algorithms , most models face drawbacks when considering more complex tasks requiring interaction between different sources, such as multimodal input data and logical time sequences. On the other hand, the biological brain is highly sharpened in this sense, empowered to automatically manage and integrate such streams of information. In this context, this work draws inspiration from recent discoveries in brain cortical circuits to propose a more biologically plausible self-supervised machine learning approach . This combines multimodal information using intra-layer modulations together with Canonical Correlation Analysis, and a memory mechanism to keep track of temporal data, the overall approach termed Canonical Cortical Graph Neural networks . This is shown to outperform recent state-of-the-art models in terms of clean audio reconstruction and energy efficiency for a benchmark audio-visual speech dataset. The enhanced performance is demonstrated through a reduced and smother neuron firing rate distribution. suggesting that the proposed model is amenable for speech enhancement in future audio-visual hearing aid devices.},
  archive      = {J_NEUCOM},
  author       = {Leandro A. Passos and João Paulo Papa and Amir Hussain and Ahsan Adeel},
  doi          = {10.1016/j.neucom.2022.11.081},
  journal      = {Neurocomputing},
  pages        = {196-203},
  shortjournal = {Neurocomputing},
  title        = {Canonical cortical graph neural networks and its application for speech enhancement in audio-visual hearing aids},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical approach for fusion of electroencephalography
and electromyography for predicting finger movements and kinematics
using deep learning. <em>NEUCOM</em>, <em>527</em>, 184–195. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain is a unique organ that performs multiple processes simultaneously, such as sensory, motor, and cognitive function. However, several neurological diseases (ataxia, dystonia, Huntington’s disease) or trauma affect the limb movement and there is no cure. Although brain-computer interfaces (BCIs) have been recently used to improve the quality of life for people with severe motor disabilities, anthropomorphic control of a prosthetic hand in upper limb rehabilitation still remains an unachieved goal. To this purpose, a hierarchical integration of neural commands to fingers was applied for execution of human hand grasping with better precision. For finger movement prediction and kinematics estimation, a neuromuscular approach was employed to establish a hierarchical synergy between electroencephalography (EEG) and electromyography (EMG). EEG, EMG and metacarpophalangeal (MCP) joint kinematics were acquired during five finger flexion movements of the human hand. EMG for five finger movements and kinematics were estimated from EEG using linear regression. A Long Short-Term Memory network (LSTM) and a random forest regressor were adjoined hierarchically for prediction of finger movements and estimation of finger kinematics from the estimated EMG. The results showed an average accuracy of 84.25 ± 0.61\% in predicting finger movements and an average minimum error of 0.318 ± 0.011 in terms of root mean squared error (RMSE) in predicting finger kinematics from EEG across six subjects and five fingers. These findings suggest the implementation of a hierarchical approach to develop anthropomorphic control for upper limb prostheses.},
  archive      = {J_NEUCOM},
  author       = {Tanaya Das and Lakhyajit Gohain and Nayan M Kakoty and MB Malarvili and Prihartini Widiyanti and Gajendra Kumar},
  doi          = {10.1016/j.neucom.2023.01.061},
  journal      = {Neurocomputing},
  pages        = {184-195},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical approach for fusion of electroencephalography and electromyography for predicting finger movements and kinematics using deep learning},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural koopman lyapunov control. <em>NEUCOM</em>,
<em>527</em>, 174–183. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning and synthesizing stabilizing controllers for unknown nonlinear control systems is a challenging problem for real-world and industrial applications. Koopman operator theory allows one to analyze nonlinear systems through the lens of linear systems and nonlinear control systems through the lens of bilinear control systems. The key idea of these methods lies in the transformation of the coordinates of the nonlinear system into the Koopman observables, which are coordinates that allow the representation of the original system (control system) as a higher dimensional linear (bilinear control) system. However, for nonlinear control systems, the bilinear control model obtained by applying Koopman operator based learning methods is not necessarily stabilizable. Simultaneous identification of stabilizable lifted bilinear control systems as well as the associated Koopman observables is still an open problem. In this paper, we propose a framework to construct such stabilizable bilinear models and identify their associated observables from data by simultaneously learning a bilinear Koopman embedding for the underlying unknown control affine nonlinear system as well as a Control Lyapunov Function (CLF) for the Koopman based bilinear model using a learner and falsifier. Our proposed approach thereby provides provable guarantees of asymptotic stability for the Koopman based representation of the unknown control affine nonlinear control system as a bilinear system. Numerical simulations are provided to validate the efficacy of our proposed class of stabilizing feedback controllers for unknown control-affine nonlinear systems .},
  archive      = {J_NEUCOM},
  author       = {Vrushabh Zinage and Efstathios Bakolas},
  doi          = {10.1016/j.neucom.2023.01.029},
  journal      = {Neurocomputing},
  pages        = {174-183},
  shortjournal = {Neurocomputing},
  title        = {Neural koopman lyapunov control},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved reciprocally convex inequality for stability
analysis of neural networks with time-varying delay. <em>NEUCOM</em>,
<em>527</em>, 167–173. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stability of a type of neural network with time-varying delay is studied. Two general ( α 2 , β 2 ) (α2,β2) and ( α 2 , β 2 , γ 2 ) (α2,β2,γ2) -dependent reciprocally convex inequalities with two and three terms are derived to introduce some quadratic terms into the estimate for the derivative of the Lyapunov–Krasovskii functionals (LKFs). The LKF method is used to develop a stability criterion for time-delay neural networks by using the new inequalities. To demonstrate the improvement of the new criterion, numerical results are provided.},
  archive      = {J_NEUCOM},
  author       = {Chenyang Shi and Kachon Hoi and Seakweng Vong},
  doi          = {10.1016/j.neucom.2023.01.048},
  journal      = {Neurocomputing},
  pages        = {167-173},
  shortjournal = {Neurocomputing},
  title        = {Improved reciprocally convex inequality for stability analysis of neural networks with time-varying delay},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HyperDNE: Enhanced hypergraph neural network for dynamic
network embedding. <em>NEUCOM</em>, <em>527</em>, 155–166. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning provides an attractive opportunity to model the evolution of dynamic networks. However, the existing methods have two limitations: (1) most graph neural network-based methods fail to utilize the high-order proximity of nodes that captures the important properties of a network topology ; (2) evolutionary dynamics-based methods are much fine-grained in modeling time information but neglect the coherence of dynamic networks, which leads to the model being susceptible to subtle noise. In this paper, we propose an enhanced hypergraph neural network framework for dynamic network embedding (HyperDNE) to tackle these issues. Specifically, we innovatively design a sequential hypergraph with dual-stream output to explore the group properties of nodes and edges, and a line graph neural network is added as an auxiliary enhancement scheme to further aggregate social influence from the degree of social convergence. Then, we compute the final embedding through attentions along the node and hyperedge levels to fuse multi-level variations in the network structure. The experimental results on six real networks demonstrate significant gains for HyperDNE over several state-of-the-art network embedding baselines. The dataset and source code of HyperDNE are publicly available at https://github.com/qhgz2013/HyperDNE.},
  archive      = {J_NEUCOM},
  author       = {Jin Huang and Tian Lu and Xuebin Zhou and Bo Cheng and Zhibin Hu and Weihao Yu and Jing Xiao},
  doi          = {10.1016/j.neucom.2023.01.039},
  journal      = {Neurocomputing},
  pages        = {155-166},
  shortjournal = {Neurocomputing},
  title        = {HyperDNE: Enhanced hypergraph neural network for dynamic network embedding},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Subspace screening rule for multi-label estimator with
sparsity-inducing regularization. <em>NEUCOM</em>, <em>527</em>,
143–154. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning has drawn wide attention for the last decade. To exploit the correlation between labels, a multi-label classifier based on the nuclear norm has been proposed recently, which joints Ranking support vector machine (RankSVM) and Binary Relevance (BR) with robust Low-rank learning (RBRL). Therefore, it has satisfactory classification outcomes in the application. Nonetheless, tackling the large-scale problem still remains a challenge for RBRL. Motivated by this, a Subspace Screening Rule (SSR) for RBRL is proposed to accelerate the solving process. Its primary strategy is to reduce the size of the matrix variable to be estimated, based on the fact that a low-rank matrix can be represented by a few subspaces. Specifically, at each iteration we delete a majority of subspaces with zero coefficients in the optimal solution by matrix decomposition and optimality condition. Then, we solve the small-scale reduced problem rather than the initial large-scale matrix problem. An excellent acceleration effect is obtained. To further improve the solving speed, Approximate Singular Value Decomposition (ASVD) and Accelerated Proximal Gradient (APG) are employed in the different stages. Extensive experiments on seven benchmark datasets as well as an artificial dataset demonstrate the efficiency of SSR.},
  archive      = {J_NEUCOM},
  author       = {Peiwei Zhong and Yitian Xu},
  doi          = {10.1016/j.neucom.2023.01.030},
  journal      = {Neurocomputing},
  pages        = {143-154},
  shortjournal = {Neurocomputing},
  title        = {Subspace screening rule for multi-label estimator with sparsity-inducing regularization},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Stochastic bipartite consensus for second-order multi-agent
systems with communication noise and antagonistic information.
<em>NEUCOM</em>, <em>527</em>, 130–142. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the bipartite consensus problem for second-order multi-agent systems with no leader, one leader and multiple leaders are investigated, where the information exchange is disturbed by measurement noise and antagonistic information. In order to attenuate the effect of communication noise, a time-varying gain c ( t ) c(t) is utilized and the stochastic approximation bipartite control protocol is proposed. It is given that the underlying protocol can solve the bipartite consensus problem for MASs with no leader/one leader/multiple leaders if the communication topology is strongly connected/has a spanning tree/has a spanning forest and the c ( t ) c(t) satisfies some mild condition. Meanwhile, for system with these three cases, a series of sufficient and necessary conditions are given. Especially, for the case with no leader, we obtain that the final state of agent is related with the initial position and initial velocity of each agent. For the case with one leader, we can get that the followers in one group can follow up the state of one leader, and the followers in another group tend to the opposite value. Additionally, for the case with multiple leaders, the containment control can be achieved where followers’ states in one group can converge to the quai-convex hull of leaders’ state and the ones in another group converge to the opposite convex hull . Finally, some numerical examples are given to support our new results.},
  archive      = {J_NEUCOM},
  author       = {Chongyang Wang and Zhi Liu and Ancai Zhang and Jianlong Qiu and Yingxue Du},
  doi          = {10.1016/j.neucom.2023.01.031},
  journal      = {Neurocomputing},
  pages        = {130-142},
  shortjournal = {Neurocomputing},
  title        = {Stochastic bipartite consensus for second-order multi-agent systems with communication noise and antagonistic information},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MENet: Lightweight multimodality enhancement network for
detecting salient objects in RGB-thermal images. <em>NEUCOM</em>,
<em>527</em>, 119–129. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most red–green–blue and thermal (RGB-T) salient object detection methods require high memory consumption and incur large computational costs, which limit their applicability. To alleviate the computational resource requirements, we propose a lightweight multimodality enhancement network (MENet) for RGB-T salient object detection with relatively few parameters. As the RGB and thermal images are from different domains, the modality gap leads to unsatisfactory results if using simple feature concatenation. Instead, we introduce a multimodality complementary enhancement module with a nested residual structure to fuse RGB and thermal features. During decoding, we design a recursive sharpening module that is inspired by atrous spatial pyramid pooling and dense connections and has fewer parameters than similar methods. By reducing the number of parameters and computations of each component, MENet ends up having only 21.26 M parameters and running with 2.501G floating-point operations. Experiments were performed on three benchmark datasets. The results show that the proposed MENet can consistently outperform 16 state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Junyi Wu and Wujie Zhou and Xiaohong Qian and Jingsheng Lei and Lu Yu and Ting Luo},
  doi          = {10.1016/j.neucom.2023.01.024},
  journal      = {Neurocomputing},
  pages        = {119-129},
  shortjournal = {Neurocomputing},
  title        = {MENet: Lightweight multimodality enhancement network for detecting salient objects in RGB-thermal images},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forgery face detection via adaptive learning from multiple
experts. <em>NEUCOM</em>, <em>527</em>, 110–118. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important and challenging problem, Face Forgery Detection has gained considerable attention. Usually, it suffers from the diversity of forgery patterns in forgery images, which requires a detection model to have capability of capturing various patterns in the challenging scenarios. To address this problem, we present a divide-and-aggregate learning framework to build multi-expert models and integrate them into a unified model. Firstly, the built multi-expert models are pre-trained to capture and preserve the specific forgery pattern produced by each manipulation method separately. Secondly, to transfer diverse knowledge of experts, we propose an integrating approach based on knowledge distillation . However, the difference of manipulation-aware knowledge among these experts concerns the way of distillation when the knowledge is combined in the only student model. Thus, to determine the importance of each expert, we propose a sample-aware Adaptive Learning from Experts strategy (ALFE) to assign adaptive expert distillation weights for each fake sample based on the predictions of each expert. Experiments show that our method achieves SOTA performances on ACC/AUC in the benchmark of FaceForensics++, demonstrating the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Xinghe Fu and Shengming Li and Yike Yuan and Bin Li and Xi Li},
  doi          = {10.1016/j.neucom.2023.01.017},
  journal      = {Neurocomputing},
  pages        = {110-118},
  shortjournal = {Neurocomputing},
  title        = {Forgery face detection via adaptive learning from multiple experts},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLC-net: Contextual and local collaborative network for
lesion segmentation in diabetic retinopathy images. <em>NEUCOM</em>,
<em>527</em>, 100–109. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is the leading cause of blindness among people of working age. Fundus lesions are clinical signs of DR, and their recognition and delineation are important for early screening, grading, and monitoring of the disease. We propose in this work a fully automatic deep convolutional neural network method for simultaneous segmentation of four different types of DR-related fundus lesions. To exploit multi-scale image information, we propose a collaborative architecture that comprises a contextual branch and a local branch. An attention mechanism is designed to fuse feature maps from all decoding layers in order to effectively and fully combine informative features from the two branches. Moreover, an auxiliary classification task with a novel supervision scheme is introduced to reduce model overfitting and further improve the accuracy of lesion segmentation . Extensive experiments are conducted using three public fundus datasets, and our method produces a mean AUC value of 0.677, 0.629, and 0.581 on them respectively. The results demonstrate the advantages of the proposed method, outperforming alternative strategies and other state-of-the-art methods in the literature.},
  archive      = {J_NEUCOM},
  author       = {Xiyue Wang and Yuqi Fang and Sen Yang and Delong Zhu and Minghui Wang and Jing Zhang and Jun Zhang and Jun Cheng and Kai-yu Tong and Xiao Han},
  doi          = {10.1016/j.neucom.2023.01.013},
  journal      = {Neurocomputing},
  pages        = {100-109},
  shortjournal = {Neurocomputing},
  title        = {CLC-net: Contextual and local collaborative network for lesion segmentation in diabetic retinopathy images},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Engineering morphological development in a robotic bipedal
walking problem: An empirical study. <em>NEUCOM</em>, <em>527</em>,
83–99. (<a href="https://doi.org/10.1016/j.neucom.2023.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In living beings, the natural development of the body has been shown to facilitate learning. The application of these natural developmental principles in robotics have been considered in different robotic morphologies and scenarios, leading to mixed results. Development was found to be beneficial for learning in some instances, but also irrelevant or detrimental in others. This mix of results and scenarios has allowed researchers to extract some notions about the conditions that must be fulfilled or set to apply morphological development successfully. Notions that we have organized to set a series of design conditions to successfully apply morphological development. Thus, in this article, we are going to focus on the study of one of them that has been frequently addressed by researchers in their studies in very general terms. It can be described as the need to achieve a suitable synergy among the different components involved in the development and learning process: morphological development strategy, controller, task, and learning algorithm. In particular, we have concentrated on empirically determining the influence of five developmental strategies, implemented in different ways, applied at different speeds and deployed in different orders and combinations, over the problem of a NAO robot controlled by an artificial neural network obtained through a neuroevolutionary algorithm learning a bipedal walking task. The results obtained permit providing a more detailed description of what a suitable synergy implies and how it can be utilized to design more successful morphological developmental processes to improve robot learning.},
  archive      = {J_NEUCOM},
  author       = {M. Naya-Varela and A. Faina and R.J. Duro},
  doi          = {10.1016/j.neucom.2023.01.003},
  journal      = {Neurocomputing},
  pages        = {83-99},
  shortjournal = {Neurocomputing},
  title        = {Engineering morphological development in a robotic bipedal walking problem: An empirical study},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). THFuse: An infrared and visible image fusion network using
transformer and hybrid feature extractor. <em>NEUCOM</em>, <em>527</em>,
71–82. (<a href="https://doi.org/10.1016/j.neucom.2023.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion aims to integrate complementary information from different types of images into one image. The existing image fusion methods are primarily based on convolutional neural network (CNN), which ignores long-range dependencies of images, resulting in the fusion network unable to generate images with good complementarity. Inspired by the importance of global information, we introduced the transformer technique into the CNN-based fusion network as a way to improve the entire image-level perception in complex fusion scenarios. In this paper, we propose an end-to-end image fusion framework based on transformer and hybrid feature extractor, which enables the network to focus on both global and local information, using the characteristics of transformer to compensate for the shortcomings of CNN itself. In our network, the dual-branch CNN module is used to extract the shallow features of images, and then the vision transformer module is used to obtain the global channel and spatial relationship in the features. Finally, the fusion results are obtained through the image reconstruction module. We calculate the loss in the features of different depths according to the different kinds of original images by using the pre-trained VGG19 network. The experimental results show the effectiveness of adding the vision transformer module. Compared with other traditional and deep learning methods , our method achieves state-of-the-art qualitative and quantitative experiments performance.},
  archive      = {J_NEUCOM},
  author       = {Jun Chen and Jianfeng Ding and Yang Yu and Wenping Gong},
  doi          = {10.1016/j.neucom.2023.01.033},
  journal      = {Neurocomputing},
  pages        = {71-82},
  shortjournal = {Neurocomputing},
  title        = {THFuse: An infrared and visible image fusion network using transformer and hybrid feature extractor},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural collapse inspired attraction–repulsion-balanced loss
for imbalanced learning. <em>NEUCOM</em>, <em>527</em>, 60–70. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance distribution widely exists in real-world engineering. However, the mainstream optimization algorithms that seek to minimize error will trap the deep learning model in sub-optimums when facing extreme class imbalance. It seriously harms the classification precision, especially in the minor classes. The essential reason is that the gradients of the classifier weights are imbalanced among the components from different classes. In this paper, we propose Attraction–Repulsion-Balanced Loss (ARB-Loss) to balance the different components of the gradients. We perform experiments on large-scale classification and segmentation datasets, and our ARB-Loss can achieve state-of-the-art performance via only one-stage training instead of 2-stage learning like nowadays SOTA works.},
  archive      = {J_NEUCOM},
  author       = {Liang Xie and Yibo Yang and Deng Cai and Xiaofei He},
  doi          = {10.1016/j.neucom.2023.01.023},
  journal      = {Neurocomputing},
  pages        = {60-70},
  shortjournal = {Neurocomputing},
  title        = {Neural collapse inspired attraction–repulsion-balanced loss for imbalanced learning},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel total nitrogen prediction method based on recurrent
neural networks utilizing cross-coupling attention and selective
attention. <em>NEUCOM</em>, <em>527</em>, 48–59. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the critical role the total nitrogen (TN) plays in the stable operation of wastewater treatment plants (WWTPs), it is necessary to predict its future variation accurately. However, limited by current detection techniques, only a few kinds of water quality parameters (WQPs) with finite historical data can be obtained in the WWTPs. The small sample size of WQPs tremendously hinders the precision of TN prediction. In this study, a novel cross-coupling attention recurrent neural network (CCA-RNN) is proposed to overcome this problem. First, cross-coupling attention (CCA) is designed to enable the topological structures in the historical input data to be directly and effectively extracted with fewer training samples. Then, selective attention is introduced to dynamically select the useful topological relationships and the corresponding variables sent by the high-speed channel. Compared with the other state-of-the-art methods, CCA-RNN achieves the best performance on both the public and practical wastewater datasets, proving its superiority and great potential to be deployed in similar problems.},
  archive      = {J_NEUCOM},
  author       = {Jingxuan Geng and Chunhua Yang and Lijuan Lan and Yonggang Li and Jie Han and Can Zhou},
  doi          = {10.1016/j.neucom.2023.01.010},
  journal      = {Neurocomputing},
  pages        = {48-59},
  shortjournal = {Neurocomputing},
  title        = {A novel total nitrogen prediction method based on recurrent neural networks utilizing cross-coupling attention and selective attention},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum to “realistic acceleration of neural networks
with fine-grained tensor decomposition” [neurocomputing 512 (2022)
52–68]. <em>NEUCOM</em>, <em>527</em>, 47. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Rui Lv and Dingheng Wang and Jiangbin Zheng and Yefan Xie and Zhao-Xu Yang},
  doi          = {10.1016/j.neucom.2023.01.065},
  journal      = {Neurocomputing},
  pages        = {47},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Realistic acceleration of neural networks with fine-grained tensor decomposition” [Neurocomputing 512 (2022) 52–68]},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balanced knowledge distillation for long-tailed learning.
<em>NEUCOM</em>, <em>527</em>, 36–46. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep models trained on long-tailed datasets exhibit unsatisfactory performance on tail classes. Existing methods usually modify the classification loss to increase the learning focus on tail classes, which unexpectedly sacrifice the performance on head classes. In fact, this scheme leads to a contradiction between the two goals of long-tailed learning, i.e., learning generalizable representations and facilitating learning for tail classes. In this work, we explore knowledge distillation in long-tailed scenarios and propose a novel distillation framework, named Balanced Knowledge Distillation (BKD) , to disentangle the contradiction between the two goals and achieve both simultaneously. Specifically, given a teacher model, we train the student model by minimizing the combination of an instance-balanced classification loss and a class-balanced distillation loss. The former benefits from the sample diversity and learns generalizable representation, while the latter considers the class priors and facilitates learning for tail classes. We conduct extensive experiments on several long-tailed benchmark datasets and demonstrate that the proposed BKD is an effective knowledge distillation framework in long-tailed scenarios, as well as a competitive method for long-tailed learning. Our source code is available: https://github.com/EricZsy/BalancedKnowledgeDistillation .},
  archive      = {J_NEUCOM},
  author       = {Shaoyu Zhang and Chen Chen and Xiyuan Hu and Silong Peng},
  doi          = {10.1016/j.neucom.2023.01.063},
  journal      = {Neurocomputing},
  pages        = {36-46},
  shortjournal = {Neurocomputing},
  title        = {Balanced knowledge distillation for long-tailed learning},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Last-iterate convergence analysis of stochastic momentum
methods for neural networks. <em>NEUCOM</em>, <em>527</em>, 27–35. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic momentum method is a commonly used acceleration technique for solving large-scale stochastic optimization problems. Current convergence results of stochastic momentum methods under non-convex stochastic settings mostly discuss convergence in terms of the random output and minimum output, which requires temporal and spatial statistics of historical data. On the other hand, the last-iterate convergence allows us to avoid storing or selecting past output iterates after each iteration, while maintaining rigour in convergence analysis . To this end, we address the convergence of the last iterate output (called last-iterate convergence ) of the stochastic momentum methods for non-convex stochastic optimization problems, in a way which is conformal with traditional optimization theory . For generality, we prove the last-iterate convergence of the stochastic momentum methods under a unified framework, covering both stochastic heavy ball momentum and stochastic Nesterov accelerated gradient momentum, whose momentum factors can be either constant or time-varying coefficients. Finally, the last-iterate convergence of the stochastic momentum methods is verified on the benchmark MNIST and CIFAR-10 datasets. The implementation of SUM is available at: https://github.com/xudp100/SUMhttps://github.com/xudp100/SUM.},
  archive      = {J_NEUCOM},
  author       = {Jinlan Liu and Dongpo Xu and Yinghua Lu and Jun Kong and Danilo P. Mandic},
  doi          = {10.1016/j.neucom.2023.01.032},
  journal      = {Neurocomputing},
  pages        = {27-35},
  shortjournal = {Neurocomputing},
  title        = {Last-iterate convergence analysis of stochastic momentum methods for neural networks},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An IoU-aware siamese network for real-time visual tracking.
<em>NEUCOM</em>, <em>527</em>, 13–26. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most Siamese trackers decompose the tracking task into two branches: classification and bounding box regression. They choose the bounding box with the highest classification score or the combination of the classification and predicted localization scores as the target. However, the misalignment between the classification and localization accuracy will degrade tracking performance. In this paper, we propose an IoU-aware Siamese tracker named IASNet , which predicts the IoU classification score of each regressed box to represent its localization confidence. We introduce a novel residual alignment module to capture the scale of each predicted bounding box and its border context, which further improves the reliability of the classification prediction. In addition, we build dynamic links between the classification and regression branches to enhance their interaction. The proposed dynamic loss enables the training to focus on high-quality positive samples, leading to more precise localization. Extensive experimental results on VOT2016, VOT2019, OTB100, GOT10k, UAV123, and LaSOT show that the proposed IASNet achieves state-of-the-art tracking performance and runs at approximately 65 fps on a GTX 3090 GPU, which far exceeds the real-time requirement.},
  archive      = {J_NEUCOM},
  author       = {Bingbing Wei and Hongyu Chen and Siqi Cao and Qinghai Ding and Haibo Luo},
  doi          = {10.1016/j.neucom.2023.01.041},
  journal      = {Neurocomputing},
  pages        = {13-26},
  shortjournal = {Neurocomputing},
  title        = {An IoU-aware siamese network for real-time visual tracking},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Self-supervised learning based transformer and convolution
hybrid network for one-shot organ segmentation. <em>NEUCOM</em>,
<em>527</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot medical segmentation aims at segmenting the desired regions from the input medical imaging data with only a pre-annotated example as the reference. By using the minimal annotation data to facilitate the segmentation, the few-shot manner receives great attention in the medial image analysis community due to its weak requirement on human annotation. For one-shot segmentation methods , one core issue is to learn a feature embedding space where the features of the desired segmentation regions on the unlabeled image and the references are high correlation. Previous works rely on the similarity between image features as a constraint to establish such embedding space, ignoring the correlation between samples mined from image features . To address this issue, we propose a novel transformer and convolution hybrid network for building the global correlation between the reference sample (support) and the desired segmentation sample (query). The convolution network is first to extract the local features of the support and query, then, the transformer further extracts the global features from the local feature space. To build the global correction between the support and query, we proposed a semantic dependency relationship embedding which introduces the channel-wise and spatial-wise co-information of them to the transformer. We employ superpixel-based self-supervised learning to train the proposed network to solve the problem of insufficient training samples in the field of medical image segmentation . Comprehensive experiments on two benchmarks demonstrate the superior capacity of the proposed approach when compared to the current alternatives and baseline models .},
  archive      = {J_NEUCOM},
  author       = {Bo Wang and Qian Li and Zheng You},
  doi          = {10.1016/j.neucom.2022.12.028},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised learning based transformer and convolution hybrid network for one-shot organ segmentation},
  volume       = {527},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Δfree-LSTM: An error distribution free deep learning for
short-term traffic flow forecasting. <em>NEUCOM</em>, <em>526</em>,
180–190. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely and accurate traffic flow forecasting is open challenging. Canonical long short-term memory (LSTM) network is considered qualified to capture the long-term temporal dependencies in traffic flow. However, the training of LSTM networks is often guided by the mean square error (MSE) criterion. Such criterion depends on a strong assumption that the errors between the traffic flow and its predictions are Gaussian independent identically distributed. In this regard, the forecasting performance is seriously deteriorated by non-Gaussian noises inside the traffic flow sequences. To address this issue, we relax the assumption of the prediction errors to arbitrary distribution by a negative guided mixed correntropy criterion. Then, we formulate a robust loss function by the negative guided mixed correntropy criterion. We subsequently equip the loss function in an LSTM network, termed Δ free Δfree -LSTM, for short-term traffic flow forecasting. Extensive experiments on four benchmark datasets demonstrate that the Δ free Δfree -LSTM network outperforms the traditional parametric and nonparametric models, as well as state-of-the-art LSTM family models. The source code is available at https://github.com/541764418/Delta-free-LSTM .},
  archive      = {J_NEUCOM},
  author       = {Weiwei Fang and Wenhao Zhuo and Youyi Song and Jingwen Yan and Teng Zhou and Jing Qin},
  doi          = {10.1016/j.neucom.2023.01.009},
  journal      = {Neurocomputing},
  pages        = {180-190},
  shortjournal = {Neurocomputing},
  title        = {Δfree-LSTM: An error distribution free deep learning for short-term traffic flow forecasting},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Density-based clustering with fully-convolutional networks
for crowd flow detection from drones. <em>NEUCOM</em>, <em>526</em>,
169–179. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd analysis from drones has attracted increasing attention in recent times due to the ease of use and affordable cost of these devices. However, how this technology can provide a solution to crowd flow detection is still an unexplored research question. To this end, we propose a crowd flow detection method for video sequences shot by a drone. The method is based on a fully-convolutional network that learns to perform crowd clustering in order to detect the centroids of crowd-dense areas and track their movement in consecutive frames. The proposed method proved effective and efficient when tested on the Crowd Counting datasets of the VisDrone challenge, characterized by video sequences rather than still images. The encouraging results show that the proposed method could open up new ways of analyzing high-level crowd behavior from drones.},
  archive      = {J_NEUCOM},
  author       = {Giovanna Castellano and Eugenio Cotardo and Corrado Mencar and Gennaro Vessio},
  doi          = {10.1016/j.neucom.2023.01.059},
  journal      = {Neurocomputing},
  pages        = {169-179},
  shortjournal = {Neurocomputing},
  title        = {Density-based clustering with fully-convolutional networks for crowd flow detection from drones},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A predefined-time and anti-noise varying-parameter ZNN model
for solving time-varying complex stein equations. <em>NEUCOM</em>,
<em>526</em>, 158–168. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A predefined-time and anti-noise varying-parameter zeroing neural network (PTAN-VPZNN) is designed to resolve time-varying complex Stein equations in this paper. Differing from the existing ZNNs, the merits of the proposed PTAN-VPZNN include: 1) a varying parameter that improves ZNN model’s convergence speed, which is more compatible with characteristics of the actual hardware parameter; 2) a noise-tolerant activation function which enables the PTAN-VPZNN model to solve Stein equations under noisy environments . Thence, the PTAN-VPZNN model has better convergence performance and noise immunity ability. Moreover, the predefined-time convergence of the PTAN-VPZNN is presented and the robustness of the PTAN-VPZNN is analyzed under constant noise, through rigorous theoretical derivations. Numerical studies demonstrate that the performance of the PTAN-VPZNN is better than the existing ZNNs including a linear ZNN (LZNN), a nonlinear ZNN (NLZNN), a finite-time convergent ZNN (FTCZNN) and a predefined-time convergent ZNN (PTCZNN), when solving Stein equations with or without noise involved. Finally, the PTAN-VPZNN is applied to a mobile manipulator for completing a path-tracking task, showing its potential application in robot control.},
  archive      = {J_NEUCOM},
  author       = {Lin Xiao and Linju Li and Juan Tao and Weibing Li},
  doi          = {10.1016/j.neucom.2023.01.008},
  journal      = {Neurocomputing},
  pages        = {158-168},
  shortjournal = {Neurocomputing},
  title        = {A predefined-time and anti-noise varying-parameter ZNN model for solving time-varying complex stein equations},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust recurrent neural networks for time series
forecasting. <em>NEUCOM</em>, <em>526</em>, 143–157. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNNs) are widely utilized in time series forecasting tasks. In practical applications, there are noises in real-life time series data . A model’s generalization capacity will be diminished by model uncertainty with regard to input noises. However, the robustness of RNNs with respect to input noises has not been well studied yet. The localized stochastic sensitivity (LSS), which measures output disturbances with respect to input perturbations of learning models, has been successfully applied to improve the robustness of different neural networks on tabular and image data. But its effectiveness on time series data has not been explored. Therefore, we extend the idea of LSS and apply it to the robust RNNs training for time series forecasting problems. With the minimization of LSS, output sensitivities of RNNs with respect to small perturbations are reduced. So, the proposed robust RNNs will not be affected by slight input noises. We have used the LSTM as an example for theoretical analysis and analyzed the effectiveness of LSS on several RNN variants including the vanilla RNN, the gated recurrent unit (GRU), the long-short-term memory (LSTM), and the bi-directional long short-term memory (Bi-LSTM) in empirical studies. Experimental results confirm the efficiency of applying LSS to enhance the robustness of RNNs for time series data. For example, the robust RNNs outperform their counterpart by 53.26\% 53.26\% and 49.45\% 49.45\% on average in terms of Root Mean Squared Error and R-Square on five datasets.},
  archive      = {J_NEUCOM},
  author       = {Xueli Zhang and Cankun Zhong and Jianjun Zhang and Ting Wang and Wing W.Y. Ng},
  doi          = {10.1016/j.neucom.2023.01.037},
  journal      = {Neurocomputing},
  pages        = {143-157},
  shortjournal = {Neurocomputing},
  title        = {Robust recurrent neural networks for time series forecasting},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). EACP: An effective automatic channel pruning for neural
networks. <em>NEUCOM</em>, <em>526</em>, 131–142. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large data scale and computational resources required by Convolutional Neural Networks (CNNs) hinder the practical application on mobile devices . However, channel pruning has become one of the most efficient methods for addressing this problem, with many existing researches proving its practicability in the field of model compression . The current channel pruning methods mainly start with the perspective of assessing the importance of channels or manual setting of the evaluation criteria, which requires unnecessary human intervention and shows the lack of certain automaticity. In this paper, an effective automatic channel pruning (EACP) method for neural networks is proposed. Specifically, we adopt the k-means++ method to cluster filters with similar features hierarchically in each convolutional layer , forming an initial compact compression structure. Subsequently, we use an improved social group optimization (SGO) algorithm to iteratively search and optimize the compression process of the post-clustered structure to find the optimal compressed structure. The effectiveness of the proposed approach is tested with respect to three leading CNN models on two image classification datasets. In CIFAR-10, our method reduces the FLOPs of GoogLeNet by 58.10\% and improves the accuracy by 0.20\% compared to the baseline.},
  archive      = {J_NEUCOM},
  author       = {Yajun Liu and Dakui Wu and Wenju Zhou and Kefeng Fan and Zhiheng Zhou},
  doi          = {10.1016/j.neucom.2023.01.014},
  journal      = {Neurocomputing},
  pages        = {131-142},
  shortjournal = {Neurocomputing},
  title        = {EACP: An effective automatic channel pruning for neural networks},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic representation and dependency learning for
multi-label image recognition. <em>NEUCOM</em>, <em>526</em>, 121–130.
(<a href="https://doi.org/10.1016/j.neucom.2023.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently many multi-label image recognition (MLR) works have made significant progress by introducing pre-trained object detection models to generate lots of proposals or utilizing statistical label co-occurrence to enhance the correlation among different categories. However, these works have some limitations: (1) the effectiveness of the network significantly depends on pre-trained object detection models that bring expensive and unaffordable computation; (2) the network performance degrades when there exist occasional co-occurrence objects in images, especially for the rare categories. To address these problems, we propose a novel and effective semantic representation and dependency learning (SRDL) framework to learn category-specific semantic representation for each category and capture semantic dependency among all categories. Specifically, we design a category-specific attentional regions (CAR) module to generate channel/spatial-wise attention matrices to guide the model to focus on semantic-aware regions. We also design an object erasing (OE) module to implicitly learn semantic dependency among categories by erasing semantic-aware regions to regularize the network training. Extensive experiments and comparisons on two popular MLR benchmark datasets (i.e., MS-COCO and Pascal VOC 2007) demonstrate the effectiveness of the proposed framework over current state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Tao Pu and Mingzhan Sun and Hefeng Wu and Tianshui Chen and Ling Tian and Liang Lin},
  doi          = {10.1016/j.neucom.2023.01.018},
  journal      = {Neurocomputing},
  pages        = {121-130},
  shortjournal = {Neurocomputing},
  title        = {Semantic representation and dependency learning for multi-label image recognition},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DC-FUDA: Improving deep clustering via fully unsupervised
domain adaptation. <em>NEUCOM</em>, <em>526</em>, 109–120. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By transferring knowledge from a source domain, the performance of deep clustering on an unlabeled target domain can be greatly improved. When achieving this, traditional approaches assume that an adequate amount of labeled data are available in the source domain. However, this assumption is not always satisfied in practice. First, it cannot be guaranteed that rich labeled samples are readily available in the selected source domain. Second, the noisy data in the source domain may lead to negative transferring. In this paper, we propose a novel transfer learning framework to improve deep clustering via fully unsupervised domain adaptation , called DC-FUDA. Specifically, to select reliable instances in the source domain for transferring, we propose a novel adaptive threshold algorithm to select low entropy instances. To transfer important features of the selected instances, we propose a feature-level domain adaptation network (FeatureDA) that cancels an unstable instance generation process. With extensive experiments, we validate that our method effectively improves deep clustering. Besides, without using any labeled data in the source domain, our method achieves competitive results, compared to the state-of-the-art methods using labeled data in the source domain.},
  archive      = {J_NEUCOM},
  author       = {Zhimeng Yang and Yazhou Ren and Zirui Wu and Ming Zeng and Jie Xu and Yang Yang and Xiaorong Pu and Philip S. Yu and Lifang He},
  doi          = {10.1016/j.neucom.2023.01.058},
  journal      = {Neurocomputing},
  pages        = {109-120},
  shortjournal = {Neurocomputing},
  title        = {DC-FUDA: Improving deep clustering via fully unsupervised domain adaptation},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Residual learning with annularly convolutional neural
networks for classification and segmentation of 3D point clouds.
<em>NEUCOM</em>, <em>526</em>, 96–108. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis of point clouds through deep convolutional neural networks is an active area of research due to their massive real-world applications including autonomous driving , indoor navigation , robotics, virtual/augmented reality, unmanned aerial vehicles , and drone technology. However, capturing the fine-grained geometric and semantic properties for the underlying recognition task with raw unstructured point cloud is highly challenging due to the lack of explicit neighborhood relationship and sparsity among the points. In this paper, we have introduced a deep, hierarchical 3D point based architecture for object classification and part segmentation that is able to learn robust geometric features which remain invariant to both the geometry and orientation of the local patches. The proposed architecture consists of multiple layers of sampling, concentric annular convolution, pooling, and residual feature propagation blocks. In the skip connections of our deep residual design, we propose to use a combination of linear projection shortcut and nonlinear ReLU group normalization shortcut with batch normalization , to improve both the optimization landscape and the representational power. Our network achieves on par or even better than state-of-the-art results on synthetic and real-world object classification (i.e., ModelNet40 and ScanObjectNN) and part segmentation (i.e., ShapeNet-part) benchmark datasets. The implementation and results have been made available at …https://github.com/Rabbia-Hassan/Deep_Annular_Residual_Feature_Learning_for_3dPointCloudsGitHub-link},
  archive      = {J_NEUCOM},
  author       = {R. Hassan and M.M. Fraz and A. Rajput and M. Shahzad},
  doi          = {10.1016/j.neucom.2023.01.026},
  journal      = {Neurocomputing},
  pages        = {96-108},
  shortjournal = {Neurocomputing},
  title        = {Residual learning with annularly convolutional neural networks for classification and segmentation of 3D point clouds},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning applications for urban photovoltaic
potential estimation: A survey. <em>NEUCOM</em>, <em>526</em>, 80–95.
(<a href="https://doi.org/10.1016/j.neucom.2023.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing worldwide consensus agrees that a global energy transition to renewable energy sources is urgent to avoid the direst consequences of rapid climate change. This transition is a substantial challenge facing humanity, which requires cooperation and innovation across disciplines and nations. In this context, the precise estimation of the renewable potential of a given area is valuable for decision-makers. Cities will play an essential role in this transition through distributed photovoltaic generation as evidenced by the UN 11 th 11th sustainable development goal. However, the complex nature of cities makes this estimation a difficult problem. Recently, several machine learning approaches have successfully contributed to different aspects of the urban photovoltaic potential estimation problem. In the present manuscript, these proposals are summarized, following a hierarchical framework usually described in the literature, including the latest available research. Input and target variables involved in the discussed works are reclassified using a novel categorization. This categorization highlights interesting trends in the field, for each sub-problem in the hierarchical approach, which allows the identification of knowledge gaps and possible future lines of research. The present work presents other unexplored avenues and lists concisely the techniques and variables used for each estimation problem, facilitating improvements on already explored techniques or innovation on not yet explored avenues.},
  archive      = {J_NEUCOM},
  author       = {Alvaro Valderrama and Carlos Valle and Hector Allende and Marcelo Ibarra and Camila Vásquez},
  doi          = {10.1016/j.neucom.2023.01.006},
  journal      = {Neurocomputing},
  pages        = {80-95},
  shortjournal = {Neurocomputing},
  title        = {Machine learning applications for urban photovoltaic potential estimation: A survey},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recent advances in automatic feature detection and
classification of fruits including with a special emphasis on watermelon
(citrillus lanatus): A review. <em>NEUCOM</em>, <em>526</em>, 62–79. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This document provides an overview of advances in the task of automatic feature detection and classification of fruits, with and special interest in watermelon (Citrillus lanatus ). The review was written with the objective to highlight the wealth of knowledge that exist in the application of analytical, smart and sensing image recognition techniques commonly used in agro-industry, and the computational approaches used to make the classification possible. Also, an specific interest is put in the contributions made in the development of automatic recognition systems geared towards for watermelon using images, acoustic and spectroscopy methodologies. The importance of this document is that it provides a conceptual summary of the methods for the automatic recognition of fruits, including machine learning and evolutionary computational algorithms to analyze their sensed data. In conclusion this is a first step into recognizing the challenges and opportunities that can be addressed in this field to augment the visibility of these methods and to further modernize the agro-industrial sector.},
  archive      = {J_NEUCOM},
  author       = {Danilo Caceres-Hernandez and Ricardo Gutierrez and Kelvin Kung and Juan Rodriguez and Oscar Lao and Kenji Contreras and Kang-Hyun Jo and Javier E. Sanchez-Galan},
  doi          = {10.1016/j.neucom.2023.01.005},
  journal      = {Neurocomputing},
  pages        = {62-79},
  shortjournal = {Neurocomputing},
  title        = {Recent advances in automatic feature detection and classification of fruits including with a special emphasis on watermelon (Citrillus lanatus): A review},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal discovery of 1-factor measurement models in linear
latent variable models with arbitrary noise distributions.
<em>NEUCOM</em>, <em>526</em>, 48–61. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of causal discovery is especially challenging when the variables of interest cannot be directly measured. In measurement models, the measured variables were generated by latent causal variables that are causally related to each other, and by estimating the measurement model from measured data, one is able to recover the latent variables and their causal relations. In this paper, we provide precise sufficient identifiability conditions for the linear pure measurement model, and show what information of the causal structure can be recovered from observed data without prior knowledge of data distributions. In particular, we first show that, based on second-order statistics, although the pure measurement model is in general not fully identifiable under the assumption of two pure measurement variables, we can identify the set of all candidate measurement models. We then further prove that the pure measurement model can be identified uniquely based on higher-order statistics. Next, to address more general situations, we offer the identifiability conditions of linear measurement models with arbitrary noise distributions. We finally develop a unified method to learn pure measurement models from data. Experimental results on both synthetic and real-world data demonstrate the usefulness of our theory and the effectiveness of our approach.},
  archive      = {J_NEUCOM},
  author       = {Feng Xie and Yan Zeng and Zhengming Chen and Yangbo He and Zhi Geng and Kun Zhang},
  doi          = {10.1016/j.neucom.2023.01.034},
  journal      = {Neurocomputing},
  pages        = {48-61},
  shortjournal = {Neurocomputing},
  title        = {Causal discovery of 1-factor measurement models in linear latent variable models with arbitrary noise distributions},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Global stability of delayed genetic regulatory networks
with wider hill functions: A mixing monotone semiflows approach.
<em>NEUCOM</em>, <em>526</em>, 39–47. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the global stability of delayed genetic regulatory networks (DGRNs) with Hill-type activation (or inhibition) functions based on the mixing monotone semiflows approach, where Hill coefficients can be arbitrary positive real number. A new result on the global stability of DGRN is given in the case that all Hill coefficients are less than or equal to 1. In addition, for all Hill coefficients greater than 1, a new sufficient condition for global convergence of DGRN is given, which is less conservative than the condition of the existing correlation results. Finally, two numerical examples and simulations are given to explain the effect of obtained results.},
  archive      = {J_NEUCOM},
  author       = {Jiejie Chen and Ping Jiang and Boshan Chen and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2023.01.057},
  journal      = {Neurocomputing},
  pages        = {39-47},
  shortjournal = {Neurocomputing},
  title        = {Global stability of delayed genetic regulatory networks with wider hill functions: A mixing monotone semiflows approach},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From ℓ1 subgradient to projection: A compact neural network
for ℓ1-regularized logistic regression. <em>NEUCOM</em>, <em>526</em>,
30–38. (<a href="https://doi.org/10.1016/j.neucom.2023.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ℓ 1 ℓ1 regularization has been used for logistic regression to circumvent the overfitting and use the estimated sparse coefficient for feature selection. However, the challenge of such regularization is that the ℓ 1 ℓ1 regularization is not differentiable, making the standard convex optimization algorithm not applicable to this problem. This paper presents a simple projection neural network for ℓ 1 ℓ1 -regularized logistics regression. In contrast to many available solvers in the literature, the proposed neural network does not require any extra auxiliary variable nor smooth approximation , and its complexity is almost identical to that of the gradient descent for logistic regression without ℓ 1 ℓ1 regularization, thanks to the projection operator. We also investigate the convergence of the proposed neural network by using the Lyapunov theory and show that it converges to a solution of the problem with any arbitrary initial value. The proposed neural solution significantly outperforms state-of-the-art methods concerning the execution time and is competitive in terms of accuracy and AUROC.},
  archive      = {J_NEUCOM},
  author       = {Majid Mohammadi and Amir Ahooye Atashin and Damian A. Tamburri},
  doi          = {10.1016/j.neucom.2023.01.021},
  journal      = {Neurocomputing},
  pages        = {30-38},
  shortjournal = {Neurocomputing},
  title        = {From ℓ1 subgradient to projection: A compact neural network for ℓ1-regularized logistic regression},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Projection-preserving block-diagonal low-rank representation
for subspace clustering. <em>NEUCOM</em>, <em>526</em>, 19–29. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel model named projection-preserving block-diagonal low-rank representation (PBDIR) is proposed and can obtain a more distinguishable representation matrix for clustering. PBDIR acquires a more advantageous representation by extracting the essential features. Specifically, we introduce a projection matrix to our model to learn a new feature space that can capture more significant features. Therefore, our model learns a more robust representation, which can reduce noise interference. Meanwhile, we introduce a block-diagonal regularization to ensure that the obtained representation matrix involves a k -block diagonal, where k denotes the number of clusters. This term brings more benefits for clustering tasks . Experimental results on real datasets show that our model can significantly improve the clustering performance and the proposed approach is robust against Gaussian noise , Multiplicative noise , and Salt-and-Pepper noise.},
  archive      = {J_NEUCOM},
  author       = {Zisen Kong and Dongxia Chang and Zhiqiang Fu and Jiapeng Wang and Yiming Wang and Yao Zhao},
  doi          = {10.1016/j.neucom.2023.01.051},
  journal      = {Neurocomputing},
  pages        = {19-29},
  shortjournal = {Neurocomputing},
  title        = {Projection-preserving block-diagonal low-rank representation for subspace clustering},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised feature learning for disjoint hyperspectral
imagery classification. <em>NEUCOM</em>, <em>526</em>, 9–18. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of spatial-spectral fusion and deep learning , the classification performance of hyperspectral imagery (HSI) has been promoted greatly. For some widely used datasets, the classification accuracy almost reaches 100\%. However, for hyperspectral image classification, random sampling is still the most common strategy to collect the training and test samples. Because the training and test samples are randomly selected from the same image, so they have a high correlation and the classification results are overoptimistic. Besides, random sampling is not a good choice for practical applications because we cannot always collect training and test samples from the same region. Disjoint sampling selects training and testing samples from different local regions, which will provide a more objective performance evaluation for HSI classification models . In this paper, we first show the huge classification performance difference caused by different sampling strategies with a simple experiment, then we analyze the underlying reasons from the spectral information , spatial-spectral combination, sample overlapping and spatial distance, finally, a semi-supervised feature learning method is proposed for disjoint HSI classification, in which the spatial and spectral information are exploited effectively and reasonably. The experimental results based on three HSI datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Xianghai Cao and Chenguang Li and Jie Feng and Licheng Jiao},
  doi          = {10.1016/j.neucom.2023.01.054},
  journal      = {Neurocomputing},
  pages        = {9-18},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised feature learning for disjoint hyperspectral imagery classification},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data reduction via multi-label prototype generation.
<em>NEUCOM</em>, <em>526</em>, 1–8. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A very common practice to speed up instance based classifiers is to reduce the size of their training set, that is, replace it by a condensing set, hoping that their accuracy will not worsen. This can be achieved by applying a Prototype Selection or Generation algorithm, also referred to as a Data Reduction Technique. Most of these techniques cannot be applied on multi-label problems, where an instance may belong to more than one classes. Reduction through Homogeneous Clustering (RHC) and Reduction by Space Partitioning (RSP3) are parameter-free single-label Prototype Generation algorithms. Both are based on recursive data partitioning procedures that identify homogeneous clusters of training data, which they replace by their representatives. This paper proposes variations of these algorithms for multi-label training datasets. The proposed methods generate multi-label prototypes and inherit all the desirable properties of their single-label versions. They consider clusters that contain instances that share at least one common label as homogeneous clusters. It is shown via an experimental study based on nine multi-label datasets that the proposed algorithms achieve good reduction rates without negatively affecting classification accuracy .},
  archive      = {J_NEUCOM},
  author       = {Stefanos Ougiaroglou and Panagiotis Filippakis and Georgia Fotiadou and Georgios Evangelidis},
  doi          = {10.1016/j.neucom.2023.01.004},
  journal      = {Neurocomputing},
  pages        = {1-8},
  shortjournal = {Neurocomputing},
  title        = {Data reduction via multi-label prototype generation},
  volume       = {526},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse representation for heterogeneous information
networks. <em>NEUCOM</em>, <em>525</em>, 111–122. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complex network is a fundamental tool to describe real-world complex systems, with most real-world systems containing multiple object types and relationships that can be described as heterogeneous information networks. However, with the increasing network complexity, understanding the complex patterns and finding the meta paths or meta-structures of the heterogeneous information networks has become challenging. This paper proposes a sparse representation for heterogeneous information networks and extracts the heterogeneous information atoms that describe the basic connection pattern of the original heterogeneous information network. The heterogeneous information atoms help extract the main meta-paths or meta-structures and understand the complex patterns of the original heterogeneous information network. Furthermore, the heterogeneous information networks can be decomposed, dimension-reduced, and reconstructed through the heterogeneous information atoms. Extensive experimental results demonstrate that heterogeneous information atoms and sparse coding represent the basic connection pattern of real-world heterogeneous information networks. Indeed, the developed method can reconstruct a network with a recovery exceeding 90\%.},
  archive      = {J_NEUCOM},
  author       = {Xuemeng Zhai and Zhiwei Tang and Zhiwei Liu and Wanlei Zhou and Hangyu Hu and Gaolei Fei and Guangmin Hu},
  doi          = {10.1016/j.neucom.2023.01.035},
  journal      = {Neurocomputing},
  pages        = {111-122},
  shortjournal = {Neurocomputing},
  title        = {Sparse representation for heterogeneous information networks},
  volume       = {525},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FuzzyGAN: Fuzzy generative adversarial networks for
regression tasks. <em>NEUCOM</em>, <em>525</em>, 88–110. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are well-known tools for data generation and semi-supervised classification. GANs, with less labeled data, outperform Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs) in classification tasks . The success of GANs in classification tasks motivates the development of GAN-based techniques for semi-supervised regression tasks . However, developing GANs for regression introduces two major challenges: (1) inherent instability in the GAN formulation and (2) performing regression and achieving stability simultaneously. This paper introduces techniques that show improvement in the GANs’ regression capability. We bake a differentiable fuzzy logic system at multiple locations in a GAN. The fuzzy logic takes the output of either the generator or the discriminator to predict the output, y , and evaluate the generator’s performance. We outline the results of applying the fuzzy logic system across multiple GANs and summarize each approach’s efficacy. This paper shows that adding a fuzzy logic layer can enhance GAN’s ability to perform regression; the most desirable injection location is problem-specific, and we show this through experiments over various datasets. Besides, we demonstrate empirically that the fuzzy-infused GANs are competitive with the DNNs.},
  archive      = {J_NEUCOM},
  author       = {Ryan Nguyen and Shubhendu Kumar Singh and Rahul Rai},
  doi          = {10.1016/j.neucom.2023.01.015},
  journal      = {Neurocomputing},
  pages        = {88-110},
  shortjournal = {Neurocomputing},
  title        = {FuzzyGAN: Fuzzy generative adversarial networks for regression tasks},
  volume       = {525},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Overfitting-avoiding goal-guided exploration for
hard-exploration multi-goal reinforcement learning. <em>NEUCOM</em>,
<em>525</em>, 76–87. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hard-exploration multi-goal reinforcement learning tasks, the agent faces challenges to achieve a series of distant goals with sparse rewards. Directly exploring to pursue these hard goals can hardly succeed, because the agent is unable to acquire learning signals applicable to these goals. To progressively enhance agent ability and promote exploration, goal-guided exploration methods generate easier auxiliary goals that gradually approach the original hard goals for the agent to pursue. However, due to the neglect of the growth of agent generalizability , the goal generation region of the previous methods is limited, which causes overfitting and traps the exploration for further goals. In this paper, after modeling the multi-goal RL as a distribution-matching process, we propose an overfitting-avoiding goal-guided exploration method (OGE), where the generation of auxiliary goals follows the Wasserstein-distance-based optimal transport geodesic, and the generation region is in the Lipschitz-constant-delimited generalizability margin. Our OGE is compared with state-of-the-art methods in hard-exploration multi-goal robotic manipulation tasks. Apart from showing the highest learning efficiency, in those tasks where all the prior methods meet overfitting and fail, our method can still successfully guide the agent to achieve the hard goals.},
  archive      = {J_NEUCOM},
  author       = {Changlin Han and Zhiyong Peng and Yadong Liu and Jingsheng Tang and Yang Yu and Zongtan Zhou},
  doi          = {10.1016/j.neucom.2023.01.016},
  journal      = {Neurocomputing},
  pages        = {76-87},
  shortjournal = {Neurocomputing},
  title        = {Overfitting-avoiding goal-guided exploration for hard-exploration multi-goal reinforcement learning},
  volume       = {525},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cost-sensitive learning with modified stein loss function.
<em>NEUCOM</em>, <em>525</em>, 57–75. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cost-sensitive learning (CSL), which has gained widespread attention in class imbalance learning (CIL), can be implemented either by tuning penalty parameters or by designing new loss functions. In this paper, we propose a cost-sensitive learning method with a modified Stein loss function (CSMS) and a robust CSMS (RCSMS). Specifically, CSMS is flexible, as it realizes CSL from above two aspects simultaneously. In contrast, RCSMS merely achieves CSL by tuning penalty parameters, but the adopted loss function makes it insensitive to noise. To our best knowledge, it is the first time for Stein loss function derived from statistics to be applied in machine learning , which not only offers two alternative class imbalance solutions but also provides a novel idea for the design of loss functions in CIL. The mini-batch stochastic sub-gradient descent (MBGD) approach is employed to optimize CSMS and RCSMS. Meanwhile, the Rademacher complexity is used to analyze their generalization error bounds. Extensive experiments profoundly confirm the superiority of both models over benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Saiji Fu and Yingjie Tian and Jingjing Tang and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2023.01.052},
  journal      = {Neurocomputing},
  pages        = {57-75},
  shortjournal = {Neurocomputing},
  title        = {Cost-sensitive learning with modified stein loss function},
  volume       = {525},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guest editorial: Special issue on encoding-decoding-based
state estimation for neural networks. <em>NEUCOM</em>, <em>525</em>,
54–56. (<a href="https://doi.org/10.1016/j.neucom.2023.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Lifeng Ma and Lei Zou and Xiaojian Yi and Tingwen Huang},
  doi          = {10.1016/j.neucom.2023.01.001},
  journal      = {Neurocomputing},
  pages        = {54-56},
  shortjournal = {Neurocomputing},
  title        = {Guest editorial: Special issue on encoding-decoding-based state estimation for neural networks},
  volume       = {525},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum machine learning in medical image analysis: A
survey. <em>NEUCOM</em>, <em>525</em>, 42–53. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the outstanding superposition and entanglement properties of quantum computing , quantum machine learning has attracted widespread attention in many fields, such as medical image analysis, password cracking , and pattern recognition. Although classical machine learning is widely used and has shown great potential in medical image analysis, the bottlenecks of insufficient labeled data and low processing efficiency still exist. To overcome these challenges, massive studies combined quantum computing with machine learning to explore more advanced algorithms, which have achieved distinguished improvements in parameter optimization, execution efficiency, and the reduction of error rates. Quantum machine learning provides new insights for the intersectional research of quantum technology and medical image analysis and contributes to the future development of medical image analysis. This review delivers an overview of the definition and taxonomy of quantum machine learning , as well as summarizes various quantum machine learning methods and their applications in medical image analysis over the past decade.},
  archive      = {J_NEUCOM},
  author       = {Lin Wei and Haowen Liu and Jing Xu and Lei Shi and Zheng Shan and Bo Zhao and Yufei Gao},
  doi          = {10.1016/j.neucom.2023.01.049},
  journal      = {Neurocomputing},
  pages        = {42-53},
  shortjournal = {Neurocomputing},
  title        = {Quantum machine learning in medical image analysis: A survey},
  volume       = {525},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DKTNet: Dual-key transformer network for small object
detection. <em>NEUCOM</em>, <em>525</em>, 29–41. (<a
href="https://doi.org/10.1016/j.neucom.2023.01.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is a fundamental computer vision task that plays a crucial role in a wide range of real-world applications. However, it is still a challenging task to detect the small size objects in the complex scene, due to the low resolution and noisy representation appearance caused by occlusion, distant depth view, etc . To tackle this issue, a novel transformer architecture, Dual-Key Transformer Network (DKTNet), is proposed in this paper. To improve the feature attention ability, the coherence of linear layer outputs Q and V are enhanced by a dual-K integrated from K 1 K1 and K 2 K2 , which are computed along Q and V, respectively. Instead of spatial-wise attention, channel-wise self-attention mechanism is adopted to promote the important feature channels and suppress the confusing ones. Moreover, 2D and 1D convolution computations for Q, K and V are proposed. Compared with the fully-connected computation in conventional transformer architectures, the 2D convolution can better capture local details and global contextual information, and the 1D convolution can reduce network complexity significantly. Experimental evaluation is conducted on both general and small object detection datasets. The superiority of the aforementioned features in our proposed approach is demonstrated with the comparison against the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Shoukun Xu and Jianan Gu and Yining Hua and Yi Liu},
  doi          = {10.1016/j.neucom.2023.01.055},
  journal      = {Neurocomputing},
  pages        = {29-41},
  shortjournal = {Neurocomputing},
  title        = {DKTNet: Dual-key transformer network for small object detection},
  volume       = {525},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on kinship verification. <em>NEUCOM</em>,
<em>525</em>, 1–28. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this survey, kinship verification is defined as the automatic process of verifying whether two or more persons are blood relatives (kin) by analyzing images of their faces. Kinship verification is an important research field in computer vision with many applications such as finding missing persons, family album organization, and online image search. Although substantial progress has been made in kinship verification in the past decade, there are still challenges such as intrinsic (face i.e. , differences in facial appearance) and extrinsic (acquisition i.e. , varying imaging conditions) problems. And there is still a demand for more diverse datasets. Therefore, this paper provides a survey on kinship verification methods and datasets. The survey starts with the definition of kinship verification and its corresponding intrinsic and extrinsic challenges. Then, an overview of kinship verification methods and datasets is given. Finally, a new multi-modal dataset (Nemo-Kinship Dataset) is proposed as a benchmark dataset addressing large inter-subject age variations consisting of 4216 videos of 248 persons from 85 families. The newly collected dataset is used to systematically test and analyze state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Wei Wang and Shaodi You and Sezer Karaoglu and Theo Gevers},
  doi          = {10.1016/j.neucom.2022.12.031},
  journal      = {Neurocomputing},
  pages        = {1-28},
  shortjournal = {Neurocomputing},
  title        = {A survey on kinship verification},
  volume       = {525},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). HiBERT: Detecting the illogical patterns with hierarchical
BERT for multi-turn dialogue reasoning. <em>NEUCOM</em>, <em>524</em>,
167–177. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue reasoning is a new task beyond the traditional dialogue system , because it requires recognizing not only semantic relevance but also logical consistency between the candidate response and the dialogue history . Like “all happy families are happy alike, all unhappy families are unhappy in their own way”, various illogical patterns exist in the data. For example, some candidate responses use many similar words but with contradicted meanings with history; while some candidates may employ totally different words but convey consistent meanings. Therefore, an ideal dialogue reasoning model should gather clues from both coarse-grained utterance-level and fine-grained word-level to determine the logical relation between candidates and the dialogue history . However, traditional models mainly rely on the widely used BERT to read all the history and candidates word by word but ignore the utterance-level signals, which cannot well capture various illogical patterns in this task. To tackle this problem, we propose a novel Hierarchical BERT (HiBERT) to recognize both utterance-level and word-level illogical patterns in this paper. Specifically, BERT is firstly utilized to encode the dialogue history and each candidate response as the contextualized representation. Secondly, hierarchical reasoning architecture is conducted with this contextualized representation to obtain the word-level and the utterance-level attention distributions, respectively. In detail, we utilize the word-grained attention mechanism to obtain the word-level representation, and propose two different types of attention function, i.e, hard attention and soft attention, to obtain the utterance-grained representation. Finally, we fuse both the word-grained representation and the utterance-grained representation to calculate the logical ranking scores for the given candidate. Experimental results on two public dialogue datasets show that our model obtains higher ranking measures than the widely used BERT model, validating the effectiveness of hierarchical reading of HiBERT. Further analysis on the impact of context length and attention weights shows that the HiBERT actually has the ability to recognize different illogical patterns.},
  archive      = {J_NEUCOM},
  author       = {Xu Wang and Hainan Zhang and Shuai Zhao and Hongshen Chen and Bo Cheng and Zhuoye Ding and Sulong Xu and Weipeng Yan and Yanyan Lan},
  doi          = {10.1016/j.neucom.2022.12.038},
  journal      = {Neurocomputing},
  pages        = {167-177},
  shortjournal = {Neurocomputing},
  title        = {HiBERT: Detecting the illogical patterns with hierarchical BERT for multi-turn dialogue reasoning},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stability analysis of delayed neural networks based on
improved quadratic function condition. <em>NEUCOM</em>, <em>524</em>,
158–166. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stability of a class of neural networks (NNs) with time-varying delay is explored in this work. The characteristics of integral inequalities are considered, and the general stability condition (GSC) of delayed NNs avoiding high-order delay is given in the form of quadratic functions. For the GSC of NNs, under the number of decision variables remains unchanged, the information of time-delay and its derivatives are further excavated by delay-partitioning approach. Meanwhile, the free-moving points are established in each subintervals divided, and the traditional static constraints are transformed into dynamic constraints, which relaxes the feasibility space. Based on these methods, the improved stability criteria are given. Finally, two examples are provided to illustrate the meliority of the method under the same number of decision variables.},
  archive      = {J_NEUCOM},
  author       = {Guo-Qiang Kong and Liang-Dong Guo},
  doi          = {10.1016/j.neucom.2022.12.012},
  journal      = {Neurocomputing},
  pages        = {158-166},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis of delayed neural networks based on improved quadratic function condition},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-label feature selection based on label distribution
and neighborhood rough set. <em>NEUCOM</em>, <em>524</em>, 142–157. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is an indispensable technology in multi-semantic high-dimensional data preprocessing, which has been brought into focus in recent years. However, most existing methods explicitly assume that the significance of all relevant labels is the same for every instance, while ignoring the real scenarios that the significance of available labels to each instance is usually different. In this paper, we propose a novel multi-label feature selection based on label distribution and neighborhood rough set, known as LDRS. To be specific, we first construct a label enhancement method based on instance information distribution to convert the logical labels of multi-label data into label distribution, thereby capturing label significance to provide additional information for learning tasks. Then, we extend the neighborhood rough set model for label distribution learning, and discuss the related properties in detail. This extended model can effectively avoid the selection of neighborhood granularity and seamlessly apply to handle label distribution data. After that, two feature significance measures are established to realize the quality evaluation of features and the fusion of label-specific features. Finally, a novel feature selection framework is designed, which takes into account feature significance, label significance, and label-specific features, simultaneously. Experiments on both public and real-world datasets exhibit the advantages of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jinghua Liu and Yaojin Lin and Weiping Ding and Hongbo Zhang and Cheng Wang and Jixiang Du},
  doi          = {10.1016/j.neucom.2022.11.096},
  journal      = {Neurocomputing},
  pages        = {142-157},
  shortjournal = {Neurocomputing},
  title        = {Multi-label feature selection based on label distribution and neighborhood rough set},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning deep texture-structure decomposition for low-light
image restoration and enhancement. <em>NEUCOM</em>, <em>524</em>,
126–141. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A great many low-light image restoration methods have built their models according to Retinex theory . However, most of these methods cannot well achieve image detail enhancement. To achieve simultaneous restoration and enhancement, we study deep low-light image enhancement from a perspective of texture-structure decomposition, that is, learning image smoothing operator. Specifically, we design a low-light restoration and enhancement framework, in which a Deep Texture-Structure Decomposition (DTSD) network is introduced to estimate two complementary constituents: Fine-Texture (FT) and Prominent-Structure (PS) maps from low-light image. Since these two maps are leveraged to approximate FT and PS maps obtained from normal-light image, they can be combined as the restored image in a manner of pixel-wise addition. The DTSD network has three parts: U-attention block, Decomposition-Merger (DM) block, and Upsampling-Reconstruction (UR) block. To better explore multi-level informative features at different scales than U-Net, U-attention block is designed with intra group and inter group attentions. In the DM block, we extract high-frequency and low-frequency features in low-resolution space. After obtaining informative feature maps from these two blocks, these maps are fed into the UR block for the final prediction. Numerous experimental results have demonstrated that the proposed method can achieve simultaneous low-light image restoration and enhancement, and it has superior performance against many state-of-the-art approaches in terms of several objective and perceptual metrics.},
  archive      = {J_NEUCOM},
  author       = {Lijun Zhao and Ke Wang and Jinjing Zhang and Anhong Wang and Huihui Bai},
  doi          = {10.1016/j.neucom.2022.12.043},
  journal      = {Neurocomputing},
  pages        = {126-141},
  shortjournal = {Neurocomputing},
  title        = {Learning deep texture-structure decomposition for low-light image restoration and enhancement},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unified neuroadaptive fault-tolerant control of
fractional-order systems with or without state constraints.
<em>NEUCOM</em>, <em>524</em>, 117–125. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of controlling fractional-order nonlinear systems remains interesting and challenging due to the powerful and hereditary memory features of such systems. In this paper, we investigate the adaptive tracking control problem for a class of fractional-order nonlinear systems with or without state constraints. The tan-type barrier Lyapunov function (BLF) is adopted for the first time in fractional Lyapunov direct method. Such technique allows for the accommodation of the situations with and without state constraints in a unified framework. Moreover, neural network (NN) is utilized to reconstruct the sophisticated nonlinear functions arising from the fractional-order differentiation of the virtual controller, resulting in a neuroadaptive fault-tolerant control scheme. It is shown that, with the proposed unified control, all the closed-loop signals are semiglobally ultimately uniformly bounded whether state constraints are imposed or not. Both theoretical analysis and numerical simulation confirm the effectiveness of the developed approach.},
  archive      = {J_NEUCOM},
  author       = {Hong Cheng and Xiucai Huang and Zeqiang Li},
  doi          = {10.1016/j.neucom.2022.12.035},
  journal      = {Neurocomputing},
  pages        = {117-125},
  shortjournal = {Neurocomputing},
  title        = {Unified neuroadaptive fault-tolerant control of fractional-order systems with or without state constraints},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Temporal action detection with dynamic weights based on
curriculum learning. <em>NEUCOM</em>, <em>524</em>, 106–116. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enable temporal action localization, the computer needs to recognize the locations and classes of action instances in a video. The main challenge to temporal action detection is that the videos are often long and untrimmed, consisting of varying action content. Existing temporal action detection frameworks exhibit a gap between the training and testing phases, which is detrimental to model performance. Specifically, all positive samples are trained identically in the training phase. By contrast, in the testing phase, the positive samples with the best classification and localization scores are selected, while all others are suppressed. To mitigate this issue, we build an auxiliary branch to unify the training and testing procedures. In the construction of the auxiliary branch, we design a dynamic weighting strategy based on curriculum learning, where the weights of training samples are a combination of their classification and localization scores. Motivated by the speculation of curriculum learning, we emphasize the importance of classification and localization scores in different training stages. The classification score accounts for a higher proportion of the combined score in the early stages of the training process. As the epoch increases, the localization score gradually increases in proportion as well. The experimental results demonstrate that our methodology of curriculum-based learning enhances the performance of current action localization techniques. On THUMOS14, our technique outperforms the existing state-of-the-art technique (57.6\% vs 55.5\%). And the performance on ActivityNet v1.3 (mAP@Avg) reaches 35.4\%.},
  archive      = {J_NEUCOM},
  author       = {Yunze Chen and He Jiang and Junrui Xiao and Ding Li and Qingyi Gu},
  doi          = {10.1016/j.neucom.2022.12.049},
  journal      = {Neurocomputing},
  pages        = {106-116},
  shortjournal = {Neurocomputing},
  title        = {Temporal action detection with dynamic weights based on curriculum learning},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One step multi-view spectral clustering via joint adaptive
graph learning and matrix factorization. <em>NEUCOM</em>, <em>524</em>,
95–105. (<a href="https://doi.org/10.1016/j.neucom.2022.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering based on graph learning has attracted extensive attention due to its simplicity and efficiency in recent years. However, there are still some issues in most of the existing graph-based multi-view clustering methods . First, most of those methods require post-processing such as K-means or spectral rotation to get the final discrete clustering result . Second, graph-based clustering methods perform clustering on a fixed input similarity graph , which could induce bad clustering results if the initial graph is with low quality. Third, these methods have high computation cost, which hinders them for dealing with large-scale data. In order to solve these problems, we propose a multi-view spectral clustering method via joint Adaptive Graph Learning and Matrix Factorization (AGLMF). In this method, to reduce computational cost, we adopt the anchor-based strategy to construct the input similarity graphs. Then, we use the l 1 l1 -norm to learn a high quality similarity graph adaptively from original similarity graphs which can make the final graph more robust than original ones. In addition, AGLMF uses symmetric non-negative matrix factorization to learn the final clustering indicators which can show the final consistent clustering result directly. Finally, experimental results on multiple multi-view datasets validate the effectiveness of the proposed algorithm when compared with previous multi-view spectral clustering algorithms. The demo code of this work is publicly available at https://github.com/theywq/AGLMF.git.},
  archive      = {J_NEUCOM},
  author       = {Wenqi Yang and Yansu Wang and Chang Tang and Hengjian Tong and Ao Wei and Xia Wu},
  doi          = {10.1016/j.neucom.2022.12.023},
  journal      = {Neurocomputing},
  pages        = {95-105},
  shortjournal = {Neurocomputing},
  title        = {One step multi-view spectral clustering via joint adaptive graph learning and matrix factorization},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A classification framework for investigating neural
correlates of the limit of stability during weight-shifting in lower
limb amputees. <em>NEUCOM</em>, <em>524</em>, 84–94. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coordination of the body with the central nervous system has been studied using various biomechanical, neurophysiological, and neuroimaging studies . Different postural strategies provide evidence of cortical involvement to maintain postural stability, which can be utilised to minimise the risk of falls in the elderly and various pathological individuals. In this paper, we investigated the effect of vibrotactile feedback in Electroencephalography (EEG) based classification of voluntary postural sway during weight-shifting exercises in healthy and transfemoral amputees. The EEG data recorded during forward, backward, right, and left shifting as well as normal standing, with and without vibrotactile feedback, is decomposed using discrete wavelet transform . The energy of the coefficients from levels 4 to 7 forms the feature space to be forwarded to the weighted kNN classifier and ensemble bagged trees. We have achieved significantly higher classification rates across all the conditions for healthy and amputee subjects. Predictor importance from ensemble bagged tree models provides the highest contributions from the low-frequency band of 0–3.9 Hz and channels located over the motor and somatosensory cortex. We have also observed the contributions associated with the spinocerebellum and cerebrocerebellum.},
  archive      = {J_NEUCOM},
  author       = {Ayesha Tooba Khan and Aayushi Khajuria and Biswarup Mukherjee and Deepak Joshi},
  doi          = {10.1016/j.neucom.2022.12.044},
  journal      = {Neurocomputing},
  pages        = {84-94},
  shortjournal = {Neurocomputing},
  title        = {A classification framework for investigating neural correlates of the limit of stability during weight-shifting in lower limb amputees},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distribution preserving-based deep semi-NMF for data
representation. <em>NEUCOM</em>, <em>524</em>, 69–83. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The semi-nonnegative matrix factorization (Semi-NMF) is a promising soft K-means clustering technique. Deep Semi-NMF, which stacks one-layer Semi-NMF into multi-layer, is able to learn the hierarchical projections and can obtain the deep hidden representations according to the unknown attributes of the given data. On the other hand, the inherent structure of the each data cluster can be described by the distribution of the intraclass data. Then one hopes to learn the new deep hidden representations which can preserve the intrinsic structures embedded in the original data space perfectly. Here seamlessly integrating the benefits of the Deep Semi-NMF and the distribution preserving strategy, we propose a novel distribution preserving-based deep semi-nonnegative matrix factorization method (DPNMF) to achieve this goal. In DPNMF, by maintaining the consistency of two distributions that can approximate the manifold structures, we can seek the deep hidden features which reveal the original intrinsic structures. As a result, the manifold structures in the raw data are well preserved in the new feature space. We also devise an adaptive projected Barzilai-Borwein method to optimize the proposed constrained objective function efficiently. The experimental results on the several real-world datasets show that the proposed DPNMF can achieve advantageous clustering performance in terms of accuracy (ACC), normalized mutual information (NMI), and adjusted rand index (ARI).},
  archive      = {J_NEUCOM},
  author       = {Anyong Qin and Zhuolin Tan and Xingli Tan and Yongji Wu and Cheng Jing and Yuan Yan Tang},
  doi          = {10.1016/j.neucom.2022.12.046},
  journal      = {Neurocomputing},
  pages        = {69-83},
  shortjournal = {Neurocomputing},
  title        = {Distribution preserving-based deep semi-NMF for data representation},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain-agnostic single-image super-resolution via a
meta-transfer neural architecture search. <em>NEUCOM</em>, <em>524</em>,
59–68. (<a href="https://doi.org/10.1016/j.neucom.2022.12.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fueled by the powerful learning ability of deep networks, generalized models have been proposed that use external datasets for single-image super-resolution tasks. However, a model trained only with external data may have difficulty in super-resolving images in a domain that differs from the training data. To solve this drawback, several methods have been proposed for internal learning approaches that learn the weights of the network accordance with the test image. Despite these attempts to adapt to specific images using internal learning, they suffer from poor performance due to lack of flexibility that comes from using a fixed architecture regardless of image domain. We thus propose a novel training process that includes external and internal learning. Our internal learning process finds a suitable network architecture and trains the weights for each unseen test image. The overall training process allows the network to learn obtain knowledge from external data and internal learning in a balanced manner. In blind and non-blind experiments, our proposed method outperforms state-of-the-art super-resolution algorithms in various image domains with different kernels. Our proposed approach obtains impressive results in terms of expressing detailed texture and accurate color in images from various domains.},
  archive      = {J_NEUCOM},
  author       = {Bokyeung Lee and Kyungdeuk Ko and Jonghwan Hong and Hanseok Ko},
  doi          = {10.1016/j.neucom.2022.12.050},
  journal      = {Neurocomputing},
  pages        = {59-68},
  shortjournal = {Neurocomputing},
  title        = {Domain-agnostic single-image super-resolution via a meta-transfer neural architecture search},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discontinuous grammar as a foreign language.
<em>NEUCOM</em>, <em>524</em>, 43–58. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to achieve deep natural language understanding, syntactic constituent parsing is a vital step, highly demanded by many artificial intelligence systems to process both text and speech. One of the most recent proposals is the use of standard sequence-to-sequence models to perform constituent parsing as a machine translation task, instead of applying task-specific parsers. While they show a competitive performance, these text-to-parse transducers are still lagging behind classic techniques in terms of accuracy, coverage and speed. To close the gap, we here extend the framework of sequence-to-sequence models for constituent parsing, not only by providing a more powerful neural architecture for improving their performance, but also by enlarging their coverage to handle the most complex syntactic phenomena: discontinuous structures. To that end, we design several novel linearizations that can fully produce discontinuities and, for the first time, we test a sequence-to-sequence model on the main discontinuous benchmarks, obtaining competitive results on par with task-specific discontinuous constituent parsers and achieving state-of-the-art scores on the (discontinuous) English Penn Treebank.},
  archive      = {J_NEUCOM},
  author       = {Daniel Fernández-González and Carlos Gómez-Rodríguez},
  doi          = {10.1016/j.neucom.2022.12.045},
  journal      = {Neurocomputing},
  pages        = {43-58},
  shortjournal = {Neurocomputing},
  title        = {Discontinuous grammar as a foreign language},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive full-state constrained tracking control for mobile
robotic system with unknown dead-zone input. <em>NEUCOM</em>,
<em>524</em>, 31–42. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the adaptive neural networks (NNs) tracking control problem for a class of mobile robot systems with full-state constraints. First, to compensate for the adverse effects of the unknown dead-zone input, which is ubiquitous in mobile robot motors, a new robust control algorithm is put forward by the use of adaptive control technique. Then, a new unified barrier function (UBF) is constructed to deal with the problem of state constraints. Different from traditional barrier Lyapunov function (BLF) methods, which can only constrain the error of the system state and virtual controller, our proposed control method can constrain the system state directly by introducing a novel nonlinear transformation function and a new coordinate transformation. It’s worth noting that the UBF can be utilized to deal with both constrained and unconstrained cases by resizing parameters without changing the control structure. Furthermore, adaptive NNs are introduced to approximate the uncertainty of the system. Finally, based on the Lyapunov stability theory , it is proved that all signals in the closed-loop system are ultimately bounded and the full-state constraints are never violated. The effectiveness of the control method is verified on simulation examples and a mobile robot experimental platform.},
  archive      = {J_NEUCOM},
  author       = {Xi Luo and Dianrui Mu and Zhen Wang and Pengju Ning and Changchun Hua},
  doi          = {10.1016/j.neucom.2022.12.025},
  journal      = {Neurocomputing},
  pages        = {31-42},
  shortjournal = {Neurocomputing},
  title        = {Adaptive full-state constrained tracking control for mobile robotic system with unknown dead-zone input},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Center-point-pair detection and context-aware
re-identification for end-to-end multi-object tracking. <em>NEUCOM</em>,
<em>524</em>, 17–30. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online multi-object tracking aims at generating the trajectories for multiple objects in the surveillance scene. It remains a challenging problem in crowded scenes because objects often gather together and occlude in tracking frames. The main impact of crowd occlusions is that it severely harms the performance of the detector and significantly increases the difficulty in extracting object features. In this paper, we propose an end-to-end tracking framework that alleviates such issues and estimates more accurate trajectories. Firstly, We design a Center-Point-Pair detection branch for object detection, which learns the correlations between the object head and the body to simultaneously predict the head and body regions to alleviate unreliable detection in tracking scenes. Secondly, we introduce the context information around the object to the tracker, inspired by the human search pattern. We propose a Context-Aware Re-Identification branch that includes the Previous-Frame Guided Spatial-Attention Model and the Previous-Frame Guided Channel-Attention Model to extract more discriminative object features. Thirdly, to harness the power of deep features for data association in generating reliable trajectories, we propose the Similarity Cluster Trajectory Management method that expands affinity descriptor and adopts the minority obeying the majority principle to association trajectories and detections. The experiments on diverse and challenging MOT datasets show that our tracking framework achieves superior results compared to other state-of-the-arts offline and online multi-object tracking methods.},
  archive      = {J_NEUCOM},
  author       = {Xin Zhang and Yunan Ling and Yuanzhe Yang and Chengxiang Chu and Zhong Zhou},
  doi          = {10.1016/j.neucom.2022.11.094},
  journal      = {Neurocomputing},
  pages        = {17-30},
  shortjournal = {Neurocomputing},
  title        = {Center-point-pair detection and context-aware re-identification for end-to-end multi-object tracking},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple exponential stability and instability for
state-dependent switched neural networks with time-varying delays and
piecewise-linear radial basis activation functions. <em>NEUCOM</em>,
<em>524</em>, 1–16. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formulates multiple exponential stability and instability for a class of state-dependent switched neural networks (NNs) with time-varying delays in two cases of switching threshold W W&amp;lt;q and W ⩾ q W⩾q . Correspondingly, the index set N = { 1 , 2 , ⋯ , n } N={1,2,⋯,n} is divided into four categories N 1 , N 2 , N 3 , N 4 N1,N2,N3,N4 for W W&amp;lt;q and N ̃ 1 , N ̃ 2 , N ̃ 3 , N ̃ 4 Ñ1,Ñ2,Ñ3,Ñ4 for W ⩾ q W⩾q . According to the invariant interval acquired in these four categories, the state space is partitioned into 5 N 2 ♯ 5N2♯ ( 4 N 2 ̃ ♯ 4N2̃♯ ) regions, where N 2 ♯ N2♯ ( N 2 ̃ ♯ N2̃♯ ) signifies the number of elements in N 2 N2 ( N 2 ̃ N2̃ ). Together with reduction to absurdity, function continuity and monotonicity, as well as Lyapunov method, sufficient conditions are developed to guarantee there exists a unique equilibrium point in each region and 3 N 2 ♯ ( 3 N ̃ 2 ♯ ) 3N2♯(3Ñ2♯) equilibrium points are locally exponentially stable, the others are unstable. Three numerical examples are provided to validate the effectiveness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Liguang Wan and Zhenxing Liu},
  doi          = {10.1016/j.neucom.2022.12.040},
  journal      = {Neurocomputing},
  pages        = {1-16},
  shortjournal = {Neurocomputing},
  title        = {Multiple exponential stability and instability for state-dependent switched neural networks with time-varying delays and piecewise-linear radial basis activation functions},
  volume       = {524},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view contour-constrained transformer network for
thin-cap fibroatheroma identification. <em>NEUCOM</em>, <em>523</em>,
224–234. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification and detection of thin-cap fibroatheroma (TCFA) from intravascular optical coherence tomography (IVOCT) images is critical for treatment of coronary heart diseases . Recently, deep learning methods have shown promising successes in TCFA identification. However, most methods usually do not effectively utilize multi-view information or incorporate prior domain knowledge. In this paper, we propose a multi-view contour-constrained transformer network (MVCTN) for TCFA identification in IVOCT images. Inspired by the diagnosis process of cardiologists, we use contour constrained self-attention modules (CCSM) to emphasize features corresponding to salient regions (i.e., vessel walls) in an unsupervised manner and enhance the visual interpretability based on class activation mapping (CAM). Moreover, we exploit transformer modules (TM) to build global-range relations between two views (i.e., polar and Cartesian views) to effectively fuse features at multiple feature scales. Experimental results on a semi-public dataset and an in-house dataset demonstrate that the proposed MVCTN outperforms other single-view and multi-view methods. Lastly, the proposed MVCTN can also provide meaningful visualization for cardiologists via CAM.},
  archive      = {J_NEUCOM},
  author       = {Sijie Liu and Jingmin Xin and Jiayi Wu and Yangyang Deng and Ruisheng Su and Wiro J. Niessen and Nanning Zheng and Theo van Walsum},
  doi          = {10.1016/j.neucom.2022.12.041},
  journal      = {Neurocomputing},
  pages        = {224-234},
  shortjournal = {Neurocomputing},
  title        = {Multi-view contour-constrained transformer network for thin-cap fibroatheroma identification},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Class-aware sample reweighting optimal transport for
multi-source domain adaptation. <em>NEUCOM</em>, <em>523</em>, 213–223.
(<a href="https://doi.org/10.1016/j.neucom.2022.12.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Source Domain Adaptation (MSDA) techniques have attracted widespread attention due to their availability to transfer knowledge from multiple source domains to the unlabeled target domain. Optimal transport (OT) has recently been utilized to measure the distance between distributions in virtue of its robustness. This paper proposes a novel OT-based Class-Aware Sample Reweighting (CASR) method to achieve sample-level fine-grained alignment between multi-source and target. Technically, the class-aware sampling strategy ensures class-level conditional alignment during transport by explicitly selecting samples from each domain. Besides, the sample-reweighting module is designed to allocate specific mass to each transmitted sample, which considers the classification reliability and the spatial information correlation to obtain the alignment priority between target and multi-source and further optimize the transport plan. Extensive experiments conducted on several benchmarks show that CASR presents significant advantages compared with other MSDA methods, and the visualization analysis further demonstrates the effectiveness of each proposed module.},
  archive      = {J_NEUCOM},
  author       = {Shengsheng Wang and Bilin Wang and Zhe Zhang and Ali Asghar Heidari and Huiling Chen},
  doi          = {10.1016/j.neucom.2022.12.048},
  journal      = {Neurocomputing},
  pages        = {213-223},
  shortjournal = {Neurocomputing},
  title        = {Class-aware sample reweighting optimal transport for multi-source domain adaptation},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPNet: A novel deep neural network for retinal vessel
segmentation based on shared decoder and pyramid-like loss.
<em>NEUCOM</em>, <em>523</em>, 199–212. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of retinal vessel images is critical to the diagnosis of retinopathy . Recently, convolutional neural networks have shown significant ability to extract the blood vessel structure. However, it remains challenging to refined segmentation for the capillaries and the edges of retinal vessels due to thickness inconsistencies and blurry boundaries. In this paper, we propose a novel deep neural network for retinal vessel segmentation based on shared decoder and pyramid-like loss (SPNet) to address the above problems. Specifically, we introduce a decoder-sharing mechanism to capture multi-scale semantic information, where feature maps at diverse scales are decoded through a sequence of weight-sharing decoder modules. Also, to strengthen characterization on the capillaries and the edges of blood vessels, we define a residual pyramid architecture which decomposes the spatial information in the decoding phase. A pyramid-like loss function is designed to compensate possible segmentation errors progressively. Experimental results on public benchmarks show that the proposed method outperforms the backbone network and most state-of-the-art methods, especially in the regions of the capillaries and the vessel contours. In addition, performances on cross-datasets verify that SPNet shows stronger generalization ability .},
  archive      = {J_NEUCOM},
  author       = {Geng-Xin Xu and Chuan-Xian Ren},
  doi          = {10.1016/j.neucom.2022.12.039},
  journal      = {Neurocomputing},
  pages        = {199-212},
  shortjournal = {Neurocomputing},
  title        = {SPNet: A novel deep neural network for retinal vessel segmentation based on shared decoder and pyramid-like loss},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strengthened multiple correlation for multi-label few-shot
intent detection. <em>NEUCOM</em>, <em>523</em>, 191–198. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A challenging problem that arises in few-shot intent detection is the complexity of multiple intention (multi-label) detection. The prototypical network uses the mean value of support instances as label prototype, which cannot eliminate the interference among features of multiple labels, making the learned label prototypes deviate from the real label features. Meanwhile, regardless of the correlation with the label prototype, all the feature dimensions in the query instance are treated equally, which reduces the accuracy of similarity measurement between the query instance and the label prototype. In this paper, we propose a hybrid calculation of correlation for few-shot multi-label intent detection method (HCC-FSML) to overcome the problem. This method proposes an instance-level attention mechanism to focus on the instance representation with high correlation between support instances and positive labels, so as to improve the consistency between the label prototype and the real label features; In the similarity measurement, the feature-level attention mechanism is introduced to focus on the feature dimensions of query instance with high correlation with positive label prototype, so as to improve the accuracy of similarity measurement. The experiment shows that the proposed method achieves new state-of-the-art results in intent detection by focusing on typical features of instances and reducing multiple interference among labels.},
  archive      = {J_NEUCOM},
  author       = {Ruizhi Zhang and Senlin Luo and Limin Pan and Yong Ma and Zhouting Wu},
  doi          = {10.1016/j.neucom.2022.12.047},
  journal      = {Neurocomputing},
  pages        = {191-198},
  shortjournal = {Neurocomputing},
  title        = {Strengthened multiple correlation for multi-label few-shot intent detection},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DPF-S2S: A novel dual-pathway-fusion-based
sequence-to-sequence text recognition model. <em>NEUCOM</em>,
<em>523</em>, 182–190. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel dual-pathway-fusion-based sequence-to-sequence learning model (DPF-S2S) is proposed for text recognition in the wild, which mainly focuses on enriching the spatial information and extracting high-dimensional representation features to assist decoding. In particular, a double alignment module is developed to solve the problem of text misalignment, where both position and vision information are well considered. Moreover, a global fusion module is deployed to enrich 2D information in the aligned attention maps, which benefits accurate recognition from complicated scenes with arbitrary text shapes and poor imaging conditions. Benchmark evaluations on seven datasets have demonstrated the superiority of proposed DPF-S2S model in comparison to other state-of-the-art text recognition methods, which presents great competitiveness on identifying texts in both regular and irregular scenes. In addition, extensive ablation studies have been carried out, which validate the effectiveness of applied strategies in proposed DPF-S2S.},
  archive      = {J_NEUCOM},
  author       = {Yuqing Zhang and Peishu Wu and Han Li and Yurong Liu and Fuad E. Alsaadi and Nianyin Zeng},
  doi          = {10.1016/j.neucom.2022.12.034},
  journal      = {Neurocomputing},
  pages        = {182-190},
  shortjournal = {Neurocomputing},
  title        = {DPF-S2S: A novel dual-pathway-fusion-based sequence-to-sequence text recognition model},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tri-modality consistency optimization with heterogeneous
augmented images for visible-infrared person re-identification.
<em>NEUCOM</em>, <em>523</em>, 170–181. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared person re-identification (VI-ReID) is a challenging technology due to the large gap between daytime visible modality and night-time infrared modality. Previous studies mainly investigate the invariant modality-shared information by the feature-level constraint. They hardly eliminate the large discrepancy between both the inter- and intra- modality, obtaining suboptimal results. In this paper, we propose a novel Tri-modality Consistency Optimization Model (TCOM) to adequately decrease inter- and intra- modality discrepancies for VI-ReID. To this end, a pivotal heterogeneous augmented modality is generated by fusing visible images and infrared images. For tackling the distribution discrepancy, we design a Triplet Center Loss (TCL) to maintain the feature consistency by mitigating the relative distance among different modalities. Furthermore, we define a regularization term named Compact Intra-modality Constraint (CIC) that forces the same pedestrian within each modality to possess the compact feature distribution. With the two invariant constraints, TCOM explores the inter- and intra- modality space-invariant representation and compels the feature distribution from different modalities to be close to each other. Extensive experiments on mainstream databases demonstrate that TCOM achieves superior performance.},
  archive      = {J_NEUCOM},
  author       = {Tongzhen Si and Fazhi He and Penglei Li and Xiaoxin Gao},
  doi          = {10.1016/j.neucom.2022.12.042},
  journal      = {Neurocomputing},
  pages        = {170-181},
  shortjournal = {Neurocomputing},
  title        = {Tri-modality consistency optimization with heterogeneous augmented images for visible-infrared person re-identification},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph representation learning based on deep generative
gaussian mixture models. <em>NEUCOM</em>, <em>523</em>, 157–169. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning is an effective tool for facilitating graph analysis with machine learning methods. Most GNNs, including Graph Convolutional Networks (GCN), Graph Recurrent Neural Networks (GRNN), and Graph Auto-Encoders (GAE), employ vectors to represent nodes in a deterministic way without exploiting the uncertainty in hidden variables. Deep generative models are combined with GAE in the Variational Graph Auto-Encoder (VGAE) framework to address this issue. While traditional VGAE-based methods can capture hidden and hierarchical dependencies in latent spaces, they are limited by the data’s multimodality. Here, we propose the Gaussian Mixture Model (GMM) to model the prior distribution in VGAE. Furthermore, an adversarial regularization is incorporated into the proposed approach to ensure the fruitful impact of the latent representations on the results. We demonstrate the performance of the proposed method on clustering and link prediction tasks. Our experimental results on real datasets show remarkable performance compared to state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Ghazaleh Niknam and Soheila Molaei and Hadi Zare and David Clifton and Shirui Pan},
  doi          = {10.1016/j.neucom.2022.11.087},
  journal      = {Neurocomputing},
  pages        = {157-169},
  shortjournal = {Neurocomputing},
  title        = {Graph representation learning based on deep generative gaussian mixture models},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised medical image feature learning by using
de-melting reduction auto-encoder. <em>NEUCOM</em>, <em>523</em>,
145–156. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature learning is a fundamental and highly prioritized problem in medical image analysis. Although it has shown considerable improvements, it remains challenging because of its weak feature expression ability, low model-learning efficiency, and weak robustness. To address these limitations, a novel unsupervised feature learning method in the medical image classification task, named de-melting reduction auto-encoder (DMRAE), is proposed in this study. A joint fusion network structure is constructed; it not only improves the expression of target features but also reduces the loss of feature decoding and parameters. To obtain a robust solution, a newly designed decomposed-reconstructed loss function is used to strengthen the semantic context between adjacent feature extractor layers, successfully avoiding the insufficient model-learning ability from the single optimization objective and improving the quality of the extracted features. Finally, extensive experiments on datasets consisting of 400 breast ultrasonographic images and 6000 lung computed tomography images are conducted to demonstrate the effectiveness of the proposed method. Experimental results reveal that the DMRAE significantly reduces the annotation effort and outperforms existing methods by a significant margin.},
  archive      = {J_NEUCOM},
  author       = {Yu Sun and Jinyu Cong and Kuixing Zhang and Muwei Jian and Benzheng Wei},
  doi          = {10.1016/j.neucom.2022.12.017},
  journal      = {Neurocomputing},
  pages        = {145-156},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised medical image feature learning by using de-melting reduction auto-encoder},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Corrigendum to “low-light image enhancement with knowledge
distillation” [neurocomputing 518 (2023) 332–343]. <em>NEUCOM</em>,
<em>523</em>, 144. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Ziwen Li and Yuehuan Wang and Jinpu Zhang},
  doi          = {10.1016/j.neucom.2022.12.037},
  journal      = {Neurocomputing},
  pages        = {144},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Low-light image enhancement with knowledge distillation” [Neurocomputing 518 (2023) 332–343]},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ISM-net: Mining incremental semantics for class incremental
learning. <em>NEUCOM</em>, <em>523</em>, 130–143. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning (CIL) aims to learn new classes from the data stream, where old class data is largely discarded due to data privacy or memory restrictions. A handful of exemplars cannot reflect the complete distribution of old classes, and the separation between old and new classes is hard to guarantee, which is an important cause of catastrophic forgetting. To overcome this problem, we first propose incremental semantics mining (ISM) to reduce the misclassification between old and new classes by excluding the semantics of old classes from the representation of new classes. Then, we propose a distillation-based representation expansion strategy to encode the incremental semantics into an additional representation space. Compared to the standard representation expansion strategy, our method features lower memory overhead and computational costs. In addition, an old model queue is proposed to facilitate the maintenance of earlier knowledge. Extensive experiments on CIFAR-100 and ImageNet datasets demonstrate the superiority of our method in both performance and parameter efficiency. Several state-of-the-art results are established under different incremental settings. Code: https://github.com/zihuanqiu/ISM-Net},
  archive      = {J_NEUCOM},
  author       = {Zihuan Qiu and Linfeng Xu and Zhichuan Wang and Qingbo Wu and Fanman Meng and Hongliang Li},
  doi          = {10.1016/j.neucom.2022.12.029},
  journal      = {Neurocomputing},
  pages        = {130-143},
  shortjournal = {Neurocomputing},
  title        = {ISM-net: Mining incremental semantics for class incremental learning},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DDCNet: Deep dilated convolutional neural network for dense
prediction. <em>NEUCOM</em>, <em>523</em>, 116–129. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense pixel matching problems such as optical flow and disparity estimation are among the most challenging tasks in computer vision. Recently, several deep learning methods designed for these problems have been successful. A sufficiently larger effective receptive field (ERF) and a higher resolution of spatial features within a network are essential for providing higher-resolution dense estimates. In this work, we present a systemic approach to design network architectures that can provide a larger receptive field while maintaining a higher spatial feature resolution. To achieve a larger ERF, we utilized dilated convolutional layers . By aggressively increasing dilation rates in the deeper layers, we were able to achieve a sufficiently larger ERF with a significantly fewer number of trainable parameters. We used optical flow estimation problem as the primary benchmark to illustrate our network design strategy. The benchmark results (Sintel, KITTI, and Middlebury) indicate that our compact networks can achieve comparable performance in the class of lightweight networks.},
  archive      = {J_NEUCOM},
  author       = {Ali Salehi and Madhusudhanan Balasubramanian},
  doi          = {10.1016/j.neucom.2022.12.024},
  journal      = {Neurocomputing},
  pages        = {116-129},
  shortjournal = {Neurocomputing},
  title        = {DDCNet: Deep dilated convolutional neural network for dense prediction},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing recommendations with contrastive learning from
collaborative knowledge graph. <em>NEUCOM</em>, <em>523</em>, 103–115.
(<a href="https://doi.org/10.1016/j.neucom.2022.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There have been excellent results using knowledge graphs in recommender systems . Knowledge graphs can be used as auxiliary information to alleviate data sparsity and strengthen the modeling of item sets and the representation of user preferences. However, users as the Core subject in the recommendation process, should be taken seriously. We believe that the user&#39;s choice of items will be affected by internal and external factors. Internal factors refer to the users’ fuzzy interest sets, which initially affect the users&#39; choices. External factors refer to the influence of similar users and similar items in the users&#39; selection of items. Inspired by the success of contrastive learning in graph collaborative filtering, we propose the K nowledge A ugmented U ser R epresentation (KAUR) model to explore contrastive learning in collaborative knowledge graphs, learning semantic neighbors (external factors) and extract fuzzy interest sets (internal factors) from collaborative knowledge graphs. Specifically, we use the graph neural network to learn the representation of each node in the collaborative knowledge graph and regard the information of nodes and their propagated neighbors’ information as positive contrastive pairs, and then use contrastive learning to enhance the node representations. To further explore the potential interests of users, we regard users (or items) with other similar users (or items) as semantic neighbors and incorporate them into contrastive learning as positive pairings as well. Then the extracted fuzzy interest sets are merged into the user representations to get better interpretability . We conduct extensive experiments on three standard datasets and the results show that our KAUR model outperforms current state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Yubin Ma and Xuan Zhang and Chen Gao and Yahui Tang and Linyu Li and Rui Zhu and Chunlin Yin},
  doi          = {10.1016/j.neucom.2022.12.032},
  journal      = {Neurocomputing},
  pages        = {103-115},
  shortjournal = {Neurocomputing},
  title        = {Enhancing recommendations with contrastive learning from collaborative knowledge graph},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time adaptive neural self-triggered decentralized
control for stochastic nonlinear systems with strong interconnections.
<em>NEUCOM</em>, <em>523</em>, 92–102. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a fixed-time adaptive self-triggered decentralized control strategy based on the neural network for a class of stochastic nonlinear systems with strong interconnections. With the help of the special property of the Gaussian function, the strong interconnected functions in stochastic systems can be handled successfully without matching conditions assumptions, and the processing conditions of strong interconnected functions are relaxed. Moreover, a self-triggered mechanism is designed to decrease the waste of the system communication resources. On this basis, a fixed-time adaptive self-triggered decentralized control scheme is constructed by utilizing the fixed-time stability theory such that the stochastic nonlinear system with strong interconnections is fixed-time stable in probability. Finally, the feasibility of the developed control strategy can be ensured by the simulation result.},
  archive      = {J_NEUCOM},
  author       = {Zhechen Zhu and Quanxin Zhu},
  doi          = {10.1016/j.neucom.2022.12.030},
  journal      = {Neurocomputing},
  pages        = {92-102},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time adaptive neural self-triggered decentralized control for stochastic nonlinear systems with strong interconnections},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CapsulePose: A variational CapsNet for real-time end-to-end
3D human pose estimation. <em>NEUCOM</em>, <em>523</em>, 81–91. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating 3D human poses from images is an ill-posed regression problem , which is usually tackled by viewpoint-invariant convolutional neural networks (CNNs). Recently, capsule networks (CapsNets) have been introduced as a viable alternative to CNNs, ensuring viewpoint-equivariance and drastically reducing both the dataset size and the network complexity, while retaining high output accuracy. We propose a real-time end-to-end human pose estimation (HPE) network which employs state-of-the-art matrix capsules [1] and a fast variational Bayesian capsule routing, without relying on pre-training, complex data augmentation or multiple datasets. We achieve comparable results to the HPE state-of-the-art, and the lowest error among methods using CapsNets, while at the same time achieving other desirable properties , namely greater generalization capabilities, stronger viewpoint equivariance and highly decreased data dependency , allowing for our network to be trained with only a fraction of the available datasets and without any data augmentation .},
  archive      = {J_NEUCOM},
  author       = {Nicola Garau and Nicola Conci},
  doi          = {10.1016/j.neucom.2022.11.097},
  journal      = {Neurocomputing},
  pages        = {81-91},
  shortjournal = {Neurocomputing},
  title        = {CapsulePose: A variational CapsNet for real-time end-to-end 3D human pose estimation},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ISIC_WSM: Generating weak segmentation maps for the ISIC
archive. <em>NEUCOM</em>, <em>523</em>, 69–80. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing skin cancer in time could greatly increase patients’ chances of recovery. For this reason, in recent years, numerous decision support systems have been proposed to help dermatologists in this diagnosis. These systems are generally based on Convolutional Neural Networks and are used for both segmentation and classification of lesions. Although their main goal is to correctly recognize the lesions’ type, the preliminary segmentation step has been shown to increase the performance of the classifier. In fact, this is not surprising because physicians also use information on the shape of the lesion to make a diagnosis. Thanks to the ISIC archive, a huge number of skin lesion images, along with the corresponding metadata (type, position, dimension, etc.), are publicly available to train a deep neural network, but, unfortunately, only a small fraction of them are labeled for segmentation. To overcome this limitation, in this paper, a weak supervised approach is proposed to extract the segmentation label maps from the entire ISIC archive. Moreover, to demonstrate the quality of the proposed approach, the generated supervisions were first compared with those available in ISIC and, then, used to train a segmentation network , whose performance was evaluated against that obtained using only the small set of ISIC label maps. To foster reproducibility and to promote future research in lesion segmentation and classification, the generated ISIC Weak Segmentation Map (ISIC_WSM) dataset has been released. As far as we know, this is the first dataset that contains segmentation supervisions for clinical images of skin lesions.},
  archive      = {J_NEUCOM},
  author       = {Simone Bonechi},
  doi          = {10.1016/j.neucom.2022.12.033},
  journal      = {Neurocomputing},
  pages        = {69-80},
  shortjournal = {Neurocomputing},
  title        = {ISIC_WSM: Generating weak segmentation maps for the ISIC archive},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving dynamic gesture recognition in untrimmed videos by
an online lightweight framework and a new gesture dataset ZJUGesture.
<em>NEUCOM</em>, <em>523</em>, 58–68. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human–computer interaction technology brings great convenience to people, and dynamic gesture recognition makes it possible for a man to interact naturally with a machine. However, recognizing gestures quickly and precisely in untrimmed videos remains a challenge in real-world systems since: (1) It is challenging to locate the temporal boundaries of performing gestures; (2) There are significant differences in performing gestures among different people, resulting in a variety of gestures; (3) There must be a trade-off between the accuracy and the computational consumption. In this work, we propose an online lightweight two-stage framework, including a detection module and a gesture recognition module, to precisely detect and classify dynamic gestures in untrimmed videos. Specifically, we first design a low-power detection module to locate gestures in time series, then a temporal relational reasoning module is employed for gesture recognition. Moreover, we present a new dynamic gesture dataset named ZJUGesture, which contains nine classes of common gestures in various scenarios. Extensive experiments on the proposed ZJUGesture and 20-bn-Jester dataset demonstrate the attractive performance of our method with high accuracy and a low computational cost.},
  archive      = {J_NEUCOM},
  author       = {Chao Xu and Xia Wu and Mengmeng Wang and Feng Qiu and Yong Liu and Jun Ren},
  doi          = {10.1016/j.neucom.2022.12.022},
  journal      = {Neurocomputing},
  pages        = {58-68},
  shortjournal = {Neurocomputing},
  title        = {Improving dynamic gesture recognition in untrimmed videos by an online lightweight framework and a new gesture dataset ZJUGesture},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid attention-oriented experience replay for deep
reinforcement learning and its application to a multi-robot cooperative
hunting problem. <em>NEUCOM</em>, <em>523</em>, 44–57. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple robots complete a cooperative hunting task by obtaining environmental information and autonomously learning hunting decision-making strategies. However, with the increase in the number of environment participants, it becomes difficult for robots to process a large amount of environmental information. Thus, a multi-robot cooperative hunting decision-making method called hybrid attention-oriented experience replay in multi-agent deep deterministic policy gradient (HAER-MADDPG) is proposed. First, a hybrid attention module is designed to pay greater attention to key information in a large amount of environmental information by integrating it with the multi-agent deep deterministic policy gradient (MADDPG). The method then combines hybrid attention and prioritized experience replay to improve the utilization of experience samples. Finally, the proposed algorithm is tested through a predator–prey game. The results show that the effectiveness, convergence speed, and scalability of the proposed algorithm are better than those of the baseline algorithms. In addition, HAER-MADDPG is effectively applied to a hunting task with real robots.},
  archive      = {J_NEUCOM},
  author       = {Lingli Yu and Shuxin Huo and Zhengjiu Wang and Keyi Li},
  doi          = {10.1016/j.neucom.2022.12.020},
  journal      = {Neurocomputing},
  pages        = {44-57},
  shortjournal = {Neurocomputing},
  title        = {Hybrid attention-oriented experience replay for deep reinforcement learning and its application to a multi-robot cooperative hunting problem},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online numerical association rule miner. <em>NEUCOM</em>,
<em>523</em>, 33–43. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green AI refers to those AI methods that are friendly to the environment, i.e., are capable to keep the consumption of electrical energy at a minimum. In this sense, a new numerical association rule miner is proposed that presents a combination of the already existing offline uARMSolver, belonging to a Red AI class, and a newly developed onlineNARM miner representing the new Green AI. The former is devoted to exhaustive search of the evolutionary solution space, while the latter for faster exploiting of already explored search space. The experimental results on four transaction databases showed that, by sacrificing the quality of the results by 0.7 ∼\% 0.7∼\% , by the onlineNARM we can obtain the results almost 85.0 ∼\% 85.0∼\% faster than with the uARMSolver in the best test scenario.},
  archive      = {J_NEUCOM},
  author       = {Iztok Fister and Andres Iglesias and Akemi Galvez and Iztok Fister Jr.},
  doi          = {10.1016/j.neucom.2022.12.002},
  journal      = {Neurocomputing},
  pages        = {33-43},
  shortjournal = {Neurocomputing},
  title        = {Online numerical association rule miner},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network models for time-varying tensor
complementarity problems. <em>NEUCOM</em>, <em>523</em>, 18–32. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existence and uniqueness of solutions and fast algorithms for tensor complementarity problems are hot topics in nowadays. We present a time-varying tensor complementarity problem (TVTCP) under tensor-tensor product (t-product). Theoretical analysis shows that the TVTCP is equivalent to a time-varying absolute value equation (TVAVE) under the mild conditions. Based on the absolute value equation, some neural networks for solving time-varying tensor inverse and TVTCP under the t-product are proposed and corresponding convergence are studied. Moreover, if the activation function (AF) of the neural networks is Mwsbp function, then we present the upper bound of the convergence time for the proposed neural networks. The numerical test results further illustrate that the proposed neural networks can solve time-varying tensor inverse and TVTCP effectively.},
  archive      = {J_NEUCOM},
  author       = {Ping Wei and Xuezhong Wang and Yimin Wei},
  doi          = {10.1016/j.neucom.2022.12.008},
  journal      = {Neurocomputing},
  pages        = {18-32},
  shortjournal = {Neurocomputing},
  title        = {Neural network models for time-varying tensor complementarity problems},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mask-guided modality difference reduction network for RGB-t
semantic segmentation. <em>NEUCOM</em>, <em>523</em>, 9–17. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By exploiting the complementary information of RGB modality and thermal modality, RGB-thermal (RGB-T) semantic segmentation is robust to adverse lighting conditions. When fusing features from RGB images and thermal images , the existing methods design different feature fusion strategies, but most of these methods overlook the modality differences caused by different imaging mechanisms. This may result in insufficient usage of complementary information. To address this issue, we propose a novel Mask-guided Modality Difference Reduction Network (MMDRNet), where the mask is utilized in the image reconstruction to ensure that the modality discrepancy within foreground regions is minimized. Doing so enables the generation of more discriminative representations for foreground pixels, thus facilitating the segmentation task . On top of this, we present a Dynamic Task Balance (DTB) method to balance the modality difference reduction task and semantic segmentation task dynamically. The experimental results on the MFNet dataset and the PST900 dataset demonstrate the superiority of the proposed mask-guided modality difference reduction strategy and the effectiveness of the DTB method.},
  archive      = {J_NEUCOM},
  author       = {Wenli Liang and Yuanjian Yang and Fangyu Li and Xi Long and Caifeng Shan},
  doi          = {10.1016/j.neucom.2022.12.036},
  journal      = {Neurocomputing},
  pages        = {9-17},
  shortjournal = {Neurocomputing},
  title        = {Mask-guided modality difference reduction network for RGB-T semantic segmentation},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A discrete memristive neural network and its application for
character recognition. <em>NEUCOM</em>, <em>523</em>, 1–8. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design of artificial neural networks based on memristor has attracted increasing attentions from researchers. However, there are no reports on the discrete memristor based neural network . In this work, a novel discrete memristor BP neural network is designed. Firstly, a discrete memristor is introduced, in which the internal state can be controlled by the input discrete current signal. Secondly, theoretical basis of the proposed discrete memristor BP neural network is given where the weights are defined by the memristor resistance and can be adjusted according to discrete feedback errors. Finally, a three layers discrete memristor BP neural network is built to perform MNIST-10 handwriting recognition. Numerical results show a high classification accuracy of 97.16\% and it verifies the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Shaobo He and Jun Liu and Huihai Wang and Kehui Sun},
  doi          = {10.1016/j.neucom.2022.12.014},
  journal      = {Neurocomputing},
  pages        = {1-8},
  shortjournal = {Neurocomputing},
  title        = {A discrete memristive neural network and its application for character recognition},
  volume       = {523},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameterizing echo state networks for multi-step time
series prediction. <em>NEUCOM</em>, <em>522</em>, 214–228. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of multi-dimensional time-series data, which may represent such diverse phenomena as climate changes or financial markets, remains a challenging task in view of inherent nonlinearities and non-periodic behavior. In contrast to other recurrent neural networks, echo state networks (ESNs) are attractive for (online) learning due to lower requirements w.r.t. training data and computational power. However, the randomly-generated reservoir renders the choice of suitable hyper-parameters as an open research topic. We systematically derive and exemplarily demonstrate design guidelines for the hyper-parameter optimization of ESNs . For the evaluation, we focus on the prediction of chaotic time series, an especially challenging problem in machine learning. Our findings demonstrate the power of a hyper-parameter-tuned ESN when auto-regressively predicting time series over several hundred steps. We found that ESNs’ performance improved by 85.1\% - 99.8\% 85.1\%-99.8\% over an already wisely chosen default parameter initialization. In addition, the fluctuation range is considerably reduced such that significantly worse performance becomes very unlikely across random reservoir seeds. Moreover, we report individual findings per hyper-parameter partly contradicting common knowledge to further, help researchers when training new models.},
  archive      = {J_NEUCOM},
  author       = {Johannes Viehweg and Karl Worthmann and Patrick Mäder},
  doi          = {10.1016/j.neucom.2022.11.044},
  journal      = {Neurocomputing},
  pages        = {214-228},
  shortjournal = {Neurocomputing},
  title        = {Parameterizing echo state networks for multi-step time series prediction},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dissimilate-and-assimilate strategy for video anomaly
detection and localization. <em>NEUCOM</em>, <em>522</em>, 203–213. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised anomaly detection in videos is a challenging task owing to the remarkable generalization capacity of the deep convolutional autoencoders and the complex nature of anomalous events. In this study, we introduce a dissimilate-and-assimilate strategy to learn essential patterns of multilevel latent representations of normal spatial and temporal information. To obtain the core normality of the appearance and motion samples over multiple layers of the network, our proposed method diversifies the latent patterns of normal spatial and temporal data to make the out-of-distribution samples discrete (dissimilation) and integrates the latent features of two different samples into a single sample using a feature attention mechanism for robust optimization (assimilation). Based on the learned representations, the network generates convincing predictions of the normal frame, even if it receives abnormal samples after training. That is, the anomalous objects in a series of frames can be detected with significant reconstruction errors, thus leading to better detection and precise localization performance. To verify the effectiveness of the proposed method, we quantify the preciseness of anomaly localization using the outside-inside error ratio along with the traditional area under the curve (AUC) metric to measure the detection performance on the USCD Pedestrian 2, CHUK Avenue and ShanghaiTech Campus datasets.},
  archive      = {J_NEUCOM},
  author       = {Wooyeol Hyun and Woo-Jeoung Nam and Seong-Whan Lee},
  doi          = {10.1016/j.neucom.2022.12.026},
  journal      = {Neurocomputing},
  pages        = {203-213},
  shortjournal = {Neurocomputing},
  title        = {Dissimilate-and-assimilate strategy for video anomaly detection and localization},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pinning synchronization for markovian jump neural networks
with uncertain impulsive effects. <em>NEUCOM</em>, <em>522</em>,
194–202. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work concentrates on synchronization of neural networks (NNs) with Markovian parameters, where the Markov chain has partially unknown transition probabilities (PUTP). Due to the existence of interference and noise in practice, we combine the uncertain variable with the complex coupling term as the impulsive disturbance of NNs. A corresponding mode-dependent pinning controller is designed to reduce the control costs, and synchronization error system is also derived, whose impulsive update state is listed separately. A sufficient condition of synchronization for NNs is completed by constructing a Lyapunov functional candidate and a series of iterations. Because the disturbance should avoid being too frequent to guarantee synchronization of NNs, the allowed minimum interval h h of the impulsive disturbance is derived. Finally, the correctness and the superiority of the developed result are illustrated by a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Yuru Guo and Zenghong Huang and Lixin Yang and Hongxia Rao and Hui Chen and Yong Xu},
  doi          = {10.1016/j.neucom.2022.12.021},
  journal      = {Neurocomputing},
  pages        = {194-202},
  shortjournal = {Neurocomputing},
  title        = {Pinning synchronization for markovian jump neural networks with uncertain impulsive effects},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of automatic image classification methods for
urticaceae pollen classification. <em>NEUCOM</em>, <em>522</em>,
181–193. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pollen classification is considered an important task in palynology. In the Netherlands, two genera of the Urticaceae family, named Parietaria and Urtica , have high morphological similarities but induce allergy at a very different level. Therefore, distinction between these two genera is very important. Within this group, the pollen of Urtica membranacea is the only species that can be recognized easily under the microscope. For the research presented in this study, we built a dataset from 6472 pollen images and our aim was to find the best possible classifier on this dataset by analysing different classification methods, both machine learning and deep learning-based methods. For machine learning-based methods, we measured both texture and moment features based on images from the pollen grains. Varied feature selection techniques, classifiers as well as a hierarchical strategy were implemented for pollen classification. For deep learning-based methods, we compared the performance of six popular Convolutional Neural Networks : AlexNet, VGG16, VGG19 , MobileNet V1, MobileNet V2 and ResNet50 . Results show that compared with flat classification models , a hierarchical strategy yielded the highest accuracy with 94.5\% among machine learning-based methods. Among deep learning-based methods, ResNet50 achieved an accuracy of 99.4\%, slightly outperforming the other neural networks investigated. In addition, we investigated the influence on performance by changing the size of image datasets to 1000 and 500 images, respectively. Results demonstrated that on smaller datasets, ResNet50 still achieved the best classification performance. An ablation study was implemented to help understanding why the deep learning-based methods outperformed the other models investigated. Using Urticaceae pollen as an example, our research provides a strategy of selecting a classification model for pollen datasets with highly similar pollen grains to support palynologists and could potentially be applied to other image classification tasks .},
  archive      = {J_NEUCOM},
  author       = {Chen Li and Marcel Polling and Lu Cao and Barbara Gravendeel and Fons J. Verbeek},
  doi          = {10.1016/j.neucom.2022.11.042},
  journal      = {Neurocomputing},
  pages        = {181-193},
  shortjournal = {Neurocomputing},
  title        = {Analysis of automatic image classification methods for urticaceae pollen classification},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GradFuzz: Fuzzing deep neural networks with gradient vector
coverage for adversarial examples. <em>NEUCOM</em>, <em>522</em>,
165–180. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are susceptible to adversarial attacks that add perturbations to the input data, leading to misclassification errors and causing machine-learning systems to fail. For defense, adversarial training leverages possible crashing inputs, i.e., adversarial examples ; but, the input space of DNNs is enormous and high-dimensional, making it difficult to find in a wide range. Coverage-guided fuzzing is promising in this respect. However, this leaves the question of what coverage metrics are appropriate for DNNs. We observed that the abilities of existing coverage metrics are limited. They lack gradual guidance toward crashes because of a simple search for a wide neuron activation area. None of the existing approaches can simultaneously achieve high crash quantity, high crash diversity, and efficient fuzzing time. Apart from this, the evaluation methodologies adopted by state-of-the-art fuzzers need rigorous improvements. To address these problems, we present a new DNN fuzzer named GradFuzz. Our idea is the gradient vector coverage, which provides gradual guidance to misclassified categories. We implemented our system and performed experiments under rigorous evaluation methodologies. Our evaluation results indicate that GradFuzz outperforms state-of-the-art DNN fuzzers : GradFuzz can locate a more diverse set of errors, beneficial to adversarial training, on the MNIST and CIFAR-10 datasets without sacrificing both crash quantity and fuzzing efficiency.},
  archive      = {J_NEUCOM},
  author       = {Leo Hyun Park and Soochang Chung and Jaeuk Kim and Taekyoung Kwon},
  doi          = {10.1016/j.neucom.2022.12.019},
  journal      = {Neurocomputing},
  pages        = {165-180},
  shortjournal = {Neurocomputing},
  title        = {GradFuzz: Fuzzing deep neural networks with gradient vector coverage for adversarial examples},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive fusion network for RGB-d salient object detection.
<em>NEUCOM</em>, <em>522</em>, 152–164. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing state-of-the-art RGB-D saliency detection models mainly utilize the depth information as complementary cues to enhance the RGB information. However, depth maps can be easily influenced by environment and hence are full of noises. Thus, indiscriminately integrating multi-modality (i.e., RGB and depth) features may induce noise-degraded saliency maps. In this paper, we propose a novel Adaptive Fusion Network (AFNet) to solve this problem. Specifically, we design a triplet encoder network consisting of three subnetworks to process RGB, depth, and fused features, respectively. The three subnetworks are interlinked and form a grid net to facilitate mutual refinement of these multi-modality features. Moreover, we propose a Multi-modality Feature Interaction (MFI) module to exploit complementary cues between depth and RGB modalities and adaptively fuse the multi-modality features. Finally, we design the Cascaded Feature Interweaved Decoder (CFID) to exploit complementary information between multi-level features and refine them iteratively to achieve accurate saliency detection . Experimental results on six commonly used benchmark datasets verify that the proposed AFNet outperforms 20 state-of-the-art counterparts in terms of six widely adopted evaluation metrics . Source code will be publicly available at https://github.com/clelouch/AFNet upon paper acceptance.},
  archive      = {J_NEUCOM},
  author       = {Tianyou Chen and Jin Xiao and Xiaoguang Hu and Guofeng Zhang and Shaojie Wang},
  doi          = {10.1016/j.neucom.2022.12.004},
  journal      = {Neurocomputing},
  pages        = {152-164},
  shortjournal = {Neurocomputing},
  title        = {Adaptive fusion network for RGB-D salient object detection},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training with scaled logits to alleviate class-level
over-fitting in few-shot learning. <em>NEUCOM</em>, <em>522</em>,
142–151. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are criticized for the requirement of large set of labeled training data. Therefore, few-shot learning (FSL), which enables fast learning with only a few labeled examples, draws increasing attention. In FSL, the model is trained on base classes to learn the meta-knowledge, which is then applied to novel classes. The generalization from base classes to novel classes in FSL suffers from the class-level over-fitting problem. Generally, in traditional classification tasks , training samples and test samples are from the same class set, where over-fitting happens at the sample level. However, in FSL, the model is evaluated with classification tasks on novel classes. Thus, good fitting on base classes does not guarantee a good generalization to novel classes. In this paper, we reveal the class-level over-fitting problem in FSL and provide an explanation of the cause of this problem. Based on the explanation, we argue that simply scaling the logits of classifier during training can alleviate the class-level over-fitting problem, and analyze how scaling logits (SL) alleviates class-level over-fitting based on gradient back-propagation. Extensive experiments show that SL boosts the performance to the extent of 14\% on four popular benchmark datasets. Further, SL also demonstrates its effectiveness on confidence calibration.},
  archive      = {J_NEUCOM},
  author       = {Rui-Qi Wang and Fei Zhu and Xu-Yao Zhang and Cheng-Lin Liu},
  doi          = {10.1016/j.neucom.2022.12.011},
  journal      = {Neurocomputing},
  pages        = {142-151},
  shortjournal = {Neurocomputing},
  title        = {Training with scaled logits to alleviate class-level over-fitting in few-shot learning},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep thermal-guided approach for effective low-light
visible image enhancement. <em>NEUCOM</em>, <em>522</em>, 129–141. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light visible image enhancement is important for various visual computing applications under conditions of poor lighting or hazardous weather. However, existing low-light image enhancement methods are mostly based on a single visible channel and cannot achieve satisfactory performance when processing real-captured nighttime images. In this paper, we attempt to utilize the complementary edge/texture features presented in thermal images to provide a stable guidance map to facilitate the enhancement of features extracted on low-light visible images. For this purpose, we propose a novel Central Difference Convolution-based Multi-Receptive-Field (CDC-MRF) module to effectively extract multi-scale edge/texture features on thermal images. Then, we design a thermal-guided convolutional block (TGCB) to enhance the low-light visible features under the guidance of thermal features. To our best knowledge, the proposed thermal-guided low-light image enhancement network (TGLLE-Net) represents the first attempt to perform low-light visible image enhancement by incorporating complementary information presented in both visible and thermal channels. The advantages of the proposed TGLLE-Net are twofold. Firstly, it is capable of suppressing severe noise disturbance presented in low-light visible images under the guidance of low-frequency components in thermal images. Moreover, TGLLE-Net can promote detail/appearance restoration of objects with distinctive thermal features (e.g., pedestrians, vehicles, and buildings). Both objective and subjective evaluation results demonstrate that our proposed TGLLE-Net outperforms state-of-the-art methods in terms of restoration accuracy, visual perception, and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Yanpeng Cao and Xi Tong and Fan Wang and Jiangxin Yang and Yanlong Cao and Sabin Tiberius Strat and Christel-Loic Tisse},
  doi          = {10.1016/j.neucom.2022.12.007},
  journal      = {Neurocomputing},
  pages        = {129-141},
  shortjournal = {Neurocomputing},
  title        = {A deep thermal-guided approach for effective low-light visible image enhancement},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimized fuzzy deep learning model for data
classification based on NSGA-II. <em>NEUCOM</em>, <em>522</em>, 116–128.
(<a href="https://doi.org/10.1016/j.neucom.2022.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful paradigm, deep learning (DL) models have been used in many applications for classification tasks in images, text, and audio. Through DL models, we can learn task-driven features from big data. However, DL models are fully deterministic and cannot handle uncertain and imprecise data. DL models are often sensitive to noise in data and do not operate well in areas where data are vague. Moreover, when there is a large feature set or high-dimensional data with irrelevant and redundant features, the DL models’ performance decreases in classification due to training with irrelevant features. To gain reliable results in such high-dimensional problems, DL models require a large amount of data which usually grows exponentially concerning the number of features. Data uncertainty problems and irrelevant features in DL models cause low performance in classification tasks . This paper proposes an optimized fuzzy deep learning (OFDL) model for data classification based on Non-Dominated Sorting Genetic Algorithm II (NSGA-II). OFDL utilizes optimization in the composition of DL and fuzzy learning via the NSGA-II in multi-modal learning. To achieve effective classification, OFDL first considers intelligent feature selection by finding the best trade-offs between two conflicting objective functions, minimizing the number of features, and maximizing the accuracy (maximizing weights of selected features). Next, to reach optimized backpropagation and fuzzy membership functions , OFDL utilizes Pareto optimal solutions for multi-objective optimization using NSGA-II based on their objective functions. Furthermore, the fusion layer in OFDL fused optimized views of DL and fuzzy learning that provides a high-level representation of inputs and optimum features for classification tasks where the data contain high uncertainties and noises. This functionality gives valuable attributes during classification since identifying and selecting appropriate features ensures prompt and correct class. Also, it provides deep insight into tackling the effect of ambiguous data and each feature’s uncertainty in the classification tasks. The examination of OFDL reveals good performance in terms of F-measure, accuracy, recall, precision, and True Positive Rate (TPR) compared to fuzzy classifiers. Furthermore, OFDL has higher accuracy in classification tasks than earlier fuzzy DNN models.},
  archive      = {J_NEUCOM},
  author       = {Abbas Yazdinejad and Ali Dehghantanha and Reza M. Parizi and Gregory Epiphaniou},
  doi          = {10.1016/j.neucom.2022.12.027},
  journal      = {Neurocomputing},
  pages        = {116-128},
  shortjournal = {Neurocomputing},
  title        = {An optimized fuzzy deep learning model for data classification based on NSGA-II},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed optimization for consensus performance of
delayed fractional-order double-integrator multi-agent systems.
<em>NEUCOM</em>, <em>522</em>, 105–115. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses distributed optimization problems concerning consensus in delayed fractional-order double-integrator multi-agent systems (FDMSs). To start with, an optimized distributed protocol with state-fractional-order-derivative feedback (SF) is presented for delayed FDMSs. Then, the consensus problems are studied for the two kinds of delayed FDMSs with SF in the presence of symmetric time-delays over undirected network topology and asymmetric time-delays over directed network topology. Next, by the means of graph theory, matrix theory and frequency-domain analysis method, the sufficient conditions to guarantee consensus of delayed FDMSs with SF are derived. Compared to the traditional distributed protocol without SF, the proposed distributed optimization protocol with SF are taken into account to enable better consensus performance in delayed FDMSs with SF. Finally, numerical experiments are carried out to verify the feasibility of our theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Jun Liu and Nan Zhou and Kaiyu Qin and Badong Chen and Yonghong Wu and Kup-Sze Choi},
  doi          = {10.1016/j.neucom.2022.12.005},
  journal      = {Neurocomputing},
  pages        = {105-115},
  shortjournal = {Neurocomputing},
  title        = {Distributed optimization for consensus performance of delayed fractional-order double-integrator multi-agent systems},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint coupled representation and homogeneous reconstruction
for multi-resolution small sample face recognition. <em>NEUCOM</em>,
<em>522</em>, 89–104. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Off-the-shelf dictionary learning algorithms have achieved satisfactory results in small sample face recognition applications. However, the achieved results depend on the facial images obtained at a single resolution. In practice, the resolution of the images captured on the same target is different because of the different shooting equipment and different shooting distances. These images of the same category at different resolutions will pose a great challenge to these algorithms. In this paper, we propose a Joint Coupled Representation and Homogeneous Reconstruction (JCRHR) for multi-resolution small sample face recognition. In JCRHR, an analysis dictionary is introduced and combined with the synthetic dictionary for coupled representation learning , which better reveals the relationship between coding coefficients and samples. In addition, a coherence enhancement term is proposed to improve the coherent representation of the coding coefficients at different resolutions, which facilitates the reconstruction of the sample by its homogeneous atoms. Moreover, each sample at different resolutions is assigned a different coding coefficient in the multi-dictionary learning process, so that the learned dictionary is more in line with the actual situation. Furthermore, a regularization term based on the fractional norm is drawn into the dictionary coupled learning to remove the redundant information in the dictionary, which can reduce the negative impacts of the redundant information. Comprehensive results demonstrate that the proposed JCRHR method achieves better results than the state-of-the-art methods, on several small sample face databases.},
  archive      = {J_NEUCOM},
  author       = {Xiaojin Fan and Mengmeng Liao and Jingfeng Xue and Hao Wu and Lei Jin and Jian Zhao and Liehuang Zhu},
  doi          = {10.1016/j.neucom.2022.12.016},
  journal      = {Neurocomputing},
  pages        = {89-104},
  shortjournal = {Neurocomputing},
  title        = {Joint coupled representation and homogeneous reconstruction for multi-resolution small sample face recognition},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatio-temporal matching for siamese visual tracking.
<em>NEUCOM</em>, <em>522</em>, 73–88. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Siamese trackers formulate the visual tracking task as a similarity matching problem through cross correlation. It is arduous for such methods to track targets with the presence of distractors. We suspect the reasons are twofold: 1) The irrelevant activated channels in the correlation map will produce ambiguous matching results. 2) The pipeline is a per-frame matching process and cannot handle the response aberrance caused by temporal context variation. In this paper, we propose a spatio-temporal matching process to thoroughly explore the capability of 4-D matching in space (height, width and channel) and time. In spatial matching, we introduce a space-variant instance-aware correlation (SI-Corr) to implement different channel-wise response recalibration for each matching position. SI-Corr can guide the generation of instance-aware features and distinguish the target and distractors at the instance level. In temporal matching, we design an aberrance repressed module (ARM) to investigate the short-term positional relationship between the target and distractors. ARM utilizes a simple optimization method to restrict the abrupt alteration of the interframe response maps, which allows the network to learn a temporal consistency of context structure distribution. Moreover, we efficiently embed temporal consistency into the inference process. Experiments on six benchmarks, including OTB100, VOT2018, VOT2020, GOT-10k, LaSOT and TrackingNet, demonstrate the state-of-the-art performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jinpu Zhang and Kaiheng Dai and Ziwen Li and Ruonan Wei and Yuehuan Wang},
  doi          = {10.1016/j.neucom.2022.11.093},
  journal      = {Neurocomputing},
  pages        = {73-88},
  shortjournal = {Neurocomputing},
  title        = {Spatio-temporal matching for siamese visual tracking},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balanced masking strategy for multi-label image
classification. <em>NEUCOM</em>, <em>522</em>, 64–72. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imbalance is an essential issue in multi-label image classification that may reduce the model’s generalization ability . Unlike oversampling or undersampling in single-label image classification , simply removing or repeating some images in multi-label classification will influence labels in other categories due to complex label dependencies. Current methods usually tackle this issue from either data resampling or loss function design. This paper proposes a balanced masking strategy to solve the imbalance problem in feature space for graph-based methods. By selectively manipulating the label node embedding of the graph, the model can gain the priors of the majority of samples to maintain intra-class and inter-class balance simultaneously, thus performing better and more stable. Extensive experiments verify the adaptability and effectiveness of our method, which can be easily applied to any graph-based multi-label model to achieve highly competitive performance.},
  archive      = {J_NEUCOM},
  author       = {Jin Yuan and Yao Zhang and Zhongchao Shi and Xin Geng and Jianping Fan and Yong Rui},
  doi          = {10.1016/j.neucom.2022.11.022},
  journal      = {Neurocomputing},
  pages        = {64-72},
  shortjournal = {Neurocomputing},
  title        = {Balanced masking strategy for multi-label image classification},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Delay-dependent and order-dependent conditions for stability
and stabilization of fractional-order memristive neural networks with
time-varying delays. <em>NEUCOM</em>, <em>522</em>, 53–63. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stability and stabilization problems of fractional-order memristive neural networks with time-varying delays are addressed. Based on Jensen-based integral inequalities, novel delay-dependent and order-dependent stability conditions for fractional-order memristive neural networks with time-varying delays are established. The proposed stability criterion is in terms of linear matrix inequalities and is easy to be verified and applied. Then, a linear feedback control law that stabilizes fractional-order memristive neural networks with time-varying delays is designed by utilizing the obtained stability conditions. Two numerical examples are used to illustrate the effectiveness and less conservativeness of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Xiao-Chuang Jin and Jun-Guo Lu and Qing-Hao Zhang},
  doi          = {10.1016/j.neucom.2022.12.006},
  journal      = {Neurocomputing},
  pages        = {53-63},
  shortjournal = {Neurocomputing},
  title        = {Delay-dependent and order-dependent conditions for stability and stabilization of fractional-order memristive neural networks with time-varying delays},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local-global coordination with transformers for referring
image segmentation. <em>NEUCOM</em>, <em>522</em>, 39–52. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring image segmentation has sprung up benefiting from the outstanding performance of deep neural networks . However, most existing methods explore either local details or the global context of the scene without sufficiently modelling the coordination between them, leading to sub-optimal results. In this paper, we propose a transformer-based method to enforce the in-depth coordination between short- and long-range dependencies in both explicit and implicit fusion processes. Specifically, we design a Cross Modality Transformer (CMT) module with two successive blocks for explicitly integrating linguistic and visual features, which first locates the related visual region in a global view before concentrating on local patterns. Besides, a Hybrid Transformer Architecture (HTA) is utilized as a feature extractor in the encoding stage to capture global relationships and retain local cues. It can further aggregate the multi-modal features in an implicit manner. In the decoding stage, a Cross-level Information Integration module (CI2) is developed to gather information from adjacent levels by dual top-down paths, including a guided filtration path and a residual reservation path. Experimental results show that the proposed method outperforms the state-of-the-art methods on four RIS benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Fang Liu and Yuqiu Kong and Lihe Zhang and Guang Feng and Baocai Yin},
  doi          = {10.1016/j.neucom.2022.12.018},
  journal      = {Neurocomputing},
  pages        = {39-52},
  shortjournal = {Neurocomputing},
  title        = {Local-global coordination with transformers for referring image segmentation},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning label diffusion maps for semi-automatic
segmentation of lung CT images with COVID-19. <em>NEUCOM</em>,
<em>522</em>, 24–38. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has become one of the key approaches for dealing with many challenges in medical imaging, which includes lung segmentation in Computed Tomography (CT). The use of seeded segmentation methods is another effective approach to get accurate partitions from complex CT images, as they give users autonomy, flexibility and easy usability when selecting specific targets for measurement purposes or pharmaceutical interventions. In this paper, we combine the accuracy of deep contour leaning with the versatility of seeded segmentation to yield a semi-automatic framework for segmenting lung CT images from patients affected by COVID-19. More specifically, we design a DL-driven approach that learns label diffusion maps from a contour detection network integrated with a label propagation model, used to diffuse the seeds over the CT images. Moreover, the trained model induces the diffusion of the seeds by only taking as input a marked CT-scan, segmenting hundreds of CT slices in an unsupervised and recursive way. Another important trait of our framework is that it is capable of segmenting lung structures even in the lack of well-defined boundaries and regardless of the level of COVID-19 infection. The accuracy and effectiveness of our learned diffusion model are attested to by both qualitative as well as quantitative comparisons involving several user-steered segmentations methods and eight CT data sets containing different types of lesions caused by COVID-19.},
  archive      = {J_NEUCOM},
  author       = {Aldimir Bruzadin and Maurílio Boaventura and Marilaine Colnago and Rogério Galante Negri and Wallace Casaca},
  doi          = {10.1016/j.neucom.2022.12.003},
  journal      = {Neurocomputing},
  pages        = {24-38},
  shortjournal = {Neurocomputing},
  title        = {Learning label diffusion maps for semi-automatic segmentation of lung CT images with COVID-19},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). ASAT: Adaptively scaled adversarial training in time
series. <em>NEUCOM</em>, <em>522</em>, 11–23. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training is a method for enhancing neural networks to improve the robustness against adversarial examples . Besides the security concerns of potential adversarial examples, adversarial training can also improve the generalization ability of neural networks, train robust neural networks, and provide interpretability for neural networks. In this work, we introduce adversarial training in time series analysis to enhance the neural networks for better generalization ability by taking the finance field as an example. Rethinking existing research on adversarial training, we propose the adaptively scaled adversarial training (ASAT) in time series analysis, by rescaling data at different time slots with adaptive scales. Experimental results show that the proposed ASAT can improve both the generalization ability and the adversarial robustness of neural networks compared to the baselines. Compared to the traditional adversarial training algorithm, ASAT can achieve better generalization ability and similar adversarial robustness.},
  archive      = {J_NEUCOM},
  author       = {Zhiyuan Zhang and Wei Li and Ruihan Bao and Keiko Harimoto and Yunfang Wu and Xu Sun},
  doi          = {10.1016/j.neucom.2022.12.013},
  journal      = {Neurocomputing},
  pages        = {11-23},
  shortjournal = {Neurocomputing},
  title        = {ASAT: Adaptively scaled adversarial training in time series},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kernel reconstruction learning. <em>NEUCOM</em>,
<em>522</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a class of kernel interpolation-based methods, called kernel reconstruction learning, for solving machine learning problems. Kernel reconstruction learning uses kernel interpolators to reconstruct the unknown functions, which are needed to estimate in the problem, with estimated function values at selected knots. It can be applied to any learning problem that involves function estimation. We prove a reconstruction representer theorem, which indicates that conventional kernel methods, including kernel ridge regression, kernel support vector machine, and kernel logistic regression , can be viewed as special cases of kernel reconstruction learning. Furthermore, kernel reconstruction learning provides new algorithms for large datasets. The kernel reconstruction vector machine, kernel reconstruction logistic regression, and kernel reconstruction density estimation are discussed in detail. With appropriate implementations, they are shown to have higher prediction/estimation accuracy and/or less computational cost than popular kernel methods.},
  archive      = {J_NEUCOM},
  author       = {Yun Wu and Shifeng Xiong},
  doi          = {10.1016/j.neucom.2022.12.015},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Kernel reconstruction learning},
  volume       = {522},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep mutual learning for brain tumor segmentation with the
fusion network. <em>NEUCOM</em>, <em>521</em>, 213–220. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have been successfully applied to Brain tumor segmentation. However, the extreme data imbalance exists in the different sub-regions of tumor, results in training the deep learning methods on these data will reduce the accuracy of segmentation. We introduce the deep mutual learning strategy to address the challenges, the proposed integrates transformer layers in both encoder and decoder of a U-Net architecture. In the network, using the prediction of up-sampled layer is to deep supervise the training process for enlarging the receptive field to extract features, the feature map of the shallowest layer supervises the subsequent feature map of layers to keep more edge information to guide the sub-region segmentation accuracy . the classification logits of the deepest layer supervise the previous layer of logits to get more semantic information for distinguish of tumor sub-regions. Furthermore, the feature map and the classification logits supervise mutually to improve the overall segmentation accuracy. The experimental results on benchmark dataset shows that our method has significant performance gain over existing methods.},
  archive      = {J_NEUCOM},
  author       = {Huan Gao and Qiguang Miao and Daikai Ma and Ruyi Liu},
  doi          = {10.1016/j.neucom.2022.11.038},
  journal      = {Neurocomputing},
  pages        = {213-220},
  shortjournal = {Neurocomputing},
  title        = {Deep mutual learning for brain tumor segmentation with the fusion network},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GEnI: A framework for the generation of explanations and
insights of knowledge graph embedding predictions. <em>NEUCOM</em>,
<em>521</em>, 199–212. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) are among the most commonly used knowledge representation paradigms, being at the core of tasks such as question answering or recommendation systems. Knowledge Graph Completion (KGC) is one of the key tasks concerning KGs, where the goal is to extract new elements from the existing information. Different approaches have been proposed through the years to tackle this challenge. Among them, two analogous categories can be distinguished: rule-learning and Knowledge Graph Embeddings (KGE). Different methods have been subsequently proposed to unify both types under a single framework, such that the benefits of both proposals can be exploited. However, most of these methods consider using rule-learning models as a boosting agent for KGE models, but not as an explainability tool. This work presents GEnI 1 , a framework capable of generating insights and explanations for KGE models. GEnI follows a three-phase sequential process, generating a feasible explanation for a given prediction. Possible outcomes are rules, correlations, and influence detection. Moreover, the output is expressed in natural language to further extend the explainability of the proposal. GEnI has been successfully evaluated under three criteria: coherence, the meaningfulness of the output, and reliability. Moreover, it can be used by both translational and bilinear KGE models, offering broad coverage. Furthermore, this work also presents an in-depth review of existing integrative approaches between rule-learning and embedding models, providing a comparative framework between them.},
  archive      = {J_NEUCOM},
  author       = {Elvira Amador-Domínguez and Emilio Serrano and Daniel Manrique},
  doi          = {10.1016/j.neucom.2022.12.010},
  journal      = {Neurocomputing},
  pages        = {199-212},
  shortjournal = {Neurocomputing},
  title        = {GEnI: A framework for the generation of explanations and insights of knowledge graph embedding predictions},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stability of quaternion-valued neutral-type neural networks
with leakage delay and proportional delays. <em>NEUCOM</em>,
<em>521</em>, 191–198. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the stability issue of quaternion-valued neural networks with neutral delay, proportional delay and leakage delay. Taking use of the principle of homeomorphism, techniques of matrix inequality and Lyapunov stability theory , a main stability criterion is derived in the form of quaternion-valued linear matrix inequality for ensuring the unique existence and global stability of the equilibrium point for the considered quaternion-valued neural networks . An illustrative example and its simulations are given to show the effectiveness of the theoretical result.},
  archive      = {J_NEUCOM},
  author       = {Qiankun Song and Linji Yang and Yurong Liu and Fuad E. Alsaadi},
  doi          = {10.1016/j.neucom.2022.12.009},
  journal      = {Neurocomputing},
  pages        = {191-198},
  shortjournal = {Neurocomputing},
  title        = {Stability of quaternion-valued neutral-type neural networks with leakage delay and proportional delays},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Deep neural networks with cloud computing.
<em>NEUCOM</em>, <em>521</em>, 189–190. (<a
href="https://doi.org/10.1016/j.neucom.2022.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Kit Yan Chan ( Special issue guest editors: ) and Bilal Abu-Salih and Khan Muhammad and Vasile Palade and Rifai Chai},
  doi          = {10.1016/j.neucom.2022.12.001},
  journal      = {Neurocomputing},
  pages        = {189-190},
  shortjournal = {Neurocomputing},
  title        = {Editorial: Deep neural networks with cloud computing},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weight matrix as a switch between line attractor and plane
attractor of ring neural networks. <em>NEUCOM</em>, <em>521</em>,
181–188. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous attractor refers to a kind of low-dimensional manifold, which is embedded in high-dimensional state space. The line attractor is one-dimensional continuous attractor, while the two-dimensional continuous attractor is called plane attractor. The weight matrix and the external input play the key role for the expression of the continuous attractor. In this paper, some conditions for the parameter selection to achieve line attractor and plane attractor are given. we see that even a pretty small perturbation of the parameter may heavily affect the type and shape of the continuous attractor. The parameter selection scheme is crucial for designing the neural network model.},
  archive      = {J_NEUCOM},
  author       = {Jiali Yu and Wenshuang Chen and Jinsong Leng and Chunxiao Wang and Zhang Yi},
  doi          = {10.1016/j.neucom.2022.11.069},
  journal      = {Neurocomputing},
  pages        = {181-188},
  shortjournal = {Neurocomputing},
  title        = {Weight matrix as a switch between line attractor and plane attractor of ring neural networks},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The context effect for blind image quality assessment.
<em>NEUCOM</em>, <em>521</em>, 172–180. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image quality assessment (IQA) is a process of visuo-cognitive, which is an essential stage in human interaction with the environment. The study of the context effect (Brown and Daniel, 1987) also shows that the evaluation results made by the human vision system (HVS) is related to the contrast between the distorted image and the background environment. However, the existing IQA methods carry out the quality evaluation that only depends on the distorted image itself and ignores the impact of environment to human perception. In this paper, we propose a novel blind image quality assessment(BIQA) based on the context effect. At first, we use a graphical model to describe how the context effect influences human perception of image quality. Based on the established graph, we construct the context relation between the distorted image and the background environment by the X. Han et al. (2015). Then the context features are extracted from the constructed relation, and the quality-related features are extracted by the fine-tuned neural network from the distorted image in pixel-wise. Finally, these features are concatenated to quantify image quality degradations and then regress to quality scores. In addition, the proposed method is adaptive to various deep neural networks. Experimental results show that the proposed method not only has the state-of-art performance on the synthetic distorted images, but also has a great improvement on the authentic distorted images.},
  archive      = {J_NEUCOM},
  author       = {Zehong Liang and Wen Lu and Yong Zheng and Weiquan He and Jiachen Yang},
  doi          = {10.1016/j.neucom.2022.11.026},
  journal      = {Neurocomputing},
  pages        = {172-180},
  shortjournal = {Neurocomputing},
  title        = {The context effect for blind image quality assessment},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A neural harmonic-aware network with gated attentive fusion
for singing melody extraction. <em>NEUCOM</em>, <em>521</em>, 160–171.
(<a href="https://doi.org/10.1016/j.neucom.2022.11.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Singing melody extraction from polyphonic musical audio is one of the most challenging tasks in music information retrieval (MIR). Recently, data-driven methods based on convolutional neural networks (CNNs) have achieved great success for this task. In the literature, harmonic relationship has been proven crucial for this task. However, few existing CNN-based singing melody extraction methods consider the harmonic relationship in the training stage. The state-of-the-art CNN based methods are not capable of capturing such long-dependency harmonic relationship due to limited receptive field and unacceptable computation cost. In this paper, we introduce a neural harmonic-aware network with gated attentive fusion (NHAN-GAF) for singing melody extraction. Specifically, in the 2-D spectrograms modeling branch, we propose to employ multiple parallel 1-D CNN kernels to capture the harmonic relations between 1–2 octaves along the frequency axis in the spectrogram. Considering the advantage of jointly using Time–Frequency (T-F) domain and time domain information, we use two-branch neural nets to learn discriminative representation for this task. A novel gated attentive fusion (GAF) network is suggested to encode potential correlations between the two branches and fuse the descriptors learned from raw waveform and T-F spectrograms. Moreover, the idea of GAF can be exploited to the multimedia applications with multimodal analysis. With the two proposed components, our proposed model is capable of learning the harmonic relationship in the spectrogram and better capturing the contextual but discriminative features for singing melody extraction. We use part of the vocal tracks of the RWC dataset and MIR-1 K dataset to train the model and evaluate the performance of the proposed model on the ADC 2004, MIREX 05 and MedleyDB datasets. The experimental results show that the proposed method outperforms the state-of-the-art ones.},
  archive      = {J_NEUCOM},
  author       = {Shuai Yu and Yi Yu and Xiaoheng Sun and Wei Li},
  doi          = {10.1016/j.neucom.2022.11.086},
  journal      = {Neurocomputing},
  pages        = {160-171},
  shortjournal = {Neurocomputing},
  title        = {A neural harmonic-aware network with gated attentive fusion for singing melody extraction},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A trajectory and force dual-incremental robot skill learning
and generalization framework using improved dynamical movement
primitives and adaptive neural network control. <em>NEUCOM</em>,
<em>521</em>, 146–159. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to changes in the environment and errors that occurred during skill initialization, the robot&#39;s operational skills should be modified to adapt to new tasks. As such, skills learned by the methods with fixed features, such as the classical Dynamical Movement Primitive (DMP), are difficult to use when the using cases are significantly different from the demonstrations. In this work, we propose an incremental robot skill learning and generalization framework including an incremental DMP (IDMP) for robot trajectory learning and an adaptive neural network (NN) control method , which are incrementally updated to enable robots to adapt to new cases. IDMP uses multi-mapping feature vectors to rebuild the forcing function of DMP, which are extended based on the original feature vector. In order to maintain the original skills and represent skill changes in a new task, the new feature vector consists of three parts with different usages. Therefore, the trajectories are gradually changed by expanding the feature and weight vectors, and all transition states are also easily recovered. Then, an adaptive NN controller with performance constraints is proposed to compensate dynamics errors and changed trajectories after using the IDMP. The new controller is also incrementally updated and can accumulate and reuse the learned knowledge to improve the learning efficiency. Compared with other methods, the proposed framework achieves higher tracking accuracy, realizes incremental skill learning and modification, achieves multiple stylistic skills, and is used for obstacle avoidance with different heights, which are verified in three comparative experiments.},
  archive      = {J_NEUCOM},
  author       = {Zhenyu Lu and Ning Wang and Qinchuan Li and Chenguang Yang},
  doi          = {10.1016/j.neucom.2022.11.076},
  journal      = {Neurocomputing},
  pages        = {146-159},
  shortjournal = {Neurocomputing},
  title        = {A trajectory and force dual-incremental robot skill learning and generalization framework using improved dynamical movement primitives and adaptive neural network control},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Persistent coverage of UAVs based on deep reinforcement
learning with wonderful life utility. <em>NEUCOM</em>, <em>521</em>,
137–145. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization problem of persistent coverage for a target region by using unmanned aerial vehicles (UAVs) is addressed in this study. A deep reinforcement learning algorithm (DRL) based on bidirectional recurrent neural networks (BRNN) is proposed to obtain the optimal control output policy of UAVs which manipulate the UAVs to periodically cover the whole target region and to minimize the maximum age of cells. The UAVs coordinate autonomously by using wonderful life utility (WLU) functions and BRNN. Because all control policies share parameters, the algorithm has strong robustness and scalability which enable individual UAV to freely join or leave the task without affecting the operation of the entire system. The algorithm uses consistent outputs to control multiple heterogeneous UAVs. Simulation results are given to illustrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zhaomei Sun and Nan Wang and Hong Lin and Xiaojun Zhou},
  doi          = {10.1016/j.neucom.2022.11.091},
  journal      = {Neurocomputing},
  pages        = {137-145},
  shortjournal = {Neurocomputing},
  title        = {Persistent coverage of UAVs based on deep reinforcement learning with wonderful life utility},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Problexity—an open-source python library for supervised
learning problem complexity assessment. <em>NEUCOM</em>, <em>521</em>,
126–136. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem’s complexity assessment is an essential element of many topics in the supervised learning domain. It plays a significant role in meta-learning – becoming the basis for determining meta-attributes or multi-criteria optimization – allowing the evaluation of the training set resampling without needing to rebuild the recognition model. The tools currently available for the academic community, which would enable the calculation of problem complexity measures, are available only as libraries of the C++ and R languages. This paper describes the software module that allows for the estimation of 22 classification complexity measures and 12 regression complexity measures for the Python language – compatible with the scikit-learn programming interface – allowing for the implementation of research using them in the most popular programming environment of the machine learning community.},
  archive      = {J_NEUCOM},
  author       = {Joanna Komorniczak and Paweł Ksieniewicz},
  doi          = {10.1016/j.neucom.2022.11.056},
  journal      = {Neurocomputing},
  pages        = {126-136},
  shortjournal = {Neurocomputing},
  title        = {Problexity—An open-source python library for supervised learning problem complexity assessment},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Differential privacy preservation for graph auto-encoders:
A novel anonymous graph publishing model. <em>NEUCOM</em>, <em>521</em>,
113–125. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the number of users in social networks has grown substantially, and more data-intensive applications have been developed. This creates a demand for the ability to mine large-scale graph data more efficiently, so that the information mined can be maximized (e.g., mining social relationships between people). However, the direct publication of the original graphs leads to potential leakage of users’ privacy. Therefore, graph anonymization techniques are often utilized to process the original graphs. A key challenge of it lies in the balance between anonymity and usability. In this paper, we introduced the idea of graph auto-encoder, a fundamental element in graph neural networks , and proposed the Differential Privacy Deep Graph Auto-Encoder (DP-DGAE). Our main idea is to convert the anonymous graph publishing problem into a privacy-preserving problem for generative models , and optimize the models in terms of both privacy and usability using a multi-task learning approach. Theoretical analysis and experimental evaluations show that the DP-DGAE achieves anonymity while ensuring usability.},
  archive      = {J_NEUCOM},
  author       = {Xiaolin Li and Li Xu and Hongyan Zhang and Qikui Xu},
  doi          = {10.1016/j.neucom.2022.11.083},
  journal      = {Neurocomputing},
  pages        = {113-125},
  shortjournal = {Neurocomputing},
  title        = {Differential privacy preservation for graph auto-encoders: A novel anonymous graph publishing model},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stable and efficient resource management using deep neural
network on cloud computing. <em>NEUCOM</em>, <em>521</em>, 99–112. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource management autoscaling in a cloud computing service guarantees the high availability and extensibility of applications and services. Horizontal pod autoscaling (HPA) does not affect the executed tasks but also has the disadvantage that it cannot provide immediate scaling. Furthermore, scale down is not possible if excess resources are allocated, because it is difficult to identify the amount of resources required for applications and services; thus resources are wasted. Therefore, this study proposes Proactive Hybrid Pod Autoscaling (ProHPA), which immediately responds to irregular workloads and reduces resource overallocation. ProHPA uses a bidirectional long short-term memory (Bi-LSTM) model applied with an attention mechanism for forecasting future CPU and memory usage that has similar or different patterns. Reducing excessive resource usage with vertical pod autoscaling (ReVPA) adjusts the overallocation of resources within a pod by forecasted resource usage. Lastly, prevention overload with HPA (PoHPA) immediately performs resource scaling by using forecasted resource usage and pod information. When the performance of ProHPA was evaluated, CPU and memory average utilization were improved by 23.39\% and 42.52\%, respectively, compared with conventional HPA when initial resources were overallocated. In addition, ProHPA did not exhibit overload compared to conventional HPA when resources are insufficiently allocated.},
  archive      = {J_NEUCOM},
  author       = {Byeonghui Jeong and Seungyeon Baek and Sihyun Park and Jueun Jeon and Young-Sik Jeong},
  doi          = {10.1016/j.neucom.2022.11.089},
  journal      = {Neurocomputing},
  pages        = {99-112},
  shortjournal = {Neurocomputing},
  title        = {Stable and efficient resource management using deep neural network on cloud computing},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Max–min robust principal component analysis.
<em>NEUCOM</em>, <em>521</em>, 89–98. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Principal Component Analysis (PCA) is a powerful unsupervised dimensionality reduction algorithm , which uses squared ℓ 2 ℓ2 -norm to cleverly connect reconstruction error and projection variance, and those improved PCA methods only consider one of them, which limits their performance. To alleviate this problem, we propose a novel Max–Min Robust Principal Component Analysis via binary weight, which ingeniously combines reconstruction error and projection variance to learn projection matrix more accurately, and uses ℓ 2 ℓ2 -norm as evaluation criterion to make the model rotation invariant . In addition, we design binary weight to remove outliers to improve the robustness of model and obtain the ability of anomaly detection . Subsequently, we exploit an efficient iterative optimization algorithm to solve this problem. Extensive experimental results show that our model outperforms related state-of-the-art PCA methods.},
  archive      = {J_NEUCOM},
  author       = {Sisi Wang and Feiping Nie and Zheng Wang and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.11.092},
  journal      = {Neurocomputing},
  pages        = {89-98},
  shortjournal = {Neurocomputing},
  title        = {Max–Min robust principal component analysis},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural-network-based backstepping control for the
post-capture tethered space combination using HDO. <em>NEUCOM</em>,
<em>521</em>, 79–88. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel neural-network-based backstepping control method is designed for the post-capture tethered space combination system subjected to multi-source disturbances and actuator saturation. To cope with the multi-source disturbances, the so-called HDO is put forward which is capable of addressing both modeled and unmodeled disturbances. These disturbances are not necessarily matched disturbances and hence the backstepping design procedure is utilized. In virtue of the radial basis function neural networks (RBFNNs), the unknown nonlinearities is estimated. Additionally, the anti-windup technique is employed to handle the actuator saturation phenomenon which is unavoidable in the post-capture tethered space combination system. Sufficient conditions are derived to guarantee that the post-capture tethered space combination system is stabilized while carrying out the non-cooperative target capture mission. Finally, a number of numerical simulations are conducted on the post-capture tethered space combination to validate the proposed methodology.},
  archive      = {J_NEUCOM},
  author       = {Qinyi Wang and Yang Yu and Fan Zhang and Panfeng Huang},
  doi          = {10.1016/j.neucom.2022.11.080},
  journal      = {Neurocomputing},
  pages        = {79-88},
  shortjournal = {Neurocomputing},
  title        = {Neural-network-based backstepping control for the post-capture tethered space combination using HDO},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Context-driven pyramid registration network for estimating
large topology-preserved deformation. <em>NEUCOM</em>, <em>521</em>,
65–78. (<a href="https://doi.org/10.1016/j.neucom.2022.11.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based deformable image registration methods have become attractive alternatives to traditional methods because of their great performance and fast run time. However, it is still challenging for these methods to estimate large topology-preserved deformation, and the contextual information that is important for large deformation is also under-mined. To address these issues, we propose a novel unsupervised context-driven pyramid registration network for estimating large topology-preserved deformation named CPRNet. Specifically, based on the multi-resolution feature pyramids, we first design multi-receptive-field guidance modules, aiming at exploiting the multi-scale spatial correlation between features of two pyramids. Then we devise multi-view context fusion modules to dynamically fuse deep contextual information containing high-level semantic information from different views of feature maps. Further, we develop a residual estimation strategy to estimate the deformation in a coarse-to-fine manner. Moreover, a deformation field regularization module is proposed to address the challenge of balancing the registration performance and topology preservation. The experiments both on liver computed tomography (CT) images and brain magnetic resonance (MR) images demonstrate that our proposed method provides effective and accurate registration on various datasets with a fast run time. Compared with existing learning-based registration methods, our proposed method exceeds the performance in most trials while maintaining desirable topology preservation capability and can potentially fit various image registration tasks.},
  archive      = {J_NEUCOM},
  author       = {Peng Wang and Yunqi Yan and Lijun Qian and Shiteng Suo and Jianrong Xu and Yi Guo and Yuanyuan Wang},
  doi          = {10.1016/j.neucom.2022.11.088},
  journal      = {Neurocomputing},
  pages        = {65-78},
  shortjournal = {Neurocomputing},
  title        = {Context-driven pyramid registration network for estimating large topology-preserved deformation},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimum spanning tree brain network topology reflects
individual differences in the structure of affective experience.
<em>NEUCOM</em>, <em>521</em>, 56–64. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subjective feelings of emotion differ in the extent to which some might focus on pleasure or displeasure and some might emphasize their arousal in the reports of emotional experience. In this paper, we examine whether functional brain connectivity is modulated by individual differences in the subjective feelings of emotion. We adopt the public available DEAP dataset and utilize the unsupervised clustering method to delineate reports of emotional valence and arousal profiles in the data. Results provide evidence of two subgroups: one group consistently rates high in arousal and low in valence regarding the emotional stimulus, whereas the other group rates high in valence and low in arousal. The two groups further differ in their minimum spanning tree characteristics derived from EEG signals. Specifically, people more emphasize valence experience recruit broadly distributed brain areas than those who focus on arousal. Together, these findings provide new insights to understand individual differences in emotional experience and suggest the distinct underlying neural processing mechanisms.},
  archive      = {J_NEUCOM},
  author       = {Hanjie Liu and Jinde Cao and Jinren Zhang and Minvydas Ragulskis},
  doi          = {10.1016/j.neucom.2022.11.095},
  journal      = {Neurocomputing},
  pages        = {56-64},
  shortjournal = {Neurocomputing},
  title        = {Minimum spanning tree brain network topology reflects individual differences in the structure of affective experience},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based global and local spatial-temporal graph
convolutional network for vehicle emission prediction. <em>NEUCOM</em>,
<em>521</em>, 41–55. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays the number of vehicles is increasing day by day and vehicle emission becomes a major pollution source. To wisely control vehicle emission, accurate vehicle emission prediction is of critical importance. However, accurate vehicle emission prediction suffers from many challenges, such as the strong nonlinearity of emission data and the temporal correlation and spatial interaction between different road segments, which become more complicated for mid- and long-term prediction. To resolve these challenging issues, we propose an attention-based global and local spatial-temporal graph convolutional network (AGLGCN) to effectively predict mid- and long-term vehicle emission through a graph structural network. The proposed AGLGCN consists of two major parts: 1) a spatial-temporal attention mechanism to effectively capture the dynamic spatial-temporal correlation of vehicle emission data by merging hourly, daily, and weekly sequences, 2) a global and local spatial graph convolution network to capture the hidden global and local spatial dependencies based on graph convolution. AGLGCN can capture the dynamic temporal correlation as well as the global and local spatial information variation of vehicle emission, and effectively predict mid- and long-term time series. Two real-world vehicle emission datasets are taken to evaluate AGLGCN. Experimental results demonstrate that our proposed AGLGCN can outperform some state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xihong Fei and Qiang Ling},
  doi          = {10.1016/j.neucom.2022.11.085},
  journal      = {Neurocomputing},
  pages        = {41-55},
  shortjournal = {Neurocomputing},
  title        = {Attention-based global and local spatial-temporal graph convolutional network for vehicle emission prediction},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). BFMNet: Bilateral feature fusion network with multi-scale
context aggregation for real-time semantic segmentation.
<em>NEUCOM</em>, <em>521</em>, 27–40. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key technology for scene understanding, real-time semantic segmentation is an important topic in the field of computer vision in recent years. However, some lightweight networks designed for real-time semantic segmentation only have limited receptive field, so they cannot effectively perceive multi-scale objects in images. In addition, although the fast downsampling feature extraction network reduces the amount of computation, it has the problem of loss of detailed information, resulting in poor prediction accuracy. In this paper, we propose an efficient lightweight semantic segmentation network called BFMNet to address these issues. First, we use a lightweight bilateral structure to encode the semantic and detailed information from images respectively and introduce feature interactions during the encoding process. Furthermore, we design a novel Multi-Scale Context Aggregation Module (MSCAM) to help the network perceive the information of multi-scale objects, which is crucial for semantic segmentation. Finally, we introduce a new fusion module (AEFM) that uses attention perception to facilitate bilateral feature fusion . Our network achieves competitive results on three popular semantic segmentation benchmarks: Cityscapes, CamVid and COCO-Stuff. Specifically, on a single 2080Ti GPU, our network yields 77.7\%\% mIoU at 63.7 FPS on Cityscapes test set with the input resolution of 768 × 1536 768×1536 . Considering the speed-accuracy trade-off, we also report the results with 1024 × 2048 1024×2048 input resolution: 78.9\%\% mIoU at 31.4 FPS. On the Camvid test set, our network achieves 75.6\%\% mIoU at 95.8 FPS, while on the COCO-Stuff validation set, our network achieves 31.2\%\% mIoU.},
  archive      = {J_NEUCOM},
  author       = {Jin Liu and Fangyu Zhang and Ziyin Zhou and Jiajun Wang},
  doi          = {10.1016/j.neucom.2022.11.084},
  journal      = {Neurocomputing},
  pages        = {27-40},
  shortjournal = {Neurocomputing},
  title        = {BFMNet: Bilateral feature fusion network with multi-scale context aggregation for real-time semantic segmentation},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Objects matter: Learning object relation graph for robust
absolute pose regression. <em>NEUCOM</em>, <em>521</em>, 11–26. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual relocalization aims to estimate the pose of a camera from one or more images. In recent years deep learning-based absolute pose regression (APR) methods have attracted many attentions. They feature predicting the absolute poses without relying on any prior built maps or stored images, making the relocalization very efficient. However, robust relocalization under environments with complex appearance changes and real dynamics remains very challenging. In this paper, we propose to enhance the distinctiveness of the image features by extracting the deep relationship among objects. In particular, we extract objects in the image and construct a deep object relation graph (ORG) to incorporate the semantic connections and relative spatial clues of the objects. We integrate our ORG module into several popular APR models. Extensive experiments on various public indoor and outdoor datasets demonstrate that our ORG module greatly enhances the robustness of image representation to environmental changes and improves the pose regression performance. The code is available at https://github.com/qcyay/ORGMapNet .},
  archive      = {J_NEUCOM},
  author       = {Chengyu Qiao and Zhiyu Xiang and Xinglu Wang and Shuya Chen and Yuangang Fan and Xijun Zhao},
  doi          = {10.1016/j.neucom.2022.11.090},
  journal      = {Neurocomputing},
  pages        = {11-26},
  shortjournal = {Neurocomputing},
  title        = {Objects matter: Learning object relation graph for robust absolute pose regression},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A general framework for quantifying aleatoric and epistemic
uncertainty in graph neural networks. <em>NEUCOM</em>, <em>521</em>,
1–10. (<a href="https://doi.org/10.1016/j.neucom.2022.11.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNN) provide a powerful framework that elegantly integrates Graph theory with Machine learning for modeling and analysis of networked data. We consider the problem of quantifying the uncertainty in predictions of GNN stemming from modeling errors and measurement uncertainty. We consider aleatoric uncertainty in the form of probabilistic links and noise in feature vector of nodes, while epistemic uncertainty is incorporated via a probability distribution over the model parameters. We propose a unified approach to treat both sources of uncertainty in a Bayesian framework , where Assumed Density Filtering is used to quantify aleatoric uncertainty and Monte Carlo dropout captures uncertainty in model parameters. Finally, the two sources of uncertainty are aggregated to estimate the total uncertainty in predictions of a GNN. Results in the real-world datasets demonstrate that the Bayesian model performs at par with a frequentist model and provides additional information about predictions uncertainty that are sensitive to uncertainties in the data and model.},
  archive      = {J_NEUCOM},
  author       = {Sai Munikoti and Deepesh Agarwal and Laya Das and Balasubramaniam Natarajan},
  doi          = {10.1016/j.neucom.2022.11.049},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {A general framework for quantifying aleatoric and epistemic uncertainty in graph neural networks},
  volume       = {521},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive fixed-time quantized fault-tolerant attitude
control for hypersonic reentry vehicle. <em>NEUCOM</em>, <em>520</em>,
386–399. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the adaptive fixed-time quantized fault-tolerant attitude tracking problem for hypersonic reentry vehicle (HRV). Due to the strong nonlinearity, tight coupling, uncertain characteristics and potential actuator faults , the attitude control of HRV poses a considerable challenge. By resorting to feedback linearization technique, the inherently nonlinear attitude model of HRV is decoupled into a linear control-oriented model, where the actuator malfunction, quantization nonlinearities and multiple disturbances are incorporated into the lumped disturbance. Then a fixed-time neural network disturbance observer is designed to estimate the lumped disturbance, with the practical fixed-time stability of the observation error ensured independent of initial conditions. Subsequently, by using a hyperbolic-tangent-like function, a novel paradigm is proposed for achieving adaptive fixed-time convergence and based on the paradigm, an adaptive fixed-time nonsingular sliding mode controller is proposed. The main features of the controller include: 1) The controller gain is adjusted adaptively following the current magnitude of the output variable to obtain high transient performance. 2) The tracking error can converge to zero within a fixed time even in the case of actuator faults and signal quantization. 3) A hysteretic quantizer is implemented in the attitude control loop such that the on-board communication load can be significantly reduced. Moreover, the proposed fault-tolerant control scheme design is non-recursive, rendering the controller structure simple. Ultimately, the effectiveness of the proposed method is demonstrated by numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Jixing Lv and Changhong Wang and Yonggui Kao},
  doi          = {10.1016/j.neucom.2022.11.057},
  journal      = {Neurocomputing},
  pages        = {386-399},
  shortjournal = {Neurocomputing},
  title        = {Adaptive fixed-time quantized fault-tolerant attitude control for hypersonic reentry vehicle},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MIGT: Multi-modal image inpainting guided with text.
<em>NEUCOM</em>, <em>520</em>, 376–385. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose MIGT, a novel framework for multi-modal image inpainting that introduces textual description as guidance. We divide MIGT into three components: Coarse-to-Fine Image Inpainting Module (CFIM), Visual-Textual modalities Fusion Module (VTFM), and Multi-modal Semantic Alignment Module (MSAM). CFIM is a Unet-based inpainting model in a coarse-to-fine manner. The coarse inpainting stage produces images of rough shape and color according to the source corrupted images and the corresponding textual descriptions. The fine inpainting stage generates the final high-quality images with fine-grained textures. VTFM aims to reasonably fuse visual-textual modalities. First, we feed visual and textual features into the proposed visual-aware textual filtering mechanism to adaptively focus on desired words related to the missing areas. Then the filtered visual-aware textual features pass through an Attentional Generative Network (AGN) to obtain fusion features that are fed into the middle layers of the coarse stage for subsequent image inpainting . MSAM takes the generated image as input, reconstructing a textual description that semantically aligns the given one to guarantee the semantic consistency between the generated image and the input textual description. Extension experiments conducted on Oxford-102 flower and CUB-200–2011 bird datasets demonstrate the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Ailin Li and Lei Zhao and Zhiwen Zuo and Zhizhong Wang and Wei Xing and Dongming Lu},
  doi          = {10.1016/j.neucom.2022.11.074},
  journal      = {Neurocomputing},
  pages        = {376-385},
  shortjournal = {Neurocomputing},
  title        = {MIGT: Multi-modal image inpainting guided with text},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A nonconvex function activated noise-tolerant neurodynamic
model aided with fischer-burmeister function for time-varying quadratic
programming in the presence of noises. <em>NEUCOM</em>, <em>520</em>,
365–375. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying quadratic programming problems (TVQPPs) with equality and inequality constraints often arise in the fields of scientific computation and engineering application. Zeroing neural network (ZNN), being a special kind of recurrent neural network, has shown powerful capabilities to compute a variety of zeroing finding problems with monotonically increasing odd activation function . However, the projection sets of nonconvex activation function are obviously excluded, which means a general conclusion remain unexplored. In addition, noises are always ubiquitous in actual applications. Nevertheless, most existing ZNN-based models usually assume that the solving process is free of noise before the calculation. In this paper, a general zeroing neural network model with nonconvex activated function (GZNNM-NAF) and a general noise-tolerant zeroing neural network model with nonconvex activated function (GNTZNNM-NAF), which are also viewed as ZNN-type models, are developed by the inspiration of the traditional ZNN model from a control-based perspective. The ZNN-type models break the limitation of the traditional ZNN models of activation function, which allows nonconvex sets for projection operations and combines nonlinear complementary function for dealing with inequality constraints arising in TVQPPs. Moreover, theoretical results indicate that the ZNN-type models globally converge to time-varying optimal solution of TVQPPs with equality and inequality constraints under the noise circumstance. According to the different cases of nonconvex activation function, robustness analyses are demonstrated in detail for TVQPPs. It may enlarge the scope of the proposed method, especially in the field of practical application. Finally, a numerical example and an application example to manipulator motion generation are analyzed to verify the superiority and robustness of the developed ZNN-type models for TVQPPs with different measurement noises.},
  archive      = {J_NEUCOM},
  author       = {Yingyi Sun and Jianmin Cao and Zhongbo Sun and Shijun Tang},
  doi          = {10.1016/j.neucom.2022.11.067},
  journal      = {Neurocomputing},
  pages        = {365-375},
  shortjournal = {Neurocomputing},
  title        = {A nonconvex function activated noise-tolerant neurodynamic model aided with fischer-burmeister function for time-varying quadratic programming in the presence of noises},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ReNAP: Relation network with adaptiveprototypical learning
for few-shot classification. <em>NEUCOM</em>, <em>520</em>, 356–364. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional deep learning-based image classification methods often fail to recognize a new class that does not exist in the training dataset, particularly when the new class only has a small number of samples. Such a challenging and new learning problem is referred to as few-shot learning. In few-shot learning, the relation network (RelationNet) is a powerful method. However, in RelationNet and its state-of-the-art variants, the prototype of each class is obtained by a simple summation or average over the labeled samples. These simple sample statistics cannot accurately capture the distinct characteristics of the diverse classes of real-world images. To address this problem, in this paper, we propose the Relation Network with Adaptive Prototypical Learning method (ReNAP), which can learn the class prototypes adaptively and provide more accurate representations of the classes. More specifically, ReNAP embeds an adaptive prototypical learning module constructed by a convolutional network into RelationNet. Our ReNAP achieves superior classification performances to RelationNet and other state-of-the-art methods on four widely used benchmark datasets, FC100, CUB-200-2011, Stanford-Cars, and Stanford-Dogs.},
  archive      = {J_NEUCOM},
  author       = {Xiaoxu Li and Yalan Li and Yixiao Zheng and Rui Zhu and Zhanyu Ma and Jing-Hao Xue and Jie Cao},
  doi          = {10.1016/j.neucom.2022.11.082},
  journal      = {Neurocomputing},
  pages        = {356-364},
  shortjournal = {Neurocomputing},
  title        = {ReNAP: Relation network with adaptiveprototypical learning for few-shot classification},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformers and CNNs fusion network for salient object
detection. <em>NEUCOM</em>, <em>520</em>, 342–355. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Salient Object Detection (SOD) has achieved promising results thanks to the rapid evolution of CNN architectures. However, those CNN-based methods show limited capacity in modeling long-range interaction among pixels. In this paper, we propose to combine the merits from CNN and Transformer and design a unified model for RGB and RGB-D SOD. First, we represent the image with a sequence-to-sequence perspective and use a Transformer-based branch to express long-distance relationships of image tokens to obtain global semantic information and predict a coarse saliency map. Second, we employ a CNN-based branch to extract multi-scale local detail features to predict contour prediction for auxiliary supervision at each level. Finally, we propose the Bi-enhancement Fusion Module to fuse multi-scale cues from two branches to predict a more accurate saliency map. In addition, for RGB-D SOD, to obtain effective cross-modality features, we propose a Cross-modality Multi-Scale Transformer Module and a Depth-induced Enhancement Module to fuse RGB and depth cues in the Transformers branch and the CNNs branch, respectively. Experiments on both RGB and RGB-D SOD datasets demonstrate that our proposed model achieves satisfactory performance compared with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Cuili Yao and Lin Feng and Yuqiu Kong and Lin Xiao and Tao Chen},
  doi          = {10.1016/j.neucom.2022.10.081},
  journal      = {Neurocomputing},
  pages        = {342-355},
  shortjournal = {Neurocomputing},
  title        = {Transformers and CNNs fusion network for salient object detection},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A class of augmented complex-value FLANN adaptive algorithms
for nonlinear systems. <em>NEUCOM</em>, <em>520</em>, 331–341. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, few studies have been made on the stereophonic acoustic echo cancellation (SAEC) with nonlinear systems . To identify such nonlinear model , the functional link artificial neural network (FLANN) and the widely linear model can provide an approach to explore the SAEC with complex random variable. In this paper, a class of augmented complex-value functional link network (ACFLN) adaptive algorithms is developed. Based on the augmented complex-value functional least-mean-square (ACFLMS) algorithm, we have proposed the recursive augmented complex-value functional least-mean-square (RACFLMS) algorithm designed by a recursive structure . To further reduce its computational complexity and enhance its performance, a novel inverse square root function is employed in its structure of the RACFLMS algorithm. The results of several experiments demonstrate that our approach can effectively model the nonlinear systems and verify the improvement of the proposed algorithms.},
  archive      = {J_NEUCOM},
  author       = {Zheng-Yan Luo and Ji-Liu Zhou and Yi-Fei Pu and Lei Li},
  doi          = {10.1016/j.neucom.2022.11.047},
  journal      = {Neurocomputing},
  pages        = {331-341},
  shortjournal = {Neurocomputing},
  title        = {A class of augmented complex-value FLANN adaptive algorithms for nonlinear systems},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stability of stochastic hopfield neural networks driven by
g-brownian motion with time-varying and distributed delays.
<em>NEUCOM</em>, <em>520</em>, 320–330. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, p th exponential stability and quasi-surely exponential stability of stochastic Hopfield neural networks driven by G -Brownian motion are investigated. Under a sublinear expectation framework, we give several lemmas related to the Halanay inequality and the Burkholder-Davis-Gundy ineqaulity. Our stability results is based on the class of the multidimensional Halanay inequalities, as well as the Burkholder-Davis-Gundy inequalities. The main originality lies in the fact that we consider Knightian uncertainty of the theory model of stochastic Hopfield neural networks . Finally, two numerical examples are presented to illustrate our new theory.},
  archive      = {J_NEUCOM},
  author       = {Fanhong Zhang and Chen Fei and Weiyin Fei},
  doi          = {10.1016/j.neucom.2022.10.065},
  journal      = {Neurocomputing},
  pages        = {320-330},
  shortjournal = {Neurocomputing},
  title        = {Stability of stochastic hopfield neural networks driven by G-brownian motion with time-varying and distributed delays},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proximal boosting: Aggregating weak learners to minimize
non-differentiable losses. <em>NEUCOM</em>, <em>520</em>, 301–319. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient boosting is a prediction method that iteratively combines weak learners to produce a complex and accurate model. From an optimization point of view, the learning procedure of gradient boosting mimics a gradient descent on a functional variable. This paper proposes to build upon the proximal point algorithm, when the empirical risk to minimize is not differentiable, in order to introduce a novel boosting approach, called proximal boosting . It comes with a compagnon algorithm inspired by Grubb and Bagnell (2011) and called residual proximal boosting , which is aimed at better controlling the approximation error. Theoretical convergence is proved for these two procedures under different hypotheses on the empirical risk and advantages of leveraging proximal methods for boosting are illustrated by numerical experiments on simulated and real-world data. In particular, we exhibit a favorable comparison over gradient boosting regarding convergence rate and prediction accuracy.},
  archive      = {J_NEUCOM},
  author       = {Erwan Fouillen and Claire Boyer and Maxime Sangnier},
  doi          = {10.1016/j.neucom.2022.11.065},
  journal      = {Neurocomputing},
  pages        = {301-319},
  shortjournal = {Neurocomputing},
  title        = {Proximal boosting: Aggregating weak learners to minimize non-differentiable losses},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locality preserving triplet discriminative projections for
dimensionality reduction. <em>NEUCOM</em>, <em>520</em>, 284–300. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph embedding framework is widely used for developing dimensionality-reduction algorithms. Many such supervised algorithms construct an intrinsic graph to compact intra-class samples or describe their local structures and build a penalty graph to increase the separability of inter-class samples. However, in the available intrinsic graph construction , manually selecting a set of appropriate neighbors associated with each sample is challenging. In addition, the construction of a penalty graph may seriously impair the intrinsic structures of the samples. Thus, in an attempt to address these issues, this study proposes an algorithm referred to as locality-preserving triplet discriminative projections. The proposed algorithm comprises locality-preserving and discriminative graphs. First, a weighted least-square function is used to calculate the edge weights of the locality-preserving graph. An improvement of the locality-preserving graph constructed in this study is that suitable neighbors are soft-selected. Meanwhile, the triplets of the samples are exploited for discriminative graph construction. Through the separation of the marginal samples and using less focus on samples with good discriminability , this graph enhances the discriminability with less damage to the intrinsic structure. In addition, to further improve the performance of the discriminative graph, a class-relevant margin is added to separate similar classes. The experimental results on four public datasets show that the proposed algorithm outperforms several other dimensionality reduction methods.},
  archive      = {J_NEUCOM},
  author       = {Tingting Su and Dazheng Feng and Haoshuang Hu and Meng Wang and Mohan Chen},
  doi          = {10.1016/j.neucom.2022.11.043},
  journal      = {Neurocomputing},
  pages        = {284-300},
  shortjournal = {Neurocomputing},
  title        = {Locality preserving triplet discriminative projections for dimensionality reduction},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A spatiotemporal correlation deep learning network for
brain penumbra disease. <em>NEUCOM</em>, <em>520</em>, 274–283. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain penumbra is a critical condition that is closely related to stroke. Thus, there is high demand for fast and accurate segmentation of penumbra tissue in magnetic resonance images. However, most convolutional neural networks (CNNs) focus on learning contextual semantic information from two-dimensional imaging slides, ignoring the spatiotemporal correlations among adjacent slides. Here, we propose an encoder-decoder network (ConvLSTM-Net) with a specifically convolutional long short-term memory skip connection to extract the spatiotemporal correlations of features of adjacent slices in a non-linear manner. A mixed loss function is also used to improve the segmentation performance . We test the proposed method on the penumbra segmentation challenge and obtain an average Dice score over 80\%, indicating that its performance is superior to or comparable with that of state-of-the-art segmentation methods . A mixed loss function provides positive support for the stability of model training. In addition, we visualize two representative samples to improve the interpretability of the results of ConvLSTM-Net.},
  archive      = {J_NEUCOM},
  author       = {Liangliang Liu and Pei Zhang and Gongbo Liang and Shufeng Xiong and Jianxin Wang and Guang Zheng},
  doi          = {10.1016/j.neucom.2022.11.041},
  journal      = {Neurocomputing},
  pages        = {274-283},
  shortjournal = {Neurocomputing},
  title        = {A spatiotemporal correlation deep learning network for brain penumbra disease},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Considering three elements of aesthetics: Multi-task
self-supervised feature learning for image style classification.
<em>NEUCOM</em>, <em>520</em>, 262–273. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image style classification is the basis of computational aesthetics, and its role has become increasingly important with the rise of computational aesthetics. Most of the current image style classification methods use supervised learning for model training. These methods require a large number of expensive aesthetic style labels. Unlike existing methods, self-supervised learning can perform feature learning on many current unlabeled style images, thereby alleviating the constraint that current supervised learning methods require a large amount of labeled data. However, the self-supervised learning method also poses the problem that it is difficult to fully characterize the highly subjective aesthetic style characteristics. Therefore, this study proposes a multi-task self-supervised style feature learning algorithm considering the three elements of aesthetics. The three elements of aesthetics include compositional rules, luminance and color. The algorithm designs multiple self-supervised learning tasks from multiple perspectives and proposes a joint learning method for multiple self-supervised learning tasks, so that the model can learn the style features of images more comprehensively than ordinary self-supervised learning methods. The experimental results on three large image style datasets also show that the method proposed in this paper can effectively learn the style features of images and outperform most style feature learning algorithms based on supervised learning in terms of classification results.},
  archive      = {J_NEUCOM},
  author       = {Hua Zhang and Yizhang Luo and Lingjun Zhang and Yifan Wu and Muwei Wang and Zhuonan Shen},
  doi          = {10.1016/j.neucom.2022.10.076},
  journal      = {Neurocomputing},
  pages        = {262-273},
  shortjournal = {Neurocomputing},
  title        = {Considering three elements of aesthetics: Multi-task self-supervised feature learning for image style classification},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online adaptive optimal control algorithm based on
synchronous integral reinforcement learning with explorations.
<em>NEUCOM</em>, <em>520</em>, 250–261. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a novel algorithm, based on synchronous policy iteration, to solve the continuous-time infinite-horizon optimal control problem of input affine system dynamics. The integral reinforcement is measured as an excitation signal to estimate the solution to the Hamilton–Jacobi–Bellman equation. In addition, the proposed method is completely model-free, that is, no a priori knowledge of the system is required. Using the adaptive tuning law, the actor and critic neural networks can simultaneously approximate the optimal value function and policy. The persistence of excitation condition is required to guarantee the convergence of the two networks. Unlike in traditional policy iteration algorithms, the restriction of the initial admissible policy was eliminated using this method. The effectiveness of the proposed algorithm is verified through numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Lei Guo and Han Zhao},
  doi          = {10.1016/j.neucom.2022.11.055},
  journal      = {Neurocomputing},
  pages        = {250-261},
  shortjournal = {Neurocomputing},
  title        = {Online adaptive optimal control algorithm based on synchronous integral reinforcement learning with explorations},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A noise-suppressing discrete-time neural dynamics model for
solving time-dependent multi-linear m-tensor equation. <em>NEUCOM</em>,
<em>520</em>, 240–249. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural dynamics plays an important role in handling various complex problems related to matrices or even tensors, e.g., the multi-linear M M -tensor equation investigated in this paper. However, the existing methods for computing the time-dependent multi-linear M M -tensor equation bear the following weaknesses: 1) all of them are under the short-time invariant hypothesis, thereby generating considerable residual errors for time-dependent ones; 2) most of them are depicted in continuous-time form, which can not be directly implemented in the digital equipment; and 3) all of them only consider the noise-free conditions, lacking robustness over truncation errors and round-off errors widely existing in the digital equipment. This paper remedies these three weaknesses by proposing a noise-suppressing discrete-time neural dynamics (NSDTND) model for the time-dependent multi-linear M M -tensor equation. Additionally, analyses on the convergence and robustness are shown to demonstrate that the proposed NSDTND model is globally convergent and has a superior immunity to noises. Then, numerical experimental verifications and an application to the particle movement are provided to prove the superiority and effectiveness of the proposed NSDTND model for solving time-dependent multi-linear M M -tensor equation with noises considered.},
  archive      = {J_NEUCOM},
  author       = {Mei Liu and Huanmei Wu and Mingsheng Shang},
  doi          = {10.1016/j.neucom.2022.11.071},
  journal      = {Neurocomputing},
  pages        = {240-249},
  shortjournal = {Neurocomputing},
  title        = {A noise-suppressing discrete-time neural dynamics model for solving time-dependent multi-linear M-tensor equation},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). State estimation of complex-valued neural networks with
leakage delay: A dynamic event-triggered approach. <em>NEUCOM</em>,
<em>520</em>, 230–239. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of state estimation is investigated for a class of discrete-time complex-valued neural networks (CVNNs) with both leakage delay and discrete time-varying delays. The signal transmission from output sensors to state estimator is implemented via a shared wireless network with limited communication resources. For the aim of reducing the consumption of limited communication resources, the transmission strategy based on dynamic event-triggering is introduced to determine when the updating of the output measurement should be carried out. By taking use of some properties of Hermitian matrix and constructing an appropriate Lyapunov–Krasovskii functional, a sufficient criterion is derived for ensuring the asymptotical stability of the estimation error system without separating the CVNN to its real-part system and imagination one is derived, which is quite different from those approach used in exiting literature. The gain matrix for estimator is designed by resorting to a set of feasible solutions of linear matrix inequalities (LMIs) with complex-valued variables. A numerical example and its simulation results are given to illustrate the validity of the theoretical result.},
  archive      = {J_NEUCOM},
  author       = {Bing Li and Feiyang Liu and Qiankun Song and Dongpei Zhang and Huanhuan Qiu},
  doi          = {10.1016/j.neucom.2022.11.079},
  journal      = {Neurocomputing},
  pages        = {230-239},
  shortjournal = {Neurocomputing},
  title        = {State estimation of complex-valued neural networks with leakage delay: A dynamic event-triggered approach},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ENSO analysis and prediction using deep learning: A review.
<em>NEUCOM</em>, <em>520</em>, 216–229. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {El Niño/Southern Oscillation (ENSO) mainly occurs in the tropical Pacific Ocean every a few years. But it affects the climate around the world and has a dramatic impact on the development of ecology and agriculture. The analysis and prediction of ENSO become particularly important for meteorology and disaster management. However, due to insufficient data, spring predictability barrier (SPB), and model uncertainty, traditional analysis models face challenges. To address these issues, researchers begin to apply deep learning (DL) technologies to ENSO research, exploring the impact of ENSO on the world&#39;s extreme climate changes. In recent years, deep learning-based methods have obtained impressive progress with more accurate and effective predictions of ENSO. In this paper, we summarize the attempts of DL technologies in predicting ENSO. We first introduce the properties of ENSO, followed by the architecture introduction of DL technologies and their application to ENSO. We then investigate the potential of DL technologies for ENSO prediction from various aspects, including model evaluation metrics , prediction algorithms, overcoming SPB and prediction uncertainty. Finally, we provide discussions on the future trends and challenges of using DL technologies for ENSO prediction.},
  archive      = {J_NEUCOM},
  author       = {Gai-Ge Wang and Honglei Cheng and Yiming Zhang and Hui Yu},
  doi          = {10.1016/j.neucom.2022.11.078},
  journal      = {Neurocomputing},
  pages        = {216-229},
  shortjournal = {Neurocomputing},
  title        = {ENSO analysis and prediction using deep learning: A review},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GDN: Guided down-sampling network for real-time semantic
segmentation. <em>NEUCOM</em>, <em>520</em>, 205–215. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time semantic segmentation has attracted wide attention in the computer vision field, and its performance depends on both rich semantic information and high-resolution information. Most networks fastly reduce image resolution or prune feature channels in the coding stage to improve the computing speed and concatenate the shallow feature to the deep feature in the decoding stage for filling in the high-resolution details. Here, we propose a new real-time semantic image segmentation method called guided down-sampling network. The guided down-sampling decomposes the original image into a group of compressed images that replace the original image as the input of the encoding layers. This operation reduces the size of the feature map and meanwhile retains the most spatial information of the original image. Furthermore, a two-branch sub-network is designed to extract semantic information and restore high-resolution image details from compressed images for better supervising feature learning . Our network is tested on the Cityscapes dataset on a single Nvidia GeForce GTX 1080Ti GPU, and the competitive results of 113 FPS and 75.6\% mIoU have been achieved. The code is available at ( https://github.com/ldrunning/segmentation ).},
  archive      = {J_NEUCOM},
  author       = {Die Luo and Hongtao Kang and Junan Long and Jun Zhang and Xiuli Liu and Tingwei Quan},
  doi          = {10.1016/j.neucom.2022.11.075},
  journal      = {Neurocomputing},
  pages        = {205-215},
  shortjournal = {Neurocomputing},
  title        = {GDN: Guided down-sampling network for real-time semantic segmentation},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised named entity recognition in multi-level
contexts. <em>NEUCOM</em>, <em>520</em>, 194–204. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition is a critical task in the natural language processing field. Most existing methods for this task can only exploit contextual information within a sentence. However, their performance on recognizing entities in limited or ambiguous sentence-level contexts is usually unsatisfactory. Fortunately, other sentences in the same document can provide supplementary document-level contexts to help recognize these entities. In addition, words themselves contain word-level contextual information since they usually have different preferences of entity type and relative position from named entities. In this paper, we propose a semi-supervised unified framework to incorporate multi-level contexts for named entity recognition. We use bi-directional gated recurrent units and incorporate pre-trained language model embeddings to capture sentence-level contextual information. To incorporate document-level contexts, we propose to capture interactions between sentences via a multi-head self attention network . To mine word-level contexts, we propose an auxiliary task to predict the type of each word to capture its type preference. We jointly train our model in entity recognition and the auxiliary classification task via multi-task learning. We conduct experiments on two widely-used sequence taggers: CRF tagger and boundary tagger. The experimental results on the CoNLL dataset in English, Dutch, and German validate the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Yubo Chen and Chuhan Wu and Tao Qi and Zhigang Yuan and Yuesong Zhang and Shuai Yang and Jian Guan and Donghong Sun and Yongfeng Huang},
  doi          = {10.1016/j.neucom.2022.11.064},
  journal      = {Neurocomputing},
  pages        = {194-204},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised named entity recognition in multi-level contexts},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised domain adaptation based on the predictive
uncertainty of models. <em>NEUCOM</em>, <em>520</em>, 183–193. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) aims to improve the prediction performance in the target domain under distribution shifts from the source domain. The key principle of UDA is to minimize the divergence between the source and the target domains. To follow this principle, many methods employ a domain discriminator to match the feature distributions. Some recent methods evaluate the discrepancy between two predictions on target samples to detect those that deviate from the source distribution. However, their performance is limited because they either match the marginal distributions or measure the divergence conservatively. In this paper, we present a novel UDA method that learns domain-invariant features that minimize the domain divergence. We propose model uncertainty as a measure of the domain divergence. Our UDA method based on model uncertainty (MUDA) adopts a Bayesian framework and provides an efficient way to evaluate model uncertainty by means of Monte Carlo dropout sampling. Experiment results on image recognition tasks show that our method is superior to existing state-of-the-art methods. We also extend MUDA to multi-source domain adaptation problems.},
  archive      = {J_NEUCOM},
  author       = {JoonHo Lee and Gyemin Lee},
  doi          = {10.1016/j.neucom.2022.11.070},
  journal      = {Neurocomputing},
  pages        = {183-193},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised domain adaptation based on the predictive uncertainty of models},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cloud-based self-triggered coordination for nonlinear
multi-agent consensus. <em>NEUCOM</em>, <em>520</em>, 171–182. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the practical tracking consensus problem for first-orderheterogeneous nonlinear multi-agent systems in presence of external disturbances under directed graphs. Agents with limited communication capability interact with each other through a cloud repository, where the information exchange is asynchronous and indirect. The system model is more general than the ones in existing results, moreover, locally Lipschitz nonlinearities and adaptive control schemes are taken into account. It is proven that under the designed self-triggered protocol, agents can track a virtual leader with bounded error and Zeno behaviour is excluded for real implementation. Finally, a numerical simulation demonstrates the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Shanshan Hong and Yu Zhang},
  doi          = {10.1016/j.neucom.2022.11.061},
  journal      = {Neurocomputing},
  pages        = {171-182},
  shortjournal = {Neurocomputing},
  title        = {Cloud-based self-triggered coordination for nonlinear multi-agent consensus},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural networks compression: A comparative survey and
choice recommendations. <em>NEUCOM</em>, <em>520</em>, 152–170. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state-of-the-art performance for several real-world problems is currently reached by deep and, in particular, convolutional neural networks (CNN). Such learning models exploit recent results in the field of deep learning , leading to highly performing, yet very large neural networks with typically millions to billions of parameters. As a result, such models are often redundant and excessively oversized, with a detrimental effect on the environment in terms of unnecessary energy consumption and a limitation to their deployment on low-resource devices. The necessity for compression techniques able to reduce the number of model parameters and their resource demand is thereby increasingly felt by the research community. In this paper we propose the first extensive comparison, to the best of our knowledge, of the main lossy and structure-preserving approaches to compress pre-trained CNNs, applicable in principle to any existing model. Our study is intended to provide a first and preliminary guidance to choose the most suitable compression technique when there is the need to reduce the occupancy of pre-trained models. Both convolutional and fully-connected layers are included in the analysis. Our experiments involved two pre-trained state-of-the-art CNNs (proposed to solve classification or regression problems) and five benchmarks, and gave rise to important insights about the applicability and performance of such techniques w.r.t. the type of layer to be compressed and the category of problem tackled.},
  archive      = {J_NEUCOM},
  author       = {Giosué Cataldo Marinó and Alessandro Petrini and Dario Malchiodi and Marco Frasca},
  doi          = {10.1016/j.neucom.2022.11.072},
  journal      = {Neurocomputing},
  pages        = {152-170},
  shortjournal = {Neurocomputing},
  title        = {Deep neural networks compression: A comparative survey and choice recommendations},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kernelized transformed subspace clustering with geometric
weights for non-linear manifolds. <em>NEUCOM</em>, <em>520</em>,
141–151. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The naive assumption of subspace clustering is that the data should be separable into separate subspaces. Another consideration of the conventional subspace clustering methods is the linear manifolds. What if, the data doesn’t hold this assumption? We propose a novel subspace clustering framework that works even if the raw data is not separable into separate subspaces. It also generalizes it for non-linear manifolds. To achieve the intended goal, we embed subspace clustering techniques into kernelized transform learning with weighting matrix regularization which accounts for nonlinearity. For the weighting matrix, we use similarity between tangent spaces on data manifolds for local structure and euclidean distances for capturing global geometric structure. The complete optimization problem is solved using alternate minimization. The weighted norm regularization is solved by designing a fixed-point continuation algorithm to obtain an approximate closed solution. To test the performance of the proposed framework, we provide the experimental results on handwritten digits clustering, face image clustering, and motion segmentation . The superiority of the results proves the effectiveness of the weighting matrix in kernelized transformed subspace clustering formulation.},
  archive      = {J_NEUCOM},
  author       = {Jyoti Maggu and Angshul Majumdar},
  doi          = {10.1016/j.neucom.2022.11.077},
  journal      = {Neurocomputing},
  pages        = {141-151},
  shortjournal = {Neurocomputing},
  title        = {Kernelized transformed subspace clustering with geometric weights for non-linear manifolds},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain-specific knowledge-driven pan-sharpening algorithm.
<em>NEUCOM</em>, <em>520</em>, 129–140. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pan-sharpening can provide multispectral images with high spatial resolutions, which are useful for many remote sensing image applications. Currently, deep learning technology has been widely used in pan-sharpening. Most of these deep learning-based methods ignore domain-specific knowledge that can improve spatial and spectral performance. Some improved methods adopt an injection structure which injects initial details obtained from panchromatic images into multispectral images through detail mapping. However, the initial details lack frequency-domain information. Moreover, the detail mapping is completed by convolutional neural networks , which lack sufficient nonlinearity to generate rich and diverse details. To solve the above problems, a domain-specific knowledge-driven pan-sharpening framework based on a detail injection structure is proposed, which includes two stages of knowledge-driven initial detail acquisition and data-driven detail mapping. In the first stage, in order to perform better feature reconstruction in the frequency domain, the PAN-MS method is introduced to provide initial details containing frequency-domain information. In the second stage, a newly designed detail-mapping generative adversarial network (GAN) maps initial details to more various output details. Experiments conducted on three public datasets has proven that the proposed algorithm outperforms some state-of-the-art methods in terms of spatial and spectral performance.},
  archive      = {J_NEUCOM},
  author       = {Nan Shi and Ping Wang and Fan Li},
  doi          = {10.1016/j.neucom.2022.11.068},
  journal      = {Neurocomputing},
  pages        = {129-140},
  shortjournal = {Neurocomputing},
  title        = {Domain-specific knowledge-driven pan-sharpening algorithm},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning based web crawler detection for
diversity and dynamics. <em>NEUCOM</em>, <em>520</em>, 115–128. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crawler detection is always an important research topic in network security . With the development of web technology, crawlers are constantly updating and changing, and their types are becoming diverse. The diversity and dynamics of crawlers pose significant challenges for feature applicability and model robustness. Existing crawler detection methods can only detect a limited number of crawlers by predefined rules and can not cover all types of crawlers; worse, they can be completely invalidated by the emergence of new types of crawlers. In this paper, we propose a reinforcement learning based web crawler detection method for diversity and dynamics (WC3D), which is composed of a feature selector and a session classifier. The feature selector selects the appropriate feature set for different types of crawlers with deep deterministic policy gradient. The session classifier makes crawler detection and provides rewards to the feature selector. The two modules are trained jointly to optimize the feature selection and session classification processes. Extensive experiments demonstrate the existence of crawler diversity and that the proposed method is still highly robust against the new type of crawlers and achieves state-of-the-art performance even without considering the dynamics of the crawlers.},
  archive      = {J_NEUCOM},
  author       = {Yang Gao and Zunlei Feng and Xiaoyang Wang and Mingli Song and Xingen Wang and Xinyu Wang and Chun Chen},
  doi          = {10.1016/j.neucom.2022.11.059},
  journal      = {Neurocomputing},
  pages        = {115-128},
  shortjournal = {Neurocomputing},
  title        = {Reinforcement learning based web crawler detection for diversity and dynamics},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TJU-DNN: A trajectory-unified framework for training deep
neural networks and its applications. <em>NEUCOM</em>, <em>520</em>,
103–114. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The training method for deep neural networks mainly adopts the gradient descent (GD) method. These methods, however, are very sensitive to initialization and hyperparameters. In this paper, an enhanced gradient descent method guided by the trajectory-based method for training deep neural networks , termed the Trajectory Unified Framework (TJU) method, is presented. From a theoretical viewpoint, the robustness of the TJU-based method is supported by an analytical basis presented in the paper. From a computational viewpoint, a TJU methodology consisting of a Block-Diagonal-Pseudo-Transient-Continuation method and a gradient descent method , termed the TJU-GD method, for training deep neural networks is added to obtain high-quality results. Furthermore, to resolve the issue of imbalanced classification, a TJU-Focal-GD method is developed and evaluated. Experimental numerical evaluation of the proposed TJU-GD on various public datasets reveals that the proposed method can achieve great improvements over baseline methods . Specifically, the proposed TJU-Focal-GD also possesses several advantages over other methods for a class of imbalanced datasets from the homemade power line inspection dataset (PLID).},
  archive      = {J_NEUCOM},
  author       = {Xian-Long Lv and Hsiao-Dong Chiang and Bin Wang and Yong-Feng Zhang},
  doi          = {10.1016/j.neucom.2022.11.052},
  journal      = {Neurocomputing},
  pages        = {103-114},
  shortjournal = {Neurocomputing},
  title        = {TJU-DNN: A trajectory-unified framework for training deep neural networks and its applications},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Brain tumor categorization from imbalanced MRI dataset using
weighted loss and deep feature fusion. <em>NEUCOM</em>, <em>520</em>,
94–102. (<a href="https://doi.org/10.1016/j.neucom.2022.11.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based brain tumor classification from brain magnetic resonance imaging (MRI) is a significant research problem. The research problem encounters a major challenge. The training datasets used to develop deep learning algorithms could be imbalanced with significantly more samples for one type of tumor than others. This imbalance in the training dataset affects the performance of tumor classification using deep learning models as the classifier performance gets biased towards the majority class. The article addresses the challenge of training data imbalance by proposing a novel class-weighted focal loss and studies the effects of weighted loss functions on feature learning by convolutional neural networks (CNN). However, finding optimal class weights is a challenge and the predictions of CNN trained using weighted functions could be biased. The article presents two approaches to improve the performance of the expert system: deep feature fusion and majority voting on classifier predictions. In the first approach, the deep feature fusion concerns the fusion of deep features extracted from CNN models trained using separate loss functions. The fused deep features are classified using proven models, such as support vector machine (SVM) and k-nearest neighbours (KNN). In the other approach, a majority voting is performed on the predictions for three different feature sets extracted from CNN models trained using separate loss functions. The majority voting uses the same classifier upon three different feature sets. The proposed approaches show a significant improvement in brain tumor predictions over a state of the art method based on CNN trained using cross-entropy loss. The classification errors between the majority class and the minority class samples are reduced considerably in the proposed strategies. The experiments are evaluated using the Figshare dataset, and the performance improved for the metrics: accuracy, precision, recall, balanced accuracy and F-scores.},
  archive      = {J_NEUCOM},
  author       = {S. Deepak and P.M. Ameer},
  doi          = {10.1016/j.neucom.2022.11.039},
  journal      = {Neurocomputing},
  pages        = {94-102},
  shortjournal = {Neurocomputing},
  title        = {Brain tumor categorization from imbalanced MRI dataset using weighted loss and deep feature fusion},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust monocular 3D face reconstruction under challenging
viewing conditions. <em>NEUCOM</em>, <em>520</em>, 82–93. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite extensive research, 3D face reconstruction from a single image remains an open research problem due to the high degree of variability in pose, occlusions and complex lighting conditions. While deep learning-based methods have achieved great success, they are usually limited to near frontal images and images that are free of occlusions. Also, the lack of diverse training data with 3D annotations considerably limits the performance of such methods. As such, existing methods fail to recover, with high fidelity, the facial details especially when dealing with images captured under extreme conditions. To address this issue, we propose an unsupervised coarse-to-fine framework for the reconstruction of 3D faces with detailed textures. Our core idea is that multiple images of the same person but captured under different viewing conditions should provide the same 3D face. We thus propose to leverage a self-augmentation learning technique to train a model that is robust to diverse variations. In addition, instead of directly employing image pixels, we use a set of discriminative features describing the identity and attributes of the face as input to the refinement module, making the model invariant to viewing conditions. This combination of self-augmentation learning with rich face-related features allows the reconstruction of plausible facial details even under challenging viewing conditions. We train the model end-to-end and in a self-supervised manner, without any 3D annotations, landmarks or identity labels, using a combination of an image-level photometric loss and a perception-level loss that is identity and attribute-aware. We evaluate the proposed approach on CelebA and AFLW2000 datasets, and demonstrate its robustness to appearance variations despite learning from unlabeled images. The qualitative comparisons indicate that our method produces detailed 3D faces even under extreme occlusions, out of plane rotations and noise perturbations where existing state-of-the-art methods often fail. We also quantitatively show that our method outperforms SOTA with more than 30.14\%, 9.87\% and 11.3\% in terms of PSNR , SSIM and IDentity similarity, respectively.},
  archive      = {J_NEUCOM},
  author       = {Hoda Mohaghegh and Farid Boussaid and Hamid Laga and Hossein Rahmani and Mohammed Bennamoun},
  doi          = {10.1016/j.neucom.2022.11.048},
  journal      = {Neurocomputing},
  pages        = {82-93},
  shortjournal = {Neurocomputing},
  title        = {Robust monocular 3D face reconstruction under challenging viewing conditions},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Depth dynamic center difference convolutions for monocular
3D object detection. <em>NEUCOM</em>, <em>520</em>, 73–81. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate 3D information is essential in the fields of autonomous driving and mobile robotics. Monocular 3D object detection provides a more economical solution than traditional LiDAR-dependent methods. Due to the lack of depth cues, monocular 3D object detection is extremely challenging to efficiently detect objects in 3D space from a single image. To mitigate this issue, we first identify how the depth information on surrounding pixels provides additional support for depth map estimation in the 3D detection of driving scenes. Based on this observation, we design Depth Dynamic Center Difference Convolution (DDCDC), which introduces surrounding pixel cues in depth estimation and has different convolution kernels weights for each pixel of all examples. This module not only overcomes the limitations of conventional 2D convolution, but also highlights the differences in depth information between the target and the background, so more attention is paid to interesting objects. Finally, we design an end-to-end monocular 3D object detection network with proposed DDCDC convolution modules. As a demonstration of the effectiveness of our method, our module is validated on two datasets: KITTI and nuScenes. The DDCDC achieves the most significant improvement in a simple setup compared to existing methods. Our evaluation results for the KITTI split1/split2 set are 23.83/21.48,16.00/13.92,12.04/10.59 (based on easy, medium, and hard), while the results for the nuScenes test set are mAP = 0.364 and NDS = 0.434.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Wu and Dongliang Ma and Xin Qu and Xin Jiang and Dan Zeng},
  doi          = {10.1016/j.neucom.2022.11.032},
  journal      = {Neurocomputing},
  pages        = {73-81},
  shortjournal = {Neurocomputing},
  title        = {Depth dynamic center difference convolutions for monocular 3D object detection},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiscale echo self-attention memory network for
multivariate time series classification. <em>NEUCOM</em>, <em>520</em>,
60–72. (<a href="https://doi.org/10.1016/j.neucom.2022.11.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, ESN has been applied to time series classification own to its high-dimensional random projection ability and training efficiency characteristic. The major drawback of applying ESN to time series classification is that ESN cannot capture long-term dependency information well. Therefore, the Multiscale Echo Self-Attention Memory Network (MESAMN) is proposed to address this issue. Specifically, the MESAMN consists of a memory encoder and a memory learner. In the memory encoder, multiple differently initialized ESNs are utilized for high-dimensional projection which is then followed by a self-attention mechanism to capture the long-term dependent features. A multiscale convolutional neural network is developed as the memory learner to learn local features using features extracted by the memory encoder. Experimental results show that the proposed MESAMN yields better performance on 18 multivariate time series classification tasks as well as three 3D skeleton-based action recognition tasks compared to existing models. Furthermore, the capacity for capturing long-term dependencies of the MESAMN is verified empirically.},
  archive      = {J_NEUCOM},
  author       = {Huizi Lyu and Desen Huang and Sen Li and Wing W.Y. Ng and Qianli Ma},
  doi          = {10.1016/j.neucom.2022.11.066},
  journal      = {Neurocomputing},
  pages        = {60-72},
  shortjournal = {Neurocomputing},
  title        = {Multiscale echo self-attention memory network for multivariate time series classification},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LaCERA: Layer-centric event-routing architecture.
<em>NEUCOM</em>, <em>520</em>, 46–59. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic processors are hardware dedicated to spiking neural networks (SNNs) to accelerate SNN operations with low-power consumption. Early proposed digital neuromorphic processors define SNN topology in a neuron-centric manner in full support of topology reconfiguration. However, this high reconfigurability comes at the cost of large memory usage, and the state-of-the-art SNN topology barely needs such high reconfigurability as for convolutional SNNs (Conv-SNNs). Further, neuron-centric routing methods hardly allow weight-reuse for Conv-SNNs. To address these concerns, we propose the layer-centric event-routing architecture (LaCERA) that uses layers (or sub-layers) as the granularity of topology unlike neuron-centric routing methods. LaCERA supports the high reconfigurability of Conv-SNN topology and high efficiency in memory usage given the use of lightweight lookup tables for event-routing and high weight-reuse rate. To evaluate LaCERA, we implemented a neuromorphic processor with 32 cores, each of which employs LaCERA, in a field-programmable gate array. The evaluation on the processor level highlights (i) almost ideal weight-reuse rate for Conv-SNNs, (ii) high efficiency in event-routing memory usage, ca. 100 × × that of Loihi, and (iii) high flexibility of layer partitioning into sub-layers over multiple cores. Further, our neuromorphic processor achieved approximately a 10 × × improvement in inference speed compared with graphics processing units (TITAN RTX and RTX A6000).},
  archive      = {J_NEUCOM},
  author       = {ChangMin Ye and Vladimir Kornijcuk and DongHyung Yoo and Jeeson Kim and Doo Seok Jeong},
  doi          = {10.1016/j.neucom.2022.11.046},
  journal      = {Neurocomputing},
  pages        = {46-59},
  shortjournal = {Neurocomputing},
  title        = {LaCERA: Layer-centric event-routing architecture},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A decentralized learning strategy to restore connectivity
during multi-agent formation control. <em>NEUCOM</em>, <em>520</em>,
33–45. (<a href="https://doi.org/10.1016/j.neucom.2022.11.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a decentralized learning algorithm to restore communication connectivity during multi-agent formation control . The time-varying connectivity profile of a mobile multi-agent system represents the dynamic information exchange capabilities among agents. While connected to the neighbors, each mobile agent in the proposed scheme learns to raise the team connectivity. When the inter-agent communication is lost, the associated trained neural network generates appropriate control actions to restore connectivity. The proposed learning technique leverages an adaptive control formalism, wherein a neural network tries to mimic the negative gradient of a value that relies on the agent-to-neighbor distances. All agents use the conventional consensus protocol during the connected multi-agent dynamics, and under communication loss, only the lost agent executes the neural network predicted actions to come back to the fleet. Simulation results demonstrate the effectiveness of our proposed approach for single/multiple agent loss even in the presence of velocity disturbances.},
  archive      = {J_NEUCOM},
  author       = {Rajdeep Dutta and Harikumar Kandath and Senthilnath Jayavelu and Li Xiaoli and Suresh Sundaram and Daniel Pack},
  doi          = {10.1016/j.neucom.2022.11.054},
  journal      = {Neurocomputing},
  pages        = {33-45},
  shortjournal = {Neurocomputing},
  title        = {A decentralized learning strategy to restore connectivity during multi-agent formation control},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stability of the caputo fractional-order inertial neural
network with delay-dependent impulses. <em>NEUCOM</em>, <em>520</em>,
25–32. (<a href="https://doi.org/10.1016/j.neucom.2022.11.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the stability of the Caputo fractional-order inertial neural network (CFOINN) with destabilizing and stabilizing delay-dependent impulses, separately. Firstly, based on average impulsive delay (AID), stability conditions for the Caputo fractional-order (CFO) system with destabilizing and stabilizing delay-dependent impulses are separately given by utilizing properties of the CFO derivative. Then, by constructing the Lyapunov function for the CFOINN with delayed impulses, some stability criteria are obtained. Finally, numerical examples are presented to verify the effectiveness of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Lingao Luo and Lulu Li and Wei Huang and Qian Cui},
  doi          = {10.1016/j.neucom.2022.11.060},
  journal      = {Neurocomputing},
  pages        = {25-32},
  shortjournal = {Neurocomputing},
  title        = {Stability of the caputo fractional-order inertial neural network with delay-dependent impulses},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning approach for solving linear programming
problems. <em>NEUCOM</em>, <em>520</em>, 15–24. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the optimal solution to a linear programming (LP) problem is a long-standing computational problem in Operations Research. This paper proposes a deep learning approach in the form of feed-forward neural networks to solve the LP problem. The latter is first modeled by an ordinary differential equations (ODE) system, the state solution of which globally converges to the optimal solution of the LP problem. A neural network model is constructed as an approximate state solution to the ODE system, such that the neural network model contains the prediction of the LP problem. Furthermore, we extend the capability of the neural network by taking the parameter of LP problems as an input variable so that one neural network can solve multiple LP instances in a one-shot manner. Finally, we validate the proposed method through a collection of specific LP examples and show concretely how the proposed method solves the example.},
  archive      = {J_NEUCOM},
  author       = {Dawen Wu and Abdel Lisser},
  doi          = {10.1016/j.neucom.2022.11.053},
  journal      = {Neurocomputing},
  pages        = {15-24},
  shortjournal = {Neurocomputing},
  title        = {A deep learning approach for solving linear programming problems},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Invariant and consistent: Unsupervised representation
learning for few-shot visual recognition. <em>NEUCOM</em>, <em>520</em>,
1–14. (<a href="https://doi.org/10.1016/j.neucom.2022.11.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot visual recognition aims to identify novel unseen classes with few labels while learning generalized prior knowledge from base classes. Recent ideas propose to explore this problem in an unsupervised setting, i.e. , without any labels in base classes, which reduces the heavy consumption of manual annotations. In this paper, we build upon a self-supervised insight and propose a novel unsupervised learning approach that joints Invariant and Consistent (InCo) representation for the few-shot task. For the invariant representation operation, we present a geometric invariance module to construct the rotation prediction of each instance, which learns the intra-instance variance and improves the feature discrimination. To further build consistency representation of inter-instance, we propose a pairwise consistency module from two contrastive learning aspects: a holistic contrastive learning with historical training queues, and a local contrastive learning for enhancing the representation of current training samples. Moreover, to better facilitate contrastive learning among features, we introduce an asymmetric convolutional architecture to encode high-quality representations. Comprehensive experiments on 4 public benchmarks demonstrate the utility of our approach and the superiority compared to existing approaches.},
  archive      = {J_NEUCOM},
  author       = {Heng Wu and Yifan Zhao and Jia Li},
  doi          = {10.1016/j.neucom.2022.11.073},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Invariant and consistent: Unsupervised representation learning for few-shot visual recognition},
  volume       = {520},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A survey for solving mixed integer programming via machine
learning. <em>NEUCOM</em>, <em>519</em>, 205–217. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) has been recently introduced to solving optimization problems , especially for combinatorial optimization (CO) tasks. In this paper, we survey the trend of leveraging ML to solve the mixed-integer programming problem (MIP). Theoretically, MIP is an NP-hard problem, and most CO problems can be formulated as MIP. Like other CO problems , the human-designed heuristic algorithms for MIP rely on good initial solutions and cost a lot of computational resources. Therefore, researchers consider applying machine learning methods to solve MIP since ML-enhanced approaches can provide the solution based on the typical patterns from the training data. Specifically, we first introduce the formulation and preliminaries of MIP and representative traditional solvers. Then, we show the integration of machine learning and MIP with detailed discussions on related learning-based methods, which can be further classified into exact and heuristic algorithms . Finally, we propose the outlook for learning-based MIP solvers, the direction toward more combinatorial optimization problems beyond MIP, and the mutual embrace of traditional solvers and ML components. We maintain a list of papers that utilize machine learning technologies to solve combinatorial optimization problems , which is available at https://github.com/Thinklab-SJTU/awesome-ml4co .},
  archive      = {J_NEUCOM},
  author       = {Jiayi Zhang and Chang Liu and Xijun Li and Hui-Ling Zhen and Mingxuan Yuan and Yawen Li and Junchi Yan},
  doi          = {10.1016/j.neucom.2022.11.024},
  journal      = {Neurocomputing},
  pages        = {205-217},
  shortjournal = {Neurocomputing},
  title        = {A survey for solving mixed integer programming via machine learning},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Research on emotional semantic retrieval of attention
mechanism oriented to audio-visual synesthesia. <em>NEUCOM</em>,
<em>519</em>, 194–204. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital video is widely used to record people’s daily lives and share people’s moods, but few researchers have conducted research on the consistency of emotional expression between short videos and music. In order to be able to match the appropriate background music to the short video image autonomously and efficiently, the paper analyzed the emotional connection between the two from the audio-visual synesthesia. First, emotional semantics was used as a bridge to connect video data and music data, and a video-music synesthesia data set based on semantic words was constructed. Then, an attention mechanism was incorporated to better extract key features in video images. In the extraction of music features, an improved lenet5 network was used, and the optimal network parameters were determined through experiments. Finally, the two types of features were fused and the mutual retrieval between video and music was performed. In order to compare the performance of different models, different CNN models were calculated in the processing of video images, including VGG16, VGG19 , AlexNet and GoogleNet, and the attention mechanism was added to each network for calculation to compare its retrieval accuracy . In the processing of music data, different CNN algorithms were also used for comparative experiments, and networks with different layers were used to determine the optimal results. The experimental results show that the audiovisual synesthesia retrieval model based on emotion can effectively measure the emotional similarity between video images and music, and the method of the paper can produce a good match between them. The research method of the paper is the exploration of computer synesthetic intelligence, which can stimulate the creative inspiration of image and music creative designers. While enhancing the emotional experience of digital products, it also improves the efficiency and quality of development.},
  archive      = {J_NEUCOM},
  author       = {Weixing Wang and Qianqian Li and Jingwen Xie and Ningfeng Hu and Ziao Wang and Ning Zhang},
  doi          = {10.1016/j.neucom.2022.11.036},
  journal      = {Neurocomputing},
  pages        = {194-204},
  shortjournal = {Neurocomputing},
  title        = {Research on emotional semantic retrieval of attention mechanism oriented to audio-visual synesthesia},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inverse-model-based iterative learning control for unknown
MIMO nonlinear system with neural network. <em>NEUCOM</em>,
<em>519</em>, 187–193. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides an inverse-model-based iterative learning control (ILC) for the unknown multi-input multi-output (MIMO) nonlinear system with neural network (NN), where a novel gradient adaptive law is used to update the NN weights both hidden and output layers such a faster convergence can be achieved. First, a three-layer NN structure is introduced to observe the MIMO nonlinear system with input–output data, and a new gradient algorithm is proposed to update the unknown parameters of both hidden and output layers. Then, the input dynamic can be obtained with the NN observer, and the inversion-model-based control is designed. Moreover, the ideal inversion control can be obtained based on the reference signal, and the inverse ILC is designed. The stability of the NN observer and the convergence of the inverse-model-based control are analyzed. Finally, a SCARA manipulator MIMO model is simulated to illustrate the correctness of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Yongfeng Lv and Xuemei Ren and Jianyan Tian and Xiaowei Zhao},
  doi          = {10.1016/j.neucom.2022.11.040},
  journal      = {Neurocomputing},
  pages        = {187-193},
  shortjournal = {Neurocomputing},
  title        = {Inverse-model-based iterative learning control for unknown MIMO nonlinear system with neural network},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-step scalable spectral clustering algorithm using
landmarks and probability density estimation. <em>NEUCOM</em>,
<em>519</em>, 173–186. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering is one of the most important clustering approaches , often yielding performance superior to other clustering approaches . However, it is not scalable to large data sets in its original form due to the computational burden of the required large-matrix eigen-decomposition. In this paper, a two-step spectral clustering algorithm is introduced by extending recent advances of scalable spectral clustering based on low-rank affinity matrix using landmarks. In the first step, a scalable spectral clustering algorithm using raw landmark-based affinity matrix is adopted. In the second step, a novel low-rank affinity matrix is learnt via the probability density estimators, constructed from the estimated clusters as derived from the first step. Since the prior information on cluster labels can be utilised in the second step, this learnt affinity matrix reflects intrinsic pairwise data relationships much better. While the proposed more complicated algorithm results in a higher computational cost than the previous landmark-based spectral research, it can be shown that the associated computational cost still scales well with data size. It is demonstrated that the proposed algorithm is capable of achieving far superior performance than other state-of-the-art algorithms for several benchmark multi-class image data sets.},
  archive      = {J_NEUCOM},
  author       = {Xia Hong and Junbin Gao and Hong Wei and James Xiao and Richard Mitchell},
  doi          = {10.1016/j.neucom.2022.11.063},
  journal      = {Neurocomputing},
  pages        = {173-186},
  shortjournal = {Neurocomputing},
  title        = {Two-step scalable spectral clustering algorithm using landmarks and probability density estimation},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Command filtered-based neuro-adaptive robust finite-time
trajectory tracking control of autonomous underwater vehicles under
stochastic perturbations. <em>NEUCOM</em>, <em>519</em>, 158–172. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of finite-time trajectory tracking control is studied and addressed for a 6 degree of freedom (DOF) autonomous underwater vehicle (AUV) subjected to unknown dynamic model, stochastic perturbations, external disturbances (matched and mismatched) and saturation input nonlinearities. Based on the backstepping control approach, novel finite-time control inputs are designed and proposed. Artificial neural networks (ANNs) and finite-time adaptation laws are exploited to approximate the nonlinear dynamics of AUV, the stochastic perturbations and the upper bound of external disturbances. To handle the destructive effects of saturation input nonlinearities, finite-time auxiliary system method is utilized. To overcome the explosion of complexity problem of backstepping control strategy, compensator-based finite-time command filter approach is exploited. By utilizing the Lyapunov stability theorem, it is mathematically proven and demonstrated that the suggested nonlinear control inputs are able to guarantee the semi-global finite-time stability in probability (SGFSP) of the closed-loop AUV system. Finally, numerical simulations are carried out to illustrate and depict the effectiveness and performance of the proposed neuro-adaptive robust finite-time control scheme.},
  archive      = {J_NEUCOM},
  author       = {Fatemeh Sedghi and Mohammad Mehdi Arefi and Ali Abooee},
  doi          = {10.1016/j.neucom.2022.11.005},
  journal      = {Neurocomputing},
  pages        = {158-172},
  shortjournal = {Neurocomputing},
  title        = {Command filtered-based neuro-adaptive robust finite-time trajectory tracking control of autonomous underwater vehicles under stochastic perturbations},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A consensus algorithm based on multi-agent system with state
noise and gradient disturbance for distributed convex optimization.
<em>NEUCOM</em>, <em>519</em>, 148–157. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Almost all systems are inevitably subject to various uncertainties or disturbances from the external environment in practical applications. Taking these factors into consideration, in this paper a distributed algorithm with state noise and gradient disturbance is proposed for solving distributed optimization problem with closed convex set constraint based on multi-agent system under weight-balanced graph. Moreover, based on the gradient tracking and projection methods, the proposed distributed algorithm with gradient tracking can improve the convergence rate by introducing a projection error term and an auxiliary parameter. In contrast to some existing constrained distributed gradient algorithms, the proposed one can make the convergence faster and enhance the performance of convergence. The proposed algorithm is illustrated with two simulation examples to show its effectiveness and robustness.},
  archive      = {J_NEUCOM},
  author       = {Xiwang Meng and Qingshan Liu},
  doi          = {10.1016/j.neucom.2022.11.051},
  journal      = {Neurocomputing},
  pages        = {148-157},
  shortjournal = {Neurocomputing},
  title        = {A consensus algorithm based on multi-agent system with state noise and gradient disturbance for distributed convex optimization},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal binning for a variance based alternative of mutual
information in pattern recognition. <em>NEUCOM</em>, <em>519</em>,
135–147. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mutual information (MI) is a widely used similarity measure in pattern recognition. MI uses entropy as a measure of uncertainty to quantify the structural similarity of two vectors. Replacing entropy with variance as a measure of uncertainty, an analogous class of similarity measures can be derived and estimated by regression techniques. Recently, the non-linear piecewise constant regression (PWCR) has been proposed to drive similarity measures of this scheme, leading to competitive alternatives of MI. Although PWCR is based on binning, the optimal binning technique for certain problems remained an open question. In this paper, we show mathematically that the optimal binning needs to be aligned with the expected relationship between the vectors being compared. In general, approximately optimal binnings can be found by combinatorial optimization, and in certain cases the optimal binning can be determined by k-means clustering. The theoretical findings are supported by numerical experiments that show a 2–5\% increase in the AUC scores in simulated pattern recognition scenarios and improved feature rankings in feature selection problems. The results suggest that the proposed binning techniques could improve the performance of PWCR-driven similarity measures in real-world applications.},
  archive      = {J_NEUCOM},
  author       = {Attila Fazekas and György Kovács},
  doi          = {10.1016/j.neucom.2022.11.037},
  journal      = {Neurocomputing},
  pages        = {135-147},
  shortjournal = {Neurocomputing},
  title        = {Optimal binning for a variance based alternative of mutual information in pattern recognition},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EEGraph: An open-source python library for modeling
electroencephalograms using graphs. <em>NEUCOM</em>, <em>519</em>,
127–134. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connectivity studies make it possible to identify alterations in brain connections and to associate these pathologies with different neurological disorders. However, a clinical test is necessary to obtain information about the state of the brain. Electroencephalograms (EEGs) provide this information in addition to being tests with other benefits for the patient (non-invasive, low-cost, high reproducibility). Graph theory can be used to represent both the anatomical and functional connections of the brain by means of connectivity measures. The procedure of transforming an EEG into a graph can be slightly tedious for researchers, especially when implementing different connectivity measures. The open-source Python library EEGraph automatically performs the modeling of an EEG through a graph, providing its matrix and visual representation. It recognizes various EEG input formats, identifying the number of electrodes and the location of each electrode in the brain. Moreover, it allows the user to choose from 12 connectivity measures to produce the graph from the EEG, with great flexibility to define specific parameters to adapt them to each study, including EEG time-windows segmentation and separation in frequency bands. The EEGraph library is developed as a tool, for researchers and clinical specialists in the field of neuroscience, that provides direct information on the connectivity of the brain from electroencephalography signals. Its documentation and source code are available at https://github.com/ufvceiec/EEGRAPH . It can be installed from the Python Package Index using pip install EEGRAPH. The EEGraph library was built aiming to facilitate the development of connectivity studies based on the modeling of electroencephalography tests through graphs. It includes a wide range of connectivity measures, which, together with the multiple output options, make EEGraph an easy to use and powerful tool with direct applications in both the clinical and neuroscience research fields.},
  archive      = {J_NEUCOM},
  author       = {Ana M. Maitin and Alberto Nogales and Pedro Chazarra and Álvaro José García-Tejedor},
  doi          = {10.1016/j.neucom.2022.11.050},
  journal      = {Neurocomputing},
  pages        = {127-134},
  shortjournal = {Neurocomputing},
  title        = {EEGraph: An open-source python library for modeling electroencephalograms using graphs},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial examples based on object detection tasks: A
survey. <em>NEUCOM</em>, <em>519</em>, 114–126. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning plays a critical role in the applications of artificial intelligence. The trend of processing images or videos as input data and pursuing execution efficiency in practical applications is unstoppable. However, the vulnerability due to the complex structure of deep networks makes it at risk of attacks. Object detection, as the significant product impacted by the deep learning frame, corresponds to this weakness implicated by its multiple-tasks property. Besides, these applications involving object detection techniques are integrated deeply into our lives, potentially leading to unimaginable loss. Adversarial example attacks, as the mainstream attack method, provide an efficacious and comprehensible idea to generate perturbation. In this survey, we review the existing adversarial example attacks in object detection tasks and inductively discuss the similarity and differences among these approaches. Finally, we construct this survey for discussing the attacks in the object detection field and point out the possible direction for adversarial defenses in future studies.},
  archive      = {J_NEUCOM},
  author       = {Jian-Xun Mi and Xu-Dong Wang and Li-Fang Zhou and Kun Cheng},
  doi          = {10.1016/j.neucom.2022.10.046},
  journal      = {Neurocomputing},
  pages        = {114-126},
  shortjournal = {Neurocomputing},
  title        = {Adversarial examples based on object detection tasks: A survey},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature pyramid network with multi-scale prediction fusion
for real-time semantic segmentation. <em>NEUCOM</em>, <em>519</em>,
104–113. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature pyramid network (FPN) is constructed from a bottom-up pathway and a top-down pathway. The method involves multi-scale features, so it can obtain rich contextual information from lower scales and high resolution from the largest scale. Additionally, different receptive fields are effective to capture both thin and large objects in image scenes. All feature maps concatenate together to predict the targets. However, the average pooling method yields the problem of combining the best predictions with poorer ones. In this paper, we proposed a dual prediction to leverage the useful characteristics of each FPN feature map. A low scale prediction attains good precision for large objects. The other one suitably segments narrow objects. Finally, a multi-scale fusion is deployed with an attention part. The attention module finds pixels of a low scale having high probabilities of wrong labels, and then requires the supplements from a high scale. A multi-scale fusion allows the network to learn across the different scales of predictions. We have achieved good Results 77.9\% mIoU at 62 FPS on Cityscapes and 44.1\% mIoU on Mapillary Vistas.},
  archive      = {J_NEUCOM},
  author       = {Toan Van Quyen and Min Young Kim},
  doi          = {10.1016/j.neucom.2022.11.062},
  journal      = {Neurocomputing},
  pages        = {104-113},
  shortjournal = {Neurocomputing},
  title        = {Feature pyramid network with multi-scale prediction fusion for real-time semantic segmentation},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Functional network: A novel framework for interpretability
of deep neural networks. <em>NEUCOM</em>, <em>519</em>, 94–103. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The layered structure of deep neural networks hinders the use of numerous analysis tools and thus the development of its interpretability . Inspired by the success of functional brain networks , we propose a novel framework for interpretability of deep neural networks , that is, the functional network. We construct the functional network of fully connected networks and explore its small-worldness. In our experiments, the mechanisms of regularization methods , namely, batch normalization and dropout, are revealed using graph theoretical analysis and topological data analysis. Our empirical analysis shows the following: (1) batch normalization enhances model performance by increasing the global efficiency and the number of loops but reduces adversarial robustness by lowering the fault tolerance . (2) Dropout improves generalization and robustness of models by improving the functional specialization and fault tolerance . (3) The models with different regularizations can be clustered accurately according to their functional topological differences, reflecting the great potential of the functional network and topological data analysis in interpretability.},
  archive      = {J_NEUCOM},
  author       = {Ben Zhang and Zhetong Dong and Junsong Zhang and Hongwei Lin},
  doi          = {10.1016/j.neucom.2022.11.035},
  journal      = {Neurocomputing},
  pages        = {94-103},
  shortjournal = {Neurocomputing},
  title        = {Functional network: A novel framework for interpretability of deep neural networks},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analyzing chinese text with clause relevance structure.
<em>NEUCOM</em>, <em>519</em>, 82–93. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discourse structure is generally represented as hierarchical structure, the two most well known representations are rhetorical structure theory (RST) and Penn discourse treebank (PDTB). The main problem of the hierarchical structure is that it can not describe the direct semantic relevance between the elementary discourse units (EDU), especially the non-adjacent and cross-level EDUs. Discourse dependency structure (DDS) has been put forward in recent years to describe the head-dependent relation between the EDUs. However, the judgment process of the head can not be answered theoretically. This problem is particularly serious in Chinese discourse analysis, because Chinese lacks the form differences between the main clauses and the subordinate clauses. In this paper, we propose clause relevance structure to represent the discourse structure. Compared with the hierarchical discourse structure and DDS, the clause relevance structure can effectively describe the direct semantic association between discontinuous and cross-level clauses in a text, and the construction of structure is not presupposed by the head recognition. We propose the judgment criteria and formal constraints of the clause relevance structure, and built a human-annotated corpus on Chinese text. Based on the Chinese corpus, we explore the automatic recognition of clause relevance structure. The clause relevance recognition task is formalized as a classification problem and performed by the BERT-based model. A bidirectional LSTM layer is added on the top of the BERT to improve the performance, and the recognition accuracy (90.77\%) is achieved by the BERT-LSTM model. Experimental results show that the long distance clause pairs are the main difficulties in the clause relevance recognition, and these difficulties mainly focus on the positive examples, while the clause pairs with short distance are especially difficult to be correctly recognized as negative relevance.},
  archive      = {J_NEUCOM},
  author       = {Chen Lyu and Wenhe Feng},
  doi          = {10.1016/j.neucom.2022.10.077},
  journal      = {Neurocomputing},
  pages        = {82-93},
  shortjournal = {Neurocomputing},
  title        = {Analyzing chinese text with clause relevance structure},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MAENet: A novel multi-head association attention enhancement
network for completing intra-modal interaction in image captioning.
<em>NEUCOM</em>, <em>519</em>, 69–81. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning attracts much attention as it bridges computer vision and natural language processing . Recent works show that transformer-based models with the multi-head self-attention can explore intra-modal interactions for generating high-quality image captions. However, the subspace of each attention head is operated independently in these multi-head attention methods, which ignores the association between attention heads and makes the learning of intra-modal interaction incomplete. In this paper, we propose a Multi-head Association Attention Enhancement Network (MAENet) for image captioning, which leverages a novel Multi-head Association Attention Enhancement (MAE) block for completing intra-modal interaction learning. The proposed MAE block contains Multi-head Association Attention (MAA) and Attention Enhancement (AE) module.The MAA calculates the contributive weight of different attention heads, and captures the associated information from adjacent attention subspaces via learned associative parameters. The AE module follows with the MAA to further enhance the association attention results through an additional spatial and channel-wise attention aggregation. It’s worth noting that the MAE block is a plug-and-play module that can be cascaded with other multi-head attention mechanisms. Extensive experiments on MS COCO show that our model achieves a quite competitive performance, especially for the model of MAE block cascaded with X-linear attention obtains the best-reported SPICE performance of 23.5\% 23.5\% on the Karpathy test split. This clearly demonstrates that the proposed model can better model the interactive information and result in superior captions.},
  archive      = {J_NEUCOM},
  author       = {Nannan Hu and Chunxiao Fan and Yue Ming and Fan Feng},
  doi          = {10.1016/j.neucom.2022.11.045},
  journal      = {Neurocomputing},
  pages        = {69-81},
  shortjournal = {Neurocomputing},
  title        = {MAENet: A novel multi-head association attention enhancement network for completing intra-modal interaction in image captioning},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Depth guided feature selection for RGBD salient object
detection. <em>NEUCOM</em>, <em>519</em>, 57–68. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth information can greatly benefit the saliency detection in RGBD images if they are utilized well. Prevalent methods generally directly fuse depth and RGB features in networks. However, due to the inherent inconsistent between RGB and depth information, the RGB features are easy to be interfered by the intrinsic noise existed in depth features, making the precise RGBD saliency detection still a challenge. In this paper, we propose a novel Depth Guided Feature Selection network (DGFSnet) that takes depth information as prior and dynamically selects the complementary RGB information for RGBD salient object detection. Specifically, DGFSnet first includes a Depth Weight Generation module (DWG) to learn a set of layer-specific weights from multi-scale depth features. Guiding by these learned weights, DGFSnet further devises a Weight-guided Feature Aggregation module (WFA) to assign them to their corresponding RGB layers for dynamically enhancing and selecting saliency-related RGB features. With two modules, DGFSnet is able to effectively integrate the multi-modality complementaries and further highlight salient regions . Experimental results over seven popular RGBD salient object detection benchmarks demonstrate that DGFSnet fairly locates salient regions and effectively segments the complete object.},
  archive      = {J_NEUCOM},
  author       = {Zun Li and Congyan Lang and Guanqin Li and Tao Wang and Yidong Li},
  doi          = {10.1016/j.neucom.2022.11.030},
  journal      = {Neurocomputing},
  pages        = {57-68},
  shortjournal = {Neurocomputing},
  title        = {Depth guided feature selection for RGBD salient object detection},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disguised heterogeneous face recognition using deep
neighborhood difference relational network. <em>NEUCOM</em>,
<em>519</em>, 44–56. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous face recognition (HFR) aims to match a probe face image to a gallery of images in a different modality, such as visible to thermal. The complexity of the problem is further increased by the presence of facial disguise, one of the emerging problems in application of face biometrics . While several works have been proposed for HFR, disguised HFR remains one of the unexplored challenges of face recognition. Most of the proposed methods apply constraints on the network output for cross-modality image matching, consequently ignoring the image relationships within the network. The deep features within a network contain additional information which can be exploited for improved performance. With this motivation, we propose a Deep Neighborhood Difference Relational (DNDR) network and Joint Discrimination Loss for disguised HFR. The network calculates the difference relationships between cross-modality images in deep feature space. It implicitly learns to ignore the real-to-disguise feature relationships while focusing on real-to-real facial features for HFR. The proposed method learns the relationships between images of the same identity rather than optimizing the network on a hand-crafted metric loss function. For an input image pair , the DNDR network outputs identity representative embeddings of each image and a match probability of the image pair. The embedding distance and the match probability are then fused for more robust classification accuracy . Extensive experiments on publicly available heterogeneous face databases show the effectiveness of the proposed method for visible to infrared, visible to thermal, and visible to sketch face recognition.},
  archive      = {J_NEUCOM},
  author       = {Usman Cheema and Seungbin Moon},
  doi          = {10.1016/j.neucom.2022.11.058},
  journal      = {Neurocomputing},
  pages        = {44-56},
  shortjournal = {Neurocomputing},
  title        = {Disguised heterogeneous face recognition using deep neighborhood difference relational network},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MUSE: Multi-faceted attention for signed network embedding.
<em>NEUCOM</em>, <em>519</em>, 36–43. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed network embedding is an approach to learning low-dimensional representations of nodes in signed networks with both positive and negative links, which facilitates downstream tasks such as link prediction with general data mining frameworks. Due to the distinct properties and significant added value of negative links, existing signed network embedding methods usually design dedicated methods based on social theories such as balance theory and status theory. However, existing signed network embedding methods ignore the characteristics of multiple facets of each node and mix them up in one single representation, which limits the ability to capture the fine-grained attentions between node pairs. In this paper, we propose MUSE , a MU lti-faceted attention-based S igned network E mbedding framework to tackle this problem. Specifically, a joint intra- and inter-facet attention mechanism is introduced to aggregate fine-grained information from neighbor nodes. Moreover, balance theory is also utilized to guide information aggregation from multi-order balanced and unbalanced neighbors. Experimental results on four real-world signed network datasets demonstrate the effectiveness of our proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Dengcheng Yan and Youwen Zhang and Wenxin Xie and Ying Jin and Yiwen Zhang},
  doi          = {10.1016/j.neucom.2022.11.021},
  journal      = {Neurocomputing},
  pages        = {36-43},
  shortjournal = {Neurocomputing},
  title        = {MUSE: Multi-faceted attention for signed network embedding},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised video summarization using deep non-local video
summarization networks. <em>NEUCOM</em>, <em>519</em>, 26–35. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video summarization is to extract effective information from videos to quickly obtain the most informative summary. Most of the existing video summarization methods use recurrent neural networks and their variants such as long and short-term memory (LSTM), to simulates the variable range time dependence between video frames. However, those methods can only process serial inputs of the video frames along with the hidden layer information from the previous time step, which affects the performance and the quality of video summarization. To tackle this issue, we present a deep non-local video summarization network (DN-VSN) for original video abstracts in this paper. Our unsupervised model treats video summarization as a sequence of decision problems. Given an input video, the probability that a video frame is selected as a part of the summary is obtained through a non-local convolutional network , and a strategy gradient algorithm of reinforcement learning is adopted for optimization in the training phase. The proposed method has been tested on four widely used datasets. The experimental results show the superiority of the proposed unsupervised model over the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Sha-Sha Zang and Hui Yu and Yan Song and Ru Zeng},
  doi          = {10.1016/j.neucom.2022.11.028},
  journal      = {Neurocomputing},
  pages        = {26-35},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised video summarization using deep non-local video summarization networks},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Output synchronization analysis and PD control for coupled
fractional-order neural networks with multiple weights. <em>NEUCOM</em>,
<em>519</em>, 17–25. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the output synchronization for multiple weighted coupled fractional-order neural networks (MWCFONNs) with certain and uncertain parameters, respectively. By utilizing the properties of Mittag–Leffler functions and the Laplace transform , some output synchronization criteria for MWCFONNs are established. Moreover, a proportional-derivative (PD) controller is proposed to deal with the output synchronization for MWCFONNs, and two output synchronization criteria are derived on the basis of the Lyapunov functional method and inequality techniques. Finally, two numerical examples are utilized to verify the effectiveness of the output synchronization criteria.},
  archive      = {J_NEUCOM},
  author       = {Yi-Tong Lin and Jin-Liang Wang and Chen-Guang Liu},
  doi          = {10.1016/j.neucom.2022.11.016},
  journal      = {Neurocomputing},
  pages        = {17-25},
  shortjournal = {Neurocomputing},
  title        = {Output synchronization analysis and PD control for coupled fractional-order neural networks with multiple weights},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Occluded prohibited object detection in x-ray images with
global context-aware multi-scale feature aggregation. <em>NEUCOM</em>,
<em>519</em>, 1–16. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prohibited Object Detection (POD) in X-ray images plays an important role in protecting public safety. Automatic and accurate POD is required to relieve the working pressure of security inspectors. However, the existing methods cannot obtain a satisfactory detection accuracy, and especially, the problem of object occlusion also has not been solved well. Therefore, in this paper, according to the specific characteristics of X-ray images as well as low-level and high-level features of Convolutional Neural Network (CNN), different feature enhancement strategies have been elaborately designed for occluded POD. First, a learnable Gabor convolutional layer is designed and embedded into the low layer of the network to enhance the network&#39;s capability to capture the edge and contour information of object. A Spatial Attention (SA) mechanism is then designed to weight the output features of the Gabor convolutional layer to enhance the spatial structure information of object and suppress the background noises simultaneously. For the high-level features, Global Context Feature Extraction (GCFE) module is proposed to extract multi-scale global contextual information of object. And, a Dual Scale Feature Aggregation (DSFA) module is proposed to fuse these global features with those of another layer. To verify the effectiveness of the proposed modules, they are embedded into typical one-stage and two-stage object detection frameworks, i.e., Faster R-CNN and YOLO v5L, obtaining POD-F and POD-Y methods, respectively. The proposed methods have been extensively evaluated on three publicly available benchmark datasets, namely SIXray, OPIXray and WIXray. The experimental results show that, compared with existing methods, the proposed POD-Y method can achieve a state-of-the-art detection accuracy. And POD-F can also achieve a competitive detection performance among the two-stage detection methods. 1},
  archive      = {J_NEUCOM},
  author       = {Chunjie Ma and Li Zhuo and Jiafeng Li and Yutong Zhang and Jing Zhang},
  doi          = {10.1016/j.neucom.2022.11.034},
  journal      = {Neurocomputing},
  pages        = {1-16},
  shortjournal = {Neurocomputing},
  title        = {Occluded prohibited object detection in X-ray images with global context-aware multi-scale feature aggregation},
  volume       = {519},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RFE-SRN: Image-text similarity reasoning network based on
regional feature enhancement. <em>NEUCOM</em>, <em>518</em>, 593–601.
(<a href="https://doi.org/10.1016/j.neucom.2022.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-text matching aims to make a connection between visual and natural information. Some of the current methods have made great progress by using global alignment between images and sentences and local alignment between the image region and its corresponding word. However, the importance of the correlation between global alignment and local alignment is ignored to some extends. Therefore, in this paper, we propose a new region feature enhancement-based image text similarity inference network. Firstly, the image region feature is enhanced by graph convolutional neural network , which is used to find the correlation among different image region features with the production of features’ sematic relationship. Secondly, we propose a vector-based similarity representation to describe local and global alignment with a more comprehensive way. Finally, a graph convolution neural network is introduced to construct a similarity graph for propagating correlation between local alignment and global alignment to every part. By testing on the MSCOCO and Flickr30k dataset, our proposed method shows great accuracy performance and competitiveness.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyu Yang and Chao Li and Dongzhong Zheng and Peng Wen and Guangqiang Yin},
  doi          = {10.1016/j.neucom.2022.11.003},
  journal      = {Neurocomputing},
  pages        = {593-601},
  shortjournal = {Neurocomputing},
  title        = {RFE-SRN: Image-text similarity reasoning network based on regional feature enhancement},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection with scalable variational gaussian process
via sensitivity analysis based on l2 divergence. <em>NEUCOM</em>,
<em>518</em>, 577–592. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the most important issues in supervised learning and there are a lot of different feature selection approaches in the literature. Among them one recent approach is to use Gaussian process (GP) because it can capture well the hidden relevance between the features of the input and the output. However, the existing feature selection approaches with GP suffer from the scalability problem due to high computational cost of inference with GP. Moreover, they use the Kullback–Leibler (KL) divergence in the sensitivity analysis for feature selection, but we show in this paper that the KL divergence underestimates the relevance of important features in some cases of classification. To remedy such drawbacks of the existing GP based approaches, we propose a new feature selection method with scalable variational Gaussian process (SVGP) and L 2 L2 divergence. With the help of SVGP the proposed method exploits given large data sets well for feature selection through so-called inducing points while avoiding the scalability problem. Moreover, we provide theoretical analysis to motivate the choice of L 2 L2 divergence for feature selection in both classification and regression. To validate the performance of the proposed method, we compare it with other existing methods through experiments with synthetic and real data sets.},
  archive      = {J_NEUCOM},
  author       = {Younghwan Jeon and Ganguk Hwang},
  doi          = {10.1016/j.neucom.2022.11.013},
  journal      = {Neurocomputing},
  pages        = {577-592},
  shortjournal = {Neurocomputing},
  title        = {Feature selection with scalable variational gaussian process via sensitivity analysis based on l2 divergence},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Safe reinforcement learning for affine nonlinear systems
with state constraints and input saturation using control barrier
functions. <em>NEUCOM</em>, <em>518</em>, 562–576. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a novel safe reinforcement learning (RL) control algorithm to solve safe optimal problems for discrete-time affine nonlinear systems , while the safety and convergence of the control algorithm are proven. The algorithm is proposed based on an adjusted policy iteration (PI) framework using only the measured data along the system trajectories in the environment. The adjusted PI algorithm combines with the system predictive information. Unlike most PI algorithms, an effective method of obtaining an initial safe and stable control policy is given here. In addition, control barrier functions (CBFs) and an input constraint function are introduced to augment reward functions. And the monotonically nonincreasing property of the iterative value function maintains the safe set forward invariant in the PI framework. Moreover, the safety and convergence of the proposed algorithm are proven in theory. Then, the design and implementation of the proposed algorithm are presented based on the identifier-actor-critic structure, where neural networks are employed to approximate the system dynamics, the iterative control policy, and the iterative value function, respectively. Finally, the simulation results illustrate the effectiveness and safety of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Shihan Liu and Lijun Liu and Zhen Yu},
  doi          = {10.1016/j.neucom.2022.11.006},
  journal      = {Neurocomputing},
  pages        = {562-576},
  shortjournal = {Neurocomputing},
  title        = {Safe reinforcement learning for affine nonlinear systems with state constraints and input saturation using control barrier functions},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A high-precision distributed neural processor for efficient
computation of a new distributed FxSMAP-l algorithm applied to real-time
active noise control systems. <em>NEUCOM</em>, <em>518</em>, 545–561.
(<a href="https://doi.org/10.1016/j.neucom.2022.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last decade, there has been growing interest in developing active noise cancellation (ANC) systems since they have emerged as a potential solution in the noise reduction of indoor or outdoor sources. Regarding the last point, if the users need to reduce the noise in some extended areas, a very-large amount of microphones and loudspeakers are required. As a consequence, the ANC system demands a large amount of computation. One potential solution can be given if the information is partitioned and distributed into several computing systems since the use of a centralized computing system could be insufficient. However, current distributed strategies demand a huge computationally cost. Therefore, the development of an efficient distributed ANC system to be applied in practical real-time ANC applications is a challenging task. Here, we present two contributions, which involve the development of a new variant of the filtered-x set membership affine projection-like algorithm to save a large amount of computational cost and the design of a FPGA-based distributed neural processor to efficiently simulate the proposed algorithm. Specifically, we improve two aspects to create a compact and high-performance distributed neural processor. The first aspect is linked to the improvement of the processing system. In particular, we make extraordinary efforts to optimize existing spiking neural arithmetic circuits , which are highly demanded in the computation of the proposed algorithm. The second improvement is related to the development of a new communication scheme based on cutting-edge variants of spiking neural P (SN P) systems to efficiently perform the data distribution between multiple FPGAs. To demonstrate the computational capabilities of the proposed FPGA-based distributed neural processor, we develop an acoustic sensor network as proof-of-concept. Our results have demonstrated that the proposed distributed FPGA-based neural processor can be used in practical real-time ANC applications.},
  archive      = {J_NEUCOM},
  author       = {Xochitl Maya and Luis Garcia and Angel Vazquez and Eduardo Pichardo and Juan-Carlos Sanchez and Hector Perez and Juan-Gerardo Avalos and Giovanny Sanchez},
  doi          = {10.1016/j.neucom.2022.11.017},
  journal      = {Neurocomputing},
  pages        = {545-561},
  shortjournal = {Neurocomputing},
  title        = {A high-precision distributed neural processor for efficient computation of a new distributed FxSMAP-L algorithm applied to real-time active noise control systems},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Refined probability distribution module for fine-grained
visual categorization. <em>NEUCOM</em>, <em>518</em>, 533–544. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual categorization is an important task in computer vision. Prior works on fine-grained visual categorization have paid much attention to addressing intra-class variation and inter-class similarity. However, they rarely study that task from the perspective of probability distribution. In this paper, we propose a novel refined probability distribution module based on deep convolutional neural network . Our module computes the probability of an image by fully utilizing the similarity information between images. Firstly, we use deep neural networks to obtain the initial probability distribution and extract features. Then, we build a network whose inputs are features for calculating image-to-image similarity scores. Finally, our module refines the initial probability distribution based on an effective batch random walk operation with similarity scores. Our module can be plugged into many deep convolutional neural networks. Experimental results show that our approach outperforms state-of-the-art methods on the CUB-200–2011, FGVC-Aircraft and Stanford Cars datasets respectively.},
  archive      = {J_NEUCOM},
  author       = {Peipei Zhao and Qiguang Miao and Hongsheng Li and Ruyi Liu and Yining Quan and Jianfeng Song},
  doi          = {10.1016/j.neucom.2022.10.004},
  journal      = {Neurocomputing},
  pages        = {533-544},
  shortjournal = {Neurocomputing},
  title        = {Refined probability distribution module for fine-grained visual categorization},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One for all: One-stage referring expression comprehension
with dynamic reasoning. <em>NEUCOM</em>, <em>518</em>, 523–532. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring Expression Comprehension (REC) is one of the most important tasks in visual reasoning that requires a model to detect the target object referred by a natural language expression. Among the proposed pipelines, the one-stage Referring Expression Comprehension (OSREC) has become the dominant trend since it merges the region proposal and selection stages. Many state-of-the-art OSREC models adopt a multi-hop reasoning strategy because a sequence of objects is frequently mentioned in a single expression which needs multi-hop reasoning to analyze the semantic relation . However, one unsolved issue of these models is that the number of reasoning steps needs to be pre-defined and fixed before inference, ignoring the varying complexity of expressions. In this paper, we propose a Dynamic Multi-step Reasoning Network , which allows the reasoning steps to be dynamically adjusted based on the reasoning state and expression complexity. Specifically, we adopt a Transformer module to memorize &amp; process the reasoning state and a Reinforcement Learning strategy to dynamically infer the reasoning steps. The work achieves the state-of-the-art performance or significant improvements on several REC datasets, ranging from RefCOCO (+, g) with short expressions, to Ref-Reasoning, a dataset with long and complex compositional expressions.},
  archive      = {J_NEUCOM},
  author       = {Zhipeng Zhang and Zhimin Wei and Zhongzhen Huang and Rui Niu and Peng Wang},
  doi          = {10.1016/j.neucom.2022.10.022},
  journal      = {Neurocomputing},
  pages        = {523-532},
  shortjournal = {Neurocomputing},
  title        = {One for all: One-stage referring expression comprehension with dynamic reasoning},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Depth-aware inverted refinement network for RGB-d salient
object detection. <em>NEUCOM</em>, <em>518</em>, 507–522. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in multi-modal feature fusion boost the development of RGB-D salient object detection (SOD), and many remarkable RGB-D SOD models have been proposed. However, though some existing methods consider fusing the cross-level multi-modal features, they ignore the difference between inter-level having the multi-modal details in convolutional neural networks (CNNs) based RGB-D SOD. Therefore, exploring the correlations and differences of cross-level multi-modal features is a critical issue. In this paper, we present a novel depth-aware inverted refinement network (DAIR) to progressively guide the cross-level multi-modal features through backward propagation, which considerably preserves the different level details with multi-modal cues. Specifically, we innovatively design an end-to-end inverted refinement network to guide cross-level and cross-modal learning for revealing complementary relations of the cross-modal. The inverted refinement network also refines the low-level spatial details by the high-level global contextual cues. In particular, considering the difference of multi-modal and the effect of depth quality, a depth-aware intensified module (DAIM) is proposed with capturing the paired relationship of the pixel-level and inter-channel for the depth map. It promotes the representative capability of the depth details. Extensive experiments on nine challenging RGB-D SOD datasets demonstrate remarkable performance boosting of our proposed model against the fourteen state-of-the-art (SOTA) RGB-D SOD approaches.},
  archive      = {J_NEUCOM},
  author       = {Lina Gao and Bing Liu and Ping Fu and Mingzhu Xu},
  doi          = {10.1016/j.neucom.2022.11.031},
  journal      = {Neurocomputing},
  pages        = {507-522},
  shortjournal = {Neurocomputing},
  title        = {Depth-aware inverted refinement network for RGB-D salient object detection},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Masked face recognition with convolutional visual
self-attention network. <em>NEUCOM</em>, <em>518</em>, 496–506. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the global outbreak of COVID-19, wearing face masks has been actively introduced as an effective public measure to reduce the risk of virus infection. This measure leads to the failure of face recognition in many cases. Therefore, it is very necessary to improve the recognition performance of masked face recognition (MFR). Inspired by the successful application of self-attention in computer vision, we propose a Convolutional Visual Self-Attention Network (CVSAN), which uses self-attention to augment the convolution operator. Specifically, this is achieved by connecting a convolutional feature map, which enforces local features , to a self-attention feature map that is capable of modeling long-range dependencies. Since there is currently no publicly available large-scale masked face data, we generate a Masked VGGFace2 dataset based on the face detection algorithm to train the CVSAN model. Experiments show that the CVSAN algorithm significantly improves the performance of MFR compared to other algorithms.},
  archive      = {J_NEUCOM},
  author       = {Yiming Ge and Hui Liu and Junzhao Du and Zehua Li and Yuheng Wei},
  doi          = {10.1016/j.neucom.2022.10.025},
  journal      = {Neurocomputing},
  pages        = {496-506},
  shortjournal = {Neurocomputing},
  title        = {Masked face recognition with convolutional visual self-attention network},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-scale reconstruction method for the anomaly
detection in stochastic dynamic networks. <em>NEUCOM</em>, <em>518</em>,
482–495. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalous edges and/or nodes is a challenging problem for dynamic networks, due to the spatio-temporal (ST) patterns and randomness underneath the time-varying topology and node attributes. Existing methods commonly ignore randomness, and the anomaly detectors would be sensitive, especially in highly variable dynamic networks. In this paper, a new reconstruction method, the multi-scale variational graph recurrent autoencoder (M-VGRAE), is designed to detect anomalies in stochastic dynamic networks. Overall, upon the framework of Learning from Pure Normal (LPN), the M-VGRAE is trained to reconstruct the normal nodes and edges, and is used to detect the anomalies that cannot be reconstructed well by the trained M-VGRAE. To reduce sensitivity against the high variability, the reconstruction of stochastic dynamic networks is performed in a multi-scale manner. Specifically, the randomness is modeled by introducing multiple latent random variables at each node, each of which models the local randomness of attributes and connectivity within the temporal neighborhoods in a specific hop and historical interval. Then, the local randomness is approximated by employing the variational autoencoder (VAE) with a designed multi-scale ST feature extractor based on graph neural networks and recurrent neural networks . By such design, the capture of ST patterns and the modeling of randomness are jointly achieved. To show the effectiveness of the M-VGRAE in detecting anomalous edges and nodes, experiments are conducted on four real-world datasets of dynamic networks. The results demonstrate that the M-VGRAE consistently outperforms the existing baselines in terms of AUC score on anomaly detection .},
  archive      = {J_NEUCOM},
  author       = {Chenming Yang and Hui Wen and Bryan Hooi and Yue Wu and Liang Zhou},
  doi          = {10.1016/j.neucom.2022.11.002},
  journal      = {Neurocomputing},
  pages        = {482-495},
  shortjournal = {Neurocomputing},
  title        = {A multi-scale reconstruction method for the anomaly detection in stochastic dynamic networks},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging angular distributions for improved knowledge
distillation. <em>NEUCOM</em>, <em>518</em>, 466–481. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation as a broad class of methods has led to the development of lightweight and memory efficient models, using a pre-trained model with a large capacity (teacher network) to train a smaller model (student network). Recently, additional variations for knowledge distillation, utilizing activation maps of intermediate layers as the source of knowledge, have been studied. Generally, in computer vision applications , it is seen that the feature activation learned by a higher-capacity model contains richer knowledge, highlighting complete objects while focusing less on the background. Based on this observation, we leverage the teacher’s dual ability to accurately distinguish between positive (relevant to the target object) and negative (irrelevant) areas. We propose a new loss function for distillation, called angular margin-based distillation (AMD) loss. AMD loss uses the angular distance between positive and negative features by projecting them onto a hypersphere, motivated by the near angular distributions seen in many feature extractors. Then, we create a more attentive feature that is angularly distributed on the hypersphere by introducing an angular margin to the positive feature. Transferring such knowledge from the teacher network enables the student model to harness the teacher’s higher discrimination of positive and negative features, thus distilling superior student models. The proposed method is evaluated for various student–teacher network pairs on four public datasets. Furthermore, we show that the proposed method has advantages in compatibility with other learning techniques, such as using fine-grained features, augmentation, and other distillation methods.},
  archive      = {J_NEUCOM},
  author       = {Eun Som Jeon and Hongjun Choi and Ankita Shukla and Pavan Turaga},
  doi          = {10.1016/j.neucom.2022.11.029},
  journal      = {Neurocomputing},
  pages        = {466-481},
  shortjournal = {Neurocomputing},
  title        = {Leveraging angular distributions for improved knowledge distillation},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). End-to-end feature diversity person search with rank
constraint of cross-class matrix. <em>NEUCOM</em>, <em>518</em>,
453–465. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person search aims to locate and identify specific persons from a series of uncropped images, which has achieved a significant impact on many human-related applications, e.g., person activity understanding and person tracking. Person search includes two sub-tasks: person detection and person re-identification. Person detection focuses on finding the commonality of all identities, while person re-identification focuses on finding the differences among different identities. To mitigate the impact of the different purposes of these two sub-tasks on a person search model, we split the ResNet50 network according to the sub-task, and propose a feature diversity person search (FDPS) framework based on the rank constraint of the cross-class matrix. We first construct a model called the split-baseline (S-bsl), and then introduce the deformable convolution to locate the entire person area. More importantly, a rank perception optimization (RPO) loss is proposed in the FDPS framework to enhance the discrimination and diversity of inter-class features. Experimental results on PRW and CUHK-SYSU datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yue Zhang and Shuqin Wang and Shichao Kan and Yigang Cen and Linna Zhang},
  doi          = {10.1016/j.neucom.2022.10.080},
  journal      = {Neurocomputing},
  pages        = {453-465},
  shortjournal = {Neurocomputing},
  title        = {End-to-end feature diversity person search with rank constraint of cross-class matrix},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Object-aware bounding box regression for online multi-object
tracking. <em>NEUCOM</em>, <em>518</em>, 440–452. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the detection technology, regressing predicted bounding boxes provides an effective approach in multiple object tracking. However, if only the information in the current frame is considered, identity (ID) switch is easy to happen when objects interact. In this paper, we propose an Object-Aware Bounding Box Regression (OABBR) for online multi-object tracking. We first propose an Object-Aware Spatial-Temporal Understanding (OASTU) module to mine the correlated information in corresponding object’s trajectory. OASTU updates features of predictions by the correlated information. By using the updated features, we further perform bounding box regression. Besides, to make features extracted by the backbone network contain more ID information, we construct a weak ID constraint in the training phase. The introduced weak ID constraint facilitates OASTU to be ID consistent and further alleviates ID switch. By exploring the spatial-temporal information in corresponding object’s trajectory, each prediction is able to know the information of the corresponding object, which makes the purpose of its regression clearer. Experimental results on four public benchmarks demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hongli Li and Yongsheng Dong and Xuelong Li},
  doi          = {10.1016/j.neucom.2022.11.004},
  journal      = {Neurocomputing},
  pages        = {440-452},
  shortjournal = {Neurocomputing},
  title        = {Object-aware bounding box regression for online multi-object tracking},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven predictive point-to-point iterative learning
control. <em>NEUCOM</em>, <em>518</em>, 431–439. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating the idea of predictive control and point-to-point iterative learning control , this paper presents a data-driven predictive point-to-point iterative learning control scheme for a class of unknown repetitive non-affine nonlinear SISO systems. The tracking task is driven by the optimal control input sequence generated by the proposed algorithm, and the tracking errors at the specified sampling time instants are minimized. The advantages of this scheme are that the structure of the controller and its stability analysis both are based on an equivalent dynamic linearization data model of the nonlinear system , and the proposed scheme does not involve the operation of matrix inversion. Numerical simulations verify the effectiveness of this method.},
  archive      = {J_NEUCOM},
  author       = {Xueming Zhang and Zhongsheng Hou},
  doi          = {10.1016/j.neucom.2022.11.014},
  journal      = {Neurocomputing},
  pages        = {431-439},
  shortjournal = {Neurocomputing},
  title        = {Data-driven predictive point-to-point iterative learning control},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can relearning local representation help small networks for
human pose estimation? <em>NEUCOM</em>, <em>518</em>, 418–430. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human pose estimation is a special detection task for small object localization. It requires considering not only global structure but local and fine detail due to variable body poses and complex scenes. However, with the sliding window learning mechanism, the convolutional neural network (CNN) can only see the spatial information in a specific size of receptive field in a certain layer. As the network deepens and the receptive field becomes larger, the network gradually focuses on the global spatial information and loses the perception of local features . To help the deep convolutional neural network have the ability to relearn local information for structure analysis in deeper layers, we propose a layer-channel mixed attention mechanism named integrated attention that can be flexibly embedded into a CNN. Multiple features from the previous layers are aggregated to build attention with synchronously observing different ranges of spatial structures. Through our integrated attention, the network can observe the interdependence between local structures across different receptive fields and more clues can be learned to enhance the expressive power of the network for feature learning . The results of extensive experiments show that the integrated attention mechanism is beneficial to human pose estimation. In particular, the integrated attention can help small networks achieve more accurate predictions and even outperforms larger ones with less computation and parameters. Compared with other attention and keypoint refinement modules, our improvement effect is more stable and better.},
  archive      = {J_NEUCOM},
  author       = {Dingning Xu and Lijun Guo and Rong Zhang and Jiangbo Qian and Shangce Gao},
  doi          = {10.1016/j.neucom.2022.11.025},
  journal      = {Neurocomputing},
  pages        = {418-430},
  shortjournal = {Neurocomputing},
  title        = {Can relearning local representation help small networks for human pose estimation?},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph neural networks meet with distributed graph
partitioners and reconciliations. <em>NEUCOM</em>, <em>518</em>,
408–417. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown great success in various applications. As real-world graphs are large, training GNNs in distributed systems is desirable. In current training schemes, their edge partitioning strategies have a strong impact on the performance of GNNs for the unbalanced influence of high-degree nodes and the damaged neighbor integrity of low-degree nodes. Meanwhile, a lack of reconciliations of different local models leads to converging up and down across workers. In this work, we design DEPR, a suitable framework for distributed GNN training. We propose a degree-sensitive edge partitioning with influence-balancing and locality-preserving to adapt distributed GNNs training by following an owner-compute rule (each partition performs all the computations involving data that it owns). And then knowledge distillation and contrastive learning are used to reconcile the fusion of local models and boost convergence. We show in extensive empirical experiments on the node classification task of three large-scale graph datasets (Reddit, Amazon, and OGB-Products) that DEPR achieves 2x speedup of convergence and get absolute up 3.97 performance improvement of F1-micro score compared to DistDGL.},
  archive      = {J_NEUCOM},
  author       = {Zongshen Mu and Siliang Tang and Chang Zong and Dianhai Yu and Yueting Zhuang},
  doi          = {10.1016/j.neucom.2022.09.096},
  journal      = {Neurocomputing},
  pages        = {408-417},
  shortjournal = {Neurocomputing},
  title        = {Graph neural networks meet with distributed graph partitioners and reconciliations},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal distributions of rewards for a two-armed slot
machine. <em>NEUCOM</em>, <em>518</em>, 401–407. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the continuous time two-armed bandit (TAB) problem where the slot machine has two different arms in the sense that the two arms have different expected rewards and variances. We explore the optimal distribution of rewards for two-armed bandit problems, and obtain the explicit distribution function as well as the searching rules of optimal strategy . As a by-product, we find two new counter-intuitive phenomena in nonlinear probability framework (optimal strategic framework). The first is that the combination of losing arm and winning arm can make the winning arm achieve a greater coverage probability to win expected reward, which is also referred to “good + bad = better”. The discovery implies that the traditional advice of always pursuing the arm with larger expected reward (i.e., stay on a winner rule) is not optimal in the probability framework. The second is that the combination sequence out of two independent and normal distribution-based arms is not normally distributed if the two arms are different, which is straightforward understood as “mutually independent normal + normal = unnormal”. Furthermore, we provide the optimal sequential strategy to construct the “combination” arm and numerically examine the underlying mechanism.},
  archive      = {J_NEUCOM},
  author       = {Zengjing Chen and Xinwei Feng and Shuhui Liu and Xiaodong Yan},
  doi          = {10.1016/j.neucom.2022.11.019},
  journal      = {Neurocomputing},
  pages        = {401-407},
  shortjournal = {Neurocomputing},
  title        = {Optimal distributions of rewards for a two-armed slot machine},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Robust multi-view learning with the bounded LINEX loss.
<em>NEUCOM</em>, <em>518</em>, 384–400. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning, as a promising direction, emphasizes the consensus principle and the complementarity principle to boost the performance. By exploiting view-consistency or view-discrepancy among different views, numerous successful multi-view support vector machine models have been proposed. However, existing methods face two challenges. Firstly, most multi-view support vector machine models only consider the consensus principle, but ignore the complementarity principle. How to build a novel model with both principles has not been fully considered. Secondly, most multi-view support vector machine models neglect the robustness when the multi-view dataset is contaminated by the noisy samples, error-prone samples and view-inconsistent samples. Considering that the bounded linear-exponential (BLINEX) loss function possesses elegant merits, i.e., asymmetry and boundedness, developing a robust BLINEX-based model is worth exploring. Therefore, in this paper, we propose a BLINEX-based multi-view learning method called MVASY-BX, which explores the consensus and complementarity information with a between-view co-regularization term and importance weights of two views respectively. The mixed BLINEX loss is designed to make the model robust to noisy samples, view-inconsistent samples and error-prone samples. We solve linear and nonlinear MVASY-BX through the stochastic sub-gradient descent algorithm and the alternating direction method of multipliers respectively. Furthermore, we analyze the generalization error bound via Rademacher complexity. The comprehensive experiments confirm that our proposed model is more competitive than other benchmark methods.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Tang and Hao He and Saiji Fu and Yingjie Tian and Gang Kou and Shan Xu},
  doi          = {10.1016/j.neucom.2022.10.078},
  journal      = {Neurocomputing},
  pages        = {384-400},
  shortjournal = {Neurocomputing},
  title        = {Robust multi-view learning with the bounded LINEX loss},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learn from structural scope: Improving aspect-level
sentiment analysis with hybrid graph convolutional networks.
<em>NEUCOM</em>, <em>518</em>, 373–383. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-level sentiment analysis aims to determine the sentiment polarity towards a specific target in a sentence. The main challenge of this task is to effectively model the relation between targets and sentiments so as to filter out noisy opinion words from irrelevant targets. Most recent efforts capture relations through target-sentiment pairs or opinion spans from a word-level or phrase-level perspective. Based on the observation that targets and sentiments essentially establish relations following the grammatical hierarchy of phrase-clause-sentence structure, it is hopeful to exploit comprehensive syntactic information for better guiding the learning process. Therefore, we introduce the concept of Scope , which outlines a structural text region related to a specific target. To jointly learn structural Scope and predict the sentiment polarity, we propose a hybrid graph convolutional network (HGCN) to synthesize information from constituency tree and dependency tree, exploring the potential of linking two syntax parsing methods to enrich the representation. Experimental results on five public datasets illustrate that our HGCN model outperforms current state-of-the-art baselines. More specifically, the average accuracy/ F 1 score improvements of our HGCN compared to baseline models on Restaurant 14, 15 and 16 are 2.46\%/5.36\%, 2.25\%/5.70\% and 1.73\%/5.50\%, while the performance improvements are 3.32\%/4.30\% and 2.50\%/3.08\% on the Laptop and Twitter datasets, respectively. Furthermore, when cascaded to five models, our method has significantly improved their performances by simplifying the sentence from multiple targets to a single one.},
  archive      = {J_NEUCOM},
  author       = {Lvxiaowei Xu and Xiaoxuan Pang and Jianwang Wu and Ming Cai and Jiawei Peng},
  doi          = {10.1016/j.neucom.2022.10.071},
  journal      = {Neurocomputing},
  pages        = {373-383},
  shortjournal = {Neurocomputing},
  title        = {Learn from structural scope: Improving aspect-level sentiment analysis with hybrid graph convolutional networks},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PSGAN: Revisit the binary discriminator and an alternative
for face frontalization. <em>NEUCOM</em>, <em>518</em>, 360–372. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial network (GAN) based face frontalization is a cheap and convenient way to eliminate the impact of pose variance on face recognition. The sigmoid cross-entropy loss function is usually employed for the discriminator in those GAN based face synthesis methods. There are two disadvantages for this loss function: 1) The discriminator always wins the generator easily at the beginning of training because the convergence of the discriminator and the generator is unbalanced; 2) The training of GANs becomes unstable due to the prediction boundary uncertainty and massive parameters of the traditional binary discriminator. In order to eliminate the impacts caused by the traditional discriminator in the general GANs, a Bayesian induced perceptual self-representation discriminator ( i.e. PSD ) is proposed, which can also maintain the identity information, and simultaneously reduce the model parameters and training difficulty. There are three key contributions in this work: 1) On the basis of PSD, a perceptual self-representation GAN ( i.e. PSGAN ) with a new architecture is proposed, which reduces the training difficulty without lowering the synthetic quality; 2) In order to further improve the performance of our method, multiple features extracted from different layers are adopted to constitute a multi-perceptual self-representation discriminator ( i.e. MPSD ); 3) The proposed PSD discriminator is more lightweight with fewer parameters and can also be easily plugged and played in various GANs. Extensive qualitative and quantitative experiments on both restricted and unrestricted face databases and non-facial datasets demonstrate its superiority.},
  archive      = {J_NEUCOM},
  author       = {Qingyan Duan and Lei Zhang and Yan Zhang and Xinbo Gao},
  doi          = {10.1016/j.neucom.2022.11.033},
  journal      = {Neurocomputing},
  pages        = {360-372},
  shortjournal = {Neurocomputing},
  title        = {PSGAN: Revisit the binary discriminator and an alternative for face frontalization},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection for distance-based regression: An umbrella
review and a one-shot wrapper. <em>NEUCOM</em>, <em>518</em>, 344–359.
(<a href="https://doi.org/10.1016/j.neucom.2022.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) may improve the performance, cost-efficiency, and understandability of supervised machine learning models. In this paper, FS for the recently introduced distance-based supervised machine learning model is considered for regression problems . The study is contextualized by first providing an umbrella review (review of reviews) of recent development in the research field. We then propose a saliency-based one-shot wrapper algorithm for FS, which is called MAS-FS . The algorithm is compared with a set of other popular FS algorithms, using a versatile set of simulated and benchmark datasets. Finally, experimental results underline the usefulness of FS for regression, confirming the utility of certain filter algorithms and particularly the proposed wrapper algorithm.},
  archive      = {J_NEUCOM},
  author       = {Joakim Linja and Joonas Hämäläinen and Paavo Nieminen and Tommi Kärkkäinen},
  doi          = {10.1016/j.neucom.2022.11.023},
  journal      = {Neurocomputing},
  pages        = {344-359},
  shortjournal = {Neurocomputing},
  title        = {Feature selection for distance-based regression: An umbrella review and a one-shot wrapper},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Low-light image enhancement with knowledge distillation.
<em>NEUCOM</em>, <em>518</em>, 332–343. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light image enhancement studies how to improve the quality of images captured under poor lighting conditions, which is of real-world importance. Currently, convolutional neural network (CNN)-based methods with state-of-the-art performance have become the mainstream of research. However, most CNN-based methods improve the performance of the algorithm by increasing the width and depth of the neural network , which requires large computing device resources. In this paper, we propose a knowledge distillation method for low light image enhancement. The proposed method uses a teacher-student framework in which the teacher network tries to transfer the rich knowledge to the student network. The student network learns the knowledge of image enhancement under the supervision of ground truth images and under the guidance of the teacher network simultaneously. Knowledge transfer between the teacher-student network is accomplished by distillation loss based on attention maps. We designed a gradient-guided low-light image enhancement network that can be divided into an enhancement branch and a gradient branch, where the enhancement branch is learned under the guidance of the gradient branch to better preserve structural information. The teacher and student networks use a similar structure, but they have different model sizes. The teacher network has more parameters and more powerful learning capabilities than the student network. With the help of knowledge distillation , our approach can improve the performance of the student network without increasing the computational burden during the testing phase. The qualitative and quantitative experimental results demonstrate the superiority of our method compared to the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Ziwen Li and Yuehuan Wang and Jinpu Zhang},
  doi          = {10.1016/j.neucom.2022.10.083},
  journal      = {Neurocomputing},
  pages        = {332-343},
  shortjournal = {Neurocomputing},
  title        = {Low-light image enhancement with knowledge distillation},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effects of feedback control in small-world neuronal networks
interconnected according to a human connectivity map. <em>NEUCOM</em>,
<em>518</em>, 321–331. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a phenomenological two-dimensional discrete model coupled in a structure of a clustered network to investigate the suppression of neuronal synchronization in a complex network. We constructed a network according to a weighted human connectivity matrix and an adjacency matrix that carries small-world properties. The coupling between neurons is inserted through a chemical synapse term and a neuronal activation function . The neuronal synchronization is measured by the Kuramoto order parameter. We intend to achieve the suppression of burst phase synchronization, and for that, we use a mathematical tool, based on the technique of deep brain stimulation , which consists of applying an external signal to the network after a certain time, causing the bursts to desynchronize. Our results are efficient when applying the feedback method both in the global network and in the cortical regions . We have seen that for cortical regions , synchronization is more difficult to suppress, however, by slightly increasing the perturbation, we are able to achieve the desired effect. This shows that it is possible to use the control efficiently in isolated cortical areas , therefore, we present a new alternative to conventional methods, avoiding to apply the control to the entire network to obtain the same results.},
  archive      = {J_NEUCOM},
  author       = {Adriane S. Reis and Eduardo L. Brugnago and Ricardo L. Viana and Antonio M. Batista and Kelly C. Iarosz and Iberê L. Caldas},
  doi          = {10.1016/j.neucom.2022.11.008},
  journal      = {Neurocomputing},
  pages        = {321-331},
  shortjournal = {Neurocomputing},
  title        = {Effects of feedback control in small-world neuronal networks interconnected according to a human connectivity map},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven analysis of global research trends in medical
image: A survey. <em>NEUCOM</em>, <em>518</em>, 308–320. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of artificial intelligence and high-performance computing equipment, new technologies have huge effects on medical image research. However, it is difficult to find out when new research topics appear, who those authors with influences are, and how relevant publications influence the academic community. In order to catch up with global research trends, traditional methods of literature review are inadequate to acquire information. In this case, a data-driven analysis offers a new quantitative approach to studying global research trends. Specifically, this paper used several basic bibliometric indexes to characterize the global trends of medical image research from 1993 to 2022, including yearly output, active journals, important authors, active institutions, and main countries. Furthermore, we utilized network-based methods to analyze the internal relations of co-word, co-authorship, and co-citation, so as to discover academic hotspots and clarify global research trends. Finally, some conclusions are drawn as follow: (1) The present medical image research is on an upward trend. The number of publications on medical image surged since 2015 due to advances in deep learning. Deep learning and convolutional neural networks (CNNs) are both popular research keywords in recent years. (2) IEEE Transactions on Medical Imaging is the most influential journal in view of Total Local Citation Score (TLCS) and Total Global Citation Score (TGCS), followed by Medical Image Analysis . Neurocomputing and Information Fusion are well-recognized in local research community. (3) Van Ginneken B and Aerts HJWL are representative scholars in consideration of TLCS and TGCS. (4) The USA is a leading country in medical image research. Other influential countries include China, India, UK, Germany, France, Canada, Netherlands, Australia, Italy, South Korea, Switzerland, etc. Most important institutions are from these countries, including Harvard , UMich , Stanford , UPenn , UNC , CAS , SJTU , UCL , UofT , RU , etc. (5) Application of artificial intelligence technologies, especially CNNs, has dramatically promoted global studies of medical image since 2015. Interdisciplinary collaborations become popular among experts with different disciplines backgrounds. We can infer that medical image analysis and application based on deep learning will still be a flourishing field in the near future with the improvement of algorithms and the application of high-performance computing equipment.},
  archive      = {J_NEUCOM},
  author       = {Chao Fan and Kai Hu and Yuyi Yuan and Yu Li},
  doi          = {10.1016/j.neucom.2022.10.047},
  journal      = {Neurocomputing},
  pages        = {308-320},
  shortjournal = {Neurocomputing},
  title        = {A data-driven analysis of global research trends in medical image: A survey},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic event-triggered-based single-network ADP optimal
tracking control for the unknown nonlinear system with constrained
input. <em>NEUCOM</em>, <em>518</em>, 294–307. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an event-triggered-based optimal tracking control scheme for the unknown nonlinear system with unmeasurable state, constrained input, and limited communication. Firstly, an event-triggered Hamilton–Jacobi-Bellman (HJB) equation is derived based on an augmented system and a discounted cost function. Next, a novel online event-triggered-based neural networks (NNs) observer (NNsO) is constructed to obtain the unmeasurable state and the unknown system dynamics. Then, a single critic neural network (NN) based on the adaptive dynamic programming (ADP) framework is established to solve the event-triggered HJB equation, and the designed critic NN weight updating law can relax the restrictions of initial admissible control and persistence of excitation condition. Furthermore, a static triggering rule with an exponential term is designed to reduce communication and computing burden, and based on this, a dynamic triggering rule is established by introducing an auxiliary dynamic variable to obtain efficient communication and computing. It is proved that the tracking error and all the NN weight estimation errors are uniformly ultimately bounded (UUB), and the Zeno behavior is excluded. Finally, two simulation examples are presented to verify the effectiveness and superiority of the proposed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Haoming Zou and Guoshan Zhang},
  doi          = {10.1016/j.neucom.2022.11.015},
  journal      = {Neurocomputing},
  pages        = {294-307},
  shortjournal = {Neurocomputing},
  title        = {Dynamic event-triggered-based single-network ADP optimal tracking control for the unknown nonlinear system with constrained input},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrated nonholonomic multi-robot consensus tracking
formation using neural-network-optimized distributed model predictive
control strategy. <em>NEUCOM</em>, <em>518</em>, 282–293. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For constructing a distributed consensus formation scheme for the two-wheel mobile robots with directed communication topology and nonholonomic constraints, in this work, an integrated leader–follower consensus formation framework using neural-network-optimized distributed model predictive control (NNODMPC) strategy is presented. The proposed leader–follower formation framework can be regarded as integrating a consensus trajectories planning subsystem (CTPS) and a consensus tracking subsystem. The CTPS can plan the consensus trajectories for the mobile robots through a leader–follower structure, and in the consensus tracking subsystem, the robots are guided to the consensus. To simultaneously control these two subsystems, the NNODMPC based protocol is applied. The errors and constraints of the integrated system can be incorporated and formulated into a constrained quadratic programming (QP) problem whose optimal solution can be obtained by a primal–dual neural networks (PDNN) QP optimizer. Stability analysis illustrates the convergence of the proposed DMPC-based consensus formation system. The novelties of this work are rooted in the construction of a generalized consensus formation scheme for the practical wheeled robots with nonholonomic constraints, the formulation of an MPC-based distributed consensus controller and the consideration of system constraints. The experimental results on the mobile robots are conducted to verify the effectiveness of the proposed strategy.},
  archive      = {J_NEUCOM},
  author       = {Hanzhen Xiao and C.L. Philip Chen and Guanyu Lai and Dengxiu Yu and Yun Zhang},
  doi          = {10.1016/j.neucom.2022.11.007},
  journal      = {Neurocomputing},
  pages        = {282-293},
  shortjournal = {Neurocomputing},
  title        = {Integrated nonholonomic multi-robot consensus tracking formation using neural-network-optimized distributed model predictive control strategy},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural-network-based boundary control for a gantry crane
system with unknown friction and output constraint. <em>NEUCOM</em>,
<em>518</em>, 271–281. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a neural-network-based boundary control method for a gantry system with unknown friction and output constraint. Firstly, to tackle the unknown friction, a radial basis function neural network (RBFNN) is adopted to approximate it. Secondly, we employ a barrier Lyapunov function to handle the output constraint problem. Then, a neural-network-based boundary controller is proposed to deal with the aforementioned problems. Subsequently, based on the Lyapunov stability approach, the uniformly ultimately bounded stability of the state of the closed-loop system is guaranteed. Finally, the effectiveness of the developed control method is illustrated through both numerical simulations and physical experiments.},
  archive      = {J_NEUCOM},
  author       = {Ling Ma and Xuyang Lou and Jiajia Jia},
  doi          = {10.1016/j.neucom.2022.11.010},
  journal      = {Neurocomputing},
  pages        = {271-281},
  shortjournal = {Neurocomputing},
  title        = {Neural-network-based boundary control for a gantry crane system with unknown friction and output constraint},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI meets UAVs: A survey on AI empowered UAV perception
systems for precision agriculture. <em>NEUCOM</em>, <em>518</em>,
242–270. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision Agriculture (PA) promises to boost crop productivity while reducing agricultural costs and environmental footprints, and therefore is attracting ever-increasing interests in both academia and industry. This management strategy is underpinned by various advanced technologies including Unmanned Aerial Vehicle (UAV) sensing systems and Artificial Intelligence (AI) perception algorithms. In particular, due to their unique advantages such as a low cost, high spatio-temporal resolutions, flexibility, automation functions and minimized risk of operation, UAV sensing systems have been extensively applied in many civilian applications including PA since 2010. In parallel, AI algorithms (deep learning since 2012 in particular) are also drawing ever-increasing attention in different fields, since they are able to analyse an unprecedented volume/velocity/variety of data (semi-) automatically, which are also becoming computationally practical with the advancements of cloud computing , Graphics Processing Units and parallel computing . In this survey paper, therefore, a thorough review is performed on recent use of UAV sensing systems (e.g., UAV platforms, external sensing units) and AI algorithms (mainly supervised learning algorithms) in PA applications throughout the crop life-cycle, as well as the challenges and prospects for future development of UAVs and AI in agriculture sector. It is envisioned that this review is able to provide a timely technical reference, demystifying and promoting research, deployment and successful exploitation of AI empowered UAV perception systems for PA, and therefore contributing to addressing future agricultural and human nutrition challenges.},
  archive      = {J_NEUCOM},
  author       = {Jinya Su and Xiaoyong Zhu and Shihua Li and Wen-Hua Chen},
  doi          = {10.1016/j.neucom.2022.11.020},
  journal      = {Neurocomputing},
  pages        = {242-270},
  shortjournal = {Neurocomputing},
  title        = {AI meets UAVs: A survey on AI empowered UAV perception systems for precision agriculture},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair classification by loss balancing via fairness-aware
batch sampling. <em>NEUCOM</em>, <em>518</em>, 231–241. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing classification models often output discriminatory results since they learn the target attribute without addressing data imbalance with respect to the protected attributes (e.g., gender). The models tend to focus on learning toward demographic groups containing the larger number of training samples, which consequently leads to training loss discrepancy between the groups. Our work focuses on addressing the occurrence of training loss discrepancy between the groups to improve the model’s fairness. To this end, we firstly define the target-protected group using the target and protected attribute labels and observe the group-wise training loss in terms of previous fairness approaches. From the observation, we figure out that balancing the total loss across all the groups allows to mitigate fairness issue significantly, and meanwhile, only considering the sample size of each group to obtain a balanced mini-batch is not enough for mitigating fairness. Motivated by the observations, we propose a fairness-aware batch sampling scheme that adaptively updates batch sampling probability ( BSP ) and constructs a fairness-aware mini-batch from the model’s point of view. Our key idea is to balance the training losses via training with fairness-aware mini-batch. Through extensive experiments on two facial attribute benchmark datasets and one tabular dataset, our simple and effective sampling strategy achieves superior improvement in terms of two standard fairness metrics. We validate our algorithm with various experimental settings (e.g, multi-attribute classification, binary classification with multiple protected attributes). Moreover, we introduce a new metric for measuring the trade-off between fairness and classification performance. On this metric, our algorithm also achieves the best trade-off performance.},
  archive      = {J_NEUCOM},
  author       = {Dohyung Kim and Sungho Park and Sunhee Hwang and Hyeran Byun},
  doi          = {10.1016/j.neucom.2022.11.018},
  journal      = {Neurocomputing},
  pages        = {231-241},
  shortjournal = {Neurocomputing},
  title        = {Fair classification by loss balancing via fairness-aware batch sampling},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A top-k POI recommendation approach based on LBSN and
multi-graph fusion. <em>NEUCOM</em>, <em>518</em>, 219–230. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {POI(Point of Interest) recommendation is a basic and on-going issue in LBSN (Location-based Social Network) services. In this paper, a novel POI recommendation approach which is based on LBSN and multi-graph fusion is proposed. First, we take advantages of the graph neural network to construct user-POI interaction graph based on the rating data of users and construct user social graph based on the user social networks. First-order friends and high-order friends will be considered simultaneously in the user social graph. And then, we present a spectral cluster-based algorithm to gain the latent vector of the POI in location space. After this, the graph neural network is used to learn the information above. Lastly, we predict the score based on the aforementioned information and pick out the top- k POIs with the highest scores to form a recommendation list. Extensive experiments conducted on real datasets demonstrated that the method proposed in this paper can effectively generate the embedding vectors of users and POIs, and can achieve high recommendation accuracy as well.},
  archive      = {J_NEUCOM},
  author       = {Jinfeng Fang and Xiangfu Meng and Xueyue Qi},
  doi          = {10.1016/j.neucom.2022.10.048},
  journal      = {Neurocomputing},
  pages        = {219-230},
  shortjournal = {Neurocomputing},
  title        = {A top-k POI recommendation approach based on LBSN and multi-graph fusion},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). View position prior-supervised light field angular
super-resolution network with asymmetric feature extraction and
spatial-angular interaction. <em>NEUCOM</em>, <em>518</em>, 206–218. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light field imaging can record the intensity and direction information of light rays in space, which attracts extensive attention. However, the trade-off between angular and spatial resolution cannot be avoided due to the limitation of sensors in commercial light field cameras. To mitigate this problem, this paper proposes the view position prior-supervised light field angular super-resolution network with asymmetric feature extraction and spatial-angular interaction. First, there is a severe information asymmetry between the spatial and angular dimensions in light fields with sparse views. The asymmetric feature extraction block is proposed to extract spatial and angular features with different receptive fields in an asymmetric manner. As a result, more light field intrinsic features are extracted, which improves the utilization rate of the limited light field information. Second, the existing methods usually ignore the correlations among the newly synthesized views. The spatial-angular interaction module is proposed to collect the local and global information, build relations between any two points in the feature space, and reconstruct light field consistencies. Thus, the complete view correlations can be established. Last but not least, we investigate the impact of the given views on each viewpoint and propose a loss function based on the view position prior, which reduces the quality difference among the synthesized sub-aperture images and further improves the network performance. Comprehensive experiments demonstrate that our method can perform best on all datasets, and the depth estimation results present a new perspective to show the superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yanlong Cao and Lingyu Wang and Lifei Ren and Jiangxin Yang and Yanpeng Cao},
  doi          = {10.1016/j.neucom.2022.10.043},
  journal      = {Neurocomputing},
  pages        = {206-218},
  shortjournal = {Neurocomputing},
  title        = {View position prior-supervised light field angular super-resolution network with asymmetric feature extraction and spatial-angular interaction},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A practical tutorial on solving optimization problems via
PlatEMO. <em>NEUCOM</em>, <em>518</em>, 190–205. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PlatEMO is an open-source platform for solving complex optimization problems , which provides a variety of metaheuristics including evolutionary algorithms, swarm intelligence algorithms, multi-objective optimization algorithms, surrogate-assisted optimization algorithms, and many others. Due to the problem-independent nature of most metaheuristics, they are versatile for solving problems with various difficulties such as multimodal landscapes, discrete search spaces, multiple objectives, strict constraints, and expensive evaluations, regardless of the fields the problems belong to. Since PlatEMO was published in 2017, it has been used by many researchers from both academia and industry in the computational intelligence community. However, the basic terms and concepts about optimization may confuse practitioners and junior researchers new to metaheuristics. Hence, this paper presents a practical introduction to the use of PlatEMO 4.0, focusing on the procedures of defining problems, selecting suitable metaheuristics, and collecting results. Note, however, that a description of the technical details of metaheuristics is beyond the scope of this paper and interested readers may refer to the cited references.},
  archive      = {J_NEUCOM},
  author       = {Ye Tian and Weijian Zhu and Xingyi Zhang and Yaochu Jin},
  doi          = {10.1016/j.neucom.2022.10.075},
  journal      = {Neurocomputing},
  pages        = {190-205},
  shortjournal = {Neurocomputing},
  title        = {A practical tutorial on solving optimization problems via PlatEMO},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When friendship meets sequential human check-ins: Inferring
social circles with variational mobility. <em>NEUCOM</em>, <em>518</em>,
174–189. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pervasiveness of mobile devices and the popularity of positioning technology generate diverse location-based social network platforms, which allow users to share POIs, post messages, and make online friends. Trajectory-based social circle inference (TSCI), aiming at inferring the social ties based on human mobility data, is one of the fundamental tasks that may facilitate a range of downstream applications such as group recommendation/advertising and crowdsourcing. Despite their promising results on TSCI, existing solutions still confront with three major challenges, including (1) inadequate representation learning ability of contextual information in the sparse check-in data; (2) the lack of a more generalized trajectory encoding mechanism for mobility pattern discovering; and (3) the neglect of modeling the explicit label correlations. To overcome these challenges, we propose a Graph-based Social Circle Inference (GSCI) framework to exploit implicit human mobility patterns and integrate the inherent correlations among social ties of users. We propose to integrate POI’s contextual information into a density representation from the perspective of graph learning rather than solely relying on the sequential visiting behaviors . We also introduce a mobility-specific end-to-end paradigm with variational attention for learning human mobility regularity, by which our GSCI can encode more meaningful and disentangled patterns into the trajectory representations. Besides, we design a graph neural network-based classifier to model the intrinsic associations among user connections which can significantly improve the inference performance. Extensive experiments conducted on real-world mobility datasets demonstrate the superiority of our proposed framework compared with the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Qiang Gao and Fan Zhou and Xin Yang and Guisong Liu},
  doi          = {10.1016/j.neucom.2022.10.049},
  journal      = {Neurocomputing},
  pages        = {174-189},
  shortjournal = {Neurocomputing},
  title        = {When friendship meets sequential human check-ins: Inferring social circles with variational mobility},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Power normalized cepstral robust features of deep neural
networks in a cloud computing data privacy protection scheme.
<em>NEUCOM</em>, <em>518</em>, 165–173. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) have developed rapidly in data privacy protection applications such as medical treatment and finance. However, DNNs require high-speed and high-memory computers in terms of computation, otherwise training can be very lengthy. Furthermore, DNNs are often not available in resource-constrained mobile devices . Therefore, training and executing DNNs are increasingly using cloud computing . In the paper, the Power Normalized Cepstrum-based Robust Feature Detector (PNC-RFD), with deep learning in the cloud computing, is proposed for data privacy protection. The proposed PNC-RFD extracts a specified number of signal segments of high robustness used to embed and extract various data. For the sake of embedding and extracting the data, a method of information hiding employing Dual-Tree Complex Wavelet Packet Transform (DT CWPT) is therefore presented. The presented scheme simultaneously embeds multiple data into coefficients of the DT CWPT of signal segments. By embedding the data into the orthogonal spaces, the proposed method ensures the independent extraction of the multiple data. In line with the performance analysis, the superiority of the presented scheme is elaborated through making the comparison with the current state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Mianjie Li and Zhihong Tian and Xiaojiang Du and Xiaochen Yuan and Chun Shan and Mohsen Guizani},
  doi          = {10.1016/j.neucom.2022.11.001},
  journal      = {Neurocomputing},
  pages        = {165-173},
  shortjournal = {Neurocomputing},
  title        = {Power normalized cepstral robust features of deep neural networks in a cloud computing data privacy protection scheme},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Camera-aware representation learning for person
re-identification. <em>NEUCOM</em>, <em>518</em>, 155–164. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (ReID) aims to associate the same person across non-overlapping cameras. However, most of existing works neglect the issue of camera-imbalanced data distribution. Consequently, pedestrian representation learning gives preference to the head cameras, which have comparatively more training data, and disregards the tail cameras, which have relatively less training data. In this paper, we propose a novel framework for camera-aware representation learning to overcome this issue, named CARL . On the proxy level representation learning , CARL presents a multiple-center softmax loss to correct the head camera bias and presents a hard sub-center mining strategy to improve the discrimination of tail camera samples. On the pair-wise level representation learning , CARL builds a camera-balanced memory bank ( CBM ) to re-balance the sample pair distribution and proposes a camera-paired loss for pair-wise metric learning. Extensive experiments and ablation studies on MSMT17, the current largest ReID dataset with massive camera-imbalanced data distribution, demonstrate that our CARL is superior to previous metric learning based ReID methods and achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Jinlin Wu and Yuxin Yang and Zhen Lei and Yang Yang and Shukai Chen and Stan Z. Li},
  doi          = {10.1016/j.neucom.2022.11.009},
  journal      = {Neurocomputing},
  pages        = {155-164},
  shortjournal = {Neurocomputing},
  title        = {Camera-aware representation learning for person re-identification},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Study of the performance and scalability of federated
learning for medical imaging with intermittent clients. <em>NEUCOM</em>,
<em>518</em>, 142–154. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a data decentralization privacy-preserving technique used to perform machine or deep learning in a secure way. In this paper we present theoretical aspects about federated learning, such as the presentation of an aggregation operator, different types of federated learning, and issues to be taken into account in relation to the distribution of data from the clients, together with the exhaustive analysis of a use case where the number of clients varies. Specifically, a use case of medical image analysis is proposed, using chest X-ray images obtained from an open data repository. In addition to the advantages related to privacy, improvements in predictions (in terms of accuracy, loss and area under the curve) and reduction of execution times will be studied with respect to the classical case (the centralized approach). Different clients will be simulated from the training data, selected in an unbalanced manner. The results of considering three or ten clients are exposed and compared between them and against the centralized case. Two different problems related to intermittent clients are discussed, together with two approaches to be followed for each of them. Specifically, this type of problems may occur because in a real scenario some clients may leave the training, and others enter it, and on the other hand because of client technical or connectivity problems . Finally, improvements and future work in the field are proposed.},
  archive      = {J_NEUCOM},
  author       = {Judith Sáinz-Pardo Díaz and Álvaro López García},
  doi          = {10.1016/j.neucom.2022.11.011},
  journal      = {Neurocomputing},
  pages        = {142-154},
  shortjournal = {Neurocomputing},
  title        = {Study of the performance and scalability of federated learning for medical imaging with intermittent clients},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive neural network finite-time control for nonlinear
cyber-physical systems with external disturbances under malicious
attacks. <em>NEUCOM</em>, <em>518</em>, 133–141. (<a
href="https://doi.org/10.1016/j.neucom.2022.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the finite-time tracking control problem for a class of high-order nonlinear cyber-physical systems (CPSs) with external disturbances, which are subject to malicious attacks occurring in controller-actuator (C-A) channel. Combining the variable structure (VS) control method and the artificial neural network (NN) technique, a novel adaptive neural network finite-time control strategy is developed. In particular, a Gaussian radial basis function neural network (RBFNN) is designed as an adaptive neural estimator working in an online manner to achieve the estimation and reconstruction of malicious attacks and external disturbances. Furthermore, rigorous proofs have been presented to show that the proposed control scheme can guarantee that the output tracking error converges to the origin in finite time. Finally, the proposed control scheme is applied to heavy duty vehicle system (HDVS) as a testbed , and a representative simulation is provided to demonstrate the validity and effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zhaoyang Cuan and Da-Wei Ding and Yongliang Yang and Yunxia Xia},
  doi          = {10.1016/j.neucom.2022.11.012},
  journal      = {Neurocomputing},
  pages        = {133-141},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural network finite-time control for nonlinear cyber-physical systems with external disturbances under malicious attacks},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge enhancement improves adversarial robustness in image
classification. <em>NEUCOM</em>, <em>518</em>, 122–132. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imperceptible adversarial examples are capable of deceiving the deep neural networks with high confidence. Recent studies show that it is particularly effective to control the attack space to low-frequency components of the image on the basis of adversarial training . However, those methods face the problem of losing valuable knowledge, especially shape information, which is vital for classification and robustness. To alleviate this issue, we propose a new method based on edge detection, named Edge Enhancement (EE), which can explicitly make up for the missing shape information in frequency constraints and further enhance the adversarial robustness. Specifically, we first employ a traditional edge detection algorithm called Canny to obtain shape information due to its simplicity and intrinsic robustness. Then, we augment the low-frequency space via obtained shape features, with the weighting operation carried on. This operation can be regarded as an emphasis on shape information, which could mitigate the texture bias of deep neural networks , thereby further serving the robustness. Finally, we feed the augmented features into the deep neural network. It is worth noting that these modules are optimized along with the deep neural network, which enables an end-to-end training fashion. Experimental results show that our proposed model can significantly improve adversarial robustness over the state-of-the-art methods on three benchmark datasets, including MNIST, Tiny ImageNet, and particularly ImageNet. For example, our method achieves 51.66\% accuracy on ImageNet under 10-iteration targeted PGD white-box attack where the prior art has 36.94\% accuracy. Code is available at https://github.com/Aiqz/Edge-Enhancement.},
  archive      = {J_NEUCOM},
  author       = {Lirong He and Qingzhong Ai and Yuqing Lei and Lili Pan and Yazhou Ren and Zenglin Xu},
  doi          = {10.1016/j.neucom.2022.10.059},
  journal      = {Neurocomputing},
  pages        = {122-132},
  shortjournal = {Neurocomputing},
  title        = {Edge enhancement improves adversarial robustness in image classification},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decoupled dynamic group equivariant filter for saliency
prediction on omnidirectional image. <em>NEUCOM</em>, <em>518</em>,
111–121. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current saliency prediction models based on convolutional neural networks (CNNs) achieve solid improvement in predicting human attention on omnidirectional image (ODI). However, these models that employ standard convolution have two main shortcomings: content-agnostic and computation-intensive. To address these two shortcomings, we propose a decoupled dynamic group equivariant filter (DDGF). Specifically, inspired by the attention mechanism that adopts light-weight branches for estimating spatial and channel attention, we decouple group equivariant convolution ( i.e. p4 convolution) into spatial and channel dynamic group equivariant filters. Such a design not only makes p4 convolution filter adaptive to ODI content, but also considerably reduces computational cost. To our best knowledge, the DDGF is the first decoupled dynamic convolution filter that applied to the task of saliency prediction. Meanwhile, we observe that it is effective and efficient when replacing standard group equivariant convolution with DDGF in ODI saliency prediction. Experimental results show that the proposed DDGF can achieve superior performance in comparison with other state-of-the-art methods. Additionally, we conduct ablation experiments to verify the effectiveness of each component of the proposed DDGF.},
  archive      = {J_NEUCOM},
  author       = {Dandan Zhu and Kaiwei Zhang and Guokai Zhang and Qiangqiang Zhou and Xiongkuo Min and Guangtao Zhai and Xiaokang Yang},
  doi          = {10.1016/j.neucom.2022.09.107},
  journal      = {Neurocomputing},
  pages        = {111-121},
  shortjournal = {Neurocomputing},
  title        = {Decoupled dynamic group equivariant filter for saliency prediction on omnidirectional image},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gaussian-type activation function with learnable parameters
in complex-valued convolutional neural network and its application for
PolSAR classification. <em>NEUCOM</em>, <em>518</em>, 95–110. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To process complex-valued information such as SAR signals conveniently, the complex-valued convolutional neural network (CV-CNN) has been proposed in recent years, and it has achieved great success in SAR image recognition. This paper proposes an activation function with learnable parameters based on the Gaussian-type activation function (GTAF) in CV-CNN to improve the utilization of information in the real and imaginary parts of the neuro. For the multi-channel input of the feature map, this paper discusses two ways to set the parameters of the Gaussian-type activation function. One is that all channels share the same parameters, called the channel-sharing Gaussian-type activation function (CSGTAF). The other is that each channel has its independent parameters, called the channel-exclusive Gaussian-type activation function (CEGTAF). In addition, this paper derives the backpropagation formula of both CSGTAF and CEGTAF in detail for the training process of CV-CNN. This paper performs experimental analysis on three L-band standard PolSAR datasets. The experimental results show that, compared with the traditional method and the Gaussian activation function with fixed parameters, both CSGTAF and CEGTAF achieve higher recognition accuracy, and the difference in the recognition effect of different targets in the same dataset is little. Both show good recognition performance and have good stability and versatility.},
  archive      = {J_NEUCOM},
  author       = {Yun Zhang and Qinglong Hua and Haotian Wang and Zhenyuan Ji and Yong Wang},
  doi          = {10.1016/j.neucom.2022.10.082},
  journal      = {Neurocomputing},
  pages        = {95-110},
  shortjournal = {Neurocomputing},
  title        = {Gaussian-type activation function with learnable parameters in complex-valued convolutional neural network and its application for PolSAR classification},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online time-series forecasting using spiking reservoir.
<em>NEUCOM</em>, <em>518</em>, 82–94. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT-based automated systems require efficient online time-series analysis and forecasting and there is a growing requirement to enable such processing at the low-cost constrained edge devices. Classical approaches such as Online Autoregressive Integrated Moving Average (Online ARIMA), Seasonal ARIMA (SARIMA) etc. and Artificial Neural Network (ANN) based techniques including Long-short Term Memory (LSTM) do not cater to this niche requirement due to their memory and computation power requirements. Neuromorphic computing and bio-plausible spiking neural networks , being both data and energy efficient, may offer a better solution. In this work, a novel spiking reservoir based network is proposed for online time series forecasting that relies on temporal spike encoding with a feedback driven online learning mechanism. The proposed network is capable of avoiding rapidly fading memory problem. The prediction accuracy of the network (tested on nine time-series datasets) outperforms conventional methods like SARIMA, Online ARIMA, Stacked LSTM, achieving up to 8\% higher R2 score while using negligible buffer memory.},
  archive      = {J_NEUCOM},
  author       = {Arun M. George and Sounak Dey and Dighanchal Banerjee and Arijit Mukherjee and Manan Suri},
  doi          = {10.1016/j.neucom.2022.10.067},
  journal      = {Neurocomputing},
  pages        = {82-94},
  shortjournal = {Neurocomputing},
  title        = {Online time-series forecasting using spiking reservoir},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Value activation for bias alleviation: Generalized-activated
deep double deterministic policy gradients. <em>NEUCOM</em>,
<em>518</em>, 70–81. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is vital to accurately estimate the value function in Deep Reinforcement Learning (DRL) such that the agent could execute proper actions instead of suboptimal ones. However, existing actor-critic methods suffer more or less from underestimation bias or overestimation bias, which negatively affect their performance. In this paper, we reveal a simple but effective principle: proper value correction benefits bias alleviation , where we propose the generalized-activated weighting operator that uses any non-decreasing function, namely activation function, as weights for better value estimation. Particularly, we integrate the generalized-activated weighting operator into value estimation and introduce a novel algorithm, Generalized-activated Deep Double Deterministic Policy Gradients (GD3). We theoretically show that GD3 is capable of alleviating the potential estimation bias. We interestingly find that simple activation functions lead to satisfying performance with no additional tricks, and could contribute to faster convergence. Experimental results on numerous challenging continuous control tasks show that GD3 with task-specific activation outperforms the common baseline methods. We also uncover a fact that fine-tuning the polynomial activation function achieves superior results on most of the tasks. Codes will be available upon publication.},
  archive      = {J_NEUCOM},
  author       = {Jiafei Lyu and Yu Yang and Jiangpeng Yan and Xiu Li},
  doi          = {10.1016/j.neucom.2022.10.085},
  journal      = {Neurocomputing},
  pages        = {70-81},
  shortjournal = {Neurocomputing},
  title        = {Value activation for bias alleviation: Generalized-activated deep double deterministic policy gradients},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of natural images inspired by the human
visual system. <em>NEUCOM</em>, <em>518</em>, 60–69. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a three-step model based on the integration of Deep Neural Networks (DNN) and Decision Models is introduced for image classification which is inspired by the human visual system . To make a decision about an object, many actions should be done in a hierarchical process in the brain. First, the retina receives visual stimuli and transfers them to the visual cortex in the brain. The information extracted in the visual cortex , is accumulated over time to select an appropriate response. Many of the current decision-making models do not show how each image is converted into useful information for the decision model. Some models have used neural networks to convert each image into the information needed in the decision-making model; however, the role of the retina is ignored among these models. In this paper, a combination of retina inspired filters, CNN-based description and accumulator-based decision model is used to classify images. This model’s structure resembles the human brain due to the usage of the DoG filter bank as retina inspired filter in the first stage of it. This model shows a significant improvement in accuracy in comparison to other models; furthermore, its performance is acceptable even with the small sample training set.},
  archive      = {J_NEUCOM},
  author       = {Paria Davoodi and Mehdi Ezoji and Naser Sadeghnejad},
  doi          = {10.1016/j.neucom.2022.10.055},
  journal      = {Neurocomputing},
  pages        = {60-69},
  shortjournal = {Neurocomputing},
  title        = {Classification of natural images inspired by the human visual system},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of long sequential data using circular
dilated convolutional neural networks. <em>NEUCOM</em>, <em>518</em>,
50–59. (<a href="https://doi.org/10.1016/j.neucom.2022.10.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of long sequential data is an important Machine Learning task and appears in many application scenarios. Recurrent Neural Networks, Transformers, and Convolutional Neural Networks are three major techniques for learning from sequential data. Among these methods, Temporal Convolutional Networks (TCNs) which are scalable to very long sequences have achieved remarkable progress in time series regression. However, the performance of TCNs for sequence classification is not satisfactory because they use a skewed connection protocol and output classes at the last position. Such asymmetry restricts their performance for classification which depends on the whole sequence. In this work, we propose a symmetric multi-scale architecture called Circular Dilated Convolutional Neural Network (CDIL-CNN), where every position has an equal chance to receive information from other positions at the previous layers. Our model gives classification logits in all positions, and we can apply a simple ensemble learning to achieve a better decision. We have tested CDIL-CNN on various long sequential datasets. The experimental results show that our method has superior performance over many state-of-the-art approaches. The model and experiments are available at (https://github.com/LeiCheng-no/CDIL-CNN).},
  archive      = {J_NEUCOM},
  author       = {Lei Cheng and Ruslan Khalitov and Tong Yu and Jing Zhang and Zhirong Yang},
  doi          = {10.1016/j.neucom.2022.10.054},
  journal      = {Neurocomputing},
  pages        = {50-59},
  shortjournal = {Neurocomputing},
  title        = {Classification of long sequential data using circular dilated convolutional neural networks},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unpaired referring expression grounding via bidirectional
cross-modal matching. <em>NEUCOM</em>, <em>518</em>, 39–49. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring expression grounding is an important and challenging task in computer vision. To avoid the laborious annotation in conventional referring grounding, unpaired referring grounding is introduced, where the training data only contains a number of images and queries without correspondences. The few existing solutions to unpaired referring grounding are still preliminary, due to the challenges of learning vision-language correlation and lack of the top-down guidance with unpaired data. Existing works are only able to learn vision-language correlation by modality conversion, where critical information are lost. They also heavily rely on pre-extracted object proposals and thus cannot generate correct predictions with defective proposals. In this paper, we propose a novel bidirectional cross-modal matching (BiCM) framework to address these challenges. Particularly, we design a query-aware attention map (QAM) module that introduces top-down perspective via generating query-specific visual attention maps to avoid the over-reliance on pre-extracted object proposals. A cross-modal object matching (COM) module is further introduced to predict the target objects from a bottom-up perspective. This module exploits the recently emerged image-text matching pretrained model, CLIP, to learn cross-modal correlation without modality conversion. The top-down and bottom-up predictions are then integrated via a similarity fusion (SF) module. We also propose a knowledge adaptation matching (KAM) module that leverages unpaired training data to adapt pretrained knowledge to the target dataset and task. Experiments show that our framework significantly outperforms previous works on five grounding datasets.},
  archive      = {J_NEUCOM},
  author       = {Hengcan Shi and Munawar Hayat and Jianfei Cai},
  doi          = {10.1016/j.neucom.2022.10.079},
  journal      = {Neurocomputing},
  pages        = {39-49},
  shortjournal = {Neurocomputing},
  title        = {Unpaired referring expression grounding via bidirectional cross-modal matching},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatio-temporal segments attention for skeleton-based action
recognition. <em>NEUCOM</em>, <em>518</em>, 30–38. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing the dependencies between joints is critical in skeleton-based action recognition. However, the existing methods cannot effectively capture the correlation of different joints between frames, which is very useful since different body parts (such as the arms and legs in “long jump”) between adjacent frames move together. Focus on this issue, a novel spatio-temporal segments attention method is proposed. The skeleton sequence is divided into several segments, and several consecutive frames contained in each segment are encoded. And then an intra-segment self-attention module is proposed to capture the relationship of different joints in consecutive frames. In addition, an inter-segment action attention module is introduced to capture the relationship between segments to enhance the ability to distinguish similar actions. Compared with the state-of-the-art methods, our method achieves better performance on two large-scale datasets.},
  archive      = {J_NEUCOM},
  author       = {Helei Qiu and Biao Hou and Bo Ren and Xiaohua Zhang},
  doi          = {10.1016/j.neucom.2022.10.084},
  journal      = {Neurocomputing},
  pages        = {30-38},
  shortjournal = {Neurocomputing},
  title        = {Spatio-temporal segments attention for skeleton-based action recognition},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A descriptive analysis of olfactory sensation and memory in
drosophila and its relation to artificial neural networks.
<em>NEUCOM</em>, <em>518</em>, 15–29. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a background and descriptive analysis of insect memory and the coding of olfactory sensation in Drosophila , presenting graphs and summary statistics from a large dataset of neurons and synapses that was recently made publicly available and also discussing findings from the existing empirical literature. Some general principles from Drosophila olfaction are discussed as they apply to the design of analogous systems in artificial neural networks : (1) the networks used for coding are shallow; (2) the level of connectedness varies widely across neurons in the same layer; (3) much communication is between neurons in the same layer; (4) in most olfactory learning, the manner in which sensory inputs are represented in stored memory is largely fixed, and the learning process involves developing positive or negative associations with existing categories of inputs.},
  archive      = {J_NEUCOM},
  author       = {Chris Rohlfs},
  doi          = {10.1016/j.neucom.2022.10.068},
  journal      = {Neurocomputing},
  pages        = {15-29},
  shortjournal = {Neurocomputing},
  title        = {A descriptive analysis of olfactory sensation and memory in drosophila and its relation to artificial neural networks},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Plug and play augmented HQS: Convergence analysis and its
application in MRI reconstruction. <em>NEUCOM</em>, <em>518</em>, 1–14.
(<a href="https://doi.org/10.1016/j.neucom.2022.10.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse recovery in the context of the inverse problem has become an enormously popular technique in reconstructing various degraded images in various applications. One of the well-known techniques in modularizing these particular inverse problems is the Plug and Play Half-Quadratic-Splitting (PnP-HQS). This method has been demonstrated to achieve good results in the literature; however, it is still too plain to be fully exploited for reconstruction. In this regard, we introduce an augmented version of this technique dubbed “PnP-AugHQS” to efficiently utilize its capabilities in image reconstruction. We provide a comprehensive convergence analysis of the proposed algorithm to ensure its effectiveness in image reconstruction. We then exploit the new parameters to further modify the procedure of the conventional PnP in order to account for the noise in the measurement. The PnP-AugHQS is equipped with a compact deep Convolutional Neural Network denoising regularization to maximize its power in image recovery. As a special case, we further modified the algorithm to be used in the application of MRI reconstruction. Various experiments evaluated on the proposed algorithm showed the superiority of the PnP-AugHQS compared to the PnP-HQS and other state-of-the-art techniques in MRI reconstruction.},
  archive      = {J_NEUCOM},
  author       = {Arash Rasti-Meymandi and Aboozar Ghaffari and Emad Fatemizadeh},
  doi          = {10.1016/j.neucom.2022.10.061},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Plug and play augmented HQS: Convergence analysis and its application in MRI reconstruction},
  volume       = {518},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TD-net: Trans-deformer network for automatic pancreas
segmentation. <em>NEUCOM</em>, <em>517</em>, 279–293. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient pancreas segmentation is the basis for subsequent diagnosis and qualitative treatment of pancreatic cancer. Segmenting the pancreas from abdominal CT images is a challenging task because the morphology of the pancreas varies greatly among different individuals and may be affected by problems such as the unbalanced category and blurred boundaries. This paper proposes a two-stage Trans-Deformer network to solve these problems of pancreas segmentation. To be specific, we first use 2D Unet for coarse segmentation to generate candidate regions of the pancreas. In the fine segmentation stage, we propose to integrate deformable convolution into Vision Transformer (VIT) for solving the deformation problem of the pancreas. For the problem of blurred boundaries caused by low contrast in the pancreas, a multi-input module based on wavelet decomposition is proposed to make our network pay more attention to high-frequency texture information. In addition, we propose using the Scale Inter-active Fusion (SIF) module to merge local features and global features. Our method was evaluated on the public NIH dataset including 82 abdominal contrast-enhanced CT volumes and the public MSD dataset including 281 abdominal contrast-enhanced CT volumes via fourfold cross-validation. We have achieved the average Dice Similarity Coefficient (DSC) values of 89.89 ± 1.82\% on the NIH dataset, and 91.22 ± 1.37\% on the MSD dataset, outperforming other exiting state-of-the-art pancreas segmentation methods.},
  archive      = {J_NEUCOM},
  author       = {Shunbo Dai and Yu Zhu and Xiaoben Jiang and Fuli Yu and Jiajun Lin and Dawei Yang},
  doi          = {10.1016/j.neucom.2022.10.060},
  journal      = {Neurocomputing},
  pages        = {279-293},
  shortjournal = {Neurocomputing},
  title        = {TD-net: Trans-deformer network for automatic pancreas segmentation},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accurate iris segmentation and recognition using an
end-to-end unified framework based on MADNet and DSANet.
<em>NEUCOM</em>, <em>517</em>, 264–278. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their insufficient generalization ability, iris segmentation algorithms based on deep learning cannot accurately segment iris images without corresponding ground truth (GT) data. Moreover, prior to recognition, the segmented image requires normalization to reduce the influence of pupil deformation. However, normalization of nonconnected iris regions will introduce noise, thereby decreasing the recognition rate. This paper proposes an end-to-end unified framework based on deep learning that does not include normalization in order to achieve improved accuracy in iris segmentation and recognition. In this framework, a multiattention dense connection network (MADNet) and dense spatial attention network (DSANet) are designed for iris segmentation and recognition, respectively. Finally, numerous ablation experiments are conducted to demonstrate the effectiveness of MADNet and DSANet. Experiments on three employed databases show that our proposed method achieves the best segmentation and recognition performance on low-quality iris images without corresponding GT data.},
  archive      = {J_NEUCOM},
  author       = {Ying Chen and Huimin Gan and Huiling Chen and Yugang Zeng and Liang Xu and Ali Asghar Heidari and Xiaodong Zhu and Yuanning Liu},
  doi          = {10.1016/j.neucom.2022.10.064},
  journal      = {Neurocomputing},
  pages        = {264-278},
  shortjournal = {Neurocomputing},
  title        = {Accurate iris segmentation and recognition using an end-to-end unified framework based on MADNet and DSANet},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty meets fixed-time control in neural networks.
<em>NEUCOM</em>, <em>517</em>, 257–263. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fixed-time stability on uncertain neural networks with adaptive coupling strength is addressed in this paper. To beign with, a new time-varying coupling strength is introduced, which is based on the projective transform of quantized error systems. Next, to address various disturbances in master-slave systems, inhomogeneous uncertainty is taken into consideration. Then, a multi-quantized fixed-time controller is put forward to ensure that the systems reach to a prescribed trajectory in the settling time. Afterward, sufficient synchronization criteria are derived on the strength of the Lyapunov stability theorem. Finally, simulation examples are given to validate the theoretical analysis.},
  archive      = {J_NEUCOM},
  author       = {Yukun Song and Shengqin Jiang and Yu Liu and Shuiming Cai and Xiaobo Lu},
  doi          = {10.1016/j.neucom.2022.10.051},
  journal      = {Neurocomputing},
  pages        = {257-263},
  shortjournal = {Neurocomputing},
  title        = {Uncertainty meets fixed-time control in neural networks},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking general underwater object detection: Datasets,
challenges, and solutions. <em>NEUCOM</em>, <em>517</em>, 243–256. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we conduct a comprehensive study of Underwater Object Detection (UOD). UOD has evolved into an attractive research field in the computer vision community in recent years. However, existing UOD datasets collected from specific underwater scenes are limited in the number of images, categories, resolution, and environmental challenges. These limitations can lead to the settings and effectiveness of models trained on existing datasets being impaired in general underwater situations. These limitations also constrain the comprehensive exploration of UOD. To alleviate these issues, we first present a new real-world UOD dataset called RUOD that places UOD in the context of general scene understanding. The dataset contains 14,000 high-resolution images, 74,903 labeled objects, and 10 common aquatic categories. The dataset also has various marine objects and rich environmental challenges including haze-like effects, color casts, and light interference. Second, we conduct extensive and systematic experiments on RUOD to evaluate the development of general underwater scene detection from the perspective of algorithms, complex marine objects, and environmental challenges. The findings from these explorations highlight the challenges of UOD and suggest promising solutions and new directions for UOD. Finally, UOD in practice typically uses underwater image enhancement during preprocessing to improve image quality. We thus characterize object detection performance on enhanced images and find an effective auxiliary framework of image enhancement for UOD. Our dataset is available at https://github.com/dlut-dimt/RUOD.},
  archive      = {J_NEUCOM},
  author       = {Chenping Fu and Risheng Liu and Xin Fan and Puyang Chen and Hao Fu and Wanqi Yuan and Ming Zhu and Zhongxuan Luo},
  doi          = {10.1016/j.neucom.2022.10.039},
  journal      = {Neurocomputing},
  pages        = {243-256},
  shortjournal = {Neurocomputing},
  title        = {Rethinking general underwater object detection: Datasets, challenges, and solutions},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust projection twin extreme learning machines with capped
l1-norm distance metric. <em>NEUCOM</em>, <em>517</em>, 229–242. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we incorporate the idea of projection twin support vector machines (PTSVM) into the basic framework of twin extreme learning machines (TELM) and first propose a novel binary classifier named projection twin extreme learning machines (PTELM). PTELM is to seek two projection directions in the TELM feature space, such that the projected samples of one class are well separated from those of the other class. Compared with the PTSVM, PTELM tackles nonlinear cases without using several fixed kernel functions, thus PTELM is less sensitive to use specified parameters and can get better classification accuracy. Then, a new capped L 1 L1 -norm PTELM (C L 1 L1 -PTELM) is proposed by introducing capped L 1 L1 -norm distance metric in PTELM to reduce the effect of outliers. C L 1 L1 -PTELM overcomes the disadvantages of L 2 L2 -norm distance metric and hinge loss. Thus, C L 1 L1 -PTELM enhances the robust performance of our PTELM. Finally, two effective algorithms are designed to solve the problem of PTELM and to deal with the challenge of C L 1 L1 -PTELM brought by non-convex optimization problem, respectively. Simultaneously, we theoretically prove the convergence and local optimality of C L 1 L1 -PTELM algorithm. Numerical experiments on three synthetic datasets and several UCI datasets show the feasibility and effectiveness of our proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Yang Yang and Zhenxia Xue and Jun Ma and Xia Chang},
  doi          = {10.1016/j.neucom.2022.09.156},
  journal      = {Neurocomputing},
  pages        = {229-242},
  shortjournal = {Neurocomputing},
  title        = {Robust projection twin extreme learning machines with capped l1-norm distance metric},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TSFEDL: A python library for time series spatio-temporal
feature extraction and prediction using deep learning. <em>NEUCOM</em>,
<em>517</em>, 223–228. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of convolutional and recurrent neural networks is a promising framework. This arrangement allows the extraction of high-quality spatio-temporal features together with their temporal dependencies. This fact is key for time series prediction problems such as forecasting, classification or anomaly detection, amongst others. In this paper, the TSFE DL TSFEDL library is introduced. It compiles 22 state-of-the-art methods for both time series feature extraction and prediction, employing convolutional and recurrent deep neural networks for its use in several data mining tasks. The library is built upon a set of Tensorflow + Keras and PyTorch modules under the AGPLv3 license. The performance validation of the architectures included in this proposal confirms the usefulness of this Python package.},
  archive      = {J_NEUCOM},
  author       = {Ignacio Aguilera-Martos and Ángel M. García-Vico and Julián Luengo and Sergio Damas and Francisco J. Melero and José Javier Valle-Alonso and Francisco Herrera},
  doi          = {10.1016/j.neucom.2022.10.062},
  journal      = {Neurocomputing},
  pages        = {223-228},
  shortjournal = {Neurocomputing},
  title        = {TSFEDL: A python library for time series spatio-temporal feature extraction and prediction using deep learning},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DIIK-net: A full-resolution cross-domain deep interaction
convolutional neural network for MR image reconstruction.
<em>NEUCOM</em>, <em>517</em>, 213–222. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acquiring incomplete k-space matrices is an effective way to accelerate Magnetic Resonance Imaging (MRI). It is an important and challenging task to accurately reconstruct images from such under-sampled k-space matrices. On the one hand, neither image-domain oriented nor frequency-domain oriented deep Convolutional Neural Networks can simultaneously employ both frequency features and spatial features for cooperatively improving reconstruction accuracy . On the other hand, existing dual-domain reconstruction methods adopt heavy encoder-decoder frameworks, resulting in low efficiency and information loss in the process of pooling. To deal with these problems, in this paper, we propose a full-resolution dual-domain reconstruction network, called DIIK-Net. The DIIK-Net consists of a full-resolution frequency-domain branch, a full-resolution image-domain branch, and cross-domain interaction modules between the two branches. The first novelty of the proposed method is that the features of each block of frequency-domain branch are extracted by 1 × 1 1×1 filters, which reduces computational cost and captures rich contextual information. Due to the fact that an element in frequency domain conveys information of the whole image, 1 × 1 1×1 convolutional blocks are able to extract large contextual information with the interaction of image domain. The second novelty is that the image-domain branch consists of a very small number of 3 × 3 3×3 convolutional blocks and each block has very large field of perception due to integration of frequency domain. The third novelty lies in the simple and effective cross-domain interaction module. Experimental results on the challenging fastMRI dataset demonstrate that the proposed method is capable of achieving higher reconstruction accuracy with a few number of parameters.},
  archive      = {J_NEUCOM},
  author       = {Yu Liu and Yanwei Pang and Xiaohan Liu and Yiming Liu and Jing Nie},
  doi          = {10.1016/j.neucom.2022.09.048},
  journal      = {Neurocomputing},
  pages        = {213-222},
  shortjournal = {Neurocomputing},
  title        = {DIIK-net: A full-resolution cross-domain deep interaction convolutional neural network for MR image reconstruction},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extended dissipativity-based synchronization of markov jump
neural networks subject to partially known transition and mode detection
information. <em>NEUCOM</em>, <em>517</em>, 201–212. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the extended dissipativity-based synchronization problem of Markov jump neural networks with partially known probability information by using a detector from the hidden Markov model , where the partially known probability may exist in one of the transition probability matrix and detection probability matrix, or both of them simultaneously. By using such a hidden Markov model , an extended stochastic dissipative synchronization criterion for neural networks with partially known probability information is established, and a novel design method is given with the help of an improved activation function dividing method. Finally, the validity of the proposed approach is demonstrated by two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Ziwei Li and Zongjie Chen and Ting Fang and Hao Shen},
  doi          = {10.1016/j.neucom.2022.10.066},
  journal      = {Neurocomputing},
  pages        = {201-212},
  shortjournal = {Neurocomputing},
  title        = {Extended dissipativity-based synchronization of markov jump neural networks subject to partially known transition and mode detection information},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient subsampling of realistic images from GANs
conditional on a class or a continuous variable. <em>NEUCOM</em>,
<em>517</em>, 188–200. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve image quality, subsampling or refining images generated from (unconditional) generative adversarial networks (GANs) has received much attention recently. These methods are less effective or inefficient, however, for conditional GANs (cGANs) that either condition on a class (i.e., class-conditional GANs) or a continuous variable (i.e., continuous cGANs or CcGANs). Thus, we introduce a novel subsampling scheme for cGANs: conditional density ratio rejection sampling (cDR-RS). Specifically, cDR-RS comprises an improved feature extraction mechanism and a conditional Softplus loss (cSP). We also derive an error bound for the density ratio model trained with the cSP loss. Fake images are accepted or rejected based on the improved estimated conditional density ratio. An additional filtering scheme further increases fake images’ label consistency without losing diversity when sampling from CcGANs. We extensively test the effectiveness and efficiency of cDR-RS in sampling from both class-conditional GANs and CcGANs on six benchmark datasets. Experimental results demonstrate that the proposed method can achieve state-of-the-art performances in subsampling both types of conditional GANs.},
  archive      = {J_NEUCOM},
  author       = {Xin Ding and Yongwei Wang and Z. Jane Wang and William J. Welch},
  doi          = {10.1016/j.neucom.2022.10.070},
  journal      = {Neurocomputing},
  pages        = {188-200},
  shortjournal = {Neurocomputing},
  title        = {Efficient subsampling of realistic images from GANs conditional on a class or a continuous variable},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual attention-based siamese CNN with SoftmaxFocal loss
for laser-induced damage change detection of optical elements.
<em>NEUCOM</em>, <em>517</em>, 173–187. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With high-energy laser irradiating, the laser-induced damages may occur in the surfaces of optical elements in laser facilities. As the laser-induced damage changes can badly affect regular and healthy operation of laser facilities, it is essential to effectively detect real damage changes while suppressing meaningless and spurious changes in captured optical images. In order to achieve high-precision laser-induced damage change detection, this paper presents a novel deep learning model which exploits visual attention-based siamese convolutional neural network with SoftmaxFocal loss and significantly improves the performance of damage change detection. In the proposed model, an end-to-end classification network is designed and trained which fuses the spatial-channel domain collaborative attention modules into siamese convolutional neural network thus achieving more efficient feature extraction and representation. For the purpose of addressing the unbalanced distribution of hard and easy samples, a novel loss function which is termed as SoftmaxFocal loss is put forward to train the proposed network. The SoftmaxFocal loss creatively introduces an additive focusing term into original softmax loss which greatly enhances the online hard sample mining ability of the proposed model. Experiments conducted on three real datasets demonstrate the validity and superiority of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Jingwei Kou and Tao Zhan and Deyun Zhou and Yu Xie and Zhengshang Da and Maoguo Gong},
  doi          = {10.1016/j.neucom.2022.10.074},
  journal      = {Neurocomputing},
  pages        = {173-187},
  shortjournal = {Neurocomputing},
  title        = {Visual attention-based siamese CNN with SoftmaxFocal loss for laser-induced damage change detection of optical elements},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent actor-critic with time dynamical opponent model.
<em>NEUCOM</em>, <em>517</em>, 165–172. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-agent reinforcement learning , multiple agents learn simultaneously while interacting with a common environment and each other. Since the agents adapt their policies during learning, not only the behavior of a single agent becomes non-stationary, but also the environment as perceived by the agent. This renders it particularly challenging to perform policy improvement. In this paper, we propose to exploit the fact that the agents seek to improve their expected cumulative reward and introduce a novel Time Dynamical Opponent Model (TDOM) to encode the knowledge that the opponent policies tend to improve over time. We motivate TDOM theoretically by deriving a lower bound of the log objective of an individual agent and further propose Multi-Agent Actor-Critic with Time Dynamical Opponent Model (TDOM-AC). We evaluate the proposed TDOM-AC on a differential game and the Multi-agent Particle Environment. We show empirically that TDOM achieves superior opponent behavior prediction during test time. The proposed TDOM-AC methodology outperforms state-of-the-art Actor-Critic methods on the performed tasks in cooperative and especially in mixed cooperative-competitive environments. TDOM-AC results in a more stable training and a faster convergence. Our code is available at https://github.com/Yuantian013/TDOM-AC .},
  archive      = {J_NEUCOM},
  author       = {Yuan Tian and Klaus-Rudolf Kladny and Qin Wang and Zhiwu Huang and Olga Fink},
  doi          = {10.1016/j.neucom.2022.10.045},
  journal      = {Neurocomputing},
  pages        = {165-172},
  shortjournal = {Neurocomputing},
  title        = {Multi-agent actor-critic with time dynamical opponent model},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An imbalanced binary classification method based on
contrastive learning using multi-label confidence comparisons within
sample-neighbors pair. <em>NEUCOM</em>, <em>517</em>, 148–164. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For imbalanced classification, data-level methods can achieve inter-class balance, but the samples generated do not contain new information and cannot avoid the problem of introducing noise. Algorithm-level methods may lead to overfitting of the model, and its classification effect is more dependent on the specific dataset and classification task , which means they lack universality. In addition, how to deeply mine the differences in the distribution of data overlap areas, and how to effectively mine the differences between categories when the absolute number of minority samples is small, are also important challenges in imbalanced classification. This paper proposes an imbalanced binary classification method using multi-label confidence comparisons based on contrastive learning . Different from the previous idea of directly learning its distribution characteristics from minority samples, combined with the idea of contrastive learning, the classification task is redefined as the multi-label matching task by mining the deep features that can represent the commonality and difference between the neighboring samples. Multiple differentiated contrastive sample groups are obtained through random sampling in its neighbor sample pool for each sample. This sample is combined with its contrastive sample groups to form multiple sample-neighbor pairs as training samples in the multi-label matching task. The original dataset is multiplied without introducing noise, laying a foundation for the effective mining of class differences when the absolute number of minority class samples is small. Based on the corresponding reconstruction error generated by Variational AutoEncoder (VAE), for sample-neighbor pairs, a multi-label matching loss between target samples and contrastive sample groups that integrates the idea of contrastive learning is designed. a robust classifier is obtained through simultaneous iterative learning of reconstruction error and multi-label matching loss, which can better mine the distribution differences of overlapping regions. In the testing phase, multiple different contrastive sample groups and the corresponding prediction results of the samples to be classified are obtained, which categories can be judged by integrating the predictions of each group for reverse reasoning. Experimental results on 38 public datasets show that the method outperforms typical imbalanced classification methods in both F1-measure and G-mean.},
  archive      = {J_NEUCOM},
  author       = {Xin Gao and Zhihang Meng and Xin Jia and Jing Liu and Xinping Diao and Bing Xue and Zijian Huang and Kangsheng Li},
  doi          = {10.1016/j.neucom.2022.10.069},
  journal      = {Neurocomputing},
  pages        = {148-164},
  shortjournal = {Neurocomputing},
  title        = {An imbalanced binary classification method based on contrastive learning using multi-label confidence comparisons within sample-neighbors pair},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decentralized event-triggered adaptive neural network
control for nonstrict-feedback nonlinear interconnected systems with
external disturbances against intermittent DoS attacks. <em>NEUCOM</em>,
<em>517</em>, 133–147. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the issue of decentralized event-triggered adaptive neural network (NN) control for nonstrict-feedback nonlinear interconnected systems with external disturbances and intermittent denial-of-service (DoS) attacks. In the presence of DoS attack, all state variables are not used to design a feedback controller via the standard backstepping method. To solve this problem, a novel switching-type adaptive state observer with a disturbance compensation is constructed, where the disturbance compensation is obtained via constructing a disturbance observer. A decentralized event-triggered adaptive controller is designed by using the backstepping method to weaken the influences of DoS attack and the waste of communication resources, where a first-order sliding mode differentiator is introduced to prevent the “calculation explosion”. By using linear matrix inequality techniques, some solvable sufficient conditions are attained to derive the observer gain. The closed-loop system is proved to be stable via the improved average dell time method and the piecewise Lyapunov stability theories. This control scheme ensures that all closed-loop signals remain bounded. Finally, simulation results are utilized to demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yahui Cui and Haibin Sun and Linlin Hou},
  doi          = {10.1016/j.neucom.2022.10.056},
  journal      = {Neurocomputing},
  pages        = {133-147},
  shortjournal = {Neurocomputing},
  title        = {Decentralized event-triggered adaptive neural network control for nonstrict-feedback nonlinear interconnected systems with external disturbances against intermittent DoS attacks},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Safe reinforcement learning for discrete-time fully
cooperative games with partial state and control constraints using
control barrier functions. <em>NEUCOM</em>, <em>517</em>, 118–132. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel safe reinforcement learning is proposed for fully cooperative games of discrete-time multi-player systems with partial state and control constraints. The fully cooperative game is a special case of the nonzero-sum games where all players cooperate to accomplish the common task. However, there are few works for fully cooperative game issues of discrete-time systems with partial state and control constraints. The issue is addressed by our algorithm based on the constrained value iteration framework using the measured data along the system trajectories , and the Nash equilibrium of the constrained fully cooperative game is achieved. Compared to previous methods for fully cooperative game issues, neither the accurate system dynamics nor the initial admissible control policies are required via the algorithm. Meanwhile, the discrete-time exponential control barrier functions are adopted to address the issue of state constraints. Moreover, the convergence of the proposed algorithm is proven in theory. Then, the system dynamics, the control policies and the value function are approximated by the three-layer neural networks , respectively. Finally, two experiments are presented to demonstrate the safety and effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Shihan Liu and Lijun Liu and Zhen Yu},
  doi          = {10.1016/j.neucom.2022.10.058},
  journal      = {Neurocomputing},
  pages        = {118-132},
  shortjournal = {Neurocomputing},
  title        = {Safe reinforcement learning for discrete-time fully cooperative games with partial state and control constraints using control barrier functions},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised feature selection via discrete spectral
clustering and feature weights. <em>NEUCOM</em>, <em>517</em>, 106–117.
(<a href="https://doi.org/10.1016/j.neucom.2022.10.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing unsupervised feature selection methods learn the cluster structure through spectral clustering , and then use various regression models to introduce the data matrix into the indicator matrix to obtain feature selection matrix. In these methods, the clustering indicator matrix is usually continuous value, which is not the best choice for the matrix in terms of its supervising role in feature selection. Based on this, unsupervised feature selection via discrete spectral clustering and feature weights (FSDSC) is proposed in this paper. First, FSDSC integrates regression model and spectral clustering in a unified framework for feature selection, and introduces a feature weight matrix, which intuitively expresses the importance of each feature with its diagonal elements. Compared with the common feature selection matrix that requires constraints such as sparse regular items, the appearance of the feature weight matrix reduces the complexity of the model and simplifies the calculation process of feature evaluation. Secondly, for the value of the indicators matrix, the spectral clustering is improved to obtain a discrete clustering indicator matrix, which provides clearer guidance information for feature selection. Finally, in order to avoid trivial solutions , the transformation matrix is constrained by orthogonal constraint. The combination of the orthogonal regression model and spectral clustering enables the algorithm to perform feature selection and manifold information learning at the same time, thereby preserving the local geometric structure of data. Compared with other excellent unsupervised feature selection algorithms, the experimental results prove the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Ronghua Shang and Jiarui Kong and Lujuan Wang and Weitong Zhang and Chao Wang and Yangyang Li and Licheng Jiao},
  doi          = {10.1016/j.neucom.2022.10.053},
  journal      = {Neurocomputing},
  pages        = {106-117},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised feature selection via discrete spectral clustering and feature weights},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memristive FHN spiking neuron model and brain-inspired
threshold logic computing. <em>NEUCOM</em>, <em>517</em>, 93–105. (<a
href="https://doi.org/10.1016/j.neucom.2022.08.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The FitzHugh-Nagumo (FHN) spiking model has rich dynamics behaviors and can imitate the firing process of a neuron. The memristor is a nonvolatile and resistance tunable device, which gradually becomes a potential candidate for performing dynamic behaviors and implementing neuromorphic computation in the nervous system . In this paper, the memristive FitzHugh-Nagumo (MFHN) spiking model is presented. Firstly, we introduce a memristor to the FHN spiking model to build the MFHN spiking model and analyze the phase plane trajectory of the MFHN model. Secondly, we couple two MFHN models with a memristor and experimentally simulate the dynamic behaviors of two coupled neurons. The synchronous and asynchronous phenomena of two coupled neurons are discussed. Thirdly, the feasibility of the MFHN spiking model is demonstrated by the realization of binary logical operations and the implementation of binary adders. The comparison between the MFHN binary adder and the FHN binary adder is conducted. The simulation results illustrate that the proposed model efficiently performs rich, dynamic behaviors and higher firing frequency. The coupled MFHN models show the effectiveness of a memristor acting as an electric coupling synapse. The threshold logic computation can be completed efficiently by the MFHN spiking model. The MFHN binary adders reproduce the computing functions and behaviors of the biological neuron.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyan Fang and Shukai Duan and Lidan Wang},
  doi          = {10.1016/j.neucom.2022.08.056},
  journal      = {Neurocomputing},
  pages        = {93-105},
  shortjournal = {Neurocomputing},
  title        = {Memristive FHN spiking neuron model and brain-inspired threshold logic computing},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GCNDepth: Self-supervised monocular depth estimation based
on graph convolutional network. <em>NEUCOM</em>, <em>517</em>, 81–92.
(<a href="https://doi.org/10.1016/j.neucom.2022.10.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation is a challenging task of 3D reconstruction to enhance the accuracy sensing of environment awareness. This work brings a new solution with improvements, which increases the quantitative and qualitative understanding of depth maps compared to existing methods. Recently, convolutional neural networks (CNN) have demonstrated their extraordinary ability to estimate depth maps from monocular videos. However, traditional CNN does not support a topological structure, and they can work only on regular image regions with determined sizes and weights. On the other hand, graph convolutional networks (GCN) can handle the convolution of non-Euclidean data, and they can be applied to irregular image regions within a topological structure. Therefore, to preserve object geometric appearances and objects locations in the scene, in this work, we aim to exploit GCN for a self-supervised monocular depth estimation model. Our model consists of two parallel auto-encoder networks: the first is an auto-encoder that will depend on ResNet-50 and extract the feature from the input image and on multi-scale GCN to estimate the depth map. In turn, the second network will be used to estimate the ego-motion vector (i.e., 3D pose) between two consecutive frames based on ResNet-18. The estimated 3D pose and depth map will be used to construct the target image. A combination of loss functions related to photometric, reprojection, and smoothness is used to cope with bad depth prediction and preserve the discontinuities of the objects. Our method and performance are improved quantitatively and qualitatively. In particular, our method provided comparable and promising results with a high prediction accuracy of 89\% 89\% on the publicly available KITTI dataset. Our method also offers 40\% 40\% reduction in the number of trainable parameters compared to the state of the art solutions.In addition, we tested our trained model with Make3D dataset to evaluate the trained model on a new dataset with low resolution images. The source code is publicly available at (https://github.com/ArminMasoumian/GCNDepth.git)},
  archive      = {J_NEUCOM},
  author       = {Armin Masoumian and Hatem A. Rashwan and Saddam Abdulwahab and Julián Cristiano and M. Salman Asif and Domenec Puig},
  doi          = {10.1016/j.neucom.2022.10.073},
  journal      = {Neurocomputing},
  pages        = {81-92},
  shortjournal = {Neurocomputing},
  title        = {GCNDepth: Self-supervised monocular depth estimation based on graph convolutional network},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSPNet: Multi-stage progressive network for image denoising.
<em>NEUCOM</em>, <em>517</em>, 71–80. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising which aims to restore a high-quality image from the noisy version is one of the most challenging tasks in the low-level computer vision tasks . In this paper, we propose a multi-stage progressive denoising network (MSPNet) and decompose the denoising task into some sub-tasks to progressively remove noise. Specifically, MSPNet is composed of three denoising stages. Each stage combines a feature extraction module (FEM) and a mutual-learning fusion module (MFM). In the feature extraction module, an encoder-decoder architecture is employed to learn non-local contextualized features, and the channel attention blocks (CAB) are utilized to retain the local information of the image. In the mutual-learning fusion module, the criss-cross attention is introduced to balance the image spatial details and the contextualized information. Compared with the state-of-the-art works, experimental results show that MSPNet achieves notable improvements on both objective and subjective evaluations.},
  archive      = {J_NEUCOM},
  author       = {Yu Bai and Meiqin Liu and Chao Yao and Chunyu Lin and Yao Zhao},
  doi          = {10.1016/j.neucom.2022.09.098},
  journal      = {Neurocomputing},
  pages        = {71-80},
  shortjournal = {Neurocomputing},
  title        = {MSPNet: Multi-stage progressive network for image denoising},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Projection concept factorization with self-representation
for data clustering. <em>NEUCOM</em>, <em>517</em>, 62–70. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, matrix factorization-based techniques have received much attention in the data analysis field since it can perform dimensionality reduction and clustering simultaneously. Despite the great success achieved by the Non-negative matrix factorization (NMF) and concept factorization (CF) methods, they suffer from the out-of-sample problem and are sensitive to the noise. Some recent studies have indicated that the similarity relationship is capable of revealing the local structure. In this paper, a similarity graph is constructed to reflect the geometric information of manifold structure, while the concept factorization is employed to capture the global structure. In addition, the projection matrix is incorporated into the concept factorization model to eliminate the noise and avoid the out-of-sample problem. An iterative algorithm is introduced to solve the model. The experimental results obtained on both human face and text data sets verify the high efficiency of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Chenyu Shao and Mulin Chen and Yuan Yuan and Qi Wang},
  doi          = {10.1016/j.neucom.2022.10.052},
  journal      = {Neurocomputing},
  pages        = {62-70},
  shortjournal = {Neurocomputing},
  title        = {Projection concept factorization with self-representation for data clustering},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial graph convolutional neural network via structured
subdomain adaptation and domain adversarial learning for bearing fault
diagnosis. <em>NEUCOM</em>, <em>517</em>, 44–61. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) has shown remarkable results in fault diagnosis under changing working conditions in recent years. However, most UDA methods do not consider the geometric structure of the data. Furthermore, the global domain adaptation technique is commonly applied, which ignores the relation between subdomains. This paper addresses mentioned challenges by presenting the novel deep subdomain adaptation graph convolution neural network (DSAGCN), which has two key characteristics: First, a graph convolution neural network (GCNN) is employed to model the structure of data. Second, adversarial domain adaptation and local maximum mean discrepancy (LMMD) methods are applied concurrently to align the subdomain’s distribution and reduce structure discrepancy between relevant subdomains and global domains. CWRU, PU, and JNU bearing datasets are used to validate the DSAGCN method’s superiority between comparison models. The experimental results demonstrate the significance of aligning structured subdomains along with domain adaptation methods to obtain an accurate data-driven model.},
  archive      = {J_NEUCOM},
  author       = {Mohammadreza Ghorvei and Mohammadreza Kavianpour and Mohammad T.H. Beheshti and Amin Ramezani},
  doi          = {10.1016/j.neucom.2022.10.057},
  journal      = {Neurocomputing},
  pages        = {44-61},
  shortjournal = {Neurocomputing},
  title        = {Spatial graph convolutional neural network via structured subdomain adaptation and domain adversarial learning for bearing fault diagnosis},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly supervised thoracic disease localization via disease
masks. <em>NEUCOM</em>, <em>517</em>, 34–43. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enable a deep learning-based system to be used in the medical domain as a computer-aided diagnosis system, it is essential to not only classify diseases but also present the locations of the diseases. However, collecting instance-level annotations for various thoracic diseases is expensive. Therefore, weakly supervised localization methods have been proposed that use only image-level annotation. While the previous methods presented the disease location as the most discriminative part for classification, this causes a deep network to localize wrong areas for indistinguishable X-ray images. To solve this issue, we propose a spatial attention method using disease masks that describe the areas where diseases mainly occur. We then apply the spatial attention to find the precise disease area by highlighting the highest probability of disease occurrence. Meanwhile, the various sizes, rotations and noise in chest X-ray images make generating the disease masks challenging. To reduce the variation among images, we employ an alignment module to transform an input X-ray image into a generalized image. Through extensive experiments on the NIH-Chest X-ray dataset with eight kinds of diseases, we show that the proposed method results in superior localization performances compared to state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Hong-Gyu Jung and Woo-Jeoung Nam and Hyun-Woo Kim and Seong-Whan Lee},
  doi          = {10.1016/j.neucom.2022.10.019},
  journal      = {Neurocomputing},
  pages        = {34-43},
  shortjournal = {Neurocomputing},
  title        = {Weakly supervised thoracic disease localization via disease masks},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grassmannian learning mutual subspace method for image set
recognition. <em>NEUCOM</em>, <em>517</em>, 20–33. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of object recognition given a set of images as input (e.g., multiple camera sources and video frames). Convolutional neural network (CNN)-based frameworks do not exploit these sets effectively, processing a pattern as observed, not capturing the underlying feature distribution as it does not consider the variance of images in the set. To address this issue, we propose the Grassmannian learning mutual subspace method (G-LMSM), a NN layer embedded on top of CNNs that can process image sets more effectively and can be trained in an end-to-end manner. The image set is first represented by a low-dimensional input subspace and then this input subspace is matched with dictionary subspaces by a similarity of their canonical angles, an interpretable and easy to compute metric. The key idea of G-LMSM is that the dictionary subspaces are learned as points on the Grassmann manifold, optimized with Riemannian stochastic gradient descent. This learning is stable, efficient and theoretically well-grounded. We demonstrate the effectiveness of our proposed method on hand shape recognition, face identification, and facial emotion recognition.},
  archive      = {J_NEUCOM},
  author       = {Lincon S. Souza and Naoya Sogi and Bernardo B. Gatto and Takumi Kobayashi and Kazuhiro Fukui},
  doi          = {10.1016/j.neucom.2022.10.040},
  journal      = {Neurocomputing},
  pages        = {20-33},
  shortjournal = {Neurocomputing},
  title        = {Grassmannian learning mutual subspace method for image set recognition},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of delay-dependent state estimation algorithm for
nonlinear coupling complex networks with dynamical bias: An adaptive
event-triggered scheme. <em>NEUCOM</em>, <em>517</em>, 10–19. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the delay-dependent variance-constrained state estimation (DDVCSE) problem for nonlinear coupling complex networks (NCCNs) subject to dynamical bias and adaptive event-triggered mechanism (AETM). First of all, the nonlinear coupling is modeled to embody the form of data exchange between different network units, which is linearized by resorting to the Taylor expansion. Then, an augmented technique is adopted to deal with the random bias described by a dynamical equation. Furthermore, an AETM is arranged in the sensor-to-estimator channel to adjust communication rate thereby averting resource waste. A novel augmented delay-dependent state estimator is constructed such that the upper bound of state estimation error covariance (UBSEEC) can be derived in the presence of state delay, nonlinear coupling, dynamical bias and AETM. Moreover, the estimator gain is designed appropriately in the sense of locally minimized variance-constrained index. Besides, the algorithm performance issue is discussed with rigourous mathematical proof, where the monotonicity of the trace of UBSEEC with respect to coupling strength is clarified in detail. Finally, an illustrative example is carried out to demonstrate the validity of the developed DDVCSE strategy.},
  archive      = {J_NEUCOM},
  author       = {Xia Liu},
  doi          = {10.1016/j.neucom.2022.10.063},
  journal      = {Neurocomputing},
  pages        = {10-19},
  shortjournal = {Neurocomputing},
  title        = {Design of delay-dependent state estimation algorithm for nonlinear coupling complex networks with dynamical bias: An adaptive event-triggered scheme},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recurrent attention unit: A new gated recurrent unit for
long-term memory of important parts in sequential data. <em>NEUCOM</em>,
<em>517</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gated recurrent unit (GRU) is a variant of the recurrent neural network (RNN). It has been widely used in many applications, such as handwriting recognition and natural language processing . However, GRU can only memorize the sequential information, but lacks the capability of adaptively paying attention to important parts in the sequences. In this paper, we propose a novel RNN model, called recurrent attention unit (RAU), which can seamlessly integrate the attention mechanism into the interior of the GRU cell by adding an attention gate. The attention gate enhances the ability of RAU to remember long-term information and pay attention to important parts in the sequential data. Extensive experiments on adding problem, image classification , sentiment classification and language modeling show that RAU consistently outperforms GRU and other related models.},
  archive      = {J_NEUCOM},
  author       = {Zhaoyang Niu and Guoqiang Zhong and Guohua Yue and Li-Na Wang and Hui Yu and Xiao Ling and Junyu Dong},
  doi          = {10.1016/j.neucom.2022.10.050},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {Recurrent attention unit: A new gated recurrent unit for long-term memory of important parts in sequential data},
  volume       = {517},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FastPicker: Adaptive independent two-stage video-to-video
summarization for efficient action recognition. <em>NEUCOM</em>,
<em>516</em>, 231–244. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video datasets suffer from huge inter-frame redundancy, which prevents deep networks from learning effectively and increases computational costs. Therefore, several methods adopt random/uniform frame sampling or key-frame selection techniques. Unfortunately, most of the learnable frame selection methods are customized for specific models and lack generality, independence, and scalability. In this paper, we propose a novel two-stage video-to-video summarization method termed FastPicker , which can efficiently select the most discriminative and representative frames for better action recognition. Independently, the discriminative frames are selected in the first stage based on the inter-frame motion computation, whereas the representative frames are selected in the second stage using a novel Transformer-based model. Learnable frame embeddings are proposed to estimate each frame contribution to the final video classification certainty. Consequently, the frames with the largest contributions are the most representative. The proposed method is carefully evaluated by summarizing several action recognition datasets and using them to train various deep models with several backbones. The experimental results demonstrate a remarkable performance boost on Kinetics400, Something-Something-v2, ActivityNet-1.3, UCF-101, and HMDB51 datasets, e.g., FastPicker downsizes Kinetics400 by 78.7\% of its size while improving the human activity recognition .},
  archive      = {J_NEUCOM},
  author       = {Saghir Alfasly and Jian Lu and Chen Xu and Zaid Al-Huda and Qingtang Jiang and Zhaosong Lu and Charles K. Chui},
  doi          = {10.1016/j.neucom.2022.10.037},
  journal      = {Neurocomputing},
  pages        = {231-244},
  shortjournal = {Neurocomputing},
  title        = {FastPicker: Adaptive independent two-stage video-to-video summarization for efficient action recognition},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video stabilization: A comprehensive survey.
<em>NEUCOM</em>, <em>516</em>, 205–230. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video stabilization is one of the most fundamental and challenging tasks in video processing, which can be widely applied in many areas, such as video surveillance, robotics, unmanned aerial vehicles and smartphones. It is a video enhancement technology that aims to improve original video quality by removing potentially shaky camera motion. Generally, conventional methods can be divided into three types: 2D, 3D and 2.5D models, which mainly have boundedness. In the past decade, deep learning has emerged as a powerful technique for learning feature representations directly from data, leading to significant progress in video stabilization. However, previous surveys mainly focus on conventional methods and lack performance comparison. In this paper, we present a comprehensive survey of video stabilization. Firstly, we briefly review three stages of video stabilization. Then, we deliver the conventional methods and the deep learning-based methods in detail. Furthermore, we pay special attention to video stabilization quality assessment, benchmark datasets, and state-of-the-art performance. Finally, we provide discussions on current challenges and future directions to overcome the limitations of the existing methods and better meet the needs of researchers in this active area.},
  archive      = {J_NEUCOM},
  author       = {Yiming Wang and Qian Huang and Chuanxu Jiang and Jiwen Liu and Mingzhou Shang and Zhuang Miao},
  doi          = {10.1016/j.neucom.2022.10.008},
  journal      = {Neurocomputing},
  pages        = {205-230},
  shortjournal = {Neurocomputing},
  title        = {Video stabilization: A comprehensive survey},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning graph-based relationship of dual-modal features
towards subject adaptive ASD assessment. <em>NEUCOM</em>, <em>516</em>,
194–204. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) has been identified as one of the most challenging and intriguing problems in neurodevelopment of children. Recent research suggest that conventional assessment on the basis of explicit behavior observations can be well complemented by evaluation of intrinsic neurophysiological states via analyses of brain imaging data such as electroencephalogram (EEG). However, before any more objective and comprehensive insights for a joint ASD assessment may be obtained, research challenges still remain: (1) how to characterize the interaction relationship of features rooted from recordings in different modalities; and at the same time (2) how to adapt to the individuality of subjects. This study develops a graph-based solution towards individualized assessment of ASD subjects via construction of the relationship of the dual-modal features of eye-tracking recordings and EEG: (1) Relationship Matrix Construction : A shallow encoding module as a variant of Multi-Level Perception (MLP) derives the initial intra- and inter-modal relationship matrix of the features in both modalities; and (2) Graph-based Relationship Learning : A model based on Deep Graph Convolutional Networks (D-GCN) fuses the global information of dual-modal features to learn the final relationship matrix, which is refined in the process of parameter optimization under the regulation of ASD classification. The resulted sample-specific matrices can then be exploited to address the individuality of subjects under examination. Experimental results indicate that: (1) the proposed method is superior to both the single-modal and multi-modal counterparts in ASD classification; (2) it excels in mining hidden connections among features in different modalities in comparison with mainstream methods for correlation measurement; and (3) it holds potentials in mitigating the uncertain variations brought by the individuality of subjects in ASD assessment.},
  archive      = {J_NEUCOM},
  author       = {Shasha Zhang and Dan Chen and Yunbo Tang and Xiaoli Li},
  doi          = {10.1016/j.neucom.2022.10.018},
  journal      = {Neurocomputing},
  pages        = {194-204},
  shortjournal = {Neurocomputing},
  title        = {Learning graph-based relationship of dual-modal features towards subject adaptive ASD assessment},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Focus on hierarchical features: Soft-weighted hierarchical
features network. <em>NEUCOM</em>, <em>516</em>, 182–193. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods of multi-scale context are commonly used for semantic segmentation. Existing methods suffer from two flaws: (1) Underutilization of backbone-derived multi-scale feature information. (2) Mismatch between small objects and large-scale encodings. To solve the above issues, we propose a novel network to better represent high-level features, named as Soft-weighted Hierarchical Features Network (SWHF-Net) consisting of Semi-atrous Transform Feature Pyramid Module (ST-FPM) and Hierarchical Features Fusion Module (HF2M). Specifically, we propose a hierarchy-driven feature transformation function strategy to reconstruct the traditional feature pyramid module as ST-FPM. ST-FPM strengthens the properties of hierarchical features, which is beneficial for extracting the semantic representation of multi-scale objects. Simultaneously, HF2M focuses on the characteristics of features at different hierarchies, and adaptively calculates the attention map of multi-scale objects, greatly improving the efficiency. On Cityscapes, Pascal Context, and ADE20K, we achieve outstanding performance compared to the state-of-the-art methods with fewer computational costs.},
  archive      = {J_NEUCOM},
  author       = {Hongkai Lin and Wentian Xin and Shun Chang and Qianxue Yang and Qiguang Miao and Ruyi Liu and Liang Chang},
  doi          = {10.1016/j.neucom.2022.09.055},
  journal      = {Neurocomputing},
  pages        = {182-193},
  shortjournal = {Neurocomputing},
  title        = {Focus on hierarchical features: Soft-weighted hierarchical features network},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ReasonFuse: Reason path driven and global–local fusion
network for numerical table-text question answering. <em>NEUCOM</em>,
<em>516</em>, 169–181. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical Table-Text Question Answering aims to predict the program over heterogeneous tabular and textual information, which has recently attracted strong attention in the NLP research community. Current state-of-the-art methods typically use a Seq2Seq-based model to predict programs, which may suffer from the inherent limitations of error propagation. Also, existing models just combine table-text context information and previously predicted operation when reasoning. This approach may lose information over long distances especially when the program is long, and fail to exploit the inter-dependencies between operations in the program. In this paper, we propose a joint Reason Path Driven and Global–Local Fusion Network (ReasonFuse) to alleviate the above problems. First of all, inspired by the intuition that operator prediction is a classification task while operand prediction is an extraction task, we propose a reason path driven architecture that predicts operators first and then guides the operands prediction jointly. After that, the global–local information fusion mechanism is designed to aggregate the context information and global–local program information to mitigate the loss of information over long distances. Last but not least, the soft-dropout mechanism is applied when training to improve the ability and generalization of the model. We conduct extensive experiments on the FinQA and MathQA datasets, our model achieves significant improvements as compared to all published results. The ablation study and case study verify the effectiveness, generalization, and interpretability of our model.},
  archive      = {J_NEUCOM},
  author       = {Yuancheng Xia and Feng Li and Qing Liu and Li Jin and Zequn Zhang and Xian Sun and Lixu Shao},
  doi          = {10.1016/j.neucom.2022.09.046},
  journal      = {Neurocomputing},
  pages        = {169-181},
  shortjournal = {Neurocomputing},
  title        = {ReasonFuse: Reason path driven and Global–Local fusion network for numerical table-text question answering},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fractional filter based on reinforcement learning for
effective tracking under impulsive noise. <em>NEUCOM</em>, <em>516</em>,
155–168. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is valuable and meaningful to suppress impulsive noise in system identification. Existing algorithms usually only consider impulsive noise with small frequency and amplitude. Furthermore, few researchers pay attention to the tracking performance of these algorithms. This paper builds a framework based on the deep deterministic policy gradient (DDPG) algorithm with the ability to explore and correct. The enhanced fractional derivative is introduced to further improve the performance of this reinforcement learning-based framework. Thus a fractional least mean square filter algorithm based on reinforcement learning (FrlMS) is proposed. The stability of the FrlMS algorithm is analyzed. Compared with the competing algorithms, the simulation experiments in system identification show that the FrlMS algorithm has satisfactory tracking performance in the face of impulsive noise, especially when the frequency and (or) amplitude are (is) large.},
  archive      = {J_NEUCOM},
  author       = {Xuetao Xie and Zhiping Li and Yi-Fei Pu and Jian Wang and Weihua Zhang and Yang Wen},
  doi          = {10.1016/j.neucom.2022.10.038},
  journal      = {Neurocomputing},
  pages        = {155-168},
  shortjournal = {Neurocomputing},
  title        = {A fractional filter based on reinforcement learning for effective tracking under impulsive noise},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Fully distributed adaptive time-varying formation control
of singular multiagent systems. <em>NEUCOM</em>, <em>516</em>, 146–154.
(<a href="https://doi.org/10.1016/j.neucom.2022.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the fully distributed adaptive time-varying formation protocols design problem for singular multiagent systems with directed topology. The pinning control method is introduced into the design of the adaptive distributed protocols, which can effectively adjust the formation position among agents and greatly relax the constraints of the communication topology among agents. Then, the distributed algorithm that independent of the global information of the communication graph is designed to solve the proposed fully distributed protocols. Next, the sufficient conditions of time-varying formation control are provided by the feedback pulse elimination method and stability analysis. Finally, the time-varying formation simulation results are presented to verify the feasibility of the proposed theory.},
  archive      = {J_NEUCOM},
  author       = {Xiaofan Liu and Xianxiang Wu and Yongfang Xie and Baolong Guo and Jingchi Yan},
  doi          = {10.1016/j.neucom.2022.10.041},
  journal      = {Neurocomputing},
  pages        = {146-154},
  shortjournal = {Neurocomputing},
  title        = {Fully distributed adaptive time-varying formation control of singular multiagent systems},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid domain learning framework for unsupervised semantic
segmentation. <em>NEUCOM</em>, <em>516</em>, 133–145. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised semantic segmentation often fails to generalize well in unseen scenarios due to the domain gap between the source and the target domains. Unsupervised domain adaptation is one possible way to solve this problem. However, the existing methods suffer two limitations. First, the number limitation of samples may lead to decreasing generalization. Second, only the source dataset contains pixel-level annotations, which provide stronger supervision in the source domain and result in overfitting to the source domain. To tackle these issues, we propose a hybrid domain learning (HDL) framework where the hybrid domain acts as the intermediate domain between the source domain and the target domain. Specifically, we first generate the hybrid domain feature (HDF) by a deep feature interpolation method and discuss the characteristics of the hybrid domain feature. Then, we further design a triple domain strategy to align the distribution of the source domain, the hybrid domain, and the target domain. The experiments in the tasks of GTA5 to Cityscapes and SYNTHIA to Cityscapes demonstrate that the proposed HDL framework is robust to domain adaptation and outperforms the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Yuhang Zhang and Shishun Tian and Muxin Liao and Wenbin Zou and Chen Xu},
  doi          = {10.1016/j.neucom.2022.10.005},
  journal      = {Neurocomputing},
  pages        = {133-145},
  shortjournal = {Neurocomputing},
  title        = {A hybrid domain learning framework for unsupervised semantic segmentation},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective fuzzy q-learning to solve continuous
state-action problems. <em>NEUCOM</em>, <em>516</em>, 115–132. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real world problems are multi-objective. Thus, the need for multi-objective learning and optimization algorithms is inevitable. Although the multi-objective optimization algorithms are well-studied, the multi-objective learning algorithms have attracted less attention. In this paper, a fuzzy multi-objective reinforcement learning algorithm is proposed, and we refer to it as the multi-objective fuzzy Q-learning (MOFQL) algorithm. The algorithm is implemented to solve a bi-objective reach-avoid game. The majority of the multi-objective reinforcement algorithms proposed address solving problems in the discrete state-action domain. However, the MOFQL algorithm can also handle problems in a continuous state-action domain. A fuzzy inference system (FIS) is implemented to estimate the value function for the bi-objective problem. We used a temporal difference (TD) approach to update the fuzzy rules. The proposed method is a multi-policy multi-objective algorithm and can find the non-convex regions of the Pareto front.},
  archive      = {J_NEUCOM},
  author       = {Amirhossein Asgharnia and Howard Schwartz and Mohamed Atia},
  doi          = {10.1016/j.neucom.2022.10.035},
  journal      = {Neurocomputing},
  pages        = {115-132},
  shortjournal = {Neurocomputing},
  title        = {Multi-objective fuzzy Q-learning to solve continuous state-action problems},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Lightweight MIMO-WNet for single image deblurring.
<em>NEUCOM</em>, <em>516</em>, 106–114. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image deblurring, aiming at recovering a latent sharp image from a blurry image, is a highly ill-posed task as there exist infinite feasible solutions. One successful practice of the existing popular approaches is to extensively stack deep networks to regress the complicated relationships between the sharp and blurry image pairs, which results in inevitably high computational costs. In this work, we present a synergistic framework named Lightweight MIMO-WNet that optimally balances the performance and the computational costs. Our main proposal consists of a MIMO-WNet architecture that attempts to learn the complicated blurry-sharp relationships via balancing the spatial details and the high-level contextualized information, and a multiple information refining block (MIRB) that reduces the parameters while deepening the network. At each layer, the original ResBlock is replaced with the MIRB that divides the input into multiple parts and refines the information hierarchically. The experimental results on three benchmarks demonstrate that Lightweight MIMO-WNet obtains a better trade-off between the performance and the model complexity.},
  archive      = {J_NEUCOM},
  author       = {Mushui Liu and Yunlong Yu and Yingming Li and Zhong Ji and Wen Chen and Yang Peng},
  doi          = {10.1016/j.neucom.2022.10.028},
  journal      = {Neurocomputing},
  pages        = {106-114},
  shortjournal = {Neurocomputing},
  title        = {Lightweight MIMO-WNet for single image deblurring},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relationship existence recognition-based social group
detection in urban public spaces. <em>NEUCOM</em>, <em>516</em>, 92–105.
(<a href="https://doi.org/10.1016/j.neucom.2022.10.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In urban public spaces, a social group consists of two or more individuals who share some social relationships and interact based on mutual expectations. However, most existing studies found people’s F-formations on a top view, which is hard to observe their social contexts and the top-view videos are not easily accessible in real urban life. Recently, some researchers turned to urban scenes and analysed front-view human behaviours for social group detection. But these methods still cannot grasp the nature of social groups, i.e., the relationships among individuals. It is the key to finding social groups to judge whether any two individuals belong to the same cluster. Therefore, this paper proposes a new paradigm: relationship existence recognition-based social group detection. Additionally, on top of the paradigm, we designed a new social group detection algorithm incorporated with the visual cue-based and non-visual cue-based components. Specifically, the former exploits the spatial interactions and the temporal information to recognise the existence of social relationships through supervised deep learning . The latter estimates the similarities of trajectory pairs using the unsupervised spatial–temporal position information. Social group detection achieves superior accuracy with the two components’ complementary results. On Social-CAD (Social Collective Activity Dataset) and PLPS (Public Life in Public Space) datasets, extensive experiments demonstrate that our algorithm outperforms the state-of-the-art (SOTA) methods.},
  archive      = {J_NEUCOM},
  author       = {Lindong Li and Linbo Qing and Li Guo and Yonghong Peng},
  doi          = {10.1016/j.neucom.2022.10.042},
  journal      = {Neurocomputing},
  pages        = {92-105},
  shortjournal = {Neurocomputing},
  title        = {Relationship existence recognition-based social group detection in urban public spaces},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual tracking with dumbbell selection network.
<em>NEUCOM</em>, <em>516</em>, 77–91. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Siamese network-based trackers aim to train the convolutional neural network offline to match target templates and search regions. Recent researches have managed to adopt deep neural networks to extract sufficient semantic information for the Siamese trackers. However, most of the current methods suffer drastic target appearance variations for 1) failing to encode sufficient localization information of targets and 2) neglecting powerful cross-channel interaction information, thus reducing the learned features’ discriminative and representative ability the tracking accuracy. To remedy these issues, in this article, we propose a Dumbbell Selection Network (DuStNet) by exploring the correlation of the hierarchies of convolutional layers . In concrete, an adaptively Dumbbell Selection mechanism is presented to deal with the targets’ appearance deformation by providing rich semantic and localization information. Furthermore, a CSResNet is developed to improve the residual unit in backbones by strengthening the interdependence between the convolution feature channels. We ingeniously employ the Generalized Intersection over Union (GIoU) to supervise the cross-layer feature-map selection, improving tracking accuracy when utilized as a regression loss simultaneously. Our results suggest that the proposed method is robust to significant appearance variations and can generate more accurate bounding boxes in complicated scenarios. Extensive experimental results on large-scale benchmark datasets prove our method’s effectiveness, which achieves excellent performance on OTB2015, VOT2017, LaSOT, and VOT2019.},
  archive      = {J_NEUCOM},
  author       = {Tianpeng Liu and Jing Li and Jia Wu and Jun Chang and Yafu Xiao and Yan Hong},
  doi          = {10.1016/j.neucom.2022.10.031},
  journal      = {Neurocomputing},
  pages        = {77-91},
  shortjournal = {Neurocomputing},
  title        = {Visual tracking with dumbbell selection network},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised feature selection guided by orthogonal
representation of feature space. <em>NEUCOM</em>, <em>516</em>, 61–76.
(<a href="https://doi.org/10.1016/j.neucom.2022.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has been an outstanding strategy in eliminating redundant and inefficient features in high-dimensional data. This paper introduces a novel unsupervised feature selection based on the matrix factorization , namely Unsupervised Feature Selection Guided by Orthogonal Representation (UFGOR). The orthogonality between a pair of variables refers to a specific case of linear independence such that they are perfectly uncorrelated. Motivated by the benefits of the orthogonality concept, the proposed UFGOR method is established based on the distance between the selected feature set and an orthogonal set corresponding to the whole feature space. Moreover, this orthogonal set is generated via QR-matrix factorization over the whole features and is employed as the compact representation of data matrix. In the next step, an unsupervised feature selection method is performed through the matrix factorization of the generated orthogonal set. Additionally, a dual-correlation model is utilized in the objective function of UFGOR to simultaneously consider both the local correlation in a set of selected features and the global correlation among the samples of a data. A detailed convergence analysis in line with an effective iterative algorithm proposed for the UFGOR method is also given. Numerical experiments on several real-world datasets illustrate the superior efficiency of our approach in comparison with some state-of-the-art unsupervised feature selection methods.},
  archive      = {J_NEUCOM},
  author       = {Mahsa Samareh Jahani and Gholamreza Aghamollaei and Mahdi Eftekhari and Farid Saberi-Movahed},
  doi          = {10.1016/j.neucom.2022.10.030},
  journal      = {Neurocomputing},
  pages        = {61-76},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised feature selection guided by orthogonal representation of feature space},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robustness-via-synthesis: Robust training with generative
adversarial perturbations. <em>NEUCOM</em>, <em>516</em>, 49–60. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Upon the discovery of adversarial attacks , robust models have become obligatory for deep learning-based systems. Adversarial training with first-order attacks has been one of the most effective defenses against adversarial perturbations to this day. The majority of the adversarial training approaches focus on iteratively perturbing each pixel with the gradient of the loss function with respect to the input image. However, the adversarial training with gradient-based attacks lacks diversity and does not generalize well to natural images and various attacks. This study presents a robust training algorithm where the adversarial perturbations are automatically synthesized from a random vector using a generator network. The classifier is trained with cross-entropy loss regularized with the optimal transport distance between the representations of the natural and synthesized adversarial samples. Unlike prevailing generative defenses, the proposed one-step attack generation framework synthesizes diverse perturbations without utilizing the gradient of the classifier’s loss. The main contributions of the proposed robust training framework are: i) preserving the state-of-the-art generalization performance of the deep model, ii) not requiring an iterative or recursive scheme, and iii) providing robustness that is comparable with the state-of-the-art in literature. Experimental results show that the proposed approach attains comparable robustness with various gradient-based and generative robust training techniques on CIFAR10, CIFAR100, SVHN, and Tiny ImageNet datasets. In addition, compared to the baselines, the proposed robust training framework generalizes well to the natural samples. Code and trained models are available here https://github.com/ALLab-Boun/robustness-via-synthesis.git .},
  archive      = {J_NEUCOM},
  author       = {İnci M. Baytaş and Debayan Deb},
  doi          = {10.1016/j.neucom.2022.10.034},
  journal      = {Neurocomputing},
  pages        = {49-60},
  shortjournal = {Neurocomputing},
  title        = {Robustness-via-synthesis: Robust training with generative adversarial perturbations},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum to “semi-supervised semantic segmentation with
cross teacher training” [neurocomputing 508 (2022) 36–46].
<em>NEUCOM</em>, <em>516</em>, 48. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Hui Xiao and Li Dong and Hao Xu and Shuibo Fu and Diqun Yan and Kangkang Song and Chengbin Peng},
  doi          = {10.1016/j.neucom.2022.10.044},
  journal      = {Neurocomputing},
  pages        = {48},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Semi-supervised semantic segmentation with cross teacher training” [Neurocomputing 508 (2022) 36–46]},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep semi-supervised clustering for multi-variate
time-series. <em>NEUCOM</em>, <em>516</em>, 36–47. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Huge amount of data are nowadays produced by a large and disparate family of sensors, which typically measure multiple variables over time. Such rich information can be profitably organized as multivariate time-series. Collect enough labelled samples to set up supervised analysis for such kind of data is challenging while a reasonable assumption is to dispose of a limited background knowledge that can be injected in the analysis process. In this context, semi-supervised clustering methods represent a well suited tool to get the most out of such reduced amount of knowledge. With the aim to deal with multivariate time-series analysis under a limited background knowledge setting, we propose a semi-supervised (constrained) deep embedding time-series clustering framework that exploits knowledge supervision modeled as Must- and Cannot-link constraints. More in detail, our proposal, named conDetSEC (constrained Deep embedding time SEries Clustering), is based on Gated Recurrent Units (GRUs) with the aim to explicitly manage the temporal dimension associated to multi-variate time series data. conDetSEC implements a procedure in which an embedding generation step is combined with a clustering refinement step. Both steps exploit the small amount of available knowledge provided by Must- and Cannot-link constraints. More specifically, during the data embedding generation the constraints are used by jointly optimizing the network parameters via both unsupervised and semi-supervised tasks, while at the refinement step they are used in conjunction with the goal to stretch the embedding manifold towards the clustering centroids to recover a more clear cluster structure. Experimental evaluation on real-world benchmarks coming from diverse domains has highlighted the effectiveness of our proposal in comparison with state-of-the-art unsupervised and semi-supervised time-series clustering methods.},
  archive      = {J_NEUCOM},
  author       = {Dino Ienco and Roberto Interdonato},
  doi          = {10.1016/j.neucom.2022.10.033},
  journal      = {Neurocomputing},
  pages        = {36-47},
  shortjournal = {Neurocomputing},
  title        = {Deep semi-supervised clustering for multi-variate time-series},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dialogue-adaptive language model pre-training from quality
estimation☆. <em>NEUCOM</em>, <em>516</em>, 27–35. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained language models (PrLMs) have achieved great success on a wide range of natural language processing tasks by virtue of the universal language representation ability obtained by self-supervised learning on a large corpus. These models are pre-trained on standard plain texts with general language model (LM) training objectives, which would be insufficient to model dialogue-exclusive attributes like specificity and informativeness reflected in these tasks that are not explicitly captured by the pre-trained universal language representations. In this work, we propose dialogue-adaptive pre-training objectives (DAPO) derived from quality estimation to simulate dialogue-specific features, namely coherence, specificity, and informativeness. As the foundation for model pre-training, we synthesize a new dialogue corpus and build our training set with two unsupervised methods : 1) coherence -oriented context corruption, including utterance ordering, insertion, and replacement, to help the model capture the coherence inside the dialogue contexts; and 2) specificity -oriented automatic rescoring, which encourages the model to measure the quality of the synthesized data for dialogue-adaptive pre-training by considering specificity and informativeness . Experimental results on widely used open-domain response selection and quality estimation benchmarks show that DAPO significantly improves the baseline models and achieves state-of-the-art performance on the MuTual leaderboard, verifying the effectiveness of estimating quality evaluation factors into pre-training.},
  archive      = {J_NEUCOM},
  author       = {Junlong Li and Zhuosheng Zhang and Hai Zhao},
  doi          = {10.1016/j.neucom.2022.10.036},
  journal      = {Neurocomputing},
  pages        = {27-35},
  shortjournal = {Neurocomputing},
  title        = {Dialogue-adaptive language model pre-training from quality estimation☆},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint matrix decomposition for deep convolutional neural
networks compression. <em>NEUCOM</em>, <em>516</em>, 11–26. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (CNNs) with a large number of parameters require intensive computational resources, and thus are hard to be deployed in resource-constrained platforms. Decomposition-based methods, therefore, have been utilized to compress CNNs in recent years. However, since the compression factor and performance are negatively correlated, the state-of-the-art works either suffer from severe performance degradation or have relatively low compression factors. To overcome this problem, we propose to compress CNNs and alleviate performance degradation via joint matrix decomposition , which is different from existing works that compressed layers separately. The idea is inspired by the fact that there are lots of repeated modules in CNNs. By projecting weights with the same structures into the same subspace, networks can be jointly compressed with larger ranks. In particular, three joint matrix decomposition schemes are developed, and the corresponding optimization approaches based on Singular Value Decomposition are proposed. Extensive experiments are conducted across three challenging compact CNNs for different benchmark data sets to demonstrate the superior performance of our proposed algorithms. As a result, our methods can compress the size of ResNet-34 by 22 × 22× with slighter accuracy degradation compared with several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Shaowu Chen and Jiahao Zhou and Weize Sun and Lei Huang},
  doi          = {10.1016/j.neucom.2022.10.021},
  journal      = {Neurocomputing},
  pages        = {11-26},
  shortjournal = {Neurocomputing},
  title        = {Joint matrix decomposition for deep convolutional neural networks compression},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal consensus of a class of discrete-time linear
multi-agent systems via value iteration with guaranteed admissibility.
<em>NEUCOM</em>, <em>516</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the optimal consensus problem for heterogeneous discrete-time(DT) linear multi-agent systems. The optimal consensus problem is formulated as finding a global Nash equilibrium solution subjected to the defined local performance index. A reinforcement learning(RL) value iteration(VI) algorithm is introduced to obtain the optimal policies in the sense of Nash equilibrium . To ensure the effectiveness of the VI algorithm, the admissibility of the iterative control policies for multi-agent systems is considered. With theoretical analysis, a new termination criterion is established to guarantee the admissibility of the iterative control policies. Furthermore, an online learning framework is designed with an actor-critic neural network(NN) to implement the VI algorithm. Finally, two simulation examples are presented respectively for leader–follower and leaderless multi-agent systems to verify the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Pingchuan Li and Wencheng Zou and Jian Guo and Zhengrong Xiang},
  doi          = {10.1016/j.neucom.2022.10.032},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Optimal consensus of a class of discrete-time linear multi-agent systems via value iteration with guaranteed admissibility},
  volume       = {516},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction notice to “distilled and filtered deep neural
networks for real-time object detection in edge computing”
[neurocomputing 505 (2022) 225–237]. <em>NEUCOM</em>, <em>515</em>, 201.
(<a href="https://doi.org/10.1016/j.neucom.2022.10.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Guoping Yang and Bangping Wang and Shaojie Qiao and Lulu Qu and Nan Han and Guan Yuan and He Li and Tao Wu and Yuzhong Peng},
  doi          = {10.1016/j.neucom.2022.10.072},
  journal      = {Neurocomputing},
  pages        = {201},
  shortjournal = {Neurocomputing},
  title        = {Retraction notice to “Distilled and filtered deep neural networks for real-time object detection in edge computing” [Neurocomputing 505 (2022) 225–237]},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-layer segmentation of retina OCT images via advanced
u-net architecture. <em>NEUCOM</em>, <em>515</em>, 185–200. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical Coherence Tomography (OCT) is a non-invasive method which can obtain high-definition images of cross section (B-scan) of the retina. By investigating the thickness of different layers of the retina in OCT images, one can diagnose ocular diseases in an early stage. Different algorithms have been proposed for retinal layer segmentation including machine learning techniques and various advanced CNN architectures, which have been developed recently. In this research, segmentation of OCT images is carried out for 9 boundaries, equivalent to segmenting eight retinal layers. We investigate different U-net like structures which can be combined with VGG and ResNet architectures to train models using labelled examples, and accuracy for the predicted retinal layers would be compared. In reducing the complexity of networks, a method is proposed based on the concept of domain decomposition when training a large volume of data on a cloud platform.},
  archive      = {J_NEUCOM},
  author       = {N. Man and S. Guo and K.F.C. Yiu and C.K.S. Leung},
  doi          = {10.1016/j.neucom.2022.10.001},
  journal      = {Neurocomputing},
  pages        = {185-200},
  shortjournal = {Neurocomputing},
  title        = {Multi-layer segmentation of retina OCT images via advanced U-net architecture},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AsyLink: User identity linkage from text to geo-location via
sparse labeled data. <em>NEUCOM</em>, <em>515</em>, 174–184. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User Identity Linkage (UIL) aims to reveal the correspondence among account pairs across different social platforms. It has been a popular but challenging task in recent years as complex application scenarios have emerged. Existing UIL methods mainly formalize a classification problem based on symmetric information, but these techniques are hard to apply to asymmetric, sparsely labeled, and imbalanced data . To combat the challenges, we propose a novel UIL framework (AsyLink) with asymmetric information in text and geographic forms. AsyLink first uses topic modeling technologies to associate words and locations, where external text-location pairs can be conveniently introduced to reduce bias caused by sparse linkage labels. Then the user-user interactive tensors are constructed as the basis for linking. Using 3D convolutional neural networks , matching patterns in user-user interactive tensors are captured, and final predictions are based on the extracted features. Meanwhile, instead of regular classification loss, the ranking loss is introduced to predict the best answer among candidates, which is conducive to imbalanced classification. Experiments performed on four real-world datasets indicate that AsyLink achieves state-of-the-art performances and has great potential for real-world applications.},
  archive      = {J_NEUCOM},
  author       = {Jiangli Shao and Yongqing Wang and Hao Gao and Boshen Shi and Huawei Shen and Xueqi Cheng},
  doi          = {10.1016/j.neucom.2022.10.027},
  journal      = {Neurocomputing},
  pages        = {174-184},
  shortjournal = {Neurocomputing},
  title        = {AsyLink: User identity linkage from text to geo-location via sparse labeled data},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deep NMF topic modeling. <em>NEUCOM</em>, <em>515</em>,
157–173. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) based topic modeling methods do not rely on model- or data-assumptions much. However, they are usually formulated as difficult optimization problems , which may suffer from bad local minima and high computational complexity . In this paper, we propose a deep NMF (DNMF) topic modeling framework to alleviate the aforementioned problems. It first applies an unsupervised deep learning method to learn latent hierarchical structures of documents, under the assumption that if we could learn a good representation of documents by, e.g. a deep model, then the topic word discovery problem can be boosted. Then, it takes the output of the deep model to constrain a topic-document distribution for the discovery of the discriminant topic words, which not only improves the efficacy but also reduces the computational complexity over conventional unsupervised NMF methods. We constrain the topic-document distribution in three ways, which takes the advantages of the three major sub-categories of NMF—basic NMF, structured NMF, and constrained NMF respectively. To overcome the weaknesses of deep neural networks in unsupervised topic modeling, we adopt a non-neural-network deep model—multilayer bootstrap network. To our knowledge, this is the first time that a deep NMF model is used for unsupervised topic modeling. We have compared the proposed method with a number of representative references covering major branches of topic modeling on a variety of real-world text corpora. Experimental results illustrate the effectiveness of the proposed method under various evaluation metrics .},
  archive      = {J_NEUCOM},
  author       = {Jianyu Wang and Xiao-Lei Zhang},
  doi          = {10.1016/j.neucom.2022.10.002},
  journal      = {Neurocomputing},
  pages        = {157-173},
  shortjournal = {Neurocomputing},
  title        = {Deep NMF topic modeling},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). General ELLRFS-DAZN algorithm for solving future linear
equation system under various noises. <em>NEUCOM</em>, <em>515</em>,
145–156. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the problem of future linear equation system under various noises. Firstly, a continuous advanced zeroing neurodynamic (CAZN) model under noise is developed to solve continuous linear equation system . Subsequently, by combining a general explicit linear left–right four-step (ELLRFS) formula with the CAZN model, a general ELLRFS discrete advanced zeroing neurodynamic (ELLRFS-DAZN) algorithm under noise is proposed to solve the future linear equation system. Theoretical analyses and results manifest the convergence performance of the general ELLRFS-DAZN algorithm under various noises. Moreover, numerical experimental results, including those based on a UR5 manipulator, validate the effectiveness and robustness of the general ELLRFS-DAZN algorithm under various noises. Numerical experimental results based on mobile acoustic source localization further substantiate the superiority of the general ELLRFS-DAZN algorithm under constant noise. Finally, physical experimental results based on a Kinova JACO 2 manipulator substantiate the practicability of the general ELLRFS-DAZN algorithm under bounded random noise.},
  archive      = {J_NEUCOM},
  author       = {Jinjin Guo and Ning Tan and Yunong Zhang},
  doi          = {10.1016/j.neucom.2022.10.029},
  journal      = {Neurocomputing},
  pages        = {145-156},
  shortjournal = {Neurocomputing},
  title        = {General ELLRFS-DAZN algorithm for solving future linear equation system under various noises},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model tree methods for explaining deep reinforcement
learning agents in real-time robotic applications. <em>NEUCOM</em>,
<em>515</em>, 133–144. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has shown useful in the field of robotics but the black-box nature of deep neural networks impedes the applicability of deep reinforcement learning agents for real-world tasks. This is addressed in the field of explainable artificial intelligence , by developing explanation methods that aim to explain such agents to humans. Model trees as surrogate models have proven useful for producing explanations for black-box models used in real-world robotic applications , in particular, due to their capability of providing explanations in real time. In this paper, we provide an overview and analysis of available methods for building model trees for explaining deep reinforcement learning agents solving robotics tasks. We find that multiple outputs are important for the model to be able to grasp the dependencies of coupled output features, i.e. actions. Additionally, our results indicate that introducing domain knowledge via a hierarchy among the input features during the building process results in higher accuracies and a faster building process.},
  archive      = {J_NEUCOM},
  author       = {Vilde B. Gjærum and Inga Strümke and Jakob Løver and Timothy Miller and Anastasios M. Lekkas},
  doi          = {10.1016/j.neucom.2022.10.014},
  journal      = {Neurocomputing},
  pages        = {133-144},
  shortjournal = {Neurocomputing},
  title        = {Model tree methods for explaining deep reinforcement learning agents in real-time robotic applications},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-free adaptive iterative learning containment control
for unknown heterogeneous nonlinear MASs with disturbances.
<em>NEUCOM</em>, <em>515</em>, 121–132. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel model-free adaptive iterative learning control scheme is proposed for the containment control problem of unknown heterogeneous nonlinear multi-agent systems (MASs) with bounded measurable and unmeasurable disturbances. In details, the proposed scheme includes following parts. First, the agent dynamics are transformed into a partial form dynamic linearization data model along the iteration axis by using the novel concept of the pseudo gradient. Second, the distributed containment control scheme is designed for MASs under fixed topology based on the obtained data model at each working point. Then, the scheme is extended to the case of iteration-switching topologies. Finally, the convergences have been proved by rigorous mathematical analysis. The whole containment control process is characterized with data-driven nature by only using the input and output data. Simulation results illustrate the effectiveness of the schemes.},
  archive      = {J_NEUCOM},
  author       = {Tong Liu and Zhongsheng Hou},
  doi          = {10.1016/j.neucom.2022.09.154},
  journal      = {Neurocomputing},
  pages        = {121-132},
  shortjournal = {Neurocomputing},
  title        = {Model-free adaptive iterative learning containment control for unknown heterogeneous nonlinear MASs with disturbances},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient deep steering control method for self-driving cars
through feature density metric. <em>NEUCOM</em>, <em>515</em>, 107–120.
(<a href="https://doi.org/10.1016/j.neucom.2022.09.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a low cost method for input size reduction without sacrificing accuracy is proposed, which reduces required computation resources for both training and inference of deep convolutional neural network (DCNN) in the steering control of self-driving cars. Efficient processing of DCNNs is becoming prominent challenge due to its huge computation cost, number of parameters and also inadequate computation resources on power efficient hardware devices and the proposed method alleviates the problem comparing the state of the art. The proposed method introduces feature density metric (FDM) as criterion to mask and filter out regions of input image that do not contain adequate amount of features. This filtering method prevents DCNN from useless calculations belongs to feature-free regions. Compared to PilotNet, the proposed method accelerates overall training and inference phases of end-to-end (ETE) deep steering control of self-driving cars up to 1.3× and 2.0× respectively.},
  archive      = {J_NEUCOM},
  author       = {Abbas Mohammadi and Kamal Jamshidi and Hamed Shahbazi and Mehran Rezaei},
  doi          = {10.1016/j.neucom.2022.09.106},
  journal      = {Neurocomputing},
  pages        = {107-120},
  shortjournal = {Neurocomputing},
  title        = {Efficient deep steering control method for self-driving cars through feature density metric},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of transformer-based multimodal pre-trained modals.
<em>NEUCOM</em>, <em>515</em>, 89–106. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the broad industrialization of Artificial Intelligence(AI), we observe a large fraction of real-world AI applications are multimodal in nature in terms of relevant data and ways of interaction. Pre-trained big models have been proven as the most effective framework for joint modeling of multi-modality data. This paper provides a thorough account of the opportunities and challenges of Transformer-based multimodal pre-trained model (PTM) in various domains. We begin by reviewing the representative tasks of multimodal AI applications, ranging from vision-text and audio-text fusion to more complex tasks such as document layout understanding. We particularly address the new multi-modal research domain of document layout understanding. We further analyze and compare the state-of-the-art Transformer-based multimodal PTMs from multiple aspects, including downstream applications, datasets, input feature embedding, and model architectures. In conclusion, we summarize the key challenges of this field and suggest several future research directions.},
  archive      = {J_NEUCOM},
  author       = {Xue Han and Yi-Tong Wang and Jun-Lan Feng and Chao Deng and Zhan-Heng Chen and Yu-An Huang and Hui Su and Lun Hu and Peng-Wei Hu},
  doi          = {10.1016/j.neucom.2022.09.136},
  journal      = {Neurocomputing},
  pages        = {89-106},
  shortjournal = {Neurocomputing},
  title        = {A survey of transformer-based multimodal pre-trained modals},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-view graph matching for incomplete multi-view
clustering. <em>NEUCOM</em>, <em>515</em>, 79–88. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) focuses on adaptively partitioning data from diverse sources into the respective groups and has been widely studied under the assumption of complete data. However, real-world applications often encounter a more realistic incomplete multi-view clustering (IMVC) problem, where data samples are missing in certain views. There are two challenges in IMVC: 1) how to reduce the impact of the missing instances; 2) how to effectively extract the consistent information to cluster the multi-view data. To address the challenges, we propose an adaptive graph learning framework for IMVC, which optimizes the missing information to fit the intrinsic structure of each view and clusters the multi-view data by cross-view graph matching. The proposed method mainly consists of three steps. Firstly, owing to the outstanding performance of the intrinsic structure of data, we adapt it to complete the missing data of each view. Secondly, the connection graph of each view from a projection space is adaptively constructed wherein the data points are connected if and only if they belong to the same cluster. Thirdly, we further introduce a cross-view graph matching strategy to appropriately utilize complementary multi-views information and preserve view-specific semantic information. We develop an iterative algorithm for solving the proposed model. Numerical experiments on several standard datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jing-Hua Yang and Le-Le Fu and Chuan Chen and Hong-Ning Dai and Zibin Zheng},
  doi          = {10.1016/j.neucom.2022.10.007},
  journal      = {Neurocomputing},
  pages        = {79-88},
  shortjournal = {Neurocomputing},
  title        = {Cross-view graph matching for incomplete multi-view clustering},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Object-aware navigation for remote embodied visual referring
expression. <em>NEUCOM</em>, <em>515</em>, 68–78. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Remote Embodied Visual Referring Expression (REVERIE) task, an agent needs to navigate through an unseen environment to identify a referred object following high-level instructions. Despite recent efforts of vision-and-language navigation (VLN), previous methods commonly rely on detailed navigational instructions, which might not be available in practice. To address this issue, we present a method that strengthens vision-and-language (V&amp;L) navigators with object-awareness. By combining object-aware textual grounding and visual grounding operations, our technique helps the navigator recognize the relationship between instructions and the contents of captured images. As a generic method, the proposed solution can be seamlessly integrated into other V&amp;L navigators with different frameworks (for example, Seq2Seq or BERT). In order to alleviate the problem of data scarcity, we synthesize augmented data based on a simple yet effective prompt template that retains object information and destination information. Experimental results on REVERIE and R2R datasets demonstrate the proposed methods’ applicability and performance improvement across different domains.},
  archive      = {J_NEUCOM},
  author       = {Zhaohuan Zhan and Liang Lin and Guang Tan},
  doi          = {10.1016/j.neucom.2022.10.026},
  journal      = {Neurocomputing},
  pages        = {68-78},
  shortjournal = {Neurocomputing},
  title        = {Object-aware navigation for remote embodied visual referring expression},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Links synchronization control for the complex dynamical
network. <em>NEUCOM</em>, <em>515</em>, 59–67. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the complex dynamical network (CDN) with uncertainties, this paper defines the links synchronization and synthesizes the adaptive control scheme to realize it. Generally speaking, a CDN can be considered as the composition system with the two coupled dynamic subsystems : the nodes subsystem (NS) and the links subsystem (LS). We observed that there are many results in the existing literature on the NS synchronization, which implies that the state at each node tends to be the same when the NS synchronization happens. However, the LS synchronization is rarely discussed in the existing literature due to its unknown meaning and engineering practice background. Inspired by the ego-networks, this paper employs the time-varying outgoing links at each node to geometrically describe the changing of network topologic structure and regards the values-weighted of outgoing links as the state variables of LS, by which the LS synchronization is introduced, the corresponding control scheme for its implementation is synthesized under the condition that the state of NS is available and the state of LS is unavailable. The control scheme includes the adaptive controller for NS and the coupling strategy for LS. Finally, the effectiveness of proposed control scheme in this paper is verified by a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Peitao Gao and Yinhe Wang and Juanxia Zhao and LiLi Zhang and Yi Peng},
  doi          = {10.1016/j.neucom.2022.10.024},
  journal      = {Neurocomputing},
  pages        = {59-67},
  shortjournal = {Neurocomputing},
  title        = {Links synchronization control for the complex dynamical network},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-set differential privacy for fine-grained data privacy
protection. <em>NEUCOM</em>, <em>515</em>, 48–58. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy-preserving data statistics and analysis has become an urgent problem nowadays. Differential privacy (DP), as a rigorous privacy paradigm, has been widely adopted in various fields. However, in the context of large-scale mobile applications where each user has multiple records, both user-level DP and record-level DP cannot achieve a good compromise between stringent privacy and high data utility. A more satisfying privacy paradigm with desired granularity becomes very necessary. To this end, this paper proposes a fine-grained privacy paradigm called α α -event-set differential privacy, which prevents adversaries from inferring any one of α α event-sets owned by the user in data statistics and analysis. We theoretically introduce the definition, properties, and baseline mechanisms of α α -event-set DP. Besides, we implement and evaluate α α -event-set DP on mean estimation, histogram estimation, and machine learning applications, respectively. The experimental results have shown that α α -event-set DP is able to achieve a fine-grained granularity of privacy protection while allowing high data utility.},
  archive      = {J_NEUCOM},
  author       = {Teng Wang and Wanyun Yang and Xin Ma and Bin Wang},
  doi          = {10.1016/j.neucom.2022.10.006},
  journal      = {Neurocomputing},
  pages        = {48-58},
  shortjournal = {Neurocomputing},
  title        = {Event-set differential privacy for fine-grained data privacy protection},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamic graph expansion network for multi-hop knowledge
base question answering. <em>NEUCOM</em>, <em>515</em>, 37–47. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge base question answering aims to answer a question over a knowledge base. Multi-hop knowledge base question answering is a challenging task because it requires multi-step reasoning according to the question to get the answer. Existing models infer the answer over a static subgraph or attend to different parts of the question through an intermediate signal. The former obtains limited semantic information, and the latter provides limited reasoning due to the weak supervision signal. In this paper, we eliminate the limitation of static subgraph reasoning by dynamically expanding subgraphs, which connect the question and subgraph to form a joint subgraph. We then adjust the dynamic subgraph to enable reasoning at each step. Specifically, at each step, the question connects different subgraphs, respects the context while paying attention to a specific part of the question, generates a strong intermediate signal, acts on the subsequent reasoning, and finally obtains a correct answer. A large number of experiments on three datasets show that our method performs better than previous state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Wenqing Wu and Zhenfang Zhu and Jiangtao Qi and Wenling Wang and Guangyuan Zhang and Peiyu Liu},
  doi          = {10.1016/j.neucom.2022.10.023},
  journal      = {Neurocomputing},
  pages        = {37-47},
  shortjournal = {Neurocomputing},
  title        = {A dynamic graph expansion network for multi-hop knowledge base question answering},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of recent advances on stability analysis, state
estimation and synchronization control for neural networks.
<em>NEUCOM</em>, <em>515</em>, 26–36. (<a
href="https://doi.org/10.1016/j.neucom.2022.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, neural networks have been widely applied in many fields such as pattern recognition, signal and image processing and control theory. Over the past two decades or so, the analysis and synthesis for neural networks have received significant research attention. This paper provides a survey on the analysis and synthesis for neural networks, which is mainly concerned with the recent advances on stability analysis, state estimation and synchronization control for neural networks. First of all, the paper summarizes the recent results on the stability analysis for delayed neural networks, especially for neural networks with multiple discrete delays, neural networks with distributed delays, and discrete-time delayed neural networks. Then, the paper reviews the recent advances regarding the state estimation for neural networks with the emphasis on the network-based state estimation. Subsequently, the paper provides an overview on the synchronization control for neural networks. Finally, the conclusions and further research directions are given.},
  archive      = {J_NEUCOM},
  author       = {Yonggang Chen and Nannan Zhang and Juanjuan Yang},
  doi          = {10.1016/j.neucom.2022.10.020},
  journal      = {Neurocomputing},
  pages        = {26-36},
  shortjournal = {Neurocomputing},
  title        = {A survey of recent advances on stability analysis, state estimation and synchronization control for neural networks},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ER-pose: Learning edge representation for 6D pose estimation
of texture-less objects. <em>NEUCOM</em>, <em>515</em>, 13–25. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {6D pose estimation from a single RGB image is a fundamental task in computer vision. We introduce a two-stage 6D pose estimation method for texture-less objects. Instead of utilizing the object mask in almost current monocular methods, we propose an edge representation for texture-less objects. An object is represented by the combination of visible edges corresponding to the object’s 6D pose, allowing the neural network to focus more on the object’s invariant global shape and structure, rather than indistinguishable local patches with image noise and similar texture. Given an RGB image , the proposed method predicts the direction and distance to a certain object keypoint from all object pixels within the range of object edge representation, establishes voting-based sparse 2D-3D correspondences, and solves the object pose with P n P algorithm. In the experiments, we found that directly replacing the object mask with the edge representation can bring a performance improvement in two current two-stage pipelines without any modification. Further evaluations on three different benchmark datasets containing symmetric and occluded objects show our method outperforms the state-of-the-art methods using RGB images only.},
  archive      = {J_NEUCOM},
  author       = {Xu Yang and Kunbo Li and Jinge Wang and Xiumin Fan},
  doi          = {10.1016/j.neucom.2022.09.151},
  journal      = {Neurocomputing},
  pages        = {13-25},
  shortjournal = {Neurocomputing},
  title        = {ER-pose: Learning edge representation for 6D pose estimation of texture-less objects},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised anomaly pattern detection for large scale
industrial data. <em>NEUCOM</em>, <em>515</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2022.09.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting the anomalies in a large amounts of high-dimensional data has been a challenging task. In the Industry 4.0 environment, large-scale high-dimensional monitoring data features the complex pattern of high level semantics . In order to provide enterprise-wide monitoring solutions, it is necessary to identify the high-level semantic patterns of the anomalies in these data without splitting them. Existing end-to-end deep neural networks for time series are capable of recognizing the high-level semantics in natural language or speech signals, but they are barely applied in real-time anomaly detection of industrial data because of the large time costs. In this paper, we leverage the self-supervised contrastive learning methodology and propose a Composite Semantic Augmentation Encoder (CSAE) to provide an appropriate representation of industrial data and implement quick detection of anomalies in industrial application environments. CSAE is a non-sequential deep neural network with two augmentation layers and a mandatory layer. The two layers of data-augmentation are built to expand the size of samples of both low-level semantic anomalies and high-level semantic anomalies, which enables CSAE to discover diverse anomalies and improves its accuracy of high-level semantic pattern recognition. The mandatory layer is built to compress and reserve the temporal information in the industrial data to accelerate the anomaly detection. Therefore, as a non-sequential contrastive learning model, CSAE has faster training convergence than the usual sequence models. The experiment results have verified that CSAE can achieve higher prediction accuracy with less time consumption than existing machine learning models in the tasks of high dimensional anomaly pattern detection.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyue Tang and Shan Zeng and Fang Yu and Wei Yu and Zhongyin Sheng and Zhen Kang},
  doi          = {10.1016/j.neucom.2022.09.069},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised anomaly pattern detection for large scale industrial data},
  volume       = {515},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
