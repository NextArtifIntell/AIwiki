<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ICAE_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="icae---25">ICAE - 25</h2>
<ul>
<li><details>
<summary>
(2023). An exploratory design science research on troll factories.
<em>ICAE</em>, <em>31</em>(1), 95–115. (<a
href="https://doi.org/10.3233/ICA-230720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private and military troll factories (facilities used to spread rumours in online social media) are currently proliferating around the world. By their very nature, they are obscure companies whose internal workings are largely unknown, apart from leaks to the press. They are even more concealed whe n it comes to their underlying technology. At least in a broad sense, it is believed that there are two main tasks performed by a troll factory: sowing and spreading. The first is to create and, more importantly, maintain a social network that can be used for the spreading task. It is then a wicked long-term activity, subject to all sorts of problems. As an attempt to make this perspective a little clearer, this paper uses exploratory design science research to produce artefacts that could be applied to online rumour spreading in social media. Then, as a hypothesis: it is possible to design a fully automated social media agent capable of sowing a social network on microblogging platforms. The expectation is that it will be possible to identify common opportunities and difficulties in the development of such tools, which in turn will allow an evaluation of the technology, but above all the level of automation of these facilities. The research is based on a general domain Twitter corpus with 4M+ tokens and on ChatGPT, and discusses both knowledge-based and deep learning approaches for smooth tweet generation. These explorations suggest that for the current, widespread and publicly available NLP technology, troll factories work like a call centre; i.e. humans assisted by more or less sophisticated computing tools (often called cyborgs).},
  archive      = {J_ICAE},
  author       = {Marcondes, Francisco S. and Almeida, José João and Novais, Paulo},
  doi          = {10.3233/ICA-230720},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {1},
  pages        = {95-115},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {An exploratory design science research on troll factories},
  volume       = {31},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving landslide prediction by computer vision and deep
learning. <em>ICAE</em>, <em>31</em>(1), 77–94. (<a
href="https://doi.org/10.3233/ICA-230717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The destructive power of a landslide can seriously affect human beings and infrastructures. The prediction of this phenomenon is of great interest; however, it is a complex task in which traditional methods have limitations. In recent years, Artificial Intelligence has emerged as a successful alter native in the geological field. Most of the related works use classical machine learning algorithms to correlate the variables of the phenomenon and its occurrence. This requires large quantitative landslide datasets, collected and labeled manually, which is costly in terms of time and effort. In this work, we create an image dataset using an official landslide inventory, which we verified and updated based on journalistic information and interpretation of satellite images of the study area. The images cover the landslide crowns and the actual triggering values of the conditioning factors at the detail level (5 × 5 pixels). Our approach focuses on the specific location where the landslide starts and its proximity, unlike other works that consider the entire landslide area as the occurrence of the phenomenon. These images correspond to geological, geomorphological, hydrological and anthropological variables, which are stacked in a similar way to the channels of a conventional image to feed and train a convolutional neural network. Therefore, we improve the quality of the data and the representation of the phenomenon to obtain a more robust, reliable and accurate prediction model. The results indicate an average accuracy of 97.48%, which allows the generation of a landslide susceptibility map on the Aloag-Santo Domingo highway in Ecuador. This tool is useful for risk prevention and management in this area where small, medium and large landslides occur frequently.},
  archive      = {J_ICAE},
  author       = {Guerrero-Rodriguez, Byron and Garcia-Rodriguez, Jose and Salvador, Jaime and Mejia-Escobar, Christian and Cadena, Shirley and Cepeda, Jairo and Benavent-Lledo, Manuel and Mulero-Perez, David},
  doi          = {10.3233/ICA-230717},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {1},
  pages        = {77-94},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Improving landslide prediction by computer vision and deep learning},
  volume       = {31},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A broadcast sub-GHz framework for unmanned aerial vehicles
clock synchronization. <em>ICAE</em>, <em>31</em>(1), 59–75. (<a
href="https://doi.org/10.3233/ICA-230723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, set of cooperative drones are commonly used as aerial sensors, in order to monitor areas and track objects of interest (think, e.g., of border and coastal security and surveillance, crime control, disaster management, emergency first responder, forest and wildlife, traffic monitoring). Th e drones generate a quite large and continuous in time multimodal (audio, video and telemetry) data stream towards a ground control station with enough computing power and resources to store and process it. Hence, due to the distributed nature of this setting, further complicated by the movement and varying distance among drones, and to possible interferences and obstacles compromising communications, a common clock between the nodes is of utmost importance to make feasible a correct reconstruction of the multimodal data stream from the single datagrams, which may be received out of order or with different delays. A framework architecture, using sub-GHz broadcasting communications, is proposed to ensure time synchronization for a set of drones, allowing one to recover even in difficult situations where the usual time sources, e.g. GPS, NTP etc., are not available for all the devices. Such architecture is then implemented and tested using LoRa radios and Raspberry Pi computers. However, other sub-GHz technologies can be used in the place of LoRa, and other kinds of single-board computers can substitute the Raspberry Pis, making the proposed solution easily customizable, according to specific needs. Moreover, the proposal is low cost, since it does not require expensive hardware like, e.g., onboard Rubidium based atomic clocks. Our experiments indicate a worst case skew of about 16 ms between drones clocks, using cheap components commonly available in the market. This is sufficient to deal with audio/video footage at 30 fps. Hence, it can be viewed as a useful and easy to implement architecture helping to maintain a decent synchronization even when traditional solutions are not available.},
  archive      = {J_ICAE},
  author       = {Cecchinato, Niccolò and Scagnetto, Ivan and Toma, Andrea and Drioli, Carlo and Foresti, Gian Luca},
  doi          = {10.3233/ICA-230723},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {1},
  pages        = {59-75},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A broadcast sub-GHz framework for unmanned aerial vehicles clock synchronization},
  volume       = {31},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An explainable machine learning system for left bundle
branch block detection and classification. <em>ICAE</em>,
<em>31</em>(1), 43–58. (<a
href="https://doi.org/10.3233/ICA-230719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Left bundle branch block is a cardiac conduction disorder that occurs when the electrical impulses that control the heartbeat are blocked or delayed as they travel through the left bundle branch of the cardiac conduction system providing a characteristic electrocardiogram (ECG) pattern. A reduced s et of biologically inspired features extracted from ECG data is proposed and used to train a variety of machine learning models for the LBBB classification task. Then, different methods are used to evaluate the importance of the features in the classification process of each model and to further reduce the feature set while maintaining the classification performance. The performances obtained by the models using different metrics improve those obtained by other authors in the literature on the same dataset. Finally, XAI techniques are used to verify that the predictions made by the models are consistent with the existing relationships between the data. This increases the reliability of the models and their usefulness in the diagnostic support process. These explanations can help clinicians to better understand the reasoning behind diagnostic decisions.},
  archive      = {J_ICAE},
  author       = {Macas, Beatriz and Garrigós, Javier and Martínez, José Javier and Ferrández, José Manuel and Bonomini, María Paula},
  doi          = {10.3233/ICA-230719},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {1},
  pages        = {43-58},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {An explainable machine learning system for left bundle branch block detection and classification},
  volume       = {31},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neuro-distributed cognitive adaptive optimization for
training neural networks in a parallel and asynchronous manner.
<em>ICAE</em>, <em>31</em>(1), 19–41. (<a
href="https://doi.org/10.3233/ICA-230718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed Machine learning has delivered considerable advances in training neural networks by leveraging parallel processing, scalability, and fault tolerance to accelerate the process and improve model performance. However, training of large-size models has exhibited numerous challenges, due to the gradient dependence that conventional approaches integrate. To improve the training efficiency of such models, gradient-free distributed methodologies have emerged fostering the gradient-independent parallel processing and efficient utilization of resources across multiple devices or nodes. However, such approaches, are usually restricted to specific applications, due to their conceptual limitations: computational and communicational requirements between partitions, limited partitioning solely into layers, limited sequential learning between the different layers, as well as training a potential model in solely synchronous mode. In this paper, we propose and evaluate, the Neuro-Distributed Cognitive Adaptive Optimization (ND-CAO) methodology, a novel gradient-free algorithm that enables the efficient distributed training of arbitrary types of neural networks, in both synchronous and asynchronous manner. Contrary to the majority of existing methodologies, ND-CAO is applicable to any possible splitting of a potential neural network, into blocks (partitions) , with each of the blocks allowed to update its parameters fully asynchronously and independently of the rest of the blocks. Most importantly, no data exchange is required between the different blocks during training with the only information each block requires is the global performance of the model. Convergence of ND-CAO is mathematically established for generic neural network architectures, independently of the particular choices made, while four comprehensive experimental cases, considering different model architectures and image classification tasks, validate the algorithms’ robustness and effectiveness in both synchronous and asynchronous training modes. Moreover, by conducting a thorough comparison between synchronous and asynchronous ND-CAO training, the algorithm is identified as an efficient scheme to train neural networks in a novel gradient-independent, distributed, and asynchronous manner, delivering similar – or even improved results in Loss and Accuracy measures.},
  archive      = {J_ICAE},
  author       = {Michailidis, Panagiotis and Michailidis, Iakovos T. and Gkelios, Sokratis and Karatzinis, Georgios and Kosmatopoulos, Elias B.},
  doi          = {10.3233/ICA-230718},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {1},
  pages        = {19-41},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Neuro-distributed cognitive adaptive optimization for training neural networks in a parallel and asynchronous manner},
  volume       = {31},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Internet-of-things framework for scalable end-of-life
condition monitoring in remanufacturing. <em>ICAE</em>, <em>31</em>(1),
1–17. (<a href="https://doi.org/10.3233/ICA-230716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The worldwide generation of waste electrical and electronic equipment is continuously growing, with electric vehicle batteries reaching their end-of-life having become a key concern for both the environment and human health in recent years. In this context, the proliferation of Internet of Things s tandards and data ecosystems is advancing the feasibility of data-driven condition monitoring and remanufacturing. This is particularly desirable for the end-of-life recovery of high-value equipment towards sustainable closed-loop production systems. Low-Power Wide-Area Networks, despite being relatively recent, are starting to be conceived as key-enabling technologies built upon the principles of long-range communication and negligible energy consumption. While LoRaWAN is considered the open standard with the highest level of acceptance from both industry and academia, it is its random access protocol (Aloha) that limits its capacity in large-scale deployments to some extent. Although time-slotted scheduling has proved to alleviate certain scalability limitations, the constrained nature of end nodes and their application-oriented requirements significantly increase the complexity of time-slotted network management tasks. To shed light on this matter, a multi-agent network management system for the on-demand allocation of resources in end-of-life monitoring applications for remanufacturing is introduced in this work. It leverages LoRa’s spreading factor orthogonality and network-wide knowledge to increase the number of nodes served in time-slotted monitoring setups. The proposed system is validated and evaluated for end-of-life monitoring where two representative end-node distributions were emulated, with the achieved network capacity improvements ranging from 75.27% to 249.46% with respect to LoRaWAN’s legacy operation. As a result, the suitability of different agent-based strategies has been evaluated and a number of lessons have been drawnaccording to different application and hardware constraints. While the presented findings can be used to further improve the explainability of the proposed models (in line with the concept of eXplainable AI), the overall framework represents a step forward in lightweight end-of-life condition monitoring for remanufacturing.},
  archive      = {J_ICAE},
  author       = {Garrido-Hidalgo, Celia and Roda-Sanchez, Luis and Fernández-Caballero, Antonio and Olivares, Teresa and Ramírez, F. Javier},
  doi          = {10.3233/ICA-230716},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Internet-of-things framework for scalable end-of-life condition monitoring in remanufacturing},
  volume       = {31},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A measured data correlation-based strain estimation
technique for building structures using convolutional neural network.
<em>ICAE</em>, <em>30</em>(4), 395–412. (<a
href="https://doi.org/10.3233/ICA-230714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A machine learning-based strain estimation method for structural members in a building is presented The relationship between the strain responses of structural members is determined using a convolutional neural network (CNN) For accurate strain estimation, correlation analysis is introduced to select the optimal CNN model among responses from multiple structural members. The optimal CNN model trained using the response of the structural member with a high degree of correlation with the response of the target structural member is utilized to estimate the strain of the target structural member The proposed correlation-based technique can also provide the next best CNN model in case of defects in the sensors used to construct the optimal CNN. Validity is examined through the application of the presented technique to a numerical study on a three-dimensional steel structure and an experimental study on a steel frame specimen.},
  archive      = {J_ICAE},
  author       = {Oh, Byung Kwan and Yoo, Sang Hoon and Park, Hyo Seon},
  doi          = {10.3233/ICA-230714},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {4},
  pages        = {395-412},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A measured data correlation-based strain estimation technique for building structures using convolutional neural network},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predictor-corrector models for lightweight massive
machine-type communications in industry 4.0. <em>ICAE</em>,
<em>30</em>(4), 369–393. (<a
href="https://doi.org/10.3233/ICA-230713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future Industry 4.0 scenarios are characterized by seamless integration between computational and physical processes. To achieve this objective, dense platforms made of small sensing nodes and other resource constraint devices are ubiquitously deployed. All these devices have a limited number of computational resources, just enough to perform the simple operation they are in charge of. The remaining operations are delegated to powerful gateways that manage sensing nodes, but resources are never unlimited, and as more and more devices are deployed on Industry 4.0 platforms, gateways present more problems to handle massive machine-type communications. Although the problems are diverse, those related to security are especially critical. To enable sensing nodes to establish secure communications, several semiconductor companies are currently promoting a new generation of devices based on Physical Unclonable Functions, whose usage grows every year in many real industrial scenarios. Those hardware devices do not consume any computational resource but force the gateway to keep large key-value catalogues for each individual node. In this context, memory usage is not scalable and processing delays increase exponentially with each new node on the platform. In this paper, we address this challenge through predictor-corrector models, representing the key-value catalogues. Models are mathematically complex, but we argue that they consume less computational resources than current approaches. The lightweight models are based on complex functions managed as Laurent series, cubic spline interpolations, and Boolean functions also developed as series. Unknown parameters in these models are predicted, and eventually corrected to calculate the output value for each given key. The initial parameters are based on the Kane Yee formula. An experimental analysis and a performance evaluation are provided in the experimental section, showing that the proposed approach causes a significant reduction in the resource consumption.},
  archive      = {J_ICAE},
  author       = {Bordel, Borja and Alcarria, Ramón and Chung, Joaquin and Kettimuthu, Rajkumar},
  doi          = {10.3233/ICA-230713},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {4},
  pages        = {369-393},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Predictor-corrector models for lightweight massive machine-type communications in industry 4.0},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Connected system for monitoring electrical power
transformers using thermal imaging. <em>ICAE</em>, <em>30</em>(4),
353–368. (<a href="https://doi.org/10.3233/ICA-230712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stable supply of electricity is essential for the industrial activity and economic development as well as for human welfare. For this reason, electrical system devices are equipped with monitoring systems that facilitate their management and ensure an uninterrupted operation. This is the case of electrical power transformers, which usually have monitoring systems that allow early detection of anomalies in order to prevent potential malfunctions. These monitoring systems typically make use of sensors that are in physical contact with the transformer devices and can therefore be affected by transformer problems. In this work we demonstrate a monitoring system for electrical power transformers based on temperature measurements obtained by means of thermal cameras. Properly positioned, the cameras provide thermal data of the transformer, the incoming and outgoing lines and their surroundings. Subsequently, by appropriate image processing, it is possible to obtain temperature series to monitor the transformer operation. In addition, the system stores and processes thermal data in external equipment (placed in locations other than the transformers) and is equipped with a communications module that allows secure data transmission independent of the power grid. This aspect, along with the fact that there is no need to have physical contact with the transformer, make this approach safer and more reliable than standard approaches based on sensors. The proposed system has been evaluated in 14 stations belonging to the Spanish power grid, obtaining accurate and reliable temperature time series.},
  archive      = {J_ICAE},
  author       = {Segovia, F. and Ramírez, J. and Salas-Gonzalez, D. and Illán, I.A. and Martinez-Murcia, F.J. and Rodriguez-Rivero, J. and Leiva, F.J. and Gaitan, C. and Górriz, J.M.},
  doi          = {10.3233/ICA-230712},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {4},
  pages        = {353-368},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Connected system for monitoring electrical power transformers using thermal imaging},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving the competitiveness of aircraft manufacturing
automated processes by a deep neural network. <em>ICAE</em>,
<em>30</em>(4), 341–352. (<a
href="https://doi.org/10.3233/ICA-230711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy and reliability requirements in aerospace manufacturing processes are some of the most demanding in industry. One of the first steps is detection and precise measurement using artificial vision models to accurately process the part. However, these systems require complex adjustments and do not work correctly in uncontrolled scenarios, but require manual supervision, which reduces the autonomy of automated machinery. To solve these problems, this paper proposes a convolutional neural network for the detection and measurement of drills and other fixation elements in an uncontrolled industrial manufacturing environment. In addition, a fine-tuning algorithm is applied to the results obtained from the network, and a new metric is defined to evaluate the quality of detection. The efficiency and robustness of the proposed method were verified in a real production environment, with 99.7% precision, 97.6% recall and an overall quality factor of 96.0%. The reduction in operator intervention went from 13.3% to 0.6%. The presented work will allow the competitiveness of aircraft component manufacturing processes to increase, and working environments will be safer and more efficient.},
  archive      = {J_ICAE},
  author       = {Ruiz, Leandro and Díaz, Sebastián and González, José M. and Cavas, Francisco},
  doi          = {10.3233/ICA-230711},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {4},
  pages        = {341-352},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Improving the competitiveness of aircraft manufacturing automated processes by a deep neural network},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D reconstruction based on hierarchical reinforcement
learning with transferability. <em>ICAE</em>, <em>30</em>(4), 327–339.
(<a href="https://doi.org/10.3233/ICA-230710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D reconstruction is extremely important in CAD (computer-aided design)/CAE (computer-aided Engineering)/CAM (computer-aided manufacturing). For interpretability, reinforcement learning (RL) is used to reconstruct 3D shapes from images by a series of editing actions. However, typical applications of RL for 3D reconstruction face problems. The search space will increase exponentially with the action space due to the curse of dimensionality, which leads to low performance, especially for complex action spaces in 3D reconstruction. Additionally, most works involve training a specific agent for each shape class without learning related experiences from others. Therefore, we present a hierarchical RL approach with transferability to reconstruct 3D shapes (HRLT3D). First, actions are grouped into macro actions that can be chosen by the top-agent. Second, the task is accordingly decomposed into hierarchically simplified sub-tasks solved by sub-agents. Different from classical hierarchical RL (HRL), we propose a sub-agent based on augmented state space (ASS-Sub-Agent) to replace a set of sub-agents, which can speed up the training process due to shared learning and having fewer parameters. Furthermore, the ASS-Sub-Agent is more easily transferred to data of other classes due to the augmented diverse states and the simplified tasks. The experimental results on typical public dataset show that the proposed HRLT3D performs overwhelmingly better than recent baselines. More impressingly, the experiments also demonstrate the extreme transferability of our approach among data of different classes.},
  archive      = {J_ICAE},
  author       = {Li, Lan and He, Fazhi and Fan, Rubin and Fan, Bo and Yan, Xiaohu},
  doi          = {10.3233/ICA-230710},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {4},
  pages        = {327-339},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {3D reconstruction based on hierarchical reinforcement learning with transferability},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improvement of small objects detection in thermal images.
<em>ICAE</em>, <em>30</em>(4), 311–325. (<a
href="https://doi.org/10.3233/ICA-230715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal images are widely used for various applications such as safety, surveillance, and Advanced Driver Assistance Systems (ADAS). However, these images typically have low contrast, blurred aspect, and low resolution, making it difficult to detect distant and small-sized objects. To address these issues, this paper explores various preprocessing algorithms to improve the performance of already trained object detection networks. Specifically, mathematical morphology is used to favor the detection of small bright objects, while deblurring and super-resolution techniques are employed to enhance the image quality. The Logarithmic Image Processing (LIP) framework is chosen to perform mathematical morphology, as it is consistent with the Human Visual System. The efficacy of the proposed algorithms is evaluated on the FLIR dataset, with a sub-base focused on images containing distant objects. The mean Average-Precision (mAP) score is computed to objectively evaluate the results, showing a significant improvement in the detection of small objects in thermal images using CNNs such as YOLOv4 and EfficientDet.},
  archive      = {J_ICAE},
  author       = {Chaverot, Maxence and Carré, Maxime and Jourlin, Michel and Bensrhair, Abdelaziz and Grisel, Richard},
  doi          = {10.3233/ICA-230715},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {4},
  pages        = {311-325},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Improvement of small objects detection in thermal images},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated detection of vehicles with anomalous trajectories
in traffic surveillance videos. <em>ICAE</em>, <em>30</em>(3), 293–309.
(<a href="https://doi.org/10.3233/ICA-230706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video feeds from traffic cameras can be useful for many purposes, the most critical of which are related to monitoring road safety. Vehicle trajectory is a key element in dangerous behavior and traffic accidents. In this respect, it is crucial to detect those anomalous vehicle trajectories, that is , trajectories that depart from usual paths. In this work, a model is proposed to automatically address that by using video sequences from traffic cameras. The proposal detects vehicles frame by frame, tracks their trajectories across frames, estimates velocity vectors, and compares them to velocity vectors from other spatially adjacent trajectories. From the comparison of velocity vectors, trajectories that are very different (anomalous) from neighboring trajectories can be detected. In practical terms, this strategy can detect vehicles in wrong-way trajectories. Some components of the model are off-the-shelf, such as the detection provided by recent deep learning approaches; however, several different options are considered and analyzed for vehicle tracking. The performance of the system has been tested with a wide range of real and synthetic traffic videos.},
  archive      = {J_ICAE},
  author       = {Fernández-Rodríguez, Jose D. and García-González, Jorge and Benítez-Rochel, Rafaela and Molina-Cabello, Miguel A. and Ramos-Jiménez, Gonzalo and López-Rubio, Ezequiel},
  doi          = {10.3233/ICA-230706},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {293-309},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Automated detection of vehicles with anomalous trajectories in traffic surveillance videos},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constructing ensembles of dispatching rules for
multi-objective tasks in the unrelated machines environment.
<em>ICAE</em>, <em>30</em>(3), 275–292. (<a
href="https://doi.org/10.3233/ICA-230704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling is a frequently studied combinatorial optimisation problem that often needs to be solved under dynamic conditions and to optimise multiple criteria. The most commonly used method for solving dynamic problems are dispatching rules (DRs), simple constructive heuristics that build the sched ule incrementally. Since it is difficult to design DRs manually, they are often created automatically using genetic programming. Although such rules work well, their performance is still limited and various methods, especially ensemble learning, are used to improve them. So far, ensembles have only been used in the context of single-objective scheduling problems. This study aims to investigate the possibility of constructing ensembles of DRs for solving multi-objective (MO) scheduling problems. To this end, an existing ensemble construction method called SEC is adapted by extending it with non-dominated sorting to construct Pareto fronts of ensembles for a given MO problem. In addition, the algorithms NSGA-II and NSGA-III were adapted to construct ensembles and compared with the SEC method to demonstrate their effectiveness. All methods were evaluated on four MO problems with different number of criteria to be optimised. The results show that ensembles of DRs achieve better Pareto fronts compared to individual DRs. Moreover, the results show that SEC achieves equally good or even slightly better results than NSGA-II and NSGA-III when constructing ensembles, while it is simpler and slightly less computationally expensive. This shows the potential of using ensembles to increase the performance of individual DRs for MO problems.},
  archive      = {J_ICAE},
  author       = {\DJurasević, Marko and Gil-Gala, Francisco J. and Jakobović, Domagoj},
  doi          = {10.3233/ICA-230704},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {275-292},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Constructing ensembles of dispatching rules for multi-objective tasks in the unrelated machines environment},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic learning rates for continual unsupervised learning.
<em>ICAE</em>, <em>30</em>(3), 257–273. (<a
href="https://doi.org/10.3233/ICA-230701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dilemma between stability and plasticity is crucial in machine learning, especially when non-stationary input distributions are considered. This issue can be addressed by continual learning in order to alleviate catastrophic forgetting. This strategy has been previously proposed for supervised and reinforcement learning models. However, little attention has been devoted to unsupervised learning. This work presents a dynamic learning rate framework for unsupervised neural networks that can handle non-stationary distributions. In order for the model to adapt to the input as it changes its characteristics, a varying learning rate that does not merely depend on the training step but on the reconstruction error has been proposed. In the experiments, different configurations for classical competitive neural networks, self-organizing maps and growing neural gas with either per-neuron or per-network dynamic learning rate have been tested. Experimental results on document clustering tasks demonstrate the suitability of the proposal for real-world problems.},
  archive      = {J_ICAE},
  author       = {Fernández-Rodríguez, José David and Palomo, Esteban José and Ortiz-de-Lazcano-Lobato, Juan Miguel and Ramos-Jiménez, Gonzalo and López-Rubio, Ezequiel},
  doi          = {10.3233/ICA-230701},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {257-273},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Dynamic learning rates for continual unsupervised learning},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimized instance segmentation by super-resolution and
maximal clique generation. <em>ICAE</em>, <em>30</em>(3), 243–256. (<a
href="https://doi.org/10.3233/ICA-230700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of surveillance systems has led to exponential growth in collected data, enabling several advances in Deep Learning to exploit them and automate tasks for autonomous systems. Vehicle detection is a crucial task in the fields of Intelligent Vehicle Systems and Intelligent Transport systems, making it possible to control traffic density or detect accidents and potential risks. This paper presents an optimal meta-method that can be applied to any instant segmentation model, such as Mask R-CNN or YOLACT++. Using the initial detections obtained by these models and super-resolution, an optimized re-inference is performed, allowing the detection of elements not identified a priori and improving the quality of the rest of the detections. The direct application of super-resolution is limited because instance segmentation models process images according to a fixed dimension. Therefore, in cases where the super-resolved images exceed this fixed size, the model will rescale them again, thus losing the desired effect. The advantages of this meta-method lie mainly in the fact that it is not required to modify the model architecture or re-train it. Regardless of the size of the images given as input, super-resolved areas that fit the defined dimension of the object segmentation model will be generated. After applying our proposal, experiments show an improvement of up to 8.1% for the YOLACT++ model used in the Jena sequence of the CityScapes dataset.},
  archive      = {J_ICAE},
  author       = {García-Aguilar, Iván and García-González, Jorge and Luque-Baena, Rafael M. and López-Rubio, Ezequiel and Domínguez, Enrique},
  doi          = {10.3233/ICA-230700},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {243-256},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Optimized instance segmentation by super-resolution and maximal clique generation},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An elitist seasonal artificial bee colony algorithm for the
interval job shop. <em>ICAE</em>, <em>30</em>(3), 223–242. (<a
href="https://doi.org/10.3233/ICA-230705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel Artificial Bee Colony algorithm is proposed to solve a variant of the Job Shop Scheduling Problem where only an interval of possible processing times is known for each operation. The solving method incorporates a diversification strategy based on the seasonal behaviour of bee s. That is, the bees tend to explore more at the beginning of the search (spring) and be more conservative towards the end (summer to winter). This new strategy helps the algorithm avoid premature convergence, which appeared to be an issue in previous papers tackling the same problem. A thorough parametric analysis is conducted and a comparison of different seasonal models is performed on a set of benchmark instances from the literature. The results illustrate the benefit of using the new strategy, improving the performance of previous ABC-based methods for the same problem. An additional study is conducted to assess the robustness of the solutions obtained under different ranking operators, together with a sensitivity analysis to compare the effect that different levels of uncertainty have on the solutions’ robustness.},
  archive      = {J_ICAE},
  author       = {Díaz, Hernán and Palacios, Juan J. and González-Rodríguez, Inés and Vela, Camino R.},
  doi          = {10.3233/ICA-230705},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {223-242},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {An elitist seasonal artificial bee colony algorithm for the interval job shop},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using perceptual classes to dream policies in open-ended
learning robotics. <em>ICAE</em>, <em>30</em>(3), 205–222. (<a
href="https://doi.org/10.3233/ICA-230707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving Lifelong Open-ended Learning Autonomy (LOLA) is a key challenge in the field of robotics to advance to a new level of intelligent response. Robots should be capable of discovering goals and learn skills in specific domains that permit achieving the general objectives the designer establishes for them. In addition, robots should reuse previously learnt knowledge in different domains to facilitate learning and adaptation in new ones. To this end, cognitive architectures have arisen which encompass different components to support LOLA. A key feature of these architectures is to implement a proper balance between deliberative and reactive processes that allows for efficient real time operation and knowledge acquisition, but this is still an open issue. First, objectives must be defined in a domain-independent representation that allows for the autonomous determination of domain-dependent goals. Second, as no explicit reward function is available, a method to determine expected utility must also be developed. Finally, policy learning may happen in an internal deliberative scale (dreaming), so it is necessary to provide an efficient way to infer relevant and reliable data for dreaming to be meaningful. The first two aspects have already been addressed in the realm of the e-MDB cognitive architecture. For the third one, this work proposes Perceptual Classes (P-nodes) as a metacognitive structure that permits generating relevant “dreamt” data points that allow creating “imagined” trajectories for deliberative policy learning in a very efficient way. The proposed structure has been tested by means of an experiment with a real robot in LOLA settings, where it has been shown how policy dreaming is possible in such a challenging realm.},
  archive      = {J_ICAE},
  author       = {Romero, Alejandro and Meden, Blaz and Bellas, Francisco and Duro, Richard J.},
  doi          = {10.3233/ICA-230707},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {205-222},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Using perceptual classes to dream policies in open-ended learning robotics},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introduction. <em>ICAE</em>, <em>30</em>(3), 203. (<a
href="https://doi.org/10.3233/ICA-230708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ICAE},
  doi          = {10.3233/ICA-230708},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {203},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Introduction},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modal identification of building structures under unknown
input conditions using extended kalman filter and long-short term
memory. <em>ICAE</em>, <em>30</em>(2), 185–201. (<a
href="https://doi.org/10.3233/ICA-220696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various system identification (SI) techniques have been developed to ensure the sufficient structural performance of buildings. Recently, attempts have been made to solve the problem of the excessive computational time required for operational modal analysis (OMA), which is involved in SI, by using the deep learning (DL) algorithm and to overcome the limited applicability to structural problems of extended Kalman filter (EKF)-based SI technology through the development of a method enabling SI under unknown input conditions by adding a term for the input load to the algorithm. Although DL-based OMA methods and EKF-based SI techniques under unknown input conditions are being developed in various forms, they still produce incomplete identification processes when extracting the identification parameters. The neural network of the developed DL-based OMA method fails to extract all modal parameters perfectly, and EKF-based SI techniques has the limitations of a heavy algorithm and an increased computational burden with an input load term added to the algorithm. Therefore, this study proposes an EKF-based long short-term memory (EKF-LSTM) method that can identify modal parameters. The proposed EKF-LSTM method applies modal-expanded dynamic governing equations to the EKF to identify the modal parameters, where the input load used in the EKF algorithm is estimated using the LSTM method. The EKF-LSTM method can identify all modal parameters using the EKF, which is highly applicable to structural problems. Because the proposed method estimates the input load through an already trained LSTM network, there is no problem with computational burden when estimating the input load. The proposed EKF-LSTM method was verified using a numerical model with three degrees of freedom, and its effectiveness was confirmed by utilizing a steel frame structure model with three floors.},
  archive      = {J_ICAE},
  author       = {Yun, Da Yo and Park, Hyo Seon},
  doi          = {10.3233/ICA-220696},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {3},
  number       = {2},
  pages        = {185-201},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Modal identification of building structures under unknown input conditions using extended kalman filter and long-short term memory},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using sensor data to detect time-constraints in ontology
evolution. <em>ICAE</em>, <em>30</em>(2), 169–184. (<a
href="https://doi.org/10.3233/ICA-230703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an architecture for time-constrained ontology evolution comprised of two tools: the J2OIM (JSON to Ontology Instance Mapper), which uses JavaScript Object Notation (JSON) objects to populate an ontology, and TICO (Time Constrained instance-guided Ontology evolution), which analyses streams or batches of instances as they are generated and attempts to identify potential changes to their definitions that may trigger evolutionary processes. These tools help compensate for identified gaps in literature in instance mapping and modular versioning. The case-study for these tools involves a predictive maintenance (PdM) scenario in which near real-time data sensor enriched by contextual data is continuously transformed into ontology individuals that trigger ontology evolution mechanisms. Results show it is possible to use the instance mapping mechanisms in an incremental fashion while assuring no duplicates are generated and the aggregation of similar information from distinct data points into intervals. Furthermore, they show how the ontology evolution processes effectively detect variations in ontology individuals, generating and updating existing concepts and roles.},
  archive      = {J_ICAE},
  author       = {Canito, Alda and Nobre, Armando and Neves, José and Corchado, Juan and Marreiros, Goreti},
  doi          = {10.3233/ICA-230703},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {3},
  number       = {2},
  pages        = {169-184},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Using sensor data to detect time-constraints in ontology evolution},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced memetic search for reducing energy consumption in
fuzzy flexible job shops. <em>ICAE</em>, <em>30</em>(2), 151–167. (<a
href="https://doi.org/10.3233/ICA-230699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible job shop is a well-known scheduling problem that has historically attracted much research attention both because of its computational complexity and its importance in manufacturing and engineering processes. Here we consider a variant of the problem where uncertainty in operation processing times is modeled using triangular fuzzy numbers. Our objective is to minimize the total energy consumption, which combines the energy required by resources when they are actively processing an operation and the energy consumed by these resources simply for being switched on. To solve this NP-Hard problem, we propose a memetic algorithm, a hybrid metaheuristic method that combines global search with local search. Our focus has been on obtaining an efficient method, capable of obtaining similar solutions quality-wise to the state of the art using a reduced amount of time. To assess the performance of our algorithm, we present an extensive experimental analysis that compares it with previous proposals and evaluates the effect on the search of its different components.},
  archive      = {J_ICAE},
  author       = {García Gómez, Pablo and González-Rodríguez, Inés and Vela, Camino R.},
  doi          = {10.3233/ICA-230699},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {3},
  number       = {2},
  pages        = {151-167},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Enhanced memetic search for reducing energy consumption in fuzzy flexible job shops},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fitting algorithm based on multi-touch gesture for rapid
generation of railway line. <em>ICAE</em>, <em>30</em>(2), 135–150. (<a
href="https://doi.org/10.3233/ICA-230697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-computer interaction (HCI) technology plays a critically essential role in the computer-aided design of railway line locations. However, the traditional interactive design with a mouse+keyboard cannot well meet the rapid generation requirements of the railway line during scheme discussion. This research presents a fitting algorithm for the rapid generation of railway lines by using a multi-touch gesture algorithm. The fitting method from free hand-drawing lines to satisfied railway lines is proposed. Then the interactive operation hand gestures are defined and implemented into the railway line location design. The hand-drawing lines generated by defined gestures are automatically fitted with the target horizontal line by using the inflection detection algorithm based on Euclidean Distance (ED). Meanwhile, the vertical line can be fitted by a similar algorithm with an extreme point-to-point (EPP) and chord-to-point distance accumulation (CPDA). Moreover, a real-world example verification is carried out. The multi-touch gesture algorithm is applied for the automatic fitting of the railway line. Compared with the traditional interactive methods, the consumption time of railway line generation by using the multi-touch interactive mode is decreased by about 15%. This research provides fundamental support for rapid scheme discussion of railway line generation based on natural HCI, which is well-matched with modern handheld devices, and the requirements of rapid selection as well as the quick comparison of railway line schemes in the early stage of design.},
  archive      = {J_ICAE},
  author       = {Nie, Liangtao and Zhang, Ruilin and Hu, Ting and Tang, Zhe and Fang, Mingjing and Lv, Xikui and Zhang, Ruitao},
  doi          = {10.3233/ICA-230697},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {3},
  number       = {2},
  pages        = {135-150},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A fitting algorithm based on multi-touch gesture for rapid generation of railway line},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved deep learning architecture for multi-object
tracking systems. <em>ICAE</em>, <em>30</em>(2), 121–134. (<a
href="https://doi.org/10.3233/ICA-230702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust and reliable 3D multi-object tracking (MOT) is essential for autonomous driving in crowded urban road scenes. In those scenarios, accurate data association between tracked objects and incoming new detections is crucial. This paper presents a tracking system based on the Kalman filter that us es a deep learning approach to the association problem. The proposed architecture consists of three neural networks. First, a convolutional LSTM network extracts spatiotemporal features from a sequence of detections of the same track. Then, a Siamese network calculates the degree of similarity between all tracks and the new detections found at each new frame. Finally, a recurrent LSTM network is used to extract 3D and bounding box information. This model follows the tracking-by-detection paradigm and has been trained with track sequences to be able to handle missed observations and to reduce identity switches. A validation test was carried out on the Argoverse dataset to validate the performance of the proposed system. The developed deep learning approach could improve current multi-object tracking systems based on classic algorithms like the Kalman filter.},
  archive      = {J_ICAE},
  author       = {Urdiales, Jesús and Martín, David and Armingol, José María},
  doi          = {10.3233/ICA-230702},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {3},
  number       = {2},
  pages        = {121-134},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {An improved deep learning architecture for multi-object tracking systems},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A human-simulated fuzzy membrane approach for the joint
controller of walking biped robots. <em>ICAE</em>, <em>30</em>(2),
105–120. (<a href="https://doi.org/10.3233/ICA-230698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To guarantee their locomotion, biped robots need to walk stably. The latter is achieved by a high performance in joint control. This article addresses this issue by proposing a novel human-simulated fuzzy (HF) membrane control system of the joint angles. The proposed control system, human-simulated fuzzy membrane controller (HFMC), contains several key elements. The first is an HF algorithm based on human-simulated intelligent control (HSIC). This HF algorithm incorporates elements of both multi-mode proportional-derivative (PD) and fuzzy control, aiming at solving the chattering problem of multi-mode switching while improving control accuracy. The second is a membrane architecture that makes use of the natural parallelisation potential of membrane computing to improve the real-time performance of the controller. The proposed HFMC is utilised as the joint controller for a biped robot. Numerical tests in a simulation are carried out with the planar and slope walking of a five-link biped robot, and the effectiveness of the HFMC is verified by comparing and evaluating the results of the designed HFMC, HSIC and PD. Experimental results demonstrate that the proposed HFMC not only retains the advantages of traditional PD control but also improves control accuracy, real-time performance and stability.},
  archive      = {J_ICAE},
  author       = {Liu, Xingyang and Zhang, Gexiang and Mastoi, Muhammad Shahid and Neri, Ferrante and Pu, Yang},
  doi          = {10.3233/ICA-230698},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {3},
  number       = {2},
  pages        = {105-120},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A human-simulated fuzzy membrane approach for the joint controller of walking biped robots},
  volume       = {30},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
