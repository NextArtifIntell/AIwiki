<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mis---50">MIS - 50</h2>
<ul>
<li><details>
<summary>
(2023). Parallel intelligence in CPSSs: Being, becoming, and
believing. <em>MIS</em>, <em>38</em>(6), 75–80. (<a
href="https://doi.org/10.1109/MIS.2023.3284694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent debut and success of ChatGPT have brought up renewed debates and desires for artificial general intelligence (AGI) amid fears and anxieties of potential disruptions to our humanity and social values, as witnessed by the call from tech celebrities for a pause in the development of ChatGPT-style AGI tools. At the IEEE IS’ AI and CPSS Department, we would like to initiate cautious, balanced, hopefully deep investigations to address various related issues on the impact and significance of intelligent science and technology to our economy and society. Let’s start with the “three Bs” and “ACP” for parallel intelligence in CPSSs: Being by artificial systems (A), Becoming through computational experiments (C), and Believing with parallel execution (P).},
  archive      = {J_MIS},
  author       = {Jing Yang and Xiao Wang and Yonglin Tian and Xiao Wang and Fei-Yue Wang},
  doi          = {10.1109/MIS.2023.3284694},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {75-80},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Parallel intelligence in CPSSs: Being, becoming, and believing},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart decentralized autonomous organizations and operations
for smart societies: Human–autonomous organizations for industry 5.0 and
society 5.0. <em>MIS</em>, <em>38</em>(6), 70–74. (<a
href="https://doi.org/10.1109/MIS.2023.3324471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores the concept of human–autonomous organizations (HAOs) based on decentralized autonomous organizations (DAOs) and operations as well as human, artificial, natural, and organizational intelligence and their roles in shaping smart societies in the context of Industry 5.0 and Society 5.0. It discusses the potential of AI-generated content and prompt engineering in specific goal-guided manufacture and governance. Additionally, the article introduces the concept of the HAO as a framework for integrating human intelligence to achieve fair, transparent, and accountable decision making within DAOs. The proposed HAO reduces the risk of instability and unreliability in “human-in-the-loop” copilot systems and human–machine hybrid systems, leading to more reliable, secure, and flexible systems. It provides insights into the future management of smart societies and the symbiotic relationship between human ingenuity and the suite of emerging new AI technologies.},
  archive      = {J_MIS},
  author       = {Xiao Wang and Yutong Wang and Mariana Netto and Larry Stapleton and Zhe Wan and Fei-Yue Wang},
  doi          = {10.1109/MIS.2023.3324471},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {70-74},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Smart decentralized autonomous organizations and operations for smart societies: Human–Autonomous organizations for industry 5.0 and society 5.0},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seven pillars for the future of artificial intelligence.
<em>MIS</em>, <em>38</em>(6), 62–69. (<a
href="https://doi.org/10.1109/MIS.2023.3329745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence (AI) research has showcased tremendous potential to positively impact humanity and society. Although AI frequently outperforms humans in tasks related to classification and pattern recognition, it continues to face challenges when dealing with complex tasks such as intuitive decision making, sense disambiguation, sarcasm detection, and narrative understanding as these require advanced kinds of reasoning, e.g., common-sense reasoning and causal reasoning, which have not been emulated satisfactorily yet. To address these shortcomings, we propose seven pillars that we believe represent the key hallmark features for the future of AI, namely, multidisciplinarity, task decomposition, parallel analogy, symbol grounding, similarity measure, intention awareness, and trustworthiness.},
  archive      = {J_MIS},
  author       = {Erik Cambria and Rui Mao and Melvin Chen and Zhaoxia Wang and Seng-Beng Ho},
  doi          = {10.1109/MIS.2023.3329745},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {62-69},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Seven pillars for the future of artificial intelligence},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unjustified sample sizes and generalizations in explainable
artificial intelligence research: Principles for more inclusive user
studies. <em>MIS</em>, <em>38</em>(6), 52–60. (<a
href="https://doi.org/10.1109/MIS.2023.3320433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many ethical frameworks require artificial intelligence (AI) systems to be explainable. Explainable AI (XAI) models are frequently tested for their adequacy in user studies. Since different people may have different explanatory needs, it is important that participant samples in user studies are large enough to represent the target population to enable generalizations. However, it is unclear to what extent XAI researchers reflect on and justify their sample sizes or avoid broad generalizations across people. We analyzed XAI user studies (n = 220) published between 2012 and 2022. Most of the studies did not offer rationales for their sample sizes. Moreover, most of the papers generalized their conclusions beyond their study population, and there was no evidence that broader conclusions in quantitative studies were correlated with larger samples. These methodological problems can impede evaluations of whether XAI systems implement the explainability called for in ethical frameworks. We outline principles for more inclusive XAI user studies.},
  archive      = {J_MIS},
  author       = {Uwe Peters and Mary Carman},
  doi          = {10.1109/MIS.2023.3320433},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {52-60},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Unjustified sample sizes and generalizations in explainable artificial intelligence research: Principles for more inclusive user studies},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing responsible chatbots for financial services: A
pattern-oriented responsible artificial intelligence engineering
approach. <em>MIS</em>, <em>38</em>(6), 42–51. (<a
href="https://doi.org/10.1109/MIS.2023.3320437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent release of ChatGPT has gained huge attention and discussion worldwide, with responsible artificial intelligence (RAI) being a crucial topic of discussion. One key question is, “How can we ensure that AI systems, like ChatGPT, are developed and adopted in a responsible way?” To tackle RAI challenges, various ethical principles have been released by governments, organizations, and companies. However, those principles are very abstract and not practical enough. Further, significant efforts have been put on algorithm-level solutions that only address a narrow set of principles, such as fairness and privacy. To fill the gap, we adopt a pattern-oriented RAI engineering approach and build an RAI pattern catalog to operationalize RAI from a system perspective. In this article, we first summarize the major challenges in operationalizing RAI at scale and introduce how we use the RAI pattern catalog to address those challenges. We then examine the risks at each stage of the chatbot development process and recommend pattern-driven mitigations to evaluate the usefulness of the RAI pattern catalog in a real-world setting.},
  archive      = {J_MIS},
  author       = {Qinghua Lu and Yuxiu Luo and Liming Zhu and Mingjian Tang and Xiwei Xu and Jon Whittle},
  doi          = {10.1109/MIS.2023.3320437},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {42-51},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Developing responsible chatbots for financial services: A pattern-oriented responsible artificial intelligence engineering approach},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). If our aim is to build morality into an artificial agent,
how might we begin to go about doing so? <em>MIS</em>, <em>38</em>(6),
35–41. (<a href="https://doi.org/10.1109/MIS.2023.3320875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As AI becomes pervasive in most fields, from health care to autonomous driving, it is essential that we find successful ways of building morality into our machines, especially for decision making. However, the question of what it means to be moral is still debated, particularly in the context of AI. In this article, we highlight the different aspects that should be considered when building moral agents, including the most relevant moral paradigms and challenges. We also discuss the top-down and bottom-up approaches to design and the role of emotion and sentience in morality. We then propose solutions, including a hybrid approach to design and a hierarchical approach to combining moral paradigms. We emphasize how governance and policy are becoming ever more critical in AI ethics and in ensuring that the tasks we set for moral agents are attainable, that ethical behavior is achieved, and that we obtain good AI.},
  archive      = {J_MIS},
  author       = {Reneira Seeamber and Cosmin Badea},
  doi          = {10.1109/MIS.2023.3320875},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {35-41},
  shortjournal = {IEEE Intell. Syst.},
  title        = {If our aim is to build morality into an artificial agent, how might we begin to go about doing so?},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The importance of an ethical framework for trust calibration
in AI. <em>MIS</em>, <em>38</em>(6), 27–34. (<a
href="https://doi.org/10.1109/MIS.2023.3320443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transformative power of AI raises serious concerns about ethical issues within organizations and implicates the need for trust. To cope with that, numerous ethical frameworks are generally published, but only on a theoretical level. Furthermore, proper trust calibration in AI is of high relevance for the workers. Up to now, only limited studies have been carried out to investigate how an ethical framework can foster proper trust calibration of workers in practice. To close this gap, an ethical framework is investigated that ensures trust calibration by targeting AI reliability and AI safety. Finally, the effectiveness of the applied framework is evaluated based on 17 interviews within an international automotive supplier. As a result, this ethical framework led to a major increase in trust. This is a groundbreaking outcome since workers are willing to accept a lower level of AI safety and AI reliability at the same time.},
  archive      = {J_MIS},
  author       = {Amelie Schmid and Manuel Wiesche},
  doi          = {10.1109/MIS.2023.3320443},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {27-34},
  shortjournal = {IEEE Intell. Syst.},
  title        = {The importance of an ethical framework for trust calibration in AI},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Whom to trust, how and why: Untangling artificial
intelligence ethics principles, trustworthiness, and trust.
<em>MIS</em>, <em>38</em>(6), 19–26. (<a
href="https://doi.org/10.1109/MIS.2023.3322586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present an overview of the literature on trust in artificial intelligence (AI) and AI trustworthiness and argue for distinguishing these concepts more clearly and gathering more empirically evidence on what contributes to people’s trusting behaviors. We discuss that trust in AI involves not only reliance on the system itself but also trust in the system’s developers. AI ethics principles such as explainability and transparency are often assumed to promote user trust, but empirical evidence of how such features actually affect how users perceive the system’s trustworthiness is not as abundant or not that clear. AI systems should be recognized as sociotechnical systems, where the people involved in designing, developing, deploying, and using the system are as important as the system for determining whether it is trustworthy. Without recognizing these nuances, “trust in AI” and “trustworthy AI” risk becoming nebulous terms for any desirable feature for AI systems.},
  archive      = {J_MIS},
  author       = {Andreas Duenser and David M. Douglas},
  doi          = {10.1109/MIS.2023.3322586},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {19-26},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Whom to trust, how and why: Untangling artificial intelligence ethics principles, trustworthiness, and trust},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The building blocks of a responsible artificial intelligence
practice: An outlook on the current landscape. <em>MIS</em>,
<em>38</em>(6), 9–18. (<a
href="https://doi.org/10.1109/MIS.2023.3320438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For artificial intelligence (AI)-driven companies, awareness of the urgency of the responsible application of AI became essential with increased interest from different stakeholders. Responsible AI (RAI) has emerged as a practice to guide the design, development, deployment, and use of AI systems to ensure a benefit to users and those impacted by the systems’ outcomes. This benefit is achieved through trustworthy models and strategies that assimilate ethical principles to ensure compliance with regulations and standards for long-term trust. However, RAI comes with the challenge of lack of standardization when it comes to which principles to adopt, what they mean, and how they can be operationalized. This article aims to bridge the gap between principles and practice through a study of different approaches taken in the literature and the proposition of a foundational framework.},
  archive      = {J_MIS},
  author       = {Maryem Marzouk and Cyrine Zitoun and Oumaima Belghith and Sabri Skhiri},
  doi          = {10.1109/MIS.2023.3320438},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {9-18},
  shortjournal = {IEEE Intell. Syst.},
  title        = {The building blocks of a responsible artificial intelligence practice: An outlook on the current landscape},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence ethics and trust: From principles to
practice. <em>MIS</em>, <em>38</em>(6), 5–8. (<a
href="https://doi.org/10.1109/MIS.2023.3324470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the proliferation of ethical frameworks of artificial intelligence (AI) from different organizations such as government agencies, large corporations, and academic institutions, it is still a challenge to implement and operationalize ethical and legal frameworks for AI in practice due to its complexities. The implementation and operationalization involve different aspects in original theoretical and practical research on designing, developing, presenting, testing, and evaluating approaches, which are supported by advanced AI techniques and interdisciplinary research, in particular, social science, law, and cognitive science. This editorial provides an overview of the field of operationalization of AI ethics and trust, and highlights a few key topics covered in this special issue, i.e., the current landscape of AI ethics implementation, trust and trustworthiness in AI, ethical framework for trust calibration, approaches to build morality in AI, implementation of AI ethics with a pattern-oriented engineering approach, and inclusive user studies.},
  archive      = {J_MIS},
  author       = {Fang Chen and Jianlong Zhou and Andreas Holzinger and Kenneth R. Fleischmann and Simone Stumpf},
  doi          = {10.1109/MIS.2023.3324470},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {5-8},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Artificial intelligence ethics and trust: From principles to practice},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CRule: Category-aware symbolic multihop reasoning on
knowledge graphs. <em>MIS</em>, <em>38</em>(5), 56–64. (<a
href="https://doi.org/10.1109/MIS.2023.3291567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multihop reasoning is essential in knowledge graph (KG) research and applications. Current methods rely on specific KG entities, while human cognition operates at a more abstract level. This article proposes a category-aware rule-based (CRule) approach for symbolic multihop reasoning. Specifically, given a KG, CRule first categorizes entities and constructs a category-aware KG; it then uses rules retrieved from the categorized KG to perform multihop reasoning on the original KG. Experiments on five datasets show that CRule is simple, is effective, and combines the advantages of symbolic and neural network methods. It overcomes symbolic reasoning’s complexity limitations, can perform reasoning on KGs of more than 300,000 edges, and can be three times more efficient than neural network models.},
  archive      = {J_MIS},
  author       = {Zikang Wang and Linjing Li and Jinlin Li and Pengfei Zhao and Daniel Zeng},
  doi          = {10.1109/MIS.2023.3291567},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {56-64},
  shortjournal = {IEEE Intell. Syst.},
  title        = {CRule: Category-aware symbolic multihop reasoning on knowledge graphs},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The SRVM: A similarity-based relevance vector machine for
remaining useful lifetime prediction in the industrial internet of
things. <em>MIS</em>, <em>38</em>(5), 45–55. (<a
href="https://doi.org/10.1109/MIS.2023.3289067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of Industry 4.0 and intelligent manufacturing, remaining useful lifetime (RUL) prediction can forecast the future degradation state of machinery and then estimate the remaining service time before it loses its safe operation ability. Accordingly, a series of predictive maintenance strategies can be regulated in advance for equipment in the Industrial Internet of Things. To tackle the challenges of insufficiency of failure data and lack of confidence in RUL prediction results, a similarity-based relevance vector machine (SRVM) is proposed in this article. Primarily, the relationship among latent variables in the SRVM is learned adaptively through similarity computations to fully utilize the limited degradation data. Furthermore, these internal variables in the SRVM are treated as time-varying variables and re-estimated dynamically to provide RUL prediction with reliable confidence. The experiment results show that the prediction accuracy of the SRVM is higher than that of other baseline methods.},
  archive      = {J_MIS},
  author       = {Guorui Li and Yajun Wu and Cong Wang and Sancheng Peng and Jianwei Niu and Shui Yu},
  doi          = {10.1109/MIS.2023.3289067},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {45-55},
  shortjournal = {IEEE Intell. Syst.},
  title        = {The SRVM: A similarity-based relevance vector machine for remaining useful lifetime prediction in the industrial internet of things},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Big data analytics and mental health: Would ethics be the
only safeguard against the risks of identifying “potential patients”?
<em>MIS</em>, <em>38</em>(5), 37–44. (<a
href="https://doi.org/10.1109/MIS.2023.3287409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite all the prospects for data growth, sharing, and processing, and all the benefits that big data can bring, this revolution is not exempt from risks. Even if, at some point, computers may be able to provide diagnoses with greater accuracy than medical professionals, would ethics be the only safeguard against the possible risks? In this article, we implement a pragmatic approach to answer this question by focusing on possible outcomes concerning “potential patients.” We define a “potential patient” as an individual who has not yet shown obvious or early signs of disease. Through the outcomes and inferences derived from big data analysis, such a patient could potentially require early treatment, more accurate diagnoses, and medications that are better adapted to the patient’s conditions.},
  archive      = {J_MIS},
  author       = {Kevin Palomino and Carmen Berdugo},
  doi          = {10.1109/MIS.2023.3287409},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {37-44},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Big data analytics and mental health: Would ethics be the only safeguard against the risks of identifying “Potential patients”?},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective interpretable policy distillation via critical
experience point identification. <em>MIS</em>, <em>38</em>(5), 28–36.
(<a href="https://doi.org/10.1109/MIS.2023.3265868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretable policy distillation aims to imitate a deep reinforcement learning (DRL) policy into a self-explainable model. However, the distilled policy usually does not generalize well to complex tasks. To investigate this phenomenon, we examine the experience pools of DRL tasks and find that these interactive experience distributions are heavy tailed. However, this critical issue is largely ignored by existing approaches, and, thus, they do not fully unitize the less frequent but very critical experience points. To address this issue, we propose characterizing decision boundaries via the minimum experience retention to deal with the heavy-tailed experience distributions. Our method identifies critical experience points that are close to the model’s decision boundaries, and such experience points are more critical because they portray the prerequisite of a model to take an action. As a result, our method distills the DRL policy to a self-explainable structure without a neural structure and ambiguous intermediate parameters. Through experiments on six games, we show that our method outperforms the state-of-the-art baselines in cumulative rewards, stability, and faithfulness.},
  archive      = {J_MIS},
  author       = {Xiao Liu and Shuyang Liu and Bo An and Yang Gao and Shangdong Yang and Wenbin Li},
  doi          = {10.1109/MIS.2023.3265868},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {28-36},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Effective interpretable policy distillation via critical experience point identification},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effectively modeling sentence interactions with
factorization machines for fact verification. <em>MIS</em>,
<em>38</em>(5), 18–27. (<a
href="https://doi.org/10.1109/MIS.2023.3301170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fact verification is a very challenging task that requires retrieving multiple evidence sentences from a reliable corpus to authenticate claims. Many claims require the simultaneous integration and reasoning of several pieces of evidence for verification. Existing models exhibit limitations in two aspects: 1) during the sentence selection stage, they only consider the interaction between the claim and the evidence, disregarding the intersentence information, and 2) most fusion strategies employed in current research, such as addition, concatenation, or simple neural networks, fail to capture the relationships and logical information among the evidence. To alleviate these problems, we propose select and fact verification modeling (SFVM). Our model utilizes a multihead self-attention mechanism combined with a gating mechanism to facilitate sentence interaction and enhance sentence embeddings. Then, we utilize factorization machines to effectively express the compressed alignment vectors, which are then used to expand the representations of the base evidence. To distinguish the importance of features, we use the evidence fusion network to determine the importance of various feature interactions. Results from experiments on the two public datasets showed that SFVM can utilize richer information between the claim and the evidence for fact verification and achieve competitive performance on the FEVER dataset.},
  archive      = {J_MIS},
  author       = {Zhendong Chen and Fuzhen Zhuang and Lejian Liao and Meihuizi Jia and Jiaqi Li and Heyan Huang},
  doi          = {10.1109/MIS.2023.3301170},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {18-27},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Effectively modeling sentence interactions with factorization machines for fact verification},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Why do we need neurosymbolic AI to model pragmatic
analogies? <em>MIS</em>, <em>38</em>(5), 12–16. (<a
href="https://doi.org/10.1109/MIS.2023.3305862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hallmark of intelligence is the ability to use a familiar domain to make inferences about a less familiar domain, known as analogical reasoning. In this article, we delve into the performance of large language models (LLMs) in dealing with progressively complex analogies expressed in unstructured text. We discuss analogies at four distinct levels of complexity: lexical, syntactic, semantic, and pragmatic. As the analogies become more complex, they require increasingly extensive, diverse knowledge beyond the textual content, unlikely to be found in the lexical co-occurrence statistics that power LLMs. We discuss neurosymbolic AI techniques that combine statistical and symbolic AI, informing the representation of unstructured text to highlight and augment relevant content, provide abstraction, and guide the mapping process. This maintains the efficiency of LLMs while preserving the ability to explain analogies for pedagogical applications.},
  archive      = {J_MIS},
  author       = {Thilini Wijesiriwardene and Amit Sheth and Valerie L. Shalin and Amitava Das},
  doi          = {10.1109/MIS.2023.3305862},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {12-16},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Why do we need neurosymbolic AI to model pragmatic analogies?},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Can ChatGPT’s responses boost traditional natural language
processing? <em>MIS</em>, <em>38</em>(5), 5–11. (<a
href="https://doi.org/10.1109/MIS.2023.3305861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The employment of foundation models is steadily expanding, especially with the launch of ChatGPT and the release of other foundation models. These models have shown the potential of emerging capabilities to solve problems without being particularly trained to solve them. A previous work demonstrated these emerging capabilities in affective computing tasks; the performance quality was similar to that of traditional natural language processing (NLP) techniques but fell short of specialized trained models, like fine-tuning of the RoBERTa language model. In this work, we extend this by exploring whether ChatGPT has novel knowledge that would enhance existing specialized models when they are fused together. We achieve this by investigating the utility of verbose responses from ChatGPT for solving a downstream task in addition to studying the utility of fusing that with existing NLP methods. The study is conducted on three affective computing problems: namely, sentiment analysis, suicide tendency detection, and big-five personality assessment. The results conclude that ChatGPT has, indeed, novel knowledge that can improve existing NLP techniques by way of fusion, be it early or late fusion.},
  archive      = {J_MIS},
  author       = {Mostafa M. Amin and Erik Cambria and Björn W. Schuller},
  doi          = {10.1109/MIS.2023.3305861},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {5-11},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Can ChatGPT’s responses boost traditional natural language processing?},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine ethics research: Promises and potential pitfalls.
<em>MIS</em>, <em>38</em>(4), 62–68. (<a
href="https://doi.org/10.1109/MIS.2023.3283169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How should machines treat people? What would it take to develop an ethical machine? These questions were the focus of a 2006 special issue, as well as the Association for the Advancement of Artificial Intelligence 2005 Fall Symposium on Machine Ethics. Since then, ethical issues surrounding AI and data analytics—lately referred to by the umbrella term FATE: Fairness, Accountability, Transparency and Ethics—have captured the attention of researchers and practitioners working in broad areas. We reflect on how ethics research has evolved, highlighting key points of progress, but also noting some possible challenges and pitfalls that we must bear in mind.},
  archive      = {J_MIS},
  author       = {Jahna Otterbacher and Yannis Manolopoulos},
  doi          = {10.1109/MIS.2023.3283169},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {62-68},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Machine ethics research: Promises and potential pitfalls},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal fusion-based image hiding algorithm for secure
healthcare system. <em>MIS</em>, <em>38</em>(4), 53–61. (<a
href="https://doi.org/10.1109/MIS.2022.3210331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of artificial intelligence plays a significant role of multimedia applications, especially in the healthcare domain. However, it has brought about the problem of sensitive information leakage. To address these challenges, an interesting multimodal fusion-based robust image hiding algorithm is proposed in this article. First, fused image is considered as mark image generated from MRI and CT images using nonsubsampled shearlet transform. Second, we employed principal component analysis to compute the appropriate coefficients of cover image for embedding purpose. Third, fused mark image is Arnold cat map encoded to address the security issue hidden mark media. Finally, the fusion of fractional dual-tree complex wavelet transform and randomized singular value decomposition is utilized to conceal encrypted fused mark media inside host image. Our findings show that the proposed algorithm outperforms some of the recent techniques in terms of high robustness and invisibility.},
  archive      = {J_MIS},
  author       = {Om Prakash Singh and Amit Kumar Singh and Huiyu Zhou},
  doi          = {10.1109/MIS.2022.3210331},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {53-61},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Multimodal fusion-based image hiding algorithm for secure healthcare system},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning and smart contract-assisted secure data
sharing for IoT-based intelligent agriculture. <em>MIS</em>,
<em>38</em>(4), 42–51. (<a
href="https://doi.org/10.1109/MIS.2022.3201553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent development of Internet of Things (IoT) and unmanned aerial vehicles (UAVs) has revolutionized traditional agriculture with intelligence and automation. In a typical intelligent agriculture (IA) ecosystem, massive and real-time data are generated, analyzed, and sent to the cloud server (CS) for the purpose of addressing complex agricultural issues, such as yield prediction, water feed calculation, and so on. This helps farmer and associated stakeholders to take correct decision that improves the yield and quality of agricultural product. However, the distributed nature of IA entities and the usage of insecure wireless communication open various challenges related to data sharing, monitoring, storage, and further makes the entire IA ecosystem vulnerable to various potential attacks. In this article, we exploit deep learning and smart contract to propose a new IoT-enabled IA framework for enabling secure data sharing among its various entities. Specifically, first we develop new authentication and key management scheme to ensure secure data transmission in IoT-enabled IA. The encrypted transactions are then used by the CS to analyze and further detect intrusions by a novel deep learning architecture. In CS, the smart contract (SC)-based consensus mechanism is executed on legitimate transactions that verifies and adds the formed blocks into blockchain by a peer-to-peer CSs network. In comparison to existing competing security solutions, a rigorous comparative research demonstrates that the proposed approach provides greater security and more utility characteristics.},
  archive      = {J_MIS},
  author       = {Randhir Kumar and Prabhat Kumar and Ahamed Aljuhani and A. K. M. Najmul Islam and Alireza Jolfaei and Sahil Garg},
  doi          = {10.1109/MIS.2022.3201553},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {42-51},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Deep learning and smart contract-assisted secure data sharing for IoT-based intelligent agriculture},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fault diagnosis of rotating machinery based on a mutual
dimensionless index and a convolution neural network. <em>MIS</em>,
<em>38</em>(4), 33–41. (<a
href="https://doi.org/10.1109/MIS.2023.3273450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the fault diagnosis process of petrochemical rotating machinery, it is difficult to accurately identify faults by relying only on dimensionless index methods. Therefore, a fault diagnosis of rotating machinery based on mutual dimensionless index and a convolution neural network is proposed. First, it collects the rotating machinery fault signal of the petrochemical large unit and mutual dimensionless index. Then the sensitivity analysis of mutual dimensionless index is carried out to extract the sensitive features. And then, the sensitive feature samples are mapped to the common subspace of the adversarial network for capacity augmentation. Finally, the sensitive features sample after capacity is input to the convolutional neural network for recognition. Through the verification of the petrochemical experimental platform fault and the wind turbine blade fault, The proposed method has a good diagnosis effect and can adapt to complex on-site conditions.},
  archive      = {J_MIS},
  author       = {Naiquan Su and Qinghua Zhang and Lingmeng Zhou and Xiaoxiao Chang and Ting Xu},
  doi          = {10.1109/MIS.2023.3273450},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {33-41},
  shortjournal = {IEEE Intell. Syst.},
  title        = {A fault diagnosis of rotating machinery based on a mutual dimensionless index and a convolution neural network},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New user intent discovery with robust pseudo label training
and source domain joint training. <em>MIS</em>, <em>38</em>(4), 21–31.
(<a href="https://doi.org/10.1109/MIS.2023.3283909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering new user intents based on existing intents from constantly incoming unlabeled data is an important task in many intelligent systems deployed in the real world (e.g., dialogue systems). Since data with new intents are completely unlabeled, most current approaches employ clustering methods to generate pseudo labels to train their models. However, due to intent gaps between existing and new intents, pseudo labels generated by these models are noisy, and prior knowledge from existing intents is not fully utilized. To mitigate these issues, we propose a robust pseudo label training and source domain joint-training network to refine the noisy pseudo labels and make full use of prior knowledge. Experimental results on three intent detection datasets show that our model is more effective and robust than state-of-the-art methods. The code and data are released at https://github.com/Lackel/PTJN.},
  archive      = {J_MIS},
  author       = {Wenbin An and Feng Tian and Ping Chen and Qinghua Zheng and Wei Ding},
  doi          = {10.1109/MIS.2023.3283909},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {21-31},
  shortjournal = {IEEE Intell. Syst.},
  title        = {New user intent discovery with robust pseudo label training and source domain joint training},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DCAT: Combining multisemantic dual-channel attention fusion
for text classification. <em>MIS</em>, <em>38</em>(4), 10–19. (<a
href="https://doi.org/10.1109/MIS.2023.3268228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is a fundamental and central position in natural language processing. There are many solutions to the text classification problem, but few use the semantic combination of multiple perspectives to improve the classification performance. This article proposes a dual-channel attention network model called DCAT, which uses the complementarity between semantics to refine the understanding deficit. Specifically, DCAT first captures the logical semantics of the text through transductive learning and graph structure. Then, at the attention fusion layer (channel), we use logical semantics to perform joint semantic training on other semantics to correct the predictions of unlabeled test data incrementally. Experiments show that DCAT can achieve more accurate classification on a wide range of text classification datasets, which is vital for subsequent text mining tasks.},
  archive      = {J_MIS},
  author       = {Kaifang Dong and Yifan Liu and Fuyong Xu and Peiyu Liu},
  doi          = {10.1109/MIS.2023.3268228},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {10-19},
  shortjournal = {IEEE Intell. Syst.},
  title        = {DCAT: Combining multisemantic dual-channel attention fusion for text classification},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiment classification of cryptocurrency-related social
media posts. <em>MIS</em>, <em>38</em>(4), 5–9. (<a
href="https://doi.org/10.1109/MIS.2023.3283170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many researchers agree that sentiment analysis can improve the performance of quantitative trading models. We develop two off-the-shelf solutions for analyzing the sentiments of cryptocurrency-related social media posts. First, we posttrain and fine-tune a Twitter-oriented model based on the bidirectional encoder representations from transformers (BERT) architecture, BERTweet, on the cryptocurrency domain, resulting in CryptoBERT. Second, we generate the language-universal cryptocurrency emoji (LUKE) sentiment lexicon and prediction pipeline, utilizing the sentiment of emojis prevalent in social media. CryptoBERT is highly accurate, while LUKE is suitable for non-English posts, thus allowing for direct classification and noisy label generation in less popular languages. Our research can help cryptocurrency investors develop trading software supported by sentiments mined from social media.},
  archive      = {J_MIS},
  author       = {Mikolaj Kulakowski and Flavius Frasincar},
  doi          = {10.1109/MIS.2023.3283170},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {5-9},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Sentiment classification of cryptocurrency-related social media posts},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From stochastic parrots to intelligent assistants—the
secrets of data and human interventions. <em>MIS</em>, <em>38</em>(3),
63–67. (<a href="https://doi.org/10.1109/MIS.2023.3268723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI is all the rage nowadays—primarily driven by ChatGPT capturing the public imagination and attracting hundreds of millions of users in record time, reaching 100 million users in two months. However, there is much ambiguity from the providers about the technology, the methodology, and the way OpenAI makes it work. This compounds the mystique and speculation. I focus on what we know, with a particular emphasis on the aspects that the makers of ChatGPT avoid discussing with the public—namely, the underlying dependence on much manual intervention in training data curation, data labeling, operational interventions by humans, and reinforcement learning. Unfortunately, despite the criticality of these issues to the scientific community, they are hardly discussed. In this article, I attempt to address some of the issues in the hope of stimulating further studies of these less glorified but critical topics.},
  archive      = {J_MIS},
  author       = {Usama M. Fayyad},
  doi          = {10.1109/MIS.2023.3268723},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {63-67},
  shortjournal = {IEEE Intell. Syst.},
  title        = {From stochastic parrots to intelligent Assistants—The secrets of data and human interventions},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurosymbolic artificial intelligence (why, what, and how).
<em>MIS</em>, <em>38</em>(3), 56–62. (<a
href="https://doi.org/10.1109/MIS.2023.3268724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans interact with the environment using a combination of perception—transforming sensory inputs from their environment into symbols, and cognition—mapping symbols to knowledge about the environment for supporting abstraction, reasoning by analogy, and long-term planning. Human perception-inspired machine perception, in the context of artificial intelligence (AI), refers to large-scale pattern recognition from raw data using neural networks trained using self-supervised learning objectives such as next-word prediction or object recognition. On the other hand, machine cognition encompasses more complex computations, such as using knowledge of the environment to guide reasoning, analogy, and long-term planning. Humans can also control and explain their cognitive functions. This seems to require the retention of symbolic mappings from perception outputs to knowledge about their environment. For example, humans can follow and explain the guidelines and safety constraints driving their decision making in safety-critical applications such as health care, criminal justice, and autonomous driving.},
  archive      = {J_MIS},
  author       = {Amit Sheth and Kaushik Roy and Manas Gaur},
  doi          = {10.1109/MIS.2023.3268724},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {56-62},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Neurosymbolic artificial intelligence (Why, what, and how)},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COVID-19 sentiment analysis based on tweets. <em>MIS</em>,
<em>38</em>(3), 51–55. (<a
href="https://doi.org/10.1109/MIS.2023.3239180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, based on sentiment analysis of tweets, we investigate how individuals in Italy perceived the COVID-19 outbreak and its implications in real life. We unveil the most discussed narratives on Twitter and measure how users’ interests, sentiments, and emotions have evolved over time and across the several aspects of the pandemic. Our analysis shows that while the overall sentiment is negative, Italians have shown upbeat responses to the pandemic, especially in regards to the vaccination campaign. The emotion analysis reveals that while fear progressively decreased after the first wave of the pandemic, the overall anger has remained constant but gradually turned into various narratives.},
  archive      = {J_MIS},
  author       = {Valerio La Gatta and Vincenzo Moscato and Marco Postiglione and Giancarlo Sperlí},
  doi          = {10.1109/MIS.2023.3239180},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {51-55},
  shortjournal = {IEEE Intell. Syst.},
  title        = {COVID-19 sentiment analysis based on tweets},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multiview text imagination network based on latent
alignment for image-text matching. <em>MIS</em>, <em>38</em>(3), 41–50.
(<a href="https://doi.org/10.1109/MIS.2023.3265176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image-text matching fields, one of the keys to improving performance is to extract features with more semantic information. Existing works demonstrate that semantic enrichment through knowledge expansion can improve performance. Most of them expand image features, however, the shortage of semantic information in text modality and the unilateral character of the view are often bottlenecks that limit the performance of image-text matching models. To solve the two problems, we aggregate knowledge from multiple views and propose a word imagination graph (WIG). A WIG can be used to expand textual semantic information by imagination based on input images. Then, utilizing WIG, we construct a novel multiview text imagination network (MTIN). A MTIN enables latent alignment of images and texts on tags, which can assist matching on a semantic level. Results from the Flickr30K and MS-COCO datasets demonstrate the effectiveness of our method. The source code has been released on GitHub https://github.com/smileslabsh/Multiview-Text-Imagination-Network .},
  archive      = {J_MIS},
  author       = {Heng Shang and Guoshuai Zhao and Jing Shi and Xueming Qian},
  doi          = {10.1109/MIS.2023.3265176},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {41-50},
  shortjournal = {IEEE Intell. Syst.},
  title        = {A multiview text imagination network based on latent alignment for image-text matching},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating emotion descriptions for fine art paintings via
multiple painting representations. <em>MIS</em>, <em>38</em>(3), 31–40.
(<a href="https://doi.org/10.1109/MIS.2023.3260992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of generating emotion descriptions for fine art paintings using machine learning is gaining increasing attention. However, captioning the emotions depicted in paintings is challenging due to the artistic and subtle nature of the relied-upon visual clues. Previous studies on painting emotion captioning mainly focus on content-oriented semantic features, resulting in limited performance. Recognizing that facial expressions and body language can reflect human emotions, we propose a novel painting emotion captioning model that incorporates two additional features: facial expression feature and human pose feature. Our model includes a feature fusion method to incorporate these features with commonly used object features. The experiment results on public datasets demonstrate that our proposed model outperforms the baseline. Further experiments on paintings with abstract appearances and image corruptions show the promising performance of our proposed model.},
  archive      = {J_MIS},
  author       = {Yue Lu and Chao Guo and Xingyuan Dai and Fei-Yue Wang},
  doi          = {10.1109/MIS.2023.3260992},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {31-40},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Generating emotion descriptions for fine art paintings via multiple painting representations},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MFGCN: A multimodal fusion graph convolutional network for
online car-hailing demand prediction. <em>MIS</em>, <em>38</em>(3),
21–30. (<a href="https://doi.org/10.1109/MIS.2023.3250600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of online car hailing provides an excellent opportunity to provide convenient travel services. However, with the tremendous increase of users and online taxis, online car-hailing prediction systems face several challenges: 1) the difficulty of modeling nonlinear spatiotemporal interactions between users and vehicles, 2) the difficulty of incorporating context information and multimodal attribute enhancement data, and 3) the problems of data sparsity. To cope with these challenges, we propose a novel multimodal fusion graph convolutional network (MFGCN) for online car-hailing prediction. The model consists of a multimodal origin destination graph convolutional network module that contains three graph convolutional networks to extract spatial patterns from geography, semantics, and functional correlation; a multimodal attribute enhancement module that incorporates weather and temporal activity patterns; and a temporal attention skip-long short-term memory module that captures the periodic variations. Extensive experiments conducted on real-world taxi demand datasets show that MFGCN outperforms the state-of-the-art methods.},
  archive      = {J_MIS},
  author       = {Lyuchao Liao and Ben Li and Fumin Zou and Dejuan Huang},
  doi          = {10.1109/MIS.2023.3250600},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {21-30},
  shortjournal = {IEEE Intell. Syst.},
  title        = {MFGCN: A multimodal fusion graph convolutional network for online car-hailing demand prediction},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The dynamic vectors-based attention model for chinese
mathematical term extraction. <em>MIS</em>, <em>38</em>(3), 12–20. (<a
href="https://doi.org/10.1109/MIS.2023.3246240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Term extraction aims to extract domain-specific terminology from documents. Secondary school mathematics terminology plays a guiding role in the learning and teaching of secondary school mathematics. We found that there needs to be more work in this field and that there are two main issues in extracting the terms from the middle school mathematics text: the polysemy of one character problem and nested terms problem. Accordingly, we have constructed a secondary school mathematics corpus and proposed a model to resolve these problems, termed BERT-LLA-CRF. Using pretraining to obtain dynamic word vectors to improve the model’s understanding of text semantics and solve the problem of multiple meanings of one word, the proposed model integrates attention mechanisms and Chinese character information to solve the nested terminology problem. The experiment results show that the proposed model effectively solves those problems and achieves good middle-school mathematics term extraction results.},
  archive      = {J_MIS},
  author       = {Maosheng Zhong and Jiangling Kuang and GanLin Liu and Xin Hua and Jiahua Wu},
  doi          = {10.1109/MIS.2023.3246240},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {12-20},
  shortjournal = {IEEE Intell. Syst.},
  title        = {The dynamic vectors-based attention model for chinese mathematical term extraction},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Irregularly sampled multivariate time series classification:
A graph learning approach. <em>MIS</em>, <em>38</em>(3), 3–11. (<a
href="https://doi.org/10.1109/MIS.2023.3239797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, graph-based learning methods are proven to be effective for modeling spatial and structural dependencies. However, when applied to IS-MTS, they encounter three major challenges due to the complex data characteristics of IS-MTS: 1) variable time intervals between observations; 2) asynchronous time points across dimensions; and 3) a lack of prior knowledge of connectivity structure for message propagation. To fill these gaps, we propose a multivariate temporal graph network to coherently capture structural interactions, learn temporal dependencies, and handle challenging characteristics of IS-MTS data. Specifically, we first build a multivariate interaction module to handle frequent missing values and extract the graph structure relation automatically. Second, we design a novel adjacent graph propagation mechanism to aggregate the neighbor information from multistep snapshots. Third, we construct a masked temporal-aware attention module to explicitly consider the timestamp context and interval irregularity. Based on an extensive experimental evaluation, we demonstrate the superior performance of the proposed method.},
  archive      = {J_MIS},
  author       = {Zhen Wang and Ting Jiang and Zenghui Xu and Ji Zhang and Jianliang Gao},
  doi          = {10.1109/MIS.2023.3239797},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {3-11},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Irregularly sampled multivariate time series classification: A graph learning approach},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recurrent neural networks for oil well event prediction.
<em>MIS</em>, <em>38</em>(2), 73–80. (<a
href="https://doi.org/10.1109/MIS.2023.3252446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have conducted a comparison between three types of recurrent neural networks and their ability to predict anomalies occurring in oil wells using a publicly available dataset. We have included two types of well-known state-of-the-art recurrent neural networks and a new type with neurons evolved specifically for the dataset using automatic programming. We show that the new type of recurrent neuron offers a massive improvement over the state of the art. The overall test accuracy of the new network type is 94.6%, which is an improvement by 18.3%, or 14.6 percentage points. We also show that a network with the new neuron performs better than any other solution proposed for the dataset.},
  archive      = {J_MIS},
  author       = {Lars Vidar Magnusson and J. Roland Olsson and Chau Thi Thuy Tran},
  doi          = {10.1109/MIS.2023.3252446},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {73-80},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Recurrent neural networks for oil well event prediction},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial anomaly detection in hyperspectral imaging using
optical neural networks. <em>MIS</em>, <em>38</em>(2), 64–72. (<a
href="https://doi.org/10.1109/MIS.2023.3241431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral imaging (HSI) is a widely used technology, yet hard to implement in real-time anomaly detection due to its extensive data flow volume. An autoencoder structured hybrid optical–electrical neural network method is proposed in this work that realizes feature exaction and anomaly detection during the hyperspectral data acquisition process to address such issues. In the proposed method, a digital micromirror device functions as the core optical processor to extract low-level features from the hyperspectral data flow. Weight binarization and a conditional subnetwork are utilized to suit optical computation. Pretraining by artificial data is implemented to ease the training data burden. Case studies on defect detection and foreign object detection have demonstrated that the proposed method can significantly reduce the sampling time by orders of magnitude without loss of detection accuracy.},
  archive      = {J_MIS},
  author       = {Lingfeng Liu and Dong Ni and Liankui Dai},
  doi          = {10.1109/MIS.2023.3241431},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {64-72},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Spatial anomaly detection in hyperspectral imaging using optical neural networks},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EAGLE: Contrastive learning for efficient graph anomaly
detection. <em>MIS</em>, <em>38</em>(2), 55–63. (<a
href="https://doi.org/10.1109/MIS.2022.3229147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is a popular and vital task in various real-world scenarios, which has been studied for several decades. Recently, many studies extending deep learning-based methods have shown preferable performance on graph anomaly detection. However, existing methods lack efficiency that is definitely necessary for embedded devices. Toward this end, we propose an Efficient Anomaly detection model on heterogeneous Graphs via contrastive LEarning (EAGLE) by contrasting abnormal nodes with normal ones in terms of their distances to the local context. The proposed method first samples instance pairs on meta-path level for contrastive learning. Then, a Graph AutoEncoder-based model is applied to learn informative node embeddings in an unsupervised way, which will be further combined with the discriminator to predict the anomaly scores of nodes. Experimental results show that EAGLE outperforms the state-of-the-art methods on three heterogeneous network datasets.},
  archive      = {J_MIS},
  author       = {Jing Ren and Mingliang Hou and Zhixuan Liu and Xiaomei Bai},
  doi          = {10.1109/MIS.2022.3229147},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {55-63},
  shortjournal = {IEEE Intell. Syst.},
  title        = {EAGLE: Contrastive learning for efficient graph anomaly detection},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting anomalies in small unmanned aerial systems via
graphical normalizing flows. <em>MIS</em>, <em>38</em>(2), 46–54. (<a
href="https://doi.org/10.1109/MIS.2023.3252810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing deployment of small unmanned aerial systems (sUASs) on various tasks, it becomes crucial to analyze and detect anomalies from their flight logs. To support research in this area, we curate Drone Log Anomaly (DLA), the first real-world time series anomaly detection dataset in the domain of sUASs, which contains 41 sUAS flight logs annotated with various types of anomalies. As anomalies tend to occur in low-density areas within a distribution, we propose graphical normalizing flows (GNF), a graph-based autoregressive deep learning model, to perform anomaly detection through density estimation. GNF contains 1) a temporal encoding module using a transformer to capture the temporal dynamics, 2) an interfeature encoding module leveraging graph representation learning on a Bayesian network to model the statistical dependencies among time series features, and 3) a density-estimation module with normalizing flows. Extensive experiments have demonstrated GNF’s superior anomaly detection power on DLA compared with state-of-the-art baselines.},
  archive      = {J_MIS},
  author       = {Yihong Ma and Md Nafee Al Islam and Jane Cleland-Huang and Nitesh V. Chawla},
  doi          = {10.1109/MIS.2023.3252810},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {46-54},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Detecting anomalies in small unmanned aerial systems via graphical normalizing flows},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extreme event discovery with self-attention for PM2.5
anomaly prediction. <em>MIS</em>, <em>38</em>(2), 36–45. (<a
href="https://doi.org/10.1109/MIS.2023.3236561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine particulate matter (PM2.5) values of a particular location form a time series, whose prediction is challenging due to the complicated interactions between numerous factors from meteorological measurements, terrain conditions, and industry and human habitation activities, and their predictions have attracted considerable attention from the deep learning community. Although the deep learning approach for PM2.5 prediction generally has an acceptable accuracy, it has difficulty in PM2.5 anomaly prediction, while mispredictions prevent the authority from issuing proper instructions to reduce the impact on general health. We use extreme value theory (EVT) to formulate the PM2.5 prediction problem with a self-attention-based neural network implementation. EVT-based loss accounts for the rarity of anomalous data, and self-attention captures global information. Experiments demonstrate that the proposed model obtains an improved performance of 478% in F1 score and 286% in Matthews correlation coefficient (MCC) over the fully connected network, and 229% in F1 and 148% in MCC over the typical transformer trained with the traditional loss function.},
  archive      = {J_MIS},
  author       = {Hsin-Chih Yang and Ming-Chuan Yang and Guo-Wei Wong and Meng Chang Chen},
  doi          = {10.1109/MIS.2023.3236561},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {36-45},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Extreme event discovery with self-attention for PM2.5 anomaly prediction},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep anomaly analytics: Advancing the frontier of anomaly
detection. <em>MIS</em>, <em>38</em>(2), 32–35. (<a
href="https://doi.org/10.1109/MIS.2023.3255590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep anomaly analytics is a rapidly evolving field that leverages the power of deep learning to identify anomalies in various datasets. The use of deep anomaly analytics has increased significantly in recent years due to the growing need to detect anomalies in complex data that traditional methods struggle to handle. Deep anomaly analytics has the potential to transform various industries, including, e.g., healthcare, finance, and cybersecurity, by providing valuable insights and helping to diagnose diseases, prevent fraud, and detect cyber threats. However, there are also many challenges associated with deep anomaly analytics. This editorial provides an overview of the field of deep anomaly analytics, and highlights a few key challenges facing this field, i.e., time series anomaly detection, graph anomaly detection, efficiency (of models), and solving real-world problems. Additionally, it serves as an introduction to this special issue that delves further into these topics.},
  archive      = {J_MIS},
  author       = {Feng Xia and Leman Akoglu and Charu Aggarwal and Huan Liu},
  doi          = {10.1109/MIS.2023.3255590},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {32-35},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Deep anomaly analytics: Advancing the frontier of anomaly detection},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the persistence of multilabel learning, its recent
trends, and its open issues. <em>MIS</em>, <em>38</em>(2), 28–31. (<a
href="https://doi.org/10.1109/MIS.2023.3255591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilabel data comprise instances associated with multiple binary target variables. The main learning task from such data is multilabel classification, where the goal is to output a bipartition of the target variables into relevant and irrelevant ones for a given instance. Other tasks involve ranking the target variables from the most to the least relevant one or even outputting a full joint distribution for every possible assignment of values to the binary targets.},
  archive      = {J_MIS},
  author       = {Nikolaos Mylonas and Ioannis Mollas and Bin Liu and Yannis Manolopoulos and Grigorios Tsoumakas},
  doi          = {10.1109/MIS.2023.3255591},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {28-31},
  shortjournal = {IEEE Intell. Syst.},
  title        = {On the persistence of multilabel learning, its recent trends, and its open issues},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking homework in the age of artificial intelligence.
<em>MIS</em>, <em>38</em>(2), 24–27. (<a
href="https://doi.org/10.1109/MIS.2023.3255599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of natural language processing techniques has led to the development of advanced conversational tools such as ChatGPT, capable of assisting users with a variety of activities. Media attention has centered on ChatGPT’s potential impact, policy implications, and ethical ramifications, particularly in the context of education. As such tools become more accessible, students across the globe may use them to assist with their homework. However, it is still unclear whether ChatGPT’s performance is advanced enough to pose a serious risk of plagiarism. We fill this gap by evaluating ChatGPT on two introductory and two advanced university-level courses. We find that ChatGPT receives near-perfect grades on the majority of questions in the introductory courses but has not yet reached the level of sophistication required to pass in advanced courses. Moreover, adding a few full stops or typos may fool a machine learning algorithm designed to detect ChatGPT-generated text. These findings suggest that, at least for some courses, current artificial intelligence tools pose a real threat that can no longer be overlooked by educational institutions.},
  archive      = {J_MIS},
  author       = {Hazem Ibrahim and Rohail Asim and Fareed Zaffar and Talal Rahwan and Yasir Zaki},
  doi          = {10.1109/MIS.2023.3255599},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {24-27},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Rethinking homework in the age of artificial intelligence},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Will affective computing emerge from foundation models and
general artificial intelligence? A first evaluation of ChatGPT.
<em>MIS</em>, <em>38</em>(2), 15–23. (<a
href="https://doi.org/10.1109/MIS.2023.3254179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ChatGPT has shown the potential of emerging general artificial intelligence capabilities, as it has demonstrated competent performance across many natural language processing tasks. In this work, we evaluate the capabilities of ChatGPT to perform text classification on three affective computing problems, namely, big-five personality prediction, sentiment analysis, and suicide tendency detection. We utilize three baselines, a robust language model (RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and a simple bag-of-words (BoW) baseline. Results show that the RoBERTa model trained for a specific downstream task generally has a superior performance. On the other hand, ChatGPT provides decent results and is relatively comparable to the Word2Vec and BoW baselines. ChatGPT further shows robustness against noisy data, where the Word2Vec model achieves worse results due to noise. Results indicate that ChatGPT is a good generalist model that is capable of achieving good results across various problems without any specialized training; however, it is not as good as a specialized model for a downstream task.},
  archive      = {J_MIS},
  author       = {Mostafa M. Amin and Erik Cambria and Björn W. Schuller},
  doi          = {10.1109/MIS.2023.3254179},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {15-23},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Will affective computing emerge from foundation models and general artificial intelligence? a first evaluation of ChatGPT},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI’s 10 to watch, 2022. <em>MIS</em>, <em>38</em>(2), 3–14.
(<a href="https://doi.org/10.1109/MIS.2023.3252919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IEEE Intelligent Systems is promoting young and aspiring artificial intelligence (AI) scientists and recognizing the rising stars as “AI‘s 10 Watch.” This biennial 2022 edition is slightly different from the previous editions: We solicited submissions from individuals who had obtained their Ph.D. up to 10 years prior (as opposed to 5 years in all of the previous editions). This led to more applications of the highest quality. The selection committee finally had to select 10 outstanding contributors from a pool of 30+ highly competitive and strong nominations, which made the selection decisions rather difficult. After a careful and detailed selection process through many rounds of discussions via e-mails and live meetings, the committee voted unanimously on a short list of 10 top candidates who have all demonstrated outstanding achievements in different areas of AI. The selection was based solely on scientific quality, reputation, impact, and expert endorsements accumulated since their Ph.D. It is our honor and privilege to announce the following 2022 class of “AI’s 10 to Watch.”• Bo Li. She is working on trustworthy machine learning (ML) at the intersection of ML, security and privacy, and game theory. She was able to integrate domain knowledge and logical reasoning abilities into data-driven statistical ML models to improve learning robustness with guarantees, and she has designed scalable privacy-preserving data-publishing frameworks for high-dimensional data. Her work has provided rigorous guarantees for the trustworthiness of learning systems and been deployed in industrial applications. She is an assistant professor with the University of Illinois at Urbana-Champaign.• Tongliang Liu. He is working in the fields of trustworthy ML. His work in theories and algorithms of ML with noisy labels has led to significant contributions and influence in the fields of ML, computer vision, natural language processing (NLP), and data mining, as large-scale datasets in those fields are prone to suffering severe label errors. He is a senior lecturer at the School of Computer Science, University of Sydney, and a visiting associate professor at the Department of Machine Learning, Mohamed bin Zayed University of Artificial Intelligence.• Liqiang Nie. He is the dean of and a professor with the School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen). He works on multimedia content analysis and search, with a particular emphasis on data-driven multimodal learning and knowledge-guided multimodal reasoning. He pioneered the explicit modeling of consistent, complementary, and partial alignment relationships among modalities.• Soujanya Poria. He is an assistant professor at Singapore University of Technology and Design (SUTD). His seminal research on fusing information from textual, audio, and visual modalities for diverse behavioral and affective tasks significantly improved systems reliant on multimodal data, paving the way to various novel research avenues. His latest works are on information extraction, vision–language reasoning, and understanding human conversations in terms of common sense-based, context-grounded causal explanations.• Deqing Sun. He is a staff research scientist at Google. He has made significant contributions to computer vision, in particular in motion estimation. His work on optical flow (“Classic+NL” and “PWC-Net”) has been very influential and has been powering commercial applications such as Super SloMo in NVIDIA’s RTX platform, Face Unblur, and Fusion Zoom on Google’s Pixel phone.• Yizhou Sun. She is a pioneer in heterogeneous information network (HIN) mining, with a recent focus on deep graph learning, neural symbolic reasoning, and providing neural solutions to multiagent dynamical systems. Her work has a wide spectrum of applications, ranging from e-commerce, health care, and material science to hardware design. She is currently an associate professor at the University of California, Los Angeles (UCLA).• Jiliang Tang. He is a University Foundation Professor at Michigan State University. He works on graph ML and trustworthy AI and their applications in education and biology. His contributions to these fields include highly cited algorithms, well-received systems, and popular books.• Zhangyang “Atlas” Wang. He works on efficient and reliable ML. Recently, his core research theme is to leverage, understand, and expand the role of sparsity, from classical optimization to modern neural networks (NNs), whose impacts span the efficient training/inference of large-foundation models, robustness and trustworthiness, generative AI, graph learning, and more.• Hongzhi Yin. He has worked on trustworthy data intelligence to turn data into privacy-preserving, robust, explainable, and fair intelligent services in various industries and scenarios. He is also a leading expert researching and developing next-generation intelligent systems and algorithms for lightweight on-device predictive analytics as well as recommendation and decentralized ML on massive and heterogeneous data. He is an associate professor and ARC Future Fellow at the University of Queensland.• Liang Zheng. He is a senior lecturer at the Australian National University and works on data-centric computer vision, where he seeks to improve the quality of training and validation data, predict test data difficulty without labels, and more. These efforts provide a complementary perspective to model-centric developments. He has also made significant contributions to object re-identification and the broader smart city initiative through the introduction of widely used benchmarks and baseline methods.},
  archive      = {J_MIS},
  author       = {Jürgen Dix and Zhongfei Zhang},
  doi          = {10.1109/MIS.2023.3252919},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {3-14},
  shortjournal = {IEEE Intell. Syst.},
  title        = {AI’s 10 to watch, 2022},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Affect detection from wearables in the “real” wild: Fact,
fantasy, or somewhere in between? <em>MIS</em>, <em>38</em>(1), 76–84.
(<a href="https://doi.org/10.1109/MIS.2022.3221854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affect detection from wearables in the “real” wild—where people go about their daily routines in heterogeneous contexts—is a different problem than affect detection in the lab or in the “quasi” wild (e.g., curated or restricted contexts). The U.S. government recently supported a program to develop and evaluate the performance of contemporary affect detection systems in the real-wild along the dimensions of accuracy, robustness, and generalizability. Evaluations by an independent testing team revealed that none of the performing teams met the aspirational performance metrics. Alarmingly, performance was near zero for several cases. This article is the result of soul searching to reconcile the chasm between expected and achieved performance in light of past successes of the field. We discuss the major challenges faced, their implications for future research, and suggest a path forward.},
  archive      = {J_MIS},
  author       = {Sidney K. D’Mello and Brandon M. Booth},
  doi          = {10.1109/MIS.2022.3221854},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {76-84},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Affect detection from wearables in the “Real” wild: Fact, fantasy, or somewhere in between?},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A semantic web approach to fault tolerant autonomous
manufacturing. <em>MIS</em>, <em>38</em>(1), 69–75. (<a
href="https://doi.org/10.1109/MIS.2023.3235677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The next phase of manufacturing is centered on making the switch from traditional automated to autonomous systems. Future factories are required to be agile, allowing for more customized production and resistance to disturbances. Such production lines would be able to reallocate resources as needed and minimize downtime while keeping up with market demands. These systems must be capable of complex decision-making based on parameters, such as machine status, sensory/IoT data, and inspection results. Current manufacturing lines lack this complex capability and instead focus on low-level decision-making on the machine level without utilizing the generated data to its full extent. This article presents progress toward this autonomy by introducing Semantic Web capabilities applied to managing the production line. Finally, a full autonomous manufacturing use case is also developed to showcase the value of Semantic Web in a manufacturing context. This use case utilizes diverse data sources and domain knowledge to complete a manufacturing process despite malfunctioning equipment. It highlights the benefit of Semantic Web in manufacturing by integrating the heterogeneous information required for the process to be completed. This provides an approach to autonomous manufacturing not yet fully realized at the intersection of Semantic Web and manufacturing.},
  archive      = {J_MIS},
  author       = {Fadi El Kalach and Ruwan Wickramarachchi and Ramy Harik and Amit Sheth},
  doi          = {10.1109/MIS.2023.3235677},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {69-75},
  shortjournal = {IEEE Intell. Syst.},
  title        = {A semantic web approach to fault tolerant autonomous manufacturing},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Point cloud registration using multiattention mechanism and
deep hybrid features. <em>MIS</em>, <em>38</em>(1), 58–68. (<a
href="https://doi.org/10.1109/MIS.2022.3220659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to some unfavorable factors, how to accurately register point clouds is still a challenging task. In this article, an effective point cloud registration network is proposed with multiple attention mechanism and deep hybrid features. For the features obtained with a graph neural network, three attention modules, namely the spatial attention module, channel attention module, and self-geometric attention module, are utilized to mine various areas of regional information. An attention-based feature fusion module, which consists of three consecutive residual blocks, is devised to fuse the features from the three attention modules. Moreover, the capability of the network for correctly matching point clouds is enhanced, by using deep hybrid features to guide the correspondence search and the calculation of matching confidence. Experimental results on several widely used datasets demonstrate the effectiveness of the proposed point cloud registration network.},
  archive      = {J_MIS},
  author       = {Yu-Xin Zhang and Zhan-Li Sun and Zhi-Gang Zeng and Kin-Man Lam},
  doi          = {10.1109/MIS.2022.3220659},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {58-68},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Point cloud registration using multiattention mechanism and deep hybrid features},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convolutional neural network-assisted adaptive sampling for
sparse feature detection in image and video data. <em>MIS</em>,
<em>38</em>(1), 45–57. (<a
href="https://doi.org/10.1109/MIS.2022.3215779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a feature detection approach that employs an adaptive sampling technique coupled with a convolutional neural network (CNN) model, to detect sparse features of interest in high-dimensional input data. Adaptive sampling criterion smartly explores the high-dimensional input and exploits the regions of interest. The CNN model determines the likelihood of the presence of the desired features, which guides the exploitation component of the sampling strategy. The effectiveness of the approach is illustrated using case studies, where emotions in a candidate’s interview video are detected for evaluation purpose and anomalies in a product’s image are extracted for quality control. The approach reduces evaluation time and minimizes amount of input data to be accessed and processed while effectively identifying desired sparse features.},
  archive      = {J_MIS},
  author       = {Geet Lahoti and Chitta Ranjan and Jialei Chen and Hao Yan and Chuck Zhang},
  doi          = {10.1109/MIS.2022.3215779},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {45-57},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Convolutional neural network-assisted adaptive sampling for sparse feature detection in image and video data},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ECCVideo: A scalable edge cloud collaborative video analysis
system. <em>MIS</em>, <em>38</em>(1), 34–44. (<a
href="https://doi.org/10.1109/MIS.2022.3214614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video analysis drives a wide range of applications in the fields of public safety, autonomous vehicles, etc., with the great potential to impact society. Traditional cloud-based approaches are not applicable because of prohibitive bandwidth consumption and high response latency, while simply edge-based video analysis suffers from large computation delay, considering the restricted computing capacity of edge servers. Therefore, in this article, we focus on low-latency edge-cloud collaborative video analytic applications (ECCVApps) by making full use of resources at both the edge and cloud. Particularly, we present an edge-cloud collaborative video analysis system called ECCVideo, to support the unified management of heterogeneous servers and facilitate the development and deployment of large-scale ECCVApps. Under ECCVideo, we design the application architecture of ECCVApps, including presentation paradigm, transparent communication services, and full lifecycle management. To validate the proposed system, a real-time object detection application is deployed on the ECCVideo prototype.},
  archive      = {J_MIS},
  author       = {Qing Han and Xuebin Ren and Peng Zhao and Yimeng Wang and Luhui Wang and Cong Zhao and Xinyu Yang},
  doi          = {10.1109/MIS.2022.3214614},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {34-44},
  shortjournal = {IEEE Intell. Syst.},
  title        = {ECCVideo: A scalable edge cloud collaborative video analysis system},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). StereoPairFree: Self-constructed stereo correspondence
network from natural images. <em>MIS</em>, <em>38</em>(1), 19–33. (<a
href="https://doi.org/10.1109/MIS.2022.3193697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a variant of a convolutional neural network-based stereo matching method, StereoPairFree, that requires only normal and not left or right stereo images. The corresponding image patches for training stereo matching cost networks look similar, apart from some properties, such as different illumination, occlusion, distortion, and foreshortening. We propose a method for generating synthesized pairs of corresponding image patches for a given image patch. We also propose a multipatch matching cost network that exploits various input patch sizes. The proposed matching cost network is optimized by cross-based cost aggregation and semiglobal matching, followed by consistency checks and bilateral filtering. Hence, StereoPairFree does not require a single stereo pair but standard images to build a deep learning stereo matching method. It is the first stereo matching method constructed from normal images and significantly outperforms monocular stereo matching approaches (Hur and Roth, 2020), (Hur and Roth, 2021), (Schuster et al., 2020). We evaluated StereoPairFree with the KITTI-2012, KITTI-2015, and Middlebury datasets. It significantly outperformed the baseline and several deep learning-based methods using these datasets.},
  archive      = {J_MIS},
  author       = {Vinh Quang Dinh and Tae Jong Choi},
  doi          = {10.1109/MIS.2022.3193697},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {19-33},
  shortjournal = {IEEE Intell. Syst.},
  title        = {StereoPairFree: Self-constructed stereo correspondence network from natural images},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HetGRec: Heterogeneous graph attention network for group
recommendation. <em>MIS</em>, <em>38</em>(1), 9–18. (<a
href="https://doi.org/10.1109/MIS.2022.3211074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the popularity of group activities in social media, group recommendation becomes increasingly significant. It aims to pursue a list of preferred items for a target group. Recently, some methods perform graph neural network on the interaction graph. However, these works ignore that the interaction relationships among groups, users, and items are heterogeneous, i.e., two objects can be connected via different paths. In this article, we propose a heterogeneous graph attention network for group recommendation. It first employs meta-path-based random walk with restart to search for strongly correlated neighbors for each node. Then, it performs a dual-hierarchical attention network to extract semantics existing in each meta-path and fuse them to obtain hybrid representation of groups and items. Extensive experiments on three public datasets demonstrate its superiority over the state-of-the-art methods for group recommendation.},
  archive      = {J_MIS},
  author       = {Song Zhang and Nan Zheng and Danli Wang},
  doi          = {10.1109/MIS.2022.3211074},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {9-18},
  shortjournal = {IEEE Intell. Syst.},
  title        = {HetGRec: Heterogeneous graph attention network for group recommendation},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulation driven AI: From artificial to actual and vice
versa. <em>MIS</em>, <em>38</em>(1), 3–8. (<a
href="https://doi.org/10.1109/MIS.2023.3235676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this perspective, we discuss the important role of simulations in building state-of-the-art artificial intelligence (AI) systems. We first explain why simulations become vital in building complex AI systems. Then, we study some challenges and candidate solutions related to simulation-based AI systems. Finally, we discuss future research directions in this field.},
  archive      = {J_MIS},
  author       = {Li Li and Yilun Lin and Yutong Wang and Fei-Yue Wang},
  doi          = {10.1109/MIS.2023.3235676},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {3-8},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Simulation driven AI: From artificial to actual and vice versa},
  volume       = {38},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
