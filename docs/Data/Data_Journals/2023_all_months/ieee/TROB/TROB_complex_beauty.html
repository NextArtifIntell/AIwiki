<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TROB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="trob---283">TROB - 283</h2>
<ul>
<li><details>
<summary>
(2023). Robot–camera calibration in tightly constrained environment
using interactive perception. <em>TROB</em>, <em>39</em>(6), 4952–4970.
(<a href="https://doi.org/10.1109/TRO.2023.3299533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulation in tight environment is challenging but increasingly common in vision-guided robotic applications. The significantly reduced amount of available feedback (limited visual cues, field of view, robot motion space, etc.) hinders solving the hand-eye relationship accurately. In this article, we propose a new generic approach for online robot–camera calibration that could deal with the least feedback input available in tight environment: an arbitrarily restricted motion space and a single feature point with unknown position for the robot end-effector. We introduce the interactive perception to generate prescribed but tunable robot motions to reveal high-dimensional sensory feedback, which is not obtainable from static images. We then define the interactive feature plane (IFP), whose spatial property corresponds to the robot-actuating trajectories. A depth-free adaptive controller is proposed based on image feedback, where the converged orientation of IFP directly harvests the data for solving the hand–eye relationship. Our algorithm requires neither external calibration sensors/objects nor large-scale data acquisition process. Simulations demonstrate the validity of our method to accurately calibrate different types of robot under various system set-ups. In experiments, we show good results of our algorithm in terms of accuracy and consistency under tight motion space compared to existing approaches using external objects and/or optimization.},
  archive      = {J_TROB},
  author       = {Fangxun Zhong and Bin Li and Wei Chen and Yun-Hui Liu},
  doi          = {10.1109/TRO.2023.3299533},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4952-4970},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robot–Camera calibration in tightly constrained environment using interactive perception},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust and efficient depth-based obstacle avoidance for
autonomous miniaturized UAVs. <em>TROB</em>, <em>39</em>(6), 4935–4951.
(<a href="https://doi.org/10.1109/TRO.2023.3315710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanosize drones hold enormous potential to explore unknown and complex environments. Their small size makes them agile and safe for operation close to humans and allows them to navigate through narrow spaces. However, their tiny size and payload restrict the possibilities for onboard computation and sensing, making fully autonomous flight extremely challenging. The first step toward full autonomy is reliable obstacle avoidance, which has proven to be challenging by itself in a generic indoor environment. Current approaches utilize vision-based or 1-D sensors to support nanodrone perception algorithms. This article presents a lightweight obstacle avoidance system based on a novel millimeter form factor 64 pixels multizone time-of-flight (ToF) sensor and a generalized model-free control policy. In-field tests are based on the Crazyflie 2.1, extended by a custom multizone ToF deck, featuring a total flight mass of 35 g. The algorithm only uses 0.3\% of the onboard processing power ( ${210}\,{\mu }\mathrm{{s}}$ execution time) with a frame rate of 15 f/s. The presented autonomous nanosize drone reaches 100\% reliability at 0.5 m/s in a generic and previously unexplored indoor environment.},
  archive      = {J_TROB},
  author       = {Hanna Müller and Vlad Niculescu and Tommaso Polonelli and Michele Magno and Luca Benini},
  doi          = {10.1109/TRO.2023.3315710},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4935-4951},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust and efficient depth-based obstacle avoidance for autonomous miniaturized UAVs},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrated task and motion planning for safe legged
navigation in partially observable environments. <em>TROB</em>,
<em>39</em>(6), 4913–4934. (<a
href="https://doi.org/10.1109/TRO.2023.3299524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a hierarchically integrated framework for safe task and motion planning (TAMP) of bipedal locomotion in a partially observable environment with dynamic obstacles and uneven terrain. The high-level task planner employs linear temporal logic for a reactive game synthesis between the robot and its environment and provides a formal guarantee on navigation safety and task completion. To address environmental partial observability, a belief abstraction model is designed by partitioning the environment into multiple belief regions and employed at the high-level navigation planner to estimate the dynamic obstacles&#39; location. This additional location information of dynamic obstacles offered by belief abstraction enables less conservative long-horizon navigation actions beyond guaranteeing immediate collision avoidance. Accordingly, a synthesized action planner sends a set of locomotion actions to the middle-level motion planner while incorporating safe locomotion specifications extracted from safety theorems based on a reduced-order model (ROM) of the locomotion process. The motion planner employs the ROM to design safety criteria and a sampling algorithm to generate nonperiodic motion plans that accurately track high-level actions. At the low level, a foot placement controller based on an angular-momentum linear inverted pendulum model is implemented and integrated with an ankle-actuated passivity-based controller for full-body trajectory tracking. To address external perturbations, this study also investigates the safe sequential composition of the keyframe locomotion state and achieves robust transitions against external perturbations through reachability analysis. The overall TAMP framework is validated with extensive simulations and hardware experiments on bipedal walking robots Cassie and Digit designed by Agility Robotics.},
  archive      = {J_TROB},
  author       = {Abdulaziz Shamsah and Zhaoyuan Gu and Jonas Warnke and Seth Hutchinson and Ye Zhao},
  doi          = {10.1109/TRO.2023.3299524},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4913-4934},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Integrated task and motion planning for safe legged navigation in partially observable environments},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Invariant descriptors of motion and force trajectories for
interpreting object manipulation tasks in contact. <em>TROB</em>,
<em>39</em>(6), 4892–4912. (<a
href="https://doi.org/10.1109/TRO.2023.3309230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invariant descriptors of point and rigid-body motion trajectories have been proposed in the past as representative task models for motion recognition and generalization. Currently, no invariant descriptor exists for representing force trajectories, which appear in contact tasks. This article introduces invariant descriptors for force trajectories by exploiting the duality between motion and force. Two types of invariant descriptors are presented depending on whether the trajectories consist of screw or vector coordinates. Methods and software are provided for robustly calculating the invariant descriptors from noisy measurements using optimal control. Using experimental human demonstrations of 3-D contour following and peg-on-hole alignment tasks, invariant descriptors are shown to result in task representations that do not depend on the calibration of reference frames or sensor locations. The tuning process for the optimal control problems is shown to be fast and intuitive. Similar to motions in free space, the proposed invariant descriptors for motion and force trajectories may prove useful for the recognition and generalization of constrained motions, such as during object manipulation in contact.},
  archive      = {J_TROB},
  author       = {Maxim Vochten and Ali Mousavi Mohammadi and Arno Verduyn and Tinne De Laet and Erwin Aertbeliën and Joris De Schutter},
  doi          = {10.1109/TRO.2023.3309230},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4892-4912},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Invariant descriptors of motion and force trajectories for interpreting object manipulation tasks in contact},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Circular accessible depth: A robust traversability
representation for UGV navigation. <em>TROB</em>, <em>39</em>(6),
4875–4891. (<a href="https://doi.org/10.1109/TRO.2023.3308780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present the circular accessible depth (CAD), a robust traversability representation for an unmanned ground vehicle (UGV) to learn traversability in various scenarios containing irregular obstacles. To predict CAD, we propose a neural network, namely CADNet, with an attention-based multiframe point cloud fusion module, stability-attention module (SAM), to encode the spatial features from point clouds captured by LiDAR. CAD is designed based on the polar coordinate system and focuses on predicting the border of traversable area. Since it encodes the spatial information of the surrounding environment, which enables a semisupervised learning for the CADNet, and thus, desirably avoids annotating a large amount of data. Extensive experiments demonstrate that CAD outperforms baselines in terms of robustness and precision. We also implement our method on a real UGV and show that it performs well in real-world scenarios.},
  archive      = {J_TROB},
  author       = {Shikuan Xie and Ran Song and Yuenan Zhao and Xueqin Huang and Yibin Li and Wei Zhang},
  doi          = {10.1109/TRO.2023.3308780},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4875-4891},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Circular accessible depth: A robust traversability representation for UGV navigation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BioSLAM: A bioinspired lifelong memory system for general
place recognition. <em>TROB</em>, <em>39</em>(6), 4855–4874. (<a
href="https://doi.org/10.1109/TRO.2023.3306615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present BioSLAM, a lifelong (lifelong simultaneous localization and mapping) SLAM framework for learning various new appearances incrementally and maintaining accurate place recognition for previously visited areas. Unlike humans, artificial neural networks suffer from catastrophic forgetting and may forget the previously visited areas when trained with new arrivals. For humans, researchers discover that there exists a memory replay mechanism in the brain to keep the neuron active for previous events. Inspired by this discovery, BioSLAM designs a gated generative replay to control the robot&#39;s learning behavior based on the feedback rewards. Specifically, BioSLAM provides a novel dual-memory mechanism for the maintenance of: 1) a dynamic memory to efficiently learn new observations; and 2) a static memory to balance new–old knowledge. When the agent is encountered with different appearances under new domains, the complete processing pipeline can help to incrementally update the place recognition ability, robust to the increasing complexity of long-term place recognition. We demonstrate BioSLAM in three incremental SLAM scenarios as follows. 1) A 120 km city-scale trajectories with LiDAR-based inputs. 2) A multivisited 4.5 km campus-scale trajectories with LiDAR-vision inputs. 3) An official Oxford dataset with 10 km visual inputs under different environmental conditions. We show that BioSLAM can incrementally update the agent&#39;s place recognition ability and outperform the state-of-the-art incremental approach, generative replay, by 24\% in terms of place recognition accuracy. To the best of our knowledge, BioSLAM is the first memory-enhanced lifelong SLAM system to help incremental place recognition in long-term navigation tasks.},
  archive      = {J_TROB},
  author       = {Peng Yin and Abulikemu Abuduweili and Shiqi Zhao and Lingyun Xu and Changliu Liu and Sebastian Scherer},
  doi          = {10.1109/TRO.2023.3306615},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4855-4874},
  shortjournal = {IEEE Trans. Robot.},
  title        = {BioSLAM: A bioinspired lifelong memory system for general place recognition},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust convex model predictive control for quadruped
locomotion under uncertainties. <em>TROB</em>, <em>39</em>(6),
4837–4854. (<a href="https://doi.org/10.1109/TRO.2023.3299527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers quadruped locomotion control in the presence of uncertainties. Two types of structured uncertainties are considered, namely, uncertain friction constraints and uncertain model dynamics. Then, a min-max optimization model is formulated based on robust optimization, and a robust min-max model predictive controller is proposed by recurrently solving the optimization model. We prove that the min-max optimization model is equivalent to a convex quadratic constrained quadratic program by exploiting the structure of uncertainties. Moreover, a two-stage optimization algorithm is proposed to solve the optimization problem efficiently, allowing for the deployment of the controller onto the real robot. The results show that the proposed optimization algorithm can improve solving frequency by $\sim$ 11× compared with Gurobi. The proposed controller is able to stabilize quadruped locomotion in challenging scenarios where the uncertainties are caused by significant disturbances and unknown environments.},
  archive      = {J_TROB},
  author       = {Shaohang Xu and Lijun Zhu and Hai-Tao Zhang and Chin Pang Ho},
  doi          = {10.1109/TRO.2023.3299527},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4837-4854},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust convex model predictive control for quadruped locomotion under uncertainties},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic control of a macro–mini aerial manipulator with
elastic suspension. <em>TROB</em>, <em>39</em>(6), 4820–4836. (<a
href="https://doi.org/10.1109/TRO.2023.3299548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a macro–mini aerial manipulator with elastic suspension is introduced. The mini is an omnidirectional aerial manipulator suspended from the macro by a spring. The macro is a Cartesian robot that moves the anchoring point of the spring. This design combines the advantages of the large workspace of the macrorobot with the high dynamics of aerial vehicles, while reducing energy consumption thanks to gravity compensation. A partitioned control scheme is first implemented to regulate the aerial manipulator and its carrier separately. The redundancy resolution strategy positions the macrorobot to minimize the energy consumption of the aerial manipulator at steady state. Then, a nonlinear model predictive controller replaces the partitioned controller to improve further the efficiency of the combined system, notably by anticipating the slow dynamics of the macrorobot. A sufficient condition for offset-free tracking has been investigated theoretically. Experiments with a cable-driven parallel robot as macro are carried out to assess the added value of the carrier. Both controllers are validated and compared experimentally.},
  archive      = {J_TROB},
  author       = {Arda Yiğit and Loïc Cuvillon and Miguel Arpa Perozo and Sylvain Durand and Jacques Gangloff},
  doi          = {10.1109/TRO.2023.3299548},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4820-4836},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Dynamic control of a Macro–Mini aerial manipulator with elastic suspension},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aerobatic trajectory generation for a VTOL fixed-wing
aircraft using differential flatness. <em>TROB</em>, <em>39</em>(6),
4805–4819. (<a href="https://doi.org/10.1109/TRO.2023.3301312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel algorithm for aerobatic trajectory generation for a vertical take-off and landing (VTOL) tailsitter flying wing aircraft. The algorithm differs from existing approaches for fixed-wing trajectory generation, as it considers a realistic six-degree-of-freedom (6-DOF) flight dynamics model, including aerodynamic equations. Using a global dynamics model enables the generation of aerobatics trajectories that exploit the entire flight envelope, allowing agile maneuvering through the stall regime, sideways uncoordinated flight, inverted flight, etc. The method uses the differential flatness property of the global tailsitter flying wing dynamics, which is derived in this work. By performing snap minimization in the differentially flat output space, a computationally efficient algorithm, suitable for online motion planning, is obtained. The algorithm is demonstrated in extensive flight experiments encompassing six aerobatic maneuvers, a time-optimal drone racing trajectory, and an airshowlike aerobatic sequence for three tailsitter aircraft.},
  archive      = {J_TROB},
  author       = {Ezra Tal and Gilhyun Ryou and Sertac Karaman},
  doi          = {10.1109/TRO.2023.3301312},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4805-4819},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Aerobatic trajectory generation for a VTOL fixed-wing aircraft using differential flatness},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust and efficient trajectory planning for formation
flight in dense environments. <em>TROB</em>, <em>39</em>(6), 4785–4804.
(<a href="https://doi.org/10.1109/TRO.2023.3301295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formation flight has a vast potential for aerial robot swarms in various applications. However, the existing methods lack the capability to achieve fully autonomous large-scale formation flight in dense environments. To bridge the gap, we present a complete formation flight system that effectively integrates real-world constraints into aerial formation navigation. This article proposes a differentiable graph-based metric to quantify the overall similarity error between formations. This metric is invariant to rotation, translation, and scaling, providing more freedom for formation coordination. We design a distributed trajectory optimization framework that considers formation similarity, obstacle avoidance, and dynamic feasibility. The optimization is decoupled to make large-scale formation flights computationally feasible. To improve the elasticity of formation navigation in highly constrained scenes, we present a swarm reorganization method that adaptively adjusts the formation parameters and task assignments by generating local navigation goals. A novel swarm agreement strategy called global-remap-local-replan and a formation-level path planner is proposed in this article to coordinate the global planning and local trajectory optimizations.To validate the proposed method, we design comprehensive benchmarks and simulations with other cutting-edge works in terms of adaptability, predictability, elasticity, resilience, and efficiency. Finally, integrated with palm-sized swarm platforms with onboard computers and sensors, the proposed method demonstrates its efficiency and robustness by achieving the largest scale formation flight in dense outdoor environments.},
  archive      = {J_TROB},
  author       = {Lun Quan and Longji Yin and Tingrui Zhang and Mingyang Wang and Ruilin Wang and Sheng Zhong and Xin Zhou and Yanjun Cao and Chao Xu and Fei Gao},
  doi          = {10.1109/TRO.2023.3301295},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4785-4804},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust and efficient trajectory planning for formation flight in dense environments},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bioinspired rigid-soft hybrid origami actuator with
controllable versatile motion and variable stiffness. <em>TROB</em>,
<em>39</em>(6), 4768–4784. (<a
href="https://doi.org/10.1109/TRO.2023.3311630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional soft pneumatic actuators (SPAs) are made of soft materials that facilitate safe interaction and adaptability. In positioning and loading tasks, however, SPAs demonstrate limited performance. In this article, we extend the current designs of SPAs upon integrating a tendon-driven parallel mechanism into a pneumatic origami chamber, inspired by the performances and structures of vertebrates. The inner rigid/outer soft actuator exploits the advantages of both, parallel mechanisms to achieve precise, versatile motion, and SPAs, to form a compliant, modular structure. With the antagonistic actuation of tendons-pulling and air-pushing, the actuator can exhibit multimode motion, tunable stiffness, and load-carrying maneuvers. Kinematic and quasi-static models are developed to predict the behavior and to control the actuator. Using readily accessible materials and fabrication methods, a prototype was built, on which validation experiments were conducted. The results prove the effectiveness of the model, and demonstrate the motion and stiffness characteristics of the actuator. The design strategy and comprehensive guidelines should expand the capabilities of soft robots for wider applications, and facilitate the development of robots with rigid-soft hybrid structures.},
  archive      = {J_TROB},
  author       = {Zhuang Zhang and Genliang Chen and Yuanhao Xun and Yongzhou Long and Jue Wang and Hao Wang and Jorge Angeles},
  doi          = {10.1109/TRO.2023.3311630},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4768-4784},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Bioinspired rigid-soft hybrid origami actuator with controllable versatile motion and variable stiffness},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed information-based source seeking. <em>TROB</em>,
<em>39</em>(6), 4749–4767. (<a
href="https://doi.org/10.1109/TRO.2023.3309099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we design an information-based multirobot source seeking algorithm where a group of mobile sensors localizes and moves close to a single source using only local range-based measurements. In the algorithm, the mobile sensors perform source identification/localization to estimate the source location; meanwhile, they move to new locations to maximize the Fisher information about the source contained in the sensor measurements. In doing so, they improve the source location estimate and move closer to the source. Our algorithm is superior in convergence speed compared with traditional field climbing algorithms, is flexible in the measurement model and the choice of information metric, and is robust to measurement model errors. Moreover, we provide a fully distributed version of our algorithm, where each sensor decides its own actions and only shares information with its neighbors through a sparse communication network. We perform extensive simulation experiments to test our algorithms on large-scale systems and implement physical experiments on small ground vehicles with light sensors, demonstrating success in seeking a light source.},
  archive      = {J_TROB},
  author       = {Tianpeng Zhang and Victor Qin and Yujie Tang and Na Li},
  doi          = {10.1109/TRO.2023.3309099},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4749-4767},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Distributed information-based source seeking},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Layered control for cooperative locomotion of two
quadrupedal robots: Centralized and distributed approaches.
<em>TROB</em>, <em>39</em>(6), 4728–4748. (<a
href="https://doi.org/10.1109/TRO.2023.3319896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a layered control approach for real-time trajectory planning and control of robust cooperative locomotion by two holonomically constrained quadrupedal robots. A novel interconnected network of reduced-order models, based on the single rigid body (SRB) dynamics, is developed for trajectory planning purposes. At the higher level of the control architecture, two different model predictive control (MPC) algorithms are proposed to address the optimal control problem of the interconnected SRB dynamics: centralized and distributed MPCs. The distributed MPC assumes two local quadratic programs that share their optimal solutions according to a one-step communication delay and an agreement protocol. At the lower level of the control scheme, distributed nonlinear controllers are developed to impose the full-order dynamics to track the prescribed reduced-order trajectories generated by MPCs. The effectiveness of the control approach is verified with extensive numerical simulations and experiments for the robust and cooperative locomotion of two holonomically constrained A1 robots with different payloads on variable terrains and in the presence of disturbances. It is shown that the distributed MPC has a performance similar to that of the centralized MPC, while the computation time is reduced significantly.},
  archive      = {J_TROB},
  author       = {Jeeseop Kim and Randall T. Fawcett and Vinay R. Kamidi and Aaron D. Ames and Kaveh Akbari Hamed},
  doi          = {10.1109/TRO.2023.3319896},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4728-4748},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Layered control for cooperative locomotion of two quadrupedal robots: Centralized and distributed approaches},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid iLQR model predictive control for contact implicit
stabilization on legged robots. <em>TROB</em>, <em>39</em>(6),
4712–4727. (<a href="https://doi.org/10.1109/TRO.2023.3308773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model predictive control (MPC) is a popular strategy for controlling robots but is difficult for systems with contact due to the complex nature of hybrid dynamics. To implement MPC for systems with contact, dynamic models are often simplified or contact sequences fixed in time in order to plan trajectories efficiently. In this work, we propose the hybrid iterative linear quadratic regulator (iLQR) (HiLQR), which extends iLQR to a class of piecewisesmooth hybrid dynamical systems with state jumps. This is accomplished by, first, allowing for changing hybrid modes in the forward pass, second, using the saltation matrix to update the gradient information in the backwards pass, and third, using a reference extension to account for mode mismatch. We demonstrate these changes on a variety of hybrid systems and compare the different strategies for computing the gradients. We further show how HiLQR can work in an MPC fashion (HiLQR MPC) by, first, modifying how the cost function is computed when contact modes do not align, second, utilizing parallelizations when simulating rigid body dynamics, and third, using efficient analytical derivative computations of the rigid body dynamics. The result is a system that can modify the contact sequence of the reference behavior and plan whole body motions cohesively—which is crucial when dealing with large perturbations. HiLQR MPC is tested on two systems: first, the hybrid cost modification is validated on a simple actuated bouncing ball hybrid system. Then, HiLQR MPC is compared against methods that utilize centroidal dynamic assumptions on a quadruped robot (Unitree A1). HiLQR MPC outperforms the centroidal methods in both simulation and hardware tests.},
  archive      = {J_TROB},
  author       = {Nathan J. Kong and Chuanzheng Li and George Council and Aaron M. Johnson},
  doi          = {10.1109/TRO.2023.3308773},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4712-4727},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Hybrid iLQR model predictive control for contact implicit stabilization on legged robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global planning for contact-rich manipulation via local
smoothing of quasi-dynamic contact models. <em>TROB</em>,
<em>39</em>(6), 4691–4711. (<a
href="https://doi.org/10.1109/TRO.2023.3300230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The empirical success of reinforcement learning (RL) in contact-rich manipulation leaves much to be understood from a model-based perspective, where the key difficulties are often attributed to 1) the explosion of contact modes, 2) stiff, nonsmooth contact dynamics and the resulting exploding/discontinuous gradients, and 3) the nonconvexity of the planning problem. The stochastic nature of RL addresses 1) and 2) by effectively sampling and averaging the contact modes. On the other hand, model-based methods have tackled the same challenges by smoothing contact dynamics analytically. Our first contribution is to establish the theoretical equivalence of the two smoothing schemes for simple systems, and provide qualitative and empirical equivalence on several complex examples. In order to further alleviate 2), our second contribution is a convex, differentiable, and quasi-dynamic formulation of contact dynamics, which is amenable to both smoothing schemes, and has proven to be highly effective for contact-rich planning. Our final contribution resolves 3), where we show that classical sampling-based motion planning algorithms can be effective in global planning when contact modes are abstracted via smoothing. Applying our method on several challenging contact-rich manipulation tasks, we demonstrate that efficient model-based motion planning can achieve results comparable to RL, but with dramatically less computation.},
  archive      = {J_TROB},
  author       = {Tao Pang and H. J. Terry Suh and Lujie Yang and Russ Tedrake},
  doi          = {10.1109/TRO.2023.3300230},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4691-4711},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Global planning for contact-rich manipulation via local smoothing of quasi-dynamic contact models},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deformable object manipulation with constraints using path
set planning and tracking. <em>TROB</em>, <em>39</em>(6), 4671–4690. (<a
href="https://doi.org/10.1109/TRO.2023.3306618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotic deformable object manipulation (DOM) applications, constraints arise commonly from environments and task-specific requirements. Enabling DOM with constraints is, therefore, crucial for its deployment in practice. However, dealing with constraints turns out to be challenging due to many inherent factors, such as inaccessible deformation models of deformable objects (DOs) and varying environmental setups. This article presents a systematic manipulation framework for DOM subject to constraints by proposing a novel path set planning and tracking scheme. First, constrained DOM tasks are formulated into a versatile optimization formalism, which enables dynamic constraint imposition. Because of the lack of the local optimization objective and high state dimensionality, the formulated problem is not analytically solvable. To address this, planning of the path set, which collects paths of DO feedback points, is proposed subsequently to offer feasible path and motion references for the DO in constrained setups. Both theoretical analyses and computationally efficient algorithmic implementation of path set planning are discussed. Lastly, a control architecture combining path set tracking and constraint handling is designed for task execution. The effectiveness of our methods is validated in a variety of DOM tasks with constrained experimental settings.},
  archive      = {J_TROB},
  author       = {Jing Huang and Xiangyu Chu and Xin Ma and Kwok Wai Samuel Au},
  doi          = {10.1109/TRO.2023.3306618},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4671-4690},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Deformable object manipulation with constraints using path set planning and tracking},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physically feasible repair of reactive, linear temporal
logic-based, high-level tasks. <em>TROB</em>, <em>39</em>(6), 4653–4670.
(<a href="https://doi.org/10.1109/TRO.2023.3304009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A typical approach to creating complex robot behaviors is to compose atomic controllers, or skills, such that the resulting behavior satisfies a high-level task; however, when a task cannot be accomplished with a given set of skills, it is difficult to know how to modify the skills to make the task possible. We present a method for combining symbolic repair with physical feasibility checking and implementation to automatically modify existing skills such that the robot can execute a previously infeasible task. We encode robot skills in linear temporal logic (LTL) formulas that capture both safety constraints and goals for reactive tasks. Furthermore, our encoding captures the full skill execution, as opposed to prior work where only the state of the world before and after the skill is executed are considered. Our repair algorithm suggests symbolic modifications, then attempts to physically implement the suggestions by modifying the original skills subject to Linear Temporal Logic (LTL) constraints derived from the symbolic repair. If skills are not physically possible, we automatically provide additional constraints for the symbolic repair. We demonstrate our approach with a Baxter and a Clearpath Jackal.},
  archive      = {J_TROB},
  author       = {Adam Pacheck and Hadas Kress-Gazit},
  doi          = {10.1109/TRO.2023.3304009},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4653-4670},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Physically feasible repair of reactive, linear temporal logic-based, high-level tasks},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Configuration identification for a freeform modular
self-reconfigurable robot - FreeSN. <em>TROB</em>, <em>39</em>(6),
4636–4652. (<a href="https://doi.org/10.1109/TRO.2023.3303848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modular self-reconfigurable robotic systems are potentially more robust and adaptive than conventional systems. This article proposes a novel freeform and truss-structured modular self-reconfigurable robot called FreeSN, containing node and strut modules. A node module contains a low-carbon steel spherical shell. A strut module contains two magnetic-based freeform connectors, which can connect to any position of the node module and provide spherical motions. Accurate configuration identification is essential for the automation of modular robot systems. This article presents a novel configuration identification system for FreeSN, including connection point magnetic localization, module identification, module orientation fusion, and system configuration fusion. A magnetic sensor array is integrated into the node module. A graph convolutional network-based magnetic localization algorithm is proposed, which can efficiently locate a variable number of magnet arrays under ferromagnetic material distortion. The module relative orientation is then estimated by fusing the magnetic localization result with the inertia moment unit and wheel odometry. Finally, the system configuration can be estimated, including the connection topology graph and the poses of modules. The configuration identification system is validated by a series of accuracy evaluation experiments and two library-based automation demonstrations based on closed-loop control.},
  archive      = {J_TROB},
  author       = {Yuxiao Tu and Tin Lun Lam},
  doi          = {10.1109/TRO.2023.3303848},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4636-4652},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Configuration identification for a freeform modular self-reconfigurable robot - FreeSN},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RING++: Roto-translation invariant gram for global
localization on a sparse scan map. <em>TROB</em>, <em>39</em>(6),
4616–4635. (<a href="https://doi.org/10.1109/TRO.2023.3303035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global localization plays a critical role in many robot applications. LiDAR-based global localization draws the community&#39;s focus with its robustness against illumination and seasonal changes. To further improve the localization under large viewpoint differences, we propose RING++ that has roto-translation-invariant representation for place recognition and global convergence for both rotation and translation estimation. With the theoretical guarantee, RING++ is able to address the large viewpoint difference using a lightweight map with sparse scans. In addition, we derive sufficient conditions of feature extractors for the representation preserving the roto-translation invariance, making RING++ a framework applicable to generic multichannel features. To the best of our knowledge, this is the first learning-free framework to address all the subtasks of global localization in the sparse scan map. Validations on real-world datasets show that our approach demonstrates better performance than state-of-the-art learning-free methods and competitive performance with learning-based methods. Finally, we integrate RING++ into a multirobot/session simultaneous localization and mapping system, performing its effectiveness in collaborative applications.},
  archive      = {J_TROB},
  author       = {Xuecheng Xu and Sha Lu and Jun Wu and Haojian Lu and Qiuguo Zhu and Yiyi Liao and Rong Xiong and Yue Wang},
  doi          = {10.1109/TRO.2023.3303035},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4616-4635},
  shortjournal = {IEEE Trans. Robot.},
  title        = {RING++: Roto-translation invariant gram for global localization on a sparse scan map},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantically enhanced multi-object detection and tracking
for autonomous vehicles. <em>TROB</em>, <em>39</em>(6), 4600–4615. (<a
href="https://doi.org/10.1109/TRO.2023.3299517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate ambient perception via multi-object detection and tracking is instrumental for autonomous vehicles. This article addresses two main challenges when operating solely on 3-D light laser detection and ranging (LiDAR) point clouds: the classification of objects with similar geometric structures and tracking under the commonplace setting of low-frequency sensing. First, we design a semantically enhanced feature aggregation module that fuses features learned from two branches with different resolutions and depths. Subsequently, the extracted semantic information combined with our proposed Margin Loss allows the re-identification module to extract time-invariant geometric features. These features are fused with the positional information provided by the detector by a cluster-based Earth&#39;s mover distance algorithm along with conflation to improve the tracking stability. Extensive experiments on nuScenes demonstrate that our proposed model outperforms the state-of-the-art methods for both LiDAR-based 3-D object detection and tracking. In particular, we report an increase of 1.1\% in average multi-object tracking accuracy, as well higher mean average precision for detection by 6.2\% and 7.5\% on motorcycle and bicycle, respectively.},
  archive      = {J_TROB},
  author       = {Tao Wen and Nikolaos M. Freris},
  doi          = {10.1109/TRO.2023.3299517},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4600-4615},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Semantically enhanced multi-object detection and tracking for autonomous vehicles},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The foreseeable future: Self-supervised learning to predict
dynamic scenes for indoor navigation. <em>TROB</em>, <em>39</em>(6),
4581–4599. (<a href="https://doi.org/10.1109/TRO.2023.3304239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for generating, predicting, and using spatiotemporal occupancy grid maps (SOGM), which embed future semantic information of real dynamic scenes. We present an autolabeling process that creates SOGMs from noisy real navigation data. We use a 3-D–2-D feedforward architecture, trained to predict the future time steps of SOGMs, given 3-D Lidar frames as input. Our pipeline is entirely self-supervised, thus enabling lifelong learning for real robots. The network is composed of a 3-D back-end that extracts rich features and enables the semantic segmentation of the lidar frames, and a 2-D front-end that predicts the future information embedded in the SOGM representation, potentially capturing the complexities and uncertainties of real-world multiagent interactions. We also design a navigation system that uses these predicted SOGMs within planning, after they have been transformed into spatiotemporal risk maps. We verify our navigation system&#39;s abilities in simulation, validate it on a real robot, study SOGM predictions on real data in various circumstances, and provide a novel indoor 3-D lidar dataset, collected during our experiments, which includes our automated annotations.},
  archive      = {J_TROB},
  author       = {Hugues Thomas and Jian Zhang and Timothy D. Barfoot},
  doi          = {10.1109/TRO.2023.3304239},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4581-4599},
  shortjournal = {IEEE Trans. Robot.},
  title        = {The foreseeable future: Self-supervised learning to predict dynamic scenes for indoor navigation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variable stiffness soft robotic fingers using snap-fit
kinematic reconfiguration. <em>TROB</em>, <em>39</em>(6), 4567–4580. (<a
href="https://doi.org/10.1109/TRO.2023.3303850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Versatile and secure grasping in robotic systems remains a difficult challenge to address when objects possess a wide range of different properties (size, weight, friction coefficient, etc.). The human hand is often the primary source of inspiration for many technologies addressing this challenge, and a notable feature of our hands is that they can vary their stiffness to match the requirements of the task, e.g., become stiffer or more compliant depending on specific requirements. Many robotic devices have been proposed in the literature mirroring this capability, either using an adjustable internal tension mechanism similar to what happens with human tendons or another physical phenomenon yielding the same effect. This article proposes a new type of soft robotic fingers using a novel method to produce a variable stiffness achieved by modifying the kinematic structure of the fingers using snap-fit joints, a very simple alternative to most variable stiffness mechanisms. The resulting modification of the geometry and kinematics of the fingers, including their number of degrees of freedom, allows to greatly alter the intrinsic stiffness of the grasp produced by these fingers. A notable feature of the proposed new design is that one pair of fingers can be used to switch the stiffness of another pair if a dual arm robot is used.},
  archive      = {J_TROB},
  author       = {Jérôme Bastien and Lionel Birglen},
  doi          = {10.1109/TRO.2023.3303850},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4567-4580},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Variable stiffness soft robotic fingers using snap-fit kinematic reconfiguration},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatiotemporal calibration of 3-d millimetre-wavelength
radar-camera pairs. <em>TROB</em>, <em>39</em>(6), 4552–4566. (<a
href="https://doi.org/10.1109/TRO.2023.3311680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles (AVs) fuse data from multiple sensors and sensing modalities to impart a measure of robustness when operating in adverse conditions. Radars and cameras are popular choices for use in sensor fusion; although radar measurements are sparse in comparison to camera images, radar scans penetrate fog, rain, and snow. However, accurate sensor fusion depends upon knowledge of the spatial transform between the sensors and any temporal misalignment that exists in their measurement times. During the life cycle of an AV, these calibration parameters may change, so the ability to perform in-situ spatiotemporal calibration is essential to ensure reliable long-term operation. State-of-the-art 3D radar-camera spatiotemporal calibration algorithms require bespoke calibration targets that are not readily available in the field. In this paper, we describe an algorithm for targetless spatiotemporal calibration that does not require specialized infrastructure. Our approach leverages the ability of the radar unit to measure its own ego-velocity relative to a fixed, external reference frame. We analyze the identifiability of the spatiotemporal calibration problem and determine the motions necessary for calibration. Through a series of simulation studies, we characterize the sensitivity of our algorithm to measurement noise. Finally, we demonstrate accurate calibration for three real-world systems, including a handheld sensor rig and a vehicle-mounted sensor array. Our results show that we are able to match the performance of an existing, target-based method, while calibrating in arbitrary, infrastructure-free environments.},
  archive      = {J_TROB},
  author       = {Emmett Wise and Qilong Cheng and Jonathan Kelly},
  doi          = {10.1109/TRO.2023.3311680},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4552-4566},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Spatiotemporal calibration of 3-D millimetre-wavelength radar-camera pairs},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical stratification and benchmarking of robotic
grasping performance. <em>TROB</em>, <em>39</em>(6), 4539–4551. (<a
href="https://doi.org/10.1109/TRO.2023.3306613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic grasping is fundamental to many real-world applications, and new approaches must be systematically evaluated. However, in most cases, the performance of a specific approach is assessed by simply counting the number of successful attempts in a given task, and this success rate is then compared to those of other solutions, without taking into account the random variability across different experiments (e.g. due to sensor noise or variations in object placement). In order to address this issue, we classify the observed performance into qualitatively ordered outcomes, thereby stratifying the results. We then show how to analyze these results in a statistical framework, which accounts for the variability between experiments. The advantages of our approach are demonstrated in the practical comparison of four grasp planning algorithms. In particular, we show that the proposed approach allows us to carry out several distinct evaluations from a single set of experiments, without having to repeat the data collection process. We demonstrate that differences between the algorithms, which would not be apparent from overall success rates, can be identified and evaluated.},
  archive      = {J_TROB},
  author       = {Brice Denoun and Miles Hansard and Beatriz León and Lorenzo Jamone},
  doi          = {10.1109/TRO.2023.3306613},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4539-4551},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Statistical stratification and benchmarking of robotic grasping performance},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning a flexible neural energy function with a unique
minimum for globally stable and accurate demonstration learning.
<em>TROB</em>, <em>39</em>(6), 4520–4538. (<a
href="https://doi.org/10.1109/TRO.2023.3303011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a stable autonomous dynamic system (ADS) encoding human motion rules has been shown as an effective way for demonstration learning. However, the stability guarantee may sacrifice the demonstration learning accuracy. This article solves the issue by learning a stability certificate, represented by a neural energy function, on the demonstration set. We propose a polarlike space analysis approach to derive parameter constraints to guarantee the unique-minimum property of the neural energy function, which is essential for it to be a cogent stability certificate. Then, the neural energy function is learned to capture the demonstration preferences via constrained optimization algorithms. With the learned neural energy function, a globally asymptotically stable ADS with predefined position constraint is further formulated. We also quantitatively analyze the generalization ability of the learned ADS by utilizing the substantial flexibility of the neural energy function. The effectiveness of the proposed approach is validated on the LASA dataset and two representative robotic experiments.},
  archive      = {J_TROB},
  author       = {Zhehao Jin and Weiyong Si and Andong Liu and Wen-An Zhang and Li Yu and Chenguang Yang},
  doi          = {10.1109/TRO.2023.3303011},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4520-4538},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning a flexible neural energy function with a unique minimum for globally stable and accurate demonstration learning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semiautonomous robotic manipulator for minimally invasive
aortic valve replacement. <em>TROB</em>, <em>39</em>(6), 4500–4519. (<a
href="https://doi.org/10.1109/TRO.2023.3315966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aortic valve surgery is the preferred procedure for replacing a damaged valve with an artificial one. The ValveTech robotic platform comprises a flexible articulated manipulator and surgical interface supporting the effective delivery of an artificial valve by teleoperation and endoscopic vision. This article presents our recent work on force-perceptive, safe, semiautonomous navigation of the ValveTech platform prior to valve implantation. First, we present a force observer that transfers forces from the manipulator body and tip to a haptic interface. Second, we demonstrate how hybrid forward/inverse mechanics, together with endoscopic visual servoing, lead to autonomous valve positioning. Benchtop experiments and an artificial phantom quantify the performance of the developed robot controller and navigator. Valves can be autonomously delivered with a 2.0±0.5 mm position error and a minimal misalignment of 3.4±0.9°. The hybrid force/shape observer (FSO) algorithm was able to predict distributed external forces on the articulated manipulator body with an average error of 0.09 N. FSO can also estimate loads on the tip with an average accuracy of 3.3\%. The presented system can lead to better patient care, delivery outcome, and surgeon comfort during aortic valve surgery, without requiring sensorization of the robot tip, and therefore obviating miniaturization constraints.},
  archive      = {J_TROB},
  author       = {Izadyar Tamadon and S. M. Hadi Sadati and Virginia Mamone and Vincenzo Ferrari and Christos Bergeles and Arianna Menciassi},
  doi          = {10.1109/TRO.2023.3315966},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4500-4519},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Semiautonomous robotic manipulator for minimally invasive aortic valve replacement},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intrinsic contact sensing and object perception of an
adaptive fin-ray gripper integrating compact deflection sensors.
<em>TROB</em>, <em>39</em>(6), 4482–4499. (<a
href="https://doi.org/10.1109/TRO.2023.3311610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to their tremendous adaptability to free-form objects, soft grippers with fin-ray structure have a wide range of applications. However, kinetostatics analysis and contact sensing for such soft grippers are quite a challenge due to large structural deformations. In this article, a model-based method for intrinsic contact sensing, object perception, and interactive manipulation, is proposed for this kind of adaptive grippers. The contributions arise from the integration of compact strain-gauge sensors, that are particularly fabricated for slender flexible beams undergoing large deformations. Using a discretization-based approach, the contact condition can be identified efficiently in light of the local deformations gathered via the deflection sensors. Prototypes are developed using simple materials and manufacturing methods, on which various validation experiments are conducted. Owing to the contact sensing capability, the developed adaptive fin-ray gripper is able to perceive the boundary geometry and structural compliance of unstructured objects. Moreover, sensor-based feed-back control can be accomplished to perform interactive manipulation, in which the contact force between the finger and object can be regulated precisely (around $5\,\%$ RMS error) in real-time.},
  archive      = {J_TROB},
  author       = {Genliang Chen and Shujie Tang and Shaoqiu Xu and Tong Guan and Yuanhao Xun and Zhuang Zhang and Hao Wang and Zhongqin Lin},
  doi          = {10.1109/TRO.2023.3311610},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4482-4499},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Intrinsic contact sensing and object perception of an adaptive fin-ray gripper integrating compact deflection sensors},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DISG: Driving-integrated spherical gear enables
singularity-free full-range joint motion. <em>TROB</em>, <em>39</em>(6),
4464–4481. (<a href="https://doi.org/10.1109/TRO.2023.3311911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dexterous joints have attracted interest in the field of robotics. This article presents a driving-integrated spherical gear (DISG) that enables entire spherical meshing and active driving between two spherical gears, forming a dexterous multidegrees of freedom rolling contact joint. The DISG consists of a pair of spherical gears and an omnidirectional internal driver. The spherical gear shape is a combined projection of the conventional planar gear profile in the longitudinal and latitudinal directions, which can mesh and be driven over the entire sphere. An actively driving magnet and a passively following magnet are magnetically connected across the spherical gear and together form the internal driver, enabling arbitrary connection points throughout the sphere. In all configurations, one spherical gear can roll in all directions on the surface of the other. Furthermore, we analyze the kinematics of DISG and prove that the DISG-based dexterous joint has good kinematic characteristics, such as singularity-free and full-range workspace. We verify the theoretical and physical characteristics of DISG in a series of experiments on the prototype. We also compare DISG-based joints to other joint actuators and show that DISG-based joints have advantages in dexterity, motion range, compactness, and lightweight.},
  archive      = {J_TROB},
  author       = {Guanqi Liang and Lijun Zong and Tin Lun Lam},
  doi          = {10.1109/TRO.2023.3311911},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4464-4481},
  shortjournal = {IEEE Trans. Robot.},
  title        = {DISG: Driving-integrated spherical gear enables singularity-free full-range joint motion},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unified motion planner for walking, running, and jumping
using the three-dimensional divergent component of motion.
<em>TROB</em>, <em>39</em>(6), 4443–4463. (<a
href="https://doi.org/10.1109/TRO.2023.3321396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Running and jumping are locomotion modes that allow legged robots to rapidly traverse great distances and overcome difficult terrain. In this article, we show that the 3-D divergent component of motion (3D-DCM) framework, which was successfully used for generating walking trajectories in previous works, retains its validity and coherence during flight phases, and, therefore, can be used for planning running and jumping motions. We propose a highly efficient motion planner that generates stable center-of-mass (CoM) trajectories for running and jumping with arbitrary contact sequences and time parametrizations. The proposed planner constructs the complete motion plan as a sequence of motion phases that can be of different types: stance, flight, transition phases, etc. We introduce a unified formulation of the CoM and DCM waypoints at the start and end of each motion phase, which makes the framework extensible and enables the efficient waypoint computation in matrix and algorithmic form. The feasibility of the generated reference trajectories is demonstrated by extensive whole-body simulations with the humanoid robot TORO.},
  archive      = {J_TROB},
  author       = {George Mesesan and Robert Schuller and Johannes Englsberger and Christian Ott and Alin Albu-Schäffer},
  doi          = {10.1109/TRO.2023.3321396},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4443-4463},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Unified motion planner for walking, running, and jumping using the three-dimensional divergent component of motion},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variable stiffness linear actuator based on differential
drive fiber jamming. <em>TROB</em>, <em>39</em>(6), 4429–4442. (<a
href="https://doi.org/10.1109/TRO.2023.3236941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable stiffness technologies have been widely adopted in soft robotics, also combining them with different actuation technologies and demonstrating the potential to increase the range of possible applications of soft systems, such as soft continuum manipulators. However, in most cases, the variable stiffness capabilities of these soft system are far from satisfying the application requirements. With the aim to explore new possibilities to fill this gap, in this work, we present a novel variable stiffness linear actuator (VSLA) based on the combination of composite fiber jamming and the inverse pneumatic artificial muscles working principle. The differential pressure driving approach adopted to control the VSLA decouples the actuator deformation from the variable stiffness capabilities, and this makes the VSLA a suitable candidate for the realization of new kind of continuous arms. Moreover, the VSLA novel architecture introduced in this article was analytically modeled considering the interaction among constituent elements and performances in different loading conditions have been computed. The results obtained from the experimental tests validated the model goodness in terms of assumptions made and showed remarkable variable stiffness capabilities, with a maximum jamming ratio that reaches 21.3.},
  archive      = {J_TROB},
  author       = {Luca Arleo and Lucrezia Lorenzon and Matteo Cianchetti},
  doi          = {10.1109/TRO.2023.3236941},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4429-4442},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Variable stiffness linear actuator based on differential drive fiber jamming},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Morphological design for pneumatic soft actuators and robots
with desired deformation behavior. <em>TROB</em>, <em>39</em>(6),
4408–4428. (<a href="https://doi.org/10.1109/TRO.2023.3323825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A homogeneous pneumatic soft robot may generate complex output motions using a simple input pressure, resulting from its morphological shape that locally deforms the soft material to different degrees by simultaneously tailoring the structural characteristics and orienting the input pressure. To date, design of the morphological shape (inverse problem) has not been fully addressed. This article outlines a geometry–mechanics–optimization integrated approach to automatically shaping a pneumatic soft actuator or robot that achieves the desired deformation behavior. Instead of constraining the robot&#39;s geometry within any predefined regular shape, we employ B-splines to allow generation of freeform boundary surfaces, and use nonlinear mechanical modelling and shape derivative based optimization to navigate the high-dimensional design space. Our design framework can readily regulate the surface quality during the morphological evolution, by imposing the geometric constraints in terms of the principal curvatures and the minimal distance between surfaces as penalty functions. The effect of external forces including the gravity and the interaction force at the end-effector is also taken into account to generalize the method for design problems in which the load capability is also pursued. To improve the computational efficiency, suboptimization problems are constructed within a trust region in which the displacement-dependent objective function is approximated by its first-order Taylor polynomial based on the gradient information to avoid frequently performing time-consuming nonlinear finite element analysis. The suboptimization problems are then solved by the quasi-Newton method combined with the backtracking line search strategy. We showcase various applications to validate our design approach, including actuators for basic extension, bending, and twisting motions, and continuous robot arms that can perform desired in-plane and out-of-plane configurations. We also show that our method can address design of multiple chambers for achieving multiple target deformation behaviors, by co-optimizing the morphological shape and air pressures, which is validated by two examples.},
  archive      = {J_TROB},
  author       = {Feifei Chen and Zenan Song and Shitong Chen and Guoying Gu and Xiangyang Zhu},
  doi          = {10.1109/TRO.2023.3323825},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4408-4428},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Morphological design for pneumatic soft actuators and robots with desired deformation behavior},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed differential dynamic programming architectures
for large-scale multiagent control. <em>TROB</em>, <em>39</em>(6),
4387–4407. (<a href="https://doi.org/10.1109/TRO.2023.3319894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes two decentralized multiagent optimal control methods that combine the computational efficiency and scalability of differential dynamic programming (DDP) and the distributed nature of the alternating direction method of multipliers (ADMM). The first one, nested distributed DDP, is a three-level architecture, which employs ADMM for consensus, an augmented Lagrangian layer for local constraints and DDP as the local optimizer. The second one, merged distributed DDP, is a two-level architecture that addresses both consensus and local constraints with ADMM, further reducing computational complexity. Both frameworks are fully decentralized since all computations are parallelizable among the agents and only local communication is necessary. Simulation results that scale up to thousands of cars and hundreds of drones demonstrate the effectiveness of the algorithms. Superior scalability to large-scale systems against other DDP and sequential quadratic programming methods is also illustrated. Finally, hardware experiments on a multirobot platform verify the applicability of the methods. A video with all results is provided in the supplementary material.},
  archive      = {J_TROB},
  author       = {Augustinos D. Saravanos and Yuichiro Aoyama and Hongchang Zhu and Evangelos A. Theodorou},
  doi          = {10.1109/TRO.2023.3319894},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4387-4407},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Distributed differential dynamic programming architectures for large-scale multiagent control},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient and consistent bundle adjustment on lidar point
clouds. <em>TROB</em>, <em>39</em>(6), 4366–4386. (<a
href="https://doi.org/10.1109/TRO.2023.3311671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous determination of sensor poses and scene geometry is a fundamental problem for robot vision that is often achieved by Bundle Adjustment (BA). This article presents an efficient and consistent bundle adjustment method for light detection and ranging (lidar) sensors. The method employs edge and plane features to represent the scene geometry, and directly minimizes the natural Euclidean distance from each raw point to the respective geometry feature. A nice property of this formulation is that the geometry features can be analytically solved, drastically reducing the dimension of the numerical optimization. To represent and solve the resultant optimization problem more efficiently, this paper then adopts and formalizes the concept of point cluster , which encodes all raw points associated to the same feature by a compact set of parameters, the point cluster coordinates . We derive the closed-form derivatives, up to the second order, of the BA optimization based on the point cluster coordinates and show their theoretical properties such as the null spaces and sparsity. Based on these theoretical results, this paper develops an efficient second-order BA solver. Besides estimating the lidar poses, the solver also exploits the second order information to estimate the pose uncertainty caused by measurement noises, leading to consistent estimates of lidar poses. Moreover, thanks to the use of point cluster, the developed solver fundamentally avoids the enumeration of each raw point in all steps of the optimization: cost evaluation, derivatives evaluation and uncertainty evaluation. The implementation of our method is open sourced to benefit the robotics community.},
  archive      = {J_TROB},
  author       = {Zheng Liu and Xiyuan Liu and Fu Zhang},
  doi          = {10.1109/TRO.2023.3311671},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4366-4386},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Efficient and consistent bundle adjustment on lidar point clouds},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time velocity vector resolving of artificial lateral
line array with fishlike motion noise suppression. <em>TROB</em>,
<em>39</em>(6), 4350–4365. (<a
href="https://doi.org/10.1109/TRO.2023.3297050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past decade has seen the rapid development of the robotic fish in many aspects. However, the velocity measurement problem has not been fully addressed, which limits the autonomy of the robotic fish. To this end, an artificial lateral line (ALL) sensor, inspired by the sensory organs of fish, is developed in this article. By measuring the deformation of the sensitive element, the local flow field around the robotic fish is sensed. According to the characteristics of fishlike motions, a fairing structure is proposed to suppress the turbulence noise and yaw motion noise caused by fishlike oscillation of the tail. This structure ensure that the flow measured by the ALL sensor is closer to laminar flow under viscous effects. Furthermore, to measure the magnitude and direction of the robotic fish velocity, an ALL sensor array is assembled by mounting multiple sensors on the robot&#39;s surface to sense the flow field distribution. Next, a kinematic-based fusion method is proposed for the array system, which obtained the real-time velocity vector of the robotic fish by solving overdetermined motion equations. The proposed ALL array system is tested on a freely swimming robotic fish, and our method achieves a mean absolute error of 0.018 m/s, a linearity ( $R^{2}$ ) of 0.951, and a position tracking error of 0.085 m. Additionally, the fairing structure is found to improve the signal-to-noise ratio by 116\%.},
  archive      = {J_TROB},
  author       = {Zhuoliang Zhang and Chao Zhou and Long Cheng and Xiaofei Wang and Min Tan},
  doi          = {10.1109/TRO.2023.3297050},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4350-4365},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Real-time velocity vector resolving of artificial lateral line array with fishlike motion noise suppression},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-optimal handover trajectory planning for aerial
manipulators based on discrete mechanics and complementarity
constraints. <em>TROB</em>, <em>39</em>(6), 4332–4349. (<a
href="https://doi.org/10.1109/TRO.2023.3301298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning a time-optimal trajectory for aerial robots is critical in many drone applications, such as rescue missions and package delivery, which have been widely researched in recent years. However, it still involves several challenges, particularly when it comes to incorporating special task requirements as well as the aerial robot&#39;s dynamics into the planning. In this work, we study a case where an aerial manipulator shall pick up a parcel from a moving mobile robot in a time-optimal manner. Rather than setting up the approach trajectory manually, which makes it difficult to determine the optimal total travel time to accomplish the desired task within dynamic limits, we propose an optimization framework, which utilizes the framework of discrete mechanics and complementarity constraints. In the proposed approach, the system dynamics is considered via discrete variational Lagrangian mechanics that provides reliable estimation results according to our experiments. The handover opportunities are automatically determined and arranged based on the desired complementarity constraints. Finally, the performance of the proposed framework is verified with numerical simulations and hardware experiments with our self-designed aerial manipulator.},
  archive      = {J_TROB},
  author       = {Wei Luo and Jingshan Chen and Henrik Ebel and Peter Eberhard},
  doi          = {10.1109/TRO.2023.3301298},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4332-4349},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Time-optimal handover trajectory planning for aerial manipulators based on discrete mechanics and complementarity constraints},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ImMesh: An immediate LiDAR localization and meshing
framework. <em>TROB</em>, <em>39</em>(6), 4312–4331. (<a
href="https://doi.org/10.1109/TRO.2023.3321227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a novel light detection and ranging (LiDAR)(-inertial) odometry and mapping framework to achieve the goal of simultaneous localization and meshing in real time. This proposed framework termed immediately meshing (ImMesh) comprises four tightly-coupled modules: receiver, localization, meshing, and broadcaster. The localization module first utilizes the preprocessed sensor data from the receiver, estimates the sensor pose online by registering LiDAR scans to maps, and dynamically grows the map. Then, our meshing module takes the registered LiDAR scan for incrementally reconstructing the triangle mesh on the fly. Finally, the real-time odometry, map, and mesh are published via our broadcaster. The primary contribution of this work is the meshing module, which represents a scene by an efficient voxel structure, performs fast finding of voxels observed by new scans, and incrementally reconstructs triangle facets in each voxel. This voxel-wise meshing operation is delicately designed for the purpose of efficiency; it first performs a dimension reduction by projecting 3-D points to a 2-D local plane contained in the voxel, and then executes the meshing operation with pull, commit, and push steps for incremental reconstruction of triangle facets. To the best of authors&#39; knowledge, this is the first work in the literature that can reconstruct online the triangle mesh of large-scale scenes, just relying on a standard CPU without GPU acceleration.},
  archive      = {J_TROB},
  author       = {Jiarong Lin and Chongjian Yuan and Yixi Cai and Haotian Li and Yunfan Ren and Yuying Zou and Xiaoping Hong and Fu Zhang},
  doi          = {10.1109/TRO.2023.3321227},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4312-4331},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ImMesh: An immediate LiDAR localization and meshing framework},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uniform passive fault-tolerant control of a quadcopter with
one, two, or three rotor failure. <em>TROB</em>, <em>39</em>(6),
4297–4311. (<a href="https://doi.org/10.1109/TRO.2023.3297048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a uniform passive fault-tolerant control (FTC) method for a quadcopter that does not rely on fault information subject to one, two adjacent, two opposite, or three rotor failure. The uniform control implies that the passive FTC is able to cover the condition from quadcopter fault-free to rotor failure without the need for controller switching. To achieve the purpose of passive FTC, the fault of rotors is modeled as a lumped disturbance acting on the virtual control of the quadcopter system. The estimated disturbance is used directly in the passive FTC. At the same time, a modified controller structure is designed to achieve the passive FTC ability for two and three rotor failure. To avoid the control allocation switching from the fault-free control to the FTC, a dynamic control allocation is used. In addition, the closed-loop stability is analyzed in the presence of up to three rotor failure. To validate the proposed uniform passive FTC method, outdoor experiments are performed for the first time , which have demonstrated that the hovering quadcopter is able to recover from one rotor failure using the proposed controller and resume its mission even if two adjacent, two opposite, or three rotors fail, without the need for any rotor fault information or controller switching. Experimental results can be viewed in this video: https://youtu.be/N1OudPXFXnE . Source code is placed on https://github.com/RflyBUAA/DegradedControl.git},
  archive      = {J_TROB},
  author       = {Chenxu Ke and Kai-Yuan Cai and Quan Quan},
  doi          = {10.1109/TRO.2023.3297048},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4297-4311},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Uniform passive fault-tolerant control of a quadcopter with one, two, or three rotor failure},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An informative path planning framework for active learning
in UAV-based semantic mapping. <em>TROB</em>, <em>39</em>(6), 4279–4296.
(<a href="https://doi.org/10.1109/TRO.2023.3313811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) are frequently used for aerial mapping and general monitoring tasks. Recent progress in deep learning enabled automated semantic segmentation of imagery to facilitate the interpretation of large-scale complex environments. Commonly used supervised deep learning for segmentation relies on large amounts of pixelwise labeled data, which is tedious and costly to annotate. The domain-specific visual appearance of aerial environments often prevents the usage of models pretrained on publicly available datasets. To address this, we propose a novel general planning framework for UAVs to autonomously acquire informative training images for model retraining. We leverage multiple acquisition functions and fuse them into probabilistic terrain maps. Our framework combines the mapped acquisition function information into the UAV&#39;s planning objectives. In this way, the UAV adaptively acquires informative aerial images to be manually labeled for model retraining. Experimental results on real-world data and in a photorealistic simulation show that our framework maximizes model performance and drastically reduces labeling efforts. Our map-based planners outperform state-of-the-art local planning.},
  archive      = {J_TROB},
  author       = {Julius Rückin and Federico Magistri and Cyrill Stachniss and Marija Popović},
  doi          = {10.1109/TRO.2023.3313811},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4279-4296},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An informative path planning framework for active learning in UAV-based semantic mapping},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Surfing algorithm: Agile and safe transition strategy for
hybrid aerial underwater vehicle in waves. <em>TROB</em>,
<em>39</em>(6), 4262–4278. (<a
href="https://doi.org/10.1109/TRO.2023.3319928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The agile and safe transdomain in waves is a promising feature but the primary bottleneck of the hybrid aerial underwater vehicle (HAUV). In this article, the surfing algorithm is proposed for Nezha-mini, our predeveloped HAUV prototype, to search for the dynamic window facilitating takeoff in waves and avoiding hazardous waves. For the first time, the cross-domain window, i.e., the vehicle is at the wave crest and heading downstream, is characterized and defined through the vehicle-wave coupled dynamic model. The novel surfing algorithm consists of the gradient perceptron, time-limited momentum gradient search, heading server, and initial conditions. Nezha-mini senses, searches, and tracks the dynamic window in real-time, until the takeoff decisions are triggered. Numerical simulations and experiments in regular and irregular waves reveal the effectiveness of the algorithm. The vehicle maintains a healthy initial attitude and inaccessible wave disturbance during takeoff, thus alleviating the thrust distraction from stability recovery and uncertainty. The average transition time and energy cost are reduced by 59.2\% and 26.1\% compared with random takeoff cases, and the locomotion is smooth, graceful, and low-risk. The computation and cost are low as the algorithm only requires the basic flight controller and the data from the inertial measurement unit instead of the prior parameters of the HAUV and waves. In comparison with the adaptive robust controller, which resists wave disturbance directly, this article provides an enlightening strategy from the perspective of harnessing waves.},
  archive      = {J_TROB},
  author       = {Yuanbo Bi and Yufei Jin and Hexiong Zhou and Yulin Bai and Chenxin Lyu and Zheng Zeng and Lian Lian},
  doi          = {10.1109/TRO.2023.3319928},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4262-4278},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Surfing algorithm: Agile and safe transition strategy for hybrid aerial underwater vehicle in waves},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Redundancy resolution at position level. <em>TROB</em>,
<em>39</em>(6), 4240–4261. (<a
href="https://doi.org/10.1109/TRO.2023.3309097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing the degrees of freedom (DoFs) of robotic systems makes them more versatile and flexible. This usually renders the system kinematically redundant: the main manipulation or interaction task does not fully determine its joint maneuvers. Additional constraints or objectives are required to solve the underdetermined control and planning problems. The state-of-the-art approaches arrange tasks in a hierarchy and decouple lower priority tasks from higher priority tasks on velocity or torque level using projectors. We develop an approach to redundancy resolution and decoupling on position level by determining subspaces of the configurations space independent of the primary task. We call them orthogonal foliations because they are, in a certain sense, orthogonal to the task self-motion manifolds. The approach provides a better insight into the topological properties of robot kinematics and control problems, allowing a global view. A condition for the existence of orthogonal foliations is derived. If the condition is not satisfied, we will still find approximate solutions by numerical optimization. Coordinates can be defined on these orthogonal foliations and can be used as additional task variables for control. We show in simulations that we can control the system without the need for projectors using these coordinates, and we validate the approach experimentally on a seven-DoF robot.},
  archive      = {J_TROB},
  author       = {Alin Albu-Schäffer and Arne Sachtler},
  doi          = {10.1109/TRO.2023.3309097},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4240-4261},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Redundancy resolution at position level},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crawling soft robot exploiting wheel-legs and multimodal
locomotion for high terrestrial maneuverability. <em>TROB</em>,
<em>39</em>(6), 4230–4239. (<a
href="https://doi.org/10.1109/TRO.2023.3299530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to efficiently traverse complex terrain remains an unresolved challenge for mobile soft robots, because their deformable bodies limit the magnitude of the forces they can exert on the environment. To achieve high maneuverability, this article demonstrates a pneumatic soft crawling robot equipped with wheel-legs capable of multimodal locomotion to negotiate various obstacles. The soft robot consists of a pneumatic soft actuator capable of multiple modes of bending deformation as the body and four identical multispoked wheel-legs with passive unidirectional forward rotation as limbs. The synergy of the body actuator and wheel-legs enables the robot to achieve multiple crawling gaits, including gecko-like crawling and inchworm-like crawling. A single gait or a combination of multiple gaits, as well as shape-morphing of the body, enables the robot to navigate obstacles as diverse as confined spaces, inclined surfaces, gaps, and stairs, or to avoid obstacles by circumventing them. Our study substantially improves the maneuverability of pneumatic soft crawling robots, thereby providing new routes for the potential applications of soft robots in obstacle-filled scenarios, including search and rescue, exploration, and inspection.},
  archive      = {J_TROB},
  author       = {Xinpei Ai and Hengmao Yue and Wei Dawid Wang},
  doi          = {10.1109/TRO.2023.3299530},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4230-4239},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Crawling soft robot exploiting wheel-legs and multimodal locomotion for high terrestrial maneuverability},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Localization of partially hidden moving targets using a
fleet of UAVs via bounded-error estimation. <em>TROB</em>,
<em>39</em>(6), 4211–4229. (<a
href="https://doi.org/10.1109/TRO.2023.3303693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the cooperative search and track of moving targets by unmanned aerial vehicles (UAVs) over some regions of interest (RoIs). The RoI contains obstacles that may partly hide the targets. UAVs are not aware of the obstacles&#39; locations and cannot determine when an obstacle limits their field of view. In this article, no map of the RoI is built. This reduces the computational complexity but makes the selection of an appropriate point of view to observe a specific part of the RoI difficult. Showing the absence of a target at a given location of the RoI is then challenging. To address this problem, we introduce a detectability set for each point of the RoI as the set of all UAV locations from where that point is visible. The detectability sets are unknown to the UAVs and evolve with time when the environment is time varying. We assume that each detectability set contains at least one half-cone with a minimal aperture, which translates the fact that targets are never fully occluded by the environment. We prove that a finite number of $L$ simultaneous observations are sufficient to guarantee the presence or absence of targets at a given location. This leads to a partition of the fleet into groups of $L$ UAVs that simultaneously collect measurements on a specific zone of the RoI. Assuming that state perturbations and measurement noises are bounded, a distributed set-membership estimator is used to evaluate set estimates for potential target locations. The trajectories of the UAVs are designed using a model-predictive control approach to reduce the estimation uncertainty. Simulations illustrate the performance of the proposed approach in the presence of unknown static or moving obstacles.},
  archive      = {J_TROB},
  author       = {Julius Ibenthal and Luc Meyer and Hélène Piet-Lahanier and Michel Kieffer},
  doi          = {10.1109/TRO.2023.3303693},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4211-4229},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Localization of partially hidden moving targets using a fleet of UAVs via bounded-error estimation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LSTP: Long short-term motion planning for legged and
legged-wheeled systems. <em>TROB</em>, <em>39</em>(6), 4190–4210. (<a
href="https://doi.org/10.1109/TRO.2023.3302239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a hybrid motion planning and control approach applicable to various ground robot types and morphologies. Our two-step approach uses a sampling-based planner to compute an approximate motion, which is then fed to numerical optimization for refinement. The sampling-based stage finds a long-term global plan consisting of a contact schedule and sequence of keyframes, i.e., stable whole-body configurations. Subsequently, the optimization refines the solution with a short-term planning horizon to satisfy all nonlinear dynamics constraints. The proposed hybrid planner can compute plans for scenarios that would be difficult for trajectory optimization or sampling planner alone. We present tasks of traversing challenging terrain that requires discovering a contact schedule, navigating nonconvex obstacles, and coordinating many degrees of freedom. Our hybrid planner has been applied to three different robots: a quadruped, a wheeled quadruped, and a legged excavator. We validate our hybrid locomotion planner in the real world and simulation, generating behaviors we could not achieve with previous methods. The results show that computing and executing hybrid locomotion plans is possible on hardware in real time.},
  archive      = {J_TROB},
  author       = {Edo Jelavic and Kaixian Qu and Farbod Farshidian and Marco Hutter},
  doi          = {10.1109/TRO.2023.3302239},
  journal      = {IEEE Transactions on Robotics},
  number       = {6},
  pages        = {4190-4210},
  shortjournal = {IEEE Trans. Robot.},
  title        = {LSTP: Long short-term motion planning for legged and legged-wheeled systems},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hypergraph-based multi-robot task and motion planning.
<em>TROB</em>, <em>39</em>(5), 4166–4186. (<a
href="https://doi.org/10.1109/TRO.2023.3297011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a multi-robot task and motion planning method that, when applied to the rearrangement of objects by manipulators, results in solution times up to three orders of magnitude faster than the existing methods and successfully plans for problems with up to 20 objects, more than three times as many objects as comparable methods. We achieve this improvement by decomposing the planning space to consider manipulators alone, objects, and manipulators holding objects. We represent this decomposition with a hypergraph where vertices are decomposed elements of the planning spaces and hyperarcs are transitions between elements. The existing methods use graph-based representations where vertices are full composite spaces and edges are transitions between these. Using the hypergraph reduces the representation size of the planning space for multimanipulator object rearrangement, the number of hypergraph vertices scales linearly with the number of either robots or objects, while the number of hyperarcs scales quadratically with the number of robots and linearly with the number of objects. In contrast, the number of vertices and edges in graph-based representations scales exponentially in the number of robots and objects. We show that similar gains can be achieved for other multi-robot task and motion planning problems.},
  archive      = {J_TROB},
  author       = {James Motes and Tan Chen and Timothy Bretl and Marco Morales Aguirre and Nancy M. Amato},
  doi          = {10.1109/TRO.2023.3297011},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4166-4186},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Hypergraph-based multi-robot task and motion planning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterexample-guided repair for symbolic-geometric action
abstractions. <em>TROB</em>, <em>39</em>(5), 4152–4165. (<a
href="https://doi.org/10.1109/TRO.2023.3294918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated task and motion planning (TMP) offers a promising class of approaches for solving robot planning problems with intricate symbolic and geometric constraints. However, TMP planners rely on difficult-to-construct abstract models of robot actions. In this article, we propose a method for automatically constructing and continuously improving an abstraction of robot actions via observations of the robot performing the actions. This method, called automatic abstraction repair , allows action abstractions to be initially incorrect or incomplete and converge toward a correct model over time. Here, we demonstrate abstraction repair using constrained polynomial zonotopes (CPZs), an expressive nonconvex set representation for modeling predicates over joint symbolic and geometric state. The repair process performs a hybrid optimizing search over symbolic edit operations to predicate formulae and continuous predicate parameters to improve the grounding of the abstraction to the behavior of a physical robot. In this work, we describe the predicate model, introduce the symbolic-geometric abstraction repair problem, and present an anytime algorithm for automatic abstraction repair. We demonstrate that abstraction repair can improve realistic action abstractions for common mobile manipulation actions from a handful of observations and discuss the tradeoffs of the CPZ model for predicate representation.},
  archive      = {J_TROB},
  author       = {Wil Thomason and Hadas Kress-Gazit},
  doi          = {10.1109/TRO.2023.3294918},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4152-4165},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Counterexample-guided repair for symbolic-geometric action abstractions},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal and robust category-level perception: Object pose
and shape estimation from 2-d and 3-d semantic keypoints. <em>TROB</em>,
<em>39</em>(5), 4131–4151. (<a
href="https://doi.org/10.1109/TRO.2023.3277273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider a category-level perception problem, where one is given 2-D or 3-D sensor data picturing an object of a given category (e.g., a car) and has to reconstruct the 3-D pose and shape of the object despite intraclass variability (i.e., different car models have different shapes). We consider an active shape model , where—for an object category—we are given a library of potential computer-aided design models describing objects in that category, and we adopt a standard formulation where pose and shape are estimated from 2-D or 3-D keypoints via nonconvex optimization. Our first contribution is to develop PACE3D $^{\star }$ and PACE2D $^{\star }$ , the first certifiably optimal solvers for pose and shape estimation using 3-D and 2-D keypoints, respectively. Both the solvers rely on the design of tight (i.e., exact) semidefinite relaxations. Our second contribution is to develop outlier-robust versions of both the solvers, named PACE3D # and PACE2D #. Toward this goal, we propose ROBIN( Reject Outliers Based on INvariants ), a general graph-theoretic framework to prune outliers, which uses compatibility hypergraphs to model measurements&#39; compatibility. We show that in category-level perception problems, these hypergraphs can be built from the winding orders of the keypoints (in 2-D) or their convex hulls (in 3-D), and many outliers can be filtered out via maximum hyperclique computation. The last contribution is an extensive experimental evaluation. Besides providing an ablation study on simulated datasets and on the PASCAL3D + dataset, we combine our solver with a deep keypoint detector and show that PACE3D # improves over the state of the art in vehicle pose estimation in the ApolloScape datasets, and its runtime is compatible with practical applications. We release our code at https://github.com/MIT-SPARK/PACE .},
  archive      = {J_TROB},
  author       = {Jingnan Shi and Heng Yang and Luca Carlone},
  doi          = {10.1109/TRO.2023.3277273},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4131-4151},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Optimal and robust category-level perception: Object pose and shape estimation from 2-D and 3-D semantic keypoints},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KT-BT: A framework for knowledge transfer through behavior
trees in multirobot systems. <em>TROB</em>, <em>39</em>(5), 4114–4130.
(<a href="https://doi.org/10.1109/TRO.2023.3290449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multirobot and multiagent systems demonstrate collective (swarm) intelligence through systematic and distributed integration of local behaviors in a group. Agents sharing knowledge about the mission and environment can enhance performance at individual and mission levels. However, this is difficult to achieve, partly due to the lack of a generic framework for transferring part of the known knowledge (behaviors) between agents. This article presents a new knowledge representation framework and a transfer strategy called KT-BT: knowledge transfer through behavior trees. The KT-BT framework follows a query-response-update mechanism through an online behavior tree framework, where agents broadcast queries for unknown conditions and respond with appropriate knowledge using a condition-action-control subflow. We embed a novel grammar structure called stringBT that encodes knowledge, enabling behavior sharing. We theoretically investigate the properties of the KT-BT framework in achieving homogeneity of high knowledge across the entire group compared to a heterogeneous system without the capability of sharing their knowledge. We extensively verify our framework in a simulated multirobot search and rescue problem. The results show successful knowledge transfers and improved group performance in various scenarios. We further study the effects of opportunities and communication range on group performance, knowledge spread, and functional heterogeneity in a group of agents, presenting interesting insights.},
  archive      = {J_TROB},
  author       = {Sanjay Sarma Oruganti Venkata and Ramviyas Parasuraman and Ramana Pidaparti},
  doi          = {10.1109/TRO.2023.3290449},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4114-4130},
  shortjournal = {IEEE Trans. Robot.},
  title        = {KT-BT: A framework for knowledge transfer through behavior trees in multirobot systems},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning modular robot control policies. <em>TROB</em>,
<em>39</em>(5), 4095–4113. (<a
href="https://doi.org/10.1109/TRO.2023.3284362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modular robots can be rearranged into a new design, perhaps each day, to handle a wide variety of tasks by forming a customized robot for each new task. However, reconfiguring just the mechanism is not sufficient: each design also requires its own unique control policy. One could craft a policy from scratch for each new design, but such an approach is not scalable, especially given the large number of designs that can be generated from even a small set of modules. Instead, we create a modular policy framework where the policy structure is conditioned on the hardware arrangement, and use just one training process to create a policy that controls a wide variety of designs. Our approach leverages the fact that the kinematics of a modular robot can be represented as a design graph , with nodes as modules and edges as connections between them. Given a robot, its design graph is used to create a policy graph with the same structure, where each node contains a deep neural network, and modules of the same type share knowledge via shared parameters (e.g., all legs on a hexapod share the same network parameters). We developed a model-based reinforcement learning algorithm, interleaving model learning and trajectory optimization to train the policy. We show the modular policy generalizes to a large number of designs that were not seen during training without any additional learning. Finally, we demonstrate the policy controlling a variety of designs to locomote with both simulated and real robots.},
  archive      = {J_TROB},
  author       = {Julian Whitman and Matthew Travers and Howie Choset},
  doi          = {10.1109/TRO.2023.3284362},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4095-4113},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning modular robot control policies},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Log-GPIS-MOP: A unified representation for mapping,
odometry, and planning. <em>TROB</em>, <em>39</em>(5), 4078–4094. (<a
href="https://doi.org/10.1109/TRO.2023.3296982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whereas dedicated scene representations are required for each different task in conventional robotic systems, this article demonstrates that a unified representation can be used directly for multiple key tasks. We propose the log-Gaussian process implicit surface for mapping, odometry, and planning (Log-GPIS-MOP): a probabilistic framework for surface reconstruction, localization, and navigation based on a unified representation. Our framework applies a logarithmic transformation to a Gaussian process implicit surface (GPIS) formulation to recover a global representation that accurately captures the Euclidean distance field with gradients and, at the same time, the implicit surface. By directly estimating the distance field and its gradient through Log-GPIS inference, the proposed incremental odometry technique computes the optimal alignment of an incoming frame and fuses it globally to produce a map. Concurrently, an optimization-based planner computes a safe collision-free path using the same Log-GPIS surface representation. We validate the proposed framework on simulated and real datasets in 2-D and 3-D, and benchmark against the state-of-the-art approaches. Our experiments show that Log-GPIS-MOP produces competitive results in sequential odometry, surface mapping, and obstacle avoidance.},
  archive      = {J_TROB},
  author       = {Lan Wu and Ki Myung Brian Lee and Cedric Le Gentil and Teresa Vidal-Calleja},
  doi          = {10.1109/TRO.2023.3296982},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4078-4094},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Log-GPIS-MOP: A unified representation for mapping, odometry, and planning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A restorable, variable stiffness pneumatic soft gripper
based on jamming of strings of beads. <em>TROB</em>, <em>39</em>(5),
4065–4077. (<a href="https://doi.org/10.1109/TRO.2023.3280595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots based on particle jamming cannot return to the initial position and initial mechanical state due to the accumulation of particles after removing the particle jamming, which means poor restorability, and the compliance of the robots during deformation will be reduced because of the jamming effect. Here, we present the design, fabrication, and tests of a novel soft actuator with good restorability and compliance. To improve the restorability of the actuator, we used cotton threads to connect the spherical acrylic beads into form strings instead of discrete beads. The beads could be pulled to the initial position by the threads, the actuator also returns to the initial state. To avoid the jamming effect during the deformation of the actuator, we used compressed air to drive the actuator and injected the beads into the actuator after the active deformation. To reduce the driving pressure and facilitate the flow of the beads, an initial noncontact, frame-type strain constraint structure was designed for the soft actuator. Experimental data show that the actuator was flexible during bending and the stiffness can increase more than 12-fold to resist the external load. By pulling the threads, the actuator could be restored to the initial state with an error of less than 3\% of the actuator length after an operation cycle. The soft gripper based on the actuator can grasp repeatedly or laterally. The gripper can grasp soft objects such as a piece of tofu and a balloon of water, and the maximum weight that can be stably grasped is 2.744 kg.},
  archive      = {J_TROB},
  author       = {Fenglin Han and Lei Fei and Run Zou and Weijian Li and Jinghao Zhou and Haiming Zhao},
  doi          = {10.1109/TRO.2023.3280595},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4065-4077},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A restorable, variable stiffness pneumatic soft gripper based on jamming of strings of beads},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight human-friendly robotic arm based on transparent
hydrostatic transmissions. <em>TROB</em>, <em>39</em>(5), 4051–4064. (<a
href="https://doi.org/10.1109/TRO.2023.3290310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present theoretical and experimental results regarding the development and the control of a two-link robotic arm with remotized actuation via rolling diaphragm hydrostatic transmissions. We propose a dynamical model capturing the essential dynamics of the developed transmission/robot ensemble and implement a control strategy consisting of two nested loops, the inner one performing high-bandwidth joint torque regulation and the outer one producing various types of compliance responses for effective human–robot interactions. Extensive sets of experiments, testing both the low-level torque controller and the high-level compliance controller, confirm the effectiveness of the proposed hardware-software remotization architecture.},
  archive      = {J_TROB},
  author       = {Marco Bolignari and Gianluca Rizzello and Luca Zaccarian and Marco Fontana},
  doi          = {10.1109/TRO.2023.3290310},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4051-4064},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Lightweight human-friendly robotic arm based on transparent hydrostatic transmissions},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ContourPose: Monocular 6-d pose estimation method for
reflective textureless metal parts. <em>TROB</em>, <em>39</em>(5),
4037–4050. (<a href="https://doi.org/10.1109/TRO.2023.3290300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pose estimation is an essential technology for industrial robots to perform precise gripping and assembly. The state-of-the-art deep learning-based approach uses an indirect strategy, i.e., first finding local correspondence between the 2-D image and 3-D model, and then using the perspective-n-point and RANSAC methods to calculate the poses of ordinary objects. However, the metal parts in industry are reflective and textureless, making it difficult to identify distinguishable point features to establish 2-D–3-D correspondences. To address this problem, in this article, we propose a novel deep learning based two-stage method for pose estimation of reflective textureless metal parts, which accurately estimates the target pose using monocular red green blue (RGB) images. Since contours play an important role in both keypoints prediction and pose estimation stages, our method is named ContourPose. First, an additional contour decoder is adopted to implicitly constrain the keypoints prediction in the former stage, which improves the accuracy of the keypoints prediction. Then, the predicted contour of the previous stage is taken as geometric prior that is used to iteratively solve for the optimal pose. Experiments indicate that the proposed approach for reflective textureless metal parts has a significant improvement over the state-of-the-art approaches.},
  archive      = {J_TROB},
  author       = {Zaixing He and Quanzhi Li and Xinyue Zhao and Jin Wang and Huarong Shen and Shuyou Zhang and Jianrong Tan},
  doi          = {10.1109/TRO.2023.3290300},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4037-4050},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ContourPose: Monocular 6-D pose estimation method for reflective textureless metal parts},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grasp it like a pro 2.0: A data-driven approach exploiting
basic shape decomposition and human data for grasping unknown objects.
<em>TROB</em>, <em>39</em>(5), 4016–4036. (<a
href="https://doi.org/10.1109/TRO.2023.3286115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the improvements in their computational and physical intelligence, robots are now capable of operating in real-world environments. However, manipulation and grasping capabilities are still areas that require significant improvements. To address this, we introduce a new data-driven grasp planning algorithm called Grasp it Like a Pro 2.0. This algorithm utilizes a small number of human demonstrations to teach a robot how to grasp arbitrary objects. By decomposing objects into basic shapes, our algorithm generates candidate grasps that can generalize to different object&#39;s geometry. The algorithm selects the grasp to execute based on a selection policy that maximizes a novel grasp quality metric introduced in this article. This metric considers the complex interdependencies between the predicted grasp, the local approximation produced by the basic shape decomposition, and the gripper used. We evaluate our approach against multiple baselines using different grippers and objects. The results demonstrate the effectiveness of our method in generating and selecting high-quality and reliable grasps. With a soft underactuated robotic hand, our algorithm achieves a 94.0\% success rate in 150 grasps across 30 different objects. Similarly, with a rigid gripper, it achieves an 85.0\% success rate in 80 grasps across 16 different objects.},
  archive      = {J_TROB},
  author       = {Alessandro Palleschi and Franco Angelini and Chiara Gabellieri and Do Won Park and Lucia Pallottino and Antonio Bicchi and Manolo Garabini},
  doi          = {10.1109/TRO.2023.3286115},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {4016-4036},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Grasp it like a pro 2.0: A data-driven approach exploiting basic shape decomposition and human data for grasping unknown objects},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning approaches to grasp synthesis: A review.
<em>TROB</em>, <em>39</em>(5), 3994–4015. (<a
href="https://doi.org/10.1109/TRO.2023.3280597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping is the process of picking up an object by applying forces and torques at a set of contacts. Recent advances in deep learning methods have allowed rapid progress in robotic object grasping. In this systematic review, we surveyed the publications over the last decade, with a particular interest in grasping an object using all six degrees of freedom of the end-effector pose. Our review found four common methodologies for robotic grasping: sampling-based approaches, direct regression, reinforcement learning, and exemplar approaches In addition, we found two “supporting methods” around grasping that use deep learning to support the grasping process, shape approximation, and affordances. We have distilled the publications found in this systematic review (85 papers) into ten key takeaways we consider crucial for future robotic grasping and manipulation research.},
  archive      = {J_TROB},
  author       = {Rhys Newbury and Morris Gu and Lachlan Chumbley and Arsalan Mousavian and Clemens Eppner and Jürgen Leitner and Jeannette Bohg and Antonio Morales and Tamim Asfour and Danica Kragic and Dieter Fox and Akansel Cosgun},
  doi          = {10.1109/TRO.2023.3280597},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3994-4015},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Deep learning approaches to grasp synthesis: A review},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Equilibria, stability, and sensitivity for the aerial
suspended beam robotic system subject to parameter uncertainty.
<em>TROB</em>, <em>39</em>(5), 3977–3993. (<a
href="https://doi.org/10.1109/TRO.2023.3279033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies how parametric uncertainties affect the cooperative manipulation of a cable-suspended beam-shaped load by means of two aerial robots not explicitly communicating with each other. In particular, this article sheds light on the impact of the uncertain knowledge of the model parameters available to an established communicationless force-based controller. First, we find the closed-loop equilibrium configurations in the presence of the aforementioned uncertainties, and then, we study their stability. Hence, we show the fundamental role played in the robustness of the load attitude control by the internal force induced in the manipulated object by nonvertical cables. Furthermore, we formally study the sensitivity of the attitude error to such parametric variations, and we provide a method to act on the load position error in the presence of uncertainties. Eventually, we validate the results through an extensive set of numerical tests in a realistic simulation environment, including underactuated aerial vehicles and sagging-prone cables, and through hardware experiments.},
  archive      = {J_TROB},
  author       = {Chiara Gabellieri and Marco Tognon and Dario Sanalitro and Antonio Franchi},
  doi          = {10.1109/TRO.2023.3279033},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3977-3993},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Equilibria, stability, and sensitivity for the aerial suspended beam robotic system subject to parameter uncertainty},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A soft, lightweight flipping robot with versatile motion
capabilities for wall-climbing applications. <em>TROB</em>,
<em>39</em>(5), 3960–3976. (<a
href="https://doi.org/10.1109/TRO.2023.3294920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft wall-climbing robots have been limited in their ability to perform complex locomotion in diverse environments due to their structure and weight. Thus far, soft wall-climbing robots with integrated functions that can locomote in complex 3-D environments are yet to be developed. This article addresses this challenge by presenting a lightweight (2.57 g) soft wall-climbing robot with integrated linear, turning, and transitioning motion capabilities. The soft robot employs three pneumatic bending actuators and two adaptive electroadhesion pads, which enable it to flip forward, transition between two walls, turn in two directions, and adhere to various surfaces. Different motion and control strategies are proposed based on a theoretical model. The experimental results demonstrate that the robot can move at an average speed of 3.85 mm/s (0.08 body length/s) on horizontal, vertical, and inverted walls and make transitions between walls with different pinch angles within 180°. Additionally, the soft robot can carry a miniature camera on vertical walls to perform detection and surveillance tasks. This article provides a reliable structure and control strategy to enhance the multifunctionality of soft wall-climbing robots and enable their applications in unstructured environments.},
  archive      = {J_TROB},
  author       = {Rui Chen and Xinrui Tao and Changyong Cao and Pei Jiang and Jun Luo and Yu Sun},
  doi          = {10.1109/TRO.2023.3294920},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3960-3976},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A soft, lightweight flipping robot with versatile motion capabilities for wall-climbing applications},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Closed-loop magnetic manipulation for robotic
transesophageal echocardiography. <em>TROB</em>, <em>39</em>(5),
3946–3959. (<a href="https://doi.org/10.1109/TRO.2023.3281477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a closed-loop magnetic manipulation framework for robotic transesophageal echocardiography (TEE) acquisitions. Different from previous work on intracorporeal robotic ultrasound acquisitions that focus on continuum robot control, we first investigate the use of magnetic control methods for more direct, intuitive, and accurate manipulation of the distal tip of the probe. We modify a standard TEE probe by attaching a permanent magnet and an inertial measurement unit (IMU) sensor to the probe tip and replacing the flexible gastroscope with a soft tether containing only wires for transmitting ultrasound and IMU data and show that six-degree-of-freedom (DOF) localization and five-DOF closed-loop control of the probe can be achieved with an external permanent magnet based on the fusion of internal inertial measurement and external magnetic field sensing data. The proposed method does not require complex structures or motions of the actuator and the probe compared with existing magnetic manipulation methods. We have conducted extensive experiments to validate the effectiveness of the framework in terms of localization accuracy, update rate, workspace size, and tracking accuracy. In addition, our results obtained on a realistic cardiac tissue-mimicking phantom show that the proposed framework is applicable in real conditions and can generally meet the requirements for teleoperated TEE acquisitions.},
  archive      = {J_TROB},
  author       = {Keyu Li and Yangxin Xu and Ziqi Zhao and Ang Li and Max Q.-H. Meng},
  doi          = {10.1109/TRO.2023.3281477},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3946-3959},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Closed-loop magnetic manipulation for robotic transesophageal echocardiography},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AnyGrasp: Robust and efficient grasp perception in spatial
and temporal domains. <em>TROB</em>, <em>39</em>(5), 3929–3945. (<a
href="https://doi.org/10.1109/TRO.2023.3281153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the basis for prehensile manipulation, it is vital to enable robots to grasp as robustly as humans. Our innate grasping system is prompt, accurate, flexible, and continuous across spatial and temporal domains. Few existing methods cover all these properties for robot grasping. In this article, we propose AnyGrasp for grasp perception to enable robots these abilities using a parallel gripper. Specifically, we develop a dense supervision strategy with real perception and analytic labels in the spatial–temporal domain. Additional awareness of objects&#39; center-of-mass is incorporated into the learning process to help improve grasping stability. Utilization of grasp correspondence across observations enables dynamic grasp tracking. Our model can efficiently generate accurate, 7-DoF, dense, and temporally-smooth grasp poses and works robustly against large depth-sensing noise. Using AnyGrasp, we achieve a 93.3\% success rate when clearing bins with over 300 unseen objects, which is on par with human subjects under controlled conditions. Over 900 mean-picks-per-hour is reported on a single-arm system. For dynamic grasping, we demonstrate catching swimming robot fish in the water.},
  archive      = {J_TROB},
  author       = {Hao-Shu Fang and Chenxi Wang and Hongjie Fang and Minghao Gou and Jirong Liu and Hengxu Yan and Wenhai Liu and Yichen Xie and Cewu Lu},
  doi          = {10.1109/TRO.2023.3281153},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3929-3945},
  shortjournal = {IEEE Trans. Robot.},
  title        = {AnyGrasp: Robust and efficient grasp perception in spatial and temporal domains},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stable motion primitives via imitation and contrastive
learning. <em>TROB</em>, <em>39</em>(5), 3909–3928. (<a
href="https://doi.org/10.1109/TRO.2023.3289597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from humans allows nonexperts to program robots with ease, lowering the resources required to build complex robotic solutions. Nevertheless, such data-driven approaches often lack the ability to provide guarantees regarding their learned behaviors, which is critical for avoiding failures and/or accidents. In this work, we focus on reaching/point-to-point motions, where robots must always reach their goal, independently of their initial state. This can be achieved by modeling motions as dynamical systems and ensuring that they are globally asymptotically stable. Hence, we introduce a novel Contrastive Learning loss for training deep neural networks (DNN) that, when used together with an Imitation Learning loss, enforces the aforementioned stability in the learned motions. Differently from previous work, our method does not restrict the structure of its function approximator, enabling its use with arbitrary DNNs and allowing it to learn complex motions with high accuracy. We validate it using datasets and a real robot. In the former case, motions are two- and four-dimensional, modeled as first- and second-order dynamical systems. In the latter, motions are three, four, and six-dimensional, of first and second order, and are used to control a 7-DoF robot manipulator in its end effector space and joint space.},
  archive      = {J_TROB},
  author       = {Rodrigo Pérez-Dattari and Jens Kober},
  doi          = {10.1109/TRO.2023.3289597},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3909-3928},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Stable motion primitives via imitation and contrastive learning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). K-VIL: Keypoints-based visual imitation learning.
<em>TROB</em>, <em>39</em>(5), 3888–3908. (<a
href="https://doi.org/10.1109/TRO.2023.3286074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual imitation learning provides efficient and intuitive solutions for robotic systems to acquire novel manipulation skills. However, simultaneously learning geometric task constraints and control policies from visual inputs alone remains a challenging problem. In this article, we propose the keypoint-based visual imitation learning (K-VIL) approach that automatically extracts sparse, object-centric, and embodiment-independent task representations from a small number of human demonstration videos. The task representation is composed of keypoint-based geometric constraints on principal manifolds, their associated local frames, and the movement primitives that are then needed for the task execution. Our approach is capable of extracting such task representations from a single-demonstration video and of incrementally updating them when new demonstrations are available. To reproduce manipulation skills using the learned set of prioritized geometric constraints in novel scenes, we introduce a novel keypoint-based admittance controller. We evaluate our approach in several real-world applications, showcasing its ability to deal with cluttered scenes, viewpoint mismatch, new instances of categorical objects, and large object pose and shape variations. Our evaluation demonstrates the efficiency and robustness of our approach in both one-shot and few-shot imitation learning settings.},
  archive      = {J_TROB},
  author       = {Jianfeng Gao and Zhi Tao and Noémie Jaquier and Tamim Asfour},
  doi          = {10.1109/TRO.2023.3286074},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3888-3908},
  shortjournal = {IEEE Trans. Robot.},
  title        = {K-VIL: Keypoints-based visual imitation learning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Robotic snake locomotion exploiting body compliance and
uniform body tensions. <em>TROB</em>, <em>39</em>(5), 3875–3887. (<a
href="https://doi.org/10.1109/TRO.2023.3294919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The undulatory locomotion of snakes is one unique wonder of mechanical motions in nature. Traditionally, snakes were thought to push surrounding objects to propel their motion. However, this does not explain their forward locomotion and sidewinding on a flat surface. Recent studies have shown that the snake&#39;s forward locomotion and sidewinding are aided by a nonuniform ground-contact distribution. In this article, we propose a novel control strategy to achieve nonuniform ground contacts for a robotic snake locomotion using body compliance and uniform body tension. First, we present a set of mechanical analyses for a continuum snake model. Then, we demonstrate that the deflection under gravity resulting from body compliance and uniform body tension naturally yields the contact distributions required for forward and backward locomotion and sidewinding. Finally, a simple control strategy is suggested for a robotic snake locomotion, which was validated through dynamic simulations and physical experiments.},
  archive      = {J_TROB},
  author       = {Junhyoung Ha},
  doi          = {10.1109/TRO.2023.3294919},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3875-3887},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robotic snake locomotion exploiting body compliance and uniform body tensions},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust task-space quadratic programming for
kinematic-controlled robots. <em>TROB</em>, <em>39</em>(5), 3857–3874.
(<a href="https://doi.org/10.1109/TRO.2023.3286069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task-space quadratic programming (QP) is an elegant approach for controlling robots subject to constraints. Yet, in the case of kinematic-controlled (i.e., high-gain position or velocity) robots, the closed-loop QP control scheme can be prone to instability depending on how the gains related to the tasks or the constraints are chosen. In this article, we address such instability shortcomings. First, we highlight the nonrobustness of the closed-loop system against nonmodeled dynamics, such as those relative to joint dynamics, flexibilities, external perturbations, etc. Then, we propose a robust QP control formulation based on high-level integral feedback terms in the task space including the constraints. The proposed method is formally proved to ensure closed-loop robust stability and is intended to be applied to any kinematic-controlled robots under practical assumptions. We assess our approach through experiments on a fixed-base robot performing stable fast motions and a floating-base humanoid robot robustly reacting to perturbations to keep its balance.},
  archive      = {J_TROB},
  author       = {Mohamed Djeha and Pierre Gergondet and Abderrahmane Kheddar},
  doi          = {10.1109/TRO.2023.3286069},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3857-3874},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust task-space quadratic programming for kinematic-controlled robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual–tactile fusion for transparent object grasping in
complex backgrounds. <em>TROB</em>, <em>39</em>(5), 3838–3856. (<a
href="https://doi.org/10.1109/TRO.2023.3286071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The grasping of transparent objects is challenging but of significance to robots. In this article, a visual–tactile fusion framework for transparent object grasping in complex backgrounds is proposed, which synergizes the advantages of vision and touch, and greatly improves the grasping efficiency of transparent objects. First, we propose a multiscene synthetic grasping dataset named SimTrans12 K together with a Gaussian-mask annotation method. Next, based on the TaTa gripper, we propose a grasping network named transparent object-grasping convolutional neural network for grasping position detection, which shows good performance in both synthetic and real scenes. Inspired by human grasping, a tactile calibration method and a visual–tactile fusion classification method are designed, which improve the grasping success rate by 36.7\% compared with direct grasping and the classification accuracy by 39.1\%. Furthermore, the tactile height sensing module and the tactile position exploration module are added to solve the problem of grasping transparent objects in irregular and visually undetectable scenes. The experimental results demonstrate the validity of the framework.},
  archive      = {J_TROB},
  author       = {Shoujie Li and Haixin Yu and Wenbo Ding and Houde Liu and Linqi Ye and Chongkun Xia and Xueqian Wang and Xiao-Ping Zhang},
  doi          = {10.1109/TRO.2023.3286071},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3838-3856},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Visual–Tactile fusion for transparent object grasping in complex backgrounds},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aerial swarm defense using interception and herding
strategies. <em>TROB</em>, <em>39</em>(5), 3821–3837. (<a
href="https://doi.org/10.1109/TRO.2023.3292514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a multimode solution to the problem of defending a circular protected area (target) from a wide range of attacks by swarms of risk-taking and/or risk-averse attacking agents (attackers). The proposed multimode solution combines two defense strategies, namely: 1) an interception strategy for a team of defenders to intercept multiple risk-taking attackers while ensuring that the defenders do not collide with each other; 2) a herding strategy to herd a swarm of risk-averse attackers to a safe area. In particular, we develop mixed integer programs (MIPs) and geometry-inspired heuristics to distribute and assign and/or reassign the defenders to interception and herding tasks under different spatiotemporal behaviors by the attackers such as splitting into smaller swarms to evade defenders easily or high-speed maneuvers by some risk-taking attackers to maximize damage to the protected area. We provide theoretical as well as numerical comparison of the computational costs of these MIPs and the heuristics, and demonstrate the overall approach in simulations.},
  archive      = {J_TROB},
  author       = {Vishnu S. Chipade and Dimitra Panagou},
  doi          = {10.1109/TRO.2023.3292514},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3821-3837},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Aerial swarm defense using interception and herding strategies},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VAE-loco: Versatile quadruped locomotion by learning a
disentangled gait representation. <em>TROB</em>, <em>39</em>(5),
3805–3820. (<a href="https://doi.org/10.1109/TRO.2023.3297015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadruped locomotion is rapidly maturing to a degree where robots are able to realize highly dynamic maneuvers. However, current planners are unable to vary key gait parameters of the in-swing feet midair . In this article, we address this limitation and show that it is pivotal in increasing controller robustness by learning a latent space capturing the key stance phases constituting a particular gait. This is achieved via a generative model trained on a single trot style, which encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesizing a continuous variety of trot styles. We demonstrate that specific properties of the drive signal map directly to gait parameters, such as cadence, footstep height, and full-stance duration. Due to the nature of our approach, these synthesized gaits are continuously variable online during robot operation. The use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on two versions of the real ANYmal quadruped robots and demonstrate that our method achieves a continuous blend of dynamic trot styles while being robust and reactive to external perturbations.},
  archive      = {J_TROB},
  author       = {Alexander Luis Mitchell and Wolfgang Xaver Merkt and Mathieu Geisert and Siddhant Gangapurwala and Martin Engelcke and Oiwi Parker Jones and Ioannis Havoutis and Ingmar Posner},
  doi          = {10.1109/TRO.2023.3297015},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3805-3820},
  shortjournal = {IEEE Trans. Robot.},
  title        = {VAE-loco: Versatile quadruped locomotion by learning a disentangled gait representation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal logic motion planning with convex optimization via
graphs of convex sets. <em>TROB</em>, <em>39</em>(5), 3791–3804. (<a
href="https://doi.org/10.1109/TRO.2023.3291463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal logic is a concise way of specifying complex tasks. However, motion planning to achieve temporal logic specifications is difficult, and existing methods struggle to scale to complex specifications and high-dimensional system dynamics. In this article, we cast linear temporal logic motion planning as a shortest path problem in a graph of convex sets and solve it with convex optimization. This approach brings together the best of modern optimization-based temporal logic planners and older automata-theoretic methods, addressing the limitations of each: we avoid clipping and pass-through by representing paths with continuous Bezier curves; computational complexity is polynomial (not exponential) in the number of sample points; global optimality can be certified (though it is not guaranteed); soundness and probabilistic completeness are guaranteed under mild assumptions; and, most importantly, the method scales to complex specifications and high-dimensional systems, including a 30-degree-of-freedom humanoid.},
  archive      = {J_TROB},
  author       = {Vince Kurtz and Hai Lin},
  doi          = {10.1109/TRO.2023.3291463},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3791-3804},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Temporal logic motion planning with convex optimization via graphs of convex sets},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guarantees for real robotic systems: Unifying formal
controller synthesis and reachset-conformant identification.
<em>TROB</em>, <em>39</em>(5), 3776–3790. (<a
href="https://doi.org/10.1109/TRO.2023.3277268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are used increasingly often in safety-critical scenarios, such as robotic surgery or human–robot interaction. To ensure stringent performance criteria, formal controller synthesis is a promising direction to guarantee that robots behave as desired. However, formally ensured properties only transfer to the real robot when the model is appropriate. In this article, we address this problem by combining the identification of a reachset-conformant model with controller synthesis. Since the reachset-conformant model contains all the measured behaviors of the real robot, the safety properties of the model transfer to the real robot. The transferability is demonstrated by experiments on a real robot, for which we synthesize tracking controllers.},
  archive      = {J_TROB},
  author       = {Stefan B. Liu and Bastian Schürmann and Matthias Althoff},
  doi          = {10.1109/TRO.2023.3277268},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3776-3790},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Guarantees for real robotic systems: Unifying formal controller synthesis and reachset-conformant identification},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cable attachment optimization for reconfigurable
cable-driven parallel robots based on various workspace conditions.
<em>TROB</em>, <em>39</em>(5), 3759–3775. (<a
href="https://doi.org/10.1109/TRO.2023.3288838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel method to determine the optimal cable attachment configuration for reconfigurable cable-driven parallel robots (RCDPRs) considering different workspace conditions. It is shown that wrench-feasible, wrench-closure, and interference-free conditions can be formulated into inequality constraints by considering the cable attachment points as polynomial functions or variables. Furthermore, the proposed method determines the optimal cable attachment location that minimizes the cable force or maximizes the tension factor kinematically at each pose. The proposed formulation can be resolved by different optimization techniques, such as semidefinite programming relaxation and multivariable gradient-based optimization solvers. The proposed approach can be implemented on RCDPRs from low to high degrees-of-freedom and a wide range of obstacles. The proposed formulation can be widely applied for different reconfiguration mechanisms, such as rails, unmanned ground vehicle (UGV), and unmanned aerial vehicle (UAV).},
  archive      = {J_TROB},
  author       = {Hung Hon Cheng and Darwin Lau},
  doi          = {10.1109/TRO.2023.3288838},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3759-3775},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Cable attachment optimization for reconfigurable cable-driven parallel robots based on various workspace conditions},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DLSC: Distributed multi-agent trajectory planning in
maze-like dynamic environments using linear safe corridor.
<em>TROB</em>, <em>39</em>(5), 3739–3758. (<a
href="https://doi.org/10.1109/TRO.2023.3279903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an online distributed trajectory planning algorithm for a quadrotor swarm in a maze-like dynamic environment. We utilize a dynamic linear safe corridor to construct the feasible collision constraints that can ensure interagent collision avoidance and consider the uncertainty of moving obstacles. We introduce mode-based subgoal planning to resolve deadlock faster in a complex environment using only previously shared information. For dynamic obstacle avoidance, we adopt heuristic methods such as collision alert propagation and escape point planning to deal with the situation where dynamic obstacles approach the agents clustered in a narrow corridor. We prove that the proposed algorithm guarantees the feasibility of the optimization problem for every replanning step. In an obstacle-free space, the proposed method can compute the trajectories for 60 agents on average 7.66 ms per agent with an Intel i7 laptop and shows the perfect success rate. Also, our method shows 64.5 $\%$ shorter flight time than buffered Voronoi cell and 34.6 $\%$ shorter than with our previous work. We conduct the simulation in a random forest and maze with four dynamic obstacles, and the proposed algorithm shows the highest success rate and shortest flight time compared to state-of-the-art baseline algorithms. In particular, the proposed algorithm shows over 97 $\%$ success rate when the velocity of moving obstacles is below the agent&#39;s maximum speed. We validate the safety and robustness of the proposed algorithm through a hardware demonstration with ten quadrotors and two pedestrians in a maze-like environment.},
  archive      = {J_TROB},
  author       = {Jungwon Park and Yunwoo Lee and Inkyu Jang and H. Jin Kim},
  doi          = {10.1109/TRO.2023.3279903},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3739-3758},
  shortjournal = {IEEE Trans. Robot.},
  title        = {DLSC: Distributed multi-agent trajectory planning in maze-like dynamic environments using linear safe corridor},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A secure robot learning framework for cyber attack
scheduling and countermeasure. <em>TROB</em>, <em>39</em>(5), 3722–3738.
(<a href="https://doi.org/10.1109/TRO.2023.3275875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of learning-based control for robots has been extensively studied, whereas the security issue under malicious adversaries has not been paid much attention to. Malicious adversaries can invade intelligent devices and communication networks used in robots, causing incidents, achieving illegal objectives, and even injuring people. This article first investigates the problems of optimal false data injection attack scheduling and countermeasure design for car-like robots in the framework of deep reinforcement learning. Using a state-of-the-art deep reinforcement learning approach, an optimal false data injection attack scheme is proposed to deteriorate the tracking performance of a robot, guaranteeing the tradeoff between the attack efficiency and the limited attack energy. Then, an optimal tracking control strategy is learned to mitigate attacks and recover the tracking performance. More importantly, a theoretical stability guarantee of a robot using the learning-based secure control scheme is achieved. Both simulated and real-world experiments are conducted to show the effectiveness of the proposed schemes.},
  archive      = {J_TROB},
  author       = {Chengwei Wu and Weiran Yao and Wensheng Luo and Wei Pan and Guanghui Sun and Hui Xie and Ligang Wu},
  doi          = {10.1109/TRO.2023.3275875},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3722-3738},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A secure robot learning framework for cyber attack scheduling and countermeasure},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Impedance learning for human-guided robots in contact with
unknown environments. <em>TROB</em>, <em>39</em>(5), 3705–3721. (<a
href="https://doi.org/10.1109/TRO.2023.3281483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous works have developed impedance control to increase safety and improve performance in contact tasks, where the robot is in physical interaction with either an environment or a human user. This article investigates impedance learning for a robot guided by a human user while interacting with an unknown environment. We develop automatic adaptation of robot impedance parameters to reduce the effort required to guide the robot through the environment, while guaranteeing interaction stability. For nonrepetitive tasks, this novel adaptive controller can attenuate disturbances by learning appropriate robot impedance. Implemented as an iterative learning controller, it can compensate for position dependent disturbances in repeated movements. Experiments demonstrate that the robot controller can, in both repetitive and nonrepetitive tasks: first, identify and compensate for the interaction, second, ensure both contact stability (with reduced tracking error) and maneuverability (with less driving effort of the human user) in contact with real environments, and third, is superior to previous velocity-based impedance adaptation control methods.},
  archive      = {J_TROB},
  author       = {Xueyan Xing and Etienne Burdet and Weiyong Si and Chenguang Yang and Yanan Li},
  doi          = {10.1109/TRO.2023.3281483},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3705-3721},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Impedance learning for human-guided robots in contact with unknown environments},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoMerge: A framework for map assembling and smoothing in
city-scale environments. <em>TROB</em>, <em>39</em>(5), 3686–3704. (<a
href="https://doi.org/10.1109/TRO.2023.3290448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of advancing autonomous driving and increasing reliance on geospatial information, high-precision mapping not only demands accuracy but also flexible construction. Current approaches mainly rely on expensive mapping devices, which are time consuming for city-scale map construction and vulnerable to erroneous data associations without accurate GPS assistance. In this article, we present AutoMerge, a novel framework for merging large-scale maps that surpasses these limitations, which: 1) provides robust place recognition performance despite differences in both translation and viewpoint; 2) is capable of identifying and discarding incorrect loop closures caused by perceptual aliasing; and 3) effectively associates and optimizes large-scale and numerous map segments in the real-world scenario. AutoMerge utilizes multiperspective fusion and adaptive loop closure detection for accurate data associations, and it uses incremental merging to assemble large maps from individual trajectory segments given in random order and with no initial estimations. Furthermore, AutoMerge performs pose graph optimization after assembling the segments to smooth the merged map globally. We demonstrate AutoMerge on both city-scale merging (120 km) and campus-scale repeated merging (4.5 km × 8). The experiments show that AutoMerge: 1) surpasses the second- and third-best methods by 0.9\% and 6.5\% recall in segment retrieval; 2) achieves comparable 3-D mapping accuracy for 120-km large-scale map assembly; and 3) and is robust to temporally spaced revisits. To our knowledge, AutoMerge is the first mapping approach to merge hundreds of kilometers of individual segments without using GPS.},
  archive      = {J_TROB},
  author       = {Peng Yin and Shiqi Zhao and Haowen Lai and Ruohai Ge and Ji Zhang and Howie Choset and Sebastian Scherer},
  doi          = {10.1109/TRO.2023.3290448},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3686-3704},
  shortjournal = {IEEE Trans. Robot.},
  title        = {AutoMerge: A framework for map assembling and smoothing in city-scale environments},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal control for articulated soft robots. <em>TROB</em>,
<em>39</em>(5), 3671–3685. (<a
href="https://doi.org/10.1109/TRO.2023.3288837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots can execute tasks with safer interactions. However, control techniques that can effectively exploit the systems&#39; capabilities are still missing. Differential dynamic programming (DDP) has emerged as a promising tool for achieving highly dynamic tasks. But most of the literature deals with applying the DDP to articulated soft robots by using numerical differentiation, in addition to using pure feed-forward control to perform explosive tasks. Further, underactuated compliant robots are known to be difficult to control and the use of DDP-based algorithms to control them is not yet addressed. We propose an efficient DDP-based algorithm for trajectory optimization of articulated soft robots that can optimize the state trajectory, input torques, and stiffness profile. We provide an efficient method to compute the forward dynamics and the analytical derivatives of series elastic actuators (SEA)/variable stiffness actuators (VSA) and underactuated compliant robots. We present a state-feedback controller that uses locally optimal feedback policies obtained from the DDP. We show through simulations and experiments that the use of feedback is crucial in improving the performance and stabilization properties of various tasks. We also show that the proposed method can be used to plan and control underactuated compliant robots with varying degrees of underactuation effectively.},
  archive      = {J_TROB},
  author       = {Saroj Prasad Chhatoi and Michele Pierallini and Franco Angelini and Carlos Mastalli and Manolo Garabini},
  doi          = {10.1109/TRO.2023.3288837},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3671-3685},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Optimal control for articulated soft robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Creating star worlds: Reshaping the robot workspace for
online motion planning. <em>TROB</em>, <em>39</em>(5), 3655–3670. (<a
href="https://doi.org/10.1109/TRO.2023.3279029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Closed-loop motion planning is suitable for obstacle avoidance in dynamically changing environments due to its reactive nature, and various methods have been presented to provide (almost) global convergence. A common assumption in the control design is that the robot operates in a disjoint star world, i.e., all obstacles are strictly starshaped and mutually disjoint. However, in real-life scenarios obstacles may intersect due to expanded obstacle regions corresponding to robot radius or safety margins. To broaden the applicability of closed-loop motion planning methods, such as harmonic potential fields, we propose a method to reshape a workspace of intersecting obstacles into a disjoint star world. The algorithm is based on two novel concepts presented here, namely, admissible kernel and starshaped hull with specified kernel, which are closely related to the notion of starshaped hull. The utilization of the proposed method is illustrated with examples of a robot operating in a 2-D workspace using a harmonic potential field approach in combination with the developed algorithm.},
  archive      = {J_TROB},
  author       = {Albin Dahlin and Yiannis Karayiannidis},
  doi          = {10.1109/TRO.2023.3279029},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3655-3670},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Creating star worlds: Reshaping the robot workspace for online motion planning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling and control of a 5-DOF parallel continuum haptic
device. <em>TROB</em>, <em>39</em>(5), 3636–3654. (<a
href="https://doi.org/10.1109/TRO.2023.3277068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a new continuum robotics approach for haptic rendering and comanipulation. This approach is illustrated using a robotic interface with six motorized fixed axes connected by deformable beams, in parallel, to an end effector with 5 degrees of freedom. Apart from the rotation of the motors, this design has no articulation, and the motion of the end effector is achieved by deformation of the beams. The flexible beams are equipped with bending sensors, and the motors have encoders. We use a nonlinear finite element mechanical model of the robot based on a mesh of beam elements that is computed in real time at 20 Hz. The bending sensors are incorporated into the model, which allows us to obtain an accurate estimate of the force exerted by the user on the end effector. The model enables a new methodology for calculating the workspace of the continuum haptic device. The model also is propagated to a higher frequency loop (500 Hz), which performs sensing and control of the robot at high rates, using an admittance-type control to command new positions of the actuators. We show that this control methodology allows haptic rendering of virtual walls that are stiffer than the natural stiffness of the robot. Finally, we demonstrate the use of the device for simple comanipulation tasks.},
  archive      = {J_TROB},
  author       = {Margaret Koehler and Thor Morales Bieze and Alexandre Kruszewski and Allison M. Okamura and Christian Duriez},
  doi          = {10.1109/TRO.2023.3277068},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3636-3654},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Modeling and control of a 5-DOF parallel continuum haptic device},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can robots mold soft plastic materials by shaping depth
images? <em>TROB</em>, <em>39</em>(5), 3620–3635. (<a
href="https://doi.org/10.1109/TRO.2023.3288836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can robots mold soft plastic materials by shaping depth images? The short answer is no: current day robots can not. In this article, we address the problem of shaping plastic material with an anthropomorphic arm/hand robot, which observes the material with a fixed depth camera. Robots capable of molding could assist humans in many tasks, such as cooking, scooping, or gardening. Yet, the problem is complex, due to its high-dimensionality at both perception and control levels. To address it, we design three alternative data-based methods for predicting the effect of robot actions on the material. Then, the robot can plan the sequence of actions and their positions, to mold the material into a desired shape. To make the prediction problem tractable, we rely on two original ideas. First, we prove that under reasonable assumptions, the shaping problem can be mapped from point cloud to depth image space, with many benefits (simpler processing, no need for registration, lower computation time, and memory requirements). Second, we design a novel, simple metric for quickly measuring the distance between two depth images. The metric is based on the inherent point cloud representation of depth images, which enables direct and consistent comparison of image pairs through a nonuniform scaling approach, and therefore opens promising perspectives for designing depth image-based robot controllers. We assess our approach in a series of unprecedented experiments, where a robotic arm/hand molds flour from initial to final shapes, either with its own dataset, or by transfer learning from a human dataset. We conclude the article by discussing the limitations of our framework and those of current day hardware, which make human-like robot molding a challenging open research problem.},
  archive      = {J_TROB},
  author       = {Ege Gursoy and Sonny Tarbouriech and Andrea Cherubini},
  doi          = {10.1109/TRO.2023.3288836},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3620-3635},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Can robots mold soft plastic materials by shaping depth images?},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). N<span class="math inline"><sup>2</sup></span>m<span
class="math inline"><sup>2</sup></span>: Learning navigation for
arbitrary mobile manipulation motions in unseen and dynamic
environments. <em>TROB</em>, <em>39</em>(5), 3601–3619. (<a
href="https://doi.org/10.1109/TRO.2023.3284346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite its importance in both industrial and service robotics, mobile manipulation remains a significant challenge as it requires seamless integration of end-effector trajectory generation with navigation skills as well as reasoning over long-horizons. Existing methods struggle to control the large configuration space and to navigate dynamic and unknown environments. In the previous work, we proposed to decompose mobile manipulation tasks into a simplified motion generator for the end-effector in task space and a trained reinforcement learning agent for the mobile base to account for the kinematic feasibility of the motion. In this work, we introduce Neural Navigation for Mobile Manipulation (N $^{2}$ M $^{2}$ ), which extends this decomposition to complex obstacle environments, extends the agent&#39;s control to the torso joint and the norm of the end-effector motion velocities, uses a more general reward function and, thereby, enables robots to tackle a much broader range of tasks in real-world settings. The resulting approach can perform unseen, long-horizon tasks in unexplored environments while instantly reacting to dynamic obstacles and environmental changes. At the same time, it provides a simple way to define new mobile manipulation tasks. We demonstrate the capabilities of our proposed approach in extensive simulation and real-world experiments on multiple kinematically diverse mobile manipulators.},
  archive      = {J_TROB},
  author       = {Daniel Honerkamp and Tim Welschehold and Abhinav Valada},
  doi          = {10.1109/TRO.2023.3284346},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3601-3619},
  shortjournal = {IEEE Trans. Robot.},
  title        = {N$^{2}$M$^{2}$: Learning navigation for arbitrary mobile manipulation motions in unseen and dynamic environments},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geometric algebra for optimal control with applications in
manipulation tasks. <em>TROB</em>, <em>39</em>(5), 3586–3600. (<a
href="https://doi.org/10.1109/TRO.2023.3277282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems in robotics are fundamentally problems of geometry, which have led to an increased research effort in geometric methods for robotics in recent years. The results were algorithms using the various frameworks of screw theory, Lie algebra, and dual quaternions. A unification and generalization of these popular formalisms can be found in geometric algebra. The aim of this article is to showcase the capabilities of geometric algebra when applied to robot manipulation tasks. In particular, the modeling of cost functions for optimal control can be done uniformly across different geometric primitives leading to a low symbolic complexity of the resulting expressions and a geometric intuitiveness. We demonstrate the usefulness, simplicity, and computational efficiency of geometric algebra in several experiments using a Franka Emika robot. The presented algorithms were implemented in c++20 and resulted in the publicly available library gafro . The benchmark shows faster computation of the kinematics than state-of-the-art robotics libraries.},
  archive      = {J_TROB},
  author       = {Tobias Löw and Sylvain Calinon},
  doi          = {10.1109/TRO.2023.3277282},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3586-3600},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Geometric algebra for optimal control with applications in manipulation tasks},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EqVIO: An equivariant filter for visual-inertial odometry.
<em>TROB</em>, <em>39</em>(5), 3567–3585. (<a
href="https://doi.org/10.1109/TRO.2023.3289587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual-inertial odometry (VIO) is the problem of estimating a robot&#39;s trajectory by combining information from an inertial measurement unit (IMU) and a camera and is of great interest to the robotics community. This article develops a novel Lie group symmetry for the VIO problem and applies the recently proposed equivariant filter. The proposed symmetry is compatible with the invariance of the VIO reference frame, leading to improved filter consistency. The bias-free IMU dynamics are group-affine, ensuring that filter linearization errors depend only on the bias estimation error and measurement noise. Furthermore, visual measurements are equivariant with respect to the symmetry, enabling the application of the higher order equivariant output approximation to reduce the approximation error in the filter update equation. As a result, the equivariant filter based on this Lie group is a consistent estimator for VIO with lower linearization error in the propagation of state dynamics and a higher order equivariant output approximation than standard formulations. Experimental results on the popular EuRoC and UZH FPV datasets demonstrate that the proposed system outperforms other state-of-the-art VIO algorithms in terms of both speed and accuracy.},
  archive      = {J_TROB},
  author       = {Pieter van Goor and Robert Mahony},
  doi          = {10.1109/TRO.2023.3289587},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3567-3585},
  shortjournal = {IEEE Trans. Robot.},
  title        = {EqVIO: An equivariant filter for visual-inertial odometry},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time deformable-contact-aware model predictive control
for force-modulated manipulation. <em>TROB</em>, <em>39</em>(5),
3549–3566. (<a href="https://doi.org/10.1109/TRO.2023.3286070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The force modulation of robotic manipulators has been extensively studied for several decades. However, it is not yet commonly used in safety-critical applications due to a lack of accurate interaction contact modeling and weak performance guarantees—a large proportion of them concerning the modulation of interaction forces. This study presents a high-level framework for simultaneous trajectory optimization and force control of the interaction between a manipulator and soft environments, which is prone to external disturbances. Sliding friction and normal contact force are taken into account. The dynamics of the soft contact model and the manipulator are simultaneously incorporated in a trajectory optimizer to generate desired motion and force profiles. A constrained optimization framework based on the alternative direction method of multipliers has been employed to efficiently generate real-time optimal control inputs and high-dimensional state trajectories in a model-predictive control fashion. The experimental validation of the model performance is conducted on a soft substrate with known material properties using a Cartesian space force control mode. Results show a comparison of ground truth and real-time model-based contact force and motion tracking for multiple Cartesian motions in the valid range of the friction model. It is shown that a contact-model-based motion planner can compensate for frictional forces and motion disturbances and improve the overall motion and force tracking accuracy. The proposed high-level planner has the potential to facilitate the automation of medical tasks involving the manipulation of compliant, delicate, and deformable tissues.},
  archive      = {J_TROB},
  author       = {Lasitha Wijayarathne and Ziyi Zhou and Ye Zhao and Frank L. Hammond},
  doi          = {10.1109/TRO.2023.3286070},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3549-3566},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Real-time deformable-contact-aware model predictive control for force-modulated manipulation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smoothly connected preemptive impact reduction and contact
impedance control. <em>TROB</em>, <em>39</em>(5), 3536–3548. (<a
href="https://doi.org/10.1109/TRO.2023.3286045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes novel control methods that lower impact force by preemptive movement and smooth transition to conventional contact-based impedance control. These techniques are suggested for application in force-control-based robots and position/velocity-control-based robots. Strong impact forces have a negative influence on multiple robotic tasks. Recently, preemptive impact reduction techniques that expand conventional contact impedance control using proximity sensors have been examined. However, a seamless transition from impact reduction to contact impedance control has yet to be demonstrated. It has, therefore, been necessary to switch control strategies or perform complicated parameter tuning. In contrast, our proposed methods utilize a serial combined impedance control framework to solve these problems. The preemptive impact reduction feature can be added to an already-implemented impedance controller because the parameter design is divided into impact reduction and contact impedance control. There is no discontinuity or abrupt alteration in the contact force, nor are there any excessively large contact forces that exceed the intended repulsive force established by the contact impedance control during the transition. Furthermore, although the preemptive impact reduction uses a crude optical proximity sensor, the influence of reflectance is minimized by employing a virtual viscous force. Analyses and real-world experiments with a 1-D mass model confirm these features, which are useful for many robots performing contact tasks.},
  archive      = {J_TROB},
  author       = {Hikaru Arita and Hayato Nakamura and Takuto Fujiki and Kenji Tahara},
  doi          = {10.1109/TRO.2023.3286045},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3536-3548},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Smoothly connected preemptive impact reduction and contact impedance control},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Localized and incremental probabilistic inference for
large-scale networked dynamical systems. <em>TROB</em>, <em>39</em>(5),
3516–3535. (<a href="https://doi.org/10.1109/TRO.2023.3297010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present new algorithms for distributed factor graph optimization (DFGO) problems that arise in the probabilistic inference of large-scale networked robotic systems for both batch and real-time problems. First, for the batch DFGO problem, we derive a type of the alternating direction method of multipliers (ADMM) algorithm called the local consensus ADMM (LC-ADMM). The LC-ADMM is fully localized; therefore, the computational effort, communication bandwidth, and memory for each agent scale like $o(1)$ with respect to the network size . We establish two new theoretical results for the LC-ADMM: 1) exponential convergence when the objective is strongly convex and has a Lipschitz continuous subdifferential and 2) $o(1/k)$ convergence when the objective is convex and has a unique solution. We also show that the LC-ADMM allows the use of nonquadratic loss functions, such as $\ell _{1}$ -norm and Huber loss. Second, we also develop the incremental DFGO (iDFGO) algorithm for real-time problems by combining the ideas from the LC-ADMM and the Bayes tree. To derive a time-scalable algorithm, we exploit the temporal sparsity of the real-time factor graph and the convergence of the augmented factors of the LC-ADMM. The iDFGO algorithm incrementally recomputes estimates when new factors are added to the graph and is scalable with respect to both network size and time. We validate the LC-ADMM and iDFGO in simulations with examples from multiagent simultaneous localization and mapping and power grids.},
  archive      = {J_TROB},
  author       = {Kai Matsuka and Soon-Jo Chung},
  doi          = {10.1109/TRO.2023.3297010},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3516-3535},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Localized and incremental probabilistic inference for large-scale networked dynamical systems},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient paradigm for feasibility guarantees in legged
locomotion. <em>TROB</em>, <em>39</em>(5), 3499–3515. (<a
href="https://doi.org/10.1109/TRO.2023.3280431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing feasible body trajectories for legged systems on arbitrary terrains is a challenging task. In this article, we present a paradigm that allows to design feasible Center of Mass (CoM) and body trajectories in an efficient manner. In our previous work (Orsolino et al., 2020), we introduced the notion of the two-dimensional feasible region , where static balance and the satisfaction of joint-torque limits were guaranteed, whenever the projection of the CoM lied inside the proposed admissible region. In this work, we propose a general formulation of the improved feasible region that guarantees dynamic balance alongside the satisfaction of both joint-torque and kinematic limits in an efficient manner. To incorporate the feasibility of the kinematic limits, we introduce an algorithm that computes the reachable region of the CoM. Furthermore, we propose an efficient planning strategy that utilizes the improved feasible region to design feasible CoM and body orientation trajectories. Finally, we validate the capabilities of the improved feasible region and the effectiveness of the proposed planning strategy, using simulations and experiments on the 90 kg hydraulically actuated quadruped and the 21 kg Aliengo robots.},
  archive      = {J_TROB},
  author       = {Abdelrahman Abdalla and Michele Focchi and Romeo Orsolino and Claudio Semini},
  doi          = {10.1109/TRO.2023.3280431},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3499-3515},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An efficient paradigm for feasibility guarantees in legged locomotion},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online self-calibration for visual-inertial navigation:
Models, analysis, and degeneracy. <em>TROB</em>, <em>39</em>(5),
3479–3498. (<a href="https://doi.org/10.1109/TRO.2023.3275878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As sensor calibration plays an important role in visual-inertial sensor fusion, this article performs an in-depth investigation of online self-calibration for robust and accurate visual-inertial state estimation. To this end, we first conduct complete observability analysis for visual-inertial navigation systems (VINS) with full calibration of sensing parameters, including inertial measurement unit (IMU)/camera intrinsics and IMU-camera spatial-temporal extrinsic calibration, along with readout time of rolling shutter (RS) cameras (if used). We study different inertial model variants containing intrinsic parameters that encompass most commonly used models for low-cost inertial sensors. With these models, the observability analysis of linearized VINS with full sensor calibration is performed. Our analysis theoretically proves the intuition commonly assumed in the literature—that is, VINS with full sensor calibration has four unobservable directions, corresponding to the system&#39;s global yaw and position, while all sensor calibration parameters are observable given fully excited motions. Moreover, we, for the first time, identify degenerate motion primitives for IMU and camera intrinsic calibration, which, when combined, may produce complex degenerate motions. We compare the proposed online self-calibration on commonly used IMUs against the state-of-art offline calibration toolbox Kalibr, showing that the proposed system achieves better consistency and repeatability. Based on our analysis and experimental evaluations, we also offer practical guidelines to effectively perform online IMU-camera self-calibration in practice.},
  archive      = {J_TROB},
  author       = {Yulin Yang and Patrick Geneva and Xingxing Zuo and Guoquan Huang},
  doi          = {10.1109/TRO.2023.3275878},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3479-3498},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Online self-calibration for visual-inertial navigation: Models, analysis, and degeneracy},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safely: Safe stochastic motion planning under constrained
sensing via duality. <em>TROB</em>, <em>39</em>(5), 3464–3478. (<a
href="https://doi.org/10.1109/TRO.2023.3297018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a robot operating in an uncertain environment with stochastic, dynamic obstacles. Despite the clear benefits for trajectory optimization, it is often hard to keep track of each obstacle at every time step due to sensing and hardware limitations. We introduce the $\mathtt {Safely}{}$ motion planner, a receding-horizon control framework, that simultaneously synthesizes both a trajectory for the robot to follow as well as a sensor selection strategy that prescribes trajectory-relevant obstacles to measure at each time step while respecting the sensing constraints of the robot. We perform the motion planning using sequential quadratic programming, and prescribe obstacles to sense based on a novel connection between the duality information associated with the convex subproblems and the effect of uncertainty reduction through Kalman filter updates. We guarantee safety by ensuring that the probability of the robot colliding with any of the obstacles is below a prescribed threshold at every time step of the planned robot trajectory. We demonstrate the efficacy of the $\mathtt {Safely}{}$ motion planner through software and hardware experiments.},
  archive      = {J_TROB},
  author       = {Michael Hibbard and Abraham P. Vinod and Jesse Quattrociocchi and Ufuk Topcu},
  doi          = {10.1109/TRO.2023.3297018},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3464-3478},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Safely: Safe stochastic motion planning under constrained sensing via duality},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A pareto-optimal local optimization framework for
multiobjective ergodic search. <em>TROB</em>, <em>39</em>(5), 3452–3463.
(<a href="https://doi.org/10.1109/TRO.2023.3284358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our work is motivated by humanitarian assistant and disaster relief (HADR) where often it is critical to find signs of life in the presence of conflicting criteria, objectives, and information. We believe ergodic search can provide a framework for exploiting available information as well as exploring for new information in applications, such as HADR. Existing ergodic search methods typically consider search using only a single information map. However, one can readily envision many scenarios where multiple information maps that encode different types of relevant information are used. Ergodic search methods currently do not possess the ability to simultaneously search multiple information maps, nor do they have a way to balance which information gets priority. This leads us to formulate a multiobjective ergodic search (MO-ES) problem, which aims to find the so-called Pareto-optimal solutions, for the purpose of providing human decision makers various solutions that trade off among conflicting criteria. To efficiently solve MO-ES, we develop a framework called sequential local ergodic search (SL-ES), which leverages the recent advances in ergodic search methods as well as the idea of local optimization to efficiently compute Pareto-optimal solutions. Our numerical results show that SL-ES computes solutions of better quality and runs faster than the baselines.},
  archive      = {J_TROB},
  author       = {Zhongqiang Ren and Akshaya Kesarimangalam Srinivasan and Bhaskar Vundurthy and Ian Abraham and Howie Choset},
  doi          = {10.1109/TRO.2023.3284358},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3452-3463},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A pareto-optimal local optimization framework for multiobjective ergodic search},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human–robot interaction evaluation-based AAN control for
upper limb rehabilitation robots driven by series elastic actuators.
<em>TROB</em>, <em>39</em>(5), 3437–3451. (<a
href="https://doi.org/10.1109/TRO.2023.3286073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Series elastic actuators (SEAs) have been the most popular compliant actuators as they possess a variety of advantages, such as high compliance, good backdrivability, and tolerance to shocks. They have been adopted by various rehabilitation robots to provide appropriate assistance with suitable compliance during human–robot interaction. For a multijoint SEA-driven rehabilitation robot, a big challenge is to develop an assist-as-needed (AAN) method without losing stability during uncertain physical human–robot interaction. For this purpose, this article proposes a human–robot interaction evaluation-based AAN method for upper limb rehabilitation robots driven by SEAs. First, in order to stabilize the SEA-level dynamics, singular perturbation theory is adopted to design a fast time-scale controller. Second, for the robot-level dynamics, an iterative learning algorithm is adopted for impedance adaption according to the task performance and human intention. The interaction force feedback is introduced for human–robot interaction evaluation, and the intensity of robotic assistance will be adjusted periodically according to the evaluation results. The stability of human–robot interaction is provided with the Lyapunov method. Finally, the proposed rehabilitation method is constructed and implemented on a two-degree-of-freedom SEA-driven robot. It handles the uncertain interaction in such a principle that correct movements will lead to less assistance for encouraging participation and incorrect movements will lead to more assistance for effective training. The proposed method adapts to the subject&#39;s intention and encourages higher participation by decreasing impedance learning strength and increasing allowable motion error. It can fit the participants with different motor capabilities and provide adaptive assistance when a specific trainee tries to change his/her participation during rehabilitation. The performance of the AAN method was validated with experimental studies involving healthy subjects.},
  archive      = {J_TROB},
  author       = {Shuaishuai Han and Haoping Wang and Haoyong Yu},
  doi          = {10.1109/TRO.2023.3286073},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3437-3451},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Human–Robot interaction evaluation-based AAN control for upper limb rehabilitation robots driven by series elastic actuators},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Near-optimal multi-robot motion planning with finite
sampling. <em>TROB</em>, <em>39</em>(5), 3422–3436. (<a
href="https://doi.org/10.1109/TRO.2023.3281152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An underlying structure in several sampling-based methods for continuous multirobot motion planning (MRMP) is the tensor roadmap , which emerges from combining multiple probabilistic roadmap (PRM) graphs constructed for the individual robots via a tensor product. We study the conditions under which the tensor roadmap encodes a near-optimal solution for MRMP—satisfying these conditions implies near optimality for a variety of popular planners, including dRRT*, and the discrete methods M* and conflict-based search, when applied to the continuous domain. We develop the first finite-sample analysis of this kind, which specifies the number of samples, their deterministic distribution, and magnitude of the connection radii that should be used by each individual PRM graph, to guarantee near-optimality using the tensor roadmap. This significantly improves upon a previous asymptotic analysis, wherein the number of samples tends to infinity. Our new finite sample-size analysis supports guaranteed high-quality solutions in practice within finite time. To achieve our new result, we first develop a sampling scheme, which we call the staggered grid , for finite-sample motion planning for individual robots, which requires significantly fewer samples than previous work. We then extend it to the much more involved MRMP setting, which requires to account for interactions among multiple robots. Finally, we report on a few experiments that serve as a verification of our theoretical findings and raise interesting questions for further investigation.},
  archive      = {J_TROB},
  author       = {Dror Dayan and Kiril Solovey and Marco Pavone and Dan Halperin},
  doi          = {10.1109/TRO.2023.3281152},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3422-3436},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Near-optimal multi-robot motion planning with finite sampling},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Perceptive locomotion through nonlinear model-predictive
control. <em>TROB</em>, <em>39</em>(5), 3402–3421. (<a
href="https://doi.org/10.1109/TRO.2023.3275384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic locomotion in rough terrain requires accurate foot placement, collision avoidance, and planning of the underactuated dynamics of the system. Reliably optimizing for such motions and interactions in the presence of imperfect and often incomplete perceptive information is challenging. We present a complete perception, planning, and control pipeline, which can optimize motions for all degrees of freedom of the robot in real time. To mitigate the numerical challenges posed by the terrain, a sequence of convex inequality constraints is extracted as local approximations of foothold feasibility and embedded into an online model-predictive controller. Steppability classification, plane segmentation, and a signed distance field are precomputed per elevation map to minimize the computational effort during the optimization. A combination of multiple-shooting, real-time iteration, and a filter-based line search is used to solve the formulated problem reliably and at high rate. We validate the proposed method in scenarios with gaps, slopes, and stepping stones in simulation and experimentally on the ANYmal quadruped platform, resulting in state-of-the-art dynamic climbing.},
  archive      = {J_TROB},
  author       = {Ruben Grandia and Fabian Jenelten and Shaohui Yang and Farbod Farshidian and Marco Hutter},
  doi          = {10.1109/TRO.2023.3275384},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3402-3421},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Perceptive locomotion through nonlinear model-predictive control},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning of CPG-regulated locomotion
controller for a soft snake robot. <em>TROB</em>, <em>39</em>(5),
3382–3401. (<a href="https://doi.org/10.1109/TRO.2023.3286046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent control of soft robots is challenging due to the nonlinear and difficult-to-model dynamics. One promising model-free approach for soft robot control is reinforcement learning (RL). However, model-free RL methods tend to be computationally expensive and data-inefficient and may not yield natural and smooth locomotion patterns for soft robots. In this work, we develop a bioinspired design of a learning-based goal-tracking controller for a soft snake robot. The controller is composed of two modules: An RL module for learning goal-tracking behaviors given the unmodeled and stochastic dynamics of the robot, and a central pattern generator (CPG) with the Matsuoka oscillators for generating stable and diverse locomotion patterns. We theoretically investigate the maneuverability of Matsuoka CPG&#39;s oscillation bias, frequency, and amplitude for steering control, velocity control, and sim-to-real adaptation of the soft snake robot. Based on this analysis, we proposed a composition of RL and CPG modules such that the RL module regulates the tonic inputs to the CPG system given state feedback from the robot, and the output of the CPG module is then transformed into pressure inputs to pneumatic actuators of the soft snake robot. This design allows the RL agent to naturally learn to entrain the desired locomotion patterns determined by the CPG maneuverability. We validated the optimality and robustness of the control design in both simulation and real experiments, and performed extensive comparisons with state-of-art RL methods to demonstrate the benefit of our bioinspired control design.},
  archive      = {J_TROB},
  author       = {Xuan Liu and Cagdas D. Onal and Jie Fu},
  doi          = {10.1109/TRO.2023.3286046},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3382-3401},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Reinforcement learning of CPG-regulated locomotion controller for a soft snake robot},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tactile and chemical sensing with haptic feedback for a
telepresence explosive ordnance disposal robot. <em>TROB</em>,
<em>39</em>(5), 3368–3381. (<a
href="https://doi.org/10.1109/TRO.2023.3278455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots can be used to mitigate risks in unsafe and austere settings. In recent years, explosive ordnance disposal robots have reduced the technician&#39;s time-on-target, and thus, reduce the direct risk of exposure. This article focuses on the study and development of innovative techniques as the foundational work for a new robot platform. The proposed system includes an organic electrochemical transistor device to detect the existence of explosive residues, and lead to decisions for safe-removal progress. Taurus&#39; surgical gripper facilitates object tactile exploration, and manipulation with control precision to the millimeter range. The highly sensitive triboelectric tactile sensor could reduce intrusiveness during contact, and mitigate the risk of detonation. Haptic devices and visual displays are used to convey important signals, in order to improve the situational awareness of the teleoperator. A machine learning classifier can be used to assist the user to identify objects from tactile sampling. The integration of these methodologies allows for a sensitive approach to concealed objects that are only accessible through tactile sensing.},
  archive      = {J_TROB},
  author       = {Chenxi Xiao and Aaron Benjamin Woeppel and Gina Marie Clepper and Shengjie Gao and Shujia Xu and Johannes F. Rueschen and Daniel Kruse and Wenzhuo Wu and Hong Z. Tan and Thomas Low and Stephen P. Beaudoin and Bryan W. Boudouris and William G. Haris and Juan P. Wachs},
  doi          = {10.1109/TRO.2023.3278455},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3368-3381},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tactile and chemical sensing with haptic feedback for a telepresence explosive ordnance disposal robot},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive fingers coordination for robust grasp and in-hand
manipulation under disturbances and unknown dynamics. <em>TROB</em>,
<em>39</em>(5), 3350–3367. (<a
href="https://doi.org/10.1109/TRO.2023.3280028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a control framework for achieving a robust object grasp and manipulation in hand. In-hand manipulation remains a demanding task as the object is never stable and task success relies on carefully synchronizing the fingers&#39; dynamics. Indeed, fingers must simultaneously generate motion while maintaining contact with the object and, by staying within the hand&#39;s frame, ensuring that the object remains manipulable. These challenges are exacerbated once the hand gets disturbed or when the internal dynamics of the manipulated object are unknown, such as when it is filled with liquid moving during manipulation. We present a control strategy based on coupled dynamical systems (DSs), whereby the fingers move in synchronization using an intermediate dynamics responsible for coordinating fingers. To adapt to changes in forces due to model uncertainties and unexpected disturbances, we employ an adaptive torque-controller combined with a joint impedance regulator that guarantees high tracking accuracy while adapting to dynamic changes. We validate the approach in multiple experiments on 16-degrees-of-freedom robotic hand grasping and manipulating objects with different mass properties, e.g., uneven or varying mass distribution in a glass half-filled with water. We show that the robot can compensate for disturbances generated by internal dynamics and external perturbations. Additionally, we showcase how our controller, in conjunction with learning from human demonstration, provides a robust solution for more complicated manipulations such as finger gaiting.},
  archive      = {J_TROB},
  author       = {Farshad Khadivar and Aude Billard},
  doi          = {10.1109/TRO.2023.3280028},
  journal      = {IEEE Transactions on Robotics},
  number       = {5},
  pages        = {3350-3367},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Adaptive fingers coordination for robust grasp and in-hand manipulation under disturbances and unknown dynamics},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cognitive exercise for persons with alzheimer’s disease and
related dementia using a social robot. <em>TROB</em>, <em>39</em>(4),
3332–3346. (<a href="https://doi.org/10.1109/TRO.2023.3272846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reminiscence therapy (RT) can improve the mood and communication of persons living with Alzheimer&#39;s disease and Alzheimer&#39;s-disease-related dementias (PLWD). Traditional RT requires professionals&#39; facilitation, limiting its accessibility to PLWD. Social robotics has the potential to facilitate RT, enabling accessible home-based RT. However, studies are needed to investigate how PLWD would perceive a robot-mediated reminiscence therapy (RMRT) and how to develop RMRT for positive user experience and successful adoption. In this article, we develop a prototype of RMRT using a humanoid social robot and test it with 12 participants (seven PLWD, two with mild cognitive impairment, and three informal caregivers). The robot automatically displays a memory trigger on its tablet and engages participants in a relatable conversation during RMRT. A mixed-method approach is employed to assess its acceptability and usability. Our results show that PLWD have an overall positive user experience with the RMRT. Participants laugh and sing along with the robot during RMRT and demonstrate intention to use it. In addition, we discuss a robot control method and several critical problems for RMRT. The RMRT can facilitate both verbal and nonverbal social interaction for PLWD and holds promise for engaging, personalized, and efficient home-based cognitive exercises for PLWD.},
  archive      = {J_TROB},
  author       = {Fengpei Yuan and Marie Boltz and Dania Bilal and Ying-Ling Jao and Monica Crane and Joshua Duzan and Abdurhman Bahour and Xiaopeng Zhao},
  doi          = {10.1109/TRO.2023.3272846},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3332-3346},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Cognitive exercise for persons with alzheimer&#39;s disease and related dementia using a social robot},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On-board deep-learning-based unmanned aerial vehicle fault
cause detection and classification via FPGAs. <em>TROB</em>,
<em>39</em>(4), 3319–3331. (<a
href="https://doi.org/10.1109/TRO.2023.3269380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase in the use of unmanned aerial vehicles (UAVs)/drones, it is important to detect and identify causes of failure in real time for proper recovery from a potential crash-like scenario or postincident forensics analysis. The cause of crash could be either a fault in the sensor/actuator system, a physical damage/attack, or a cyber attack on the drone&#39;s software. In this work, we propose novel architectures based on deep convolutional and long short-term memory neural networks to detect (via autoencoder) and classify drone misoperations based on real-time sensor data. The proposed architectures are able to learn high-level features automatically from the raw sensor data. Empirical results show that our solution is able to detect (with over 90\% accuracy) and classify various types of drone misoperations [with about 99\% accuracy (simulation data) and up to 85\% accuracy (experimental data)]. Furthermore, with the help of field programmable gate array-based hardware acceleration, we achieved a speedup of 40x ( $\sim\!\text{2.6 ms}$ ) for detection, while consuming half the amount of power compared with onboard GPU devices, such as NVIDIA Jetson TX2.},
  archive      = {J_TROB},
  author       = {Vidyasagar Sadhu and Khizar Anjum and Dario Pompili},
  doi          = {10.1109/TRO.2023.3269380},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3319-3331},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On-board deep-learning-based unmanned aerial vehicle fault cause detection and classification via FPGAs},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the comparability and optimal aggressiveness of the
adversarial scenario-based safety testing of robots. <em>TROB</em>,
<em>39</em>(4), 3299–3318. (<a
href="https://doi.org/10.1109/TRO.2023.3267020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the class of scenario-based safety testing algorithms in the black-box safety testing configuration. For algorithms sharing the same state–action set coverage with different sampling distributions, it is commonly believed that prioritizing the exploration of high-risk states and actions leads to a better sampling efficiency. Our proposal disputes the above intuition by introducing an impossibility theorem that provably shows that all the safety testing algorithms of the aforementioned difference perform equally well with the same expected sampling efficiency. Moreover, for testing algorithms covering different sets of states and actions, the sampling efficiency criterion is no longer applicable as different algorithms do not necessarily converge to the same termination condition. We then propose a testing aggressiveness definition based on the almost safe set concept along with an unbiased and efficient algorithm that compares the aggressiveness between testing algorithms. Empirical observations from the safety testing of bipedal locomotion controllers and vehicle decision-making modules are also presented to support the proposed theoretical implications and methodologies.},
  archive      = {J_TROB},
  author       = {Bowen Weng and Guillermo A. Castillo and Wei Zhang and Ayonga Hereid},
  doi          = {10.1109/TRO.2023.3267020},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3299-3318},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On the comparability and optimal aggressiveness of the adversarial scenario-based safety testing of robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robot proficiency self-assessment using assumption-alignment
tracking. <em>TROB</em>, <em>39</em>(4), 3279–3298. (<a
href="https://doi.org/10.1109/TRO.2023.3262187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the design of autonomous robots often emphasizes developing proficient robots, another important attribute of autonomous robot systems is their ability to evaluate their own proficiency. A robot should be able to assess how well it can perform a task before, during, and after it has attempted the task. How can autonomous robots be designed to self-assess their behavior? This article presents the assumption-alignment tracking (AAT) method for designing autonomous robots that can effectively evaluate their own performance. In AAT, the robot a) tracks the veracity of assumptions made by the robot&#39;s decision-making algorithms to measure how well these algorithms fit, or align with , its environment and hardware systems, and b) uses the measurement of alignment to assess the robot&#39;s ability to succeed at a given task based on its past experiences. The efficacy of AAT is illustrated through three case studies: a simulated robot navigating in a maze-based (discrete time) Markov chain environment, a simulated robot navigating in a continuous environment, and a real-world robot arranging blocks of different shapes and colors in a specific order on a table. Results show that AAT is able to accurately predict robot performance and, hence, determine robot proficiency in real time.},
  archive      = {J_TROB},
  author       = {Xuan Cao and Alvika Gautam and Tim Whiting and Skyler Smith and Michael A. Goodrich and Jacob W. Crandall},
  doi          = {10.1109/TRO.2023.3262187},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3279-3298},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robot proficiency self-assessment using assumption-alignment tracking},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robot programming by demonstration: Trajectory learning
enhanced by sEMG-based user hand stiffness estimation. <em>TROB</em>,
<em>39</em>(4), 3259–3278. (<a
href="https://doi.org/10.1109/TRO.2023.3258669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory learning is one of the key components of robot Programming by Demonstration approaches, which in many cases, especially in industrial practice, aim at defining complex manipulation patterns. In order to enhance these methods, which are generally based on a physical interaction between the user and the robot, guided along the desired path, an additional input channel is considered in this article. The hand stiffness, that the operator continuously modulates during the demonstration, is estimated from the forearm surface electromyography and translated into a request for a higher or lower accuracy level. Then, a constrained optimization problem is built (and solved) in the framework of smoothing B-splines to obtain a minimum curvature trajectory approximating, in this manner, the taught path within the precision imposed by the user. Experimental tests in different applicative scenarios, involving both position and orientation, prove the benefits of the proposed approach in terms of the intuitiveness of the programming procedure for the human operator and characteristics of the final motion.},
  archive      = {J_TROB},
  author       = {Luigi Biagiotti and Roberto Meattini and Davide Chiaravalli and Gianluca Palli and Claudio Melchiorri},
  doi          = {10.1109/TRO.2023.3258669},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3259-3278},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robot programming by demonstration: Trajectory learning enhanced by sEMG-based user hand stiffness estimation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe data-driven model predictive control of systems with
complex dynamics. <em>TROB</em>, <em>39</em>(4), 3242–3258. (<a
href="https://doi.org/10.1109/TRO.2023.3266995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we address the task and safety performance of data-driven model predictive controllers (DD-MPC) for systems with complex dynamics, i.e., temporally or spatially varying dynamics that may also be discontinuous. The three challenges we focus on are the accuracy of learned models, the receding horizon-induced myopic predictions of DD-MPC, and the active encouragement of safety. To learn accurate models for DD-MPC, we cautiously, yet effectively, explore the dynamical system with rapidly exploring random trees (RRT) to collect a uniform distribution of samples in the state-input space and overcome the common distribution shift in model learning. The learned model is further used to construct an RRT tree that estimates how close the model&#39;s predictions are to the desired target. This information is used in the cost function of the DD-MPC to minimize the short-sighted effect of its receding horizon nature. To promote safety, we approximate sets of safe states using demonstrations of exclusively safe trajectories, i.e., without unsafe examples, and encourage the controller to generate trajectories close to the sets. As a running example, we use a broken version of an inverted pendulum where the friction abruptly changes in certain regions. Furthermore, we showcase the adaptation of our method to a real-world robotic application with complex dynamics: robotic food-cutting. Our results show that our proposed control framework effectively avoids unsafe states with higher success rates than baseline controllers that employ models from controlled demonstrations and even random actions.},
  archive      = {J_TROB},
  author       = {Ioanna Mitsioni and Pouria Tajvar and Danica Kragic and Jana Tumova and Christian Pek},
  doi          = {10.1109/TRO.2023.3266995},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3242-3258},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Safe data-driven model predictive control of systems with complex dynamics},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inverse-dynamics MPC via nullspace resolution.
<em>TROB</em>, <em>39</em>(4), 3222–3241. (<a
href="https://doi.org/10.1109/TRO.2023.3262186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal control (OC) using inverse dynamics provides numerical benefits, such as coarse optimization, cheaper computation of derivatives, and a high convergence rate. However, to take advantage of these benefits in model predictive control (MPC) for legged robots, it is crucial to handle efficiently its large number of equality constraints. To accomplish this, we first propose a novel approach to handle equality constraints based on nullspace parameterization. Our approach balances optimality, and both dynamics and equality-constraint feasibility appropriately, which increases the basin of attraction to high-quality local minima. To do so, we modify our feasibility-driven search by incorporating a merit function. Furthermore, we introduce a condensed formulation of inverse dynamics that considers arbitrary actuator models. We also propose a novel MPC based on inverse dynamics within a perceptive locomotion framework. Finally, we present a theoretical comparison of OC with forward and inverse dynamics and evaluate both numerically. Our approach enables the first application of inverse-dynamics MPC on hardware, resulting in the state-of-the-art dynamic climbing on the ANYmal robot. We benchmark it over a wide range of robotics problems and generate agile and complex maneuvers. We show the computational reduction of our nullspace resolution and condensed formulation (up to ${47.3}\boldsymbol{\%}$ ). We provide evidence of the benefits of our approach by solving coarse optimization problems with a high convergence rate (up to 10 Hz of discretization). Our algorithm is publicly available inside Crocoddyl .},
  archive      = {J_TROB},
  author       = {Carlos Mastalli and Saroj Prasad Chhatoi and Thomas Corbéres and Steve Tonneau and Sethu Vijayakumar},
  doi          = {10.1109/TRO.2023.3262186},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3222-3241},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Inverse-dynamics MPC via nullspace resolution},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modularize-and-conquer: A generalized impact dynamics and
safe precollision control framework for floating-base tree-like robots.
<em>TROB</em>, <em>39</em>(4), 3200–3221. (<a
href="https://doi.org/10.1109/TRO.2023.3257515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible and versatile mobile robotic coworkers are becoming an indispensable commodity for helping humans with repetitive or physically demanding work. A key challenge with these systems is respecting the strict safety requirements in shared and collaborative workspaces. This inevitably requires solving their whole-body dynamics to obtain the necessary inertial impact properties. In this article, we present an integrated impact dynamics and safe precollision control framework to address the discussed challenge. We propose a novel modular dynamics approach that provides efficient formulations for reusing the uncoupled subsystem dynamics when evaluating the coupled system. Our approach is generalized for deriving the whole-body impact dynamics of any articulated floating-base robot. Furthermore, it outperforms classical monolithic approaches for computing the dynamics, making it favorable for systems with more than two dynamic subsystems while allowing decentralized computations. Finally, based on the proposed modular and generalized impact dynamics and extending our previous work, we introduce the generalized safe motion unit as a unified safety scheme for floating-base robotic structures with branched manipulation extremities. The proposed concepts are evaluated on an exemplary wheeled mobile manipulator, considering realistic use cases in simulation and real-world experiments. The obtained results validated the efficacy of our framework and developed methods.},
  archive      = {J_TROB},
  author       = {Mazin Hamad and Alexander Kurdas and Nico Mansfeld and Saeed Abdolshah and Sami Haddadin},
  doi          = {10.1109/TRO.2023.3257515},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3200-3221},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Modularize-and-conquer: A generalized impact dynamics and safe precollision control framework for floating-base tree-like robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wrench and twist capability analysis for cable-driven
parallel robots with consideration of the actuator torque–speed
relationship. <em>TROB</em>, <em>39</em>(4), 3185–3199. (<a
href="https://doi.org/10.1109/TRO.2023.3267383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wrench feasibility and twist feasibility are the workspace conditions that indicate whether the mobile-platform (MP) of the cable-driven parallel robots (CDPRs) can provide a sufficient amount of wrench and twist. Traditionally, these two quantities are evaluated independently from the actuator&#39;s torque and speed limits, which are assumed to be fixed in the literature, but they are, indeed, coupled. This results in a conservative usage of the actuator capability and, hence, hinders the robot&#39;s actual feasibility. In this study, new approaches to analyzing and commanding CDPRs by considering the coupling effect are proposed. First, the required wrench of the MP is mapped into the twist space by the motors&#39; torque–speed relationship and becomes the wrench-dependent available twist set. Then, a new workspace condition and a new metric are introduced based on the available twist set. The metric shows the maximum allowable MP speed map of the workspace. Finally, a varying speed trajectory is designed based on the metric to optimize the total MP traveling time. This study shows the potential of robot wrench–twist capability and enhances the robot hardware effectiveness without any hardware changes.},
  archive      = {J_TROB},
  author       = {Arthur Ngo Foon Chan and Sabrina Wai Yi Lam and Darwin Lau},
  doi          = {10.1109/TRO.2023.3267383},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3185-3199},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Wrench and twist capability analysis for cable-driven parallel robots with consideration of the actuator Torque–Speed relationship},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FeedForward super-twisting sliding mode control for robotic
manipulators: Application to PKMs. <em>TROB</em>, <em>39</em>(4),
3167–3184. (<a href="https://doi.org/10.1109/TRO.2023.3255586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article deals with the development and implementation of a novel feedforward super-twisting sliding mode controller for robotic manipulators. A full stability analysis based on a Lyapunov candidate is established showing a local asymptotic finite-time convergence of the proposed controller in the presence of upper bounded disturbances. Its robustness toward parametric uncertainties and system disturbances, thanks to the super-twisting approach, is pointed out. In addition, the feedforward dynamic term of the proposed controller that can compensate for the model nonlinearities is not sensitive to measurement noise. Real-time experiments have been conducted on two parallel manipulators: a 5-DOF SPIDER4 PKM and a 3-DOF Delta PKM. The effectiveness of the proposed controller is validated in different scenarios, including the nominal case and robustness toward parametric variations (payload) and speed changes},
  archive      = {J_TROB},
  author       = {Hussein Saied and Ahmed Chemori and Mohamed Bouri and Maher El Rafei and Clovis Francis},
  doi          = {10.1109/TRO.2023.3255586},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3167-3184},
  shortjournal = {IEEE Trans. Robot.},
  title        = {FeedForward super-twisting sliding mode control for robotic manipulators: Application to PKMs},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vertical jump of a humanoid robot with CoP-guided angular
momentum control and impact absorption. <em>TROB</em>, <em>39</em>(4),
3154–3166. (<a href="https://doi.org/10.1109/TRO.2023.3271136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Highly dynamic movements such as jumping are important to improve the agility and environmental adaptation of humanoid robots. This article proposes an online optimization method to realize a vertical jump with centroidal angular momentum (CAM) control and landing impact absorption for a humanoid robot. First, the robot&#39;s center of mass (CoM) trajectory is generated by nonlinear optimization. Then, a quasi-sliding mode controller is designed to ensure that the robot tracks the CoM trajectory accurately. To avoid unexpected spinning in the flight phase, a center-of-pressure-guided angular momentum controller is designed to stabilize the CAM. The modifications of CoM and CAM are realized by online optimization of dynamic components and inverse dynamics. Two quadratic programming optimizations are utilized to generate feasible contact force/torque and joint acceleration referring to uplevel CoM and CAM controllers. In addition, a viscoelastic model-based controller is designed to absorb the vibration caused by a large contact impact. A simulation and experiment of a 0.5-m high (foot lifting distance) vertical jump are achieved on a humanoid robot platform in this article (Fig. 1).},
  archive      = {J_TROB},
  author       = {Haoxiang Qi and Xuechao Chen and Zhangguo Yu and Gao Huang and Yaliang Liu and Libo Meng and Qiang Huang},
  doi          = {10.1109/TRO.2023.3271136},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3154-3166},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Vertical jump of a humanoid robot with CoP-guided angular momentum control and impact absorption},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-free 3-d shape control of deformable objects using
novel features based on modal analysis. <em>TROB</em>, <em>39</em>(4),
3134–3153. (<a href="https://doi.org/10.1109/TRO.2023.3269347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape control of deformable objects is a challenging and important robotic problem. This article proposes a model-free controller using novel 3-D global deformation features based on modal analysis. Unlike most existing controllers using geometric features, our controller employs physically based deformation features designed by decoupling global deformation into low-frequency modes. Although modal analysis is widely adopted in computer vision and simulation, its usage in robotic deformation control is still an open topic. We develop a new model-free framework for the modal-based deformation control. Physical interpretation of the modes enables us to formulate an analytical deformation Jacobian matrix mapping the robot manipulation onto changes of the modal features. In the Jacobian matrix, unknown geometric and physical models of the object are treated as low-dimensional modal parameters, which can be used to linearly parameterize the closed-loop system. Thus, an adaptive controller with proven stability can be designed to deform the object while online estimating the modal parameters. Simulations and experiments are conducted using linear, planar, and volumetric objects under different settings. The results not only confirm the superior performance of our controller, but also demonstrate its advantages over the baseline method.},
  archive      = {J_TROB},
  author       = {Bohan Yang and Bo Lu and Wei Chen and Fangxun Zhong and Yun-Hui Liu},
  doi          = {10.1109/TRO.2023.3269347},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3134-3153},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Model-free 3-D shape control of deformable objects using novel features based on modal analysis},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A distributed, event-triggered, adaptive controller for
cooperative manipulation with rolling contacts. <em>TROB</em>,
<em>39</em>(4), 3120–3133. (<a
href="https://doi.org/10.1109/TRO.2023.3268595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a distributed, event-triggered, and adaptive control algorithm for cooperative object manipulation with rolling contacts and unknown dynamic parameters. Whereas conventional cooperative manipulation methods require rigid contact points, our approach exploits rolling effects of passive end-effectors and does not require force/torque sensing. The removal of rigidity allows for more modular grasping, increased application to more object types, and online adjustment of the grasp. The proposed control algorithm exhibits the following properties: 1) it is distributed, in the sense that the robotic agents calculate their own control signal, under an event-triggered communication scheme. Such a scheme reduces the interagent communication requirements with respect to continuous communication schemes; 2) it uses an online adaptation mechanism to accommodate for unknown dynamic parameters of the object and the agents and 3) it adapts existing internal force controllers to guarantee no slip throughout the manipulation task despite the event-triggered nature of the communication scheme. Hardware implementation validates the effectiveness of the proposed approach.},
  archive      = {J_TROB},
  author       = {Wenceslao Shaw Cortez and Christos K. Verginis and Dimos V. Dimarogonas},
  doi          = {10.1109/TRO.2023.3268595},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3120-3133},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A distributed, event-triggered, adaptive controller for cooperative manipulation with rolling contacts},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SSK: Robotic pen-art system for large, nonplanar canvas.
<em>TROB</em>, <em>39</em>(4), 3106–3119. (<a
href="https://doi.org/10.1109/TRO.2023.3268585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a semiautonomous robotic pen-drawing system, called SSK, that is capable of creating pen art on a large nonplanar surface. Our robotic system relies on a seven-degree-of-freedom impedance-controlled manipulator with a three-degree-of-freedom holonomic mobile platform. We use a vector-graphics engine to take an artist&#39;s pen drawing as input, and we generate Bézier spline curves to be drawn on the given target drawing canvas. Then, our system finds a set of minimal, discrete configurations for the mobile platform to cover the entire canvas surface while considering the reachability of the manipulator. The drawing is split into multiple subdrawings according to the found configurations. Our system replicates the spline drawing on the target surface using impedance control, which enables us to compensate for the uncertainty and incompleteness inherent to canvas-surface representations and various robotic and sensor noises. We demonstrate that our system can create visually pleasing and complicated pen art on large, nonplanar surfaces.},
  archive      = {J_TROB},
  author       = {Daeun Song and Jiyoon Park and Young J. Kim},
  doi          = {10.1109/TRO.2023.3268585},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3106-3119},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SSK: Robotic pen-art system for large, nonplanar canvas},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human–robot attachment system for exoskeletons: Design and
performance analysis. <em>TROB</em>, <em>39</em>(4), 3087–3105. (<a
href="https://doi.org/10.1109/TRO.2023.3268587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exoskeleton robots found application in neurorehabilitation, telemanipulation, and power augmentation. The human–robot attachment system of an exoskeleton should transmit all the interaction forces while keeping the anatomical and robotic joint axes aligned. Existing attachment concepts were bounding the performance of modern exoskeletons due to insufficient stiffness for high-performance force control, time-consuming adaption processes, and/or bulkiness. Therefore, we developed an augmented attachment system for a recent fully actuated nine-degree-of-freedom upper limb exoskeleton. The proposed system was compared to a conventional solution in a case study with four participants. The proposed attachment system lowered the relative motion between the human and the robot under static loads for all defined landmarks by 45\% on average. The occurrence of undesired contacts in the trials was mitigated by 74\%, thus improving conditions for closed-loop force control. Furthermore, the proposed system adapted better to the user&#39;s anatomy facilitating more accurate alignment and less obstruction. On average, self-attachment took $\mathbf {43(8.3)}$ $\mathrm{s}$ to don(doff). Thereby, the alignment of anatomic landmarks had typically less than 15 mm offset to a thorough expert alignment, making self-attachment eligible. The augmented attachment system and the insights gained by the case study are expected to enable improvement of the physical human–robot interaction of exoskeletons.},
  archive      = {J_TROB},
  author       = {Yves Zimmermann and Jaeyong Song and Cédric Deguelle and Julia Läderach and Lingfei Zhou and Marco Hutter and Robert Riener and Peter Wolf},
  doi          = {10.1109/TRO.2023.3268587},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3087-3105},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Human–Robot attachment system for exoskeletons: Design and performance analysis},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven modeling for gait phase recognition in a
wearable exoskeleton using estimated forces. <em>TROB</em>,
<em>39</em>(4), 3072–3086. (<a
href="https://doi.org/10.1109/TRO.2023.3262108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of gait phases is critical in effectively assessing the assistance provided by lower limb exoskeletons. In this study, we propose a novel gait phase recognition system called ObsNet to analyze the gait of individuals with spinal cord injuries (SCI). To ensure the reliable use of exoskeletons, it is essential to maintain practicality and avoid exposing the system to unnecessary risks of fatigue, inaccuracy, or incompatibility with human-centered devices. Therefore, we propose a new approach to characterize exoskeletal-assisted gait by estimating forces on exoskeletal joints during walking. Although these estimated forces are potentially useful for detecting gait phases, their nonlinearities make it challenging for existing algorithms to generalize accurately. To address this challenge, we introduce a data-driven model that simultaneously captures both feature extraction and order dependencies, and enhance its performance through a threshold-based compensational method to filter out momentary errors. We evaluated the effectiveness of ObsNet through robotic walking experiments with two practical users with complete paraplegia. Our results indicate that ObsNet outperformed state-of-the-art methods that use joint information and other recurrent networks in identifying the gait phases of individuals with SCI ( $\boldsymbol{p}&amp;lt; \mathbf{0.05}$ ). We also observed reliable imitation of ground truth after compensation. Overall, our research highlights the potential of wearable technology to improve the daily lives of individuals with disabilities through accurate and stable state assessment.},
  archive      = {J_TROB},
  author       = {Kyeong-Won Park and Jungsu Choi and Kyoungchul Kong},
  doi          = {10.1109/TRO.2023.3262108},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3072-3086},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Data-driven modeling for gait phase recognition in a wearable exoskeleton using estimated forces},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WebGripper: Bioinspired cobweb soft gripper for adaptable
and stable grasping. <em>TROB</em>, <em>39</em>(4), 3059–3071. (<a
href="https://doi.org/10.1109/TRO.2023.3262115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web structure is a flexible structure widely used in animal predation behavior and human hunting work, which exhibits an excellent capability of gripping objects stably and securely. Inspired by the predation behavior of spiders, in this article, we present a bioinspired cobweb soft gripper, named WebGripper, which takes on a form like a spider web before grasping an object and presents an entangling state like a snake after grasping the object. These characteristics result in broad adaptability to various objects and enhanced grasping stability. The design concept, grasping principle, and fabrication process of the WebGripper are presented in this work, and the influences of cable layout and soft finger installation angle are analyzed to provide a reference for the design of the WebGripper. To evaluate the performance of the WebGripper, we carried out experiments on grasping objects with different shapes and sizes. Experimental results illustrated the universal adaptable grasping ability of the WebGripper, which exhibits excellent application prospects in many fields, such as goods sorting, fruit picking, and underwater fishing. This work is expected to promote the development of a high-performance soft gripper that may be used in a number of applications based on the understanding of the bionic web structure.},
  archive      = {J_TROB},
  author       = {Xinbo Chen and Jiantao Yao and Shuai Zhang and Kunming Zhu and Shuaiqi Kong and Shupeng Qi and Xuanhao Zhang},
  doi          = {10.1109/TRO.2023.3262115},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3059-3071},
  shortjournal = {IEEE Trans. Robot.},
  title        = {WebGripper: Bioinspired cobweb soft gripper for adaptable and stable grasping},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast soft robotic laser sweeping system using data-driven
modeling approach. <em>TROB</em>, <em>39</em>(4), 3043–3058. (<a
href="https://doi.org/10.1109/TRO.2023.3262118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots have great potential in surgical applications due to their compliance and adaptability to their environment. However, their flexibility and nonlinearity bring challenges for precise modeling, sensing, and control, especially in constrained cavities. In this article, a simple, compact two-segment soft robot for flexible laser ablation is proposed. The proximal hydraulic-driven segment can offer omnidirectional bending so as to navigate toward lesions. The distal segment driven by tendons enables precise, fast steering of laser collimator for laser sweeping on lesion targets. The dynamics of such mechanical steering motion can be enhanced with a metal spring backbone integrated along the collimator, thus facilitating the control with certain linearity and responsiveness. A soft robot modeling and control scheme based on Koopman operators is proposed. We also design a disturbance observer so as to incorporate the controller feedback with real-time fiber optic shape sensing. Experimental validation is conducted on simulated or ex-vivo laser ablation tasks, thus evaluating our control strategies in laser path following across various contours/patterns. As a result, such a simple compact laser manipulation can perform up to 6 Hz sweeping with precision of path following errors below 1 mm. Such modeling and control scheme could also be used on an endoscopic laser ablation robot with unsymmetric mechanism driven by two tendons.},
  archive      = {J_TROB},
  author       = {Kui Wang and Xiaomei Wang and Justin Di-Lang Ho and Ge Fang and Bohao Zhu and Rongying Xie and Yun-Hui Liu and Kwok Wai Samuel Au and Jason Ying-Kuen Chan and Ka-Wai Kwok},
  doi          = {10.1109/TRO.2023.3262118},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3043-3058},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A fast soft robotic laser sweeping system using data-driven modeling approach},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HARPS: An online POMDP framework for human-assisted robotic
planning and sensing. <em>TROB</em>, <em>39</em>(4), 3024–3042. (<a
href="https://doi.org/10.1109/TRO.2023.3263460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of autonomous robots to model, communicate, and act on semantic “soft data” remains challenging. The human-assisted robotic planning and sensing (HARPS) framework is presented for active semantic sensing and planning in human–robot teams to address these gaps by formally combining the benefits of online sampling-based partially observable Markov decision process policies, multimodal human–robot interaction, and Bayesian data fusion. HARPS lets humans impose model structure and extend the range of soft data by sketching and labeling new semantic features in uncertain environments. Dynamic model updating lets robotic agents actively query humans for novel and relevant semantic data, thereby improving model and state beliefs for improved online planning. Simulations of a unmanned aerial vehicle-enabled target search in a large-scale partially structured environment show significant improvements in time and beliefs required for interception versus conventional planning with robot-only sensing. A human subject study in the same environment shows an average doubling in dynamic target capture rate compared to the lone robot case and highlights the robustness of HARPS over a range of user characteristics and interaction modalities.},
  archive      = {J_TROB},
  author       = {Luke Burks and Hunter M. Ray and Jamison McGinley and Sousheel Vunnam and Nisar Ahmed},
  doi          = {10.1109/TRO.2023.3263460},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3024-3042},
  shortjournal = {IEEE Trans. Robot.},
  title        = {HARPS: An online POMDP framework for human-assisted robotic planning and sensing},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic semantic data association for collaborative
human-robot sensing. <em>TROB</em>, <em>39</em>(4), 3008–3023. (<a
href="https://doi.org/10.1109/TRO.2023.3262111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans cannot always be treated as oracles for collaborative sensing. Robots, thus, need to maintain beliefs over unknown world states when receiving semantic data from humans, as well as account for possible discrepancies between the human-provided data and these beliefs. To this end, this article introduces the problem of semantic data association (SDA) in relation to conventional data association problems for sensor fusion. It then develops a novel probabilistic semantic data association (PSDA) algorithm to rigorously address SDA in general settings, unlike previous work on semantic data fusion, which developed heuristic techniques for specific settings. PSDA is further incorporated into a recursive hybrid Bayesian data fusion scheme that uses Gaussian mixture priors for object states and softmax functions for semantic human sensor data likelihoods. Simulations of a multiobject search task show that PSDA enables robust collaborative state estimation under a wide range of conditions where semantic human sensor data can be erroneous or contain significant reference ambiguities.},
  archive      = {J_TROB},
  author       = {Shohei Wakayama and Nisar Ahmed},
  doi          = {10.1109/TRO.2023.3262111},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {3008-3023},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Probabilistic semantic data association for collaborative human-robot sensing},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing robots for reachability and dexterity: Continuum
surgical robots as a pretext application. <em>TROB</em>, <em>39</em>(4),
2989–3007. (<a href="https://doi.org/10.1109/TRO.2023.3275381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article contributes a novel method to assess robot dexterity. Existing Jacobian-based dexterity metrics, such as the manipulability index or the condition number, do not allow for comparisons between robot architectures, are local in nature, and are affected by robot dimensions (robot size). On the contrary, the introduced metric is global and allows for quantitative comparisons of robot architectures as it explicitly incorporates the orientational and positional coverage of a robot&#39;s end-effector. Experiments presented show that the proposed dexterity metric can improve the computational and precision performance of numerical inverse kinematics and showcase its suitability for use in computational dexterous robot design and, in particular, for designing concentric tube robots with high orientational and positional dexterity.},
  archive      = {J_TROB},
  author       = {Konrad Leibrandt and Lyndon da Cruz and Christos Bergeles},
  doi          = {10.1109/TRO.2023.3275381},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2989-3007},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Designing robots for reachability and dexterity: Continuum surgical robots as a pretext application},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Static shape control of soft continuum robots using deep
visual inverse kinematic models. <em>TROB</em>, <em>39</em>(4),
2973–2988. (<a href="https://doi.org/10.1109/TRO.2023.3275375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft continuum robots are highly flexible and adaptable, making them ideal for unstructured environments such as the human body and agriculture. However, their high compliance and maneuverability make them difficult to model, sense, and control. Current control strategies focus on Cartesian space control of the end-effector, but few works have explored full-body control. This study presents a novel image-based deep learning approach for closed-loop kinematic shape control of soft continuum robots. The method combines a local inverse kinematics formulation in the image space with deep convolutional neural networks for accurate shape control that is robust to feedback noise and mechanical changes in the continuum arm. The shape controller is fast and straightforward to implement; it takes only a few hours to generate training data, train the network, and deploy, requiring only a web camera for feedback. This method offers an intuitive and user-friendly way to control the robot&#39;s 3-D shape and configuration through teleoperation using only 2-D hand-drawn images of the desired target state without the need for further user instruction or consideration of the robot&#39;s kinematics.},
  archive      = {J_TROB},
  author       = {Elijah Almanzor and Fan Ye and Jialei Shi and Thomas George Thuruthel and Helge A. Wurdemann and Fumiya Iida},
  doi          = {10.1109/TRO.2023.3275375},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2973-2988},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Static shape control of soft continuum robots using deep visual inverse kinematic models},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structure-to-shape aortic 3-d deformation reconstruction for
endovascular interventions. <em>TROB</em>, <em>39</em>(4), 2954–2972.
(<a href="https://doi.org/10.1109/TRO.2023.3267694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluoroscopy-guided endovascular interventions by using X-ray images are challenging. The catheter needs to be manipulated precisely inside the aorta, while only 2-D views from the X-ray fluoroscopy are currently used to help the surgeons. Because the catheter is operated in a 3-D space, a visualization of the deforming 3-D aorta will be useful as guidance for catheter manipulation. Existing 3-D reconstruction methods fall short in only focusing on the deformation reconstruction of the aortic 3-D centerline, or using additional prior knowledge of 3-D catheter position for estimating the aortic 3-D deformation. In this article, we propose a novel framework that reconstructs the aortic 3-D deformation by fusing a preoperative 3-D model and two intraoperative X-ray images. Different from existing methods, the proposed framework reconstructs aortic deformation using a coarse-to-fine pipeline by first reconstructing the aortic 3-D centerline and then reconstructing the 3-D shape. To obtain the accurate features for the fluoroscopic-based 3-D reconstruction, we extract semantic features from the X-ray images, and compute the distance field to efficiently calculate the 3-D–2-D nonrigid correspondence. Nonlinear least squares optimization is used to solve the deformation of both centerline and shape. The proposed framework is validated using phantom and patient datasets, whose results demonstrate improved efficiency and accuracy compared with the existing methods. This framework provides a valuable clinical tool for endovascular interventions.},
  archive      = {J_TROB},
  author       = {Yanhao Zhang and Raphael Falque and Liang Zhao and Yongbo Chen and Shoudong Huang and Hongdong Li},
  doi          = {10.1109/TRO.2023.3267694},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2954-2972},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Structure-to-shape aortic 3-D deformation reconstruction for endovascular interventions},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization design method of tendon-sheath transmission
path under curvature constraint. <em>TROB</em>, <em>39</em>(4),
2933–2953. (<a href="https://doi.org/10.1109/TRO.2023.3255545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application requirements of the tendon-sheath mechanism in the field of precision machinery are becoming increasingly extensive. However, the contact friction between the tendon and sheath seriously affects the transmission accuracy. In the case of unavoidable friction, optimizing the tendon transmission path to reduce tension loss and elastic deformation has become an important research direction. In this article, the influence law of the tendon transmission path on the tension and displacement transmission is obtained using the two parameters related to the curvature of the transmission path: total bending angle and equivalent tendon length. Then, based on the optimal control theory and minimum principle, the different transmission path solutions of the minimum tension loss, the minimum tendon deformation, and the coupling of tension and displacement are obtained; the numerical optimization method verifies the correctness of the proposed theory. Finally, an optimal design of a tendon-constrained synchronous rotation mechanism for the manipulator is carried out, and the linkage performance is greatly improved by optimizing the transmission path.},
  archive      = {J_TROB},
  author       = {Yanan Li and Weining Lu and Yu Liu and Deshan Meng and Xueqian Wang and Bin Liang},
  doi          = {10.1109/TRO.2023.3255545},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2933-2953},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Optimization design method of tendon-sheath transmission path under curvature constraint},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An object SLAM framework for association, mapping, and
high-level tasks. <em>TROB</em>, <em>39</em>(4), 2912–2932. (<a
href="https://doi.org/10.1109/TRO.2023.3273180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object SLAM is considered increasingly significant for robot high-level perception and decision-making. Existing studies fall short in terms of data association, object representation, and semantic mapping and frequently rely on additional assumptions, limiting their performance. In this article, we present a comprehensive object SLAM framework that focuses on object-based perception and object-oriented robot tasks. First, we propose an ensemble data association approach for associating objects in complicated conditions by incorporating parametric and nonparametric statistic testing. In addition, we suggest an outlier-robust centroid and scale estimation algorithm for modeling objects based on the iForest and line alignment. Then a lightweight and object-oriented map is represented by estimated general object models. Taking into consideration the semantic invariance of objects, we convert the object map to a topological map to provide semantic descriptors to enable multimap matching. Finally, we suggest an object-driven active exploration strategy to achieve autonomous mapping in the grasping scenario. A range of public datasets and real-world results in mapping, augmented reality, scene matching, relocalization, and robotic manipulation have been used to evaluate the proposed object SLAM framework for its efficient performance.},
  archive      = {J_TROB},
  author       = {Yanmin Wu and Yunzhou Zhang and Delong Zhu and Zhiqiang Deng and Wenkai Sun and Xin Chen and Jian Zhang},
  doi          = {10.1109/TRO.2023.3273180},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2912-2932},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An object SLAM framework for association, mapping, and high-level tasks},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward consistent and efficient map-based visual-inertial
localization: Theory framework and filter design. <em>TROB</em>,
<em>39</em>(4), 2892–2911. (<a
href="https://doi.org/10.1109/TRO.2023.3272847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on designing a consistent and efficient filter for visual-inertial localization given a prebuilt map. First, we propose a new Lie group with its algebra based on which a novel invariant extended Kalman filter (invariant EKF) is designed. We theoretically prove that, when we do not consider the uncertainty of map information, the proposed invariant EKF is able to naturally preserve the correct observability properties of the system. To consider the uncertainty of map information, we introduce a Schmidt filter. With the Schmidt filter, the uncertainty of map information can be taken into consideration to avoid overconfident estimation while the computation cost only increases linearly with the size of the map keyframes. In addition, we introduce an easily implemented observability-constrained technique because directly combining the invariant EKF with the Schmidt filter cannot maintain the correct observability properties of the system that considers the uncertainty of map information. Finally, we validate our proposed system&#39;s high consistency, accuracy, and efficiency via extensive simulations and real-world experiments.},
  archive      = {J_TROB},
  author       = {Zhuqing Zhang and Yang Song and Shoudong Huang and Rong Xiong and Yue Wang},
  doi          = {10.1109/TRO.2023.3272847},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2892-2911},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Toward consistent and efficient map-based visual-inertial localization: Theory framework and filter design},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SRVIO: Super robust visual inertial odometry for dynamic
environments and challenging loop-closure conditions. <em>TROB</em>,
<em>39</em>(4), 2878–2891. (<a
href="https://doi.org/10.1109/TRO.2023.3268591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been extensive research on visual localization and odometry for autonomous robots and virtual reality during the past decades. Traditionally, this problem has been solved with the help of expensive sensors, such as light detection and ranging (LiDAR). Nowadays, the focus of the leading research in this field is on robust localization using more economic sensors, such as cameras and inertial measurement units. Consequently, geometric visual localization methods have become more accurate over time. However, these methods still suffer from significant loss and divergence in challenging environments, such as a room full of moving people. Scientists started using deep neural networks (DNNs) to mitigate this problem. The main idea behind using DNNs is to better understand challenging aspects of the data and overcome complex conditions such as the movement of a dynamic object in front of the camera that covers the full view of the camera, extreme lighting conditions, and the high speed of the camera. Prior end-to-end DNN methods did overcome some of these challenges. However, no general and robust framework is available to overcome all challenges together. In this article, we have combined geometric and DNN-based methods to have the generality and speed of geometric SLAM frameworks and overcome most of these challenging conditions with the help of DNNs and deliver the most robust framework so far. To do so, we have designed a framework based on VINS-Mono and shown that it can achieve state-of-the-art results on TUM-Dynamic, TUM-VI, ADVIO, and EuRoC datasets compared to geometric and end-to-end DNN-based simultaneous localization and mappings. Our proposed framework can also achieve outstanding results on extreme simulated cases resembling the aforementioned challenges.},
  archive      = {J_TROB},
  author       = {Ali Samadzadeh and Ahmad Nickabadi},
  doi          = {10.1109/TRO.2023.3268591},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2878-2891},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SRVIO: Super robust visual inertial odometry for dynamic environments and challenging loop-closure conditions},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relative transformation estimation based on fusion of
odometry and UWB ranging data. <em>TROB</em>, <em>39</em>(4), 2861–2877.
(<a href="https://doi.org/10.1109/TRO.2023.3264946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study the problem of estimating the four-degree-of-freedom (3-D position and heading) robot-to-robot relative frame transformation using onboard odometry and interrobot distance measurements. First, we present a theoretical analysis of the problem, namely, the derivation and interpretation of the Cramèr–Rao lower bound, the Fisher information matrix, and its determinant. Second, we propose optimization-based solutions, including a quadratically constrained quadratic programming (QCQP) formulation and its semidefinite programming (SDP) relaxation. Third, based on the theoretical results, we can detect singular configurations as well as measure the uncertainty of each individual parameter. We perform extensive simulations and real-life experiments with aerial robots to show that the proposed QCQP and SDP methods can outperform state-of-the-art approaches, especially in geometrically poor or large measurement noise conditions. In general, the QCQP method provides the best results at the expense of computational time, while the SDP method runs much faster and is sufficiently accurate in most cases.},
  archive      = {J_TROB},
  author       = {Thien Hoang Nguyen and Lihua Xie},
  doi          = {10.1109/TRO.2023.3264946},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2861-2877},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Relative transformation estimation based on fusion of odometry and UWB ranging data},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ranging-based localizability optimization for mobile robotic
networks. <em>TROB</em>, <em>39</em>(4), 2842–2860. (<a
href="https://doi.org/10.1109/TRO.2023.3263772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotic networks relying on noisy range measurements between agents for cooperative localization, the achievable positioning accuracy strongly depends on the network geometry. This motivates the problem of planning robot trajectories in such multirobot systems in a way that maintains high localization accuracy. We present potential-based planning methods, where localizability potentials are introduced to characterize the quality of the network geometry for cooperative position estimation. These potentials are based on Cramér Rao lower bounds (CRLB) and provide a theoretical lower bound on the error covariance achievable by any unbiased position estimator. In the process, we establish connections between CRLBs and the theory of graph rigidity, which has been previously used to plan the motion of robotic networks. We develop decentralized deployment algorithms appropriate for large networks, and we use equality-constrained CRLBs to extend the concept of localizability to scenarios where additional information about the relative positions of the ranging sensors is known. We illustrate the resulting robot deployment methodology through simulated examples and an experiment.},
  archive      = {J_TROB},
  author       = {Justin Cano and Jerome Le Ny},
  doi          = {10.1109/TRO.2023.3263772},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2842-2860},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Ranging-based localizability optimization for mobile robotic networks},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoPR: Toward accurate visual localization with continuous
place-descriptor regression. <em>TROB</em>, <em>39</em>(4), 2825–2841.
(<a href="https://doi.org/10.1109/TRO.2023.3262106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual place recognition (VPR) is an image-based localization method that estimates the camera location of a query image by retrieving the most similar reference image from a map of geo-tagged reference images. In this work, we look into two fundamental bottlenecks for its localization accuracy: 1) reference map sparseness and 2) viewpoint invariance. First, the reference images for VPR are only available at sparse poses in a map, which enforces an upper bound on the maximum achievable localization accuracy through VPR. We, therefore, propose Continuous Place-descriptor Regression (CoPR) to densify the map and improve localization accuracy. We study various interpolation and extrapolation models to regress additional VPR feature descriptors from only the existing references. Second, we compare different feature encoders and show that CoPR presents value for all of them. We evaluate our models on three existing public datasets and report on average around 30\% improvement in VPR-based localization accuracy using CoPR, on top of the 15\% increase by using a viewpoint-variant loss for the feature encoder. The complementary relation between CoPR and relative pose estimation is also discussed.},
  archive      = {J_TROB},
  author       = {Mubariz Zaffar and Liangliang Nan and Julian Francisco Pieter Kooij},
  doi          = {10.1109/TRO.2023.3262106},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2825-2841},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CoPR: Toward accurate visual localization with continuous place-descriptor regression},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Certifiable object pose estimation: Foundations, learning
models, and self-training. <em>TROB</em>, <em>39</em>(4), 2805–2824. (<a
href="https://doi.org/10.1109/TRO.2023.3271568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider a certifiable object pose estimation problem, where—given a partial point cloud of an object—the goal is to not only estimate the object pose, but also provide a certificate of correctness for the resulting estimate. Our first contribution is a general theory of certification for end-to-end perception models. In particular, we introduce the notion of $\zeta$-correctness , which bounds the distance between an estimate and the ground truth. We then show that $\zeta$ -correctness can be assessed by implementing two certificates: 1) a certificate of observable correctness , which asserts if the model output is consistent with the input data and prior information; and 2) a certificate of nondegeneracy , which asserts whether the input data are sufficient to compute a unique estimate. Our second contribution is to apply this theory and design a new learning-based certifiable pose estimator. In particular, we propose C-3PO , a semantic-keypoint-based pose estimation model, augmented with the two certificates, to solve the certifiable pose estimation problem. C-3PO also includes a keypoint corrector , implemented as a differentiable optimization layer, that can correct large detection errors (e.g., due to the sim-to-real gap). Our third contribution is a novel self-supervised training approach that uses our certificate of observable correctness to provide the supervisory signal to C-3PO during training. In it, the model trains only on the observably correct input–output pairs produced in each batch and at each iteration. As training progresses, we see that the observably correct input–output pairs grow, eventually reaching near 100\% in many cases. We conduct extensive experiments to evaluate the performance of the corrector, the certification, and the proposed self-supervised training using the ShapeNet and YCB datasets. The experiments show that 1) standard semantic-keypoint-based methods (which constitute the backbone of C-3PO ) outperform more recent alternatives in challenging problem instances; 2) C-3PO further improves performance and significantly outperforms all the baselines; and 3) C-3PO ’s certificates are able to discern correct pose estimates. 1},
  archive      = {J_TROB},
  author       = {Rajat Talak and Lisa R. Peng and Luca Carlone},
  doi          = {10.1109/TRO.2023.3271568},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2805-2824},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Certifiable object pose estimation: Foundations, learning models, and self-training},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NEPTUNE: Nonentangling trajectory planning for multiple
tethered unmanned vehicles. <em>TROB</em>, <em>39</em>(4), 2786–2804.
(<a href="https://doi.org/10.1109/TRO.2023.3264950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite recent progress in trajectory planning for multiple robots and a single tethered robot, trajectory planning for multiple tethered robots to reach their individual targets without entanglements remains a challenging problem. In this article, a complete approach is presented to address this problem. First, a multirobot tether-aware representation of homotopy is proposed to efficiently evaluate the feasibility and safety of a potential path in terms of 1) the cable length required to reach a target following the path, and 2) the risk of entanglements with the cables of other robots. Then the proposed representation is applied in a decentralized and online planning framework, which includes a graph-based kinodynamic trajectory finder and an optimization-based trajectory refinement, to generate entanglement-free, collision-free, and dynamically feasible trajectories. The efficiency of the proposed homotopy representation is compared against the existing single and multiple tethered robot planning approaches. Simulations with up to eight UAVs show the effectiveness of the approach in entanglement prevention and its real-time capabilities. Flight experiments using three tethered UAVs verify the practicality of the presented approach. The software implementation is publicly available online. 1},
  archive      = {J_TROB},
  author       = {Muqing Cao and Kun Cao and Shenghai Yuan and Thien-Minh Nguyen and Lihua Xie},
  doi          = {10.1109/TRO.2023.3264950},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2786-2804},
  shortjournal = {IEEE Trans. Robot.},
  title        = {NEPTUNE: Nonentangling trajectory planning for multiple tethered unmanned vehicles},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic navigation of microswarms for dynamic obstacle
avoidance. <em>TROB</em>, <em>39</em>(4), 2770–2785. (<a
href="https://doi.org/10.1109/TRO.2023.3263773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control and navigation of microrobotic swarms have drawn extensive attention recently. Avoiding dynamic obstacles using swarms is one of the major challenges that still remain unsolved. In this work, we develop a control strategy to navigate microrobotic swarms to targeted positions while avoiding dynamic obstacles. We first propose a criterion to evaluate the real-time locomotion efficiency during dynamic obstacle avoidance, i.e., the swarm moving direction and the distance between the swarm and the target. Subsequently, a hierarchical radar with three functional boundaries (detection, safety, and prediction circle) is designed for swarms. The optimal moving direction of the swarm with the existence of dynamic obstacles is selected based on the three circles. The effectiveness of the algorithm is validated by simulations and experiments. Using the proposed strategy, the swarm is capable of avoiding multiple moving obstacles and reaching the predefined target. Finally, to show the compatibility of the proposed control method, the swarm is deployed in a micromaze with different dynamic obstacles, and the results also validate the effectiveness of the strategy.},
  archive      = {J_TROB},
  author       = {Yuezhen Liu and Hui Chen and Qian Zou and Xingzhou Du and Yibin Wang and Jiangfan Yu},
  doi          = {10.1109/TRO.2023.3263773},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2770-2785},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Automatic navigation of microswarms for dynamic obstacle avoidance},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperation for scalable supervision of autonomy in mixed
traffic. <em>TROB</em>, <em>39</em>(4), 2751–2769. (<a
href="https://doi.org/10.1109/TRO.2023.3262120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in autonomy offer the potential for dramatic positive outcomes in a number of domains, yet enabling their safe deployment remains an open problem. This work&#39;s motivating question is: In safety-critical settings, can we avoid the need to have one human supervise one machine at all times? The work formalizes this scalable supervision problem by considering remotely located human supervisors and investigating how autonomous agents can cooperate to achieve safety. This article focuses on the safety-critical context of autonomous vehicles (AVs) merging into traffic consisting of a mixture of AVs and human drivers. The analysis establishes high reliability upper bounds on human supervision requirements. It further shows that AV cooperation can improve supervision reliability by orders of magnitude and counterintuitively requires fewer supervisors (per AV) as more AVs are adopted. These analytical results leverage queuing-theoretic analysis, order statistics, and a conservative, reachability-based approach. A key takeaway is the potential value of cooperation in enabling the deployment of autonomy at scale. While this work focuses on AVs, the scalable supervision framework may be of independent interest to a broader array of autonomous control challenges.},
  archive      = {J_TROB},
  author       = {Cameron Hickert and Sirui Li and Cathy Wu},
  doi          = {10.1109/TRO.2023.3262120},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2751-2769},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Cooperation for scalable supervision of autonomy in mixed traffic},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robot active neural sensing and planning in unknown
cluttered environments. <em>TROB</em>, <em>39</em>(4), 2738–2750. (<a
href="https://doi.org/10.1109/TRO.2023.3262114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active sensing and planning in unknown, cluttered environments is an open challenge for robots intending to provide home service, search and rescue, narrow-passage inspection, and medical assistance. Although many active sensing methods exist, they often consider open spaces, assume known settings, or mostly do not generalize to real-world scenarios. In this article, we present the active neural sensing approach that generates the kinematically feasible viewpoint sequences for the robot manipulator with an in-hand camera to gather the minimum number of observations needed to reconstruct the underlying environment. Our framework actively collects the visual RGBD observations, aggregates them into scene representation, and performs object shape inference to avoid unnecessary robot interactions with the environment. We train our approach on synthetic data with domain randomization and demonstrate its successful execution via sim-to-real transfer in reconstructing narrow, covered, real-world cabinet environments cluttered with unknown objects. The natural cabinet scenarios impose significant challenges for robot motion and scene reconstruction due to surrounding obstacles and low ambient lighting conditions. However, despite unfavorable settings, our method exhibits high performance compared to its baselines in terms of various environment reconstruction metrics, including planning speed, the number of viewpoints, and overall scene coverage.},
  archive      = {J_TROB},
  author       = {Hanwen Ren and Ahmed H. Qureshi},
  doi          = {10.1109/TRO.2023.3262114},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2738-2750},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robot active neural sensing and planning in unknown cluttered environments},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Offline time-independent multiagent path planning.
<em>TROB</em>, <em>39</em>(4), 2720–2737. (<a
href="https://doi.org/10.1109/TRO.2023.3258690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines a novel planning problem for multiple agents that cannot share holding resources, named Offline Time-Independent Multiagent Path Planning (OTIMAPP) . Given a graph and a set of start-goal pairs, the problem to be addressed is assigning a path to each agent, such that every agent eventually reaches its destination without blocking others, regardless of when each agent starts and finishes each own action. This motivation stems from timing uncertainties, including the reality gaps between planning and robot execution. In contrast to conventional solution, concepts of multirobot path planning that rely on timings, once OTIMAPP solutions are obtained, they can be executed without any synchronization between robot actions. Moreover, there is a theoretical guarantee that all robots eventually reach their destinations, provided they avoid interrobot collisions. This study attempts to establish OTIMAPP both theoretically and practically. Specifically, we present a formalization of the problem, solution conditions based on a categorization of deadlocks, computational complexities showing that OTIMAPP is computationally intractable, practical relaxation of the solution concept, two algorithms to solve OTIMAPP based on multiagent pathfinding algorithms, empirical results showing large OTIMAPP instances can be solved to some extent, as well as robot demonstrations of asynchronous OTIMAPP execution.},
  archive      = {J_TROB},
  author       = {Keisuke Okumura and François Bonnet and Yasumasa Tamura and Xavier Défago},
  doi          = {10.1109/TRO.2023.3258690},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2720-2737},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Offline time-independent multiagent path planning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DRL-VO: Learning to navigate through crowded dynamic scenes
using velocity obstacles. <em>TROB</em>, <em>39</em>(4), 2700–2719. (<a
href="https://doi.org/10.1109/TRO.2023.3257549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel learning-based control policy with strong generalizability to new environments that enables a mobile robot to navigate autonomously through spaces filled with both static obstacles and dense crowds of pedestrians. The policy uses a unique combination of input data to generate the desired steering angle and forward velocity: a short history of lidar data, kinematic data about nearby pedestrians, and a subgoal point. The policy is trained in a reinforcement learning setting using a reward function that contains a novel term based on velocity obstacles to guide the robot to actively avoid pedestrians and move toward the goal. Through a series of 3-D simulated experiments with up to 55 pedestrians, this control policy is able to achieve a better balance between collision avoidance and speed (i.e., higher success rate and faster average speed) than state-of-the-art model-based and learning-based policies, and it also generalizes better to different crowd sizes and unseen environments. An extensive series of hardware experiments demonstrate the ability of this policy to directly work in different real-world environments with different crowd sizes with zero retraining. Furthermore, a series of simulated and hardware experiments show that the control policy also works in highly constrained static environments on a different robot platform without any additional training. Lastly, several important lessons that can be applied to other robot learning systems are summarized.},
  archive      = {J_TROB},
  author       = {Zhanteng Xie and Philip Dames},
  doi          = {10.1109/TRO.2023.3257549},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2700-2719},
  shortjournal = {IEEE Trans. Robot.},
  title        = {DRL-VO: Learning to navigate through crowded dynamic scenes using velocity obstacles},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic optimization fabrics for motion generation.
<em>TROB</em>, <em>39</em>(4), 2684–2699. (<a
href="https://doi.org/10.1109/TRO.2023.3255587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization fabrics are a geometric approach to real-time local motion generation, where motions are designed by the composition of several differential equations that exhibit a desired motion behavior. We generalize this framework to dynamic scenarios and nonholonomic robots and prove that fundamental properties can be conserved. We show that convergence to desired trajectories and avoidance of moving obstacles can be guaranteed using simple construction rules of the components. In addition, we present the first quantitative comparisons between optimization fabrics and model predictive control and show that optimization fabrics can generate similar trajectories with better scalability, and thus, much higher replanning frequency (up to 500 Hz with a 7 degrees of freedom robotic arm). Finally, we present empirical results on several robots, including a nonholonomic mobile manipulator with 10 degrees of freedom and avoidance of a moving human, supporting the theoretical findings.},
  archive      = {J_TROB},
  author       = {Max Spahn and Martijn Wisse and Javier Alonso-Mora},
  doi          = {10.1109/TRO.2023.3255587},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2684-2699},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Dynamic optimization fabrics for motion generation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CBSS: A new approach for multiagent combinatorial path
finding. <em>TROB</em>, <em>39</em>(4), 2669–2683. (<a
href="https://doi.org/10.1109/TRO.2023.3266993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional multiagent path finding (MAPF) problems aim to compute an ensemble of collision-free paths for multiple agents from their respective starting locations to preallocated destinations. This article considers a generalized version of MAPF called multiagent combinatorial path finding, where agents must collectively visit a large number of intermediate target locations along their paths before arriving at destinations. This problem involves not only planning collision-free paths for multiple agents but also assigning targets and specifying the visiting order for each agent (i.e., target sequencing). To solve the problem, we leverage conflict-based search (CBS) for MAPF and propose a novel approach called conflict-based Steiner search (CBSS). CBSS interleaves 1) the collision resolution strategy in CBS to bypass the curse of dimensionality in MAPF and 2) multiple traveling salesman algorithms to handle the combinatorics in target sequencing, to compute optimal or bounded suboptimal paths for agents while visiting all the targets. We also develop two variants of CBSS that trade off runtime against solution optimality. Our test results verify the advantage of CBSS over the baselines in terms of computing cheaper paths and improving success rates within a runtime limit for up to 20 agents and 50 targets. Finally, we run both Gazebo simulation and physical robot tests to validate that the planned paths are executable.},
  archive      = {J_TROB},
  author       = {Zhongqiang Ren and Sivakumar Rathinam and Howie Choset},
  doi          = {10.1109/TRO.2023.3266993},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2669-2683},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CBSS: A new approach for multiagent combinatorial path finding},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spontaneous-ordering platoon control for multirobot path
navigation using guiding vector fields. <em>TROB</em>, <em>39</em>(4),
2654–2668. (<a href="https://doi.org/10.1109/TRO.2023.3266994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a distributed guiding-vector-field (DGVF) algorithm for a team of robots to form a spontaneous-ordering platoon moving along a predefined desired path in the $n$ -dimensional Euclidean space. Particularly, by adding a path parameter as an additional virtual coordinate to each robot, the DGVF algorithm can eliminate the singular points where the vector fields vanish, and govern robots to approach a closed and even self-intersecting desired path. Then, the interactions among neighboring robots and a virtual target robot through their virtual coordinates enable the realization of the desired platoon; in particular, relative parametric displacements can be achieved with arbitrary ordering sequences. Rigorous analysis is provided to guarantee the global convergence of the spontaneous-ordering platoon on the common desired path from any initial positions. Two-dimensional experiments using three HUSTER-0.3 unmanned surface vessels (USVs) are conducted to validate the practical effectiveness of the proposed DGVF algorithm, and 3-D numerical simulations are presented to demonstrate its effectiveness and robustness when tackling higher dimensional multirobot path-navigation missions and some robots breakdown.},
  archive      = {J_TROB},
  author       = {Bin-Bin Hu and Hai-Tao Zhang and Weijia Yao and Jianing Ding and Ming Cao},
  doi          = {10.1109/TRO.2023.3266994},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2654-2668},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Spontaneous-ordering platoon control for multirobot path navigation using guiding vector fields},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing UAV resupply scheduling for heterogeneous and
persistent aerial service. <em>TROB</em>, <em>39</em>(4), 2639–2653. (<a
href="https://doi.org/10.1109/TRO.2023.3263077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the current advances in unmanned aerial vehicle (UAV) technologies, aerial vehicles are becoming very attractive for many purposes. However, currently the bottleneck in their adoption is no longer due to architectural and protocol challenges and constraints, but rather to the limited energy that they can rely on. In this article, we design two power resupply schemes under the assumption of a fleet of homogeneous UAVs. Such schemes are designed to minimize the size of the fleet to be devoted to a persistent service (i.e., carried out at all times) of a set of aerial locations. First, we consider the case where the aerial locations to be served are equidistant from an energy supply station. In that scenario, we design a simple scheduling scheme, that we name homogeneous rotating resupply ( HoRR ), which we prove to be feasible and exact in the sense that it uses the minimum possible number of UAVs to guarantee the permanent coverage of the aerial service locations. Then, we extend that work for the case of nonevenly distributed aerial locations. In this new scenario, we demonstrate that the problem becomes NP-hard, and design a lightweight scheduling scheme, partitioned heterogeneous rotating resupply ( PHeRR ), which extends the operation of HoRR to the heterogeneous case. Through numerical analysis, we show that PHeRR provides near-exact resupply schedules.},
  archive      = {J_TROB},
  author       = {Edgar Arribas and Vicent Cholvi and Vincenzo Mancuso},
  doi          = {10.1109/TRO.2023.3263077},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2639-2653},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Optimizing UAV resupply scheduling for heterogeneous and persistent aerial service},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multirobot system for 3-d surface reconstruction with
centralized and distributed architectures. <em>TROB</em>,
<em>39</em>(4), 2623–2638. (<a
href="https://doi.org/10.1109/TRO.2023.3258641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose an original solution to the problem of surface reconstruction of large-scale unknown environments, with multiple cooperative robots. As they progress through the 3-D environment, the robots rely on volumetric maps obtained via a TSDF representation to extract discrete incomplete surface elements (ISEs), and a list of candidate viewpoints is generated to cover them. A next-best-view planning approach, which approximately solves a traveling salesman problem (TSP) via greedy allocation, is then used to iteratively assign these viewpoints to the robots. Two multiagent architectures, a centralized one (TSP-Greedy Allocation or TSGA) and a distributed one (dist-TSGA), in which the robots locally compute their maps and share them, are developed and compared. Extensive numerical and real-world experiments with multiple aerial and ground robots in challenging 3-D environments show the flexibility and effectiveness of our surface representation of a volumetric map. The experiments also shed light on the nexus between reconstruction accuracy and surface completeness, and between total distance traveled and execution time.},
  archive      = {J_TROB},
  author       = {Guillaume Hardouin and Julien Moras and Fabio Morbidi and Julien Marzat and El Mustapha Mouaddib},
  doi          = {10.1109/TRO.2023.3258641},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2623-2638},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A multirobot system for 3-D surface reconstruction with centralized and distributed architectures},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asymmetric self-play-enabled intelligent heterogeneous
multirobot catching system using deep multiagent reinforcement learning.
<em>TROB</em>, <em>39</em>(4), 2603–2622. (<a
href="https://doi.org/10.1109/TRO.2023.3257541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to develop a more robust and intelligent heterogeneous system for adversarial catching in security and rescue tasks, in this article, we discuss the specialities of applying asymmetric self-play and curriculum learning techniques to deal with the increasing heterogeneity and number of different robots in modern heterogeneous multirobot systems (HMRS). Our method, based on actor-critic multiagent reinforcement learning, provides a framework that can enable cooperative behaviors among heterogeneous multirobot teams. This leads to the development of an HMRS for complex catching scenarios that involve several robot teams and real-world constraints. We conduct simulated experiments to evaluate different mechanisms&#39; influence on our method&#39;s performance, and real-world experiments to assess our system&#39;s performance in complex real-world catching problems. In addition, a bridging study is conducted to compare our method with a state-of-the-art method called S2M2 in heterogeneous catching problems, and our method performs better in adversarial settings. As a result, we show that the proposed framework, through fusing asymmetric self-play and curriculum learning during training, is able to successfully complete the HMRS catching task under realistic constraints in both simulation and the real world, thus providing a direction for future large-scale intelligent security &amp; rescue HMRS.},
  archive      = {J_TROB},
  author       = {Yuan Gao and Junfeng Chen and Xi Chen and Chongyang Wang and Junjie Hu and Fuqin Deng and Tin Lun Lam},
  doi          = {10.1109/TRO.2023.3257541},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2603-2622},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Asymmetric self-play-enabled intelligent heterogeneous multirobot catching system using deep multiagent reinforcement learning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy-aware, collision-free information gathering for
heterogeneous robot teams. <em>TROB</em>, <em>39</em>(4), 2585–2602. (<a
href="https://doi.org/10.1109/TRO.2023.3257512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the problem of safely coordinating a team of sensor-equipped robots to reduce uncertainty about a dynamical process, where the objective tradeoffs information gain and energy cost. Optimizing this tradeoff is desirable, but leads to a nonmonotone objective function in the set of robot trajectories. Therefore, common multirobot planners based on coordinate descent lose their performance guarantees. Furthermore, methods that handle nonmonotonicity lose their performance guarantees when subject to interrobot collision avoidance constraints. As it is desirable to retain both the performance guarantee and safety guarantee , this work proposes a hierarchical approach with a distributed planner that uses local search with a worst-case performance guarantees and a decentralized controller based on control barrier functions that ensures safety and encourages timely arrival at sensing locations. Via extensive simulations, hardware-in-the-loop tests, and hardware experiments, we demonstrate that the proposed approach achieves a better tradeoff between sensing and energy cost than coordinate-descent-based algorithms.},
  archive      = {J_TROB},
  author       = {Xiaoyi Cai and Brent Schlotfeldt and Kasra Khosoussi and Nikolay Atanasov and George J. Pappas and Jonathan P. How},
  doi          = {10.1109/TRO.2023.3257512},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2585-2602},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Energy-aware, collision-free information gathering for heterogeneous robot teams},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-entropy regularized policy gradient for multirobot
nonadversarial moving target search. <em>TROB</em>, <em>39</em>(4),
2569–2584. (<a href="https://doi.org/10.1109/TRO.2023.3263459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the multirobot efficient search (MuRES) for a nonadversarial moving target problem from the multiagent reinforcement learning (MARL) perspective. MARL is deemed as a promising research field for cooperative multiagent applications. However, one of the main bottlenecks of applying MARL to the MuRES problem is the nonstationarity introduced by multiple learning agents. With learning agents simultaneously updating their policies, the environment cannot be modeled as a stationary Markov decision process, which results in the inapplicability of fundamental reinforcement learning techniques such as deep $Q$ -network and policy gradient (PG). In view of that, we adopt the centralized training and decentralized execution scheme and thereby propose a cross-entropy regularized policy gradient (CE-PG) method to train the learning agents/robots. We let the robots commit to a predetermined policy during execution, collect the trajectories, and then perform centralized training for the corresponding policy improvement. In this way, the nonstationarity problem is overcome, in that the robots do not update their policies during execution. During the centralized training stage, we improve the canonical PG method to consider the interactions among robots by adding a cross-entropy regularization term, which essentially functions to “disperse” the robots in the environment. Extensive simulation results and comparisons with state of the art show CE-PG&#39;s superior performance, and we also validate the algorithm with a real multirobot system in an indoor moving target search scenario.},
  archive      = {J_TROB},
  author       = {Hongliang Guo and Zhaokai Liu and Rui Shi and Wei-Yun Yau and Daniela Rus},
  doi          = {10.1109/TRO.2023.3263459},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2569-2584},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Cross-entropy regularized policy gradient for multirobot nonadversarial moving target search},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image-integrated magnetic actuation systems for localization
and remote actuation of medical miniature robots: A survey.
<em>TROB</em>, <em>39</em>(4), 2549–2568. (<a
href="https://doi.org/10.1109/TRO.2023.3271582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic miniature robots are promising tools for minimally invasive and noninvasive therapy. Constructing systems with actuation–perception loops is an essential step to progress from fundamental research to clinical applications, and from manual to automated manipulation. Such systems include imaging devices for tracking miniature robots inside a living body, and magnetic actuators for manipulating the robots. In this survey article, the designs, features, and control of various magnetic actuation systems with imaging modalities are summarized. The strategies of actuation–perception cooperation are discussed from both hardware and software aspects, aiming to provide a paradigm for building automated image-guided systems in clinical scenarios. Furthermore, the solutions when both the systems and surgeons simultaneously participate in the operation are introduced. We also discuss the advantages and drawbacks of reported techniques, major challenges, and potential prospects in this field.},
  archive      = {J_TROB},
  author       = {Xingzhou Du and Jiangfan Yu},
  doi          = {10.1109/TRO.2023.3271582},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2549-2568},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Image-integrated magnetic actuation systems for localization and remote actuation of medical miniature robots: A survey},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autonomous navigation for robot-assisted intraluminal and
endovascular procedures: A systematic review. <em>TROB</em>,
<em>39</em>(4), 2529–2548. (<a
href="https://doi.org/10.1109/TRO.2023.3269384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased demand for less invasive procedures has accelerated the adoption of Intraluminal Procedures (IP) and Endovascular Interventions (EI) performed through body lumens and vessels. As navigation through lumens and vessels is quite complex, interest grows to establish autonomous navigation techniques for IP and EI for reaching the target area. Current research efforts are directed toward increasing the Level of Autonomy (LoA) during the navigation phase. One key ingredient for autonomous navigation is Motion Planning (MP) techniques. This paper provides an overview of MP techniques categorizing them based on LoA. Our analysis investigates advances for the different clinical scenarios. Through a systematic literature analysis using the PRISMA method, the study summarizes relevant works and investigates the clinical aim, LoA, adopted MP techniques, and validation types. We identify the limitations of the corresponding MP methods and provide directions to improve the robustness of the algorithms in dynamic intraluminal environments. MP for IP and EI can be classified into four subgroups: node, sampling, optimization, and learning-based techniques, with a notable rise in learning-based approaches in recent years. One of the review&#39;s contributions is the identification of the limiting factors in IP and EI robotic systems hindering higher levels of autonomous navigation. In the future, navigation is bound to become more autonomous, placing the clinician in a supervisory position to improve control precision and reduce workload.},
  archive      = {J_TROB},
  author       = {Ameya Pore and Zhen Li and Diego Dall&#39;Alba and Albert Hernansanz and Elena De Momi and Arianna Menciassi and Alicia Casals Gelpí and Jenny Dankelman and Paolo Fiorini and Emmanuel Vander Poorten},
  doi          = {10.1109/TRO.2023.3269384},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2529-2548},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Autonomous navigation for robot-assisted intraluminal and endovascular procedures: A systematic review},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and fabrication of concentric tube robots: A survey.
<em>TROB</em>, <em>39</em>(4), 2510–2528. (<a
href="https://doi.org/10.1109/TRO.2023.3255512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concentric tube robots (CTRs) have drawn significant research attention over the years, particularly due to their applications in minimally invasive surgery (MIS). Indeed, their small size, flexibility, and high dexterity enable several potential benefits for MIS. The research has led to an increasing number of discoveries and scientific breakthroughs in CTR design, fabrication, control, and applications. Numerous prototypes have emerged from different research groups, each with its own design and specifications. This survey paper provides an overview of the state of the art of the mechatronics aspects of CTRs, including approaches for the design and fabrication of the tubes, actuation unit, and end effector. In addition to the various hardware and associated fabrication methods, we propose to the research community, a unifying way of classifying CTRs based on their actuation unit architecture, as well as a set of specification details for the evaluation of future CTR prototypes. Finally, we also aim to highlight the current advancements, challenges, and perspectives of CTR design and fabrication.},
  archive      = {J_TROB},
  author       = {Chibundo J. Nwafor and Cédric Girerd and Guillaume J. Laurent and Tania K. Morimoto and Kanty Rabenorosoa},
  doi          = {10.1109/TRO.2023.3255512},
  journal      = {IEEE Transactions on Robotics},
  number       = {4},
  pages        = {2510-2528},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design and fabrication of concentric tube robots: A survey},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The design, education and evolution of a robotic baby.
<em>TROB</em>, <em>39</em>(3), 2488–2507. (<a
href="https://doi.org/10.1109/TRO.2023.3240619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by Alan Turing&#39;s idea of a child machine, in this article, we introduce the formal definition of a robotic baby, an integrated system with minimal world knowledge at birth, capable of learning incrementally and interactively, and adapting to the world. Within the definition, fundamental capabilities and system characteristics of the robotic baby are identified and presented as the system-level requirements. As a minimal viable prototype, the Baby architecture is proposed with a systems engineering design approach to satisfy the system-level requirements, which has been verified and validated with simulations and experiments on a robotic system. We demonstrate the capabilities of the robotic baby in natural language acquisition and semantic parsing in English and Chinese, as well as in natural language grounding, natural language reinforcement learning, natural language programming, and system introspection for explainability. The education and evolution of the robotic baby are illustrated with real-world robotic demonstrations. Inspired by the genetic inheritance in human beings, knowledge inheritance in robotic babies and its benefits regarding evolution are discussed.},
  archive      = {J_TROB},
  author       = {Hanqing Zhu and Sean Wilson and Eric Feron},
  doi          = {10.1109/TRO.2023.3240619},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2488-2507},
  shortjournal = {IEEE Trans. Robot.},
  title        = {The design, education and evolution of a robotic baby},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A general framework for hierarchical redundancy resolution
under arbitrary constraints. <em>TROB</em>, <em>39</em>(3), 2468–2487.
(<a href="https://doi.org/10.1109/TRO.2022.3232266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing interest in autonomous robots with a high number of degrees of freedom for industrial applications and service robotics demands control algorithms to handle multiple tasks as well as hard constraints efficiently. This article presents a general framework in which both kinematic (velocity- or acceleration-based) and dynamic (torque-based) control of redundant robots are handled in a unified fashion. The framework allows for the specification of redundancy resolution problems featuring a hierarchy of arbitrary (equality and inequality) constraints, arbitrary weighting of the control effort in the cost function and an additional input used to optimize possibly remaining redundancy. To solve such problems, a generalization of the saturation in the null space algorithm is introduced, which extends the original method according to the features required by our general control framework. Variants of the developed algorithm are presented, which ensure both efficient computation and optimality of the solution. Experiments on a KUKA LBRiiwa robotic arm, as well as simulations with a highly redundant mobile manipulator are reported.},
  archive      = {J_TROB},
  author       = {Mario Daniele Fiore and Gaetano Meli and Anton Ziese and Bruno Siciliano and Ciro Natale},
  doi          = {10.1109/TRO.2022.3232266},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2468-2487},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A general framework for hierarchical redundancy resolution under arbitrary constraints},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-based visual-strain fusion for eye-in-hand
continuum robot pose estimation and control. <em>TROB</em>,
<em>39</em>(3), 2448–2467. (<a
href="https://doi.org/10.1109/TRO.2023.3240556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing has significantly extended the practical value of the eye-in-hand camera, enabling and promoting its applications for quantitative measurement. However, fully vision-based pose estimation methods sometimes encounter difficulties in handling cases with deficient features. In this article, we fuse visual information with the sparse strain data collected from a single-core fiber inscribed with fiber Bragg gratings (FBGs) to facilitate continuum robot pose estimation. An improved extreme learning machine algorithm with selective training data updates is implemented to establish and refine the FBG-empowered (F-emp) pose estimator online . The integration of F-emp pose estimation can improve sensing robustness by reducing the number of times that visual tracking is lost given moving visual obstacles and varying lighting. In particular, this integration solves pose estimation failures under full occlusion of the tracked features or complete darkness. Utilizing the fused pose feedback, a hybrid controller incorporating kinematics and data-driven algorithms is proposed to accomplish fast convergence with high accuracy. The online-learning error compensator can improve the target tracking performance with a 52.3\%–90.1\% error reduction compared with constant-curvature model-based control, without requiring fine model-parameter tuning and prior data acquisition.},
  archive      = {J_TROB},
  author       = {Xiaomei Wang and Jing Dai and Hon-Sing Tong and Kui Wang and Ge Fang and Xiaochen Xie and Yun-Hui Liu and Kwok Wai Samuel Au and Ka-Wai Kwok},
  doi          = {10.1109/TRO.2023.3240556},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2448-2467},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning-based visual-strain fusion for eye-in-hand continuum robot pose estimation and control},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Close the optical sensing domain gap by physics-grounded
active stereo sensor simulation. <em>TROB</em>, <em>39</em>(3),
2429–2447. (<a href="https://doi.org/10.1109/TRO.2023.3235591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we focus on the simulation of active stereovision depth sensors, which are popular in both academic and industry communities. Inspired by the underlying mechanism of the sensors, we designed a fully physics-grounded simulation pipeline that includes material acquisition, ray-tracing-based infrared (IR) image rendering, IR noise simulation, and depth estimation. The pipeline is able to generate depth maps with material-dependent error patterns similar to a real depth sensor in real time. We conduct real experiments to show that perception algorithms and reinforcement learning policies trained in our simulation platform could transfer well to the real-world test cases without any fine-tuning. Furthermore, due to the high degree of realism of this simulation, our depth sensor simulator can be used as a convenient testbed to evaluate the algorithm performance in the real world, which will largely reduce the human effort in developing robotic algorithms. The entire pipeline has been integrated into the SAPIEN simulator and is open-sourced to promote the research of vision and robotics communities.},
  archive      = {J_TROB},
  author       = {Xiaoshuai Zhang and Rui Chen and Ang Li and Fanbo Xiang and Yuzhe Qin and Jiayuan Gu and Zhan Ling and Minghua Liu and Peiyu Zeng and Songfang Han and Zhiao Huang and Tongzhou Mu and Jing Xu and Hao Su},
  doi          = {10.1109/TRO.2023.3235591},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2429-2447},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Close the optical sensing domain gap by physics-grounded active stereo sensor simulation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An on-wall-rotating strategy for effective upstream motion
of untethered millirobot: Principle, design, and demonstration.
<em>TROB</em>, <em>39</em>(3), 2419–2428. (<a
href="https://doi.org/10.1109/TRO.2023.3249569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Untethered miniature robots that can access narrow and harsh environments in the body show great potential for future biomedical applications. Despite the many types of millirobot that have been developed, swimming against the fast blood flow remains a big challenge due to lack of the ability to stay still and the large fluidic resistance from blood. This article proposes an on-wall-rotating strategy and a streamlined millirobot to achieve effective upstream motion in the lumen. First, the principle of on-wall-rotating strategy and the dynamic motion model of the millirobot is established. Then, a critical safety angle $\theta _{s}$ is theoretically and experimentally analyzed for the safe and stable control of the robot. After that, a series of experiments are conducted to verify the proposed driving strategy. The results suggest that the robot is able to move at a speed of 5 mm/s against flow velocity of 138 mm/s, which is comparable to the blood flow of 2700 mm $^{3}$ /s and several times faster than other reported driving strategies. This work offers a new strategy for the untethered magnetic robot construction and control for blood vessels, which would promote the application of millirobot for biomedical engineering.},
  archive      = {J_TROB},
  author       = {Liu Yang and Tieshan Zhang and Han Huang and Hao Ren and Wanfeng Shang and Yajing Shen},
  doi          = {10.1109/TRO.2023.3249569},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2419-2428},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An on-wall-rotating strategy for effective upstream motion of untethered millirobot: Principle, design, and demonstration},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel contact modeling for high aspect ratio soft robots.
<em>TROB</em>, <em>39</em>(3), 2400–2418. (<a
href="https://doi.org/10.1109/TRO.2023.3239134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contact modeling between a soft robot and its environment is challenging due to soft robots&#39; compliance and the difficulty of embedding sensors. Current modeling methods are computationally expensive and require highly accurate material characterization to produce useful results. In this article, we present a contact model that utilizes linear complementarity and Hencky bar-chain methods, and requires only static images to efficiently predict the interaction between actuator and environment. These methods have yet to be introduced to the soft robotics community for modeling robots that deform due to eigenstrains or strains not caused by external forces. We validated our model using a custom experimental setup and computer vision algorithm on 3-mm OD, 90-mm long, tube-like actuators. Our results indicated a 1.06\% difference in shape between model and experiment, with computation times in 10 s of ms—three to four orders of magnitude faster than nonlinear gradient descent. Additionally, the error in interaction forces between the model and experiment decreased as pressure increased, with an average error magnitude of 45\% and 21\% for pressures at the low and high ends of the tested range, respectively.},
  archive      = {J_TROB},
  author       = {Gillian J. McDonald and Benjamin Hamlen and Emmanuel Detournay and Timothy M. Kowalewski},
  doi          = {10.1109/TRO.2023.3239134},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2400-2418},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Novel contact modeling for high aspect ratio soft robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid robotic grasping with a soft multimodal gripper and a
deep multistage learning scheme. <em>TROB</em>, <em>39</em>(3),
2379–2399. (<a href="https://doi.org/10.1109/TRO.2023.3238910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping has long been considered an important and practical task in robotic manipulation. Yet achieving robust and efficient grasps of diverse objects is challenging, since it involves gripper design, perception, control, and learning, etc. Recent learning-based approaches have shown excellent performance in grasping a variety of novel objects. However, these methods either are typically limited to one single grasping mode or else more end effectors are needed to grasp various objects. In addition, gripper design and learning methods are commonly developed separately, which may not adequately explore the ability of a multimodal gripper. In this article, we present a deep reinforcement learning (DRL) framework to achieve multistage hybrid robotic grasping with a new soft multimodal gripper. A soft gripper with three grasping modes (i.e., enveloping , sucking , and enveloping_then_sucking ) can both deal with objects of different shapes and grasp more than one object simultaneously. We propose a novel hybrid grasping method integrated with the multimodal gripper to optimize the number of grasping actions. We evaluate the DRL framework under different scenarios (i.e., with different ratios of objects of two grasp types). The proposed algorithm is shown to reduce the number of grasping actions (i.e., enlarge the grasping efficiency, with maximum values of 161.0\% in simulations, and 153.5\% in real-world experiments) compared to single grasping modes.},
  archive      = {J_TROB},
  author       = {Fukang Liu and Fuchun Sun and Bin Fang and Xiang Li and Songyu Sun and Huaping Liu},
  doi          = {10.1109/TRO.2023.3238910},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2379-2399},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Hybrid robotic grasping with a soft multimodal gripper and a deep multistage learning scheme},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cosserat rod modeling of continuum robots from newtonian and
lagrangian perspectives. <em>TROB</em>, <em>39</em>(3), 2360–2378. (<a
href="https://doi.org/10.1109/TRO.2023.3238171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cosserat rod theory proved efficient modeling performances in robotics, especially in the context of continuum robots, in the past decade. The implementation of such theory is far from being unique and straightforward. We consider the illustrative example of multisegment, general routing tendon actuated continuum robots in their nominal static operating regime. This article details two main approaches based on Cosserat rod modeling, namely, the Newtonian and Lagrangian approaches. We provide a walk-through guide regarding theoretical derivations and numerical implementation of both approaches, together with a proof of equivalence. This comparative study is supplemented with novel contributions and extensions of each approach and in-depth discussion of their performances and applicability, as well as highlighting their special features.},
  archive      = {J_TROB},
  author       = {Matthias Tummers and Vincent Lebastard and Frédéric Boyer and Jocelyne Troccaz and Benoît Rosa and M. Taha Chikhaoui},
  doi          = {10.1109/TRO.2023.3238171},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2360-2378},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Cosserat rod modeling of continuum robots from newtonian and lagrangian perspectives},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Piecewise linear strain cosserat model for soft slender
manipulator. <em>TROB</em>, <em>39</em>(3), 2342–2359. (<a
href="https://doi.org/10.1109/TRO.2023.3236942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently soft robotics has rapidly become a novel and promising area of research with many designs and applications due to their flexible and compliant structure. However, it is more difficult to derive the nonlinear dynamic model of such soft robots. The differential kinematics and dynamics of the soft manipulator can be formulated as a set of highly nonlinear partial differential equations (PDEs) via the classic Cosserat rod theory. In this work, we propose a discrete modeling technique named piecewise linear strain (PLS) to solve the PDEs of Cosserat-based models, based on which the associated analytic models are deduced. To validate the accuracy of the proposed Cosserat model, the static model of the conical cantilever rod under gravity as a simple example is simulated by using different discretization methods. Results indicate that PLS Cosserat model is comparable to the mechanical deformation behavior of a real-world soft manipulator. Finally, a parameters identification scheme for this model is established, and the simulation as well as experimental validation demonstrate that using this method can identify the model physical parameters with high accuracy.},
  archive      = {J_TROB},
  author       = {Haihong Li and Lingxiao Xun and Gang Zheng},
  doi          = {10.1109/TRO.2023.3236942},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2342-2359},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Piecewise linear strain cosserat model for soft slender manipulator},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active-cooling-in-the-loop controller design and
implementation for an SMA-driven soft robotic tentacle. <em>TROB</em>,
<em>39</em>(3), 2325–2341. (<a
href="https://doi.org/10.1109/TRO.2023.3234801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a classical type of smart materials, shape memory alloys (SMAs) are of high energy density, light weight, and low actuating voltage, and therefore are of great potential to be used as actuators for robots. Major challenges in controlling an SMA-driven soft robot are the limited bandwidth and in cases with external loads. Active cooling has been demonstrated to dramatically increase its bandwidth, but external load may cause severe inaccuracy in the system modeling. Controllers that do not rely on accurate modeling of the SMA-driven soft robot is essential. In this article, we designed an elastomeric soft robotic tentacle actuated by three pieces of SMA springs with both active heating (Joule heating) and active cooling (compressed air). We proposed a multi-input-multi-output controller that directly uses the heating and cooling states of the three SMAs to control the tentacle&#39;s bending posture in three-dimensional (3-D) space. The successful implementation of the controller is attributed to a novel dual-channel control algorithm that integrates the bending motion control and swing motion control, and a state-machine controller for coordinating the three SMAs&#39; actuations to achieve robust swing motion control. The system with such hardware and control algorithm was capable of performing bending motions with maximum actuating speed $ &amp;gt; $ 90 $^\circ /$ s, deactuating speed $ &amp;gt; $ 25 $^\circ /$ s, closed-loop motions with rapidity (6–41 $^\circ /$ s for heating, 4–19 $^\circ /$ s for cooling), accuracy (steady-state error $ &amp;lt; $ 0.1 $^\circ$ for no load, 0.13 $\%$ of the full range; steady-state error $ &amp;lt; $ 1.2 $^\circ$ with load of 1 bodyweight, 1.6 $\%$ of the full range), and load-bearing capability (dynamic load: 1 bodyweight, static load: 8.8 bodyweights). Besides, the tentacle achieved efficient motion tracking by coordinating the bending and swing motion through the controller, for both predefined trajectories and random trajectories. We demonstrated a remotely controlled 360 $^\circ$ image scanning of a room using our proposed robotic tentacle equipped with a camera at its top end to intuitively show its performances. We believe this work will advance the design and control of SMA-driven soft continuum robots for potential uses in surgery and explorations of unknown areas.},
  archive      = {J_TROB},
  author       = {Xin An and Yafeng Cui and Hao Sun and Qi Shao and Huichan Zhao},
  doi          = {10.1109/TRO.2023.3234801},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2325-2341},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Active-cooling-in-the-loop controller design and implementation for an SMA-driven soft robotic tentacle},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lie group formulation and sensitivity analysis for shape
sensing of variable curvature continuum robots with general string
encoder routing. <em>TROB</em>, <em>39</em>(3), 2308–2324. (<a
href="https://doi.org/10.1109/TRO.2022.3232273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers a combination of actuation tendons and measurement strings to achieve accurate shape sensing and direct kinematics of continuum robots. Assuming general string routing, a methodical Lie group formulation for the shape sensing of these robots is presented. The shape kinematics is expressed using arc-length-dependent curvature distributions parameterized by modal functions, and the Magnus expansion for Lie group integration is used to express the shape as a product of exponentials. The tendon and string length kinematic constraints are solved for the modal coefficients and the configuration space and body Jacobian are derived. The noise amplification index for the shape reconstruction problem is defined and used for optimizing the string/tendon routing paths, and a planar simulation study shows the minimal number of strings/tendons needed for accurate shape reconstruction. A torsionally stiff continuum segment is used for experimental evaluation, demonstrating mean (maximal) end-effector absolute position error of less than 2\% (5\%) of total length. Finally, a simulation study of a torsionally compliant segment demonstrates the approach for general deflections and string routings. We believe that the methods of this article can benefit the design process, sensing, and control of continuum and soft robots.},
  archive      = {J_TROB},
  author       = {Andrew L. Orekhov and Elan Z. Ahronovich and Nabil Simaan},
  doi          = {10.1109/TRO.2022.3232273},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2308-2324},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Lie group formulation and sensitivity analysis for shape sensing of variable curvature continuum robots with general string encoder routing},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BarrierNet: Differentiable control barrier functions for
learning of safe robot control. <em>TROB</em>, <em>39</em>(3),
2289–2307. (<a href="https://doi.org/10.1109/TRO.2023.3249564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many safety-critical applications of neural networks, such as robotic control, require safety guarantees. This article introduces a method for ensuring the safety of learned models for control using differentiable control barrier functions (dCBFs). dCBFs are end-to-end trainable and guarantee safety. They improve over classical control barrier functions (CBFs), which are usually overly conservative. Our dCBF solution relaxes the CBF definitions by: 1) using environmental dependencies; 2) embedding them into differentiable quadratic programs. These novel safety layers are called a BarrierNet. They can be used in conjunction with any neural network-based controller. They are trained by gradient descent. With BarrierNet, the safety constraints of a neural controller become adaptable to changing environments. We evaluate BarrierNet on the following several problems: 1) robot traffic merging; 2) robot navigation in 2-D and 3-D spaces; 3) end-to-end vision-based autonomous driving in a sim-to-real environment and in physical experiments; 4) demonstrate their effectiveness compared to state-of-the-art approaches.},
  archive      = {J_TROB},
  author       = {Wei Xiao and Tsun-Hsuan Wang and Ramin Hasani and Makram Chahine and Alexander Amini and Xiao Li and Daniela Rus},
  doi          = {10.1109/TRO.2023.3249564},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2289-2307},
  shortjournal = {IEEE Trans. Robot.},
  title        = {BarrierNet: Differentiable control barrier functions for learning of safe robot control},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Noise-tolerant identification and tuning approach using deep
neural networks for visual servoing applications. <em>TROB</em>,
<em>39</em>(3), 2276–2288. (<a
href="https://doi.org/10.1109/TRO.2023.3235586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based control of unmanned aerial vehicles (UAVs) has been adopted in a wide range of applications due to the availability of low-cost onboard sensors and computers. Tuning such systems to work properly requires extensive domain-specific experience, which limits the growth of emerging applications. Moreover, obtaining performance limits for UAVs performing visual servoing is difficult due to the complexity of the models used. In this article, we propose a novel noise-tolerant approach for real-time identification and tuning of visual servoing systems. This is based on the deep neural networks (DNNs) classification of the system response generated by the modified relay feedback test (MRFT). The proposed method, called DNN with noise-protected MRFT (DNN-NP-MRFT), can be used with a multitude of vision sensors and estimation algorithms despite high levels of sensor noise. The response of DNN-NP-MRFT to noise perturbations is investigated and its effect on identification and tuning performance is analyzed. The proposed DNN-NP-MRFT is able to detect performance changes induced by the use of high latency vision sensors or by integrating an inertial measurement unit sensor into the UAV states estimation pipeline. Experimental identification closely matches simulation results, which can be used to explain the system behavior and predict the closed-loop performance limits for a given hardware and software setup. We also demonstrate the ability of DNN-NP-MRFT-tuned UAVs to reject external disturbances like wind or human push and pull. Finally, we discuss the advantages of the proposed DNN-NP-MRFT visual servoing design approach compared with other approaches in the literature.},
  archive      = {J_TROB},
  author       = {Oussama Abdul Hay and Mohamad Chehadeh and Abdulla Ayyad and Mohamad Wahbah and Muhammad Ahmed Humais and Igor Boiko and Lakmal Seneviratne and Yahya Zweiri},
  doi          = {10.1109/TRO.2023.3235586},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2276-2288},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Noise-tolerant identification and tuning approach using deep neural networks for visual servoing applications},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning stable models for prediction and control.
<em>TROB</em>, <em>39</em>(3), 2255–2275. (<a
href="https://doi.org/10.1109/TRO.2022.3228130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we demonstrate the benefits of imposing stability on data-driven Koopman operators. The data-driven identification of stable Koopman operators (DISKO) is implemented using an algorithm [1] that computes the nearest stable matrix solution to a least-squares reconstruction error. As a first result, we derive a formula that describes the prediction error of Koopman representations for an arbitrary number of time steps, and which shows that stability constraints can improve the predictive accuracy over long horizons. As a second result, we determine formal conditions on basis functions of Koopman operators needed to satisfy the stability properties of an underlying nonlinear system. As a third result, we derive formal conditions for constructing Lyapunov functions for nonlinear systems out of stable data-driven Koopman operators, which we use to verify stabilizing control from data. Finally, we demonstrate the benefits of DISKO in prediction and control with simulations using a pendulum and a quadrotor and experiments with a pusher-slider system. The paper is complemented with a video: https://sites.google.com/view/learning-stable-koopman .},
  archive      = {J_TROB},
  author       = {Giorgos Mamakoukas and Ian Abraham and Todd D. Murphey},
  doi          = {10.1109/TRO.2022.3228130},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2255-2275},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning stable models for prediction and control},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Direct kinematic singularities and stability analysis of
sagging cable-driven parallel robots. <em>TROB</em>, <em>39</em>(3),
2240–2254. (<a href="https://doi.org/10.1109/TRO.2023.3251939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sagging cable-driven parallel robots (CDPRs) are often modeled by using the Irvine&#39;s model. We will show that their configurations may be unstable, and moreover, that assessing the stability of the robot with the Irvine&#39;s model cannot be done by checking the spectrum of a stiffness matrix associated with the platform motions. In this article, we show that the static configurations of the sagging CDPRs are local extrema of the functional describing the robot potential energy. For assessing the stability, it is then necessary to check two conditions: The Legendre–Clebsch and the Jacobi conditions, both well known in optimal control theory. We will also 1) prove that there is a link between some singularities of the CDPRs and the limits of stability and 2) show that singularities of the platform wrench system are not singularities of the geometric model of the sagging CDPRs, contrary to what happens in rigid-link parallel robotics. The stability prediction results are validated in simulation by cross-validating them by using a lumped model, for which the stability can be assessed by analyzing the spectrum of a reduced Hessian matrix of the potential energy.},
  archive      = {J_TROB},
  author       = {Sébastien Briot and Jean-Pierre Merlet},
  doi          = {10.1109/TRO.2023.3251939},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2240-2254},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Direct kinematic singularities and stability analysis of sagging cable-driven parallel robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combined admittance control with type II singularity evasion
for parallel robots using dynamic movement primitives. <em>TROB</em>,
<em>39</em>(3), 2224–2239. (<a
href="https://doi.org/10.1109/TRO.2023.3238136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses a new way of generating compliant trajectories for control using movement primitives to allow physical human–robot interaction where parallel robots (PRs) are involved. PRs are suitable for tasks requiring precision and performance because of their robust behavior. However, two fundamental issues must be resolved to ensure safe operation: first, the force exerted on the human must be controlled and limited, and second, Type II singularities should be avoided to keep complete control of the robot. We offer a unified solution under the dynamic movement primitives (DMP) framework to tackle both tasks simultaneously. DMPs are used to get an abstract representation for movement generation and are involved in broad areas, such as imitation learning and movement recognition. For force control, we design an admittance controller intrinsically defined within the DMP structure, and subsequently, the Type II singularity evasion layer is added to the system. Both the admittance controller and the evader exploit the dynamic behavior of the DMP and its properties related to invariance and temporal coupling, and the whole system is deployed in a real PR meant for knee rehabilitation. The results show the capability of the system to perform safe rehabilitation exercises.},
  archive      = {J_TROB},
  author       = {Rafael J. Escarabajal and José L. Pulloquinga and Ángel Valera and Vicente Mata and Marina Vallés and Fernando J. Castillo-García},
  doi          = {10.1109/TRO.2023.3238136},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2224-2239},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Combined admittance control with type II singularity evasion for parallel robots using dynamic movement primitives},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A wearable force-sensitive and body-aware exoprosthesis for
a transhumeral prosthesis socket. <em>TROB</em>, <em>39</em>(3),
2203–2223. (<a href="https://doi.org/10.1109/TRO.2023.3251947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Upper limb prostheses are commonly mounted to the human residual limb by a passive socket. By this design, the sensitive residual limb is exposed to high reaction wrenches, which can be a source of medical complications. In this article, we introduce an active force-sensitive robotic socket, which carries the prosthesis, offloads the residual limb, and allows guidance via small interaction forces at the same time. We investigate the feasibility of this concept by a force-sensitive and wearable shoulder exoskeleton, called exoprosthesis when being combined with a prosthesis. We provide a first mechatronics prototype, two floating base controllers, and an analysis of the loads acting on the user body. Simulations and experiments confirm the concept and reveal that the wrench at residual limb can be fully compensated for the static case and by $\approx \text{50}\%$ for the investigated motions. Human-in-the-loop tests are successfully performed by three able-bodied users showing the later real-world use case in a complex grasping situation. Overall, we believe that a force-sensitive robotic socket has the potential to advance prosthetics to a new level as it provides an intuitive and seamless user control interface.},
  archive      = {J_TROB},
  author       = {Alexander Toedtheide and Edmundo Pozo Fortunić and Johannes Kühn and Elisabeth Rose Jensen and Sami Haddadin},
  doi          = {10.1109/TRO.2023.3251947},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2203-2223},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A wearable force-sensitive and body-aware exoprosthesis for a transhumeral prosthesis socket},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of a fused sonomyography and
electromyography-based control on a cable-driven ankle exoskeleton.
<em>TROB</em>, <em>39</em>(3), 2183–2202. (<a
href="https://doi.org/10.1109/TRO.2023.3236958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an assist-as-needed (AAN) control framework for exoskeleton assistance based on human volitional effort prediction via a Hill-type neuromuscular model. A sequential processing algorithm-based multirate observer is applied to continuously estimate muscle activation levels by fusing surface electromyography (sEMG) and ultrasound (US) echogenicity signals from the ankle muscles. An adaptive impedance controller manipulates the exoskeleton&#39;s impedance for a more natural behavior by following a desired intrinsic impedance model. Two neural networks provide robustness to uncertainties in the overall ankle joint-exoskeleton model and the prediction error in the volitional ankle joint torque. A rigorous Lyapunov-based stability analysis proves that the AAN control framework achieves uniformly ultimately bounded tracking for the overall system. Experimental studies on five participants with no neurological disabilities walking on a treadmill validate the effectiveness of the designed ankle exoskeleton and the proposed AAN approach. Results illustrate that the AAN control approach with fused sEMG and US echogenicity signals maintained a higher human volitional effort prediction accuracy, less ankle joint trajectory tracking error, and less robotic assistance torque than the AAN approach with the sEMG-based volitional effort prediction alone. The findings support our hypotheses that the proposed controller increases human motion intent prediction accuracy, improves the exoskeleton&#39;s control performance, and boosts voluntary participation from human subjects. The new framework potentially paves a foundation for using multimodal biological signals to control rehabilitative or assistive robots.},
  archive      = {J_TROB},
  author       = {Qiang Zhang and Krysten Lambeth and Ziyue Sun and Albert Dodson and Xuefeng Bao and Nitin Sharma},
  doi          = {10.1109/TRO.2023.3236958},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2183-2202},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Evaluation of a fused sonomyography and electromyography-based control on a cable-driven ankle exoskeleton},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time gait phase and task estimation for controlling a
powered ankle exoskeleton on extremely uneven terrain. <em>TROB</em>,
<em>39</em>(3), 2170–2182. (<a
href="https://doi.org/10.1109/TRO.2023.3235584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positive biomechanical outcomes have been reported with lower limb exoskeletons in laboratory settings, but these devices have difficulty delivering appropriate assistance in synchrony with human gait as the task or rate of phase progression change in real-world environments. This article presents a controller for an ankle exoskeleton that uses a data-driven kinematic model to continuously estimate the phase, phase rate, stride length, and ground incline states during locomotion, which enables the real-time adaptation of torque assistance to match human torques observed in a multiactivity database of ten able-bodied subjects. We demonstrate in live experiments with a new cohort of ten able-bodied participants that the controller yields phase estimates comparable to the state of the art, while also estimating task variables with similar accuracy to recent machine learning approaches. The implemented controller successfully adapts its assistance in response to changing phase and task variables, both during controlled treadmill trials ( $N=10$ , phase root-mean-square error (RMSE): 4.8 $\pm$ 2.4\%) and a real-world stress test with extremely uneven terrain ( $N=1$ , phase RMSE: 4.8 $\pm$ 2.7\%).},
  archive      = {J_TROB},
  author       = {Roberto Leo Medrano and Gray Cortright Thomas and Connor G. Keais and Elliott J. Rouse and Robert D. Gregg},
  doi          = {10.1109/TRO.2023.3235584},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2170-2182},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Real-time gait phase and task estimation for controlling a powered ankle exoskeleton on extremely uneven terrain},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven variable impedance control of a powered
knee–ankle prosthesis for adaptive speed and incline walking.
<em>TROB</em>, <em>39</em>(3), 2151–2169. (<a
href="https://doi.org/10.1109/TRO.2022.3226887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most impedance-based walking controllers for powered knee–ankle prostheses use a finite state machine with dozens of user-specific parameters that require manual tuning by technical experts. These parameters are only appropriate near the task (e.g., walking speed and incline) at which they were tuned, necessitating many different parameter sets for variable-task walking. In contrast, this article presents a data-driven, phase-based controller for variable-task walking that uses continuously variable impedance control during stance and kinematic control during swing to enable biomimetic locomotion. After generating a data-driven model of variable joint impedance with convex optimization, we implement a novel task-invariant phase variable and real-time estimates of speed and incline to enable autonomous task adaptation. Experiments with above-knee amputee participants ( $N=2$ ) show that our data-driven controller 1) features highly linear phase estimates and accurate task estimates, 2) produces biomimetic kinematic and kinetic trends as task varies, leading to low errors relative to able-bodied references, and 3) produces biomimetic joint work and cadence trends as task varies. We show that the presented controller meets and often exceeds the performance of a benchmark finite state machine controller for our two participants, without requiring manual impedance tuning.},
  archive      = {J_TROB},
  author       = {T. Kevin Best and Cara Gonzalez Welker and Elliott J. Rouse and Robert D. Gregg},
  doi          = {10.1109/TRO.2022.3226887},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2151-2169},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Data-driven variable impedance control of a powered Knee–Ankle prosthesis for adaptive speed and incline walking},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ANYexo 2.0: A fully actuated upper-limb exoskeleton for
manipulation and joint-oriented training in all stages of
rehabilitation. <em>TROB</em>, <em>39</em>(3), 2131–2150. (<a
href="https://doi.org/10.1109/TRO.2022.3226890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We developed an exoskeleton for neurorehabilitation that covered all relevant degrees of freedom of the human arm while providing enough range of motion, speed, strength, and haptic-rendering function for therapy of severely affected (e.g., mobilization) and mildly affected patients (e.g., strength and speed). The ANYexo 2.0, uniting these capabilities, could be the vanguard for highly versatile therapeutic robotics applicable to a broad target group and an extensive range of exercises. Thereby, the practical adoption of these devices in clinics will be fostered. The unique kinematic structure of the robot and the bio-inspired controlled shoulder coupling allowed training for most activities of daily living. We demonstrated this capability with 15 sample activities, including interaction with real objects and the own body with the robot in transparent mode. The robot&#39;s joints can reach $200\%$ , $398\%$ , and $354\%$ of the speed required during activities of daily living at the shoulder, elbow, and wrist, respectively. Further, the robot can provide isometric strength training. We present a detailed analysis of the kinematic properties and propose algorithms for intuitive control implementation.},
  archive      = {J_TROB},
  author       = {Yves Zimmermann and Michael Sommerhalder and Peter Wolf and Robert Riener and Marco Hutter},
  doi          = {10.1109/TRO.2022.3226890},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2131-2150},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ANYexo 2.0: A fully actuated upper-limb exoskeleton for manipulation and joint-oriented training in all stages of rehabilitation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quadruped capturability and push recovery via a
switched-systems characterization of dynamic balance. <em>TROB</em>,
<em>39</em>(3), 2111–2130. (<a
href="https://doi.org/10.1109/TRO.2023.3240622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies capturability and push recovery for quadruped locomotion. Despite the rich literature on capturability analysis and push recovery for legged robots, existing tools have been developed mainly with the requirement of reaching static or quasi-static balance following a push. In practice, this requirement commonly restricts capturability analysis to cases with simple dynamics and fails to encode the time dependence of capturable states for legged locomotion with time-based gaits. To address these issues, we apply switched systems to model quadruped locomotion and extend capturability notions through a novel specification of dynamic balance . We also provide an explicit model predictive control (EMPC) scheme to compute the dynamic balance and capturable tubes and offer a way of using the capturable tube to synthesize push recovery controllers. Such a generalization allows for a rigorous characterization of disturbance timing on the capturability of quadrupedal locomotion and opens the door of disturbance-timing-aware push recovery control strategies. Extensive simulation and hardware experiments illustrate the necessity of considering dynamic balance for quadrupedal push recovery, reveal how disturbance timing affects capturability, and demonstrate the significant improvement in disturbance rejection with the proposed strategy. Hardware experimental validations on a replica of the Mini Cheetah quadruped further verify that the proposed approach performs statistically better than the state-of-the-art baseline considered.},
  archive      = {J_TROB},
  author       = {Hua Chen and Zejun Hong and Shunpeng Yang and Patrick M. Wensing and Wei Zhang},
  doi          = {10.1109/TRO.2023.3240622},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2111-2130},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Quadruped capturability and push recovery via a switched-systems characterization of dynamic balance},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient anytime CLF reactive planning system for a bipedal
robot on undulating terrain. <em>TROB</em>, <em>39</em>(3), 2093–2110.
(<a href="https://doi.org/10.1109/TRO.2022.3228713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and experimentally demonstrate a reactive planning system for bipedal robots on unexplored, challenging terrain. The system includes: a multilayer local map for assessing traversability; an anytime omnidirectional control Lyapunov function for use with a rapidly exploring random tree star (RRT*) that generates a vector field for specifying motion between nodes; a subgoal finder when the final goal is outside of the current map; and a finite-state machine to handle high-level mission decisions. The system also includes a reactive thread that copes with robot deviations via a vector field, defined by a closed-loop feedback policy. The vector field provides real-time control commands to the robot&#39;s gait controller as a function of instantaneous robot pose. The system is evaluated on various challenging outdoor terrains and cluttered indoor scenes in both simulation and experiment on Cassie Blue, a bipedal robot with 20 degrees of freedom. All implementations are coded in C++ with the robot operating system and are available at https://github.com/UMich-BipedLab/CLF_reactive_planning_system .},
  archive      = {J_TROB},
  author       = {Jiunn-Kai Huang and Jessy W. Grizzle},
  doi          = {10.1109/TRO.2022.3228713},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2093-2110},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Efficient anytime CLF reactive planning system for a bipedal robot on undulating terrain},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auxiliary control to avoid undesirable equilibria in
constrained quadratic programs for trajectory tracking applications.
<em>TROB</em>, <em>39</em>(3), 2078–2092. (<a
href="https://doi.org/10.1109/TRO.2022.3233346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control Lyapunov function (CLF) and control barrier function (CBF) based quadratic programs (QPs) may create undesirable local equilibria in control systems. One recent solution utilizes a rotating nonradial CLF to avoid such equilibria in regulation applications. For trajectory tracking applications, a nominal feedback tracking control can be incorporated into the QP cost function to improve the tracking performance of the CLF–CBF–QP. However, the direction of the steepest descent curve of the CLF can differ from that of the nominal feedback control, which may compromise the tracking performance. Moreover, the design of a CLF is system-specific and generally not easy to realize. This article proposes a tracking–CBF–QP formulation, where a nominal tracking control is incorporated in the cost function of a CBF-based QP. If the nominal control conflicts with the CBF condition, undesirable local equilibria may be induced in the closed-loop system. This work theoretically investigates the occurrence of such undesirable local equilibria and provides an auxiliary control approach to prevent the system from falling into such equilibria. The auxiliary control is activated only when a conflict is projected between the nominal control and the CBF constraint, allowing the nominal control to guide the system otherwise. The proposed tracking–CBF–QP is utilized to design a novel leader–follower algorithm, and its effectiveness is verified experimentally.},
  archive      = {J_TROB},
  author       = {Manavendra Desai and Azad Ghaffari},
  doi          = {10.1109/TRO.2022.3233346},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2078-2092},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Auxiliary control to avoid undesirable equilibria in constrained quadratic programs for trajectory tracking applications},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust multiple-path orienteering problem: Securing against
adversarial attacks. <em>TROB</em>, <em>39</em>(3), 2060–2077. (<a
href="https://doi.org/10.1109/TRO.2022.3232268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiple-path orienteering problem asks for paths for a team of robots that maximize the total reward collected while satisfying budget constraints on the path length. This problem models many multirobot routing tasks, such as exploring unknown environments and information gathering for environmental monitoring. In this article, we focus on how to make the robot team robust to failures when operating in adversarial environments. We introduce the robust multiple-path orienteering problem (RMOP), where we seek worst case guarantees against an adversary that is capable of attacking at most $\alpha$ robots. We consider two versions of this problem: RMOP offline and RMOP online. In the offline version, there is no communication or replanning when robots execute their plans, and our main contribution is a general approximation scheme with a bounded approximation guarantee that depends on $\alpha$ and the approximation factor for single-robot orienteering. In particular, we show that the algorithm yields a: 1) constant-factor approximation when the cost function is modular; 2) $\log$ factor approximation when the cost function is submodular; and 3) constant-factor approximation when the cost function is submodular, but the robots are allowed to exceed their path budgets by a bounded amount. In the online version, the RMOP is modeled as a two-player sequential game and solved adaptively in a receding horizon fashion based on Monte Carlo tree search. In addition to theoretical analysis, we perform simulation studies for ocean monitoring and tunnel information-gathering applications to demonstrate the efficacy of our approach.},
  archive      = {J_TROB},
  author       = {Guangyao Shi and Lifeng Zhou and Pratap Tokekar},
  doi          = {10.1109/TRO.2022.3232268},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2060-2077},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust multiple-path orienteering problem: Securing against adversarial attacks},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gaussian belief space path planning for minimum sensing
navigation. <em>TROB</em>, <em>39</em>(3), 2040–2059. (<a
href="https://doi.org/10.1109/TRO.2022.3228128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a path planning methodology for a mobile robot navigating through an obstacle-filled environment to generate a reference path that is traceable with moderate sensing efforts. The desired reference path is characterized as the shortest path in an obstacle-filled Gaussian belief manifold equipped with a novel information-geometric distance function. The distance function we introduce is shown to be an asymmetric quasi-pseudometric and can be interpreted as the minimum information gain required to steer the Gaussian belief. An RRT*-based numerical solution algorithm is presented to solve the formulated shortest-path problem. To gain insight into the asymptotic optimality of the proposed algorithm, we show that the considered path length function is continuous with respect to the topology of total variation. Simulation results demonstrate that the proposed method is effective in various robot navigation scenarios to reduce sensing costs, such as the required frequency of sensor measurements and the number of sensors that must be operated simultaneously.},
  archive      = {J_TROB},
  author       = {Ali Reza Pedram and Riku Funada and Takashi Tanaka},
  doi          = {10.1109/TRO.2022.3228128},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2040-2059},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Gaussian belief space path planning for minimum sensing navigation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Motion planning for variable topology trusses:
Reconfiguration and locomotion. <em>TROB</em>, <em>39</em>(3),
2020–2039. (<a href="https://doi.org/10.1109/TRO.2022.3228400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truss robots are highly redundant parallel robotic systems that can be applied in a variety of scenarios. The variable topology truss (VTT) is a class of modular truss robots. As self-reconfigurable modular robots, a VTT is composed of many edge modules that can be rearranged into various structures depending on the task. These robots change their shape by not only controlling joint positions as with fixed morphology robots but also reconfiguring the connectivity between truss members in order to change their topology. The motion planning problem for VTT robots is difficult due to their varying morphology, high dimensionality, the high likelihood for self-collision, and complex motion constraints. In this article, a new motion planning framework to dramatically alter the structure of a VTT is presented. It can also be used to solve locomotion tasks that are much more efficient compared with previous work. Several test scenarios are used to show its effectiveness.},
  archive      = {J_TROB},
  author       = {Chao Liu and Sencheng Yu and Mark Yim},
  doi          = {10.1109/TRO.2022.3228400},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2020-2039},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Motion planning for variable topology trusses: Reconfiguration and locomotion},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulation, learning, and application of vision-based
tactile sensing at large scale. <em>TROB</em>, <em>39</em>(3),
2003–2019. (<a href="https://doi.org/10.1109/TRO.2023.3245983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale robotic skin with tactile sensing ability is emerging with the potential for use in close-contact human–robot systems. Although recent developments in vision-based tactile sensing and related learning methods are promising, they have been mostly designed for small-scale use, such as by fingers and hands, in manipulation tasks. Moreover, learning perception for such tactile devices demands a huge tactile dataset, which complicates the data collection process. To address this, this study introduces a multiphysics simulation pipeline, called SimTacLS , which considers not only the mechanical properties of external physical contact but also the realistic rendering of tactile images in a simulation environment. The system utilizes the obtained simulation dataset, including virtual images and skin deformation, to train a tactile deep neural network to extract high-level tactile information. Moreover, we adopt a generative network to minimize sim2real inaccuracy, preserving the simulation-based tactile sensing performance. Last but not least, we showcase this sim2real sensing method for our large-scale tactile sensor ( TacLink ) by demonstrating its use in two trial cases, namely, whole-arm nonprehensile manipulation and intuitive motion guidance, using a custom-built tactile robot arm integrated with TacLink. This article opens new possibilities in the learning of transferable tactile-driven robotics tasks from virtual worlds to actual scenarios without compromising accuracy.},
  archive      = {J_TROB},
  author       = {Quan Khanh Luu and Nhan Huu Nguyen and Van Anh Ho},
  doi          = {10.1109/TRO.2023.3245983},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {2003-2019},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simulation, learning, and application of vision-based tactile sensing at large scale},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting kinematic redundancy for robotic grasping of
multiple objects. <em>TROB</em>, <em>39</em>(3), 1982–2002. (<a
href="https://doi.org/10.1109/TRO.2023.3253249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans coordinate the abundant degrees of freedom (DoFs) of hands to dexterously perform tasks in everyday life. We imitate human strategies to advance the dexterity of multi-DoF robotic hands. Specifically, we enable a robot hand to grasp multiple objects by exploiting its kinematic redundancy, referring to all its controllable DoFs. We propose a human-like grasp synthesis algorithm to generate grasps using pairwise contacts on arbitrary opposing hand surface regions, no longer limited to fingertips or hand inner surface. To model the available space of the hand for grasp, we construct a reachability map, consisting of reachable spaces of all finger phalanges and the palm. It guides the formulation of a constrained optimization problem, solving for feasible and stable grasps. We formulate an iterative process to empower robotic hands to grasp multiple objects in sequence. Moreover, we propose a kinematic efficiency metric and an associated strategy to facilitate exploiting kinematic redundancy. We validated our approaches by generating grasps of single and multiple objects using various hand surface regions. Such grasps can be successfully replicated on a real robotic hand.},
  archive      = {J_TROB},
  author       = {Kunpeng Yao and Aude Billard},
  doi          = {10.1109/TRO.2023.3253249},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1982-2002},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Exploiting kinematic redundancy for robotic grasping of multiple objects},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robotic contact juggling. <em>TROB</em>, <em>39</em>(3),
1964–1981. (<a href="https://doi.org/10.1109/TRO.2023.3250160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we define “robotic contact juggling” to be the purposeful control of the motion of a 3-D smooth object as it rolls freely on a motion-controlled robot manipulator, or “hand.” While specific examples of robotic contact juggling have been studied before, in this article, we provide the first general formulation and solution method for the case of an arbitrary smooth object in a single-point rolling contact on an arbitrary smooth hand. Our formulation splits the problem into four subproblems: deriving the second-order rolling kinematics; deriving the 3-D rolling dynamics; planning rolling motions that satisfy the rolling dynamics and achieve the desired goal; and stabilization of planned rolling trajectories. The theoretical results are demonstrated in 3-D simulations and 2-D experiments using feedback from a high-speed vision system.},
  archive      = {J_TROB},
  author       = {James Zachary Woodruff and Kevin M. Lynch},
  doi          = {10.1109/TRO.2023.3250160},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1964-1981},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robotic contact juggling},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Planar in-hand manipulation using primitive rotations based
on isometric transformations. <em>TROB</em>, <em>39</em>(3), 1947–1963.
(<a href="https://doi.org/10.1109/TRO.2022.3231373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving in-hand manipulation of a grasped object is challenging in robotic communities. This article proposes a planar intrinsic in-hand manipulation approach based on isometric transformation. We demonstrate that the isometric transformation (excluding reflections) can be reduced to rotations with two fixed centers, if more than two rotations around two different centers are performed. Furthermore, this article applies this theory to reposition and reorient a grasped object by performing three or more primitive rotations sequentially. We further analyze the feasible manipulation space, where the desired position and orientation of a grasped object can be attained. The theoretical results have been verified through simulations and experiments. In addition, we performed several real-world tasks using a novel robotic hand with two rotational degrees of freedom at each finger, demonstrating that the proposed in-hand manipulation method can reposition and reorient different grasped objects in $\text{SE}(2)$ .},
  archive      = {J_TROB},
  author       = {Jie Zhao and Xiaoman Wang and Shao Hu and Xin Jiang and Yun-Hui Liu},
  doi          = {10.1109/TRO.2022.3231373},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1947-1963},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Planar in-hand manipulation using primitive rotations based on isometric transformations},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust sampling-based control of mobile manipulators for
interaction with articulated objects. <em>TROB</em>, <em>39</em>(3),
1929–1946. (<a href="https://doi.org/10.1109/TRO.2022.3233343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we investigate and deploy sampling-based control techniques for the challenging task of the mobile manipulation of articulated objects. By their nature, manipulation tasks necessitate environment interactions, which require the handling of nondifferentiable switching contact dynamics. These dynamics represent a strong limitation for traditional gradient-based optimization methods, such as model-predictive control and differential dynamic programming, which often rely on heuristics for trajectory generation. Sampling-based techniques alleviate these constraints but do not ensure robots&#39; stability and input/state constraints either. On the other hand, real-world applications in human environments require safety and robustness to unexpected events. For this reason, we propose a novel framework for safe robotic manipulation of movable articulated objects. The framework combines sampling-based control together with control barrier functions and passivity theory that, thanks to formal stability guarantees, enhance the safety and robustness of the method. We also provide the practical insights that enable robust deployment of stochastic control using a conventional central processing unit. We deploy the algorithm on a ten-degree-of-freedom mobile manipulator robot. Finally, we open source our generic and multithreaded implementation.},
  archive      = {J_TROB},
  author       = {Giuseppe Rizzi and Jen Jen Chung and Abel Gawel and Lionel Ott and Marco Tognon and Roland Siegwart},
  doi          = {10.1109/TRO.2022.3233343},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1929-1946},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust sampling-based control of mobile manipulators for interaction with articulated objects},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic OcTree mapping and shannon mutual information
computation for robot exploration. <em>TROB</em>, <em>39</em>(3),
1910–1928. (<a href="https://doi.org/10.1109/TRO.2023.3245986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robot operation in unstructured and unknown environments requires efficient techniques for mapping and exploration using streaming range and visual observations. Information-based exploration techniques, such as Cauchy–Schwarz quadratic mutual information and fast Shannon mutual information, have successfully achieved active binary occupancy mapping with range measurements. However, as we envision robots performing complex tasks specified with semantically meaningful concepts, it is necessary to capture semantics in the measurements, map representation, and exploration objective. This work presents semantic octree mapping and Shannon mutual information computation for robot exploration. We develop a Bayesian multiclass mapping algorithm based on an octree data structure, where each voxel maintains a categorical distribution over semantic classes. We derive a closed-form efficiently computable lower bound of the Shannon mutual information between a multiclass octomap and a set of range-category measurements using semantic run-length encoding of the sensor rays. The bound allows rapid evaluation of many potential robot trajectories for autonomous exploration and mapping. We compare our method against state-of-the-art exploration techniques and apply it in a variety of simulated and real-world experiments.},
  archive      = {J_TROB},
  author       = {Arash Asgharivaskasi and Nikolay Atanasov},
  doi          = {10.1109/TRO.2023.3245986},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1910-1928},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Semantic OcTree mapping and shannon mutual information computation for robot exploration},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ISimLoc: Visual global localization for previously unseen
environments with simulated images. <em>TROB</em>, <em>39</em>(3),
1893–1909. (<a href="https://doi.org/10.1109/TRO.2023.3238201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The camera is an attractive device for use in beyond visual line of sight drone operation since cameras are low in size, weight, power, and cost. However, state-of-the-art visual localization algorithms have trouble matching visual data that have significantly different appearances due to changes in illumination or viewpoint. This article presents iSimLoc, a learning-based global relocalization approach that is robust to appearance and viewpoint differences. The features learned by iSimLoc&#39;s place recognition network can be utilized to match query images to reference images of a different stylistic domain and viewpoint. In addition, our hierarchical global relocalization module searches in a coarse-to-fine manner, allowing iSimLoc to perform fast and accurate pose estimation. We evaluate our method on a dataset with appearance variations and a dataset that focuses on demonstrating large-scale matching over a long flight over complex terrain. iSimLoc achieves 88.7\% and 83.8\% successful retrieval rates on our two datasets, with 1.5 s inference time, compared to 45.8\% and 39.7\% using the next best method. These results demonstrate robust localization in a range of environments and conditions.},
  archive      = {J_TROB},
  author       = {Peng Yin and Ivan Cisneros and Shiqi Zhao and Ji Zhang and Howie Choset and Sebastian Scherer},
  doi          = {10.1109/TRO.2023.3238201},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1893-1909},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ISimLoc: Visual global localization for previously unseen environments with simulated images},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving self-consistency in underwater mapping through
laser-based loop closure. <em>TROB</em>, <em>39</em>(3), 1873–1892. (<a
href="https://doi.org/10.1109/TRO.2022.3229842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate, self-consistent bathymetric maps are needed to monitor changes in subsea environments and infrastructure. These maps are increasingly collected by underwater vehicles, and mapping requires an accurate vehicle navigation solution. Commercial off-the-shelf (COTS) navigation solutions for underwater vehicles often rely on external acoustic sensors for localization; however, survey-grade acoustic sensors are expensive to deploy and limit the range of the vehicle. Techniques from the field of simultaneous localization and mapping, particularly loop closures, can improve the quality of the navigation solution over dead reckoning, but are difficult to integrate into COTS navigation systems. This article presents a method to improve the self-consistency of bathymetric maps by smoothly integrating loop-closure measurements into the state estimate produced by a commercial subsea navigation system. Integration is done using a white-noise-on-acceleration motion prior, without access to raw sensor measurements or proprietary models. Improvements in map self-consistency are shown for both simulated and experimental datasets, including a 3-D scan of an underwater shipwreck in Wiarton, ON, Canada.},
  archive      = {J_TROB},
  author       = {Thomas Hitchcox and James Richard Forbes},
  doi          = {10.1109/TRO.2022.3229842},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1873-1892},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Improving self-consistency in underwater mapping through laser-based loop closure},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rules of the road: Formal guarantees for autonomous vehicles
with behavioral contract design. <em>TROB</em>, <em>39</em>(3),
1853–1872. (<a href="https://doi.org/10.1109/TRO.2023.3247951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of safe and fair conflict resolution among inertial, distributed agents—particularly in highly interactive settings—is of paramount importance to the autonomous vehicles industry. The difficulty of solving this problem can be attributed to the fact that agents have to reason over other agents&#39; complex behaviors. We propose the idea of using a behavioral contract to capture a set of explicitly defined assumptions about how all agents in the environment make decisions. In this article, we present a behavioral contract for a specific class of agents that can guarantee the safety and liveness (i.e., progress) of all agents operating in accordance with it. The behavioral contract has two main components—an ordered behavioral rulebook that the agent uses to select its intended action and some additional constraints that define when an agent has precedence (or not) to take its intended action. If all of the agents act according to this contract, we can guarantee safety under all traffic conditions and liveness for all agents under “sparse” traffic conditions. The formalism of the contract also enables assignment of blame. We provide proofs of correctness of the behavioral contract and validate our results in simulation.},
  archive      = {J_TROB},
  author       = {Karena X. Cai and Tung Phan-Minh and Soon-Jo Chung and Richard M. Murray},
  doi          = {10.1109/TRO.2023.3247951},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1853-1872},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Rules of the road: Formal guarantees for autonomous vehicles with behavioral contract design},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust active visual perching with quadrotors on inclined
surfaces. <em>TROB</em>, <em>39</em>(3), 1836–1852. (<a
href="https://doi.org/10.1109/TRO.2023.3238911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous micro aerial vehicles are deployed for a variety of tasks including surveillance and monitoring. Perching and staring allow the vehicle to monitor targets without flying, saving battery power and increasing the overall mission time without the need to frequently replace batteries. This article addresses the active visual perching (AVP) control problem to autonomously perch on inclined surfaces up to $90^\circ$ . Our approach generates dynamically feasible trajectories to navigate and perch on a desired target location while taking into account actuator and field-of-view constraints. By replanning in midflight, we take advantage of more accurate target localization increasing the perching maneuver&#39;s robustness to target localization or control errors. We leverage the Karush–Kuhn–Tucker (KKT) conditions to identify the compatibility between planning objectives and the visual sensing constraint during the planned maneuver. Furthermore, we experimentally identify the corresponding boundary conditions that maximize the spatio-temporal target visibility during the perching maneuver. The proposed approach works on-board in real time with significant computational constraints relying exclusively on cameras and an inertial measurement unit. Experimental results validate the proposed approach and show a higher success rate as well as increased target interception precision and accuracy compared to a one-shot planning approach, while still retaining aggressive capabilities with flight envelopes that include large displacements from the hover position on inclined surfaces up to 90 $^\circ$ , angular speeds up to 750 $^\circ$ /s, and accelerations up to 10 m/s $^{2}$ .},
  archive      = {J_TROB},
  author       = {Jeffrey Mao and Stephen Nogar and Christopher M. Kroninger and Giuseppe Loianno},
  doi          = {10.1109/TRO.2023.3238911},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1836-1852},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust active visual perching with quadrotors on inclined surfaces},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RACER: Rapid collaborative exploration with a decentralized
multi-UAV system. <em>TROB</em>, <em>39</em>(3), 1816–1835. (<a
href="https://doi.org/10.1109/TRO.2023.3236945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the use of multiple unmanned aerial vehicles (UAVs) has great potential for fast autonomous exploration, it has received far too little attention. In this article, we present a RApid Collaborative ExploRation (RACER) approach using a fleet of decentralized UAVs. To effectively dispatch the UAVs, a pairwise interaction based on an online hgrid space decomposition is used. It ensures that all UAVs simultaneously explore distinct regions, using only asynchronous and limited communication. Furthermore, we optimize the coverage paths of unknown space and balance the workloads partitioned to each UAV with a capacitated vehicle routing problem formulation. Given the task allocation, each UAV constantly updates the coverage path and incrementally extracts crucial information to support the exploration planning. A hierarchical planner finds exploration paths, refines local viewpoints, and generates minimum-time trajectories in sequence to explore the unknown space agilely and safely. The proposed approach is evaluated extensively, showing high exploration efficiency, scalability, and robustness to limited communication. Furthermore, for the first time, we achieve fully decentralized collaborative exploration with multiple UAVs in the real world. We will release our implementation as an open-source package.},
  archive      = {J_TROB},
  author       = {Boyu Zhou and Hao Xu and Shaojie Shen},
  doi          = {10.1109/TRO.2023.3236945},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1816-1835},
  shortjournal = {IEEE Trans. Robot.},
  title        = {RACER: Rapid collaborative exploration with a decentralized multi-UAV system},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximum-entropy multi-agent dynamic games: Forward and
inverse solutions. <em>TROB</em>, <em>39</em>(3), 1801–1815. (<a
href="https://doi.org/10.1109/TRO.2022.3232300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study the problem of multiple stochastic agents interacting in a dynamic game scenario with continuous state and action spaces. We define a new notion of stochastic Nash equilibrium for boundedly rational agents, which we call the entropic cost equilibrium (ECE). We show that ECE is a natural extension to multiple agents of maximum entropy optimality for a single agent. We solve both the “forward” and “inverse” problems for the multi-agent ECE game. For the forward problem, we provide a Riccati algorithm to compute closed-form ECE feedback policies for the agents, which are exact in the linear-quadratic-gaussian case. We give an iterative variant to find locally ECE feedback policies for the nonlinear case. For the inverse problem, we present an algorithm to infer the cost functions of the multiple interacting agents given noisy, boundedly rational input and state trajectory examples from agents acting in an ECE. The effectiveness of our algorithms is demonstrated in a simulated multi-agent collision avoidance scenario, and with data from the INTERACTION traffic dataset. In both cases, we show that, by taking into account the agents&#39; game theoretic interactions using our algorithm, a more accurate model of agents&#39; costs can be learned, compared with standard inverse optimal control methods.},
  archive      = {J_TROB},
  author       = {Negar Mehr and Mingyu Wang and Maulik Bhatt and Mac Schwager},
  doi          = {10.1109/TRO.2022.3232300},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1801-1815},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Maximum-entropy multi-agent dynamic games: Forward and inverse solutions},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed multirobot task assignment via consensus ADMM.
<em>TROB</em>, <em>39</em>(3), 1781–1800. (<a
href="https://doi.org/10.1109/TRO.2022.3228132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a distributed algorithm to solve a class of multirobot task assignment problems. We formulate task assignment as a mathematical optimization and solve for optimal solutions with a variant of the consensus alternating direction method of multipliers (C-ADMM). We provide C-ADMM-based algorithms for both the primal and dual problem formulations and show the advantages of each form depending on the problem specifics. In our algorithm, each robot solves a series of local optimization problems and communicates the results to its local neighbors, ultimately converging to an optimal task assignment in problems with linear objective functions and an optimal solution of the relaxed problem in convex problems. While many other distributed algorithms require a central station for their implementation, in our algorithm, each robot only communicates with its one-hop neighbors. In linear task assignment problems, our algorithm converges to the optimal task assignment, unlike many other distributed algorithms for this problem, which yield suboptimal solutions. We demonstrate our algorithms in task assignment problems over a variety of communication network topologies, where we show that our inexact dual algorithm is at least 60\% faster than other distributed algorithms, which produce an optimal task assignment. In addition, our dual algorithm attains a 69\% speedup in computation time compared to a notable distributed variant of the Hungarian method (Chopra et al., 2017). We also apply our algorithm to a multi-unmanned-aerial-vehicle persistent surveillance problem, showing its suitability for problems involving periodic task assignments.},
  archive      = {J_TROB},
  author       = {Ola Shorinwa and Ravi N. Haksar and Patrick Washington and Mac Schwager},
  doi          = {10.1109/TRO.2022.3228132},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1781-1800},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Distributed multirobot task assignment via consensus ADMM},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust multi-robot active target tracking against sensing
and communication attacks. <em>TROB</em>, <em>39</em>(3), 1768–1780. (<a
href="https://doi.org/10.1109/TRO.2022.3233341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of multi-robot target tracking asks for actively planning the joint motion of robots to track targets. In this article, we focus on such target tracking problems in adversarial environments, where attacks or failures may deactivate robots&#39; sensors and communications. In contrast to the previous works that consider no attacks or sensing attacks only, we formalize the first robust multi-robot tracking framework that accounts for any fixed numbers of worst-case sensing and communication attacks. To secure against such attacks, we design the first robust planning algorithm, named Robust Active Target Tracking ( RATT ), which approximates the communication attacks to equivalent sensing attacks and then optimizes against the approximated and original sensing attacks. We show that RATT provides provable suboptimality bounds on the tracking quality for any non-decreasing objective function. Our analysis utilizes the notations of curvature for set functions introduced in combinatorial optimization. In addition, RATT runs in polynomial time and terminates with the same running time as state-of-the-art algorithms for (non-robust) target tracking. Finally, we evaluate RATT with both the qualitative and quantitative simulations across various scenarios. In the evaluations, RATT exhibits a tracking quality that is near-optimal and superior to varying non-robust heuristics. We also demonstrate RATT ’s superiority and robustness against varying attack models (e.g., worst-case and bounded rational attacks) and with over- and under-estimated numbers of attacks.},
  archive      = {J_TROB},
  author       = {Lifeng Zhou and Vijay Kumar},
  doi          = {10.1109/TRO.2022.3233341},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1768-1780},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust multi-robot active target tracking against sensing and communication attacks},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe control with learned certificates: A survey of neural
lyapunov, barrier, and contraction methods for robotics and control.
<em>TROB</em>, <em>39</em>(3), 1749–1767. (<a
href="https://doi.org/10.1109/TRO.2022.3232542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-enabled control systems have demonstrated impressive empirical performance on challenging control problems in robotics, but this performance comes at the cost of reduced transparency and lack of guarantees on the safety or stability of the learned controllers. In recent years, new techniques have emerged to provide these guarantees by learning certificates alongside control policies—these certificates provide concise data-driven proofs that guarantee the safety and stability of the learned control system. These methods not only allow the user to verify the safety of a learned controller but also provide supervision during training, allowing safety and stability requirements to influence the training process itself. In this article, we provide a comprehensive survey of this rapidly developing field of certificate learning. We hope that this article will serve as an accessible introduction to the theory and practice of certificate learning, both to those who wish to apply these tools to practical robotics problems and to those who wish to dive more deeply into the theory of learning for control.},
  archive      = {J_TROB},
  author       = {Charles Dawson and Sicun Gao and Chuchu Fan},
  doi          = {10.1109/TRO.2022.3232542},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1749-1767},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Safe control with learned certificates: A survey of neural lyapunov, barrier, and contraction methods for robotics and control},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft robots modeling: A structured overview. <em>TROB</em>,
<em>39</em>(3), 1728–1748. (<a
href="https://doi.org/10.1109/TRO.2022.3231360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robotics community has seen an exponential growth in the level of complexity of the theoretical tools presented for the modeling of soft robotics devices. Different solutions have been presented to overcome the difficulties related to the modeling of soft robots, often leveraging on other scientific disciplines, such as continuum mechanics, computational mechanics, and computer graphics. These theoretical and computational foundations are often taken for granted and this leads to an intricate literature that, consequently, has rarely been the subject of a complete review. For the first time, we present here a structured overview of all the approaches proposed so far to model soft robots. The chosen classification, which is based on their theoretical and numerical grounds, allows us to provide a critical analysis about their uses and applicability. This will enable robotics researchers to learn the basics of these modeling techniques and their associated numerical methods, but also to have a critical perspective on their uses.},
  archive      = {J_TROB},
  author       = {Costanza Armanini and Frédéric Boyer and Anup Teejo Mathew and Christian Duriez and Federico Renda},
  doi          = {10.1109/TRO.2022.3231360},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1728-1748},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Soft robots modeling: A structured overview},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Teleoperation of humanoid robots: A survey. <em>TROB</em>,
<em>39</em>(3), 1706–1727. (<a
href="https://doi.org/10.1109/TRO.2023.3236952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teleoperation of humanoid robots enables the integration of the cognitive skills and domain expertise of humans with the physical capabilities of humanoid robots. The operational versatility of humanoid robots makes them the ideal platform for a wide range of applications when teleoperating in a remote environment. However, the complexity of humanoid robots imposes challenges for teleoperation, particularly in unstructured dynamic environments with limited communication. Many advancements have been achieved in the last decades in this area, but a comprehensive overview is still missing. This survey article gives an extensive overview of humanoid robot teleoperation, presenting the general architecture of a teleoperation system and analyzing the different components. We also discuss different aspects of the topic, including technological and methodological advances, as well as potential applications.},
  archive      = {J_TROB},
  author       = {Kourosh Darvish and Luigi Penco and Joao Ramos and Rafael Cisneros and Jerry Pratt and Eiichi Yoshida and Serena Ivaldi and Daniele Pucci},
  doi          = {10.1109/TRO.2023.3236952},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1706-1727},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Teleoperation of humanoid robots: A survey},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on active simultaneous localization and mapping:
State of the art and new frontiers. <em>TROB</em>, <em>39</em>(3),
1686–1705. (<a href="https://doi.org/10.1109/TRO.2023.3248510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active simultaneous localization and mapping (SLAM) is the problem of planning and controlling the motion of a robot to build the most accurate and complete model of the surrounding environment. Since the first foundational work in active perception appeared, more than three decades ago, this field has received increasing attention across different scientific communities. This has brought about many different approaches and formulations, and makes a review of the current trends necessary and extremely valuable for both new and experienced researchers. In this article, we survey the state of the art in active SLAM and take an in-depth look at the open challenges that still require attention to meet the needs of modern applications. After providing a historical perspective, we present a unified problem formulation and review the well-established modular solution scheme, which decouples the problem into three stages that identify, select, and execute potential navigation actions. We then analyze alternative approaches, including belief-space planning and deep reinforcement learning techniques, and review related work on multirobot coordination. This article concludes with a discussion of new research directions, addressing reproducible research, active spatial perception, and practical applications, among other topics.},
  archive      = {J_TROB},
  author       = {Julio A. Placed and Jared Strader and Henry Carrillo and Nikolay Atanasov and Vadim Indelman and Luca Carlone and José A. Castellanos},
  doi          = {10.1109/TRO.2023.3248510},
  journal      = {IEEE Transactions on Robotics},
  number       = {3},
  pages        = {1686-1705},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A survey on active simultaneous localization and mapping: State of the art and new frontiers},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-performance six-DOF flight control of the bee<span
class="math inline"><sup>++</sup></span>: An inclined-stroke-plane
approach. <em>TROB</em>, <em>39</em>(2), 1668–1684. (<a
href="https://doi.org/10.1109/TRO.2022.3218260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new method for synthesizing and implementing high-performance six-degree-of-freedom ( $\boldsymbol{6}$ -DOF) flight controllers for the Bee $^{++}$ , an insect-scale flying robot driven by four independently-actuated flapping wings. Each wing of the Bee $^{++}$ is installed with a preset orientation such that the stroke plane generated during flight is inclined, thus enabling reliable roll, pitch, and yaw torque generation. Leveraging this capability, we propose a Lyapunov-based nonlinear control architecture that enables closed-loop position and attitude regulation and tracking. The control algorithms presented in this article simultaneously stabilize position and attitude by independently varying the wingstroke amplitudes of the four flapping wings of the Bee $^{++}$ . We use this particular control architecture to exemplify the process of controller synthesis and real-time implementation; however, the aerodynamic design of the Bee $^{++}$ is compatible with a great variety of control structures and performance objectives. As a main result, we present the first set of experimental data demonstrating sustained and robust high-performance tracking of a $\boldsymbol{6}$ -DOF reference signal during flight at the insect scale, which has been a long-standing control problem in the field of flapping-wing microrobotics. Furthermore, using data obtained through a series of systematic flight tests, we show that the Bee $^{++}$ can achieve the highest $\boldsymbol{6}$ -DOF performance ever recorded for an insect-scale flapping-wing flying robot during sustained flight.},
  archive      = {J_TROB},
  author       = {Ryan M. Bena and Xiufeng Yang and Ariel A. Calderón and Néstor O. Pérez-Arancibia},
  doi          = {10.1109/TRO.2022.3218260},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1668-1684},
  shortjournal = {IEEE Trans. Robot.},
  title        = {High-performance six-DOF flight control of the bee$^{++}$: An inclined-stroke-plane approach},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A time-independent control system for natural human gait
assistance with a soft exoskeleton. <em>TROB</em>, <em>39</em>(2),
1653–1667. (<a href="https://doi.org/10.1109/TRO.2022.3226365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When applying exoskeletons for walking assistance, one important consideration is to ensure that the users retain full control over the exoskeleton-provided assistance, which is quite limited in existing exoskeletons due to the absence of a suitable control system. In this article, a time-independent exoskeleton control system is developed based on a novel assistance profile generation method and an iterative force control method to enable continuous assistance adjustment. The assistance profile is formulated as a Gaussian function with a human state variable and can be updated online to adapt to different users. The proposed profile continuously self-adjusts along the movement of the user&#39;s leg, especially when users change their walking patterns. The proposed control system iteratively compensates for the force control lag and amplitude attenuation to enable precise tracking of the assistance profile during natural human walking. Experiments have been conducted using a soft exoskeleton on subjects with and without prior experience using an exoskeleton. The experimental results have shown the effectiveness of the proposed control system compared with a common time-dependent control system.},
  archive      = {J_TROB},
  author       = {Xiaowei Tan and Bi Zhang and Guangjun Liu and Xingang Zhao and Yiwen Zhao},
  doi          = {10.1109/TRO.2022.3226365},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1653-1667},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A time-independent control system for natural human gait assistance with a soft exoskeleton},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design, control, and experimental evaluation of a novel
robotic glove system for patients with brachial plexus injuries.
<em>TROB</em>, <em>39</em>(2), 1637–1652. (<a
href="https://doi.org/10.1109/TRO.2022.3220973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the development of an exoskeleton glove system for people who suffer from brachial plexus injuries, aiming to assist their lost grasping functionality. The robotic system consists of a portable glove system and an embedded controller. The glove system consists of linear series elastic actuators, rotary series elastic actuators, and optimized finger linkages to provide imitated human motion to each finger and a coupled motion of the hand. The design principles and optimization strategies were investigated to balance functionality, portability, and stability. The model-based force control strategy compensated with a backlash model and model-free force control strategy are presented and compared. Results show that our proposed model-free control method achieves the goal of accurate force control. Finally, experiments were conducted with the prototype of the developed integrated exoskeleton glove system. Results from three subjects with 150 trials show that our proposed exoskeleton glove system has the potential to be used as a rehabilitation device for patients.},
  archive      = {J_TROB},
  author       = {Wenda Xu and Yunfei Guo and Cesar Bravo and Pinhas Ben-Tzvi},
  doi          = {10.1109/TRO.2022.3220973},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1637-1652},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design, control, and experimental evaluation of a novel robotic glove system for patients with brachial plexus injuries},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Haptify: A measurement-based benchmarking system for
grounded force-feedback devices. <em>TROB</em>, <em>39</em>(2),
1622–1636. (<a href="https://doi.org/10.1109/TRO.2022.3226110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grounded force-feedback (GFF) devices are an established and diverse class of haptic technology based on robotic arms. However, the number of designs and how they are specified make comparing devices difficult. We thus present Haptify, a benchmarking system that can thoroughly, fairly, and noninvasively evaluate GFF haptic devices. The user holds the instrumented device end-effector and moves it through a series of passive and active experiments. Haptify records the interaction between the hand, device, and ground with a seven-camera optical motion-capture system, a 60-cm-square custom force plate, and a customized sensing end-effector. We demonstrate six key ways to assess GFF device performance: workspace shape, global free-space forces, global free-space vibrations, local dynamic forces and torques, frictionless surface rendering, and stiffness rendering. We then use Haptify to benchmark two commercial haptic devices. With a smaller workspace than the 3D Systems Touch, the more expensive Touch X outputs smaller free-space forces and vibrations, smaller and more predictable dynamic forces and torques, and higher-quality renderings of a frictionless surface and high stiffness.},
  archive      = {J_TROB},
  author       = {Farimah Fazlollahi and Katherine J. Kuchenbecker},
  doi          = {10.1109/TRO.2022.3226110},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1622-1636},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Haptify: A measurement-based benchmarking system for grounded force-feedback devices},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic parameter identification of serial robots using a
hybrid approach. <em>TROB</em>, <em>39</em>(2), 1607–1621. (<a
href="https://doi.org/10.1109/TRO.2022.3211194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based control can provide high-accuracy performance over position-based or velocity-based control. Therefore, to employ model-based control in industrial robots, it is important to estimate the dynamic parameters as accurately as possible. However, traditional estimation methods, such as least squares (LS), are not sufficiently accurate, and the feasibility of dynamic parameters cannot be guaranteed. In this article, an iterative hybrid least square (IHLS) algorithm is proposed to estimate the base parameters of industrial robots by dividing the identification processes into two loops. The inner loop integrates a linear matrix inequality with the semidefinite programming technique to guarantee physical feasibility and reuses the torque deviations between the measured torque and predicted torque to estimate the base parameters of the robot, while the outer loop substitutes the Stribeck friction model for the Coulomb-viscous friction model to estimate the joint friction torque. Moreover, backpropagation neural network (BPNN) is introduced to further estimate the joint friction torque based on the Stribeck friction model. Experiments are conducted on two industrial robots, and four methods are compared in dynamic parameter identification. Experimental results show that the hybrid approach of the IHLS algorithm with the BPNN has the best performance among the four methods.},
  archive      = {J_TROB},
  author       = {Yanjiang Huang and Jianhong Ke and Xianmin Zhang and Jun Ota},
  doi          = {10.1109/TRO.2022.3211194},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1607-1621},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Dynamic parameter identification of serial robots using a hybrid approach},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An atlas-based approach to planar variable-structure
cable-driven parallel robot configuration-space representation.
<em>TROB</em>, <em>39</em>(2), 1594–1606. (<a
href="https://doi.org/10.1109/TRO.2022.3218996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable-structure cable-driven parallel robots (VSCR) are a new class of cable robots that are able to cover nonconvex installation spaces by permitting collisions between cables and fixed objects in the environment. In this article, we show how the configuration space of a general planar VSCR can be represented as an organized set of partially overlapping regions of constant structure. The benefit of this representation, which we refer to as the “structure atlas,” is that it allows any techniques from the established cable-driven parallel robot literature to be applied locally, greatly simplifying the modeling complexity associated with VSCRs. A complete method for how such a representation can be constructed is provided, which includes identifying the set of reachable kinematic structures for a given VSCR and the area where each structure is active. We then give specific examples of how this new representation can be used for performing VSCR workspace analysis and directly solving the VSCR inverse kinematics problem. Our results are demonstrated with the aid of simulated and experimental results.},
  archive      = {J_TROB},
  author       = {Mitchell Rushton and Amir Khajepour},
  doi          = {10.1109/TRO.2022.3218996},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1594-1606},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An atlas-based approach to planar variable-structure cable-driven parallel robot configuration-space representation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shape sensing of flexible robots based on deep learning.
<em>TROB</em>, <em>39</em>(2), 1580–1593. (<a
href="https://doi.org/10.1109/TRO.2022.3221368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a deep learning method for the shape sensing of continuum robots based on multicore fiber bragg grating (FBG) fiber is introduced. The proposed method, based on an artificial neural network (ANN), differs from traditional approaches, where accurate shape reconstruction requires a tedious characterization of many characteristic parameters. A further limitation of traditional approaches is that they require either multiple fibers, whose location relative to the centerline must be precisely known (calibrated), or a single multicore fiber whose position typically coincides with the neutral line. The proposed method addresses this limitation and, thus, allows shape sensing based on a single multicore fiber placed off-center. This helps in miniaturizing and leaves the central channel available for other purposes. The proposed approach was compared to a recent state-of-the-art model-based shape sensing approach. A two-degree-of-freedom benchtop fluidics-driven catheter system was built to validate the proposed ANN. The proposed ANN-based shape sensing approach was evaluated on a 40-mm-long steerable continuum robot in both 3-D free-space and 2-D constrained environments, yielding an average shape sensing error of 0.24 and 0.49 mm, respectively. With these results, the superiority of the proposed approach compared to the recent model-based shape sensing method was demonstrated.},
  archive      = {J_TROB},
  author       = {Xuan Thao Ha and Di Wu and Mouloud Ourak and Gianni Borghesan and Jenny Dankelman and Arianna Menciassi and Emmanuel Vander Poorten},
  doi          = {10.1109/TRO.2022.3221368},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1580-1593},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Shape sensing of flexible robots based on deep learning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kinetostatic modeling of tendon-driven parallel continuum
robots. <em>TROB</em>, <em>39</em>(2), 1563–1579. (<a
href="https://doi.org/10.1109/TRO.2022.3226157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tendon-driven parallel continuum robots (PCR) consist of multiple individual continuous kinematic chains, that are actuated in bending utilizing tendons routed along their backbones. This work derives and proposes a Cosserat rod based kinetostatic modeling framework for such parallel structures that allows for efficiently solving the forward, inverse and velocity kinetostatic problems. Using this model, the kinematic properties such as reachable workspace, singularities, manipulability, and compliance of tendon-driven PCR are studied in detail. Experiments are conducted using a real robotic prototype to validate the derived modeling approach. Overall, a median pose accuracy of 4.9 mm, corresponding to 3.4\% of the continuum robots&#39; lengths, and 6.2 $^\circ$ is achieved. The median of the model&#39;s computation time results in 0.51 s on standard computing hardware. Fast computations of below 100 ms can be achieved, if an appropriate initial guess for solving the kinetostatic model is available, making the model suitable for a range of different applications including optimization or control.},
  archive      = {J_TROB},
  author       = {Sven Lilge and Jessica Burgner-Kahrs},
  doi          = {10.1109/TRO.2022.3226157},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1563-1579},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Kinetostatic modeling of tendon-driven parallel continuum robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statics and dynamics of continuum robots based on cosserat
rods and optimal control theories. <em>TROB</em>, <em>39</em>(2),
1544–1562. (<a href="https://doi.org/10.1109/TRO.2022.3226112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores the relationship between optimal control and Cosserat beam theory from the perspective of solving the forward and inverse dynamics (and statics as a subcase) of continuous manipulators and snake-like bioinspired locomotors. By invoking the principle of minimum potential energy and the Gauss principle of least constraint, it is shown that the quasi-static and dynamic evolutions of these robots are the solutions of optimal control problems in the space variable, which can be solved at each step (of loading or time) of a simulation with the shooting method. In addition to offering an alternative viewpoint on several simulation approaches proposed in the recent past, the optimal control viewpoint allows us to improve some of them while providing a better understanding of their numerical properties. The approach and its properties are illustrated through a set of numerical examples validated against a reference simulator.},
  archive      = {J_TROB},
  author       = {Frédéric Boyer and Vincent Lebastard and Fabien Candelier and Federico Renda and Mazen Alamir},
  doi          = {10.1109/TRO.2022.3226112},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1544-1562},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Statics and dynamics of continuum robots based on cosserat rods and optimal control theories},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A geometrically exact assumed strain modes approach for the
geometrico- and kinemato-static modelings of continuum parallel robots.
<em>TROB</em>, <em>39</em>(2), 1527–1543. (<a
href="https://doi.org/10.1109/TRO.2022.3219777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest on the study of continuum parallel robots (CPRs) due to their higher stiffness and better dynamics capacities than serial continuum robots (SCRs). Several works have focused on the computation of their geometrico- and kinemato-static models that can be sorted into two main categories. Models based on the continuous Cosserat equations are very accurate but assessing elastic stability with them is tricky, and discretized models allow easily checking the elastic stability, but they require a large number of elastic variables to be accurate. In this article, we extend an approach based on assumed strain modes developed for the dynamics of SCRs to the statics of CPRs. This method is able to predict the robot configuration with an excellent accuracy with a very limited number of elastic variables, contrary to other discretization methods. The method is also more than 100 times faster than finite differences for a better prediction accuracy. Finally, it is possible to assess the robot elastic stability by only checking the Hessian of the potential energy as for any discretization method, thus making the analysis of this property simpler than for the continuous Cosserat model. All results are validated through simulations on two case studies.},
  archive      = {J_TROB},
  author       = {Sébastien Briot and Frédéric Boyer},
  doi          = {10.1109/TRO.2022.3219777},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1527-1543},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A geometrically exact assumed strain modes approach for the geometrico- and kinemato-static modelings of continuum parallel robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Three-dimensional bearing-only target following via
observability-enhanced helical guidance. <em>TROB</em>, <em>39</em>(2),
1509–1526. (<a href="https://doi.org/10.1109/TRO.2022.3218268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of air-to-air target following of micro aerial vehicles (MAVs) motivated by the application of defense against malicious MAVs. When the bearing of the target MAV has been measured by the onboard visual sensor of the pursuer MAV, the problem becomes three-dimensional (3-D) bearing-only target following, which has been rarely studied in the literature and faces some unique challenges. To solve this problem, we propose the following novel results. First, to estimate the motion of the target MAV from 3-D bearing measurements, we propose a new pseudo-linear Kalman filter, which has a concise expression and superior stability compared to the classic ones such as the extended Kalman filter and modified polar coordinate filter. Second, we propose a novel approach to analyze the observability of state estimation when only bearing information is available. While the existing approaches are applicable to 2-D and single-step time-horizon cases, ours can handle more general 3-D and multiple-step time-horizon cases. Third, based on the theoretical conclusion of our observability analysis, we design a new 3-D helical guidance law that can better exploit the additional degree of freedom in 3D. The guidance law is adapted to the quadcopter&#39;s dynamics and a low-level flight controller is designed based on geometric control. Numerical simulation results verify the superior performance of the proposed algorithms compared to the state-of-the-art ones. Flight experiments on real quadrotor platforms further show the effectiveness and robustness of the proposed algorithms in practice.},
  archive      = {J_TROB},
  author       = {Jianan Li and Zian Ning and Shaoming He and Chang-Hun Lee and Shiyu Zhao},
  doi          = {10.1109/TRO.2022.3218268},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1509-1526},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Three-dimensional bearing-only target following via observability-enhanced helical guidance},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ASRO-DIO: Active subspace random optimization based depth
inertial odometry. <em>TROB</em>, <em>39</em>(2), 1496–1508. (<a
href="https://doi.org/10.1109/TRO.2022.3208503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional nonlinear state estimation is at the heart of inertial-aided navigation systems (INS). Traditional methods usually rely on good initialization and find difficulty in handling large interframe transformations due to fast camera motion. We opt to tackle these challenges by solving the depth inertial odometry (DIO) problem with random optimization. To address the exponentially increased amount of candidate states sampled for the high-dimensional state space, we propose a highly efficient variant of random optimization based on the idea of active subspace. Our method identifies the active dimensions, which contribute most significantly to the decrease of the cost function in each iteration, and samples candidate states only within the corresponding subspace. This allows us to efficiently explore the 18D state space of DIO and achieve good optimality by sampling and evaluating only thousands of candidate states. Experiments show that our method attains highly robust and accurate DIO under fast camera motions and low light conditions, without needing a slow-motion warm-up for initialization.},
  archive      = {J_TROB},
  author       = {Jiazhao Zhang and Yijie Tang and He Wang and Kai Xu},
  doi          = {10.1109/TRO.2022.3208503},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1496-1508},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ASRO-DIO: Active subspace random optimization based depth inertial odometry},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lidar-level localization with radar? The CFEAR approach to
accurate, fast, and robust large-scale radar odometry in diverse
environments. <em>TROB</em>, <em>39</em>(2), 1476–1495. (<a
href="https://doi.org/10.1109/TRO.2022.3221302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an accurate, highly efficient, and learning-free method for large-scale odometry estimation using spinning radar, empirically found to generalize well across very diverse environments—outdoors, from urban to woodland, and indoors in warehouses and mines—without changing parameters. Our method integrates motion compensation within a sweep with one-to-many scan registration that minimizes distances between nearby oriented surface points and mitigates outliers with a robust loss function. Extending our previous approach conservative filtering for efficient and accurate radar odometry (CFEAR), we present an in-depth investigation on a wider range of datasets, quantifying the importance of filtering, resolution, registration cost and loss functions, keyframe history, and motion compensation. We present a new solving strategy and configuration that overcomes previous issues with sparsity and bias, and improves our state-of-the-art by 38\%, thus, surprisingly, outperforming radar simultaneous localization and mapping (SLAM) and approaching lidar SLAM. The most accurate configuration achieves 1.09\% error at 5 Hz on the Oxford benchmark, and the fastest achieves 1.79\% error at 160 Hz.},
  archive      = {J_TROB},
  author       = {Daniel Adolfsson and Martin Magnusson and Anas Alhashimi and Achim J. Lilienthal and Henrik Andreasson},
  doi          = {10.1109/TRO.2022.3221302},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1476-1495},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Lidar-level localization with radar? the CFEAR approach to accurate, fast, and robust large-scale radar odometry in diverse environments},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental non-gaussian inference for SLAM using
normalizing flows. <em>TROB</em>, <em>39</em>(2), 1458–1475. (<a
href="https://doi.org/10.1109/TRO.2022.3216498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents normalizing flows for incremental smoothing and mapping (NF-iSAM), a novel algorithm for inferring the full posterior distribution in SLAM problems with nonlinear measurement models and non-Gaussian factors. NF-iSAM exploits the expressive power of neural networks, and trains normalizing flows to model and sample the full posterior. By leveraging the Bayes tree, NF-iSAM enables efficient incremental updates similar to iSAM2, albeit in the more challenging non-Gaussian setting. We demonstrate the advantages of NF-iSAM over state-of-the-art point and distribution estimation algorithms using range-only SLAM problems with data association ambiguity. NF-iSAM presents superior accuracy in describing the posterior beliefs of continuous variables (e.g., position) and discrete variables (e.g., data association).},
  archive      = {J_TROB},
  author       = {Qiangqiang Huang and Can Pu and Kasra Khosoussi and David M. Rosen and Dehann Fourie and Jonathan P. How and John J. Leonard},
  doi          = {10.1109/TRO.2022.3216498},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1458-1475},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Incremental non-gaussian inference for SLAM using normalizing flows},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reduced euler-lagrange equations of floating-base robots:
Computation, properties, &amp; applications. <em>TROB</em>,
<em>39</em>(2), 1439–1457. (<a
href="https://doi.org/10.1109/TRO.2022.3206716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At first glance, a floating-base robotic system is a kinematic chain, and its equations of motion are described by the inertia-coupled dynamics of its shape and movable base. However, the dynamics embody an additional structure due to the momentum evolution, which acts as a velocity constraint. In prior works of robot dynamics, matrix transformations of the dynamics revealed a block-diagonal inertia. However, the structure of the transformed matrix of Coriolis/Centrifugal (CC) terms was not examined, and is the primary contribution of this article. To this end, we simplify the CC terms from robot dynamics and derive the analogous terms from geometric mechanics. Using this interdisciplinary link, we derive a two-part structure of the CC matrix, in which each partition is iteratively computed using a self-evident velocity dependency. Through this CC matrix, we reveal a commutative property, the velocity dependencies of the skew-symmetry property, the invariance of the shape dynamics to the basis of momentum, and the curvature as a matrix operator. Finally, we show the application of the proposed CC matrix structure through controller design and locomotion analysis.},
  archive      = {J_TROB},
  author       = {Hrishik Mishra and Gianluca Garofalo and Alessandro Massimo Giordano and Marco De Stefano and Christian Ott and Andreas Kugi},
  doi          = {10.1109/TRO.2022.3206716},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1439-1457},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Reduced euler-lagrange equations of floating-base robots: Computation, properties, &amp; applications},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large-dimensional multibody dynamics simulation using
contact nodalization and diagonalization. <em>TROB</em>, <em>39</em>(2),
1419–1438. (<a href="https://doi.org/10.1109/TRO.2022.3226149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a novel multibody dynamics simulation framework that can efficiently deal with large-dimensionality and complementarity multicontact conditions. Typical contact simulation approaches require performing contact impulse fixed-point iteration, which has high time-complexity from large-size matrix factorization and multiplication, as well as susceptibility to ill-conditioned contact situations. To circumvent this, we propose a novel framework based on velocity fixed-point iteration (V-FPI), which, by utilizing a certain surrogate dynamics and contact nodalization (with virtual nodes), we achieve not only intercontact decoupling but also their interaxes decoupling (i.e., contact diagonalization) at each iteration step. This then enables us to one-shot/parallel-solve the contact problem during each V-FPI iteration-loop, while avoiding large-size/dense matrix inversion/multiplication, thereby, significantly speeding up the simulation time with improved convergence property. We theoretically show that the solution of our framework is consistent with that of the original problem and, further, elucidate mathematical conditions for the convergence of our proposed solver. Performance and properties of our proposed simulation framework are also demonstrated and experimentally validated for various large-dimensional/multicontact scenarios including deformable objects.},
  archive      = {J_TROB},
  author       = {Jeongmin Lee and Minji Lee and Dongjun Lee},
  doi          = {10.1109/TRO.2022.3226149},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1419-1438},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Large-dimensional multibody dynamics simulation using contact nodalization and diagonalization},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative magnetic manipulation via two robotically
actuated permanent magnets. <em>TROB</em>, <em>39</em>(2), 1407–1418.
(<a href="https://doi.org/10.1109/TRO.2022.3209038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetically actuated robots have proven effective in several applications, specifically in medicine. However, generating high actuating fields with a high degree of manipulability is still a challenge, especially when the application needs a large workspace to suitably cover a patient. The presented work discusses a novel approach for the control of magnetic field and field gradients using two robotically actuated permanent magnets. In this case, permanent magnets—relative to coil-based systems—have the advantage of larger field density without energy consumption. We demonstrate that collaborative manipulation of the two permanent magnets can introduce up to three additional Degrees of Freedom (DOFs) when compared to single permanent magnet approaches (five DOFs). We characterized the dual-arm system through the measurement of the fields and gradients and show accurate open-loop control with a 13.5\% mean error. We then demonstrate how the magnetic DOFs can be employed in magnetomechanical manipulation, by controlling and measuring the wrench on two orthogonal magnets within the workspace, observing a maximum crosstalk of 6.1\% and a mean error of 11.1\%.},
  archive      = {J_TROB},
  author       = {Giovanni Pittiglio and Michael Brockdorff and Tomas da Veiga and Joshua Davy and James Henry Chandler and Pietro Valdastri},
  doi          = {10.1109/TRO.2022.3209038},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1407-1418},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Collaborative magnetic manipulation via two robotically actuated permanent magnets},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BDIS: Bayesian dense inverse searching method for real-time
stereo surgical image matching. <em>TROB</em>, <em>39</em>(2),
1388–1406. (<a href="https://doi.org/10.1109/TRO.2022.3215018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In stereoscope-based minimally invasive surgeries (MISs), dense stereo matching plays an indispensable role in 3-D shape recovery, AR, VR, and navigation tasks. Although numerous deep neural network (DNN) approaches are proposed, the conventional prior-free approaches are still popular in the industry because of the lack of open-source annotated dataset and the limitation of the task-specific pretrained DNNs. Among the prior-free stereo matching algorithms, there is no successful real-time algorithm in none GPU environment for MIS. This article proposes the first CPU-level real-time prior-free stereo matching algorithm for general MIS tasks. We achieve an average $14-17$ Hz on $640 \times 480$ images with a single-core CPU (i5-9400) for surgical images. Meanwhile, it achieves slightly better accuracy than the popular efficient large-scale stereo matching (ELAS) method. The patch-based fast disparity searching algorithm is adopted for the rectified stereo images. A coarse-to-fine Bayesian probability and a spatial Gaussian mixed model were proposed to evaluate the patch probability at different scales. An optional probability density function estimation algorithm was adopted to quantify the prediction variance. Extensive experiments demonstrated the proposed method&#39;s capability to handle ambiguities introduced by the textureless surfaces and the photometric inconsistency from the non-Lambertian reflectance and dark illumination. The estimated probability managed to balance the confidences of the patches for stereo images at different scales. It has similar or higher accuracy and fewer outliers than the baseline ELAS in MIS, while it is 4–5 times faster.},
  archive      = {J_TROB},
  author       = {Jingwei Song and Qiuchen Zhu and Jianyu Lin and Maani Ghaffari},
  doi          = {10.1109/TRO.2022.3215018},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1388-1406},
  shortjournal = {IEEE Trans. Robot.},
  title        = {BDIS: Bayesian dense inverse searching method for real-time stereo surgical image matching},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simultaneous online registration-independent stiffness
identification and tip localization of surgical instruments in
robot-assisted eye surgery. <em>TROB</em>, <em>39</em>(2), 1373–1387.
(<a href="https://doi.org/10.1109/TRO.2022.3201393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Notable challenges during retinal surgery lend themselves to robotic assistance, which has proven beneficial in providing safe steady-hand manipulation. Efficient assistance from the robots heavily relies on accurate sensing of surgery states (e.g., instrument tip localization and tool-to-tissue interaction forces). Many of the existing tool tip localization methods require preoperative frame registrations or instrument calibrations. In this study, using an iterative approach and by combining vision and force-based methods, we develop calibration- and registration-independent (RI) algorithms to provide online estimates of instrument stiffness (least squares and adaptive). The estimations are then combined with a state-space model based on the forward kinematics of the steady-hand eye robot and fiber Bragg grating sensor measurements. This is accomplished using a Kalman filtering approach to improve the deflected instrument tip position estimations during robot-assisted eye surgery. The conducted experiments demonstrate that when the online RI stiffness estimations are used, the instrument tip localization results surpass those obtained from preoperative offline calibrations for stiffness.},
  archive      = {J_TROB},
  author       = {Ali Ebrahimi and Shahriar Sefati and Peter Gehlbach and Russell H. Taylor and Iulian I. Iordachita},
  doi          = {10.1109/TRO.2022.3201393},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1373-1387},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simultaneous online registration-independent stiffness identification and tip localization of surgical instruments in robot-assisted eye surgery},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auto-optimizing connection planning method for chain-type
modular self-reconfiguration robots. <em>TROB</em>, <em>39</em>(2),
1353–1372. (<a href="https://doi.org/10.1109/TRO.2022.3218992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chain-type modular robots are capable of self-reconfiguration (SR), where the connection relationship between modules is changed according to the environment and tasks. This article focuses on the connection planning of SR based on multiple in-degree single out-degree (MISO) modules. The goal is to calculate the optimal connection planning solution: the sequence with the fewest detachment and attachment actions. To this end, we propose an auto-optimizing connection planning method that contains a polynomial-time algorithm to calculate near-optimal solutions and an exponential-time algorithm to further optimize the solutions automatically when some CPUs are idle. The method combines rapidity and optimality in the face of an NP-complete problem by using configuration pointers, strings that uniquely specify the robot&#39;s configuration. Our polynomial-time algorithm, in-degree matching (IM) uses the interchangeability of connection points to reduce reconfiguration steps. Our exponential-time algorithm, tree-based branch and bound (TBB) further optimizes the solutions to the optimum by a new branching strategy and stage cost. In the experiments, we verify the feasibility of the auto-optimizing method combining IM and TBB, and demonstrate the superiority of IM over Greedy-CM in the SR of MISO modules and the near-optimality of IM compared to the optimal solutions of TBB.},
  archive      = {J_TROB},
  author       = {Haobo Luo and Tin Lun Lam},
  doi          = {10.1109/TRO.2022.3218992},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1353-1372},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Auto-optimizing connection planning method for chain-type modular self-reconfiguration robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MIRRAX: A reconfigurable robot for limited access
environments. <em>TROB</em>, <em>39</em>(2), 1341–1352. (<a
href="https://doi.org/10.1109/TRO.2022.3207095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of mobile robot platforms for inspection has gained traction in recent years. However, conventional mobile robots are unable to address the challenge of operating in extreme environments where the robot is required to traverse narrow gaps in highly cluttered areas with restricted access, typically through narrow ports. This article presents MIRRAX, a robot designed to meet these challenges by way of its reconfigurable capability. Controllers for the robot are detailed, along with an analysis on the controllability of the robot given the use of mecanum wheels in a variable configuration. Characterization on the robot&#39;s performance identified suitable configurations for operating in narrow environments. The experimental validation of the robot&#39;s controllability shows good agreement with the theoretical analysis and the capability to address the challenges of accessing entry ports as small as 150-mm diameter, as well as navigating through cluttered environments. This article also presents results from a deployment in a Magnox facility at the Sellafield nuclear site in the U.K.—the first robot to ever do so, for remote inspection and mapping.},
  archive      = {J_TROB},
  author       = {Wei Cheah and Keir Groves and Horatio Martin and Harriet Peel and Simon Watson and Ognjen Marjanovic and Barry Lennox},
  doi          = {10.1109/TRO.2022.3207095},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1341-1352},
  shortjournal = {IEEE Trans. Robot.},
  title        = {MIRRAX: A reconfigurable robot for limited access environments},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interaction control of a robotic manipulator with the
surface of deformable object. <em>TROB</em>, <em>39</em>(2), 1321–1340.
(<a href="https://doi.org/10.1109/TRO.2022.3226143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulation of deformable objects has drawn the attention of researchers over the past few years and is associated with a large spectrum of new application perspectives. In this article, we present an efficient integrated motion planning framework to effectively and accurately control a robotic manipulator executing interactive tasks on the surface of a deformable object. The proposed interactive motion planning framework is based on a mesh representation of the object, integrating three efficient preprocessing algorithmic steps, including visual object segmentation, finite element method deformation tracking, and local mesh parameterization. The use of barycentric coordinates, defined on the mesh triangles, enables the establishment of bijective transformations between the deformable part of an object surface and its planar (static and dynamic) parameterized mapping. By merging these spatial transformations with the preprocessing steps, in combination with an active stiffness scheme for robot manipulator control, we are able to achieve accurate and reactive motion planning of interactive trajectories, even under large and persistent visual occlusions (such as due to the presence of the robot in the visual scene). An extensive experimental evaluation study is presented, involving a robotic manipulator in interaction with a hemispherical model of controllable periodic active deformation, which permits precise ground truth derivation. Motion planning accuracy is evaluated in comparison with our previous direct vision-based approach, showing clearly superior performance of the proposed approach under all experimental conditions. The performance of the proposed framework is also further highlighted in tasks involving physical point tracking, interactive programming by human demonstration, as well as contact force regulation.},
  archive      = {J_TROB},
  author       = {Athanasios C. Dometios and Costas S. Tzafestas},
  doi          = {10.1109/TRO.2022.3226143},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1321-1340},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Interaction control of a robotic manipulator with the surface of deformable object},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An unconstrained convex formulation of compliant contact.
<em>TROB</em>, <em>39</em>(2), 1301–1320. (<a
href="https://doi.org/10.1109/TRO.2022.3209077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a convex formulation of compliant frictional contact and a robust performant method to solve it in practice. By analytically eliminating contact constraints, we obtain an unconstrained convex problem. Our solver has proven global convergence and warm-starts effectively, enabling simulation at interactive rates. We develop compact analytical expressions of contact forces allowing us to describe our model in clear physical terms and to rigorously characterize our approximations. Moreover, this enables us not only to model point contact but also to incorporate sophisticated models of compliant contact patches. Our time stepping scheme includes the midpoint rule, which we demonstrate achieves second order accuracy even with frictional contact. We introduce a number of accuracy metrics and show that our method outperforms the existing commercial and open-source alternatives without sacrificing accuracy. Finally, we demonstrate the robust simulation of robotic manipulation tasks at interactive rates, with accurately resolved stiction and contact transitions, as required for meaningful sim-to-real transfer. Our method is implemented in the open-source robotics toolkit Drake.},
  archive      = {J_TROB},
  author       = {Alejandro M. Castro and Frank N. Permenter and Xuchen Han},
  doi          = {10.1109/TRO.2022.3209077},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1301-1320},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An unconstrained convex formulation of compliant contact},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Choosing stiffness and damping for optimal impedance
planning. <em>TROB</em>, <em>39</em>(2), 1281–1300. (<a
href="https://doi.org/10.1109/TRO.2022.3216078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The attention given to impedance control in recent years does not match a similar focus on the choice of impedance values that the controller should execute. Current methods are hardly general and often compute fixed controller gains relying on the use of expensive sensors. In this article, we address the problem of online impedance planning for Cartesian impedance controllers that do not assign the closed-loop inertia. We propose an optimization-based algorithm that, given the Cartesian inertia, computes the stiffness and damping gains without relying on force/torque measurements and so that the effects of perturbations are less than a maximum acceptable value. By doing so, we increase robot resilience to unexpected external disturbances while guaranteeing performance and robustness. The algorithm provides an analytical solution in the case of impedance-controlled robots with diagonally dominant inertia matrix. Instead, established numerical methods are employed to deal with the more common case of nondiagonally dominant inertia. Our work attempts to create a general impedance planning framework, which needs no additional hardware and is easily applicable to any robotic system. Through experiments on real robots, including a quadruped and a robotic arm, our method is shown to be employable in real time and to lead to satisfactory behaviors.},
  archive      = {J_TROB},
  author       = {Mathew Jose Pollayil and Franco Angelini and Guiyang Xin and Michael Mistry and Sethu Vijayakumar and Antonio Bicchi and Manolo Garabini},
  doi          = {10.1109/TRO.2022.3216078},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1281-1300},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Choosing stiffness and damping for optimal impedance planning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kinegami: Algorithmic design of compliant kinematic chains
from tubular origami. <em>TROB</em>, <em>39</em>(2), 1260–1280. (<a
href="https://doi.org/10.1109/TRO.2022.3206711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Origami processes can generate both rigid and compliant structures from the same homogeneous sheet material. In this article, we advance the origami robotics literature by showing that it is possible to construct an arbitrary rigid kinematic chain with prescribed joint compliance from a single tubular sheet. Our “Kinegami” algorithm converts a Denavit–Hartenberg specification into a single-sheet crease pattern for an equivalent serial robot mechanism by composing origami modules from a catalogue. The algorithm arises from the key observation that tubular origami linkage design reduces to a Dubins path planning problem. The automatically generated structural connections and movable joints that realize the specified design can also be endowed with independent user-specified compliance. We apply the Kinegami algorithm to a number of common robot mechanisms and hand-fold their algorithmically generated single-sheet crease patterns into functioning kinematic chains. We believe this is the first completely automated end-to-end system for converting an abstract manipulator specification into a physically realizable origami design that requires no additional human input.},
  archive      = {J_TROB},
  author       = {Wei-Hsi Chen and Woohyeok Yang and Lucien Peach and Daniel E. Koditschek and Cynthia R. Sung},
  doi          = {10.1109/TRO.2022.3206711},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1260-1280},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Kinegami: Algorithmic design of compliant kinematic chains from tubular origami},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning reactive robotic grasping with a versatile
vacuum gripper. <em>TROB</em>, <em>39</em>(2), 1244–1259. (<a
href="https://doi.org/10.1109/TRO.2022.3226148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a six-step approach is proposed to simulate the grasp and evaluate the grasp quality for a versatile vacuum gripper by tracking the deformation and force-torque wrench of the gripping pad. Over 100 K synthetic grasps are generated for neural network training. Furthermore, a gripping attention convolutional neural network (GA-CNN) is developed to predict the grasp quality for real-world grasp, running by 15 Hz closed-loop control with the real-time robotic observation and force-torque feedback. Various experiments in both the simulation and physical grasps indicate that our GA-CNN can focus on the crucial region of the soft gripping pad to predict grasp qualities and perform a lower average error compared with a same-scale traditional CNN. In addition, the complexity of grasping clutters is defined from Level 1 to Level 9. The proposed grasping method achieves an average success rate of 90.2\% for static clutters at Level 1 to Level 8 and an average success rate of &gt;80.0\% for dynamic grasping at Level 1 to Level 7, which outperforms state-of-the-art grasping methods.},
  archive      = {J_TROB},
  author       = {Hui Zhang and Jef Peeters and Eric Demeester and Karel Kellens},
  doi          = {10.1109/TRO.2022.3226148},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1244-1259},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Deep learning reactive robotic grasping with a versatile vacuum gripper},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Object detection using Sim2Real domain randomization for
robotic applications. <em>TROB</em>, <em>39</em>(2), 1225–1243. (<a
href="https://doi.org/10.1109/TRO.2022.3207619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots working in unstructured environments must be capable of sensing and interpreting their surroundings. One of the main obstacles of deep-learning-based models in the field of robotics is the lack of domain-specific labeled data for different industrial applications. In this article, we propose a sim2real transfer learning method based on domain randomization for object detection with which labeled synthetic datasets of arbitrary size and object types can be automatically generated. Subsequently, a state-of-the-art convolutional neural network, YOLOv4, is trained to detect the different types of industrial objects. With the proposed domain randomization method, we could shrink the reality gap to a satisfactory level, achieving 86.32\% and 97.38\% $\mathrm{{mAP}}_{50}$ scores, respectively, in the case of zero-shot and one-shot transfers, on our manually annotated dataset containing 190 real images. Our solution fits for industrial use as the data generation process takes less than 0.5 s per image and the training lasts only around 12 h, on a GeForce RTX 2080 Ti GPU. Furthermore, it can reliably differentiate similar classes of objects by having access to only one real image for training. To our best knowledge, this is the only work thus far satisfying these constraints.},
  archive      = {J_TROB},
  author       = {Dániel Horváth and Gábor Erdős and Zoltán Istenes and Tomáš Horváth and Sándor Földi},
  doi          = {10.1109/TRO.2022.3207619},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1225-1243},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Object detection using Sim2Real domain randomization for robotic applications},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal learning of keypoint predictive models for visual
object manipulation. <em>TROB</em>, <em>39</em>(2), 1212–1224. (<a
href="https://doi.org/10.1109/TRO.2022.3204509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans have impressive generalization capabilities when it comes to manipulating objects and tools in completely novel environments. These capabilities are, at least partially, a result of humans having internal models of their bodies and any grasped object. How to learn such body representations for robots remains an open problem. In this work, we present a self-supervised learning approach that extends a robot&#39;s kinematic model for object manipulation from visual latent representations. Our framework comprises two components: First, we present our multimodal keypoint detector: A neural network autoencoder architecture that fuses proprioception and vision during learning to predict visual key points on an object; second, we show how we can learn an extension of the kinematic chain of the robot by regressing virtual joints from the visual keypoints predicted by our multimodal keypoint detector. Our evaluation shows that our approach learns to consistently predict visual keypoints on objects in the manipulator&#39;s hand and, thus, can easily facilitate learning an extended kinematic chain to include the object grasped in various configurations, from a few seconds of visual data. Finally, we show that this extended kinematic chain lends itself for object manipulation tasks such as placing a grasped object and present experiments in simulation and on hardware.},
  archive      = {J_TROB},
  author       = {Sarah Bechtle and Neha Das and Franziska Meier},
  doi          = {10.1109/TRO.2022.3204509},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1212-1224},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multimodal learning of keypoint predictive models for visual object manipulation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Probabilistic framework for hand–eye and robot–world
calibration <span
class="math inline"><em>A</em><em>X</em> = <em>Y</em><em>B</em></span>.
<em>TROB</em>, <em>39</em>(2), 1196–1211. (<a
href="https://doi.org/10.1109/TRO.2022.3214350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand–eye and robot–world calibration is a problem in which the unknown homogeneous transformations $X$ and $Y$ must be estimated for a loop closure equation $AX = YB$ for a set of transformation measurement pairs $\lbrace (A_{i}, B_{i}) \rbrace$ . Previous studies on $AX=YB$ have mainly relied on linear least-squares minimization followed by nonlinear iterative optimization for solution refinement to minimize the distances between $A_{i} X$ and $Y B_{i}$ . However, these methods have not been fully clarified, particularly in terms of calibration dependence on the coordination of $A,B,X$ , and $Y$ along the system loop, as well as the underlying noise distributions of $A_{i}$ and $B_{i}$ . They also lack flexibility in the noise properties of individual measurements; thus, they cannot incorporate the relative reliability between measurements. To address these limitations, we propose a probabilistic framework for hand–eye and robot–world calibration. The proposed framework clarifies the unclear aspects of existing methods by revealing their underlying assumptions regarding system noise. Consequently, it identifies the applicability of distance minimization to a given calibration problem and provides the optimal coordination of transformations for distance minimization. For cases in which distance minimization is inapplicable, an iterative algorithm for the maximum likelihood estimation is proposed, whereby the different noise properties of individual measurements can be accounted for. An estimation uncertainty analysis is presented for the proposed iterative algorithm to quantify the expected estimation accuracy. The presented theories and the proposed algorithm are validated using a set of numerical and hardware experiments. The code for the iterative algorithm and the estimation uncertainty is available at https://github.com/hjhdog1/probabilisticAXYB .},
  archive      = {J_TROB},
  author       = {Junhyoung Ha},
  doi          = {10.1109/TRO.2022.3214350},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1196-1211},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Probabilistic framework for Hand–Eye and Robot–World calibration $AX = YB$},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anthropomorphic twisted string-actuated soft robotic gripper
with tendon-based stiffening. <em>TROB</em>, <em>39</em>(2), 1178–1195.
(<a href="https://doi.org/10.1109/TRO.2022.3224774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Realizing high-performance soft robotic grippers is challenging because of the inherent limitations of the soft actuators and artificial muscles that drive them, including low force generation, small actuation range, and poor compactness to name a few. Despite advances in this area, realizing compact soft grippers, which exhibit high dexterity and force output, is still challenging. This article explores using twisted string actuators (TSAs) to drive a soft robotic gripper. TSAs have been widely used in numerous robotic applications, but their inclusion in soft robots has been limited. The proposed design of the gripper was inspired by the human hand, with four fingers and a thumb. Tunable stiffness was implemented in the fingers by using antagonistic TSAs. The fingers&#39; bending angles, actuation speed, blocked force output, and stiffness tuning are experimentally characterized. The gripper achieves a score of 6 on the Kapandji test and recreate 31 of the 33 grasps of the Feix GRASP taxonomy. It exhibits a maximum grasping force of 72 N, which is almost 13 times its own weight. A comparison study reveals that the proposed gripper exhibits equivalent or superior performance compared to other similar soft grippers.},
  archive      = {J_TROB},
  author       = {Revanth Konda and David Bombara and Steven Swanbeck and Jun Zhang},
  doi          = {10.1109/TRO.2022.3224774},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1178-1195},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Anthropomorphic twisted string-actuated soft robotic gripper with tendon-based stiffening},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel scaffold-reinforced actuator with tunable attitude
ability for grasping. <em>TROB</em>, <em>39</em>(2), 1164–1177. (<a
href="https://doi.org/10.1109/TRO.2022.3200550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to high compliance, adaptiveness, and easy controllability, soft actuators are widely adopted in soft grippers to grasp irregularly shaped or fragile objects. The specific motions can be preprogrammed into the flexible and constrained structures of the actuator, which provides an inexpensive and convenient method for desired motions. However, most preprogrammed structures cannot change the constraints on the actuator to achieve different kinds of deformations, which limits the motion diversities of actuators. This article proposes a scaffold reinforcement mechanism, where rotatable scaffolds distribute on the surface of the soft structure. The orientation adjustments of the scaffolds can change the deformation constraint of the actuator, which results in different kinds of motions. Based on the scaffold reinforcement mechanism, a scaffold-reinforced actuator is proposed, which can achieve bending motion and complex helical motion in the 3-D space by properly adjusting the orientation of the scaffolds. In addition, both the kinematic and mechanical models are proposed to forecast the behavior of the actuator when driven by cable displacement or tension force. Experimental results verify the validity of the theoretical model, and the actuator can achieve an independent control of bending and helical motion, which can be adopted in applications where both high dexterity and flexibility are required.},
  archive      = {J_TROB},
  author       = {Pei Jiang and Ji Luo and Jiaxing Li and Michael Z. Q. Chen and Yonghua Chen and Yang Yang and Rui Chen},
  doi          = {10.1109/TRO.2022.3200550},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1164-1177},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A novel scaffold-reinforced actuator with tunable attitude ability for grasping},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grasping living objects with adversarial behaviors using
inverse reinforcement learning. <em>TROB</em>, <em>39</em>(2),
1151–1163. (<a href="https://doi.org/10.1109/TRO.2022.3226108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Living objects are difficult to grasp since they can actively elude capture by adopting adversarial behaviors that are extremely hard to model or predict. In this case, an inappropriately strong contact force may hurt the struggling living objects and a grasping algorithm that can minimize the contact force whenever possible is required. To solve this challenging task, in this article, we present a reinforcement-learning (RL)-based algorithm with two stages: the pregrasp stage and the in-hand stage. In the pregrasp stage, the robot focuses on the living object&#39;s adversarial behavior and approaches it in a reliable manner. In particular, we use inverse RL to encode the living object&#39;s adversarial behavior into a reward function. The negative value of the learned reward function is then used to train a high-quality grasping policy that can compete with the living object&#39;s adversarial behavior with the RL framework. In the in-hand stage, we use RL to train a grasp policy such that the dexterous hand can grab the living object with the minimal force. A set of dense rewards are also specifically designed to encourage the robot to grasp and hold the living object persistently. To further improve the grasp performance, we explicitly take into account the structure of the dexterous robot hand by treating the hand as a graph and adopting graph convolutional network to formulate the grasping policy. We conduct a set of experiments to demonstrate the performance of our proposed method, in which the robot can grasp living objects with the success rate of 90\% and 95\% in the pregrasp and in-hand stages, respectively. The contact force applied by the robotic hand to the living object is dramatically reduced in comparison with the baseline grasping policy.},
  archive      = {J_TROB},
  author       = {Zhe Hu and Yu Zheng and Jia Pan},
  doi          = {10.1109/TRO.2022.3226108},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1151-1163},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Grasping living objects with adversarial behaviors using inverse reinforcement learning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exact and approximate heterogeneous bayesian decentralized
data fusion. <em>TROB</em>, <em>39</em>(2), 1136–1150. (<a
href="https://doi.org/10.1109/TRO.2022.3226115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Bayesian peer-to-peer decentralized data fusion, the underlying distributions held locally by autonomous agents are frequently assumed to be over the same set of variables (homogeneous). This requires each agent to process and communicate the full global joint distribution, and thus, leads to high computation and communication costs irrespective of relevancy to specific local objectives. This work formulates and studies heterogeneous decentralized fusion problems, defined as the set of problems in which either the communicated or the processed distributions describe different, but overlapping, random states of interest that are subsets of a larger full global joint state. We exploit the conditional independence structure of such problems and provide a rigorous derivation of novel exact and approximate conditionally factorized heterogeneous fusion rules. We further develop a new version of the homogeneous channel filter algorithm to enable conservative heterogeneous fusion for smoothing and filtering scenarios in dynamic problems. Numerical examples show more than 99.5\% potential communication reduction for heterogeneous channel filter fusion, and a multitarget tracking simulation shows that these methods provide consistent estimates while remaining computationally scalable.},
  archive      = {J_TROB},
  author       = {Ofer Dagan and Nisar R. Ahmed},
  doi          = {10.1109/TRO.2022.3226115},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1136-1150},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Exact and approximate heterogeneous bayesian decentralized data fusion},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guiding vector fields for the distributed motion
coordination of mobile robots. <em>TROB</em>, <em>39</em>(2), 1119–1135.
(<a href="https://doi.org/10.1109/TRO.2022.3224257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose coordinating guiding vector fields to achieve two tasks simultaneously with a team of robots: first, the guidance and navigation of multiple robots to possibly different paths or surfaces typically embedded in 2-D or 3-D, and second, their motion coordination while tracking their prescribed paths or surfaces. The motion coordination is defined by desired parametric displacements between robots on the path or surface. Such a desired displacement is achieved by controlling the virtual coordinates, which correspond to the path or surface&#39;s parameters, between guiding vector fields. Rigorous mathematical guarantees underpinned by dynamical systems theory and Lyapunov theory are provided for the effective distributed motion coordination and navigation of robots on paths or surfaces from all initial positions. As an example for practical robotic applications, we derive a control algorithm from the proposed coordinating guiding vector fields for a Dubins-car-like model with actuation saturation. Our proposed algorithm is distributed and scalable to an arbitrary number of robots. Furthermore, extensive illustrative simulations and fixed-wing aircraft outdoor experiments validate the effectiveness and robustness of our algorithm.},
  archive      = {J_TROB},
  author       = {Weijia Yao and Héctor García de Marina and Zhiyong Sun and Ming Cao},
  doi          = {10.1109/TRO.2022.3224257},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1119-1135},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Guiding vector fields for the distributed motion coordination of mobile robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-robot pickup and delivery via distributed resource
allocation. <em>TROB</em>, <em>39</em>(2), 1106–1118. (<a
href="https://doi.org/10.1109/TRO.2022.3216801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider a large-scale instance of the classical pickup-and-delivery vehicle routing problem that must be solved by a network of mobile cooperating robots. Robots must self-coordinate and self-allocate a set of pickup/delivery tasks while minimizing a given cost figure. This results in a large, challenging mixed-integer linear problem that must be cooperatively solved without a central coordinator. We propose a distributed algorithm based on a primal decomposition approach that provides a feasible solution to the problem in finite time. An interesting feature of the proposed scheme is that each robot computes only its own block of solution, thereby preserving privacy of sensible information. The algorithm also exhibits attractive scalability properties that guarantee solvability of the problem even in large networks. To the best of our knowledge, this is the first attempt to provide a scalable distributed solution to the problem. The algorithm is first tested through Gazebo simulations on a ROS 2 platform, highlighting the effectiveness of the proposed solution. Finally, experiments on a real testbed with a team of ground and aerial robots are provided.},
  archive      = {J_TROB},
  author       = {Andrea Camisa and Andrea Testa and Giuseppe Notarstefano},
  doi          = {10.1109/TRO.2022.3216801},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1106-1118},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multi-robot pickup and delivery via distributed resource allocation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust task scheduling for heterogeneous robot teams under
capability uncertainty. <em>TROB</em>, <em>39</em>(2), 1087–1105. (<a
href="https://doi.org/10.1109/TRO.2022.3216068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a stochastic programming framework for multiagent systems, where task decomposition, assignment, and scheduling problems are simultaneously optimized. The framework can be applied to heterogeneous mobile robot teams with distributed subtasks. Examples include pandemic robotic service coordination, explore and rescue, and delivery systems with heterogeneous vehicles. Owing to their inherent flexibility and robustness, multiagent systems are applied in a growing range of real-world problems that involve heterogeneous tasks and uncertain information. Most previous works assume one fixed way to decompose a task into roles that can later be assigned to the agents. This assumption is not valid for a complex task where the roles can vary and multiple decomposition structures exist. Meanwhile, it is unclear how uncertainties in task requirements and agent capabilities can be systematically quantified and optimized under a multiagent system setting. A representation for complex tasks is proposed: agent capabilities are represented as a vector of random distributions, and task requirements are verified by a generalizable binary function. The conditional value at risk is chosen as a metric in the objective function to generate robust plans. An efficient algorithm is described to solve the model, and the whole framework is evaluated in two different practical test cases: capture-the-flag and robotic service coordination during a pandemic (e.g., COVID-19). Results demonstrate that the framework is generalizable, is scalable up to 140 agents and 40 tasks for the example test cases, and provides low-cost plans that ensure a high probability of success.},
  archive      = {J_TROB},
  author       = {Bo Fu and William Smith and Denise M. Rizzo and Matthew Castanier and Maani Ghaffari and Kira Barton},
  doi          = {10.1109/TRO.2022.3216068},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1087-1105},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust task scheduling for heterogeneous robot teams under capability uncertainty},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bounds on optimal revisit times in persistent monitoring
missions with a distinct and remote service station. <em>TROB</em>,
<em>39</em>(2), 1070–1086. (<a
href="https://doi.org/10.1109/TRO.2022.3210784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persistent monitoring missions require an up-to-date knowledge of the changing state of the underlying environment. Unmannned aerial vehicles (UAVs) can be gainfully employed to continually visit a set of targets representing tasks (and locations) in the environment and collect data therein for long time periods. The enduring nature of these missions requires the UAV to be regularly recharged at a service station. In this article, we consider the case in which the service station is not colocated with any of the targets. An efficient monitoring requires the revisit time, defined as the maximum of the time elapsed between successive revisits to targets, to be minimized. Here, we consider the problem of determining UAV routes that lead to the minimum revisit time. The problem is NP-hard, and its computational difficulty increases with the fuel capacity of the UAV. We develop an algorithm to construct near-optimal solutions to the problem quickly when the fuel capacity exceeds a threshold. We also develop lower bounds to the optimal revisit time and use these bounds to demonstrate (through numerical simulations) that the constructed solutions are, on an average, at most 0.01\% away from the optimum.},
  archive      = {J_TROB},
  author       = {Sai Krishna Kanth Hari and Sivakumar Rathinam and Swaroop Darbha and Satyanarayana Gupta Manyam and Krishna Kalyanam and David Casbeer},
  doi          = {10.1109/TRO.2022.3210784},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1070-1086},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Bounds on optimal revisit times in persistent monitoring missions with a distinct and remote service station},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active inference and behavior trees for reactive action
planning and execution in robotics. <em>TROB</em>, <em>39</em>(2),
1050–1069. (<a href="https://doi.org/10.1109/TRO.2022.3226144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a hybrid combination of active inference and behavior trees (BTs) for reactive action planning and execution in dynamic environments, showing how robotic tasks can be formulated as a free-energy minimization problem. The proposed approach allows handling partially observable initial states and improves the robustness of classical BTs against unexpected contingencies while at the same time reducing the number of nodes in a tree. In this work, we specify the nominal behavior offline, through BTs. However, in contrast to previous approaches, we introduce a new type of leaf node to specify the desired state to be achieved rather than an action to execute. The decision of which action to execute to reach the desired state is performed online through active inference. This results in continual online planning and hierarchical deliberation. By doing so, an agent can follow a predefined offline plan while still keeping the ability to locally adapt and take autonomous decisions at runtime, respecting safety constraints. We provide proof of convergence and robustness analysis, and we validate our method in two different mobile manipulators performing similar tasks, both in a simulated and real retail environment. The results showed improved runtime adaptability with a fraction of the hand-coded nodes compared to classical BTs.},
  archive      = {J_TROB},
  author       = {Corrado Pezzato and Carlos Hernández Corbato and Stefan Bonhof and Martijn Wisse},
  doi          = {10.1109/TRO.2022.3226144},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1050-1069},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Active inference and behavior trees for reactive action planning and execution in robotics},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online search-based collision-inclusive motion planning and
control for impact-resilient mobile robots. <em>TROB</em>,
<em>39</em>(2), 1029–1049. (<a
href="https://doi.org/10.1109/TRO.2022.3211131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the emerging paradigm shift of collision-inclusive motion planning and control for impact-resilient mobile robots, and develops a unified hierarchical framework for navigation in unknown and partially observable cluttered spaces. At the lower level, we develop a deformation recovery control and trajectory replanning strategy that handles collisions that may occur at run time, locally. The low-level system actively detects collisions (via embedded Hall effect sensors on a mobile robot built in-house), enables the robot to recover from them, and locally adjusts the postimpact trajectory. Then, at the higher level, we propose a search-based planning algorithm to determine how to best utilize potential collisions to improve certain metrics, such as control energy and computational time. Our method builds upon A* with jump points. We generate a novel heuristic function, and a collision checking and adjustment technique, thus making the A* algorithm converge faster to reach the goal by exploiting and utilizing possible collisions. The overall hierarchical framework generated by combining the global A* algorithm and the local deformation recovery and replanning strategy, as well as individual components of this framework, are tested extensively both in simulation and experimentally. An ablation study draws links to related state-of-the-art search-based collision-avoidance planners (for the overall framework), as well as search-based collision-avoidance and sampling-based collision-inclusive global planners (for the higher level). Results demonstrate our method&#39;s efficacy for collision-inclusive motion planning and control in unknown environments with isolated obstacles for a class of impact-resilient robots operating in 2-D.},
  archive      = {J_TROB},
  author       = {Zhouyu Lu and Zhichao Liu and Merrick Campbell and Konstantinos Karydis},
  doi          = {10.1109/TRO.2022.3211131},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1029-1049},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Online search-based collision-inclusive motion planning and control for impact-resilient mobile robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge database-based multiobjective trajectory planning
of 7-DOF manipulator with rapid and continuous response to uncertain
fast-flying objects. <em>TROB</em>, <em>39</em>(2), 1012–1028. (<a
href="https://doi.org/10.1109/TRO.2022.3207616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problems of a 7-degree of freedom (DOF) manipulator with rapid and continuous response to uncertain fast-flying objects are addressed: 1) how to effectively solve trajectory planning of the 7-DOF manipulator with multiple criteria; and 2) how to make the 7-DOF manipulator realize the rapid and continuous response to uncertain fast-flying objects. In the proposed approach, based on the trajectory parameterization of the 7-DOF manipulator, a multiobjective teaching-learning-based optimization (MOTLBO) algorithm is adopted to find a close representation of the Pareto optimal set rather than a single solution. As such, an optimal solution can be chosen as digital knowledge information. A new methodology based on a knowledge base representing and learning the operation environment, that is, skill digitization, is presented, which enables the 7-DOF manipulator to realize the rapid and continuous response skill. Simulation and practical testing results of a ping-pong robot validate the feasibility and effectiveness of the proposed approach, in which the online trajectory generation spends only around 1 ms.},
  archive      = {J_TROB},
  author       = {Ziwu Ren and Biao Hu and Zhicheng Wang and Lining Sun and Qiuguo Zhu},
  doi          = {10.1109/TRO.2022.3207616},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {1012-1028},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Knowledge database-based multiobjective trajectory planning of 7-DOF manipulator with rapid and continuous response to uncertain fast-flying objects},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Closing the planning–learning loop with application to
autonomous driving. <em>TROB</em>, <em>39</em>(2), 998–1011. (<a
href="https://doi.org/10.1109/TRO.2022.3210767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time planning under uncertainty is critical for robots operating in complex dynamic environments. Consider, for example, an autonomous robot vehicle driving in dense, unregulated urban traffic of cars, motorcycles, buses, etc. The robot vehicle has to plan in both short and long terms, in order to interact with many traffic participants of uncertain intentions and drive effectively. Planning explicitly over a long time horizon, however, incurs prohibitive computational cost and is impractical under real-time constraints. To achieve real-time performance for large-scale planning, this work introduces a new algorithm Learning from Tree Search for Driving (LeTS-Drive), which integrates planning and learning in a closed loop, and applies it to autonomous driving in crowded urban traffic in simulation. Specifically, LeTS-Drive learns a policy and its value function from data provided by an online planner, which searches a sparsely sampled belief tree; the online planner in turn uses the learned policy and value functions as heuristics to scale up its run-time performance for real-time robot control. These two steps are repeated to form a closed loop so that the planner and the learner inform each other and improve in synchrony. The algorithm learns on its own in a self-supervised manner, without human effort on explicit data labeling. Experimental results demonstrate that LeTS-Drive outperforms either planning or learning alone, as well as open-loop integration of planning and learning.},
  archive      = {J_TROB},
  author       = {Panpan Cai and David Hsu},
  doi          = {10.1109/TRO.2022.3210767},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {998-1011},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Closing the Planning–Learning loop with application to autonomous driving},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KDF: Kinodynamic motion planning via geometric
sampling-based algorithms and funnel control. <em>TROB</em>,
<em>39</em>(2), 978–997. (<a
href="https://doi.org/10.1109/TRO.2022.3208502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We integrate sampling-based planning techniques with funnel-based feedback control to develop KDF, a new framework for solving the kinodynamic motion-planning problem via funnel control. The considered systems evolve subject to complex, nonlinear, and uncertain dynamics (also known as differential constraints). First, we use a geometric planner to obtain a high-level safe path in a user-defined extended free space. Second, we develop a low-level funnel control algorithm that guarantees safe tracking of the path by the system. Neither the planner nor the control algorithm uses information on the underlying dynamics of the system, which makes the proposed scheme easily distributable to a large variety of different systems and scenarios. Intuitively, the funnel control module is able to implicitly accommodate the dynamics of the system, allowing hence the deployment of purely geometrical motion planners. Extensive computer simulations and hardware experiments with a 6-DOF robotic arm validate the proposed approach.},
  archive      = {J_TROB},
  author       = {Christos K. Verginis and Dimos V. Dimarogonas and Lydia E. Kavraki},
  doi          = {10.1109/TRO.2022.3208502},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {978-997},
  shortjournal = {IEEE Trans. Robot.},
  title        = {KDF: Kinodynamic motion planning via geometric sampling-based algorithms and funnel control},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mechanical designs for field undulatory locomotion by a
wheeled snake-like robot with decoupled neural oscillators.
<em>TROB</em>, <em>39</em>(2), 959–977. (<a
href="https://doi.org/10.1109/TRO.2022.3226364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we demonstrate the value of using decoupled neural oscillators in conjunction with appropriate mechanical designs for snake-like robots engaging in field locomotion. Even though our typical wheeled snake robot with decoupled neural oscillators incorporating angle joint feedback can generate consistent lateral undulation, it lacks robustness. A purely decoupled actuation strategy is not practical for field locomotion. However, the application of one-way wheels and elasticity between the modules improves robustness, allowing our robot to traverse outdoor open terrain. On the other hand, the physical form of the undulatory motion must be varied to pass through intricate narrow-field environments. The lack of neural constraints between the modules passively enables this variability and also facilitates each module independently gaining propulsion (i.e., by means of reflexive thrust via sensory feedback to the neural oscillator and one-way traction generated by one-way side rollers). The designed robot is able to engage in fast creeping motion through an environment containing randomly distributed logs. The results of the field experiments show that the specially designed mechanisms in conjunction with decoupled oscillators can enhance robustness, variability, and independent local propulsion.},
  archive      = {J_TROB},
  author       = {Yasuhiro Fukuoka and Kotaro Otaka and Ryo Takeuchi and Kaito Shigemori and Kousuke Inoue},
  doi          = {10.1109/TRO.2022.3226364},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {959-977},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Mechanical designs for field undulatory locomotion by a wheeled snake-like robot with decoupled neural oscillators},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). <span class="math inline"><strong>α</strong></span>-WaLTR:
Adaptive wheel-and-leg transformable robot for versatile multiterrain
locomotion. <em>TROB</em>, <em>39</em>(2), 941–958. (<a
href="https://doi.org/10.1109/TRO.2022.3226114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptability is a fundamental yet challenging requirement for mobile robot locomotion. This article presents $\alpha$ -WaLTR, a new adaptive wheel-and-leg transformable robot for versatile multiterrain mobility. The robot has four passively transformable wheels, where each wheel consists of a central gear and multiple leg segments with embedded spring suspension for vibration reduction. These wheels enable the robot to traverse various terrains, obstacles, and stairs while retaining the simplicity in primary control and operation principles of conventional wheeled robots. The chassis dimensions and the center of gravity location were determined by a multiobjective design optimization process aimed at minimizing the weight and maximizing the robot&#39;s pitch angle for obstacle climbing. Unity-based simulations guided the selection of the design variables associated with the transformable wheels. Following the design process, $\alpha$ -WaLTR with an embedded sensing and control system was developed. Experiments showed that the spring suspension on the wheels effectively reduced the vibrations when operated in the legged mode and verified that the robot&#39;s versatile locomotion capabilities were highly consistent with the simulations. The system-level integration with an embedded control system was demonstrated via autonomous stair detection, navigation, and climbing capabilities.},
  archive      = {J_TROB},
  author       = {Chuanqi Zheng and Siddharth Sane and Kangneoung Lee and Vishnu Kalyanram and Kiju Lee},
  doi          = {10.1109/TRO.2022.3226114},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {941-958},
  shortjournal = {IEEE Trans. Robot.},
  title        = {$\mathbf{\alpha }$-WaLTR: Adaptive wheel-and-leg transformable robot for versatile multiterrain locomotion},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An investigation on the effect of actuation pattern on the
power consumption of legged robots for extraterrestrial exploration.
<em>TROB</em>, <em>39</em>(2), 923–940. (<a
href="https://doi.org/10.1109/TRO.2022.3206665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged robots have great potential to be extraterrestrial exploration rovers of extraordinary versatility. Minimizing power consumption is of vital importance in the scenarios of extraterrestrial explorations. The actuation pattern, which refers to the combination of necessary actuators that output torque, has a significant influence on the power consumption of legged robots. This article seeks to investigate the effect of actuation patterns on the power consumption of legged robots that perform motion in a quasi-static manner. The power consumption model of legged robots considering actuation patterns is deduced. Based on that, the effect of the actuation pattern on mechanical power and heat power, which are the main power-loss terms, is investigated. The lowest power consumption under various conditions achieved by different actuation patterns is investigated. Simulation results show that the power consumption can be reduced by choosing the actuation pattern properly. Furthermore, the principles of selecting the optimal actuation pattern from the perspective of power consumption are summarized, which are expected to facilitate the minimal power consumption motion planning of legged robots.},
  archive      = {J_TROB},
  author       = {Yuan Hu and Weizhong Guo and Rongfu Lin},
  doi          = {10.1109/TRO.2022.3206665},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {923-940},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An investigation on the effect of actuation pattern on the power consumption of legged robots for extraterrestrial exploration},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BiConMP: A nonlinear model predictive control framework for
whole body motion planning. <em>TROB</em>, <em>39</em>(2), 905–922. (<a
href="https://doi.org/10.1109/TRO.2022.3228390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online planning of whole-body motions for legged robots is challenging due to the inherent nonlinearity in the robot dynamics. In this work, we propose a nonlinear model predictive control (MPC) framework, the BiConMP which can generate whole body trajectories online by efficiently exploiting the structure of the robot dynamics. BiConMP is used to generate various cyclic gaits on a real quadruped robot and its performance is evaluated on different terrain, countering unforeseen pushes, and transitioning online between different gaits. Furthermore, the ability of BiConMP to generate nontrivial acyclic whole-body dynamic motions on the robot is presented. The same approach is also used to generate various dynamic motions in MPC on a humanoid robot (Talos) and another quadruped robot (AnYmal) in simulation. Finally, an extensive empirical analysis on the effects of planning horizon and frequency on the nonlinear MPC framework is reported and discussed.},
  archive      = {J_TROB},
  author       = {Avadesh Meduri and Paarth Shah and Julian Viereck and Majid Khadiv and Ioannis Havoutis and Ludovic Righetti},
  doi          = {10.1109/TRO.2022.3228390},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {905-922},
  shortjournal = {IEEE Trans. Robot.},
  title        = {BiConMP: A nonlinear model predictive control framework for whole body motion planning},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ViTAL: Vision-based terrain-aware locomotion for legged
robots. <em>TROB</em>, <em>39</em>(2), 885–904. (<a
href="https://doi.org/10.1109/TRO.2022.3222958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on vision-based planning strategies for legged robots that separate locomotion planning into foothold selection and pose adaptation. Current pose adaptation strategies optimize the robot&#39;s body pose relative to given footholds. If these footholds are not reached, the robot may end up in a state with no reachable safe footholds. Therefore, we present a vision-based terrain-aware locomotion (ViTAL) strategy that consists of novel pose adaptation and foothold selection algorithms. ViTAL introduces a different paradigm in pose adaptation that does not optimize the body pose relative to given footholds, but the body pose that maximizes the chances of the legs in reaching safe footholds. ViTAL plans footholds and poses based on skills that characterize the robot&#39;s capabilities and its terrain awareness. We use the 90-kg HyQ and 140-kg HyQReal quadruped robots to validate ViTAL and show that they are able to climb various obstacles, including stairs, gaps, and rough terrains, at different speeds and gaits. We compare ViTAL with a baseline strategy that selects the robot pose based on given selected footholds and show that ViTAL outperforms the baseline.},
  archive      = {J_TROB},
  author       = {Shamel Fahmi and Victor Barasuol and Domingo Esteban and Octavio Villarreal and Claudio Semini},
  doi          = {10.1109/TRO.2022.3222958},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {885-904},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ViTAL: Vision-based terrain-aware locomotion for legged robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A decade of MRI compatible robots: Systematic review.
<em>TROB</em>, <em>39</em>(2), 862–884. (<a
href="https://doi.org/10.1109/TRO.2022.3212626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) offers better visualization for diagnosis, interventional radiology, and surgery from other imaging modalities without X-ray exposure. Medical robots have provided solutions for many surgical and rehabilitation procedures. A symbiosis of MRI and robotics can allow manipulation in closed MR-gantry, decrease trauma, operation, and recovery time for patients and improve the dexterity, convenience, and surgical outcome for physicians. However, the inherent properties and limitations of MR scanners had hindered their development. Technological advancements in the field of computers, additive manufacturing, and sensing in the past decade have changed robotics and the focus shifted again toward MRI-compatible robots. This article provides a compendium of the state-of-the-art literature on robotic systems developed for the MRI environment presented between 2009 and 2021. The systematic review discusses surgical and fMRI study robots, the actuation, and sensing solutions developed to assist such robots, recent research emphasis, current limitations, and prospects.},
  archive      = {J_TROB},
  author       = {Muhammad Umar Farooq and Seong Young Ko},
  doi          = {10.1109/TRO.2022.3212626},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {862-884},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A decade of MRI compatible robots: Systematic review},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human to robot hand motion mapping methods: Review and
classification. <em>TROB</em>, <em>39</em>(2), 842–861. (<a
href="https://doi.org/10.1109/TRO.2022.3205510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the variety of approaches proposed in the literature to address the problem of mapping human to robot hand motions are summarized and discussed. We particularly attempt to organize under macrocategories the great quantity of presented methods that are often difficult to be seen from a general point of view due to different fields of application, specific use of algorithms, terminology, and declared goals of the mappings. First, a brief historical overview is reported, in order to provide a look on the emergence of the human to robot hand mapping problem as a both conceptual and analytical challenge that is still open nowadays. Thereafter, the survey mainly focuses on a classification of modern mapping methods under the following six categories: direct joint, direct Cartesian, task-oriented, dimensionality reduction based, pose recognition based, and hybrid mappings. For each of these categories, the general view that associates the related reported studies is provided, and representative references are highlighted. Finally, a concluding discussion along with the authors&#39; point of view regarding future desirable trends are reported.},
  archive      = {J_TROB},
  author       = {Roberto Meattini and Raúl Suárez and Gianluca Palli and Claudio Melchiorri},
  doi          = {10.1109/TRO.2022.3205510},
  journal      = {IEEE Transactions on Robotics},
  number       = {2},
  pages        = {842-861},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Human to robot hand motion mapping methods: Review and classification},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed framework matching. <em>TROB</em>,
<em>39</em>(1), 823–838. (<a
href="https://doi.org/10.1109/TRO.2022.3193301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the problem of distributed framework matching (FM), which originates from the assignment task in multirobot coordination and the matching task in pattern recognition. The objective of distributed FM is to distributively seek a correspondence which minimizes some metrics describing the disagreement between two frameworks (i.e., graphs and their embeddings). In view of the type of the underlying graph in the framework, two formulations, undirected framework matching (UFM) and directed framework matching (DFM), and their convex relaxations, relaxed UFM (RUFM), and relaxed DFM (RDFM), are presented. UFM is converted into a graph matching (GM) problem with the adjacency matrix being replaced by a matrix constructed from the undirected framework under certain graphical conditions, and can be solved distributively. Sufficient conditions for the equivalence between UFM and RUFM, and the perturbation admitting exact recovery of correspondence are established. On the other hand, DFM embeds the configuration of the directed framework via another type of matrix, whose computation is distributed, and can deal with the case of two frameworks with different sizes of node sets. A distributed optimization algorithm for solving RDFM is proposed and its convergence results are established which allows DFM to be solved in a fully distributed manner. Simulation examples on both synthetic data and real world datasets demonstrate the applicability and efficacy of our theoretical results in formation control and object matching problems.},
  archive      = {J_TROB},
  author       = {Kun Cao and Xiuxian Li and Lihua Xie},
  doi          = {10.1109/TRO.2022.3193301},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {823-838},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Distributed framework matching},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Embedded magnetic sensing for feedback control of soft HASEL
actuators. <em>TROB</em>, <em>39</em>(1), 808–822. (<a
href="https://doi.org/10.1109/TRO.2022.3200164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need to create more viable soft sensors is increasing in tandem with the growing interest in soft robots. Several sensing methods, like capacitive stretch sensing and intrinsic capacitive self-sensing, have proven to be useful when controlling soft electro-hydraulic actuators, but are still problematic. This is due to challenges around high-voltage electronic interference or the inability to accurately sense the actuator at higher actuation frequencies. These issues are compounded when trying to sense and control the movement of a multiactuator system. To address these shortcomings, we describe a two-part magnetic sensing mechanism to measure the changes in displacement of an electro-hydraulic (HASEL) actuator. Our magnetic sensing mechanism can achieve high accuracy and precision for the HASEL actuator displacement range, and accurately tracks motion at actuation frequencies up to 30 Hz, while being robust to changes in ambient temperature and relative humidity. The high accuracy of the magnetic sensing mechanism is also further emphasized in the gripper demonstration. Using this sensing mechanism, we can detect submillimeter difference in the diameters of three tomatoes. Finally, we successfully perform closed-loop control of one folded HASEL actuator using the sensor, which is then scaled into a deformable tilting platform of six units (one HASEL actuator and one sensor) that control a desired end effector position in 3D space. This work demonstrates the first instance of sensing electro-hydraulic deformation using a magnetic sensing mechanism. The ability to more accurately and precisely sense and control HASEL actuators and similar soft actuators is necessary to improve the abilities of soft, robotic platforms.},
  archive      = {J_TROB},
  author       = {Vani Sundaram and Khoi Ly and Brian K. Johnson and Mantas Naris and Maxwell P. Anderson and James Sean Humbert and Nikolaus Correll and Mark Rentschler},
  doi          = {10.1109/TRO.2022.3200164},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {808-822},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Embedded magnetic sensing for feedback control of soft HASEL actuators},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the workspace of electromagnetic navigation systems.
<em>TROB</em>, <em>39</em>(1), 791–807. (<a
href="https://doi.org/10.1109/TRO.2022.3197107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In remote magnetic navigation, a magnetic navigation system is used to generate magnetic fields to apply mechanical wrenches to steer a magnetic object. This technique can be applied to navigate untethered micro- and nanorobots, as well as tethered magnetic surgical tools for minimally invasive medicine. The design and characterization of these systems have been extensively investigated over the past decade. The determination of the region in space in which these systems can operate has yet to be formalized within the research community. This region is commonly referred to as the “workspace” and constitutes a central concept for any class of robotic system. We focus on magnetic navigation systems comprised of electromagnets and propose a first set of definitions for a magnetic workspace, a methodology to determine it, and evaluation metrics to analyze its characteristics. Our methodology and tools are illustrated with several examples of planar and spatial electromagnetic magnetic navigation systems for both didactic and realistic navigation scenarios.},
  archive      = {J_TROB},
  author       = {Quentin Boehler and Simone Gervasoni and Samuel L. Charreyron and Christophe Chautems and Bradley J. Nelson},
  doi          = {10.1109/TRO.2022.3197107},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {791-807},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On the workspace of electromagnetic navigation systems},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulating underwater human motions on the ground with a
cable-driven robotic platform. <em>TROB</em>, <em>39</em>(1), 783–790.
(<a href="https://doi.org/10.1109/TRO.2022.3197338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human performance and body motions when submerged underwater are highly influenced by buoyancy forces. In this article, we simulate the effect of buoyancy on human motion over ground by using a cable-driven robotic system. The robotic platform was configured to apply buoyancy forces on the human torso, similar to underwater, while subjects performed reaching and assembly tasks. Previous studies have analyzed muscle activity, postural balance, and limb kinematics in aquatic enclosures. However, from these studies, it is difficult to correlate observed human physiology changes with a specific underwater feature. The goal of this article is to expand our knowledge in objectively characterizing how physical underwater features affect human performance. The results of this article could help in designing more efficient overground programs to train divers in performing submarine motor tasks. For this purpose, we investigated motion of body center of mass (COM), ground reaction forces, muscular activity with surface electromyography (sEMG), and limb coordination while participants performed reaching tasks with and without simulated underwater forces. Within the simulated underwater environment with the cable system, buoyancy force significantly displaced the COM to outside the base of support. Additionally, ground reaction forces and sEMG of back muscles were significantly reduced during this condition. The results obtained in the present study are in line with previous experiments performed underwater. The results show the potential applicability of cable-driven platforms to expand our understanding in the future about the influence of aquatics on functional tasks.},
  archive      = {J_TROB},
  author       = {Alejandro Rodriguez-Barroso and Moiz Khan and Victor Santamaria and Enricco Sammarchi and Roque Saltaren and Sunil Agrawal},
  doi          = {10.1109/TRO.2022.3197338},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {783-790},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simulating underwater human motions on the ground with a cable-driven robotic platform},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of parallel variable stiffness actuators.
<em>TROB</em>, <em>39</em>(1), 768–782. (<a
href="https://doi.org/10.1109/TRO.2022.3197088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct-drive motors (DDMs) have been increasingly used for robot actuation because they provide high-fidelity torque control, but they typically have low torque density. Gearing can be used to increase the torque density of motors, but gearing decreases the power density of the actuator. Parallel elastic actuators (PEAs), composed of a spring attached in parallel to a motor, can increase both the torque and power density of the actuator without jeopardizing torque control fidelity. PEAs can also generate efficient oscillatory motion by applying the torque of the motor through resonant oscillations. However, conventional fixed stiffness springs used in PEAs only enable efficient oscillatory motion at a fixed resonant frequency defined by the stiffness of the spring. In this article, we present a parallel variable stiffness actuator (PVSA) consisting of a DDM connected in parallel to a variable stiffness spring. PVSAs retain the torque control bandwidth of DDMs and PEAs and can be used to amplify the torque and power of the motor over a range of oscillation frequencies. We present a compact design of a PVSA where a direct-drive motor, a high energy density composite spring, and a variable stiffness mechanism are arranged in a conventional cylindrical geometry, similar to a motor-gearbox assembly. We foresee the use of PVSAs in mobile robots and wearable devices, where energy efficient oscillatory motion at different frequencies, along with high torque and power density is indispensable.},
  archive      = {J_TROB},
  author       = {Chase W. Mathews and David J. Braun},
  doi          = {10.1109/TRO.2022.3197088},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {768-782},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design of parallel variable stiffness actuators},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kinematic redundancy analysis for (2<span
class="math inline"><em>n</em></span>+1)r circular manipulators.
<em>TROB</em>, <em>39</em>(1), 755–767. (<a
href="https://doi.org/10.1109/TRO.2022.3196961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The kinematic analysis of redundant serial manipulators with $2n+1$ revolute joints (integer $n \geq 3$ ), which we call circular manipulators, is presented in this article. The structure of the kinematic chain of circular manipulators has special properties that can be seen in the Denavit–Hartenberg parameters: all orthogonal distances are zero, all even-numbered offsets are zeros, but odd-numbered offsets are not. Typical manipulators that fulfill these properties are redundant 7R serial chains ( $n=3$ ) that mimic the human arm, e.g., the lightweight robot arm KUKA LBR iiwa. This 7R circular manipulator has self-motion as rotation around an axis that goes through two fixed points for a fixed pose. First, radical reparametrization is presented based on the swivel angle of the closed-form inverse kinematics solution for the 7R circular manipulator. Second, for a six-dimensional task, the inverse kinematics solution for redundant serial manipulators with $2n+1$ revolute joints ( $n\geq 3$ ) is reparametrized by the swivel angle and other $2n-6$ rotation parameters. From a geometric point of view, for a circular manipulator with $2n+1$ revolute joints, one can have ${n(n-1)}/{2}$ choices of such circular rotations. Third, we conjecture numerical kinematic singularities for circular manipulators in a recursive formula, confirming $n=5,6,7$ .},
  archive      = {J_TROB},
  author       = {Zijia Li and Mathias Brandstötter and Michael Hofbaur},
  doi          = {10.1109/TRO.2022.3196961},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {755-767},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Kinematic redundancy analysis for (2$n$+1)R circular manipulators},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kinematics modeling and control of spherical rolling contact
joint and manipulator. <em>TROB</em>, <em>39</em>(1), 738–754. (<a
href="https://doi.org/10.1109/TRO.2022.3190790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling contact joints are attracting increasing interest in applications to robotic fingers and manipulators, due to the potential of the absence of abrasion wear, the simplification of the controller, and the enlargement of reachable configurations. This article first proposes a novel two-degree-of-freedom (DOF) spherical rolling contact (SRC) joint, with the joint model elements being formulated, including rotation matrix , position vector , and free modes , as with those of classic joints. As an application, a new kind of serial manipulator formed by the SRC joints is presented, and its forward and inverse kinematics are modeled. The motions of the two-DOF SRC joint and manipulator are implemented using the FreeBOT, and the control method is proposed for the FreeBOT, such that the SRC joint and manipulator realize the motion control. The kinematics and control of the two-DOF SRC joint and manipulator are validated using physics simulations and on a real manipulator formed by FreeBOTs.},
  archive      = {J_TROB},
  author       = {Lijun Zong and Guanqi Liang and Tin Lun Lam},
  doi          = {10.1109/TRO.2022.3190790},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {738-754},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Kinematics modeling and control of spherical rolling contact joint and manipulator},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributionally robust risk map for learning-based motion
planning and control: A semidefinite programming approach.
<em>TROB</em>, <em>39</em>(1), 718–737. (<a
href="https://doi.org/10.1109/TRO.2022.3200156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a novel safety specification tool, called the distributionally robust risk map (DR-risk map), for a mobile robot operating in a learning-enabled environment. Given the robot&#39;s position, the map aims to reliably assess the conditional value-at-risk (CVaR) of collision with obstacles whose movements are inferred by Gaussian process regression (GPR). Unfortunately, the inferred distribution is subject to errors, making it difficult to accurately evaluate the CVaR of collision. To overcome this challenge, our tool measures the risk under the worst-case distribution in a so-called ambiguity set that characterizes allowable distribution errors. To resolve the infinite-dimensionality issue inherent in the construction of the DR-risk map, we derive a tractable semidefinite programming formulation that provides an upper bound of the risk, exploiting techniques from modern distributionally robust optimization. As a concrete application for motion planning, a distributionally robust RRT* algorithm is considered using the risk map that addresses distribution errors caused by GPR. Furthermore, a motion control method is devised using the DR-risk map in a learning-based model predictive control (MPC) formulation. In particular, a neural network approximation of the risk map is proposed to reduce the computational cost in solving the MPC problem. The performance and utility of the proposed risk map are demonstrated through simulation studies that show its ability to ensure the safety of mobile robots despite learning errors.},
  archive      = {J_TROB},
  author       = {Astghik Hakobyan and Insoon Yang},
  doi          = {10.1109/TRO.2022.3200156},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {718-737},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Distributionally robust risk map for learning-based motion planning and control: A semidefinite programming approach},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multitask learning for scalable and dense multilayer
bayesian map inference. <em>TROB</em>, <em>39</em>(1), 699–717. (<a
href="https://doi.org/10.1109/TRO.2022.3197106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a novel and flexible multitask multilayer Bayesian mapping framework with readily extendable attribute layers. The proposed framework goes beyond modern metric-semantic maps to provide even richer environmental information for robots in a single mapping formalism while exploiting intralayer and interlayer correlations. It removes the need for a robot to access and process information from many separate maps when performing a complex task, advancing the way robots interact with their environments. To this end, we design a multitask deep neural network with attention mechanisms as our front-end to provide heterogeneous observations for multiple map layers simultaneously. Our back-end runs a scalable closed-form Bayesian inference with only logarithmic time complexity. We apply the framework to build a dense robotic map, including metric-semantic occupancy and traversability layers. Traversability ground truth labels are automatically generated from exteroceptive sensory data in a self-supervised manner. We present extensive experimental results on publicly available datasets and data collected by a three-dimensional bipedal robot platform and show reliable mapping performance in different environments. Finally, we also discuss how the current framework can be extended to incorporate more information, such as friction, signal strength, temperature, and physical quantity concentration using Gaussian map layers. The software for reproducing the presented results or running on customized data is made publicly available.},
  archive      = {J_TROB},
  author       = {Lu Gan and Youngji Kim and Jessy W. Grizzle and Jeffrey M. Walls and Ayoung Kim and Ryan M. Eustice and Maani Ghaffari},
  doi          = {10.1109/TRO.2022.3197106},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {699-717},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multitask learning for scalable and dense multilayer bayesian map inference},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint estimation of expertise and reward preferences from
human demonstrations. <em>TROB</em>, <em>39</em>(1), 681–698. (<a
href="https://doi.org/10.1109/TRO.2022.3192969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a robot learns from human examples, most approaches assume that the human partner provides examples of optimal behavior. However, there are applications in which the robot learns from nonexpert humans. We argue that the robot should learn not only about the human&#39;s objectives, but also about their expertise level. The robot could then leverage this joint information to reduce or increase the frequency at which it provides assistance to its human&#39;s partner or be more cautious when learning new skills from novice users. Similarly, by taking into account the human&#39;s expertise, the robot would also be able to infer a human&#39;s true objectives even when the human fails to properly demonstrate these objectives due to a lack of expertise. In this article, we propose to jointly infer the expertise level and the objective function of a human given observations of their (possibly) nonoptimal demonstrations. Two inference approaches are proposed. In the first approach, inference is done over a finite discrete set of possible objective functions and expertise levels. In the second approach, the robot optimizes over the space of all possible hypotheses and finds the objective function and the expertise level that best explain the observed human behavior. We demonstrate our proposed approaches both in simulation and with real user data.},
  archive      = {J_TROB},
  author       = {Pamela Carreno-Medrano and Stephen L. Smith and Dana Kulić},
  doi          = {10.1109/TRO.2022.3192969},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {681-698},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Joint estimation of expertise and reward preferences from human demonstrations},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Behavior cloning-based robot active object detection with
automatically generated data and revision method. <em>TROB</em>,
<em>39</em>(1), 665–680. (<a
href="https://doi.org/10.1109/TRO.2022.3191745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active object detection (AOD), one of the greatest challenges in the robotics field, is the main focus of this article. Most current AOD methods are developed by reinforcement learning (RL) algorithms while they can be further improved in the aspects of training time, training efficiency, model performance, and model prediction. Therefore, different from the existing works, we propose an AOD method based on behavior cloning trained by automatically generated data. We transform the AOD task into an action classification problem to not only shorten the training time but also improve the training efficiency and model performance. As there is no available expert data for training the presented classification-based AOD model, we design an autonomous method of data generation to avoid the large amounts of manual annotations. We introduce a multiinput network for better obstacle avoidance and AOD performance, where the depth image is added to help the robot to perceive distance information of environments and objects. Moreover, we develop a revision method for model prediction to reduce the accumulation of compounding error, which improves the successful rate of the long path AOD tasks effectively. We extensively evaluate our method on an AOD dataset by the comparable experiments and the ablation study, proving that our approach outperforms other methods in AOD performance and efficiency. In addition, the AOD experiments in the real-world scenario with a TIAGo robot indicate the validity of our method.},
  archive      = {J_TROB},
  author       = {Shaopeng Liu and Guohui Tian and Xuyang Shao and Shuo Liu},
  doi          = {10.1109/TRO.2022.3191745},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {665-680},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Behavior cloning-based robot active object detection with automatically generated data and revision method},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from sparse demonstrations. <em>TROB</em>,
<em>39</em>(1), 645–664. (<a
href="https://doi.org/10.1109/TRO.2022.3191592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop the method of continuous Pontryagin differentiable programming (Continuous PDP), which enables a robot to learn an objective function from a few sparsely demonstrated keyframes. The keyframes, labeled with some time stamps, are the desired task-space outputs, which a robot is expected to follow sequentially. The time stamps of the keyframes can be different from the time of the robot&#39;s actual execution. The method jointly finds an objective function and a time-warping function such that the robot&#39;s resulting trajectory sequentially follows the keyframes with minimal discrepancy loss. The Continuous PDP minimizes the discrepancy loss using projected gradient descent by efficiently solving the gradient of the robot trajectory with respect to the unknown parameters. The method is first evaluated on a simulated robot arm and then applied to a 6-DoF quadrotor to learn an objective function for motion planning in unmodeled environments. The results show the efficiency of the method, its ability to handle time misalignment between keyframes and robot execution, and the generalization of objective learning into unseen motion conditions.},
  archive      = {J_TROB},
  author       = {Wanxin Jin and Todd D. Murphey and Dana Kulić and Neta Ezer and Shaoshuai Mou},
  doi          = {10.1109/TRO.2022.3191592},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {645-664},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning from sparse demonstrations},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from human directional corrections. <em>TROB</em>,
<em>39</em>(1), 625–644. (<a
href="https://doi.org/10.1109/TRO.2022.3190221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel approach that enables a robot to learn an objective function incrementally from human directional corrections. Existing methods learn from human magnitude corrections; since a human needs to carefully choose the magnitude of each correction, those methods can easily lead to overcorrections and learning inefficiency. The proposed method only requires human directional corrections—corrections that only indicate the direction of an input change without indicating its magnitude. We only assume that each correction, regardless of its magnitude, points in a direction that improves the robot&#39;s current motion relative to an unknown objective function. The allowable corrections satisfying this assumption account for half of the input space, as opposed to the magnitude corrections that have to lie in a shrinking level set. For each directional correction, the proposed method updates the estimate of the objective function based on a cutting plane method, which has a geometric interpretation. We have established theoretical results to show the convergence of the learning process. The proposed method has been tested in numerical examples, a user study on two human–robot games, and a real-world quadrotor experiment. The results confirm the convergence of the proposed method and further show that the method is significantly more effective (higher success rate), efficient/effortless (less human corrections needed), and potentially more accessible (fewer early wasted trials) than the state-of-the-art robot learning frameworks.},
  archive      = {J_TROB},
  author       = {Wanxin Jin and Todd D. Murphey and Zehui Lu and Shaoshuai Mou},
  doi          = {10.1109/TRO.2022.3190221},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {625-644},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning from human directional corrections},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A switched systems approach to multiagent system consensus:
A relay–explorer perspective. <em>TROB</em>, <em>39</em>(1), 605–624.
(<a href="https://doi.org/10.1109/TRO.2022.3200005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rendezvous or position consensus problem is a fundamental topic within the multiagent system (MAS) literature and has numerous engineering applications. The majority of recent results that solve the position consensus problem rely on communication networks and each agent&#39;s ability to obtain position information via direct measurements and communication. Distributed coordination strategies for MASs that are network free and have agents that cannot directly measure position information are scarce. In this work, we develop a relay–explorer strategy to achieve position consensus at a common, desired location. In particular, a group of explorer agents, lacking global position sensors, use open-loop estimators of their position to independently dead reckon toward the desired location. To prevent the difference between the estimated and true position of each explorer from growing beyond a user-defined threshold, a mobile information service provider (relay agent) that is capable of measuring its position in the global coordinate frame, intermittently visits each explorer to provide position information as determined by a maximum dwell-time condition. The relay agent has a position estimator for each explorer, and each estimator is synchronized with the corresponding explorer. The relay agent uses these position estimators to locate each explorer, maneuver to them, and provide position feedback. The contribution of this work over our precursory results is the consideration of uncertain explorer agent dynamics, which are estimated online using recurrent neural networks and integral concurrent learning. The estimated dynamics serve as feed-forward model approximations in the position estimators used by the explorers and relay agent, which generate more accurate position estimates once a finite excitation condition is satisfied. The MAS is modeled as a switched system, and a Lyapunov-based analysis is used to derive a maximum dwell-time condition for each explorer, prove the MAS is exponentially regulated to the desired location, and show the error between the estimated and true explorer dynamics is uniformly ultimately bounded. Experiments and multiple simulation examples are provided to verify the theoretical development, explore the scalability and learning performance of the approach, and shed light on future extensions.},
  archive      = {J_TROB},
  author       = {Federico M. Zegers and Patryk Deptula and Hsi-Yuan Chen and Axton Isaly and Warren E. Dixon},
  doi          = {10.1109/TRO.2022.3200005},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {605-624},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A switched systems approach to multiagent system consensus: A Relay–Explorer perspective},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Controlling collision-induced aggregations in a swarm of
micro bristle robots. <em>TROB</em>, <em>39</em>(1), 590–604. (<a
href="https://doi.org/10.1109/TRO.2022.3189846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systematically designing local interaction rules to achieve collective behaviors in robot swarms is a challenging endeavor, especially in micro robots, where size restrictions imply severe sensing, communication, and computation limitations. In such robot swarms, performing useful functions is often preconditioned on the formation of high-density aggregations which can facilitate collective signaling and information sharing. In this article, we present a systematic approach to control aggregation behaviors by leveraging the physical interactions in a swarm of 300 3-mm vibration-driven micro bristle robots that we designed and fabricated. We demonstrate the ability to control the degree of aggregation by varying the motility characteristics of the robots through global vibration frequency and amplitude inputs, after comprehensive characterization, modeling, and simulation of the locomotion dynamics and robot interactions. To quantify the degree of aggregation, we also introduce a new metric, the motility-induced phase separation index index, which unlike many existing methods does not require a scenario-specific tuning of parameters. Our investigations reveal how physics-driven interaction mechanisms can be exploited to achieve desired behaviors in minimally equipped robot swarms and highlight the specific ways in which hardware and software developments aid in the achievement of collision-induced aggregations.},
  archive      = {J_TROB},
  author       = {Zhijian Hao and Siddharth Mayya and Gennaro Notomista and Seth Hutchinson and Magnus Egerstedt and Azadeh Ansari},
  doi          = {10.1109/TRO.2022.3189846},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {590-604},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Controlling collision-induced aggregations in a swarm of micro bristle robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gaussian-process-based control of underactuated balance
robots with guaranteed performance. <em>TROB</em>, <em>39</em>(1),
572–589. (<a href="https://doi.org/10.1109/TRO.2022.3203625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of underactuated balance robots is aimed at performing both the external (actuated) subsystem trajectory tracking and internal (unactuated) subsystem balancing tasks. In this article, we propose a learning-based control design for underactuated balance robots. The key idea integrates a model predictive control method to design the desired internal subsystem trajectory and perform the external subsystem tracking task, while an inverse dynamics controller is used to stabilize the internal subsystem to its desired trajectory. The control design is based on Gaussian process (GP) regression models that are learned from experiments without requiring a priori knowledge about the robot dynamics or the demonstration of successful stabilization. GP regression models also provide estimates of modeling uncertainties of the robotic systems, and these estimations are used to enhance control robustness to modeling errors. The learning-based control design is analyzed with guaranteed stability and performance. The proposed design is demonstrated by experiments on a Furuta pendulum and an autonomous bikebot.},
  archive      = {J_TROB},
  author       = {Kuo Chen and Jingang Yi and Dezhen Song},
  doi          = {10.1109/TRO.2022.3203625},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {572-589},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Gaussian-process-based control of underactuated balance robots with guaranteed performance},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Elastic-actuation mechanism for repetitive hopping based on
power modulation and cyclic trajectory generation. <em>TROB</em>,
<em>39</em>(1), 558–571. (<a
href="https://doi.org/10.1109/TRO.2022.3189249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animal locomotion results from a combination of power modulation and cyclic appendage trajectories, but combining these two properties in small-sized robots is difficult. Here, we introduce and characterize a new elastic actuation system based on an inverted cam that is capable of generating cyclic locomotion with controlled elastic energy charge and release for small-sized robots. We designed a leg linkage and attached to the inverted cam to develop a single legged hopping platform with one actuated degree of freedom. The hopping platform was able to continuously hop forward at 1.82 Hz. The average horizontal hopping distance was 18.7 cm, and the average forward speed was 0.34 m/s. This speed was corresponding to a Froude number of 0.14. The energy consumed for one hop was 2.09 J, and the corresponding energetic cost of transport was 6.43. The combination of inverted cam and cyclic trajectory generation has the potential to be used in other robotic applications, such as flapping wings in the air and tail fin waving in water.},
  archive      = {J_TROB},
  author       = {Won Dong Shin and William Stewart and Matt A. Estrada and Auke J. Ijspeert and Dario Floreano},
  doi          = {10.1109/TRO.2022.3189249},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {558-571},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Elastic-actuation mechanism for repetitive hopping based on power modulation and cyclic trajectory generation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and control of a midair-reconfigurable quadcopter
using unactuated hinges. <em>TROB</em>, <em>39</em>(1), 539–557. (<a
href="https://doi.org/10.1109/TRO.2022.3193792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a novel quadcopter capable of changing shape midflight is presented, allowing for operation in four configurations with the capability of sustained hover in three. This is accomplished without requiring actuators beyond the four motors typical of a quadcopter. Morphing is achieved through freely rotating hinges that allow the vehicle arms to fold downwards by either reducing or reversing thrust forces. Constraints placed on the control inputs of the vehicle prevent the arms from folding or unfolding unexpectedly. This allows for the use of existing quadcopter controllers and trajectory generation algorithms with only minimal added complexity. For our experimental vehicle at hover, we find that these constraints result in a 36\% reduction of the maximum yaw torque the vehicle can produce, but do not result in a reduction of the maximum thrust or roll and pitch torques. Experimental results show that, for a typical maneuver, the added limits have a negligible effect on the trajectory tracking performance. Finally, the ability to change configurations is shown to enable the vehicle to traverse small passages, perch on hanging wires, and perform limited grasping tasks.},
  archive      = {J_TROB},
  author       = {Nathan Bucki and Jerry Tang and Mark W. Mueller},
  doi          = {10.1109/TRO.2022.3193792},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {539-557},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design and control of a midair-reconfigurable quadcopter using unactuated hinges},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tombo propeller: Bioinspired deformable structure toward
collision-accommodated control for drones. <em>TROB</em>,
<em>39</em>(1), 521–538. (<a
href="https://doi.org/10.1109/TRO.2022.3198494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing need for vertical takeoff and landing vehicles, including drones, which are safe to use and can adapt to collisions. The risks of damage by collision, to humans, obstacles in the environment, and drones themselves, are significant. This has prompted a search into nature for a highly resilient structure that can inform a design of propellers to reduce those risks and enhance safety. Inspired by the flexibility and resilience of dragonfly wings, we propose a novel design for a biomimetic drone propeller called Tombo propeller. Here, we report on the design and fabrication process of this biomimetic propeller that can accommodate collisions and recover quickly, while maintaining sufficient thrust force to hover and fly. We describe the development of an aerodynamic model and experiments conducted to investigate performance characteristics for various configurations of the propeller morphology and related properties, such as generated thrust force, thrust force deviation, collision force, recovery time, lift-to-drag ratio, and noise. Finally, we design and showcase a control strategy for a drone equipped with Tombo propellers that collides in midair with an obstacle and recovers from collision continuing flying. The results show that the maximum collision force generated by the proposed Tombo propeller is less than two-thirds that of a traditional rigid propeller, which suggests the concrete possibility to employ deformable propellers for drones flying in a cluttered environment. This research can contribute to the morphological design of flying vehicles for agile and resilient performance.},
  archive      = {J_TROB},
  author       = {Son Tien Bui and Quan Khanh Luu and Dinh Quang Nguyen and Nhat Dinh Minh Le and Giuseppe Loianno and Van Anh Ho},
  doi          = {10.1109/TRO.2022.3198494},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {521-538},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tombo propeller: Bioinspired deformable structure toward collision-accommodated control for drones},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). An anthropomorphic robotic finger with innate
human-finger-like biomechanical advantages part II: Flexible tendon
sheath and grasping demonstration. <em>TROB</em>, <em>39</em>(1),
505–520. (<a href="https://doi.org/10.1109/TRO.2022.3200143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human hand has a fantastic ability to interact with various objects in the dynamic unstructured environment of our daily activities. We believe that this outstanding performance benefits a lot from the unique biological features of the hand musculoskeletal system. In Part I of this article, a bio-inspired anthropomorphic robotic finger was developed, based on which two human-finger-like biomechanical advantages were elaborately investigated, including the anisotropic variable stiffness associated with the ligamentous joints and the enlarged feasible force space associated with the reticular extensor mechanisms. In Part II, the fingertip force-velocity characteristics resulting from the flexible tendon sheath are studied. It indicates that the fingertip force–velocity workspace can be greatly augmented owing to the self-adaptive morphing of the flexible tendon sheaths, showing the average improvement of 41.2\% theoretically and 117.5\% experimentally compared with the results of 2 mm, 4 mm, and 6 mm size rigid tendon sheaths. Grasping tests and comparisons are then conducted with four three-fingered robotic hands (one with the robotic finger proposed in Part I, one with hinge joints, one with linear extensors, and one with rigid tendon sheaths) and the human hands of six subjects to handle various objects on flat, rough, and soft surfaces. The results show that the novel bio-inspired design in this research could improve the grasping success rates of the robotic hand. Compared with the grasping test results from the robotic hand with the bio-inspired robotic finger proposed in Part I, the overall grasping performance of a robotic hand with hinge joints, linear extensors, and rigid tendon sheaths decreases by 10\%, 6\%, and 17\%, respectively. The results have also shown that with the embedded biomechanical advantages, even without complex control and sensory systems, the robotic fingers can achieve very comparable performance to human fingers in the grasping demonstrations presented, indicating average 94\% of the success rate achieved by the human fingers. Successfully demonstrating 14 of 16 grasp types in the Cutkoskey taxonomy further shows the human-finger-like grasping capability of the proposed robotic fingers.},
  archive      = {J_TROB},
  author       = {Yiming Zhu and Guowu Wei and Lei Ren and Zirong Luo and Jianzhong Shang},
  doi          = {10.1109/TRO.2022.3200143},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {505-520},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An anthropomorphic robotic finger with innate human-finger-like biomechanical advantages part II: Flexible tendon sheath and grasping demonstration},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An anthropomorphic robotic finger with innate
human-finger-like biomechanical advantages part i: Design, ligamentous
joint, and extensor mechanism. <em>TROB</em>, <em>39</em>(1), 485–504.
(<a href="https://doi.org/10.1109/TRO.2022.3200006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring human hand fundamental biomechanical features and exploiting them to robotic hands have been proven to be an effective approach to enhancing artificial hands&#39; performance, especially when interacting with various objects in dynamic unstructured environments. In this article, a bioinspired anthropomorphic robotic finger is first proposed, which embeds human finger musculoskeletal features in the design. Based on this design, three human-finger-like biomechanical advantages are systematically investigated and embodied in the bioinspired robotic finger. This article for the first time derives, presents, and experimentally verifies the mathematical models for the variable stiffness of finger ligamentous joints and self-adaptive morphing mechanism of finger flexible tendon sheaths, and validates and compares the influence of the reticular and linear extensor morphologies on fingertip feasible forces in three-dimensional (3-D) space. In this Part I of the article, two of the biomechanical properties, i.e., joint stiffness generated by the ligamentous joint of the finger, and fingertip feasible force space influenced by the reticular extensor mechanism are systematically investigated through theoretical modeling and experimental verification. Correspondingly, two biomechanical advantages were found, i.e., the ligamentous joint of the finger could provide anisotropic variable joint stiffness, enhancing the adaptivity, dexterity, and stability of fingers; and a reticular extensor mechanism could enlarge the fingertip feasible force space in 3-D space by 30.9\% theoretically and 146.4\% experimentally on average compared with the linear extensor, contributing to enrich force conditions during interactions. The third biomechanical advantage, i.e., fingertip force–velocity workspace can be augmented through the flexible tendon sheath, and grasping tests for a robotic hand designed with the aforementioned advantages are presented in Part II of this article.},
  archive      = {J_TROB},
  author       = {Yiming Zhu and Guowu Wei and Lei Ren and Zirong Luo and Jianzhong Shang},
  doi          = {10.1109/TRO.2022.3200006},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {485-504},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An anthropomorphic robotic finger with innate human-finger-like biomechanical advantages part i: Design, ligamentous joint, and extensor mechanism},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of a new bio-inspired dual-axis compliant
micromanipulator with millimeter strokes. <em>TROB</em>, <em>39</em>(1),
470–484. (<a href="https://doi.org/10.1109/TRO.2022.3192778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes the concept design of a novel bio-inspired dual-axis compliant micromanipulator with millimeter working strokes dedicated to fiber alignment. It subtly mimics the gripping and rubbing function of human hand consisting of forefinger, purlicue, and thumb. As compared with traditional dual-axis gripper, its advantages lie in millimeter-level stroke, bidirectional rotation, less slippage, and comprehensive force sensing. To achieve dexterous and reliable manipulation, a two-degree of freedom flexible decoupling mechanism and a displacement reversing mechanism based on the leaf-shaped flexible hinge are introduced. Analytical models are derived to assess the statics and dynamics properties of the micromanipulator, which are verified by conducting finite-element analysis simulation study. A prototype driven by two voice coil motors is fabricated for experimental testing. Three high-precision strain gauges with temperature compensation are glued on the sensitive region to measure the gripping force and rubbing force. Experimental results show that the gripping stroke and rubbing stroke of the manipulator are up to 2.3 and 2.1 mm, respectively. For operating a custom-made fiber flag with a diameter of 200 $\mu$ m, a rotation stroke of more than 1000 $^{\circ }$ has been achieved, which cannot be realized by previous work with the same level of compact mechanism design.},
  archive      = {J_TROB},
  author       = {Zekui Lyu and Qingsong Xu},
  doi          = {10.1109/TRO.2022.3192778},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {470-484},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design of a new bio-inspired dual-axis compliant micromanipulator with millimeter strokes},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel actuation strategy for an agile bioinspired FWAV
performing a morphing-coupled wingbeat pattern. <em>TROB</em>,
<em>39</em>(1), 452–469. (<a
href="https://doi.org/10.1109/TRO.2022.3189812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flying vertebrates exhibit sophisticated wingbeat kinematics. Their specialized forelimbs allow for the wing morphing motion to couple with the flapping motion during their level flight. Previous flyable bionic platforms have successfully applied bioinspired wing morphing but cannot yet be propelled by the morphing-coupled wingbeat pattern. Spurred by this, we develop a bioinspired flapping-wing aerial vehicle entitled RoboFalcon, which is equipped with a novel mechanism to drive the bat-style morphing wings, performs a morphing-coupled wingbeat pattern, and overall manages an appealing flight. The novel mechanism of RoboFalcon allows coupling the morphing and flapping during level flight and decoupling these when maneuvering is required, producing a bilateral asymmetric downstroke affording high rolling agility. The bat-style morphing wing is designed with a tilted mounting angle around the radius at the wrist joint to mimic the wrist supination and pronation effect of flying vertebrates’ forelimbs. Wind tunnel tests indicate that the rolling moment of the asymmetric downstroke is correlated with the flapping frequency, and the wrist mounting angle can be used for tuning the angle of attack, lift-thrust configuration, and power consumption of the equilibrium flight state. The agility of RoboFalcon is assessed through several tethered rolling maneuvers and outdoor free flight tests, and we present a concise analysis of the vehicle&#39;s lateral dynamics model based on system identification. We believe that this article yields a well-performing bionic platform and provides a new actuation strategy for the morphing-coupled flapping flight.},
  archive      = {J_TROB},
  author       = {Ang Chen and Bifeng Song and Zhihe Wang and Dong Xue and Kang Liu},
  doi          = {10.1109/TRO.2022.3189812},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {452-469},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A novel actuation strategy for an agile bioinspired FWAV performing a morphing-coupled wingbeat pattern},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive helical rolling of a snake robot to a straight pipe
with irregular cross-sectional shape. <em>TROB</em>, <em>39</em>(1),
437–451. (<a href="https://doi.org/10.1109/TRO.2022.3189224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The snake robot, which mimics the mechanism of real snakes, is expected to be used in various environments. This article addresses the challenge of snake robots autonomously adapting to and moving inside and outside pipes having complex shapes using a helical rolling motion. We consider that an irregular helical form can be defined as a combination of three components, namely the axis, cross-sectional shape, and pitch angle, and that it is easier to consider deformations that have compliance only in a specific direction. Our proposed method deforms the cross-sectional shape of the snake robot locally so that it adopts the shape of the pipe accurately. Experiments were conducted using our developed snake robot to verify the effectiveness of the proposed method, and it was demonstrated that the proposed method can be used for a snake robot moving inside and outside of straight pipes and outdoor tree, including those having noncircular and varying cross sections.},
  archive      = {J_TROB},
  author       = {Tatsuya Takemori and Motoyasu Tanaka and Fumitoshi Matsuno},
  doi          = {10.1109/TRO.2022.3189224},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {437-451},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Adaptive helical rolling of a snake robot to a straight pipe with irregular cross-sectional shape},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global model learning for large deformation control of
elastic deformable linear objects: An efficient and adaptive approach.
<em>TROB</em>, <em>39</em>(1), 417–436. (<a
href="https://doi.org/10.1109/TRO.2022.3200546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robotic manipulation of deformable linear objects (DLOs) has broad application prospects in many fields. However, a key issue is to obtain the exact deformation models (i.e., how robot motion affects DLO deformation), which are hard to theoretically calculate and vary among different DLOs. Thus, the shape control of DLOs is challenging, especially for large deformation control that requires global and more accurate models. In this article, we propose a coupled offline and online data-driven method for efficiently learning a global deformation model, allowing for both accurate modeling through offline learning and further updating for new DLOs via online adaptation. Specifically, the model approximated by a neural network is first trained offline on random data, then seamlessly migrated to the online phase, and further updated online during actual manipulation. Several strategies are introduced to improve the model&#39;s efficiency and generalization ability. We propose a convex-optimization-based controller and analyze the system&#39;s stability using the Lyapunov method. Detailed simulations and real-world experiments demonstrate that our method can efficiently and precisely estimate the deformation model and achieve the large deformation control of untrained DLOs in 2-D and 3-D dual-arm manipulation tasks better than the existing methods. It accomplishes all 24 tasks with different desired shapes on different DLOs in the real world, using only simulation data for the offline learning.},
  archive      = {J_TROB},
  author       = {Mingrui Yu and Kangchen Lv and Hanzhong Zhong and Shiji Song and Xiang Li},
  doi          = {10.1109/TRO.2022.3200546},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {417-436},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Global model learning for large deformation control of elastic deformable linear objects: An efficient and adaptive approach},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft modular climbing robots. <em>TROB</em>, <em>39</em>(1),
399–416. (<a href="https://doi.org/10.1109/TRO.2022.3189228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft climbing robots have elicited widespread attention for their potential applications in inspection, maintenance, and search and rescue tasks. However, these robots face challenges in terms of their adaptability and motion capability in various surface environments, such as surfaces with a large gap or nonflat surfaces. In this article, we develop a soft modular climbing robot called Smcbot, which is assembled based on several soft bodies and feet modules. The soft body module provides large-scale telescopic motion and high output load through two soft actuators made of shape memory alloy wires. Meanwhile, the feet modules provide considerable adhesion on different surfaces due to the applied adhesive strategy. A theoretical model is also developed to predict the output performance (e.g., stiffness and output displacement) of the soft body, and the results are verified through experiments. The adaptability and motion capability of Smcbot is demonstrated on flat and nonflat surfaces with different properties, such as surfaces with a large gap and those with smooth and rough surfaces. This article uses the modular design to expand the application scope of soft climbing robots and to facilitate their adaption to various challenging environments with low time consumption and cost.},
  archive      = {J_TROB},
  author       = {Qiqiang Hu and Erbao Dong and Dong Sun},
  doi          = {10.1109/TRO.2022.3189228},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {399-416},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Soft modular climbing robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Power-based velocity-domain variable structure passivity
signature control for physical human-(tele)robot interaction.
<em>TROB</em>, <em>39</em>(1), 386–398. (<a
href="https://doi.org/10.1109/TRO.2022.3197932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The excess of passivity (EoP) of the human biomechanics plays an imperative role in absorbing the interaction energy during physical human–(tele)robot interaction and can be exploited by controllers used for stabilization of human-centered (tele)robotic systems. However, the first generation of nonlinear EoP-based stabilizers loaded the force reflection channel resulting in degradation of the force profile. This will challenge applications that are heavily dependent on the quality of force reflection, such as telerobotic rehabilitation. This article explores the possibility of developing a nonlinear stabilizer that modifies the reflected velocity to the follower-side operator based on the corresponding EoP map. As an applied benefit in the context of telerehabilitation, the proposed stabilizer does not require information about the EoP of all patients; instead, it would require that for the individual therapist who works with the group of patients. The article provides the mathematical derivation and stability proof of the nonlinear design of the stabilizer named “power-based velocity-domain variable structure passivity signature control (PV-VSPSC).” The proposed nonlinear stabilizer is evaluated through systematic experiments and systematic grid simulation studies in this paper.},
  archive      = {J_TROB},
  author       = {Peter Paik and Smrithi Thudi and S. Farokh Atashzar},
  doi          = {10.1109/TRO.2022.3197932},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {386-398},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Power-based velocity-domain variable structure passivity signature control for physical human-(Tele)Robot interaction},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-DoF exoskeleton haptic device for the grasping of a
compliant object adapting to a user’s motion using jamming transitions.
<em>TROB</em>, <em>39</em>(1), 373–385. (<a
href="https://doi.org/10.1109/TRO.2022.3192979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recently growing field of virtual reality, the virtual grasping sensation remains in its infancy, and the discrepancy between real and virtual grasping has become a problem. This article develops a new haptic glove that presents the sensation of different types of grasping (e.g., power/precision/intermediate grasping) a compliant object. To this end, we develop an exoskeleton that fixes the movements of fingers to present a braking force and a flexible pad that reproduces a wide range of stiffness. By applying the “string jamming mechanism,” our exoskeleton has functions that existing devices do not. In that, it constrains the motion of finger extension/flexion and adduction/abduction with only one actuator and presents the braking force to all surfaces of the finger. In addition, we propose a lightweight and compact variable-stiffness pad that reproduces an extensive stiffness range based on the layer jamming technique. We conducted experiments to evaluate the mechanical performance of the prototype integrating the exoskeleton and the variable-stiffness pad and demonstrated the usefulness of the proposed glove.},
  archive      = {J_TROB},
  author       = {Ryohei Michikawa and Takahiro Endo and Fumitoshi Matsuno},
  doi          = {10.1109/TRO.2022.3192979},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {373-385},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A multi-DoF exoskeleton haptic device for the grasping of a compliant object adapting to a user&#39;s motion using jamming transitions},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterizing multidimensional capacitive servoing for
physical human–robot interaction. <em>TROB</em>, <em>39</em>(1),
357–372. (<a href="https://doi.org/10.1109/TRO.2022.3190217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Toward the goal of robots performing robust and intelligent physical interactions with people, it is crucial that robots are able to accurately sense the human body, follow trajectories around the body, and track human motion. This study introduces a capacitive servoing control scheme that allows a robot to sense and navigate around human limbs during close physical interactions. Capacitive servoing leverages temporal measurements from a multielectrode capacitive sensor array mounted on a robot&#39;s end effector to estimate the relative position and orientation (pose) of a nearby human limb. Capacitive servoing then uses these human pose estimates from a data-driven pose estimator within a feedback control loop in order to maneuver the robot&#39;s end effector around the surface of a human limb. We provide a design overview of capacitive sensors for human–robot interaction and then investigate the performance and generalization of capacitive servoing through an experiment with 12 human participants. The results indicate that multidimensional capacitive servoing enables a robot&#39;s end effector to move proximally or distally along human limbs while adapting to human pose. Using a cross-validation experiment, results further show that capacitive servoing generalizes well across people with different body size.},
  archive      = {J_TROB},
  author       = {Zackory Erickson and Henry M. Clever and Vamsee Gangaram and Eliot Xing and Greg Turk and C. Karen Liu and Charles C. Kemp},
  doi          = {10.1109/TRO.2022.3190217},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {357-372},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Characterizing multidimensional capacitive servoing for physical Human–Robot interaction},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drivable space of rehabilitation robot for physical
human–robot interaction: Definition and an expanding method.
<em>TROB</em>, <em>39</em>(1), 343–356. (<a
href="https://doi.org/10.1109/TRO.2022.3189231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical human–robot interaction performance of present rehabilitation robots are still not satisfactory in the clinical practice. Especially, the work space where the robot can be driven smoothly by users is still very limited, which prevents rehabilitation robots from being applied successfully. In this study, a new concept of drivable space is proposed to evaluate the work spaces of rehabilitation robots, and a method for expanding the drivable space is designed based on the dynamics of the coupled human–robot system and human joint characteristics. First, the definition of drivable space is presented based on comparison of human joint torques, and the minimal torques necessary to drive robot joints, which is mainly determined by the torque estimation errors for general rehabilitation robots driven smoothly by motors. Therefore, a method for improving torque estimation accuracies based on dynamics modeling is then designed. A data-driven error prediction method based on Gaussian process regression is proposed to adaptively compensate the model errors, by which the most accurate dynamic model so far for the coupled system can be obtained, and a method for generation of the training dataset, which is used in error prediction, is designed as well. Moreover, the torque–angle relationship of human joints is modeled and used to optimize the torque error distribution, by which it can be proven that the drivable space can be further expanded. Finally, performance of the proposed methods are demonstrated and validated by experiments carried out on a lower limb rehabilitation robot.},
  archive      = {J_TROB},
  author       = {Weiqun Wang and Xu Liang and Shengda Liu and Tianyu Lin and Pu Zhang and Zhen Lv and Jiaxing Wang and Zeng-Guang Hou},
  doi          = {10.1109/TRO.2022.3189231},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {343-356},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Drivable space of rehabilitation robot for physical Human–Robot interaction: Definition and an expanding method},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning ergonomic control in human–robot symbiotic walking.
<em>TROB</em>, <em>39</em>(1), 327–342. (<a
href="https://doi.org/10.1109/TRO.2022.3192779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an imitation learning strategy for extracting ergonomically safe control policies in physical human–robot interaction scenarios. The presented approach seeks to proactively reduce the risk of injuries and musculoskeletal disorders by anticipating the ergonomic effects of a robot&#39;s actions on a human partner, e.g., how the ankle angle of a prosthesis affects future knee torques of the user. To this end, we extend ensemble Bayesian interaction primitives to enable the prediction of latent biomechanical variables. This methodology yields a reactive control strategy, which we evaluate in an assisted walking task with a robotic lower limb prosthesis. Building upon the learned interaction primitives, we also present a model-predictive control (MPC) strategy that actively steers the human–robot interaction toward ergonomic and safe movement regimes. We compare the introduced control strategies and highlight the framework&#39;s ability to generate ergonomic, biomechanically safe assistive prosthetic control. A rich analysis of constrained MPC shows a 20× reduction in the effects of large perturbations on prosthetic control system. We empirically demonstrate a 16\% reduction in vertical knee reaction forces in real-world jumping experiments utilizing our control methodology and examine other optimal control strategies in simulated walking experiments.},
  archive      = {J_TROB},
  author       = {Geoffrey Clark and Heni Ben Amor},
  doi          = {10.1109/TRO.2022.3192779},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {327-342},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning ergonomic control in Human–Robot symbiotic walking},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VILENS: Visual, inertial, lidar, and leg odometry for
all-terrain legged robots. <em>TROB</em>, <em>39</em>(1), 309–326. (<a
href="https://doi.org/10.1109/TRO.2022.3193788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present visual inertial lidar legged navigation system (VILENS), an odometry system for legged robots based on factor graphs. The key novelty is the tight fusion of four different sensor modalities to achieve reliable operation when the individual sensors would otherwise produce degenerate estimation. To minimize leg odometry drift, we extend the robot&#39;s state with a linear velocity bias term, which is estimated online. This bias is observable because of the tight fusion of this preintegrated velocity factor with vision, lidar, and inertial measurement unit (IMU) factors. Extensive experimental validation on different ANYmal quadruped robots is presented, for a total duration of 2 h and 1.8 km traveled. The experiments involved dynamic locomotion over loose rocks, slopes, and mud, which caused challenges such as slippage and terrain deformation. Perceptual challenges included dark and dusty underground caverns, and open and feature-deprived areas. We show an average improvement of 62\% translational and 51\% rotational errors compared to a state-of-the-art loosely coupled approach. To demonstrate its robustness, VILENS was also integrated with a perceptive controller and a local path planner.},
  archive      = {J_TROB},
  author       = {David Wisth and Marco Camurri and Maurice Fallon},
  doi          = {10.1109/TRO.2022.3193788},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {309-326},
  shortjournal = {IEEE Trans. Robot.},
  title        = {VILENS: Visual, inertial, lidar, and leg odometry for all-terrain legged robots},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynam-SLAM: An accurate, robust stereo visual-inertial SLAM
method in dynamic environments. <em>TROB</em>, <em>39</em>(1), 289–308.
(<a href="https://doi.org/10.1109/TRO.2022.3199087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing vision-based simultaneous localization and mapping (SLAM) systems and their variants still assume that the observation is absolutely static and cannot work well in dynamic environments. Here, we present the Dynam-SLAM (Dynam), a stereo visual-inertial SLAM system capable of robust, accurate, and continuous work in high dynamic environments. Our approach is devoted to loosely coupling the stereo scene flow with an inertial measurement unit (IMU) for dynamic feature detection and tightly coupling the dynamic and static features with the IMU measurements for nonlinear optimization. First, the scene flow uncertainty caused by measurement noise is modeled to derive the accurate motion likelihood of landmarks. Meanwhile, to cope with highly dynamic environments, we additionally construct the virtual landmarks based on the detected dynamic features. Then, we build a tightly coupled, nonlinear optimization-based SLAM system to estimate the camera state by fusing IMU measurements and feature observations. Finally, we evaluate the proposed dynamic feature detection module (DFM) and the overall SLAM system in various benchmark datasets. Experimental results show that the Dynam is almost unaffected by DFM and performs well in static EuRoC datasets. Dynam outperforms the current state-of-the-art visual and visual-inertial SLAM implementations in terms of accuracy and robustness in self-collected dynamic datasets. The average absolute trajectory error of Dynam in the dynamic benchmark datasets is $\sim$ 90\% lower than that of VINS-Fusion, $\sim$ 84\% lower than that of ORB-SLAM3, and $\sim$ 88\% lower than that of Kimera.},
  archive      = {J_TROB},
  author       = {Hesheng Yin and Shaomiao Li and Yu Tao and Junlong Guo and Bo Huang},
  doi          = {10.1109/TRO.2022.3199087},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {289-308},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Dynam-SLAM: An accurate, robust stereo visual-inertial SLAM method in dynamic environments},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SOFT2: Stereo visual odometry for road vehicles based on a
point-to-epipolar-line metric. <em>TROB</em>, <em>39</em>(1), 273–288.
(<a href="https://doi.org/10.1109/TRO.2022.3188121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate localization constitutes a fundamental building block of any autonomous system. In this article, we focus on stereo cameras and present a novel approach, dubbed SOFT2, that is currently the highest-ranking algorithm on the KITTI scoreboard. SOFT2 relies on the constraints imposed by the epipolar geometry and kinematics, i.e., it is developed for configurations that cannot exhibit pure rotation. We minimize point-to-epipolar-line distances, which makes the approach resilient to object depth uncertainty, and as the first step, we estimate motion up to scale using just a single camera. Then, we propose to jointly estimate the absolute scale and the extrinsic rotation of the second camera in order to alleviate the effects of varying stereo rig extrinsics. Finally, we smooth the motion estimates in a temporal window of frames by using the proposed epipolar line bundle adjustment procedure. We also introduce a multiple hypothesis feature-matching approach for self-similar planar surfaces that account for appearance change due to perspective. We evaluate SOFT2 and compare it to ORB-SLAM2, OV2SLAM, and VINS-FUSION on the KITTI-360 dataset, KITTI train sequences, Málaga Urban dataset, Oxford Robotics Car dataset, and Multivehicle Stereo Event Camera dataset.},
  archive      = {J_TROB},
  author       = {Igor Cvišić and Ivan Marković and Ivan Petrović},
  doi          = {10.1109/TRO.2022.3188121},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {273-288},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SOFT2: Stereo visual odometry for road vehicles based on a point-to-epipolar-line metric},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent physical attack against mobile robots with
obstacle-avoidance. <em>TROB</em>, <em>39</em>(1), 253–272. (<a
href="https://doi.org/10.1109/TRO.2022.3201394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The security issue of mobile robots has attracted considerable attention in recent years. In this article, we propose an intelligent physical attack to trap mobile robots into a preset position by learning the obstacle-avoidance mechanism from external observation. The salient novelty of our work lies in revealing the possibility that physical-based attacks with intelligent and advanced design can present real threats while without prior knowledge of the system dynamics or access to the internal system. This kind of attack cannot be handled by countermeasures in traditional cyberspace security. To practice, the cornerstone of the proposed attack is to actively explore the complex interaction characteristic of the victim robot with the environment and learn the obstacle-avoidance knowledge exhibited in the limited observations of its behaviors. Then, we propose shortest-path and hands-off attack algorithms to find efficient attack paths from the tremendous motion space, achieving the driving-to-trap goal with low costs in terms of path length and activity period, respectively. The convergence of the algorithms is proved and the attack performance bounds are further derived. Extensive simulations and real-life experiments illustrate the effectiveness of the proposed attack, beckoning future investigation for the new physical threats and defense on robotic systems.},
  archive      = {J_TROB},
  author       = {Yushan Li and Jianping He and Cailian Chen and Xinping Guan},
  doi          = {10.1109/TRO.2022.3201394},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {253-272},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Intelligent physical attack against mobile robots with obstacle-avoidance},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Long-horizon multi-robot rearrangement planning for
construction assembly. <em>TROB</em>, <em>39</em>(1), 239–252. (<a
href="https://doi.org/10.1109/TRO.2022.3198020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic construction assembly planning aims to find feasible assembly sequences as well as the corresponding robot-paths and can be seen as a special case of task and motion planning (TAMP). As construction assembly can well be parallelized, it is desirable to plan for multiple robots acting concurrently. Solving TAMP instances with many robots and over a long time-horizon is challenging due to coordination constraints, and the difficulty of choosing the right task assignment. We present a planning system which enables parallelization of complex task and motion planning problems by iteratively solving smaller subproblems. Combining optimization methods to jointly solve for manipulation constraints with a sampling-based bi-directional space-time path planner enables us to plan cooperative multi-robot manipulation with unknown arrival-times. Thus, our solver allows for completing subproblems and tasks with differing timescales and synchronizes them effectively. We demonstrate the approach on multiple construction case-studies to show the robustness over long planning horizons and scalability to many objects and agents. Finally, we also demonstrate the execution of the computed plans on two robot arms to showcase the feasibility in the real world.},
  archive      = {J_TROB},
  author       = {Valentin N. Hartmann and Andreas Orthey and Danny Driess and Ozgur S. Oguz and Marc Toussaint},
  doi          = {10.1109/TRO.2022.3198020},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {239-252},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Long-horizon multi-robot rearrangement planning for construction assembly},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-triggered coverage control for mobile sensors.
<em>TROB</em>, <em>39</em>(1), 223–238. (<a
href="https://doi.org/10.1109/TRO.2022.3197339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment and coordination of mobile sensor networks for coverage control applications can present several practical challenges, including how to efficiently share limited communication resources and how to reduce the use of localization devices (e.g., radars and lidars). One potential solution to these challenges is to reduce the frequency at which agents communicate or sample each other&#39;s position. In this article, we present a distributed asynchronous self-triggered control policy for centroidal Voronoi coverage control that is shown to decrease the sampling or communication instants among agents without degrading the performance of the mobile sensor network. Each agent independently decides when to sample the position of nearby agents and uses outdated information of its neighbors until new information is required. We prove that the locational cost function describing the distribution of agents monotonically decreases everywhere outside of a bounded neighborhood around the group&#39;s optimal configuration and that the agents asymptotically converge to their Voronoi centroids if the data-sampled centroid errors approach zero. In addition, we show that the sampling intervals are always positive and lower bounded and, as illustrated by simulations and experiments, they tend to stabilize at a large value as the mobile sensor network comes to a steady state. Simulations and experiments with ground vehicles validate the control strategy and show that the proposed policy can achieve similar level of performance as a continuous or fast periodic implementation.},
  archive      = {J_TROB},
  author       = {Erick J. Rodríguez-Seda and Xiaotian Xu and Josep M. Olm and Arnau Dòria-Cerezo and Yancy Diaz-Mercado},
  doi          = {10.1109/TRO.2022.3197339},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {223-238},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Self-triggered coverage control for mobile sensors},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trajectory optimization of chance-constrained nonlinear
stochastic systems for motion planning under uncertainty. <em>TROB</em>,
<em>39</em>(1), 203–222. (<a
href="https://doi.org/10.1109/TRO.2022.3197072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present generalized polynomial chaos-based sequential convex programming (gPC-SCP) to compute a suboptimal solution for a continuous-time chance-constrained stochastic nonlinear optimal control (SNOC) problem. The approach enables motion planning for robotic systems under uncertainty. The gPC-SCP method involves two steps. The first step is to derive a surrogate problem of deterministic nonlinear optimal control (DNOC) with convex constraints by using gPC expansion and the distributionally robust convex subset of the chance constraints. The second step is to solve the DNOC problem using sequential convex programming for trajectory generation and control. We prove that in the unconstrained case, the optimal value of the DNOC converges to that of SNOC asymptotically and that any feasible solution of the constrained DNOC is a feasible solution of the chance-constrained SNOC. We also present the predictor–corrector extension (gPC-SCP $^\text{PC}$ ) for real-time motion trajectory generation in the presence of stochastic uncertainty. In the gPC-SCP $^\text{PC}$ method, we first predict the uncertainty using the gPC method and then optimize the motion plan to accommodate the uncertainty. We empirically demonstrate the efficacy of the gPC-SCP and the gPC-SCP $^\text{PC}$ methods for the following two test cases: first, collision checking under uncertainty in actuation and physical parameters and second, collision checking with stochastic obstacle model for 3DOF and 6DOF robotic systems. We validate the effectiveness of the gPC-SCP method on the 3DOF robotic spacecraft testbed.},
  archive      = {J_TROB},
  author       = {Yashwanth Kumar Nakka and Soon-Jo Chung},
  doi          = {10.1109/TRO.2022.3197072},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {203-222},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Trajectory optimization of chance-constrained nonlinear stochastic systems for motion planning under uncertainty},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Direct collocation methods for trajectory optimization in
constrained robotic systems. <em>TROB</em>, <em>39</em>(1), 183–202. (<a
href="https://doi.org/10.1109/TRO.2022.3193776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct collocation methods are powerful tools to solve trajectory optimization problems in robotics. While their resulting trajectories tend to be dynamically accurate, they may also present large kinematic errors in the case of constrained mechanical systems, i.e., those whose state coordinates are subject to holonomic or nonholonomic constraints, such as loop-closure or rolling-contact constraints. These constraints confine the robot trajectories to an implicitly-defined manifold, which complicates the computation of accurate solutions. Discretization errors inherent to the transcription of the problem easily make the trajectories drift away from this manifold, which results in physically inconsistent motions that are difficult to track with a controller. This article reviews existing methods to deal with this problem and proposes new ones to overcome their limitations. Current approaches either disregard the kinematic constraints (which leads to drift accumulation) or modify the system dynamics to keep the trajectory close to the manifold (which adds artificial forces or energy dissipation to the system). The methods we propose, in contrast, achieve full drift elimination on the discrete trajectory, or even along the continuous one, without artificial modifications of the system dynamics. We illustrate and compare the methods using various examples of different complexity.},
  archive      = {J_TROB},
  author       = {Ricard Bordalba and Tobias Schoels and Lluís Ros and Josep M. Porta and Moritz Diehl},
  doi          = {10.1109/TRO.2022.3193776},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {183-202},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Direct collocation methods for trajectory optimization in constrained robotic systems},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sampling-based planning for retrieving near-cylindrical
objects in cluttered scenes using hierarchical graphs. <em>TROB</em>,
<em>39</em>(1), 165–182. (<a
href="https://doi.org/10.1109/TRO.2022.3191596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an incremental sampling-based task and motion planner for retrieving near-cylindrical objects, like bottle, in cluttered scenes, which computes a plan for removing obstacles to generate a collision-free motion of a robot to retrieve the target object. Our proposed planner uses a two-level hierarchy, including the first-level roadmap for the target object motion and the second-level retrieval graph for the entire robot motion, to aid in deciding the order and trajectory of object removal. We use an incremental expansion strategy to update the roadmap and retrieval graph from the collisions between the target object, the robot, and the obstacles, in order to optimize the object removal sequence. The performance of our method is highlighted in several benchmark scenes, including a fixed robotic arm in a cluttered scene with known obstacle locations and a scene, where locations of some objects or even the target object are unknown due to occlusions. Our method can also efficiently solve the high-dimensional planning problem of object retrieval using a mobile manipulator and be combined with the symbolic planner to plan complex multistep tasks. We deploy our method to a physical robot and integrate it with nonprehensile actions to improve operational efficiency. Compared to the state-of-the-art approaches, our method reduces task and motion planning time up to 24.6 $\%$ with a higher success rate, and still provides a near-optimal plan.},
  archive      = {J_TROB},
  author       = {Hao Tian and Chaoyang Song and Changbo Wang and Xinyu Zhang and Jia Pan},
  doi          = {10.1109/TRO.2022.3191596},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {165-182},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Sampling-based planning for retrieving near-cylindrical objects in cluttered scenes using hierarchical graphs},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic network topology prediction for active
planning: An adaptive algorithm and application. <em>TROB</em>,
<em>39</em>(1), 147–164. (<a
href="https://doi.org/10.1109/TRO.2022.3189223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article tackles the problem of active planning to achieve cooperative localization for multirobot systems under measurement uncertainty in GNSS-limited scenarios. Specifically, we address the issue of accurately predicting the probability of a future connection between two robots equipped with range-based measurement devices. Due to the limited range of the equipped sensors, edges in the network connection topology will be created or destroyed as the robots move with respect to one another. Accurately predicting the future existence of an edge, given imperfect state estimation and noisy actuation, is therefore a challenging task. An adaptive power series expansion (or APSE) algorithm is developed based on current estimates and control candidates. Such an algorithm applies the power series expansion formula of the quadratic positive form in a normal distribution. Finite-term approximation is made to realize the computational tractability. Further analyses are presented to show that the truncation error in the finite-term approximation can be theoretically reduced to a desired threshold by adaptively choosing the summation degree of the power series. Several sufficient conditions are rigorously derived as the selection principles. Finally, extensive simulation results and comparisons, with respect to both single and multirobot cases, validate that a formally computed and therefore more accurate probability of future topology can help improve the performance of active planning under uncertainty.},
  archive      = {J_TROB},
  author       = {Liang Zhang and Zexu Zhang and Roland Siegwart and Jen Jen Chung},
  doi          = {10.1109/TRO.2022.3189223},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {147-164},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Probabilistic network topology prediction for active planning: An adaptive algorithm and application},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scaling multimodal planning: Using experience and informing
discrete search. <em>TROB</em>, <em>39</em>(1), 128–146. (<a
href="https://doi.org/10.1109/TRO.2022.3197080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulation is inherently continuous, but typically has an underlying discrete structure, such as if an object is grasped. Many problems like these are multimodal , such as pick-and-place tasks where every object grasp and placement is a mode . Multimodal problems require finding a sequence of transitions between modes—for example, a particular sequence of object picks and placements. However, many multimodal planners fail to scale when motion planning is difficult (e.g., in clutter) or the task has a long horizon (e.g., rearrangement). This work presents solutions for multimodal scalability in both these areas. For motion planning, we present an experience-based planning framework alef which reuses experience from similar modes both online and from training data. For task satisfaction, we present a layered planning approach that uses a discrete lead to bias search toward useful mode transitions, informed by weights over mode transitions. Together, these contributions enable multimodal planners to tackle complex manipulation tasks that were previously infeasible or inefficient, and provide significant improvements in scenes with high-dimensional robots.},
  archive      = {J_TROB},
  author       = {Zachary Kingston and Lydia E. Kavraki},
  doi          = {10.1109/TRO.2022.3197080},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {128-146},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Scaling multimodal planning: Using experience and informing discrete search},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient path planning in narrow passages for robots with
ellipsoidal components. <em>TROB</em>, <em>39</em>(1), 110–127. (<a
href="https://doi.org/10.1109/TRO.2022.3187818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning has long been one of the major research areas in robotics, with probabilistic roadmap (PRM) and rapidly-exploring random trees (RRT) being two of the most effective classes of planners. Though generally very efficient, these sampling-based planners can become computationally expensive in the important case of “narrow passages.” This article develops a path planning paradigm specifically formulated for narrow passage problems. The core is based on planning for rigid-body robots encapsulated by unions of ellipsoids. Each environmental feature is represented geometrically using a strictly convex body with a $\mathcal {C}^{1}$ boundary (e.g., superquadric). The main benefit of doing this is that configuration-space obstacles can be parameterized explicitly in closed form, thereby allowing prior knowledge to be used to avoid sampling infeasible configurations. Then, by characterizing a tight volume bound for multiple ellipsoids, robot transitions involving rotations are guaranteed to be collision free without needing to perform traditional collision detection. Furthermore, by combining with a stochastic sampling strategy, the proposed planning framework can be extended to solving higher dimensional problems, in which the robot has a moving base and articulated appendages. Benchmark results show that the proposed framework often outperforms the sampling-based planners in terms of computational time and success rate in finding a path through narrow corridors for both single-body robots and those with higher dimensional configuration spaces. Physical experiments using the proposed framework are further demonstrated on a humanoid robot that walks in several cluttered environments with narrow passages.},
  archive      = {J_TROB},
  author       = {Sipu Ruan and Karen L. Poblete and Hongtao Wu and Qianli Ma and Gregory S. Chirikjian},
  doi          = {10.1109/TRO.2022.3187818},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {110-127},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Efficient path planning in narrow passages for robots with ellipsoidal components},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time robust receding horizon planning using
hamilton–jacobi reachability analysis. <em>TROB</em>, <em>39</em>(1),
90–109. (<a href="https://doi.org/10.1109/TRO.2022.3187291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety guarantee prior to the deployment of robots can be difficult due to unexpected disturbances in runtime. This article presents a real-time receding-horizon robust trajectory planning algorithm for nonlinear closed-loop systems, which guarantees the safety of the system under unknown but bounded disturbances. We characterize the forward reachable sets (FRSs) of the system based on the Hamilton–Jacobi reachability analysis as a means for safety verification. For the online computation of the FRSs, we approximate nonlinear systems as LTV systems with linearization errors and compute ellipsoids that encompass the FRSs in continuous time. Using the proposed ellipsoidal approximation of the FRSs, we formulate a computationally tractable robust planning problem that can be solved online. Consequently, the proposed method enables real-time replanning of a reference trajectory with safety guarantees even when the system encounters unexpected disturbances in runtime. The flight experiment of obstacle avoidance in a windy environment validates the proposed robust planning algorithm.},
  archive      = {J_TROB},
  author       = {Hoseong Seo and Donggun Lee and Clark Youngdong Son and Inkyu Jang and Claire J. Tomlin and H. Jin Kim},
  doi          = {10.1109/TRO.2022.3187291},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {90-109},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Real-time robust receding horizon planning using Hamilton–Jacobi reachability analysis},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model predictive interaction control for robotic
manipulation tasks. <em>TROB</em>, <em>39</em>(1), 76–89. (<a
href="https://doi.org/10.1109/TRO.2022.3196607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the concept of model predictive interaction control (MPIC) as a generic, flexible, and comprehensive approach for robotic manipulation tasks. MPIC is based on the repetitive solution of an optimal control problem that includes a robot model for motion prediction as well as an interaction model for force prediction. In order to handle both elastic and rigid contact situations, a cascaded approach with low-level PD control is adopted, which allows to combine the linear-elastic environment model and the limited controller stiffness. Due to its flexibility, MPIC can be favorably used for realizing the elementary manipulation primitives (MP) within a hierarchical task planning framework, where each MP corresponds to a particular parameterization of the cost function and the constraints. The control methodology and the manipulation approach are evaluated in simulations and experiments using a 7-degree-of-freedom industrial robot.},
  archive      = {J_TROB},
  author       = {Tobias Gold and Andreas Völz and Knut Graichen},
  doi          = {10.1109/TRO.2022.3196607},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {76-89},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Model predictive interaction control for robotic manipulation tasks},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enabling visual action planning for object manipulation
through latent space roadmap. <em>TROB</em>, <em>39</em>(1), 57–75. (<a
href="https://doi.org/10.1109/TRO.2022.3188163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a framework for visual action planning of complex manipulation tasks with high-dimensional state spaces, focusing on manipulation of deformable objects. We propose a latent space roadmap (LSR) for task planning, which is a graph-based structure globally capturing the system dynamics in a low-dimensional latent space. Our framework consists of the following three parts. First, a mapping module (MM) that maps observations is given in the form of images into a structured latent space extracting the respective states as well as generates observations from the latent states. Second, the LSR, which builds and connects clusters containing similar states in order to find the latent plans between start and goal states, extracted by MM. Third, the action proposal module that complements the latent plan found by the LSR with the corresponding actions. We present a thorough investigation of our framework on simulated box stacking and rope/box manipulation tasks, and a folding task executed on a real robot.},
  archive      = {J_TROB},
  author       = {Martina Lippi and Petra Poklukar and Michael C. Welle and Anastasia Varava and Hang Yin and Alessandro Marino and Danica Kragic},
  doi          = {10.1109/TRO.2022.3188163},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {57-75},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Enabling visual action planning for object manipulation through latent space roadmap},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). POMDP planning under object composition uncertainty:
Application to robotic manipulation. <em>TROB</em>, <em>39</em>(1),
41–56. (<a href="https://doi.org/10.1109/TRO.2022.3188168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulating unknown objects in a cluttered environment is difficult because segmentation of the scene into objects, that is, object composition, is uncertain. Due to the uncertainty, prior work has either identified the “best” object composition and decided on manipulation actions accordingly or tried to greedily gather information about the “best” object composition. We instead, first, use different possible object compositions in planning, second, utilize object composition information provided by robot actions, third, consider the effect of competing object hypotheses on the desired task. We cast the manipulation planning problem as a partially observable Markov decision process (POMDP) that plans over possible object composition hypotheses. The POMDP chooses the action that maximizes long-term expected task-specific utility, and while doing so, considers informative actions and the effect of different object hypotheses on succeeding in the task. In simulation and physical robotic experiments, a probabilistic approach outperforms using the most likely object composition, and long term planning outperforms greedy decision making.},
  archive      = {J_TROB},
  author       = {Joni Pajarinen and Jens Lundell and Ville Kyrki},
  doi          = {10.1109/TRO.2022.3188168},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {41-56},
  shortjournal = {IEEE Trans. Robot.},
  title        = {POMDP planning under object composition uncertainty: Application to robotic manipulation},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partially observable markov decision processes in robotics:
A survey. <em>TROB</em>, <em>39</em>(1), 21–40. (<a
href="https://doi.org/10.1109/TRO.2022.3200138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noisy sensing, imperfect control, and environment changes are defining characteristics of many real-world robot tasks. The partially observable Markov decision process (POMDP) provides a principled mathematical framework for modeling and solving robot decision and control tasks under uncertainty. Over the last decade, it has seen many successful applications, spanning localization and navigation, search and tracking, autonomous driving, multirobot systems, manipulation, and human–robot interaction. This survey aims to bridge the gap between the development of POMDP models and algorithms at one end and application to diverse robot decision tasks at the other. It analyzes the characteristics of these tasks and connects them with the mathematical and algorithmic properties of the POMDP framework for effective modeling and solution. For practitioners, the survey provides some of the key task characteristics in deciding when and how to apply POMDPs to robot tasks successfully. For POMDP algorithm designers, the survey provides new insights into the unique challenges of applying POMDPs to robot systems and points to promising new directions for further research.},
  archive      = {J_TROB},
  author       = {Mikko Lauri and David Hsu and Joni Pajarinen},
  doi          = {10.1109/TRO.2022.3200138},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {21-40},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Partially observable markov decision processes in robotics: A survey},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms and systems for manipulating multiple objects.
<em>TROB</em>, <em>39</em>(1), 2–20. (<a
href="https://doi.org/10.1109/TRO.2022.3197013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot manipulation of multiple objects is an important topic for applications including warehouse automation, service robots performing cleaning, and large-scale object sorting. Although problems can range in complexity from a few objects to large disordered piles, autonomy remains a significant technical challenge due to the high-dimensional joint configuration space of the robot and all objects, the complex dynamics of object interaction, and the ambiguity and occlusion caused by clutter. This article surveys a broad range of classical and state-of-the-art research in multiobject manipulation and categorizes them along the dimensions of tasks, perception, predictive models, and decision-making algorithms. It also covers emerging trends and open problems faced in the ongoing effort to realize robust multiobject manipulation systems in practice.},
  archive      = {J_TROB},
  author       = {Zherong Pan and Andy Zeng and Yunzhu Li and Jingjin Yu and Kris Hauser},
  doi          = {10.1109/TRO.2022.3197013},
  journal      = {IEEE Transactions on Robotics},
  number       = {1},
  pages        = {2-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Algorithms and systems for manipulating multiple objects},
  volume       = {39},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
