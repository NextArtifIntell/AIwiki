<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmc---492">TMC - 492</h2>
<ul>
<li><details>
<summary>
(2023). Interference-aware mobile backscatter communication: A
PHY-assisted rate adaptive approach. <em>TMC</em>, <em>22</em>(12),
7498–7508. (<a href="https://doi.org/10.1109/TMC.2022.3214533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, backscatter nodes have received booming interest for many emerging mobile applications, such as sports analytics and interactive gaming. However, backscatter networks are not ready to provide a high-throughput and stable communication platform for billions of such mobile nodes due to two main factors in rate adaptation. First, the common mapping paradigm that chooses the optimal rate based on RSSIs is hardly adaptable to hardware diversity. Second, the current probing processes are not optimized for mobile scenarios due to inefficient probing trigger, inaccurate channel estimation, and unique self-interference. To address those issues, we propose MobiRate, a mobility-aware rate adaptation link-layer that fully exploits the mobility hints from PHY information to deliver a high-throughput link-layer for mobile backscatter networks. The key insight is that mobility-hints can greatly benefit link-layer design, including rate selection and channel probing. Specifically, we introduce a novel velocity-based loss-rate estimation module, a mobility-assisted probing trigger, a selective probing module, and a robust self-interference detection module, significantly saving probing time and improving probing accuracy. As MobiRate is fully compatible with the current standard, we prototype it using COTS RFID readers and commercial tags. Our extensive experiments demonstrate that MobiRate can successfully identify self-interference with detection accuracy over 90% for tags of different velocities. Moreover, it achieves up to 3.8x throughput gain over the state-of-the-art methods across a wide range of mobility, channel conditions, and tag types.},
  archive      = {J_TMC},
  author       = {Si Chen and Wei Gong and Jiangchuan Liu and Zhi Wang and Jia Zhao},
  doi          = {10.1109/TMC.2022.3214533},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7498-7508},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Interference-aware mobile backscatter communication: A PHY-assisted rate adaptive approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). (&lt;Inline-formula&gt;&lt;tex-math
notation=“LaTeX”&gt;<span
class="math inline"><em>k</em>, <em>α</em></span>&lt;/tex-math&gt;&lt;mml:math
xmlns:mml=“http://www.w3.org/1998/math/MathML”&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic
xlink:href=“hu-ieq1-3212902.gif”
xmlns:xlink=“http://www.w3.org/1999/xlink”/&gt;&lt;/inline-formula&gt;)-coverage
for RIS-aided mmWave directional communication. <em>TMC</em>,
<em>22</em>(12), 7482–7497. (<a
href="https://doi.org/10.1109/TMC.2022.3212902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfigurable intelligent surface (RIS) offers a new way to provide controllable non line-of-sight (NLoS) propagation paths for millimeter-wave (mmWave) directional communication to overcome the performance degradation caused by line-of-sight blockage. However, current coverage models do not consider the impact of path direction difference on path&#39;s availability, which is a crucial property of mmWave directional communication network. In the article, we propose a new coverage model called &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(k,\alpha)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -coverage. A receiver is &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(k,\alpha)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -covered if it is covered by at least &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; RISs to have &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; different NLoS path directions and the angular separation between any two adjacent path directions is at least &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\alpha$&lt;/tex-math&gt;&lt;/inline-formula&gt; . In this case, when the current communication direction is blocked by an obstacle, other RIS created paths are still likely to be available for transmission, which increases the robustness of mmWave directional communication. To tackle the problem of using the least number of RISs to achieve the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(k,\alpha)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -coverage, we formally define the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(k,\alpha)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -coverage models and propose methods to verify if the target area is &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(k,\alpha)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -covered by the given set of RISs. Then, we solve the problem under both deterministic and random RIS deployment schemes. For the deterministic deployment scheme, we derive the optimal &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -sided regular polygon deployment patterns and use it to achieve area &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(k,\alpha)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -coverage. An analytical performance bound on the number of RISs needed is also derived. For the random RIS deployment scheme, we derive the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(k,\alpha)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -coverage probability under uniform and spatial-Poisson RIS distributions. Finally, extensive simulation results are provided to validate our analyses.},
  archive      = {J_TMC},
  author       = {Xueyang Hu and Tian Liu and Tao Shu},
  doi          = {10.1109/TMC.2022.3212902},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7482-7497},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {(&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k,\alpha$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;hu-ieq1-3212902.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt;)-coverage for RIS-aided mmWave directional communication},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Back-guard: Wireless backscattering based user sensing with
parallel attention model. <em>TMC</em>, <em>22</em>(12), 7466–7481. (<a
href="https://doi.org/10.1109/TMC.2022.3215012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advance of wireless sensing techniques, it becomes possible to provide a fine-grained user activity tracking service at home and office. Such a technique is of broad applications in various domains such as personal activity diary, elderly care, and customized services. For example, several radio frequency (RF) based sensing systems were recently proposed for human activity recognition. However, most of them focused on specific scenarios and suffered from interference caused by other users and wireless devices. In this work, we propose Back-Guard, a backscattering-based sensing system that achieves accurate and non-intrusive user activity recognition and further user identification/authentication. Back-Guard carefully examines the backscatter spectrogram data and extracts high-level features from both spatial and temporal domains. Leveraging the parallel attention based deep learning model, our system can discriminate different motions and users accurately and robustly in various situations. We implemented a prototype system and collected data from 25 users for more than 2 months. Extensive experiments demonstrate that Back-Guard achieves 93.4 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; activity recognition accuracy and 91.5 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; user identification accuracy, respectively. In particular, Back-Guard can also tackle multiple user scenarios, which has little accuracy reduction when the users are separated, e.g., by around 2 meters.},
  archive      = {J_TMC},
  author       = {Xiang-Yang Li and Manjiang Yin and Yanyong Zhang and Panlong Yang and Chengchen Wan and Xing Guo and Haisheng Tan},
  doi          = {10.1109/TMC.2022.3215012},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7466-7481},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Back-guard: Wireless backscattering based user sensing with parallel attention model},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy efficient federated learning over heterogeneous
mobile devices via joint design of weight quantization and wireless
transmission. <em>TMC</em>, <em>22</em>(12), 7451–7465. (<a
href="https://doi.org/10.1109/TMC.2022.3213766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a popular collaborative distributed machine learning paradigm across mobile devices. However, practical FL over resource constrained mobile devices confronts multiple challenges, e.g., the local on-device training and model updates in FL are power hungry and radio resource intensive for mobile devices. To address these challenges, in this paper, we attempt to take FL into the design of future wireless networks and develop a novel joint design of wireless transmission and weight quantization for energy efficient FL over mobile devices. Specifically, we develop flexible weight quantization schemes to facilitate on-device local training over heterogeneous mobile devices. Based on the observation that the energy consumption of local computing is comparable to that of model updates, we formulate the energy efficient FL problem into a mixed-integer programming problem where the quantization and spectrum resource allocation strategies are jointly determined for heterogeneous mobile devices to minimize the overall FL energy consumption (computation + transmissions) while guaranteeing model performance and training latency. Since the optimization variables of the problem are strongly coupled, an efficient iterative algorithm is proposed, where the bandwidth allocation and weight quantization levels are derived. Extensive simulations are conducted to verify the effectiveness of the proposed scheme.},
  archive      = {J_TMC},
  author       = {Rui Chen and Liang Li and Kaiping Xue and Chi Zhang and Miao Pan and Yuguang Fang},
  doi          = {10.1109/TMC.2022.3213766},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7451-7465},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy efficient federated learning over heterogeneous mobile devices via joint design of weight quantization and wireless transmission},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy trading and power allocation strategies for
relay-assisted smart grid communications: A three-stage game approach.
<em>TMC</em>, <em>22</em>(12), 7438–7450. (<a
href="https://doi.org/10.1109/TMC.2022.3211408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smart grid, serious packet loss often occurs in the process of information interaction between the Utilities and customers, which results in supply-demand deviation and further increases the cost of the Utilities. In order to improve the information transmission performance of communication networks, the Utilities purchase relay service from telecom operator to help data aggregator units (DAU) transfer information to gateway (GW), so as to improve communication quality and reduce the cost of the Utilities. Second, in order to solve the problem of telecom operators’ energy reduction and reduce the cost of purchasing energy, we utilize energy supply point (ESP) to collect the surplus energy of retail customers for energy supply, and telecom operator pays a certain amount of remuneration to ESP in exchange for ESP to continuously supply energy to telecom operator. Then, we establish a three-stage game method and system model between the Utilities, telecom operator and ESP, and propose the relay power allocation and energy transaction pricing strategy. Due to the real-time change of energy demand, we consider two situations of energy oversupply and conservative supply, and use the backward induction method and iterative algorithm to obtain the equilibrium solution of the Stackelberg game, including the unit energy price of ESP, total power of telecom operator, the proportion of transmission power allocated to the relay service, and payment scheme of the Utilities. Simulation results show that the proposed algorithm can quickly and accurately converge to the optimal solution of the problem, and the method can improve the stability of demand-side regulation, reduce the cost of the Utilities and increase the profit of telecom operator.},
  archive      = {J_TMC},
  author       = {Jie Yang and Yajing Zhang and Yazhou Yuan and Kai Ma and Jianbo Li},
  doi          = {10.1109/TMC.2022.3211408},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7438-7450},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy trading and power allocation strategies for relay-assisted smart grid communications: A three-stage game approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coalitional formation-based group-buying for UAV-enabled
data collection: An auction game approach. <em>TMC</em>,
<em>22</em>(12), 7420–7437. (<a
href="https://doi.org/10.1109/TMC.2022.3211447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) enable promising solutions in assisting data collection in wide-area distributed sensor networks, leveraging their advanced properties of high mobility and line-of-sight communication links. However, existing UAV-assisted data collection methods mainly focus on unilaterally maximizing the utility of UAVs or sensors. Unfortunately, the problem driven by the market economy is ignored, namely the game between buyer and seller, in the process of sensors competing for UAV services. To address this problem, we propose a group-buying coalition auction method that encourages sensors to form coalitions to bid for UAV data collection services. Then, a parallel variable neighborhood ascent search algorithm is designed to quickly search the approximately optimal group-buying coalition structure. We further propose a novel group-buying coalition auction method, named TRUST, which can ensure the economical properties, i.e., truthfulness, individual rationality, and maximization of social welfare. Numerical results show that the sensors’ average age of information (AoI) under the proposed method is reduced by 16.7% and 44.5% compared with the coalition formation game (CFG) and joint trajectory design-task scheduling (TDTS) UAV-to-community methods. To our best knowledge, this is the first effort on truthful coalition formation-based group-buying auction.},
  archive      = {J_TMC},
  author       = {Nan Qi and Zanqi Huang and Wen Sun and Shi Jin and Xiang Su},
  doi          = {10.1109/TMC.2022.3211447},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7420-7437},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Coalitional formation-based group-buying for UAV-enabled data collection: An auction game approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OCVC: An overlapping-enabled cooperative vehicular fog
computing protocol. <em>TMC</em>, <em>22</em>(12), 7406–7419. (<a
href="https://doi.org/10.1109/TMC.2022.3211882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increasing time-critical and computation-intensive tasks generated by mobile applications, vehicular fog computing (VFC) has emerged as a promising solution to relieve the overload on roadside units (RSUs) or cloud centers. In VFC, tasks are offloaded to vehicular fog nodes local to the client devices, which exploits the under-explored computational resources of nearby vehicles. In this article, we propose a novel cooperative vehicular fog computing architecture from an overlapping perspective, termed Overlapping-enabled Cooperative Vehicular fog Computing (OCVC) to fully utilize vehicular fog nodes’ local potential resources. Different from traditional cooperative VFC architecture where each vehicle only works in one fog computing group at one time, the proposed OCVC architecture enables vehicles to participate in different computing groups simultaneously, and thus is able to fully exploit potential computational resources in an overlapping manner. In addition, we provide a distributed OCVC scheme to solve the complicated computing group formation, overlapping resource allocation, and task assignment problem by employing the overlapping coalition formation (OCF) game framework and a heuristic offloading algorithm. We conduct simulations for performance comparison in terms of diversified performance metrics and numerical results show that the proposed OCVC scheme performs better than other benchmarks under different conditions.},
  archive      = {J_TMC},
  author       = {Zhiwei Wei and Bing Li and Rongqing Zhang and Xiang Cheng and Liuqing Yang},
  doi          = {10.1109/TMC.2022.3211882},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7406-7419},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {OCVC: An overlapping-enabled cooperative vehicular fog computing protocol},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary multi-objective reinforcement learning based
trajectory control and task offloading in UAV-assisted mobile edge
computing. <em>TMC</em>, <em>22</em>(12), 7387–7405. (<a
href="https://doi.org/10.1109/TMC.2022.3208457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the trajectory control and task offloading (TCTO) problem in an unmanned aerial vehicle (UAV)-assisted mobile edge computing system, where a UAV flies along a planned trajectory to collect computation tasks from smart devices (SDs). We consider a scenario that SDs are not directly connected by the base station (BS) and the UAV has two roles to play: MEC server or wireless relay. The UAV makes task offloading decisions online, in which the collected tasks can be executed locally on the UAV or offloaded to the BS for remote processing. The TCTO problem involves multi-objective optimization as its objectives are to minimize the task delay and the UAV&#39;s energy consumption, and maximize the number of tasks collected by the UAV, simultaneously. This problem is challenging because the three objectives conflict with each other. The existing reinforcement learning (RL) algorithms, either single-objective RLs or single-policy multi-objective RLs, cannot well address the problem since they cannot output multiple policies for various preferences (i.e., weights) across objectives in a single run. An evolutionary multi-objective RL (EMORL) algorithm is applied to address the TCTO problem. We improve the multi-task multi-objective proximal policy optimization of the original EMORL by retaining all new learning tasks in the offspring population, which can preserve promissing learning tasks. The simulation results demonstrate that the proposed algorithm can obtain more excellent non-dominated policies by striking a balance between the three objectives regarding policy quality, compared with two evolutionary algorithms, two multi-policy RL algorithms, and the original EMORL.},
  archive      = {J_TMC},
  author       = {Fuhong Song and Huanlai Xing and Xinhan Wang and Shouxi Luo and Penglin Dai and Zhiwen Xiao and Bowen Zhao},
  doi          = {10.1109/TMC.2022.3208457},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7387-7405},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Evolutionary multi-objective reinforcement learning based trajectory control and task offloading in UAV-assisted mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When virtual network operator meets e-commerce platform:
Advertising via data reward. <em>TMC</em>, <em>22</em>(12), 7370–7386.
(<a href="https://doi.org/10.1109/TMC.2022.3208229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In China, some e-commerce platform (EP) companies such as Alibaba and JD are now allowed to partner with network operators (NOs) to act as virtual network operators (VNOs) to provide mobile data services for mobile users (MUs). However, it is a question worth researching on how to generate more profits for all network players, with EP companies being VNOs, through appropriate integration of the VNO business and the companies’ own e-commerce business. To address this issue, in this work we propose a novel incentive mechanism for advertising via mobile data reward, and model it as a three-stage static Stackelberg game. We obtain the closed-form optimal solution of the Nash equilibrium by backward induction. Besides, for the scenario lack of knowledge on the interaction between the NO and VNO in a dynamic game, we propose a deep Q-network (DQN) based algorithm to derive the optimal strategies of the NO and VNO. Simulation results show impact of system parameters on the utilities of game players and social welfare. We also study the impact of system parameters on different algorithms and discover that the proposed DQN-based algorithm can learn a good strategy as compared with the Stackelberg equilibrium solution.},
  archive      = {J_TMC},
  author       = {Qi Cheng and Hangguan Shan and Weihua Zhuang and Tony Q. S. Quek and Zhaoyang Zhang and Fen Hou},
  doi          = {10.1109/TMC.2022.3208229},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7370-7386},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {When virtual network operator meets E-commerce platform: Advertising via data reward},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Towards domain-independent and real-time gesture
recognition using mmWave signal. <em>TMC</em>, <em>22</em>(12),
7355–7369. (<a href="https://doi.org/10.1109/TMC.2022.3207570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human gesture recognition using millimeter-wave (mmWave) signals provides attractive applications including smart home and in-car interfaces. While existing works achieve promising performance under controlled settings, practical applications are still limited due to the need of intensive data collection, extra training efforts when adapting to new domains, and poor performance for real-time recognition. In this article, we propose DI-Gesture, a domain-independent and real-time mmWave gesture recognition system. Specifically, we first derive signal variations corresponding to human gestures with spatial-temporal processing. To enhance the robustness of the system and reduce data collecting efforts, we design a data augmentation framework for mmWave signals based on correlations between signal patterns and gesture variations. Furthermore, a spatial-temporal gesture segmentation algorithm is employed for real-time recognition. Extensive experimental results show DI-Gesture achieves an average accuracy of 97.92%, 99.18%, and 98.76% for new users, environments, and locations, respectively. We also evaluate DI-Gesture in challenging scenarios like real-time recognition and sensing at extreme angles, all of which demonstrates the superior robustness and effectiveness of our system.},
  archive      = {J_TMC},
  author       = {Yadong Li and Dongheng Zhang and Jinbo Chen and Jinwei Wan and Dong Zhang and Yang Hu and Qibin Sun and Yan Chen},
  doi          = {10.1109/TMC.2022.3207570},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7355-7369},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards domain-independent and real-time gesture recognition using mmWave signal},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locally adaptive status updating for optimizing age of
information in poisson networks. <em>TMC</em>, <em>22</em>(12),
7343–7354. (<a href="https://doi.org/10.1109/TMC.2022.3209663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a homogeneous Poisson bipolar network in which the bipoles represent source-destination pairs. The source nodes need to update their destinations about the new status perpetually, and the communications are taken place over a shared spectrum. The common goal of the source nodes is to minimize the network-wide age of information (AoI). We develop a policy by which every source node can adapt its frequency of generating status updates in a local and decentralized manner. At the same time, the network average AoI is minimized by reducing interference amongst transmitters located in geographical proximity. Following this policy, we also derive mathematical expressions to characterize the distribution of the optimal updating rate at each source node, the network average AoI, and the AoI violation probability, i.e., the probability that the AoI of a typical source node exceeds an age threshold. The analytical results are combined with discrete event simulations to provide a detailed evaluation of the performance of the proposed scheme. Particularly, it is shown that our policy is able to adaptively adjust the updating rate of each source node according to the variant of the network topology. In this manner, it is instrumental in decreasing both the network average AoI and AoI violation probability. Additionally, the scheme can maintain the AoI at a low level even when the network grows in size.},
  archive      = {J_TMC},
  author       = {Howard H. Yang and Meiyan Song and Chao Xu and Xijun Wang and Tony Q. S. Quek},
  doi          = {10.1109/TMC.2022.3209663},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7343-7354},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Locally adaptive status updating for optimizing age of information in poisson networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time and accurate gesture recognition with commercial
RFID devices. <em>TMC</em>, <em>22</em>(12), 7327–7342. (<a
href="https://doi.org/10.1109/TMC.2022.3211324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture recognition based on radio frequency identification (RFID) has attracted much research attention in recent years. Most existing RFID-based gesture recognition approaches use signal profile matching to distinguish different gestures, which incur large recognition latency and fail to support real-time applications. In this article, we design and implement ReActor, a real-time and accurate gesture recognition system that recognizes a user&#39;s gestures with low latency and high accuracy even when the gestures’speed varies. ReActor combines the time-domain statistical features and the frequency-domain features to precisely represent the signal profile corresponding to different gestures. To maintain high accuracy across different environments, we preprocess the signals to remove reflection signals from surrounding objects and use only the signals related to gestures to train the classifier. Moreover, we train a classifier to predict the speed of the gesture and feed the extracted features to different classifiers according to the speed. We implement ReActor and evaluate its performance in different scenarios. Experimental results show that ReActor achieves an average accuracy of 97.2% in recognizing 18 different gestures with an average latency of 72 ms, more than two orders of magnitude faster than approaches based on profile template matching.},
  archive      = {J_TMC},
  author       = {Shigeng Zhang and Zijing Ma and Chengwei Yang and Xiaoyan Kui and Xuan Liu and Weiping Wang and Jianxin Wang and Song Guo},
  doi          = {10.1109/TMC.2022.3211324},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7327-7342},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Real-time and accurate gesture recognition with commercial RFID devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RF-ear&lt;inline-formula&gt;&lt;tex-math
notation=“LaTeX”&gt;<span
class="math inline"><sup>+</sup></span>&lt;/tex-math&gt;&lt;/inline-formula&gt;:
A mechanical identification and troubleshooting system based on
contactless vibration sensing. <em>TMC</em>, <em>22</em>(12), 7310–7326.
(<a href="https://doi.org/10.1109/TMC.2022.3210150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical vibration monitoring plays a critical role in today&#39;s industrial Internet of Things (IoT) applications. Existing invasive solutions usually directly attach sensors to the target, which may affect the operations of delicate devices. Non-invasive video-based approaches incur poor performance in low light conditions, and laser-based ones have difficulties to monitor multiple objects simultaneously. In this work, we propose RF-Ear&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow/&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;feng-ieq2-3210150.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt; , a contactless vibration sensing system using Commercial off-the-shelf (COTS) RFID. RF-Ear&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow/&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;feng-ieq3-3210150.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt; could accurately monitor the mechanical vibrations of multiple devices using a single tag: it can clearly tell which object is vibrating at what frequency without attaching tags on any device. RF-Ear&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow/&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;feng-ieq4-3210150.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt; can measure the vibration with a frequency up to 987 Hz at a mean error rate of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$0.4\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; . We further employ each device&#39;s unique vibration fingerprint to identify and differentiate devices of exactly the same model. What&#39;s more, RF-Ear&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:msup&gt;&lt;mml:mrow/&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;feng-ieq6-3210150.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt; can detect the rotating machinery faults based on the constructed spectrogram, which achieves &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$98\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; accuracy on 6 types of states. To improve the computation efficiency, we optimize the input of model in both time and frequency domains, and thus enable deployment on low-cost edge devices successfully. Comprehensive experiments conducted in lab and wild demonstrate the effectiveness of our system.},
  archive      = {J_TMC},
  author       = {Yuanhao Feng and Youwei Zhang and Panlong Yang and Hao Zhou and Haohua Du and Xiang-Yang Li},
  doi          = {10.1109/TMC.2022.3210150},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7310-7326},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RF-ear&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;/inline-formula&gt;: A mechanical identification and troubleshooting system based on contactless vibration sensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). A large-scale measurement and optimization of mobile live
streaming services. <em>TMC</em>, <em>22</em>(12), 7294–7309. (<a
href="https://doi.org/10.1109/TMC.2022.3208094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Live Streaming (MLS) services are one of the most popular types of mobile apps. They involve a (often amateur) user broadcasting content to a potentially large online audience via unreliable networks. Nevertheless, we still lack a deep understanding of MLS user behavior that is critical for optimizing MLS systems, despite some active measurements on viewer-side behavior. Using detailed logs obtained from a major MLS provider, this paper first conducts an in-depth measurement study of both viewer-side and broadcaster-side behavior. Key findings include large wasteful uploads, strong viewing locality, and traffic dominance of loyal viewers. Specifically, 33.3% of uploads go unwatched, and the viewership of broadcasters tends to be localized. Inspired by our findings, we propose EdgeOpt – a centralized control center for MLS services for optimizing both the first-mile and the last-mile transmission in MLS. Specifically, EdgeOpt reduces wasteful uploading by 71% through adaptive uploading and enhances the replay quality of popular video segments by 10% via highlights retransmission. EdgeOpt also uses a learning-based content pre-fetching scheme that boosts the viewing startup by 29.5% and offloads at most 80% of the viewing workload from the edge servers with peer-assisted delivery.},
  archive      = {J_TMC},
  author       = {Zhenyu Li and Jinyang Li and Qinghua Wu and Gareth Tyson and Gaogang Xie},
  doi          = {10.1109/TMC.2022.3208094},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7294-7309},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A large-scale measurement and optimization of mobile live streaming services},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online edge computing demand response via deadline-aware V2G
discharging auctions. <em>TMC</em>, <em>22</em>(12), 7279–7293. (<a
href="https://doi.org/10.1109/TMC.2022.3208420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed edge computing systems that participate in emergency demand response (EDR) programs can adjust workload across heterogenous edges to reduce total energy consumption. Unfortunately, this approach may not always reduce sufficient energy as required by EDR. In this article, we propose to leverage Electrical Vehicles (EVs) and Vehicle-to-Grid (V2G) techniques to provide energy to the edge system, and design an auction mechanism to incentivize EVs to discharge energy for the edges. Yet, we face critical challenges, such as the uncertainty of EV bid arrivals, the restriction of discharging deadlines, and the desire to achieve required economic efficiency. To overcome such challenges, we design a novel online approach, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$E^{3}$&lt;/tex-math&gt;&lt;/inline-formula&gt; DR, of multiple algorithms that decompose our original NP-hard social cost minimization problem into two subproblems, solve the first subproblem via reformulation, the primal-dual optimization theory, and a careful payment design, and solve the second subproblem via standard solvers. We have rigorously proved that our approach finishes in polynomial time, achieves truthfulness and individual rationality economically, and leads to a parameterized competitive ratio for the long-term social cost. Through extensive evaluations using real-world data traces, we have validated the superior practical performance of our approach compared to existing algorithms.},
  archive      = {J_TMC},
  author       = {Fei Wang and Lei Jiao and Konglin Zhu and Lin Zhang},
  doi          = {10.1109/TMC.2022.3208420},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7279-7293},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online edge computing demand response via deadline-aware V2G discharging auctions},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HearMe: Accurate and real-time lip reading based on
commercial RFID devices. <em>TMC</em>, <em>22</em>(12), 7266–7278. (<a
href="https://doi.org/10.1109/TMC.2022.3208019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lip reading can help people with speech disorders to communicate with others and provide them with a new channel to interact with the world. In this paper, we design and implement HearMe , an accurate and real-time lip-reading system built on commercial radio frequency identification (RFID) devices. HearMe can be used to accurately recognize different words in a pre-defined vocabulary without limitations in light conditions and can be used in multiple user scenarios by leveraging RFID&#39;s ability in identifying different users. We design an effective data collection strategy to well capture the tiny and complex signal patterns caused by mouth motion and propose a set of algorithms to extract signal profiles related to mouth motions and mitigate interference factors like multi-path. A carefully designed set of features, including time-domain statistical features and frequency-domain features, are then extracted from the signal to lift the recognition accuracy at the word level. To reduce training costs when the model is used in a new environment, a transfer-learning-based approach is adopted to enhance the robustness of the model in cross-environment scenarios. Experimental results show that HearMe detects speaking actions of the user with an accuracy higher than 0.95 and recognizes different words in a 20-words vocabulary with an average accuracy higher than 0.88. Moreover, the latency of HearMe ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 150 ms) is nearly two orders of magnitude less than traditional approaches, making it applicable to practical scenarios that require real-time lip reading.},
  archive      = {J_TMC},
  author       = {Shigeng Zhang and Zijing Ma and Kaixuan Lu and Xuan Liu and Jia Liu and Song Guo and Albert Y. Zomaya and Jian Zhang and Jianxin Wang},
  doi          = {10.1109/TMC.2022.3208019},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7266-7278},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HearMe: Accurate and real-time lip reading based on commercial RFID devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MCore+: A real-time design achieving ∼ 500 μs scheduling for
5G MU-MIMO systems. <em>TMC</em>, <em>22</em>(12), 7249–7265. (<a
href="https://doi.org/10.1109/TMC.2022.3207160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-User (MU)-MIMO technology plays a vital role in 5G NR. Under MU-MIMO transmission, multiple users can share the same time-frequency resources simultaneously. For 5G MU-MIMO systems, it is challenging to design a scheduler. The scheduler needs to determine resource block (RB) allocation, the number of data streams and modulation and coding scheme (MCS) for each user in each transmission time interval (TTI). In particular, multiple users can be co-scheduled on the same RB for MU-MIMO transmission. In addition, it is necessary for the scheduler to find a scheduling solution within each TTI to be useful. In this paper, we present mCore &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$+$&lt;/tex-math&gt;&lt;/inline-formula&gt; , a novel design and implementation that can achieve &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 500 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu$&lt;/tex-math&gt;&lt;/inline-formula&gt; s timing performance for 5G MU-MIMO systems. mCore &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$+$&lt;/tex-math&gt;&lt;/inline-formula&gt; is meticulously designed with a multi-phase optimization and heavily leverages large-scale parallel computation. In each phase, mCore &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$+$&lt;/tex-math&gt;&lt;/inline-formula&gt; either decomposes the optimization problem into a number of independent sub-problems, or reduces the search space into a smaller but most promising subspace, or both. mCore &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$+$&lt;/tex-math&gt;&lt;/inline-formula&gt; is validated on a commercial-off-the-shelf GPU platform. Experimental results show that mCore &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$+$&lt;/tex-math&gt;&lt;/inline-formula&gt; can offer a scheduling solution in &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 500 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu$&lt;/tex-math&gt;&lt;/inline-formula&gt; s for up to 100 RBs, 100 users, 29 MCS levels and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$4 \times 12$&lt;/tex-math&gt;&lt;/inline-formula&gt; MIMO systems. Also, mCore &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$+$&lt;/tex-math&gt;&lt;/inline-formula&gt; can achieve better or comparable throughput performance compared to other state-of-the-art algorithms.},
  archive      = {J_TMC},
  author       = {Yongce Chen and Yubo Wu and Y. Thomas Hou and Wenjing Lou},
  doi          = {10.1109/TMC.2022.3207160},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7249-7265},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MCore+: A real-time design achieving ∼ 500 μs scheduling for 5G MU-MIMO systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Learning from images: Proactive caching with parallel
convolutional neural networks. <em>TMC</em>, <em>22</em>(12), 7234–7248.
(<a href="https://doi.org/10.1109/TMC.2022.3207209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous trend of data explosion, delivering packets from data servers to end users causes increased stress on both the fronthaul and backhaul traffic of mobile networks. To mitigate this problem, caching popular content closer to the end-users has emerged as an effective method for reducing network congestion and improving user experience. To find the optimal locations for content caching, many conventional approaches construct various Mixed Integer Linear Programming (MILP) models. However, such methods may fail to support online decision making due to the inherent curse of dimensionality. In this paper, a novel framework for proactive caching is proposed. This framework merges model-based optimization with data-driven techniques by transforming an optimization problem into a grayscale image. For parallel training and simple design purposes, the proposed MILP model is first decomposed into a number of sub-problems and, then, Convolutional Neural Networks (CNNs) are trained to predict content caching locations of these sub-problems. Furthermore, since the MILP model decomposition neglects the network resources (such as caching space and link bandwidth) competition among sub-problems, the CNNs’ outputs have the risk to be infeasible solutions. Therefore, two algorithms are provided: the first uses predictions from CNNs as an extra constraint to reduce the number of decision variables; the second employs CNNs’ outputs to accelerate local search. Numerical results show that the proposed scheme can reduce &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$71.6\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; computation time, whose computation time reaches around 28.9ms, with only &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$0.8\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; additional performance cost compared to the MILP solution, which provides high quality decision making in pseudo real-time.},
  archive      = {J_TMC},
  author       = {Yantong Wang and Ye Hu and Zhaohui Yang and Walid Saad and Kai-Kit Wong and Vasilis Friderikos},
  doi          = {10.1109/TMC.2022.3207209},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7234-7248},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Learning from images: Proactive caching with parallel convolutional neural networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Admission control and scheduling of isochronous traffic with
guard time in IEEE 802.11ad MAC. <em>TMC</em>, <em>22</em>(12),
7218–7233. (<a href="https://doi.org/10.1109/TMC.2022.3207969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An upsurge of low latency and bandwidth hungry applications such as virtual reality, augmented reality and availability of unlicensed spectrum in the millimeter wave band at 60 GHz have led to standardization of the new generation WiFi systems such as IEEE 802.11ad and 802.11ay. Due to the stringent Quality of Service requirement of those applications, IEEE 802.11ad/ay have introduced contention free channel access called Service Period . One type of user traffic supported by IEEE 802.11ad is isochronous traffic, which is essentially periodic traffic that requires certain channel time to be allocated before its period ends. In an earlier work, we presented three Admission Control Algorithms (ACAs) which admit isochronous requests to achieve the above goals. One of these ACAs, the proportional fair allocation admission control (PFAAC), offers the best tradeoff across different performance metrics. But it did not consider guard time (GT) overhead, which is essential in a practical system. In this paper, we present two methods to compute upper bounds on GT overhead. We evaluate performance of the modified PFAAC with the two methods and PFAAC with no GT overhead. The modified PFAAC with the method that uses a tighter upper bound on GT overhead, provides the best performance.},
  archive      = {J_TMC},
  author       = {Anirudha Sahoo and Weichao Gao and Tanguy Ropitault and Nada Golmie},
  doi          = {10.1109/TMC.2022.3207969},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7218-7233},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Admission control and scheduling of isochronous traffic with guard time in IEEE 802.11ad MAC},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed estimation and control for jamming an aerial
target with multiple agents. <em>TMC</em>, <em>22</em>(12), 7203–7217.
(<a href="https://doi.org/10.1109/TMC.2022.3207589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a distributed estimation and control approach in which a team of aerial agents equipped with radio jamming devices collaborate in order to intercept and concurrently track-and-jam a malicious target, while at the same time minimizing the induced jamming interference amongst the team. Specifically, it is assumed that the malicious target maneuvers in 3D space, avoiding collisions with obstacles and other 3D structures in its way, according to a stochastic dynamical model. Based on this, a track-and-jam control approach is proposed which allows a team of distributed aerial agents to decide their control actions online, over a finite planning horizon, to achieve uninterrupted radio-jamming and tracking of the malicious target, in the presence of jamming interference constraints. The proposed approach is formulated as a distributed model predictive control (MPC) problem and is solved using mixed integer quadratic programming (MIQP). Extensive evaluation of the system&#39;s performance validates the applicability of the proposed approach in challenging scenarios with uncertain target dynamics, noisy measurements, and in the presence of obstacles.},
  archive      = {J_TMC},
  author       = {Savvas Papaioannou and Panayiotis Kolios and Georgios Ellinas},
  doi          = {10.1109/TMC.2022.3207589},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7203-7217},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed estimation and control for jamming an aerial target with multiple agents},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). InFit: Combination movement recognition for intensive
fitness assistant via wi-fi. <em>TMC</em>, <em>22</em>(12), 7188–7202.
(<a href="https://doi.org/10.1109/TMC.2022.3209656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi technology is becoming a promising enabler of device-free fitness tracking to provide reviews and recommendations for effective homely exercise. State-of-the-art Wi-Fi fitness assistants succeed in recognizing the simple meta-movements (e.g., Push-Up and Squat) with discrete and repeatable patterns. Unfortunately, these prior attempts can hardly scale to the combination movements of ever-growing interests in intensive fitness programs. Combination movements are composed of meta-movements that are mutually concatenated or inserted. They have a compound characteristic that inherits from the diversity of combination orders and continuity of meta-movements. The compound characteristic causes substantial training data collection costs and a challenge of combination decomposition that is a prerequisite for providing fine-grained fitness assessment. To this end, we propose InFit , a Wi-Fi-based device-free fitness assistant system for combination movements. First, we design a novel data augmentation method, namely Stitching-based Virtual Sample Generation (SVSG), to reduce the training data collection costs by generating virtual combination movements. Second, a 2-stage combination movement recognition model is designed to learn temporal dependencies between movements and decompose combination movements. From its outputs, we can tell whether a combination movement is standard. Extensive experimental results show that InFit can achieve an average recognition accuracy of 94%. With zero training samples of combination movements, the average accuracy is 40% higher than the baselines. In addition, SVSG can provide a general enhancement on multiple competing schemes with similar sensing tasks.},
  archive      = {J_TMC},
  author       = {Huichuwu Li and Jiang Xiao and Wei Wang and Lu Wang and Dian Zhang and Hai Jin},
  doi          = {10.1109/TMC.2022.3209656},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7188-7202},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {InFit: Combination movement recognition for intensive fitness assistant via wi-fi},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Face-based authentication using computational secure sketch.
<em>TMC</em>, <em>22</em>(12), 7172–7187. (<a
href="https://doi.org/10.1109/TMC.2022.3207830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric features are quite suitable for identity authentication due to its inherent properties – universality, uniqueness and persistence. In fact, biometric authentication has been widely used in our daily life, especially in mobile devices. However, biometric features are quite sensitive, and once a feature is leaked to an evil adversary, it cannot be used in authentication any more. This leads to a push on research of biometric privacy protection. In this paper, we propose a face-based authentication system with the help of a computational secure sketch. The computational secure sketch takes charge of error tolerance on the face samplings. Then the face features of the same user are used to extract an authentication key, which is in turn used to do the identity authentication for the user. The computational security of the computational secure sketch makes sure that the public information obtained by the adversary does not affect the pseudorandomness of the authentication key, hence the privacy of face features is guaranteed. Moreover, the privacy protection technique in our face-based authentication system can be extended to other biometric-based authentication.},
  archive      = {J_TMC},
  author       = {Mingming Jiang and Shengli Liu and You Lyu and Yu Zhou},
  doi          = {10.1109/TMC.2022.3207830},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7172-7187},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Face-based authentication using computational secure sketch},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards impact of chunk-level characteristics on mobile live
streaming performance. <em>TMC</em>, <em>22</em>(12), 7156–7171. (<a
href="https://doi.org/10.1109/TMC.2022.3207591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, mobile live streaming is gaining a rapid growth in use, which refers to watching the media content recorded and broadcast in real time on mobile devices. In live streaming process, each video segment must go through recording, encoding, uploading, transcoding, publishing, downloading, decoding before playback. The ingest algorithm inside the streamer decides the upload bitrate, while the adaptive bitrate (ABR) algorithm inside the player determines the download bitrate. Thanks to the chunked Common Media Application Format (CMAF) standard, each segment is split into smaller chunks that can be independently encoded, transferred, decoded and played. It is of great help to quantify the impact of chunk-level characteristics on mobile live streaming performance. In this article, we establish a tandem queuing model to describe the whole streaming system. Based on the model, we respectively characterize rebuffering probability, rebuffering count, streaming latency, and average bitrate, analyzing the impact of chunk upload and download rates, upload and download time variances, startup threshold and chunk length on them. From analysis results, we propose insights and recommendations for bitrate adaptation in mobile live streaming and design simple heuristic ingest and ABR algorithms leveraging them. Extensive simulations verify the insights as well as effectiveness of designed algorithms.},
  archive      = {J_TMC},
  author       = {Tong Zhang and Zhewei Tang and Jiakun Bao and Fengyuan Ren},
  doi          = {10.1109/TMC.2022.3207591},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7156-7171},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards impact of chunk-level characteristics on mobile live streaming performance},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LEAP: TrustZone based developer-friendly TEE for intelligent
mobile apps. <em>TMC</em>, <em>22</em>(12), 7138–7155. (<a
href="https://doi.org/10.1109/TMC.2022.3207745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ARM TrustZone is widely deployed on commercial-off-the-shelf mobile devices for secure execution. However, many Apps cannot enjoy this feature because it brings many constraints to App developers. Previous works have been proposed to build a secure execution environment for developers on top of TrustZone. Unfortunately, these works are still not fully-fledged solutions for mobile Apps, especially for emerging intelligent Apps. To this end, we propose LEAP, which is a lightweight developer-friendly TEE solution for mobile Apps. LEAP enables isolated codes to execute in parallel and access peripheral (e.g., mobile GPUs) with ease, flexibly manages system resources upon different workloads, and offers the auto DevOps tool to help developers prepare the codes running on it. We implement the LEAP prototype on the off-the-shelf ARM platform and conduct extensive experiments on it. The experimental results show that Apps can be adapted to run with LEAP easily and efficiently. Compared to the state-of-the-art work along this research line, LEAP can achieve an average 3.57× speedup in supporting intelligent Apps using mobile GPU acceleration.},
  archive      = {J_TMC},
  author       = {Lizhi Sun and Shuocheng Wang and Hao Wu and Yuhang Gong and Fengyuan Xu and Yunxin Liu and Hao Han and Sheng Zhong},
  doi          = {10.1109/TMC.2022.3207745},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7138-7155},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {LEAP: TrustZone based developer-friendly TEE for intelligent mobile apps},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal pricing design for coordinated and uncoordinated IoT
networks. <em>TMC</em>, <em>22</em>(12), 7121–7137. (<a
href="https://doi.org/10.1109/TMC.2022.3208153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An Internet of Things (IoT) system can include several different types of service providers, who sell IoT service, network service, and computation service to customers, either jointly or separately. A deep understanding of complicated coupling among these providers in terms of pricing and service decisions is critical to the success of IoT networks. This paper studies the impact of the provider interaction structures on the overall IoT system with heterogeneous customers. Specifically, we first study a generic IoT scenario with three interaction structures: coordinated, vertically-uncoordinated, and horizontally-uncoordinated structures. Despite the challenging non-convex optimization problems involved in modeling and analyzing these structures, we successfully obtain the closed-form optimal pricing strategies of providers in each interaction structure. We further extend the analysis to a specific IoT scenario with local computation capability (e.g., Internet of Vehicles (IoV)). We prove that the coordinated structure is better than two uncoordinated structures for both providers and customers, as it avoids selfish price markup behaviors in uncoordinated structures. Between the two uncoordinated structures, when customers’ demand variance is large and utility-cost ratio is medium, vertically-uncoordinated structure is better than horizontal one for both providers and customers, due to the complementary providers’ competition in horizontally-uncoordinated structure. Counter-intuitively, we identify that providers’ optimal prices do not change with their costs at the critical point of customers’ full participation in the vertically-uncoordinated structure.},
  archive      = {J_TMC},
  author       = {Ningning Ding and Lin Gao and Jianwei Huang},
  doi          = {10.1109/TMC.2022.3208153},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7121-7137},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal pricing design for coordinated and uncoordinated IoT networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GREEN: A global energy efficiency maximization strategy for
multi-UAV enabled communication systems. <em>TMC</em>, <em>22</em>(12),
7104–7120. (<a href="https://doi.org/10.1109/TMC.2022.3207791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the scenario of limited energy supply, unmanned aerial vehicles (UAVs) enabled communication systems must make efficient use of energy in order to provide long-term service. In this paper, we propose a global energy efficiency maximization (GREEN) strategy for multi-UAV enabled communication systems. In such systems, a group of UAVs communicates with their associated ground terminals (GTs) by using a UAV-enabled interference channel (UAV-IC). In particular, we optimize the UAVs’ trajectory control by jointly considering both the communication throughput and the total energy consumption of the whole system. We aim to maximize the global energy efficiency (GEE) of a task for multi-UAV communications, in which the problem is challenging to optimally solve due to its non-convex nature and strongly coupled variables. To tackle this problem, first, we investigate and propose a global energy-efficient optimization problem based on the fly-hover-communicate protocol. Second, we extend our proposed solution from the single UAV-enabled system to multiple UAV-GT pairs cases. In addition, we consider the general scenario in which the UAVs also communicate while flying. Based on the successive convex approximation technique and the path discretization method, the GREEN strategy is designed for optimizing UAV trajectories in this scenario. The simulation results show that the proposed strategy can achieve significantly higher GEE than the benchmark schemes for multi-UAV enabled communications.},
  archive      = {J_TMC},
  author       = {Na Lin and Yanbo Fan and Liang Zhao and Xiaoming Li and Mohsen Guizani},
  doi          = {10.1109/TMC.2022.3207791},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7104-7120},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {GREEN: A global energy efficiency maximization strategy for multi-UAV enabled communication systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visible light integrated positioning and communication: A
multi-task federated learning framework. <em>TMC</em>, <em>22</em>(12),
7086–7103. (<a href="https://doi.org/10.1109/TMC.2022.3207164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, visible light positioning and visible light communication are becoming a promising technology for integrated sensing and communication. However, the isolated design of positioning and communication has limited the system efficiency and performance. In this article, a visible light integrated positioning and communication (VIPAC) framework is formulated, in which the positioning task for the sensing service and the channel estimation task for the communication service are integrated into a unified architecture. First, a multi-task learning architecture, which is composed of a sparsity-aware shared network and two task-oriented sub-networks, is proposed to fully exploit the inherent sparse features of visible light channels, and achieve mutual benefits between the two tasks. The depth of the shared network can be adaptively adjusted to extract the optimal shared features, and the two sub-networks are further optimized for the two tasks, respectively. Moreover, the emerging federated learning technique is introduced to devise a multi-user cooperative VIPAC scheme, which further improves the generalization ability in spatiotemporally nonstationary environments while preserving data privacy. It is shown by theoretical analysis and simulation results that, the proposed scheme can significantly improve the performance of positioning and channel estimation in spatiotemporally nonstationary environments compared with existing benchmark schemes.},
  archive      = {J_TMC},
  author       = {Tiankuo Wei and Sicong Liu and Xiaojiang Du},
  doi          = {10.1109/TMC.2022.3207164},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7086-7103},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Visible light integrated positioning and communication: A multi-task federated learning framework},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). &lt;Inline-formula&gt;&lt;tex-math notation=“LaTeX”&gt;<span
class="math inline"><code>R</code><code>a</code><code>d</code><code>a</code><code>r</code></span>&lt;/tex-math&gt;&lt;/inline-formula&gt;:
Adversarial driving style representation learning with data
augmentation. <em>TMC</em>, <em>22</em>(12), 7070–7085. (<a
href="https://doi.org/10.1109/TMC.2022.3208265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characterizing human driver&#39;s driving behaviors from global positioning system (GPS) trajectories is an important yet challenging trajectory mining task. Previous works heavily rely on high-quality GPS data to learn such driving style representations through deep neural networks. However, they have overlooked the driving contexts that greatly govern drivers’ driving activities and the data sparsity issue of practical GPS trajectories collected at a low-sampling rate. Besides, existing works omit the cold start problem, where the newly joined drivers usually have insufficient data to learn accurate driving style representations. To address these limitations, we present an adversarial driving style representation learning approach, named &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {Radar}$&lt;/tex-math&gt;&lt;/inline-formula&gt; . In addition to summarizing statistic features from raw GPS data, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {Radar}$&lt;/tex-math&gt;&lt;/inline-formula&gt; also extracts contextual features from three aspects of road condition, geographic semantic, and traffic condition. We exploit the advanced semi-supervised generative adversarial networks to construct our learning model. By jointly considering statistic features and contextual features, the trained model is able to efficiently learn driving style representations from practical GPS trajectory data. Furthermore, we enhance &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {Radar}$&lt;/tex-math&gt;&lt;/inline-formula&gt; &#39;s representation learning for drivers owning limited training data with some basic data augmentation strategies and a novel auxiliary driver based data augmentation method. Experiments on two benchmark applications, i.e., driver identification and driver number estimation, with a large real-world GPS trajectory dataset demonstrate that &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {Radar}$&lt;/tex-math&gt;&lt;/inline-formula&gt; can outperform the state-of-the-art approaches by learning more effective and accurate driving style representations.},
  archive      = {J_TMC},
  author       = {Zhidan Liu and Junhong Zheng and Jinye Lin and Liang Wang and Kaishun Wu},
  doi          = {10.1109/TMC.2022.3208265},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7070-7085},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {Radar}$&lt;/tex-math&gt;&lt;/inline-formula&gt;: Adversarial driving style representation learning with data augmentation},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Budget-aware user satisfaction maximization on service
provisioning in mobile edge computing. <em>TMC</em>, <em>22</em>(12),
7057–7069. (<a href="https://doi.org/10.1109/TMC.2022.3205427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) promises to provide mobile users with delay-sensitive services at the edge of network, and each user service request usually is associated with a Service Function Chain (SFC) requirement that consists of Virtualized Network Functions (VNFs) in order. The satisfaction of a user on his requested service is heavily impacted by the service reliability. In this article, we study user satisfaction on services provided by an MEC network through introducing a submodular function based metric to measure user satisfaction. We first formulate a novel user satisfaction problem with the aim to maximize the accumulative user satisfaction, assuming that all available computing resource in the MEC network can be used for service reliability enhancement. We show that the problem is NP-hard, and devise an approximation algorithm with a provable approximation ratio for it. We then consider the problem under a given computing resource budget constraint, for which we devise an approximation algorithm with a provable approximation ratio, at the expense of moderate budget violations. We finally evaluate the performance of the proposed algorithms through experimental simulations. Simulation results demonstrate that the proposed algorithms outperform the comparison baseline algorithms, improving the performance by more 16.1% in comparison with the baseline algorithms.},
  archive      = {J_TMC},
  author       = {Jing Li and Weifa Liang and Wenzheng Xu and Zichuan Xu and Xiaohua Jia and Albert Y. Zomaya and Song Guo},
  doi          = {10.1109/TMC.2022.3205427},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7057-7069},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Budget-aware user satisfaction maximization on service provisioning in mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised association of wi-fi probe requests under
MAC address randomization. <em>TMC</em>, <em>22</em>(12), 7044–7056. (<a
href="https://doi.org/10.1109/TMC.2022.3205924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi-on devices such as smartphones search for network availability by periodically broadcasting probe requests which encapsulate MAC addresses as device identifiers. To protect identity privacy, modern devices embed random MAC addresses in probe frames, the so-called MAC address randomization. Such randomization disrupts the frame association, inadvertently frustrating identity-oblivious statistical analytic efforts such as people counting and trajectory inference. To address that, we propose Cappuccino , a novel privacy-preserving approach that captures the association of probe requests under MAC address randomization. Cappuccino first estimates pairwise frame correlation and then associates frames over time. For frame correlation, it employs a self-supervised estimator that jointly considers multiple modalities, i.e., information elements, sequence number, and received signal strength. For multiple frame association, Cappuccino formulates frames as a minimum-cost flow optimization. To the best of our knowledge, this is the first piece of work that leverages self-supervised learning to estimate frame correlation based on multiple modalities and formulates the probe request association problem as the network flow optimization. We have conducted extensive experiments in a leading and crowded shopping mall for more than three months. Cappuccino achieves remarkable performance in terms of V-measure scores ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$&amp;gt;0.85$&lt;/tex-math&gt;&lt;/inline-formula&gt; ).},
  archive      = {J_TMC},
  author       = {Tianlang He and Jiajie Tan and S.-H. Gary Chan},
  doi          = {10.1109/TMC.2022.3205924},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7044-7056},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Self-supervised association of wi-fi probe requests under MAC address randomization},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Age-optimal scheduling over hybrid channels. <em>TMC</em>,
<em>22</em>(12), 7027–7043. (<a
href="https://doi.org/10.1109/TMC.2022.3205292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of minimizing the age of information when a source can transmit status updates over two heterogeneous channels. Our work is motivated by recent developments in 5 G mmWave technology, where transmissions may occur over an unreliable but fast (e.g., mmWave) channel or a slow reliable (e.g., sub-6 GHz) channel. The unreliable channel is modeled as a time-correlated Gilbert-Elliot channel at a high rate when the channel is in the “ON” state. The reliable channel provides a deterministic but lower data rate. The scheduling strategy determines the channel to be used for transmission in each time slot, aiming to minimize the time-average age of information (AoI). The optimal scheduling problem is formulated as a Markov Decision Process (MDP), which is challenging to solve because super-modularity does not hold in a part of the state space. We address this challenge and show that a multi-dimensional threshold-type scheduling policy is optimal for minimizing the age. By exploiting the structure of the MDP and analyzing the discrete time Markov chains (DTMCs) of the threshold-type policy, we devise a low-complexity bisection algorithm to compute the optimal thresholds. We compare different scheduling policies using numerical simulations.},
  archive      = {J_TMC},
  author       = {Jiayu Pan and Ahmed M. Bedewy and Yin Sun and Ness B. Shroff},
  doi          = {10.1109/TMC.2022.3205292},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7027-7043},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Age-optimal scheduling over hybrid channels},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross layer MAC protocol for a peer conscious opportunistic
network coded cooperation system. <em>TMC</em>, <em>22</em>(12),
7014–7026. (<a href="https://doi.org/10.1109/TMC.2022.3207332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a peer conscious opportunistic network coded cooperation (PC-O-NCC) system that exploits multi-user diversity (MUD) gain in a simple network coded cooperation (NCC) based network. It prioritizes sources with better channel conditions by granting them earlier access than the other competing nodes unlike the prevalent time division multiple access (TDMA) technique used widely in any NCC network. This improves the outage performance of the overall system. To prioritise sources with better channel conditions, a novel timer-based MAC protocol is proposed. The proposed protocol is designed such that it aims to reduce collisions by taking the network load into account along with channel conditions while generating the timer values. It also minimizes the power consumption in performing clear channel assessment (CCA) by sources which is a costly affair for battery-operated devices. The simulation results show that the proposed algorithm improves the outage performance while keeping the latency to a minimum value. The improvement in the outage performance can prove to be important in taking key decisions which becomes crucial in disaster management, drone assisted scenarios or intelligent transportation systems.},
  archive      = {J_TMC},
  author       = {Sagnik Bhattacharyya and Pankaj Kumar and Sam Darshi and Satyam Agarwal and Samar Shailendra},
  doi          = {10.1109/TMC.2022.3207332},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7014-7026},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cross layer MAC protocol for a peer conscious opportunistic network coded cooperation system},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multicriteria-based forwarding strategy for interest
flooding mitigation on named data wireless networking. <em>TMC</em>,
<em>22</em>(12), 7000–7013. (<a
href="https://doi.org/10.1109/TMC.2022.3206167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless networks, the Named Data Networking (NDN) architecture maximizes contents’ availability throughout multiple network paths based on multicast-based communication combined with stateful forwarding and caching in intermediate nodes. Despite its benefits, the downside of the architecture resides in the packet flooding not efficiently prevented by current forwarding strategies and mainly associated with the native flooding of the architecture or malicious packets from Interest Flooding Attack (IFA). This work introduces iFLAT, a multicriteria-based forwarding strategy for i nterest FL ooding mitig AT ion on named data wireless networking. It follows a cross-layer approach that considers: (i) the Received Signal Strength (RSS) to adjust itself to the current status of the wireless network links, (ii) the network traffic ( meInfo ) to detect flooding issues and traffic anomalies, and (iii) a fake Interest Blacklist to identify IFA-related flooding. In doing so, the strategy achieves better efficiency on Interest flooding mitigation, addressing both native and IFA types of flooding. We evaluated the proposed strategy by reproducing a Flying Ad hoc Network (FANET) composed of Unmanned Aerial Vehicles (UAVs) featured by the NDN stack deployed in all nodes. Simulation results show that iFLAT can effectively detect and mitigate flooding, regardless of its origin or nature, achieving greater packet forwarding efficiency than competing strategies. In broadcast storm and IFA scenarios, it achieved 25.75% and 37.37% of traffic reduction, whereas Interest satisfaction rates of 16.36% and 51.78% higher, respectively.},
  archive      = {J_TMC},
  author       = {Francisco Renato Cavalcante Araújo and André Luiz Romano Madureira and Leobino Nascimento Sampaio},
  doi          = {10.1109/TMC.2022.3206167},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {7000-7013},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A multicriteria-based forwarding strategy for interest flooding mitigation on named data wireless networking},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge assisted mobile semantic visual SLAM. <em>TMC</em>,
<em>22</em>(12), 6985–6999. (<a
href="https://doi.org/10.1109/TMC.2022.3201000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization and navigation play a key role in many location-based services and have attracted numerous research efforts. In recent years, visual SLAM has been prevailing for autonomous driving. However, the ever-growing computation resources demanded by SLAM impede its applications to resource-constrained mobile devices. In this paper, we present the design, implementation, and evaluation of edgeSLAM , an edge-assisted real-time semantic visual SLAM service running on mobile devices. edgeSLAM leverages the state-of-the-art semantic segmentation algorithm to enhance localization and mapping accuracy, and speeds up the computation-intensive SLAM and semantic segmentation algorithms by computation offloading. The key innovations of edgeSLAM include an efficient computation offloading strategy, an opportunistic data sharing method, an adaptive task scheduling algorithm, and a multi-user support mechanism. We fully implement edgeSLAM and plan to open-source it. Extensive experiments are conducted under 3 datasets. The results show that edgeSLAM can run on mobile devices at 35fps and achieve 5cm localization accuracy from real-world experiments, outperforming existing solutions by more than 15%. We also demonstrate the usability of edgeSLAM through 2 case studies of pedestrian localization and robot navigation. To the best of our knowledge, edgeSLAM is the first edge-assisted real-time semantic visual SLAM for mobile devices.},
  archive      = {J_TMC},
  author       = {Hao Cao and Jingao Xu and Danyang Li and Longfei Shangguan and Yunhao Liu and Zheng Yang},
  doi          = {10.1109/TMC.2022.3201000},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {6985-6999},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Edge assisted mobile semantic visual SLAM},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards robust WiFi fingerprint-based vehicle tracking in
dynamic indoor parking environments: An online learning framework.
<em>TMC</em>, <em>22</em>(12), 6970–6984. (<a
href="https://doi.org/10.1109/TMC.2022.3200411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The variation of wireless signal in dynamic indoor parking environments may seriously compromise the performance of fingerprint-based localization methods. In this regard, this paper investigates the problem of robust WiFi fingerprint-based vehicle tracking in dynamic indoor parking environments, aiming at designing an online learning framework to continuously train the localization model and counteract the effect of signal variation. Specifically, a Hidden Markov Model (HMM) based Online Evaluation (HOE) method is first proposed to assess the accuracy of localization results by measuring the inconsistency of locations inferred by WiFi fingerprinting and Dead Reckoning (DR). Further, an Online Transfer Learning (OTL) algorithm is designed to improve the robustness of the fingerprinting localization, which consists of a weight allocation scheme to combine two classification models (i.e., the batch model and the online model) and an instance-based transferring scheme to resample the offline fingerprints and retrain the batch model. Finally, we implement the system prototype and give comprehensive performance evaluation, which demonstrates that the proposed solutions can outperform the state-of-the-art localization algorithms around 28% &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 58% on vehicle tracking accuracy in dynamic indoor parking environments.},
  archive      = {J_TMC},
  author       = {Kai Liu and Feiyu Jin and Junbo Hu and Ruitao Xie and Fuqiang Gu and Songtao Guo and Jiangtao Luo},
  doi          = {10.1109/TMC.2022.3200411},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {6970-6984},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards robust WiFi fingerprint-based vehicle tracking in dynamic indoor parking environments: An online learning framework},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Dynamic user-scheduling and power allocation for SWIPT
aided federated learning: A deep learning approach. <em>TMC</em>,
<em>22</em>(12), 6956–6969. (<a
href="https://doi.org/10.1109/TMC.2022.3201622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has been considered as a promising paradigm for enabling distributed machine learning (ML) in wireless networks. To address the limited energy capacity of wireless devices, we propose a simultaneous wireless information and power transfer (SWIPT) aided FL, in which one FL server (FLS) co-located at a cellular base station (BS) uses SWIPT to simultaneously broadcast the global model to wireless user-devices (UDs) and provide wireless power transfer to them. The UDs then use the harvested energy to train their local models and further transmit the local models to the FLS for aggregation. To improve the spectrum efficiency, we consider that the UDs form a non-orthogonal multiple access (NOMA) group for simultaneously sending their local models over the same spectrum channel. Taking the UDs’ time-varying available energy and channel conditions into account, we propose a dynamic optimization of the UDs-scheduling, the BS&#39;s transmit-power allocation, and the UDs’ power-splitting factors for SWIPT, with the objective of minimizing the long-term energy consumption while ensuring the FL convergence. The optimization problem, however, is challenging to solve since it is a finite-horizon dynamic programming problem but with an unknown stopping time, and moreover, the action space covers both discrete and continuous variables. To address these difficulties, we first execute a series of equivalent transformations to reduce the number of decision variables and then formulate the problem as a stochastic shortest path problem, based on which we propose an actor-critic deep reinforcement learning algorithm with the proximal policy optimization to efficiently learn the policy that dynamically adjusts the UDs-scheduling for FL as well as the BS&#39;s transmit-power for SWIPT. Numerical results validate the effectiveness and performance of our proposed algorithm. The results demonstrate that our proposed algorithm can effectively reduce the long-term energy consumption in comparison with two baseline algorithms.},
  archive      = {J_TMC},
  author       = {Yang Li and Yuan Wu and Yuxiao Song and Liping Qian and Weijia Jia},
  doi          = {10.1109/TMC.2022.3201622},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {6956-6969},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic user-scheduling and power allocation for SWIPT aided federated learning: A deep learning approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Budget-feasible mechanisms in two-sided crowdsensing
markets: Truthfulness, fairness, and efficiency. <em>TMC</em>,
<em>22</em>(12), 6938–6955. (<a
href="https://doi.org/10.1109/TMC.2022.3201260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a crowdsensing platform, users are invited to provide data services, and multiple requesters compete for desired services. Due to users’ costs of providing services, it is critical to design incentive mechanisms to incentivize users with (monetary) rewards. Meanwhile, requesters may have individual budgets and compete for services with different procurement abilities. Such a setting falls into the budget-feasible mechanism design. However, most of the existing budget-feasible mechanisms focus on one-sided markets with a single requester rather than the two-sided markets with multiple requesters having different procurement abilities. Moreover, requesters and users can be selfish and strategic with their private information, which requires preventing information manipulation on both requesters’ and users’ sides. In this paper, we investigate budget-feasible mechanisms in two-sided crowdsensing markets where multiple strategic requesters come with private budgets to obtain services from the strategic users. We also consider the fairness on the requesters’ side, i.e., a requester with more budget should obtain more service. We propose budget-feasible mechanisms for two models by distinguishing the types of services, i.e., the homogeneous or heterogeneous services. All proposed mechanisms satisfy fairness, budget feasibility, truthfulness on both users’ and requesters’ sides, and the constant approximation ratio. Numerical experiment results further demonstrate the efficiency of our proposed mechanisms.},
  archive      = {J_TMC},
  author       = {Xiang Liu and Chenchen Fu and Weiwei Wu and Minming Li and Wanyuan Wang and Vincent Chau and Junzhou Luo},
  doi          = {10.1109/TMC.2022.3201260},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {6938-6955},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Budget-feasible mechanisms in two-sided crowdsensing markets: Truthfulness, fairness, and efficiency},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid p4 programmable pipelines for 5G gNodeB and user
plane functions. <em>TMC</em>, <em>22</em>(12), 6921–6937. (<a
href="https://doi.org/10.1109/TMC.2022.3201512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on hybrid pipeline designs for User Plane Function and next-generation NodeB leveraging target-specific features and an insightful discussion of P4 and target challenges and limitations. The entire or disaggregated UPF runs on P4 targets and allocates packet processing data paths in P4 hardware or DPDK/x86 software based on flow characteristics (e.g., heavy hitters) and QoS requirements (e.g., low-latency slices). For the hybrid gNodeB, most packet processing is executed in commodity Tofino hardware, while unsupported functions such as Automatic Repeat Request and cryptography are performed in DPDK/x86. We show that our hybrid UPF improves the scalability by 18× and reduces latency up to 50%. The results also suggest that careful traffic allocation to pipeline targets is required to optimize each target&#39;s strength and avoid processing delays. Finally, we demonstrate a QoS-oriented application of the hybrid UPF and present gNodeB buffer service benchmarks.},
  archive      = {J_TMC},
  author       = {Suneet Kumar Singh and Christian Esteve Rothenberg and Jonatan Langlet and Andreas Kassler and Péter Vörös and Sándor Laki and Gergely Pongrácz},
  doi          = {10.1109/TMC.2022.3201512},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {6921-6937},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Hybrid p4 programmable pipelines for 5G gNodeB and user plane functions},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Completion time minimization for UAV-enabled surveillance
over multiple restricted regions. <em>TMC</em>, <em>22</em>(12),
6907–6920. (<a href="https://doi.org/10.1109/TMC.2022.3200732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work examines a UAV-enabled surveillance mission over multiple restricted regions and aims to determine the optimal UAV trajectory that minimizes the mission completion time. The UAV is prohibited from entering the restricted regions due to government regulations or adversarial concerns. However, during the surveillance of a region, the UAV can move along the region&#39;s boundary to reduce its distance to the next region once the local task is completed. To exploit this advantage, we propose a minimum completion time (MinTime) algorithm that first determines the visiting order of the regions by employing an approximate solution of the traveling salesman problem (TSP) and then optimizes the UAV trajectory over the sequence of restricted regions using dynamic programming. In the presence of obstacles, we further propose an obstacle-aware MinTime (OA-MinTime) algorithm that treats each obstacle as an additional restricted region with zero surveillance duration, allowing the UAV to avoid the obstacles in a more efficient manner. A modified TSP solution is also proposed by taking into consideration the additional distance required to circumvent the obstacles on each inter-POI path. Simulation results show that the proposed MinTime and OA-MinTime algorithms can significantly reduce the total completion time compared to conventional minimum-distance approaches.},
  archive      = {J_TMC},
  author       = {Hsiang-Chun Tsai and Y.-W. Peter Hong and Jang-Ping Sheu},
  doi          = {10.1109/TMC.2022.3200732},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {6907-6920},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Completion time minimization for UAV-enabled surveillance over multiple restricted regions},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MobiCharger: Optimal scheduling for cooperative EV-to-EV
dynamic wireless charging. <em>TMC</em>, <em>22</em>(12), 6889–6906. (<a
href="https://doi.org/10.1109/TMC.2022.3200414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of dynamic wireless charging for Electric Vehicles (EVs), Mobile Energy Disseminator (MED), which can charge an EV in motion, becomes available. However, existing wireless charging scheduling methods for wireless sensors, which are the most related works to MED deployment, are not directly applicable for city-scale EV-to-EV dynamic wireless charging. We present MobiCharger : a Mobi le wireless Charger guidance system that determines the number of serving MEDs, and their optimal routes. We studied a metropolitan-scale vehicle mobility dataset, and found: most vehicles have routines, and the number of driving EVs changes over time, which means MED deployment should adaptively change as well. We combine EVs’ current trajectories and routines to estimate EV density and the cruising graph for MED coverage. Then, we develop an offline MED deployment method that utilizes multi-objective optimization to determine the number of serving MEDs and the driving route of each MED, and an online method that utilizes Reinforcement Learning to adjust the MED deployment when the real-time vehicle traffic changes. Our trace-driven experiments show that compared with previous methods, MobiCharger increases the medium State-of-Charge of all EVs by 50% during all time slots, and the number of charges of EVs by almost 100%.},
  archive      = {J_TMC},
  author       = {Li Yan and Haiying Shen and Liuwang Kang and Juanjuan Zhao and Zhe Zhang and Chengzhong Xu},
  doi          = {10.1109/TMC.2022.3200414},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {6889-6906},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MobiCharger: Optimal scheduling for cooperative EV-to-EV dynamic wireless charging},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepContext: Mobile context modeling and prediction via HMMs
and deep learning. <em>TMC</em>, <em>22</em>(12), 6874–6888. (<a
href="https://doi.org/10.1109/TMC.2022.3200947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile context determination is an important step for many context-aware services such as location-based services, enterprise policy enforcement, building/room occupancy detection for power/HVAC operation, etc. Especially in enterprise scenarios where policies (e.g., attending a confidential meeting only when the user is in “Location X”) are defined based on mobile context, it is paramount to verify the accuracy of the mobile context. Most of the existing solutions rely on context obtained directly from sensors which could be hacked, noisy or insufficient, which cannot be relied upon for security applications. In this article, we take a different approach by modeling mobile context based on past context data of related users and considering its unique challenges such as missing features. To this end, we propose three models for modeling mobile context based on symbolic time series data of feature-value pairs—two stochastic models based on the theory of Hidden Markov Models (HMMs) and one model based on deep learning— personalized model ( HPContext ), collaborative filtering model ( HCFContext ), and deep learning model ( DeepContext ) to eventually replace HPContext . HPContext and DeepContext predict the current context using sequential history of the user&#39;s own past context observations; while HCFContext enhances the former with collaborative filtering features, which enables it to predict the current context of the primary user based on the context observations of users related to the primary user, e.g., same team colleagues in the company, gym friends, family members, etc. DeepContext models mobile context based on symbolic (i.e., categorical valued rather than continuous-valued) time series data using deep learning techniques. These models are then used to determine the context of the primary user at the current instant or some timesteps in to the future. Each of the proposed models can also be used to enhance or complement the context obtained from sensors. Finally, these models are thoroughly validated on a real-life dataset.},
  archive      = {J_TMC},
  author       = {Vidyasagar Sadhu and Saman Zonouz and Dario Pompili},
  doi          = {10.1109/TMC.2022.3200947},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {6874-6888},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DeepContext: Mobile context modeling and prediction via HMMs and deep learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic task allocation for mobile edge learning.
<em>TMC</em>, <em>22</em>(12), 6860–6873. (<a
href="https://doi.org/10.1109/TMC.2021.3137017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the new paradigm of Mobile Edge Learning ”MEL” that enables the implementation of realistic distributed machine learning (DML) tasks on wireless edge nodes while taking into consideration the heterogeneous computing and networking environments. Therefore, a heterogeneity aware (HA) scheme is designed to solve the problem of dynamic task allocation for MEL in a way that maximizes the DML accuracy over wireless heterogeneous nodes or ’learners’ while respecting the time constraints. The problem is first formulated as a quadratically-constrained integer linear program (QCILP). Being NP-hard, it is relaxed into a non-convex problem over real variables which can be solved using commercially available numerical solvers. The relaxation also allows us to propose a solution based on deriving the analytical upper bounds of the optimal solution using Lagrangian analysis and Karush-Kuhn-Tucker (KKT) conditions. The merits of the proposed analytical solution are demonstrated by comparing its performance to the numerical approaches and comparing the validation accuracy of the proposed HA scheme to the baseline heterogeneity unaware (HU) equal task allocation approach. Simulation results show that the HA schemes decrease convergence time up-to 56% and increase the final validation accuracy up-to 8%.},
  archive      = {J_TMC},
  author       = {Umair Mohammad and Sameh Sorour and Mohamed Hefeida},
  doi          = {10.1109/TMC.2021.3137017},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {6860-6873},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic task allocation for mobile edge learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video content placement at the network edge: Centralized and
distributed algorithms. <em>TMC</em>, <em>22</em>(11), 6843–6859. (<a
href="https://doi.org/10.1109/TMC.2022.3200401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the traditional video streaming service paradigm, content providers typically provision the requested video content to viewers through a central content delivery network (CDN). However, remote viewers usually experience long video streaming delay due to uncertain wide area network delay, which severely affects the quality of experience. Multi-Access Edge Computing (MEC) offers a way to shorten the video streaming delay by building small-scale cloud infrastructures at the network edge, which are in close proximity to the viewers. In this paper, we present novel centralized and distributed algorithms for the video content placement problem in MEC. In the proposed centralized video content placement algorithm, we leverage the Lyapunov optimization technique to formulate the video content placement problem as a series of one-time-slot optimization problems and apply an Alternating Direction Method of Multipliers (ADMM)-based method to solve each of them. We further devise a distributed Multi-Agent Reinforcement Learning (MARL)-based method with value decomposition mechanism and parallelization policy update method to solve the video content placement problem. The value Decomposition mechanism deals with the credit assignment among multiple agents, which promotes the cooperative optimization of the global target and reduces the frequency of information exchange. The parallelization of policy network can speed up the convergence process. Simulation results verify the effectiveness and superiority of our proposed centralized and distributed algorithms in terms of performance.},
  archive      = {J_TMC},
  author       = {Yanan Gao and Song Yang and Fan Li and Stojan Trajanovski and Pan Zhou and Pan Hui and Xiaoming Fu},
  doi          = {10.1109/TMC.2022.3200401},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6843-6859},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Video content placement at the network edge: Centralized and distributed algorithms},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vehicloak: A blockchain-enabled privacy-preserving payment
scheme for location-based vehicular services. <em>TMC</em>,
<em>22</em>(11), 6830–6842. (<a
href="https://doi.org/10.1109/TMC.2022.3193165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles (IoV) technology enables vehicles to communicate with each other, with pedestrians and with roadside infrastructures, to realize more efficient, safer and more environmentally friendly transportation. IoV also promises rich location-based services for vehicles, such as parking and toll highway. However, preserving privacy for location-based service payments emerges as a critical and challenging problem in IoV. Existing schemes rely on centralized banks for payment processing, resulting in location privacy leakage to centralized entities. In this article, we propose a decentralized privacy-preserving payment scheme named Vehicloak for IoV based on the blockchain technology. The biggest challenge is to provide location privacy for vehicles while guaranteeing correct service payments using the transparent blockchain. To tackle this challenge, we introduce a new cryptographic technique called zk-GSigproof that integrates zero-knowledge proof with group signature. Vehicloak implements this technique in a smart contract to process payment, which verifies zero-knowledge proof and group signature without leaking location information. It is not limited to IoV and can be applied in many payment scenarios. To evaluate the performance of our scheme, we implement Vehicloak on a private blockchain of 100 nodes on Aliyun, and conduct a test with up to 4,000 transactions. The experimental results prove the feasibility of Vehicloak.},
  archive      = {J_TMC},
  author       = {Yihao Guo and Zhiguo Wan and Hui Cui and Xiuzhen Cheng and Falko Dressler},
  doi          = {10.1109/TMC.2022.3193165},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6830-6842},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Vehicloak: A blockchain-enabled privacy-preserving payment scheme for location-based vehicular services},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-offset ALOHA with SIC. <em>TMC</em>, <em>22</em>(11),
6817–6829. (<a href="https://doi.org/10.1109/TMC.2022.3197208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet-of-Things (IoT) applications for real-time control gradually increase and become computationally demanding. To provide better quality-of-service (QoS) in random access (RA) system based on slotted ALOHA (S-ALOHA), this work proposes a novel S-ALOHA system with cross-slot successive interference cancellation (SIC). To facilitate SIC, we design each slot with several time offsets (TOs) and one packet transmission time, where the length of overall TOs is a fraction of a packet transmission time. Users (re)transmit at the boundary of a TO randomly selected. This enables the base station (BS) to distinguish who makes the first and last transmissions in a collision slot and ask immediate retransmissions from them in the subsequent one or two slots. With these retransmitted packets, the BS performs SIC for the previously collided packets. We analyze the system throughput and the distribution of RA delay. The results show that the proposed system can achieve throughput from 0.5 (packets per packet transmission time) at minimum to 0.856 at maximum, depending on the number of TOs and the length of TO. In addition, to run this system stably, we propose a Bayesian-optimized backoff algorithm that enables users to use throughput-optimal (re)transmission probability. It is demonstrated that the proposed backoff algorithms can achieve the throughput close to genie-aided (GA) system.},
  archive      = {J_TMC},
  author       = {Jun-Bae Seo and Yangqian Hu and Hu Jin},
  doi          = {10.1109/TMC.2022.3197208},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6817-6829},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Time-offset ALOHA with SIC},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). S-UbiTap: Leveraging acoustic dispersion for ubiquitous and
scalable touch interface on solid surfaces. <em>TMC</em>,
<em>22</em>(11), 6800–6816. (<a
href="https://doi.org/10.1109/TMC.2022.3195226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As various computing devices, such as smartphones, IoT devices, smart speakers etc, becomes omnipresent in our daily lives, interest in ubiquitous computing interfaces is increasing. In response to this, various studies have introduced on-surface input techniques that leverage the surface of surrounding objects as touch interfaces. However, most of them struggle to support ubiquitous interaction due to their dependency on specific hardware or environments. In this work, we propose &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf S \text{-}UbiTap}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , an input method that turns any flat solid surface into a touch input space by listening to sound (i.e., with microphones already present in the commodity devices). More specifically, we develop a novel touch localization technique that leverages the physical phenomenon, called dispersion , which is the characteristic of sound as it travels through solid surfaces, and address the challenges that limit existing acoustic-based solutions in terms of portability, accuracy, usability, robustness, scalability, and responsiveness. Our extensive experiments with a prototype of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf S \text{-}UbiTap}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; show that we can support sub-centimeter accuracy on various types of surfaces with minor user calibration effort. In addition, the accuracy is maintained even when the size of the touch input space increases. In our experience with real-world users, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf S \text{-}UbiTap}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; significantly improves usability and robustness, thus enabling the emergence of more exciting applications.},
  archive      = {J_TMC},
  author       = {Anish Byanjankar and Yunxin Liu and Yuanchao Shu and Insik Shin and Myeongwon Choi and Hyosu Kim},
  doi          = {10.1109/TMC.2022.3195226},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6800-6816},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {S-UbiTap: Leveraging acoustic dispersion for ubiquitous and scalable touch interface on solid surfaces},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatiotemporal urban inference and prediction in sparse
mobile CrowdSensing: A graph neural network approach. <em>TMC</em>,
<em>22</em>(11), 6784–6799. (<a
href="https://doi.org/10.1109/TMC.2022.3195706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile CrowdSensing (MCS) has recently become a promising data acquisition paradigm, which recruits a large number of users to collect data from the target sensing areas. Obviously, with the increase of sensing scale and the decrease of sensing granularity, traditional MCS cannot fully cover the required sensing areas especially the inaccessible areas. As a variant, Sparse MCS can utilize the spatiotemporal correlations in sensing data to infer the whole sensing map only by sensing a few subareas. However, in many real-world scenarios, such as traffic congestion prediction or parking occupancy detection, inferring the current unsensed data may not be the final goal. By comparison, it is more important to get the future information through the sparse sensed data. In this paper, we turn attention from inferring the current unsensed data to predicting the future unknown data and propose an urban inference and prediction framework in Sparse MCS. To deal with the sparse sensed data, we first present a bipartite-graph-based matrix completion algorithm with spatiotemporal constraints to accurately recover the current full map. Then, by exploiting spatiotemporal correlations based on the inferred full map, we present a Graph Convolutional Networks (GCN) with spatiotemporal attention to predict the future maps. Furthermore, we design a spatiotemporal iterative method to repeatedly update the spatiotemporal attentions and constraints, in order to connect the urban inference and prediction to improve the accuracy of the whole framework. Extensive experiments have been conducted on two types of typical urban sensing tasks with four real-world data sets, which verify the effectiveness of our proposed algorithms in improving the inference and prediction accuracy with the sparse sensed data.},
  archive      = {J_TMC},
  author       = {En Wang and Weiting Liu and Wenbin Liu and Yongjian Yang and Bo Yang and Jie Wu},
  doi          = {10.1109/TMC.2022.3195706},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6784-6799},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Spatiotemporal urban inference and prediction in sparse mobile CrowdSensing: A graph neural network approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised few-shot time-series segmentation for
activity recognition. <em>TMC</em>, <em>22</em>(11), 6770–6783. (<a
href="https://doi.org/10.1109/TMC.2022.3199015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting valuable activity segments from continuously received sensor data is a key step for many downstream applications such as activity recognition, trajectory prediction, and gesture recognition. Numerous unsupervised and supervised approaches have been proposed for activity segmentation. However, current unsupervised methods generally suffer from subject and environment-dependent problems, and supervised methods require a great many labeled data which is time-consuming and expensive to be collected. To address these issues, we propose a Self-supervised Few-shot Time-series Segmentation framework called SFTSeg, which introduces few-shot learning to conduct activity segmentation only relying on several labeled target samples. To be applicable to time-series data, we design a line-level data augmentation method to build a consistency regularization for the few-shot learning framework, which can augment limited labeled target samples to enhance generalization capacity of the model. Also, we devise a time series-specific pretext task to construct a self-supervised loss with adaptive weighting, which can adopt unlabeled target data to enable the model to learn characteristics of the target data and further improve segmentation performance. The experiments illustrated that SFTSeg achieves obvious gains compared to state-of-the-art methods.},
  archive      = {J_TMC},
  author       = {Chunjing Xiao and Shiming Chen and Fan Zhou and Jie Wu},
  doi          = {10.1109/TMC.2022.3199015},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6770-6783},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Self-supervised few-shot time-series segmentation for activity recognition},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure user verification and continuous authentication via
earphone IMU. <em>TMC</em>, <em>22</em>(11), 6755–6769. (<a
href="https://doi.org/10.1109/TMC.2022.3193847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric plays an important role in user authentication. However, the most widely used biometrics, such as facial feature and fingerprint, are easy to capture or record, and thus vulnerable to spoofing attacks. On the contrary, intracorporal biometrics, such as electrocardiography and electroencephalography, are hard to collect, and hence more secure for authentication. Unfortunately, adopting them is not user-friendly due to their complicated collection methods or inconvenient constraints on users. In this paper, we propose a novel biometric-based authentication system, namely MandiPass . MandiPass leverages inertial measurement units, which have been widely deployed in portable devices, to collect intracorporal biometric from the vibration of user&#39;s mandible. It provides not only one-time verification function but also continuous authentication function. Both the two functions are secure and user-friendly. We theoretically validate the feasibility of MandiPass and develop a series of deep learning techniques for effective biometric extraction. We also utilize a Gaussian matrix to defend against replay attacks. Extensive experiment results with 34 volunteers show that MandiPass can achieve low equal error rate, even under various harsh environments.},
  archive      = {J_TMC},
  author       = {Jianwei Liu and Wenfan Song and Leming Shen and Jinsong Han and Kui Ren},
  doi          = {10.1109/TMC.2022.3193847},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6755-6769},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secure user verification and continuous authentication via earphone IMU},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure trajectory publication in untrusted environments: A
federated analytics approach. <em>TMC</em>, <em>22</em>(11), 6742–6754.
(<a href="https://doi.org/10.1109/TMC.2022.3198550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing awareness of privacy and the adoption of data regulations challenge the traditional trajectory publication framework in which a trusted server has access to the raw data from mobile clients. In the new untrusted environment, the clients call for much stronger data privacy preservation locally without sharing their raw data. Based on the emerging paradigm of federated analytics, we propose a Federated Analytics-based Secure Trajectory PUBlication (FASTPub) mechanism to operate in such untrusted environments. Compared with existing local differential privacy (LDP) methods, FASTPub guarantees LDP and loss-bounded &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -anonymity simultaneously with greatly improved data utility. Specifically, FASTPub works interactively between the server and clients and iteratively builds up the trajectory without exposing raw data. Sampled clients only respond to selected trajectory fragments with randomized answers to preserve privacy as much as possible. The server then intelligently aggregates these randomized responses leveraging the intrinsic Apriori property and a Markov independent assumption of trajectory data to guide further iterations. Extensive experiments on synthetic and real-world datasets on two downstream tasks demonstrate that FASTPub gains a remarkably improved data utility compared to the existing state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Zibo Wang and Yifei Zhu and Dan Wang and Zhu Han},
  doi          = {10.1109/TMC.2022.3198550},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6742-6754},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secure trajectory publication in untrusted environments: A federated analytics approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reliable dynamic packet scheduling with slot sharing for
real-time wireless networks. <em>TMC</em>, <em>22</em>(11), 6723–6741.
(<a href="https://doi.org/10.1109/TMC.2022.3196922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order for real-time wireless networks (RTWNs) to achieve desired Quality of Service (QoS) for real-time sensing and control, effective packet scheduling algorithms play a critical role, especially in the presence of unexpected disturbances. Most existing solutions in the literature focus either on static or dynamic schedule construction to meet the desired QoS requirements, but have a common assumption that all wireless links are reliable. However, this assumption is not realistic in real-life settings. To address this drawback, this paper introduces a novel reliable dynamic packet scheduling framework, called RD-PaS. RD-PaS can not only construct static schedules to meet both the timing and reliability requirements of end-to-end flows in RTWNs, but also construct new schedules rapidly to handle abruptly increased network traffic induced by unexpected disturbances while minimizing the impact on existing network flows. Through judiciously sharing time slots among tasks, RD-PaS can significantly reduce the number of required time slots to meet the system reliability requirement and improve the network throughput. The functional correctness of the RD-PaS framework has been validated through its implementation and deployment on a real-life RTWN testbed. Extensive simulation-based experiments have also been performed to evaluate the effectiveness of RD-PaS, especially in large-scale network settings.},
  archive      = {J_TMC},
  author       = {Tianyu Zhang and Tao Gong and Mingsong Lyu and Nan Guan and Song Han and Xiaobo Sharon Hu},
  doi          = {10.1109/TMC.2022.3196922},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6723-6741},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reliable dynamic packet scheduling with slot sharing for real-time wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Periodic updates for constrained OCO with application to
large-scale multi-antenna systems. <em>TMC</em>, <em>22</em>(11),
6705–6722. (<a href="https://doi.org/10.1109/TMC.2022.3194357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many dynamic systems, decisions on system operation are updated over time, and the decision maker requires an online learning approach to optimize its strategy in response to the changing environment. When the loss and constraint functions are convex, this belongs to the general family of online convex optimization (OCO). In existing OCO works, the environment is assumed to vary in a time-slotted fashion, while the decisions are updated at each time slot. However, many wireless communication systems permit only periodic decision updates, i.e., each decision is fixed over multiple time slots, while the environment changes between the decision epochs. The standard OCO model is inadequate for these systems. Therefore, in this article, we consider periodic decision updates for OCO. We aim to minimize the accumulation of time-varying convex loss functions, subject to both short-term and long-term constraints. Feedback information about the loss functions within the current update period may be delayed and incomplete. We propose an efficient algorithm, termed Periodic Queueing and Gradient Aggregation (PQGA), which employs novel periodic queues together with possibly multi-step aggregated gradient descent to update the decisions over time. We derive upper bounds on the dynamic regret, static regret, and constraint violation of PQGA. As an example application, we study the performance of PQGA for network virtualization in a large-scale multi-antenna system shared by multiple wireless service providers. Simulation results show that PQGA converges fast and substantially outperforms the current best alternative.},
  archive      = {J_TMC},
  author       = {Juncheng Wang and Min Dong and Ben Liang and Gary Boudreau},
  doi          = {10.1109/TMC.2022.3194357},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6705-6722},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Periodic updates for constrained OCO with application to large-scale multi-antenna systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance analysis of connection establishment procedure
under beamforming in 5G NR networks. <em>TMC</em>, <em>22</em>(11),
6690–6704. (<a href="https://doi.org/10.1109/TMC.2022.3193968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High demand for reliability, low latency, seamless connectivity lead to the 5G era. 5G cellular networks employ a random access based preamble transmission procedure for the initial locking of User Equipment (UEs) to a base station (gNB) and uplink resource scheduling. It is of utmost importance that we evaluate the factors that aid and those that limit the random access procedure in achieving its envisaged goal. In this paper, we develop an analytical model for random access procedure for connection establishment in 5G when beamforming is employed. The random access medium is modelled as a multi-channel slotted Aloha system. We use an equilibrium point analysis framework to derive the performance metrics namely, the rate at which UEs can lock on to a gNB and the average and variance of the time taken by a new UE to establish connection with the base station. We analyse the impact of the retransmission limit and the number of available preambles for random access on the performance of connection establishment of a UE. Our analysis brings out the importance of the choice of base station configurations with respect to the user demographics of a 5G NR cell.},
  archive      = {J_TMC},
  author       = {Lokesh Bommisetty and T. G. Venkatesh},
  doi          = {10.1109/TMC.2022.3193968},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6690-6704},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Performance analysis of connection establishment procedure under beamforming in 5G NR networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online user and power allocation in dynamic NOMA-based
mobile edge computing. <em>TMC</em>, <em>22</em>(11), 6676–6689. (<a
href="https://doi.org/10.1109/TMC.2022.3193366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study tackles the online user allocation problem in mobile edge computing (MEC) systems powered by non-orthogonal multiple access. App vendors need to determine a proper wireless channel in a base station/edge server and sufficient transmit power for every user. We consider a stochastic MEC system where users arrive and depart over time. When an edge server runs out of computing resources, some users will have to wait until the resources become available again, which incurs an allocation delay cost. This cost is often not investigated in many studies, which also do not consider a multi-cell, multi-channel system as we do in this work, due to its complexity. We aim to minimize the allocation delay and transmit power costs, increasing the system&#39;s energy efficiency. To achieve this objective while guaranteeing users’ data rate requirements over time, we adopt the Lyapunov framework to convert this long-term optimization problem into a series of subproblems to be solved in every time slot. To solve the aforementioned subproblems efficiently, we present a distributed game theory-based approach. The proposed algorithm is theoretically evaluated and experimentally demonstrated to outperform several baseline and state-of-the-art methods, highlighting the significance of systematic consideration for both computation and communication aspects of this problem.},
  archive      = {J_TMC},
  author       = {Phu Lai and Qiang He and Feifei Chen and Mohamed Abdelrazek and John Hosking and John Grundy and Yun Yang},
  doi          = {10.1109/TMC.2022.3193366},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6676-6689},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online user and power allocation in dynamic NOMA-based mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Online service migration in mobile edge with incomplete
system information: A deep recurrent actor-critic learning approach.
<em>TMC</em>, <em>22</em>(11), 6663–6675. (<a
href="https://doi.org/10.1109/TMC.2022.3197706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-access Edge Computing (MEC) is an emerging computing paradigm that extends cloud computing to the network edge to support resource-intensive applications on mobile devices. As a crucial problem in MEC, service migration needs to decide how to migrate user services for maintaining the Quality-of-Service when users roam between MEC servers with limited coverage and capacity. However, finding an optimal migration policy is intractable due to the dynamic MEC environment and user mobility. Many existing studies make centralized migration decisions based on complete system-level information, which is time-consuming and also lacks desirable scalability. To address these challenges, we propose a novel learning-driven method, which is user-centric and can make effective online migration decisions by utilizing incomplete system-level information. Specifically, the service migration problem is modeled as a Partially Observable Markov Decision Process (POMDP). To solve the POMDP, we design a new encoder network that combines a Long Short-Term Memory (LSTM) and an embedding matrix for effective extraction of hidden information, and further propose a tailored off-policy actor-critic algorithm for efficient training. The extensive experimental results based on real-world mobility traces demonstrate that this new method consistently outperforms both the heuristic and state-of-the-art learning-driven algorithms and can achieve near-optimal results on various MEC scenarios.},
  archive      = {J_TMC},
  author       = {Jin Wang and Jia Hu and Geyong Min and Qiang Ni and Tarek El-Ghazawi},
  doi          = {10.1109/TMC.2022.3197706},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6663-6675},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online service migration in mobile edge with incomplete system information: A deep recurrent actor-critic learning approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the convergence of multi-server federated learning with
overlapping area. <em>TMC</em>, <em>22</em>(11), 6647–6662. (<a
href="https://doi.org/10.1109/TMC.2022.3200016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-server Federated learning (FL) has been considered as a promising solution to address the limited communication resource problem of single-server FL. We consider a typical multi-server FL architecture, where the coverage areas of regional servers may overlap. The key point of this architecture is that the clients located in the overlapping areas update their local models based on the average model of all accessible regional models, which enables indirect model sharing among different regional servers. Due to the complicated network topology, the convergence analysis is much more challenging than in single-server FL. In this paper, we firstly propose a novel MS-FedAvg algorithm for this multi-server FL architecture and analyze its convergence on non-iid datasets for general non-convex settings. Since the number of clients located in each regional server is much less than single-server FL, the bandwidth of each client should be large enough to successfully communicate training models with the server, which indicates that full client participation can work in multi-server FL. Also, we provide the convergence analysis of the partial client participation scheme and develop a new biased partial participation strategy to further accelerate convergence. Our results indicate that the convergence results highly depend on the ratio of the number of clients in each area type to the total number of clients in all three strategies. The extensive experiments show remarkable performance and support our theoretical results.},
  archive      = {J_TMC},
  author       = {Zhe Qu and Xingyu Li and Jie Xu and Bo Tang and Zhuo Lu and Yao Liu},
  doi          = {10.1109/TMC.2022.3200016},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6647-6662},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the convergence of multi-server federated learning with overlapping area},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NeuSaver: Neural adaptive power consumption optimization for
mobile video streaming. <em>TMC</em>, <em>22</em>(11), 6633–6646. (<a
href="https://doi.org/10.1109/TMC.2022.3195961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video streaming services strive to support high-quality videos at higher resolutions and frame rates to improve the quality of experience (QoE). However, high-quality videos consume considerable amounts of energy on mobile devices. This paper proposes NeuSaver, which reduces the power consumption of mobile devices when streaming videos by applying an adaptive frame rate to each video chunk without compromising the user experience. NeuSaver generates a policy that can determine the appropriate frame rate for each video chunk using reinforcement learning (RL). The RL model automatically learns the policy that optimizes the QoE goals based on previous observations. NeuSaver also uses an asynchronous advantage actor-critic algorithm to reinforce the RL model quickly and robustly. Streaming servers that support NeuSaver preprocess videos into segments with various frame rates, which is similar to the process of creating videos with multiple bit rates in dynamic adaptive streaming over HTTP. NeuSaver utilizes the commonly used H.264 video codec. We evaluated NeuSaver in various experiments and a user study through four video categories along with the previously proposed model. Our experiments showed that NeuSaver effectively reduces the power consumption of mobile devices when streaming video by an average of 16.14% and up to 23.12% while maintaining high QoE.},
  archive      = {J_TMC},
  author       = {Kyoungjun Park and Myungchul Kim and Laihyuk Park},
  doi          = {10.1109/TMC.2022.3195961},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6633-6646},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {NeuSaver: Neural adaptive power consumption optimization for mobile video streaming},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Muster: Multi-source streaming for tile-based 360° videos
within cloud native 5G networks. <em>TMC</em>, <em>22</em>(11),
6616–6632. (<a href="https://doi.org/10.1109/TMC.2022.3194101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {360 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^\circ$&lt;/tex-math&gt;&lt;/inline-formula&gt; videos generally require a large amount of bandwidth between video servers and users, which puts much burden on the current CDN-based single-source video streaming solutions. The emerging cloud native 5G networks can bridge the distance between video servers and users by leveraging in-network single-source video streaming to enhance 360 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^\circ$&lt;/tex-math&gt;&lt;/inline-formula&gt; video quality. Unfortunately, the restricted bandwidth of in-network servers becomes the main bottleneck. Although tile-based video streaming is promising to reduce video transmission size while keeping user QoE, it highly depends on the accuracy of user FoV prediction, which existing prediction methods cannot guarantee. Recently, some researchers advocate the idea of “super FoV” (i.e., an extended range of predicted FoV) to cope with the inaccurate FoV prediction, which however could lower the effect of tile-based video streaming. Alternatively, we present &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf Muster}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , a multi-source streaming for tile-based 360 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^\circ$&lt;/tex-math&gt;&lt;/inline-formula&gt; videos within cloud native 5G networks. We detail the system components, provide a comprehensive model, formulate joint server selection and tile requesting problems, and correspondingly propose efficient online algorithms with a performance guarantee. Small-scale testbed and large-scale simulation based evaluation confirm the superiority of the proposed algorithms.},
  archive      = {J_TMC},
  author       = {Xinjing Yuan and Lingjun Pu and Jianxin Shi and Qianyun Gong and Jingdong Xu},
  doi          = {10.1109/TMC.2022.3194101},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6616-6632},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Muster: Multi-source streaming for tile-based 360° videos within cloud native 5G networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective parallel task offloading and content caching
in D2D-aided MEC networks. <em>TMC</em>, <em>22</em>(11), 6599–6615. (<a
href="https://doi.org/10.1109/TMC.2022.3199876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In device to device (D2D) aided mobile edge computing (MEC) networks, by implementing content caching and D2D links, the edge server and nearby mobile devices can provide task offloading platforms. For parallel tasks, proper decisions on content caching and task offloading help reduce delay and energy consumption. However, what is often ignored in the previous works is the joint optimization of parallel task offloading and content caching. In this paper, we aim to find optimal content caching and parallel task offloading strategies, so as to minimize task delay and energy consumption. The minimization problem is formulated as a multi-objective optimization problem, concerning both content caching and parallel task offloading. The content caching is formulated as an integer knapsack problem (IKP). To solve the IKP problem, an enhanced Binary Particle Swarm Optimization algorithm is proposed. The parallel task offloading problem is formulated as a constrained multi-objective optimization problem, an improved multi-objective bat algorithm is proposed to address the problem. Experimental results show that our algorithm can decrease delay and energy cost by at most 45% and 56%, respectively. In addition, the parallel task offloading ratio remains over 91% even with large number of mobile devices (MDs).},
  archive      = {J_TMC},
  author       = {Zhu Xiao and Jinmei Shu and Hongbo Jiang and John C. S. Lui and Geyong Min and Jiangchuan Liu and Schahram Dustdar},
  doi          = {10.1109/TMC.2022.3199876},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6599-6615},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-objective parallel task offloading and content caching in D2D-aided MEC networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mean-field game theory based optimal caching control in
mobile edge computing. <em>TMC</em>, <em>22</em>(11), 6585–6598. (<a
href="https://doi.org/10.1109/TMC.2022.3193764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) can use wireless access network (RAN) to provide users with nearby information technology (IT) services and cloud computing functions, which creates a high-performance and low latency service environment. By caching the popular content at small base station (SBS) can reduce the heavy backhaul load and the content retransmission. However, the time-varying and dynamic of the content requests may lead to the base station to cache the useless contents. In this paper, we study a distributed caching optimization problem in edge networks (ENs) with the spatio-temporal requirements. In the considered ENs, the cache control is described as a stochastic differential game (SDG) in which each SBS defines a caching strategy to reduce the total cost in terms of the service delay and backhaul link load. To reduce the computational complexity, the original optimization problem is transformed into a mean field game (MFG). We propose a distributed caching iterative control algorithm that decouples the information interaction between the general SBS and others through the mean field distribution. In addition, we obtain the optimal edge caching control strategy, while the existence and uniqueness of the mean field equilibrium (MFE) can also be guaranteed. Simulation results demonstrate that our proposed caching control algorithm can average reduce 27.12% storage cost and achieve better performance than other existing schemes.},
  archive      = {J_TMC},
  author       = {Hao Feng and Songtao Guo and Defang Liu and Yuanyuan Yang},
  doi          = {10.1109/TMC.2022.3193764},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6585-6598},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mean-field game theory based optimal caching control in mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximizing sensor lifetime via multi-node partial-charging
on sensors. <em>TMC</em>, <em>22</em>(11), 6571–6584. (<a
href="https://doi.org/10.1109/TMC.2022.3200070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the employment of a mobile charger to charge lifetime-critical sensors under the multi-node partial-charging model, in which the charger can simultaneously charge the sensors within its charging range and each sensor may be partially charged each time. We notice that existing studies only scheduled the charger to minimize the number of dead sensors, but did not consider the charging scheduling for the sensors that have already run out of their energy, and the dead sensors will be last charged by the mobile charger. Then, their dead durations may be very long. In this paper, we consider not only how to minimize the number of dead sensors but also reduce the dead durations of sensors. To this end, we first formulate a sensor lifetime maximization problem, which is to find a charging tour for a mobile charger to charge sensors, such that the sum of sensor lifetimes is maximized. We then propose a novel &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\frac{1}{3}$&lt;/tex-math&gt;&lt;/inline-formula&gt; -approximation algorithm for the problem. We finally evaluate the performance of the proposed algorithm through experiments. Experimental results show that both the average and maximum sensor dead durations by the proposed algorithm are up to 70% shorter than those by existing algorithms.},
  archive      = {J_TMC},
  author       = {Jingxiang Liu and Jian Peng and Wenzheng Xu and Weifa Liang and Tang Liu and Xi Peng and Zichuan Xu and Zheng Li and Xiaohua Jia},
  doi          = {10.1109/TMC.2022.3200070},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6571-6584},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Maximizing sensor lifetime via multi-node partial-charging on sensors},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging wearables for assisting the elderly with dementia
in handwashing. <em>TMC</em>, <em>22</em>(11), 6554–6570. (<a
href="https://doi.org/10.1109/TMC.2022.3193615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proper handwashing, having a crucial effect on reducing bacteria, serves as the cornerstone of hand hygiene. For elders with dementia, they suffer from a gradual loss of memory and difficulty coordinating handwashing steps. Proper assistance should be provided to them to ensure their hand hygiene adherence. Toward this end, we propose AWash, leveraging inertial measurement unit (IMU) readily available in most wrist-worn devices (e.g., smartwatches) to characterize handwashing actions and provide assistance. To monitor handwashing scenarios round-the-clock while achieving energy efficiency, we design methods that distinguish handwashing from other daily activities and dynamically adjust the sampling duty cycle. Upon detecting handwashing actions, we design several novel techniques to segment different handwashing actions and extract sensor-body inclination angles that handle particular interference of senile dementia patients. Moreover, a user-independent network model is built to recognize the handwashing actions of senile dementia patients without requiring their training data. Furthermore, we propose a transfer learning method that improves system performance. To meet users’ diverse needs, we use a state machine to make prompt decisions, supporting customized assistance. Extensive experiments on a prototype with eight older participants demonstrate that AWash can increase the user&#39;s independence in the execution of handwashing.},
  archive      = {J_TMC},
  author       = {Yetong Cao and Fan Li and Huijie Chen and Xiaochen Liu and Song Yang and Yu Wang},
  doi          = {10.1109/TMC.2022.3193615},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6554-6570},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Leveraging wearables for assisting the elderly with dementia in handwashing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Joint trajectory and passive beamforming design for
intelligent reflecting surface-aided UAV communications: A deep
reinforcement learning approach. <em>TMC</em>, <em>22</em>(11),
6543–6553. (<a href="https://doi.org/10.1109/TMC.2022.3200998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the intelligent reflecting surface (IRS)-aided unmanned aerial vehicle (UAV) communication system is studied, where the UAV is deployed to serve the user equipment (UE) with the assistance of multiple IRSs mounted on several buildings to enhance the communication quality between UAV and UE. We aim to maximize the energy efficiency of the system, including the data rate of UE and the energy consumption of UAV via jointly optimizing the UAV&#39;s trajectory and the phase shifts of reflecting elements of IRS, when the UE moves and the selection of IRSs is considered for the energy saving purpose. Since the system is complex and the environment is dynamic, it is challenging to derive low-complexity algorithms by using conventional optimization methods. To address this issue, we first propose a deep Q-network (DQN)-based algorithm by discretizing the trajectory, which has the advantage of training time. Furthermore, we propose a deep deterministic policy gradient (DDPG)-based algorithm to tackle the case with continuous trajectory for achieving better performance. The experimental results show that the proposed algorithms achieve considerable performance compared to other traditional solutions.},
  archive      = {J_TMC},
  author       = {Liang Wang and Kezhi Wang and Cunhua Pan and Nauman Aslam},
  doi          = {10.1109/TMC.2022.3200998},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6543-6553},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint trajectory and passive beamforming design for intelligent reflecting surface-aided UAV communications: A deep reinforcement learning approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrated sensing and communication in UAV swarms for
cooperative multiple targets tracking. <em>TMC</em>, <em>22</em>(11),
6526–6542. (<a href="https://doi.org/10.1109/TMC.2022.3193499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various interconnected Internet of Things (IoT) devices have emerged, led by the intelligence of the IoT, to realize exceptional interaction with the physical world. In this context, UAV swarm-enabled Multiple Targets Tracking (UAV-MTT), which can sense and track mobile targets for many applications such as hit-and-run, is an appealing topic. Unfortunately, UAVs cannot implement real-time MTT based on the traditional centralized pattern due to the complicated road network environment. It is also challenging to realize low-overhead UAV swarm cooperation in a distributed architecture for the real-time MTT. To address the problem, we propose a cyber-twin-based distributed tracking algorithm to update and optimize a trained digital model for real-time MTT. We then design a distributed cooperative tracking framework to promote MTT performance. In the design, both short-distance and long-distance distributed tracking cooperation manners are first realized with low energy consumption in communication by integrating resources of sensing and communication. Resource integration promotes target sensing efficiency with a highly successful tracking ratio as well. Theoretical derivation proves our algorithmic convergence. Hardware-in-the-loop simulation results demonstrate that our proposed algorithm can remarkably save 65.7% energy consumption in communication compared to other benchmarks while efficiently promoting 20.0% sensing performance.},
  archive      = {J_TMC},
  author       = {Longyu Zhou and Supeng Leng and Qing Wang and Qiang Liu},
  doi          = {10.1109/TMC.2022.3193499},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6526-6542},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Integrated sensing and communication in UAV swarms for cooperative multiple targets tracking},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). HealthFort: A cloud-based eHealth system with conditional
forward transparency and secure provenance via blockchain. <em>TMC</em>,
<em>22</em>(11), 6508–6525. (<a
href="https://doi.org/10.1109/TMC.2022.3199048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a servers-aided password-based subsequent-key-locked encryption mechanism to ensure the confidentiality of outsourced electronic health records (EHRs). The encryption mechanism achieves conditional forward transparency: a doctor can only access a patient&#39;s EHRs related to the current diagnosis with the patient&#39;s delegation. It also achieves portability: to delegate a doctor for accessing a specific part of EHRs, the patient only needs to send one key (at most 256 bits) in addition to the delegation information to the doctor; the patient does not need to maintain any secret in a local device. Then, we propose a blockchain-based secure EHR provenance mechanism, where a data structure of EHR provenance record is designed to precisely reflect the EHRs’ provenance information; a smart contract on a public blockchain is deployed to secure both EHRs and the corresponding provenance records. Finally, we develop a cloud-based eHealth system, dubbed HealthFort, based on the two mechanisms. Security analysis and comprehensive performance evaluation are conducted to demonstrate that HealthFort is secure and efficient.},
  archive      = {J_TMC},
  author       = {Shiyu Li and Yuan Zhang and Chunxiang Xu and Nan Cheng and Zhi Liu and Yicong Du and Xuemin Shen},
  doi          = {10.1109/TMC.2022.3199048},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6508-6525},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HealthFort: A cloud-based eHealth system with conditional forward transparency and secure provenance via blockchain},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HCFL: A high compression approach for
communication-efficient federated learning in very large scale IoT
networks. <em>TMC</em>, <em>22</em>(11), 6495–6507. (<a
href="https://doi.org/10.1109/TMC.2022.3190510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a new artificial intelligence concept that enables Internet-of-Things (IoT) devices to learn a collaborative model without sending the raw data to centralized nodes for processing. Despite numerous advantages, low computing resources at IoT devices and high communication costs for exchanging model parameters make applications of FL in massive IoT networks very limited. In this work, we develop a novel compression scheme for FL, called high-compression federated learning (HCFL) , for very large scale IoT networks. HCFL can reduce the data load for FL processes without changing their structure and hyperparameters. In this way, we not only can significantly reduce communication costs, but also make intensive learning processes more adaptable on low-computing resource IoT devices. Furthermore, we investigate a relationship between the number of IoT devices and the convergence level of the FL model and thereby better assess the quality of the FL process. We demonstrate our HCFL scheme in both simulations and mathematical analyses. Our proposed theoretical research can be used as a minimum level of satisfaction, proving that the FL process can achieve good performance when a determined configuration is met. Therefore, we show that HCFL is applicable in any FL-integrated networks with numerous IoT devices.},
  archive      = {J_TMC},
  author       = {Minh-Duong Nguyen and Sang-Min Lee and Quoc-Viet Pham and Dinh Thai Hoang and Diep N. Nguyen and Won-Joo Hwang},
  doi          = {10.1109/TMC.2022.3190510},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6495-6507},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HCFL: A high compression approach for communication-efficient federated learning in very large scale IoT networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GoComfort: Comfortable navigation for autonomous vehicles
leveraging high-precision road damage crowdsensing. <em>TMC</em>,
<em>22</em>(11), 6477–6494. (<a
href="https://doi.org/10.1109/TMC.2022.3198089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed rapid advances in autonomous driving technologies. Autonomous vehicles are more likely to be accepted if they drive comfortably to avoid potholes, bumps, and other road damage conditions, especially when there are elderly and disabled passengers on board. Traditionally, sensing road damage conditions is either labor-intensive by field investigation and reporting, or inaccurate by surveillance cameras and driving recorders due to limited perspective. In this paper, we propose GoComfort, a crowdsensing-based framework to provide low-cost and fine-grained comfortable navigation for autonomous vehicles with road damage identification leveraging high-precision road sensing data. First, we propose to exploit city-wide autonomous vehicle fleets as crowdsensing participants, and employ an edge-cloud-hybrid computing paradigm to efficiently collect high-precision road damage-related data, including 3D LiDAR point clouds and street view images. Second, we design an accurate road damage identification model fusing spatial structures of point clouds and texture features of street view images, and use an active learning-based method to address the sparse labels issue. Finally, we devise two comfortable navigation scenarios, i.e., fine-grained road damage avoidance and coarse-grained city-wide navigation, and propose a hierarchical road damage assessment diagram for comfortable route planning. Experiments using real-world road sensing data in Xiamen, China show that our approach identifies road damage conditions with an accuracy of 87.5%, and achieves a user acceptance rate of 93.8% in riding comfort evaluation, outperforming the state-of-the-art baselines.},
  archive      = {J_TMC},
  author       = {Longbiao Chen and Xin He and Xiantao Zhao and Han Li and Yunyi Huang and Binbin Zhou and Wei Chen and Yongchuan Li and Chenglu Wen and Cheng Wang},
  doi          = {10.1109/TMC.2022.3198089},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6477-6494},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {GoComfort: Comfortable navigation for autonomous vehicles leveraging high-precision road damage crowdsensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FlowCog: Context-aware semantic extraction and analysis of
information flow leaks in android apps. <em>TMC</em>, <em>22</em>(11),
6460–6476. (<a href="https://doi.org/10.1109/TMC.2022.3197638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Android apps having access to private information may be legitimate, depending on whether the app provides users enough semantics to justify the access. Existing works analyzing app semantics are coarse-grained, staying on the app-level. They can only identify whether an app, as a whole, should request special permission but cannot answer whether a specific app behavior under a particular runtime context, such as information flow, is correctly justified. We propose FlowCog , an automated system to extract semantics related to information flows and correlate such semantics with given information flows to address these issues. Particularly, FlowCog statically finds all the Android views related to the given flow via control or data dependencies and then extracts semantics, such as texts and images, from these views and associated layouts. Next, FlowCog adopts natural language processing and deep learning approaches to infer whether the extracted semantics correlate with the given flow. Our evaluation shows that FlowCog can achieve an accuracy rate of 95.4% and an F 1 score of 0.953.},
  archive      = {J_TMC},
  author       = {Xuechao Du and Xiang Pan and Yinzhi Cao and Boyuan He and Gan Fan and Yan Chen and Daigang Xu},
  doi          = {10.1109/TMC.2022.3197638},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6460-6476},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FlowCog: Context-aware semantic extraction and analysis of information flow leaks in android apps},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated multi-discriminator BiWGAN-GP based collaborative
anomaly detection for virtualized network slicing. <em>TMC</em>,
<em>22</em>(11), 6445–6459. (<a
href="https://doi.org/10.1109/TMC.2022.3200059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtualized network slicing allows a multitude of logical networks to be created on a common substrate infrastructure to support diverse services. A virtualized network slice is a logical combination of multiple virtual network functions, which run on virtual machines (VMs) as software applications by virtualization techniques. As the performance of network slices hinges on the normal running of VMs, detecting and analyzing anomalies in VMs are critical. Based on the three-tier management framework of virtualized network slicing, we first develop a federated learning (FL) based three-tier distributed VM anomaly detection framework, which enables distributed network slice managers to collaboratively train a global VM anomaly detection model while keeping metrics data locally. The high-dimensional, imbalanced, and distributed data features in virtualized network slicing scenarios invalidate the existing anomaly detection models. Considering the powerful ability of generative adversarial network (GAN) in capturing the distribution from complex data, we design a new multi-discriminator Bidirectional Wasserstein GAN with Gradient Penalty (BiWGAN-GP) model to learn the normal data distribution from high-dimensional resource metrics datasets that are spread on multiple VM monitors. The multi-discriminator BiWGAN-GP model can be trained over distributed data sources, which avoids high communication and computation overhead caused by the centralized collection and processing of local data. We define an anomaly score as the discriminant criterion to quantify the deviation of new metrics data from the learned normal distribution to detect abnormal behaviors arising in VMs. The efficiency and effectiveness of the proposed collaborative anomaly detection algorithm are validated through extensive experimental evaluation on a real-world dataset.},
  archive      = {J_TMC},
  author       = {Weili Wang and Chengchao Liang and Lun Tang and Halim Yanikomeroglu and Qianbin Chen},
  doi          = {10.1109/TMC.2022.3200059},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6445-6459},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Federated multi-discriminator BiWGAN-GP based collaborative anomaly detection for virtualized network slicing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy-efficient general PoI-visiting by UAV with a
practical flight energy model. <em>TMC</em>, <em>22</em>(11), 6427–6444.
(<a href="https://doi.org/10.1109/TMC.2022.3199237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) are being widely exploited for various applications, e.g., traversing to collect data from ground sensors, patrolling to monitor key facilities, moving to aid mobile edge computing. We summarize these UAV applications and formulate a problem, namely the general waypoint-based PoI-visiting problem . Since energy is critical due to the limited onboard storage capacity, we aim at minimizing flight energy consumption. In our problem, we pay special attention to the energy consumption for turning and switching operations on flight planning, which are usually ignored in the literature but play an important role in practical UAV flights according to our real-world measurement experiments. We propose specially designed graph parts to model the turning and switching cost and thus transfer the problem into a classic graph problem, i.e., general traveling salesman problem, which can be efficiently solved. Theoretical analysis shows that such problem transformation has the graph redefinition approximation ratio upper bound, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$max\lbrace \Theta /\delta,2\rbrace$&lt;/tex-math&gt;&lt;/inline-formula&gt; , where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\Theta$&lt;/tex-math&gt;&lt;/inline-formula&gt; is related to the designed graph parts and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\delta$&lt;/tex-math&gt;&lt;/inline-formula&gt; is a constant. Finally, we evaluate our proposed algorithm by simulations. The results show that it costs less than 107% of the optimal minimum energy consumption for small scale problems and costs only 50% as much energy as a naive algorithm for large scale problems.},
  archive      = {J_TMC},
  author       = {Feng Shan and Jianping Huang and Runqun Xiong and Fang Dong and Junzhou Luo and Suyang Wang},
  doi          = {10.1109/TMC.2022.3199237},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6427-6444},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient general PoI-visiting by UAV with a practical flight energy model},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enabling combined relay selection in stochastic wireless
networks by recurrent neural computing. <em>TMC</em>, <em>22</em>(11),
6410–6426. (<a href="https://doi.org/10.1109/TMC.2022.3195288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-carrier relay selection is of particular interest and challenge due to the spatio-frequency coupling and the dynamics of available spectral and relay resources. Among a number of promising relay selection schemes, combined relay selection stands out as an equilibrium between system complexity and reliability. Recent research progress has witnessed the capability of neural computing as a powerful tool to efficiently realize combined relay selection for a given network topology where the number of relays and their locations are fixed and known. However, for contemporary wireless networks that are highly dynamic, the classic neural computing methods can hardly help out because of the scale drifts of input and output matrices. To enable multi-carrier combined relay selection in stochastic wireless networks (SWNs) where the number of available relays for selection could vary, we propose a recurrent neural network (RNN) based framework and devise several training methods suited for various application scenarios. In addition, we conduct a set of computer experiments to verify the effectiveness and efficiency of the proposed RNN-based framework compared with several baselines. With the obtained experimental results, we also evaluate and discuss the proposed framework&#39;s reliability, generalization ability, and the robustness against imperfect channel state information (CSI).},
  archive      = {J_TMC},
  author       = {Jiashen Tang and Shuping Dang and Salwani Abdullah and Mohd Zakree Ahmad Nazri and Nasser R. Sabar},
  doi          = {10.1109/TMC.2022.3195288},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6410-6426},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enabling combined relay selection in stochastic wireless networks by recurrent neural computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Electrocardiogram based group device pairing for wearables.
<em>TMC</em>, <em>22</em>(11), 6394–6409. (<a
href="https://doi.org/10.1109/TMC.2022.3200104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread usage of wearables to provide healthcare services prompts the need for secure group communication among multiple devices using group keys. Gait-based group key establishment schemes are either vulnerable to video attacks, or fail to offer a secure group key update mechanism when group device changes. In this paper, we present an electrocardiogram (ECG) signals based group device pairing protocol, which can strengthen the security and reduce the overhead of wearables. Specifically, we first design a robust and lightweight fuzzy extractor that supports secure and efficient group device association between wearables. Meanwhile, we propose Improved Martingale Randomness Extraction (IMRE) algorithm, which utilizes the trend of InterPulse Interval (IPI) from ECG signal to extract high-entropy keys. Then we present a membership management mechanism that enables group key dynamic update when group device changes. Finally, we simulate our protocol and evaluate the accuracy and efficiency by various experiments. The experimental results demonstrate that the proposed work is robust and efficient, and the threat model-based security analysis shows that the proposed protocol can prevent both active and passive attacks.},
  archive      = {J_TMC},
  author       = {Guichuan Zhao and Qi Jiang and Ximeng Liu and Xindi Ma and Ning Zhang and Jianfeng Ma},
  doi          = {10.1109/TMC.2022.3200104},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6394-6409},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Electrocardiogram based group device pairing for wearables},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DPS: Dynamic pricing and scheduling for distributed machine
learning jobs in edge-cloud networks. <em>TMC</em>, <em>22</em>(11),
6377–6393. (<a href="https://doi.org/10.1109/TMC.2022.3195765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G and Internet of Things stimulate smart applications of edge computing, such as autonomous driving and smart city. As edge computing power increases, more and more machine learning (ML) jobs will be trained in the edge-cloud network, adopting the parameter server (PS) architecture. Due to the distinct features of the edge (low-latency and the scarcity of resources), the cloud (high delay and rich computing capacity) and ML jobs (frequent communication between workers and PSs and unfixed runtime), existing cloud job pricing and scheduling algorithms are not applicable. Therefore, how to price, deploy and schedule ML jobs in the edge-cloud network becomes a challenging problem. To solve it, we propose an auction-based online framework DPS. DPS consists of three major parts: job admission control, price function design and scheduling orchestrator. DPS dynamically prices workers and PSs based on historical job information and real-time system status, and decides whether to accept the job according to the deployment cost. DPS then deploys and schedules accepted ML jobs to pursue the maximum social welfare. Through theoretical analysis, we prove that DPS can achieve a good competition ratio and truthfulness in polynomial time. Large-scale simulations and testbed experiments show that DPS can improve social welfare by at least &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$95\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; , compared with benchmark algorithms in today&#39;s cloud system.},
  archive      = {J_TMC},
  author       = {Ruiting Zhou and Ne Wang and Yifeng Huang and Jinlong Pang and Hao Chen},
  doi          = {10.1109/TMC.2022.3195765},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6377-6393},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DPS: Dynamic pricing and scheduling for distributed machine learning jobs in edge-cloud networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CrowdManager: An ontology-based interaction and management
middleware for heterogeneous mobile crowd sensing. <em>TMC</em>,
<em>22</em>(11), 6358–6376. (<a
href="https://doi.org/10.1109/TMC.2022.3199787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the enrichment of types and numbers of sensing terminals, more and more devices such as mobile phones, smart wearables, mobile robots, drones have appeared in our life, enabling the development of Mobile Crowd Sensing (MCS) technology. MCS systems has gradually changed from isomorphic sensing to heterogeneous collaborative sensing, and finally evolved into a heterogeneous multi-source sensing mode of the fusion of humans, machines and objects (things). However, state-of-the-art systems/frameworks do not well support efficient interactions and Heterogeneous Crowd Agents (HCA) management in Heterogeneous MCS (H-MCS) systems. With this in mind, this article aims at two major gaps: Efficient interaction and collaboration of HCA, automated modeling and flexible management of HCA. To deal with the challenges, we design an ontology-based interaction and management middleware (CrowdManager). Three core modules that constitute the middleware: HCA Information Extraction and Representation (HER), Ontology-based HCA Construction &amp; Management (OCM), and Communication and Interaction Module (CIM) are well demonstrated. Extensive comparative evalution suggests that our approach not only brings rich and efficient HCA management and interactive functions to H-MCS systems, but also reduces communication time and various resource occupancy rates by more than 50%.},
  archive      = {J_TMC},
  author       = {Yimeng Liu and Zhiwen Yu and Jiangtao Wang and Bin Guo and Jiangbin Su and Jiahao Liao},
  doi          = {10.1109/TMC.2022.3199787},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6358-6376},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CrowdManager: An ontology-based interaction and management middleware for heterogeneous mobile crowd sensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combination of auction theory and multi-armed bandits:
Model, algorithm, and application. <em>TMC</em>, <em>22</em>(11),
6343–6357. (<a href="https://doi.org/10.1109/TMC.2022.3197459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-armed bandit (MAB) models have always received lots of attention from multiple research communities due to their broad application domains. The optimal selection problem with unknown rewards in advance, such as ad recommendation in social networks, spectrum access in the cognitive radio field, etc., can be efficiently solved by using MAB models. In an MAB model, given &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N$&lt;/tex-math&gt;&lt;/inline-formula&gt; arms whose rewards are unknown in advance, the player selects exactly one arm in each round, and his goal is to maximize the cumulative rewards over a fixed horizon. Further, a more general model called combinatorial MAB (i.e., CMAB), where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$K$&lt;/tex-math&gt;&lt;/inline-formula&gt; arms can be played simultaneously in each round, is put forward. However, the existing CMAB models neglect the strategic behaviors of the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N$&lt;/tex-math&gt;&lt;/inline-formula&gt; arms, which indicates that one arm might report false information to increase its own profits. In fact, in many applications such as user selection in crowdsensing, the arms are not the feelingless machines but the rational individuals. To this end, we combine the upper confidence bound (UCB) with auction theory to develop a new algorithm called auction-based UCB (AUCB). We divide the auction-based CMAB problem into two sub-problems: winning arm selection and payment computation problems. For AUCB, we derive an upper bound on regret and prove the truthfulness in one round, individual rationality, and computational efficiency. In addition, we consider an extended situation that some arms may be unavailable in some rounds and the arms will bid inconsistently in different rounds. We devise another algorithm called eAUCB to solve this problem. Extensive simulations are conducted to show the significant performance of the proposed algorithms.},
  archive      = {J_TMC},
  author       = {Guoju Gao and Sijie Huang and He Huang and Mingjun Xiao and Jie Wu and Yu-E Sun and Sheng Zhang},
  doi          = {10.1109/TMC.2022.3197459},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6343-6357},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Combination of auction theory and multi-armed bandits: Model, algorithm, and application},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collective deep reinforcement learning for intelligence
sharing in the internet of intelligence-empowered edge computing.
<em>TMC</em>, <em>22</em>(11), 6327–6342. (<a
href="https://doi.org/10.1109/TMC.2022.3199812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge intelligence is emerging as a new interdiscipline to push learning intelligence from remote centers to the edge of the network. However, with its widespread deployment, new challenges arise in terms of training efficiency and service of quality (QoS). Massive repetitive model training is ubiquitous due to the inevitable needs of users for the same types of data and training results. Additionally, a smaller volume of data samples will cause the over-fitting of models. To address these issues, driven by the Internet of intelligence, this article proposes a distributed edge intelligence sharing scheme, which allows distributed edge nodes to quickly and economically improve learning performance by sharing their learned intelligence. Considering the time-varying edge network states including data collection states, computing and communication states, and node reputation states, the distributed intelligence sharing is formulated as a multi-agent Markov decision process (MDP). Then, a novel collective deep reinforcement learning (CDRL) algorithm is designed to obtain the optimal intelligence sharing policy, which consists of local soft actor-critic (SAC) learning at each edge node and collective learning between different edge nodes. Simulation results indicate our proposal outperforms the benchmark schemes in terms of learning efficiency and intelligence sharing efficiency.},
  archive      = {J_TMC},
  author       = {Qinqin Tang and Renchao Xie and Fei Richard Yu and Tianjiao Chen and Ran Zhang and Tao Huang and Yunjie Liu},
  doi          = {10.1109/TMC.2022.3199812},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6327-6342},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collective deep reinforcement learning for intelligence sharing in the internet of intelligence-empowered edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaboration in participant-centric federated learning: A
game-theoretical perspective. <em>TMC</em>, <em>22</em>(11), 6311–6326.
(<a href="https://doi.org/10.1109/TMC.2022.3194198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a promising distributed framework for collaborative artificial intelligence model training while protecting user privacy. A bootstrapping component that has attracted significant research attention is the design of incentive mechanism to stimulate user collaboration in FL. The majority of works adopt a broker-centric approach to help the central operator to attract participants and further obtain a well-trained model. Few works consider forging participant-centric collaboration among participants to pursue an FL model for their common interests, which induces dramatic differences in incentive mechanism design from the broker-centric FL. To coordinate the selfish and heterogeneous participants, we propose a novel analytic framework for incentivizing effective and efficient collaborations for participant-centric FL. Specifically, we respectively propose two novel game models for contribution-oblivious FL (COFL) and contribution-aware FL (CAFL), where the latter one implements a minimum contribution threshold mechanism. We further analyze the uniqueness and existence for Nash equilibrium of both COFL and CAFL games and design efficient algorithms to achieve equilibrium solutions. Extensive performance evaluations show that there exists free-riding phenomenon in COFL, which can be greatly alleviated through the adoption of CAFL model with the optimized minimum threshold.},
  archive      = {J_TMC},
  author       = {Guangjing Huang and Xu Chen and Tao Ouyang and Qian Ma and Lin Chen and Junshan Zhang},
  doi          = {10.1109/TMC.2022.3194198},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6311-6326},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collaboration in participant-centric federated learning: A game-theoretical perspective},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Channel adapted antenna augmentation for improved wi-fi
throughput. <em>TMC</em>, <em>22</em>(11), 6297–6310. (<a
href="https://doi.org/10.1109/TMC.2022.3195453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates how the expansion of array size may improve the spatial diversity of state-of-the-art Wi-Fi system and increase its throughput. With comprehensive Wi-Fi measurement studies with augmented antennas, we identify the potential performance gain atop spatial diversity gains from existing technologies like MIMO and beamforming. We propose WINAS, a general Wi-Fi intelligent antenna selection scheme with full system implementation that can be easily integrated with commodity Wi-Fi AP. WINAS provides substantially improved throughput for downlink traffics. Our experimental evaluation suggests that WINAS improves Wi-Fi throughput up to 1.56x, and 1.47x in average, in real user-based evaluation.},
  archive      = {J_TMC},
  author       = {Yanbo Zhang and Weiping Sun and Yidong Ren and Sung-Ju Lee and Mo Li},
  doi          = {10.1109/TMC.2022.3195453},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6297-6310},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Channel adapted antenna augmentation for improved wi-fi throughput},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Catch your breath: Simultaneous RF tracking and respiration
monitoring with radar pairs. <em>TMC</em>, <em>22</em>(11), 6283–6296.
(<a href="https://doi.org/10.1109/TMC.2022.3197416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous respiration monitoring is significant for real-life healthcare applications, but realizing it is extremely hard as wearable sensors are cumbersome and contact-free sensors largely fail to tolerate user movements. Meanwhile, tracking users indoors mostly demands user-held devices, while device-free localization can barely tell what and who it tracks. Fortunately, as both contact-free respiration monitoring and device-free localization may rely on Radio-Frequency (RF) sensing, fusing them together creates a novel system capable of continuously tracking users while recovering their fine-grained respiratory waveforms. To this end, we propose BreathCatcher as a continuous human respiration tracking system for indoor applications. To build this system, we employ commercial-grade compact radar pairs to capture RF reflections containing respiratory signals. We then propose a hybrid human respiration and position tracking algorithm to locate and identify respiratory signals from complex RF reflection mixtures. Finally, we design an encoder-decoder deep neural network driven by variational inference to recover fine-grained respiratory waveforms. Essentially, BreathCatcher cannot only obtain respiratory waveforms from multiple walking users, but also identify each user according to the latent properties of the respiratory signals. We evidently demonstrate the accuracy of both tracking and respiration monitoring via experiments involving 12 subjects and 80 man-hour data.},
  archive      = {J_TMC},
  author       = {Tianyue Zheng and Zhe Chen and Shujie Zhang and Jun Luo},
  doi          = {10.1109/TMC.2022.3197416},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6283-6296},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Catch your breath: Simultaneous RF tracking and respiration monitoring with radar pairs},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boundary tracking of continuous objects based on feasible
region search in underwater acoustic sensor networks. <em>TMC</em>,
<em>22</em>(11), 6269–6282. (<a
href="https://doi.org/10.1109/TMC.2022.3193990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boundary tracking of sea continuous objects (e.g., oil spills and radioactive waste) is a challenging task that can be tackled via underwater acoustic sensor networks . Existing methods operate by selecting sensor nodes in the proximity of the boundary, and tend to over- or underestimate the actual boundary of the continuous object. In this article, a boundary tracking algorithm termed feasible region search for continuous objects (FRSCO) is proposed. To determine a feasible region where the actual boundary lies, the proposed method first bounds the continuous object inside a minimum elliptical boundary. Within the minimum boundary ellipse, cell partition is performed through a binary tree structure, from which a set of backbone cells is selected. These roughly localize the feasible region. By constructing and deconstructing convex hulls of nodes in each backbone cell, the feasible region location uncertainty is further narrowed down. Virtual nodes are introduced in the final feasible region to determine the boundary nodes – by applying the principle of maximum entropy. Similar to virtual nodes, the selected boundary nodes do not need to correspond to the actual sensor nodes in the proximity of the boundary. Results from realistic testbed experiments and simulations show that the FRSCO exhibits effective tracking accuracy.},
  archive      = {J_TMC},
  author       = {Li Liu and Zhiyi Zhou and Guangjie Han and Miguel Martínez-García},
  doi          = {10.1109/TMC.2022.3193990},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6269-6282},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Boundary tracking of continuous objects based on feasible region search in underwater acoustic sensor networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive scheduling and power control for multi-objective
optimization in IEEE 802.15.6 based personalized wireless body area
networks. <em>TMC</em>, <em>22</em>(11), 6251–6268. (<a
href="https://doi.org/10.1109/TMC.2022.3193013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization (MOO) has been a topic of intense interest in providing flexible trade-offs between conflicting optimization criteria in wireless body area networks (WBANs). To solve diverse multi-objective optimization problems (MOPs), conventional resource management schemes have dealt with the classic issues of WBANs, such as traffic heterogeneity, emergency response, and body shadowing. However, existing approaches have difficulty achieving MOO because, despite the personalization of WBANs, they still miss the new constraints or considerations derived from user-specific characteristics. To address this problem, in this article, we propose an adaptive scheduling and power control scheme for MOO in personalized WBANs. Specifically, we investigate the existing scheduling and power control schemes for solving MOPs in WBANs, clarify their limitations, and present two feasible solutions: priority-based adaptive scheduling and deep reinforcement learning (DRL) power control. By integrating these two mechanisms in compliance with the IEEE 802.15.6 standard, we can jointly improve the optimization criteria, that is, differentiated quality of service (QoS), transmission reliability, and energy efficiency. Through comprehensive simulations, we captured the performance variations under realistic WBAN deployment scenarios and verified that the proposed scheme can achieve a higher throughput and packet delivery ratio, lower power consumption ratio, and shorter delay compared with a conventional approach.},
  archive      = {J_TMC},
  author       = {Beom-Su Kim and Babar Shah and Ki-Il Kim},
  doi          = {10.1109/TMC.2022.3193013},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6251-6268},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive scheduling and power control for multi-objective optimization in IEEE 802.15.6 based personalized wireless body area networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-dimensional sybil-proof mechanism for dynamic spectrum
access. <em>TMC</em>, <em>22</em>(11), 6237–6250. (<a
href="https://doi.org/10.1109/TMC.2022.3200044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving higher spectrum utilization, auction-based mechanisms has been regarded as a popular tool in dynamic spectrum access (DSA). Recently, Sybil attacks in auction-based DSA mechanisms have been investigated, where a cheating bidder can manipulate an auction by submitting bids under multiple fake identities. Existing Sybil-proof mechanisms in DSA are limited to prevent Sybil attacks from primary users (PUs) or secondary users (SUs). However, both of PUs and SUs may perform Sybil attacks in DSA, i.e., double Sybil attacks. The challenge of solving the double Sybil attacks is that fictitious identities and fake bids can directly affect allocation results, but the malicious bidders cannot be straightforwardly distinguished from all bidders. To resist the double Sybil attacks, we propose STEAM, the first double Sybil-proof and two-dimensional Truthful spEctrum Auction Mechanism for DSA. Specifically, STEAM merges suspicious buyers based on geographic characteristics and sorts sellers by a bid-independent sorting method to minimize the impact of untruthful bids and Sybil attacks on the allocation results. Theoretical analysis and extensive evaluations prove that STEAM is double Sybil-proof, two-dimensional truthful, individual rational and budget-balanced, while the performance loss in various metrics within 8% compared to the existing auction-based mechanisms.},
  archive      = {J_TMC},
  author       = {Xuewen Dong and Zhichao You and Yulong Shen and Di Lu and Yang Xu and Jia Liu},
  doi          = {10.1109/TMC.2022.3200044},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {6237-6250},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A two-dimensional sybil-proof mechanism for dynamic spectrum access},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Versatile RFID-based sensing: Model, algorithm, and
applications. <em>TMC</em>, <em>22</em>(10), 6223–6236. (<a
href="https://doi.org/10.1109/TMC.2022.3181170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The signal phase is one of the most important metrics in RFID-based sensing, which is a useful technique enabling many significant applications. However, existing approaches of RFID-based sensing are often restricted in terms of the sensing capability or accuracy, due to the phase entanglement problem: the phase of the RFID signal is jointly affected by multiple factors, and the change in the signal phase cannot be directly attributed to any one of them. In order to tackle this problem, we propose RF-Prism, a versatile sensing approach that can simultaneously infer multiple physical factors (i.e., location, orientation, and material of targets), purely based on the phase readings. RF-Prism includes a comprehensive model to describe how different physical factors affect the phase of the received signal, and a complete design to disentangle the phase in the multi-frequency and multi-antenna scenario. We implement RF-Prism and evaluate its performance with extensive experiments. The results show that RF-Prism simultaneously achieves a mean localization error of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\text{7.61}~cm$&lt;/tex-math&gt;&lt;/inline-formula&gt; , a mean orientation error of 9.83 degrees, a mean tracking error of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\text{6.12}~cm$&lt;/tex-math&gt;&lt;/inline-formula&gt; , and 87.9% material identification accuracy, which outperforms state-of-the-art approaches.},
  archive      = {J_TMC},
  author       = {Meng Jin and Yuan He and Songzhen Yang and Yunhao Liu and Li Yan and Yuyi Sun},
  doi          = {10.1109/TMC.2022.3181170},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6223-6236},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Versatile RFID-based sensing: Model, algorithm, and applications},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UAV velocity function design and trajectory planning for
heterogeneous visual coverage of terrestrial regions. <em>TMC</em>,
<em>22</em>(10), 6205–6222. (<a
href="https://doi.org/10.1109/TMC.2022.3182975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel approach of designing the velocity function and the trajectory for a UAV to efficiently achieve location-dependent visual coverage. Specifically, the UAV dynamically adjusts its altitude to photograph terrestrial polygons with different image resolution requirements. Unlike prior work that assumes the UAV speed is constant, the proposed approach allows the UAV to change its speed. To minimize the task completion time, we put forward a novel approach that is composed of three algorithmic components. The first component uses an aggressive method for selecting the UAV photographing altitudes, designs the UAV velocity functions, and derives the UAV flying times for all pairs of regions. Based on the UAV flying times rather than the distances, the second component utilizes an auxiliary traveling salesman problem to determine the visited order of terrestrial regions. For each terrestrial region, the third component generates candidate coverage paths and picks up the coverage path based on the UAV flying time. We also derive analytical results on the UAV trajectory length. Large-scale simulation results indicate that the proposed approach outperforms a two-dimensional trajectory planning algorithm and a greedy algorithm for planning a three-dimensional trajectory in terms of the UAV task completion time.},
  archive      = {J_TMC},
  author       = {Yun-Chun Ko and Rung-Hung Gau},
  doi          = {10.1109/TMC.2022.3182975},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6205-6222},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {UAV velocity function design and trajectory planning for heterogeneous visual coverage of terrestrial regions},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trajectory and communication design for cache- enabled UAVs
in cellular networks: A deep reinforcement learning approach.
<em>TMC</em>, <em>22</em>(10), 6190–6204. (<a
href="https://doi.org/10.1109/TMC.2022.3181308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we investigate the content transmission in a heavy-crowded multiple access cellular network, whose data traffic is offloaded through the combination of edge caching and unmanned aerial vehicle (UAV) communication. In this context, we formulate a novel optimization problem, which minimizes the sum content acquisition delay of users by optimizing the multiuser association and cache placement jointly with UAV trajectory and transmission power over a given flight duration. However, due to the uncertainty of the environment (e.g., random content requests and dynamic UAV positions), it is often difficult and impractical to solve the formulated problem using conventional optimization methods. To this end, we model our problem as a partially observable stochastic game where the macro base station (MBS) and UAVs act as agents to collectively interact with the environment to receive distinctive observations. Moreover, we take advantage of the Proximal Policy Optimization (PPO) learning strategy and propose a novel Dual-Clip PPO-based algorithm to solve the converted problem. To guide agent exploration, a new exploration criterion is proposed in which each UAV agent can obtain an intrinsic reward when it explores beyond the boundary of explored regions (BeBold). Note that the MBS agent has the extrinsic reward given by the environment only. Numerical results reveal that the proposed algorithm outperforms the standard PPO-based deep reinforcement learning algorithm. Moreover, the proposed joint design scheme can achieve a dramatic reduction of content acquisition delay compared with the benchmark schemes.},
  archive      = {J_TMC},
  author       = {Jiequ Ji and Kun Zhu and Lin Cai},
  doi          = {10.1109/TMC.2022.3181308},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6190-6204},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Trajectory and communication design for cache- enabled UAVs in cellular networks: A deep reinforcement learning approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards transmission-friendly and robust CNN models over
cloud and device. <em>TMC</em>, <em>22</em>(10), 6176–6189. (<a
href="https://doi.org/10.1109/TMC.2022.3186496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying deep convolutional neural network (CNN) models on ubiquitous Internet of Things (IoT) devices has attracted much attention from industry and academia since it greatly facilitates our lives by providing various rapid-response services. Due to the limited resources of IoT devices, cloud-assisted training of CNN models has become the mainstream. However, most existing related works suffer from a large amount of model parameter transmission and weak model robustness . To this end, this paper proposes a cloud-assisted CNN training framework with low model parameter transmission and strong model robustness. In the proposed framework, we first introduce MonoCNN, which contains only a few learnable filters, and other filters are nonlearnable. These nonlearnable filter parameters are generated according to certain rules, i.e., the filter generation function (FGF), and can be saved and reproduced by a few random seeds. Thus, the cloud server only needs to send these learnable filters and a few seeds to the IoT device. Compared to transmitting all model parameters, sending several learnable filter parameters and seeds can significantly reduce parameter transmission. Then, we investigate multiple FGFs and enable the IoT device to use the FGF to generate multiple filters and combine them into MonoCNN. Thus, MonoCNN is affected not only by the training data but also by the FGF. The rules of the FGF play a role in regularizing the MonoCNN, thereby improving its robustness. Experimental results show that compared to state-of-the-art methods, our proposed framework can reduce a large amount of model parameter transfer between the cloud server and the IoT device while improving the performance by approximately 2.2% when dealing with corrupted data.},
  archive      = {J_TMC},
  author       = {Chuntao Ding and Zhichao Lu and Felix Juefei-Xu and Vishnu Naresh Boddeti and Yidong Li and Jiannong Cao},
  doi          = {10.1109/TMC.2022.3186496},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6176-6189},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards transmission-friendly and robust CNN models over cloud and device},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SHARP: Environment and person independent activity
recognition with commodity IEEE 802.11 access points. <em>TMC</em>,
<em>22</em>(10), 6160–6175. (<a
href="https://doi.org/10.1109/TMC.2022.3185681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we present SHARP, an original approach for obtaining human activity recognition (HAR) through the use of commercial IEEE 802.11 (Wi-Fi) devices. SHARP grants the possibility to discern the activities of different persons, across different time-spans and environments. To achieve this, we devise a new technique to clean and process the channel frequency response (CFR) phase of the Wi-Fi channel, obtaining an estimate of the Doppler shift at a radio monitor device. The Doppler shift reveals the presence of moving scatterers in the environment, while not being affected by (environment-specific) static objects. SHARP is trained on data collected as a person performs seven different activities in a single environment. It is then tested on different setups, to assess its performance as the person, the day and/or the environment change with respect to those considered at training time. In the worst-case scenario, it reaches an average accuracy higher than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$95\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; , validating the effectiveness of the extracted Doppler information, used in conjunction with a learning algorithm based on a neural network, in recognizing human activities in a subject and environment independent way. The collected CFR dataset and the code are publicly available for replicability and benchmarking purposes [1].},
  archive      = {J_TMC},
  author       = {Francesca Meneghello and Domenico Garlisi and Nicolò Dal Fabbro and Ilenia Tinnirello and Michele Rossi},
  doi          = {10.1109/TMC.2022.3185681},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6160-6175},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SHARP: Environment and person independent activity recognition with commodity IEEE 802.11 access points},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reverse auction-based computation offloading and resource
allocation in mobile cloud-edge computing. <em>TMC</em>,
<em>22</em>(10), 6144–6159. (<a
href="https://doi.org/10.1109/TMC.2022.3189050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel Reverse Auction-based Computation Offloading and Resource Allocation Mechanism, named RACORAM for the mobile Cloud-Edge computing. The basic idea is that the Cloud Service Center (CSC) recruits edge server owners to replace it to accommodate offloaded computation from nearby resource-constraint Mobile Devices (MDs). In RACORAM, the reverse auction is used to stimulate edge server owners to participate in the offloading process, and the reverse auction-based computation offloading and resource allocation problem is formulated as a Mixed Integer Nonlinear Programming (MINLP) problem, aiming to minimize the cost of the CSC. The original problem is decomposed into an equivalent master problem and subproblem, and low-complexity algorithms are proposed to solve the related optimization problems. Specifically, a Constrained Gradient Descent Allocation Method (CGDAM) is first proposed to determine the computation resource allocation strategy, and then a Greedy Randomized Adaptive Search Procedure based Winning Bid Scheduling Method (GWBSM) is proposed to determine the computation offloading strategy. Meanwhile, the CSC&#39;s payment determination for the winning edge server owners is also presented. Simulations are conducted to evaluate the performance of RACORAM, and the results show that RACORAM is very close to the optimal method with significantly reduced computational complexity, and greatly outperforms the other baseline methods in terms of the CSC&#39;s cost under different scenarios.},
  archive      = {J_TMC},
  author       = {Huan Zhou and Tong Wu and Xin Chen and Shibo He and Deke Guo and Jie Wu},
  doi          = {10.1109/TMC.2022.3189050},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6144-6159},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reverse auction-based computation offloading and resource allocation in mobile cloud-edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking fall detection with wi-fi. <em>TMC</em>,
<em>22</em>(10), 6126–6143. (<a
href="https://doi.org/10.1109/TMC.2022.3188779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past decades have witnessed a surge in human fall detection with sensors, cameras, and wireless signals. Among them, Wi-Fi-based fall detection has been one of the most attractive solutions due to the ubiquitous and pervasive deployment of Wi-Fi infrastructures. However, these approaches are still difficult to be put into practical use. To push forward Wi-Fi-based fall detection for wide deployment, three major limitations concerning environmental diversity , motion diversity , and user diversity are required to be resolved. In this paper, we propose FallDar, a Wi-Fi-based deep learning-assisted fall detection system that outperforms state-of-the-art works on the three criteria simultaneously. First, to deal with environmental diversity, FallDar characterizes falls with the speed of the body, which is the most relevant and inherent feature of falling activities, making the system resilient to environmental changes. Second, to deal with motion diversity, FallDar simulates a large amount of fall data of various falling types with a DNN-based generative model. Training with these data, FallDar is endowed the capability of detecting more types of falls. Third, to deal with user diversity, FallDar proposes to incorporate the fall detection network with a user identification network. The network is designed to extract user-independent features, requiring no fall data from new users for system adjustment. We implement FallDar on commercial Wi-Fi devices and conduct experiments in home and office environments for six months. The evaluation results show that FallDar achieves a false alarm rate of 5.7% and a missed alarm rate of 3.4% across all factors, making a fundamental step towards ubiquitous fall detection with Wi-Fi.},
  archive      = {J_TMC},
  author       = {Zheng Yang and Yi Zhang and Qian Zhang},
  doi          = {10.1109/TMC.2022.3188779},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6126-6143},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Rethinking fall detection with wi-fi},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal resource allocation for crowdsourced image
processing. <em>TMC</em>, <em>22</em>(10), 6110–6125. (<a
href="https://doi.org/10.1109/TMC.2022.3182317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourced image processing has the potential to vastly impact response timeliness in various emergency situations. Because images can provide extremely important information regarding an event of interest ( hits ), sending the right images to an analyzer as soon as possible is of crucial importance. In this paper, we consider the problem of optimally assigning resources, both local (CPUs in phones) and remote (network-based GPUs) to mobile devices for processing images, ultimately sending those of interest to a centralized entity while also accounting for the energy consumption at the distributed nodes. To that end, we use the dual-path Network Utility Maximization (NUM) framework, coupled with a hit-ratio estimator and energy costs, to enable a distributed implementation of the system. We include analysis of different hit-ratio estimators using realistic trace data, first considering immediate and then delayed feedback. We address accuracy concerns when estimating the likelihood of future image hits and provide a window-based heuristic for scenarios when hit-ratio feedback is severely delayed. Our TCP-inspired window-method predicts both image hit likelihood and current wireless network congestion with great effectiveness. Results are validated using both synthetic simulations and real-life traces.},
  archive      = {J_TMC},
  author       = {Kristina Sorensen Wheatman and Fidan Mehmeti and Mark Mahon and Hang Qiu and Kevin S. Chan and Thomas F. La Porta},
  doi          = {10.1109/TMC.2022.3182317},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6110-6125},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal resource allocation for crowdsourced image processing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Online MEC offloading for V2V networks. <em>TMC</em>,
<em>22</em>(10), 6097–6109. (<a
href="https://doi.org/10.1109/TMC.2022.3186893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an enabling technology for vehicle-to-vehicle (V2V) networks, multi-access edge computing (MEC) provides a feasible platform for sharing power and resources, and offloading some of the computation-intensive tasks between vehicles. This, however, is challenging with the unpredictable variations in road traffic conditions and vehicle mobility in MEC-enabled V2V networks. Consequently, such computation task offloading can be easily disrupted, which may require frequent switching of task offloading between vehicles and degrade the Quality of Service (QoS). In this paper, we focus on the computation offloading problem under unstable connections in MEC-enabled V2V networks. We first model this as a distributed online service optimization problem, which is proved to be NP-hard. In order to minimize the out-of-service time (i.e., the service mismatching, switching and compromise time), we propose a distributed Online Instability-aware Computation Offloading (OICO) heuristic algorithm to improve the service efficiency and quality. Specifically, in order to minimize the service mismatching rate, we design an efficient Service Path Matching (SPM) algorithm for matching pairs of customer vehicles (which require offload computing services) and server vehicles (which provide edge computing services) that share the longest matching path. We evaluate OICO through real-world traces, i.e., GAIA open dataset from DiDi. Extensive simulation results demonstrate that OICO can increase the service matching rate by 25% and reduce the power consumption by about 54% per customer vehicle compared with the existing schemes.},
  archive      = {J_TMC},
  author       = {Fangming Liu and Jian Chen and Qixia Zhang and Bo Li},
  doi          = {10.1109/TMC.2022.3186893},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6097-6109},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online MEC offloading for V2V networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On performance of low-power wide-area networks with the
combining of reconfigurable intelligent surfaces and relay.
<em>TMC</em>, <em>22</em>(10), 6086–6096. (<a
href="https://doi.org/10.1109/TMC.2022.3186394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes an integration of multiple reconfigurable intelligent surfaces (RISs) with a relay to enhance the performance of a low-power wide-area (LPWA) network. Specifically, besides using the traditional relaying approach to assist the transmission between an Internet of Things (IoT) sensor and a gateway, multiple RISs are also utilized to boost the intermediate links between the IoT sensor and the relay and between the relay and the gateway. We mathematically derive the analytical expressions of average outage probability (AOP) and average symbol error probability (ASEP) of this multiple-RIS-relay aided LPWA network over Nakagami- &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$m$&lt;/tex-math&gt;&lt;/inline-formula&gt; fading channels. The performance of the proposed network is also compared with the performance of the relay-aided LPWA network without using RISs. The analytical results show that the exploitation of RISs can greatly enhances the performance of the LPWA network. Thus, the multiple-RIS-relay aided LPWA network can operate at the high frequency band for long range transmission. Moreover, the effect of various important factors such as the location of the RISs, the Nakagami- &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$m$&lt;/tex-math&gt;&lt;/inline-formula&gt; parameters, the data transmission rate, and the modulation scheme on the performance of the multiple-RIS-relay aided LPWA network are also investigated in practical scenarios.},
  archive      = {J_TMC},
  author       = {Phuong T. Tran and Ba Cao Nguyen and Tran Manh Hoang and Tan N. Nguyen},
  doi          = {10.1109/TMC.2022.3186394},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6086-6096},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On performance of low-power wide-area networks with the combining of reconfigurable intelligent surfaces and relay},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple resolution bit tracking for continuous reliable
RFID tag identification. <em>TMC</em>, <em>22</em>(10), 6071–6085. (<a
href="https://doi.org/10.1109/TMC.2022.3187289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, radio frequency identification (RFID) technology has been applied in various fields to efficiently identify objects. Considering that identification is usually performed continuously, the latest RFID approaches use previous identification results for subsequent identifications and can identify two tags per unit time. However, these approaches have not utilized bit-level collision information in ID transmissions, which can facilitate the identification. Moreover, the assumption of reliable communication is not always valid in real-world applications. In this article, we propose a new approach called the multiple resolution bit tracking (MRB) to further improve the identification performance. This approach dynamically computes a tag set that can be unambiguously identified irrespective of any missing subset. These tags are requested to transmit their IDs in the same timeslot. Strategies to handle unreliable communication have also been proposed and optimized for MRB. We performed extensive simulations to validate the performance of our proposed approach. The results show that MRB can achieve 3.7 tags per unit time, which is 1.85 times the number achieved using the existing approaches. Furthermore, MRB handles unreliable communications well and achieves a small given tag missing rate.},
  archive      = {J_TMC},
  author       = {Weiping Zhu and Jianmin Gong and Mingzhe Li and Jiannong Cao and Zongjian He and Rong Xie},
  doi          = {10.1109/TMC.2022.3187289},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6071-6085},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multiple resolution bit tracking for continuous reliable RFID tag identification},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent deep reinforcement learning for joint decoupled
user association and trajectory design in full-duplex multi-UAV
networks. <em>TMC</em>, <em>22</em>(10), 6056–6070. (<a
href="https://doi.org/10.1109/TMC.2022.3188473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-UAV networks, the downlink (DL) and uplink (UL) associations between a UAV and a user equipment (UE) is typically coupled, which restricts each UE to associate to the same UAV for both DL and UL. However, this mode may not be efficient since UAV networks can be heterogeneous (e.g., multi-tier UAV networks) and can experience high link uncertainty due to the mobility of UAVs. The introduction of full-duplex communication in a multi-UAV network further complicates the UE-UAV association. For this reason, the idea of DL-UL decoupling (DUDe) is introduced in this work, with which each UE is allowed to associate with separate UAVs for UL and DL transmissions. Besides, the UE-UAV association depends on the flight trajectory of the UAVs, which makes the DUDe design challenging. In this article, we study the joint decoupled UL-DL association and trajectory design problem for full-duplex multi-UAV networks. A joint optimization problem is formulated with the objective of maximizing the UEs’ sum-rate in both UL and DL. Since the problem is non-convex with sophisticated states and an individual UAV may not know the reward functions of other UAVs, a robust partially observable Markov decision process (POMDP) model is proposed to characterize the model uncertainty. A multi-agent deep reinforcement learning (MADRL) approach is proposed which enables each UAV to select its policy in a distributed manner. To train the actor-critic neural networks in the MADRL approach, an improved clip and count-based proximal policy optimization (PPO) algorithm is developed. In particular, a modified clip distribution is designed to deal with the hard restrictions between current and old policies, and an intrinsic reward is introduced to enhance the exploration capability. Simulation results illustrate the superiority of our proposed schemes when compared to the benchmarks. The codes are made publicly available in GitHub ( https://github.com/isdai/MADRL-PPO ).},
  archive      = {J_TMC},
  author       = {Chen Dai and Kun Zhu and Ekram Hossain},
  doi          = {10.1109/TMC.2022.3188473},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6056-6070},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-agent deep reinforcement learning for joint decoupled user association and trajectory design in full-duplex multi-UAV networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent collaborative inference via DNN decoupling:
Intermediate feature compression and edge learning. <em>TMC</em>,
<em>22</em>(10), 6041–6055. (<a
href="https://doi.org/10.1109/TMC.2022.3183098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deploying deep neural network (DNN) models via collaborative inference, which splits a pre-trained model into two parts and executes them on user equipment (UE) and edge server respectively, becomes attractive. However, the large intermediate feature of DNN impedes flexible decoupling, and existing approaches either focus on the single UE scenario or simply define tasks considering the required CPU cycles, but ignore the indivisibility of a single DNN layer. In this article, we study the multi-agent collaborative inference scenario, where a single edge server coordinates the inference of multiple UEs. Our goal is to achieve fast and energy-efficient inference for all UEs. To achieve this goal, we design a lightweight autoencoder-based method to compress the large intermediate feature at first. Then we define tasks according to the inference overhead of DNNs and formulate the problem as a Markov decision process (MDP). Finally, we propose a multi-agent hybrid proximal policy optimization (MAHPPO) algorithm to solve the optimization problem with a hybrid action space. We conduct extensive experiments with different types of networks, and the results show that our method can reduce up to 56% of inference latency and save up to 72% of energy consumption.},
  archive      = {J_TMC},
  author       = {Zhiwei Hao and Guanyu Xu and Yong Luo and Han Hu and Jianping An and Shiwen Mao},
  doi          = {10.1109/TMC.2022.3183098},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6041-6055},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-agent collaborative inference via DNN decoupling: Intermediate feature compression and edge learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling and characterization of the detection and
suppression of bogus messages in vehicular ad hoc networks.
<em>TMC</em>, <em>22</em>(10), 6027–6040. (<a
href="https://doi.org/10.1109/TMC.2022.3182005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is very important to detect and prevent bogus messages (here called rumors) in vehicular ad hoc networks (VANETs) because such misbehaviors could cause road safety problems and even casualties. In this paper, we first propose an evolutionary public goods game (EPGG) model to detect bogus messages and stimulate nodes to implement data verification. When a node detects a rumor, it immediately broadcasts an anti-rumor. We here present a susceptible, immune, and neutral (SIN) rumor diffusion model to characterize the spread of rumors and anti-rumors. Moreover, we propose a dynamic, hierarchical public goods game (DHPGG) model to analyze the symbiosis and confrontation of rumors and anti-rumors. Simulation results show these models could detect and suppress rumors effectively in VANETs.},
  archive      = {J_TMC},
  author       = {Qing Ding and Jianfeng Wang and Xinming Zhang and Dan Keun Sung},
  doi          = {10.1109/TMC.2022.3182005},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6027-6040},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Modeling and characterization of the detection and suppression of bogus messages in vehicular ad hoc networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mobility support for MIMO-NOMA user clustering in
next-generation wireless networks. <em>TMC</em>, <em>22</em>(10),
6011–6026. (<a href="https://doi.org/10.1109/TMC.2022.3186430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Orthogonal Multiple Access (NOMA) is a promising technology for future-generation wireless systems, with potential to contribute to the improvement of spectral efficiency. NOMA groups users into clusters, based on channel gain-difference. However, user mobility continuously changes the channel gain, which often requires re-clustering. In this article, we study a set of re-clustering methods: arbitrary, one-by-one and Kuhn-Munkres assignment algorithm (KMAA), that expedite link re-establishment and keep the clusters interference-free, taking into account the mobility of users. The methods are applied to automatically dissociate identified users within clusters, when the gain-difference is lower than a given threshold, followed by re-association procedure, which integrates users into different clusters, maintaining an appropriate gain-difference. Experimental results show that the KMAA method improves efficiency and capacity through minimizing the number of re-clustering events, improving resource utilization, and lowering signaling overhead. Other sets of results highlight the throughput and outage probability gains of the KMAA method across a wide range of mobility scenarios. We also provide an analysis of the KMAA algorithm when applied to MIMO-NOMA, encompassing link resiliency and maintenance of average gain-difference, among users in clusters.},
  archive      = {J_TMC},
  author       = {Muhammad Kamran Naeem and Raouf Abozariba and Md Asaduzzaman and Mohammad Patwary},
  doi          = {10.1109/TMC.2022.3186430},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {6011-6026},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobility support for MIMO-NOMA user clustering in next-generation wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mobility management in 5G and beyond: A novel smart handover
with adaptive time-to-trigger and hysteresis margin. <em>TMC</em>,
<em>22</em>(10), 5995–6010. (<a
href="https://doi.org/10.1109/TMC.2022.3188212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 5th Generation (5G) New Radio (NR) and beyond technologies will support enhanced mobile broadband, very low latency communications, and huge numbers of mobile devices. Therefore, for very high speed users, seamless mobility needs to be maintained during the migration from one cell to another in the handover. Due to the presence of a massive number of mobile devices, the management of the high mobility of a dense network becomes crucial. Moreover, a dynamic adaptation is required for the Time-to-Trigger (TTT) and hysteresis margin, which significantly impact the handover latency and overall throughput. Therefore, in this paper, we propose an online learning-based mechanism, known as L earning-based I ntelligent M obility M anagement (LIM2) , for mobility management in 5G and beyond, with an intelligent adaptation of the TTT and hysteresis values. LIM2 uses a Kalman filter to predict the future signal quality of the serving and neighbor cells, selects the target cell for the handover using state-action-reward-state-action (SARSA) -based reinforcement learning, and adapts the TTT and hysteresis using the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\epsilon$&lt;/tex-math&gt;&lt;/inline-formula&gt; - greedy policy. We implement a prototype of the LIM2 in NS-3 and extensively analyze its performance, where it is observed that the LIM2 algorithm can significantly improve the handover operation in very high speed mobility scenarios.},
  archive      = {J_TMC},
  author       = {Raja Karmakar and Georges Kaddoum and Samiran Chattopadhyay},
  doi          = {10.1109/TMC.2022.3188212},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5995-6010},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobility management in 5G and beyond: A novel smart handover with adaptive time-to-trigger and hysteresis margin},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mean-field learning for edge computing in mobile blockchain
networks. <em>TMC</em>, <em>22</em>(10), 5978–5994. (<a
href="https://doi.org/10.1109/TMC.2022.3186699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain has been leveraged to secure transactions for the m-commerce. However, the intensive computation in the mining process restricts the participation of mobile devices. Currently, some studies have deployed edge computing services to support the mining process, where edge servers managed by one Service Provider (SP) are considered. This paper investigates a more practical scenario with multiple SPs, where servers managed by different SPs have distinct capacities and prices, making miners’ offloading decisions rather complicated. To tackle the above challenges, we consider task offloading, block propagation and miner mobility comprehensively to maximize utilities of miners. Specifically, we first formulate a Markov game, and then design a learning-based offloading algorithm for off-chain computation, where a novel learning model is constructed by integrating Deep Reinforcement Learning (DRL) and Mean Field Theory (MFT) to guarantee a Nash equilibrium. Different from existing studies, each miner merely needs to respond to the average effect from others in our system, insteading of knowing policies of others. Finally, both theoritical and performance results show that our designed algorithm has superiority on average miner utilities and algorithm convergence time compared with other representative algorithms.},
  archive      = {J_TMC},
  author       = {Xiaojie Wang and Zhaolong Ning and Lei Guo and Song Guo and Xinbo Gao and Guoyin Wang},
  doi          = {10.1109/TMC.2022.3186699},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5978-5994},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mean-field learning for edge computing in mobile blockchain networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Localizing multiple acoustic sources with a single
microphone array. <em>TMC</em>, <em>22</em>(10), 5963–5977. (<a
href="https://doi.org/10.1109/TMC.2022.3186644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to localize acoustic sources can greatly improve the perception of smart devices (e.g., a smart speaker like Amazon Alexa). In this work, we study the problem of concurrently localizing multiple acoustic sources with a single smart device. Our proposal called Symphony is the first complete solution to tackle the above problem, including method, theory, and practice. The method stems from the insight that the geometric layout of microphones on the array determines the unique relationship among signals from the same source along the same arriving path. We also establish the theoretical model of Symphony , which reveals the relation between localization performance (resolution and coverage) and impacting factors (sampling rate, array aperture, and array-wall distance). Moreover, the ability to separate and localize multiple sources is also studied theoretically and numerically. We implement Symphony with different types of commercial off-the-shelf microphone arrays and evaluate its performance under different settings. The results show that Symphony has a median localization error of 0.662 m.},
  archive      = {J_TMC},
  author       = {Weiguo Wang and Jinming Li and Yuan He and Yunhao Liu},
  doi          = {10.1109/TMC.2022.3186644},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5963-5977},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Localizing multiple acoustic sources with a single microphone array},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to help emergency vehicles arrive faster: A
cooperative vehicle-road scheduling approach. <em>TMC</em>,
<em>22</em>(10), 5949–5962. (<a
href="https://doi.org/10.1109/TMC.2022.3188344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-increasing heavy traffic congestion potentially impedes the accessibility of emergency vehicles (EVs), resulting in detrimental impacts on critical services and even safety of people&#39;s lives. Hence, it is significant to propose an efficient scheduling approach to help EVs arrive faster. Existing vehicle-centric scheduling approaches aim to recommend the optimal paths for EVs based on the current traffic status while the road-centric scheduling approaches aim to improve the traffic condition and assign a higher priority for EVs to pass an intersection. With the intuition that real-time vehicle-road information interaction and strategy coordination can bring more benefits, we propose LEVID , a LE arning-based cooperative V eh I cle-roa D scheduling approach including a real-time route planning module and a collaborative traffic signal control module, which interact with each other and make decisions iteratively. The real-time route planning module adapts the artificial potential field method to address the real-time changes of traffic signals and avoid falling into a local optimum. The collaborative traffic signal control module leverages a graph attention reinforcement learning framework to extract the latent features of different intersections and abstract their interplay to learn cooperative policies. Extensive experiments based on multiple real-world datasets show that our approach outperforms the state-of-the-art baselines.},
  archive      = {J_TMC},
  author       = {Lige Ding and Dong Zhao and Zhaofeng Wang and Guang Wang and Chang Tan and Lei Fan and Huadong Ma},
  doi          = {10.1109/TMC.2022.3188344},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5949-5962},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Learning to help emergency vehicles arrive faster: A cooperative vehicle-road scheduling approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LEAF + AIO: Edge-assisted energy-aware object detection for
mobile augmented reality. <em>TMC</em>, <em>22</em>(10), 5933–5948. (<a
href="https://doi.org/10.1109/TMC.2022.3179943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today very few deep learning-based mobile augmented reality (MAR) applications are applied in mobile devices because they are significantly energy-guzzling. In this paper, we design an edge-based energy-aware MAR system that enables MAR devices to dynamically change their configurations, such as CPU frequency, computation model size, and image offloading frequency based on user preferences, camera sampling rates, and available radio resources. Our proposed dynamic MAR configuration adaptations can minimize the per frame energy consumption of multiple MAR clients without degrading their preferred MAR performance metrics, such as latency and detection accuracy. To thoroughly analyze the interactions among MAR configurations, user preferences, camera sampling rate, and energy consumption, we propose, to the best of our knowledge, the first comprehensive analytical energy model for MAR devices. Based on the proposed analytical model, we design a LEAF optimization algorithm to guide the MAR configuration adaptation and server radio resource allocation. An image offloading frequency orchestrator, coordinating with the LEAF, is developed to adaptively regulate the edge-based object detection invocations and to further improve the energy efficiency of MAR devices. Extensive evaluations are conducted to validate the performance of the proposed analytical model and algorithms.},
  archive      = {J_TMC},
  author       = {Haoxin Wang and BaekGyu Kim and Jiang Xie and Zhu Han},
  doi          = {10.1109/TMC.2022.3179943},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5933-5948},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {LEAF + AIO: Edge-assisted energy-aware object detection for mobile augmented reality},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). In-network computation for large-scale federated learning
over wireless edge networks. <em>TMC</em>, <em>22</em>(10), 5918–5932.
(<a href="https://doi.org/10.1109/TMC.2022.3190260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most conventional Federated Learning (FL) models are using a star network topology where all users aggregate their local models at a single server (e.g., a cloud server). That causes significant overhead in terms of both communications and computing at the server, delaying the training process, especially for large scale FL systems with straggling nodes. This article proposes a novel edge network architecture that enables decentralizing the model aggregation process at the server, thereby significantly reducing the training delay for the whole FL network. Specifically, we design a highly-effective in-network computation framework (INC) consisting of a user scheduling mechanism, an in-network aggregation process (INA) which is designed for both primal- and primal-dual methods in distributed machine learning problems, and a network routing algorithm with theoretical performance bounds. The in-network aggregation process, which is implemented at edge nodes and cloud node, can adapt two typical methods to allow edge networks to effectively solve the distributed machine learning problems. Under the proposed INA, we then formulate a joint routing and resource optimization problem, aiming to minimize the aggregation latency. The problem turns out to be NP-hard, and thus we propose a polynomial time routing algorithm which can achieve near optimal performance with a theoretical bound. Simulation results showed that the proposed algorithm can achieve more than 99 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; of the optimal solution and reduce the FL training latency, up to 5.6 times w.r.t other baselines. The proposed INC framework can not only help reduce the FL training latency but also significantly decrease cloud&#39;s traffic and computing overhead. By embedding the computing/aggregation tasks at the edge nodes and leveraging the multi-layer edge-network architecture, the INC framework can liberate FL from the star topology to enable large-scale FL.},
  archive      = {J_TMC},
  author       = {Thinh Quang Dinh and Diep N. Nguyen and Dinh Thai Hoang and Tran Vu Pham and Eryk Dutkiewicz},
  doi          = {10.1109/TMC.2022.3190260},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5918-5932},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {In-network computation for large-scale federated learning over wireless edge networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving mobile interactive video QoE via two-level online
cooperative learning. <em>TMC</em>, <em>22</em>(10), 5900–5917. (<a
href="https://doi.org/10.1109/TMC.2022.3179782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models, particularly reinforcement learning (RL), have demonstrated great potential in optimizing video streaming applications. However, the state-of-the-art solutions are limited to an “offline learning” paradigm, i.e., the RL models are trained in simulators and then are operated in real networks. As a result, they inevitably suffer from the simulation-to-reality gap, showing far less satisfactory performance under real conditions compared with simulated environment. In this article, we close the gap by proposing Legato, an online RL framework for real-time mobile interactive video systems. Legato puts many individual RL agents directly into the video system, which make video bitrate decisions in real-time and evolve their models over time. Legato then employs a two-level cooperative learning mechanism to enhance video QoE. First, Legato proposes a score-based robust learning algorithm to eliminate risks of quality degradation caused by the RL model&#39;s exploration attempts. Then, Legato adaptively aggregates agents following a network condition-aware manner to form its corresponding high-level RL model that can help each individual to react to unseen network conditions. We implement Legato on an interactive real-time video system. Based on the exhaustive evaluations, we find that Legato outperforms the state-of-the-art algorithms significantly across a wide range of QoE metrics.},
  archive      = {J_TMC},
  author       = {Huanhuan Zhang and Anfu Zhou and Huadong Ma},
  doi          = {10.1109/TMC.2022.3179782},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5900-5917},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Improving mobile interactive video QoE via two-level online cooperative learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IMep: Device-free multiplayer step counting with WiFi
signals. <em>TMC</em>, <em>22</em>(10), 5887–5899. (<a
href="https://doi.org/10.1109/TMC.2022.3186473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, most of the mature WiFi-based step applications can only count the steps of a single individual, and their methods cannot capture amplitude information about each person&#39;s overall actions in multiuser scenes. It is still a challenging task to build a multiplayer step counting system in a device-free manner. In this paper, we present IMep, a novel device-free system based on WiFi that can obtain the amplitude information of each person&#39;s overall step actions and count the steps of multiple people simultaneously. Our main strategy is to establish a Multiplayer Stepping Amplitude Relation Model (MSARM) and design a Multiplayer Amplitude Decomposition Algorithm (MADA) that uses Block Term Decomposition (BTD). Moreover, we put forward a new Moving Energy Method (MEM) that captures each person&#39;s step number more clearly and accurately. The experimental results show that, IMep can function successfully in an environment of up to 7 people. The accuracies in three different room settings are 95.57%, 94.66%, and 89.94%, respectively, suggesting that IMep is effective in multi-person scenarios.},
  archive      = {J_TMC},
  author       = {Jing He and Wei Yang},
  doi          = {10.1109/TMC.2022.3186473},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5887-5899},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {IMep: Device-free multiplayer step counting with WiFi signals},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EdgeAdaptor: Online configuration adaption, model selection
and resource provisioning for edge DNN inference serving at scale.
<em>TMC</em>, <em>22</em>(10), 5870–5886. (<a
href="https://doi.org/10.1109/TMC.2022.3189186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accelerating convergence of artificial intelligence and edge computing has sparked a recent wave of interest in edge intelligence. While pilot efforts focused on edge DNN inference serving for a single user or DNN application, scaling edge DNN inference serving to multiple users and applications is however nontrivial. In this paper, we propose an online optimization framework EdgeAdaptor for multi-user and multi-application edge DNN inference serving at scale, which aims to navigate the three-way trade-off between inference accuracy, latency, and resource cost via jointly optimizing the application configuration adaption, DNN model selection and edge resource provisioning on-the-fly. The underlying long-term optimization problem is difficult since it is NP-hard and involves future uncertain information. To address these dual challenges, we fuse the power of online optimization and approximate optimization into a joint optimization framework, via i) decomposing the long-term problem into a series of single-shot fractional problems with a regularization technique, and ii) rounding the fractional solution to a near-optimal integral solution with a randomized dependent scheme. Rigorous theoretical analysis derives a parameterized competition ratio of our online algorithms, and extensive trace-driven simulations verify that its empirical value is no larger than 1.4 in typical scenarios.},
  archive      = {J_TMC},
  author       = {Kongyange Zhao and Zhi Zhou and Xu Chen and Ruiting Zhou and Xiaoxi Zhang and Shuai Yu and Di Wu},
  doi          = {10.1109/TMC.2022.3189186},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5870-5886},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EdgeAdaptor: Online configuration adaption, model selection and resource provisioning for edge DNN inference serving at scale},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Destination-feedback free distributed transmit beamforming
using guided directionality. <em>TMC</em>, <em>22</em>(10), 5858–5869.
(<a href="https://doi.org/10.1109/TMC.2022.3188602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed transmit beamforming enables cooperative radios to act as one virtual antenna array, extending their communications’ range beyond the capabilities of a single radio. Most existing distributed beamforming approaches rely on the destination radio sending feedback to adjust the transmitters’ signals for coherent combining. However, relying on the destination radio&#39;s feedback limits the communications range to that of a single radio. Existing destination-feedback-free approaches rely on phase synchronization and knowing the node locations with sub-wavelength accuracy, which becomes impractical for radios mounted on high-mobility platforms like UAVs. In this article, we propose and demonstrate a destination-feedback-free distributed beamforming approach that leverages the radio&#39;s mobility and coarse location information in a dominant line-of-sight channel. In the proposed approach, one radio acts as a guide and moves to point the beam of the remaining radios towards the destination. We specify the radios’ position requirements and verify their relation to the combined signal at the destination using simulations. A proof of concept demo was implemented using software defined radios, showing up to 9 dB SNR improvement in the beamforming direction just by relying on the coarse placement of four radios.},
  archive      = {J_TMC},
  author       = {Samer Hanna and Enes Krijestorac and Danijela Cabric},
  doi          = {10.1109/TMC.2022.3188602},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5858-5869},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Destination-feedback free distributed transmit beamforming using guided directionality},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Delay-optimal distributed edge computation offloading with
correlated computation and communication workloads. <em>TMC</em>,
<em>22</em>(10), 5846–5857. (<a
href="https://doi.org/10.1109/TMC.2022.3190046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed edge computation offloading makes use of distributed wireless edge devices to perform offloaded computation in parallel, which can substantially reduce the computation time. In this article, we explore distributed edge computation offloading where the computation workloads of edge devices are correlated with their communication workloads. In particular, we study the fundamental problem of computation workload allocation and communication scheduling for minimizing the total completion time of the computation offloading. To solve this problem, we need to tackle several challenges due to the precedence constraints of computations and communications, the interference constraints of wireless edge devices, and the correlation between computation and communication workloads. We consider preemptive, half-preemptive, and non-preemptive networks for the formulated problem, respectively. For each setting, we first develop a simplified problem of computation allocation, based on which we then devise an efficient and feasible policy that can arbitrarily approach the optimal policy. For half-preemptive and non-preemptive networks, we also characterize the optimal communication orders. Our results provides useful insights for the computation-communication co-design of distributed edge computation offloading. We evaluate the proposed algorithms using simulation results, which corroborate the advantages of the algorithms.},
  archive      = {J_TMC},
  author       = {Mingyu Chen and Xiaowen Gong and Yang Cao},
  doi          = {10.1109/TMC.2022.3190046},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5846-5857},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Delay-optimal distributed edge computation offloading with correlated computation and communication workloads},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cost-effective scheduling for dependent tasks with tight
deadline constraints in mobile edge computing. <em>TMC</em>,
<em>22</em>(10), 5829–5845. (<a
href="https://doi.org/10.1109/TMC.2022.3188770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mobile Edge Computing (MEC), latency-sensitive mobile applications comprising dependent tasks can be scheduled to edge or cloud servers to reduce latency and execution costs. However, existing algorithms based on deadline distribution can hardly satisfy tight application deadlines in heterogeneous MEC due to lacking a global view of the future impacts on descendant tasks. To fill in this gap, we formulate the deadline-constrained cost optimization problem for dependent task scheduling in MEC and propose a low-complexity scheduling algorithm that considers a single task&#39;s future impacts in two stages. Specifically: (1) In the edge scheduling stage, each task is scheduled according to its successors’ latest start times instead of its sub-deadline to alleviate the lateness of its successors. An edge-only schedule plan is generated by scheduling tasks only on edge servers to save execution costs. (2) In the cloud offloading stage, in order to utilize the powerful cloud resources to satisfy the deadline, the edge-only schedule plan missing the deadline is efficiently modified by properly offloading multiple successive tasks to the cloud. Simulation results show the substantial advantage of the proposed algorithm over baselines in both online and offline scenarios.},
  archive      = {J_TMC},
  author       = {Jiong Lou and Zhiqing Tang and Songli Zhang and Weijia Jia and Wei Zhao and Jie Li},
  doi          = {10.1109/TMC.2022.3188770},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5829-5845},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cost-effective scheduling for dependent tasks with tight deadline constraints in mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous gaze tracking with implicit saliency-aware
calibration on mobile devices. <em>TMC</em>, <em>22</em>(10), 5816–5828.
(<a href="https://doi.org/10.1109/TMC.2022.3185134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaze tracking is a useful human-to-computer interface, which plays an increasingly important role in a range of mobile applications. Gaze calibration is an indispensable component of gaze tracking, which transforms the eye coordinates to the screen coordinates. The existing approaches of gaze tracking either have limited accuracy or require the user&#39;s cooperation in calibration and in turn hurt the quality of experience. We in this paper propose vGaze, continuous gaze tracking with implicit saliency-aware calibration on mobile devices. The design of vGaze stems from our insight on the temporal and spatial dependent relation between the visual saliency and the user&#39;s gaze. vGaze is implemented as a light-weight software that identifies video frames with “useful” saliency information, sensing the user&#39;s head movement, performs opportunistic calibration using only those “useful” frames, and leverages historical information for accelerating saliency detection. We implement vGaze on a commercial mobile device and evaluate its performance in various scenarios. The results show that vGaze can work at real time with video playback applications. The average error of gaze tracking is 1.51cm (2.884 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^{\circ }$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) which decreases to 0.99cm (1.891 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^{\circ }$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) with historical information and 0.57cm (1.089 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^{\circ }$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) with an indicator.},
  archive      = {J_TMC},
  author       = {Songzhou Yang and Meng Jin and Yuan He},
  doi          = {10.1109/TMC.2022.3185134},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5816-5828},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Continuous gaze tracking with implicit saliency-aware calibration on mobile devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consortium blockchain-based spectrum trading for network
slicing in 5G RAN: A multi-agent deep reinforcement learning approach.
<em>TMC</em>, <em>22</em>(10), 5801–5815. (<a
href="https://doi.org/10.1109/TMC.2022.3190449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network slicing (NS) is envisioned as an emerging paradigm for accommodating different virtual networks on a common physical infrastructure. Considering the integration of blockchain and NS, a secure decentralized spectrum trading platform can be established for autonomous radio access network (RAN) slicing. Moreover, the realization of proper incentive mechanisms for fair spectrum trading is crucial for effective RAN slicing. This paper proposes a novel hierarchical framework for blockchain-empowered spectrum trading for NS in RAN. Specifically, we deploy a consortium blockchain platform for spectrum trading among spectrum providers and buyers for slice creation, and autonomous slice adjustment. For slice creation, the spectrum providers are infrastructure providers (InPs) and buyers are mobile virtual network operators (MVNOs). Then, underloaded MVNOs with extra spectrum to spare, trade with overloaded MVNOs, for slice spectrum adjustment. For proper incentive maximization, we propose a three-stage Stackelberg game framework among InPs, seller MVNOs, and buyer MVNOs, for joint optimal pricing and demand prediction strategies. Then, a multi-agent deep reinforcement learning (MADRL) method is designed to achieve a Stackelberg equilibrium (SE). Security assessment and extensive simulation results confirm the security and efficacy of our proposed method in terms of players’ utility maximization and fairness, compared with other baselines.},
  archive      = {J_TMC},
  author       = {Gordon Owusu Boateng and Guolin Sun and Daniel Ayepah Mensah and Daniel Mawunyo Doe and Ruijie Ou and Guisong Liu},
  doi          = {10.1109/TMC.2022.3190449},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5801-5815},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Consortium blockchain-based spectrum trading for network slicing in 5G RAN: A multi-agent deep reinforcement learning approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ColO-RAN: Developing machine learning-based xApps for open
RAN closed-loop control on programmable experimental platforms.
<em>TMC</em>, <em>22</em>(10), 5787–5800. (<a
href="https://doi.org/10.1109/TMC.2022.3188013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular networks are undergoing a radical transformation toward disaggregated, fully virtualized, and programmable architectures with increasingly heterogeneous devices and applications. In this context, the open architecture standardized by the O-RAN Alliance enables algorithmic and hardware-independent Radio Access Network (RAN) adaptation through closed-loop control. O-RAN introduces Machine Learning (ML)-based network control and automation algorithms as so-called xApps running on RAN Intelligent Controllers . However, in spite of the new opportunities brought about by the Open RAN, advances in ML-based network automation have been slow, mainly because of the unavailability of large-scale datasets and experimental testing infrastructure. This slows down the development and widespread adoption of Deep Reinforcement Learning (DRL) agents on real networks, delaying progress in intelligent and autonomous RAN control. In this paper, we address these challenges by discussing insights and practical solutions for the design, training, testing, and experimental evaluation of DRL-based closed-loop control in the Open RAN. To this end, we introduce ColO-RAN, the first publicly-available large-scale O-RAN testing framework with software-defined radios-in-the-loop. Building on the scale and computational capabilities of the Colosseum wireless network emulator, ColO-RAN enables ML research at scale using O-RAN components, programmable base stations, and a “wireless data factory.” Specifically, we design and develop three exemplary xApps for DRL-based control of RAN slicing, scheduling and online model training, and evaluate their performance on a cellular network with 7 softwarized base stations and 42 users. Finally, we showcase the portability of ColO-RAN to different platforms by deploying it on Arena, an indoor programmable testbed. The lessons learned from the ColO-RAN implementation and the extensive results from our first-of-its-kind large-scale evaluation highlight the importance of experimental frameworks for the development of end-to-end intelligent RAN control pipelines, from data analysis to the design and testing of DRL agents. They also provide insights on the challenges and benefits of DRL-based adaptive control, and on the trade-offs associated to training on a live RAN. ColO-RAN and the collected large-scale dataset are publicly available to the research community.},
  archive      = {J_TMC},
  author       = {Michele Polese and Leonardo Bonati and Salvatore D&#39;Oro and Stefano Basagni and Tommaso Melodia},
  doi          = {10.1109/TMC.2022.3188013},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5787-5800},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ColO-RAN: Developing machine learning-based xApps for open RAN closed-loop control on programmable experimental platforms},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoIoT: Automatically updated IoT device identification
with semi-supervised learning. <em>TMC</em>, <em>22</em>(10), 5769–5786.
(<a href="https://doi.org/10.1109/TMC.2022.3183118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT devices bring great convenience to a person&#39;s life and industrial production. However, their rapid proliferation also troubles device management and network security. Network administrators usually need to know how many IoT devices are in the network and whether they behave normally. IoT device identification is the first step to achieving these goals. Previous IoT device identification methods reach high accuracy in a closed environment. But they are not applicable in the continuously changing environment. When new types of devices are plugged in, they cannot update themselves automatically. Besides, they usually rely on supervised learning and need lots of labeled data, which is costly. To solve these problems, we propose a novel IoT device identification model named AutoIoT , updating itself automatically when new types of devices are plugged in. Besides, it only needs a few labeled data and identifies IoT devices with high accuracy. The evaluation on two public datasets shows that AutoIoT can identify new device types only using 1.5 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 2.5 hours’ traffic and still have high accuracy after updating. Moreover, it has a better performance than other works when there are only a few labeled data, especially in an environment with scanning traffic.},
  archive      = {J_TMC},
  author       = {Linna Fan and Lin He and Yichao Wu and Shize Zhang and Zhiliang Wang and Jia Li and Jiahai Yang and Chaocan Xiang and Xiaoqian Ma},
  doi          = {10.1109/TMC.2022.3183118},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5769-5786},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AutoIoT: Automatically updated IoT device identification with semi-supervised learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ASTL: Accumulative STL with a novel robustness metric for
IoT service monitoring. <em>TMC</em>, <em>22</em>(10), 5751–5768. (<a
href="https://doi.org/10.1109/TMC.2022.3179290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things ( IoT ) has been widely deployed to support versatile applications, where an application can be satisfied by functionally compatible and non-functionally satisfiable IoT services. Considering the fact that the capacities of IoT devices may change dynamically, whether or not, and to what extent, certain constraints can be satisfied during their execution, are to be explored. This observation motivates us to formalize the interpretation of qualitative and quantitative satisfaction for prescribed constraints, and thus, to achieve IoT service monitoring at runtime. Specifically, we formulate the problem of IoT service monitoring as a constraint satisfaction problem, where multiple constraints, including spatial-temporal constraints, energy limitation, and capacity restrictions, are considered. Specification-based monitoring is developed based on S ignal T emporal L ogic ( STL ), where a novel accumulative robustness metric is proposed, denoted A ccumulative STL ( ASTL ), to emphasize the robust satisfaction over the entire time domain. Thereafter, IoT service monitoring is converted to ASTL formulae, and its constraint satisfaction is interpreted with qualitative and quantitative semantics at runtime. Case studies and extensive evaluations are conducted upon publicly-available datasets, where various influential factors are considered. Experimental results show that our ASTL performs better than the state-of-the-art&#39;s techniques with more robust satisfaction.},
  archive      = {J_TMC},
  author       = {Deng Zhao and Zhangbing Zhou and Zhipeng Cai and Sami Yangui and Xiao Xue},
  doi          = {10.1109/TMC.2022.3179290},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5751-5768},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ASTL: Accumulative STL with a novel robustness metric for IoT service monitoring},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An incentive auction for heterogeneous client selection in
federated learning. <em>TMC</em>, <em>22</em>(10), 5733–5750. (<a
href="https://doi.org/10.1109/TMC.2022.3182876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a new distributed machine learning (ML) approach which enables thousands of mobile devices to collaboratively train artificial intelligence (AI) models using local data without compromising user privacy. Although FL represents a promising computing paradigm, such training process can not be fully realized without an appropriate economic mechanism that incentivizes the participation of heterogeneous clients. This work targets social cost minimization, and studies the incentive mechanism design in FL through a procurement auction. Different from existing literature, we consider a practical scenario of FL where clients are selected and scheduled at different global iterations to guarantee the completion of the FL job, and capture the distinct feature of FL that the number of global iterations is determined by the local accuracy of all participants to balance between computation and communication. Our auction framework &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A_{FL}$&lt;/tex-math&gt;&lt;/inline-formula&gt; first decomposes the social cost minimization problem into a series of winner determination problems (WDPs) based on the number of global iterations. To solve each WDP, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A_{FL}$&lt;/tex-math&gt;&lt;/inline-formula&gt; invokes a greedy algorithm to determine the winners, and a payment algorithm for computing remuneration to winners. Finally, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A_{FL}$&lt;/tex-math&gt;&lt;/inline-formula&gt; returns the best solution among all WDPs. We carried out theoretical analysis to prove that &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A_{FL}$&lt;/tex-math&gt;&lt;/inline-formula&gt; is truthful, individual rational, computationally efficient, and achieves a near-optimal social cost. We further extend our model to consider multiple FL jobs with corresponding budgets and propose another efficient algorithm &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A_{FL-M}$&lt;/tex-math&gt;&lt;/inline-formula&gt; to solve the extended problem. We conduct large-scale simulations based on the real-world data and testbed experiments by adopting FL frameworks FAVOR and CoCoA. Simulation and experiment results show that both &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A_{FL}$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A_{FL-M}$&lt;/tex-math&gt;&lt;/inline-formula&gt; can reduce the social cost by up to 55% compared with state-of-the-art algorithms.},
  archive      = {J_TMC},
  author       = {Jinlong Pang and Jieling Yu and Ruiting Zhou and John C.S. Lui},
  doi          = {10.1109/TMC.2022.3182876},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5733-5750},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An incentive auction for heterogeneous client selection in federated learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Age of information optimization in multi-channel based
multi-hop wireless networks. <em>TMC</em>, <em>22</em>(10), 5719–5732.
(<a href="https://doi.org/10.1109/TMC.2022.3181038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of IoT devices, with various capabilities in sensing, monitoring, and controlling, has prompted diverse emerging applications, highly relying on effective delivery of sensitive information gathered at edge devices to remote controllers for timely responses. To effectively deliver such information/status updates, this paper undertakes a holistic study of AoI in multi-hop networks by considering the relevant and realistic factors, aiming for optimizing information freshness by rapidly shipping sensitive updates captured at a source to its destination. In particular, we consider the multi-channel with OFDM (orthogonal frequency-division multiplexing) spectrum access in multi-hop networks and develop a rigorous mathematical model to optimize AoI at destination nodes. Real-world factors, including orthogonal channel access, wireless interference, and queuing model, are taken into account for the very first time to explore their impacts on the AoI. To this end, we propose two effective algorithms where the first one approximates the optimal solution as closely as we desire while the second one has polynomial time complexity, with a guaranteed performance gap to the optimal solution. The developed model and algorithms enable in-depth studies on AoI optimization problems in OFDM-based multi-hop wireless networks. Numerical results demonstrate that our solutions enjoy better AoI performance and that AoI is affected markedly by those realistic factors taken into our consideration.},
  archive      = {J_TMC},
  author       = {Jiadong Lou and Xu Yuan and Purushottam Sigdel and Xiaoqi Qin and Sastry Kompella and Nian-Feng Tzeng},
  doi          = {10.1109/TMC.2022.3181038},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5719-5732},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Age of information optimization in multi-channel based multi-hop wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aerial edge computing: Flying attitude-aware collaboration
for multi-UAV. <em>TMC</em>, <em>22</em>(10), 5706–5718. (<a
href="https://doi.org/10.1109/TMC.2022.3179399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous innovation in manufacturing, Unmanned Aerial Vehicles (UAVs) have gradually become commodities from just professional equipment. As a universal type, quadrotor UAV allows us to see its potential for applications in multiple fields. Moreover, in the brand new field of aerial computing, UAVs have started to play a leading role in providing computing services to mobile users. However, limited by the performance of onboard equipment, we often cannot rely on one UAV to complete complex computing tasks. This paper first carries out a real-world case study and discovers the importance of flying attitude in applying quadcopter UAVs to achieve aerial edge computing. Then in designing the collaboration algorithms, we apply Monte Carlo Tree Search (MCTS) to realize the independent operations of UAVs while assisting each other in accomplishing the common goals. In performance evaluation, we compare the performance of our proposed solution with the existing methods. Finally, the results show that our MCTS-based algorithm can implement efficient collaboration among UAVs while reducing energy consumption and time cost in providing AEC services.},
  archive      = {J_TMC},
  author       = {Jianwen Xu and Kaoru Ota and Mianxiong Dong},
  doi          = {10.1109/TMC.2022.3179399},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5706-5718},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Aerial edge computing: Flying attitude-aware collaboration for multi-UAV},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive deep feature fusion for continuous authentication
with data augmentation. <em>TMC</em>, <em>22</em>(10), 5690–5705. (<a
href="https://doi.org/10.1109/TMC.2022.3186614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile devices are becoming increasingly popular and are playing significant roles in our daily lives. Insufficient security and weak protection mechanisms, however, cause serious privacy leakage of the unattended devices. To fully protect mobile device privacy, we propose ADFFDA, a novel mobile continuous authentication system using an Adaptive Deep Feature Fusion scheme for effective feature representation, and a transformer-based GAN for Data Augmentation, by leveraging smartphone built-in sensors of the accelerometer, gyroscope and magnetometer. Given the normalized sensor data, ADFFDA utilizes the transformer-based GAN consisting of a transformer-based generator and a CNN-based discriminator to augment the training data for CNN training. With the augmented data and the especially-designed CNN based on the ghost module and ghost bottleneck, ADFFDA extracts deep features from the three sensors by the trained CNN, and exploits an adaptive-weighted concatenation method to adaptively fuse the CNN-extracted features. Based on the fused features, ADFFDA authenticates users by using the one-class SVM (OC-SVM) classifier. We evaluate the authentication performance of ADFFDA in terms of the efficiency of the transformer-based GAN, GAN-based data augmentation, CNN architecture, adaptive-weighted feature fusion, OC-SVM classifier, and security analysis. The experimental results show that ADFFDA obtains the best authentication performance w.r.t representative approaches, by achieving a mean equal error rate of 0.01%.},
  archive      = {J_TMC},
  author       = {Yantao Li and Li Liu and Huafeng Qin and Shaojiang Deng and Mounim A. El-Yacoubi and Gang Zhou},
  doi          = {10.1109/TMC.2022.3186614},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5690-5705},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive deep feature fusion for continuous authentication with data augmentation},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive control of local updating and model compression for
efficient federated learning. <em>TMC</em>, <em>22</em>(10), 5675–5689.
(<a href="https://doi.org/10.1109/TMC.2022.3186936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data generated at the network edge can be processed locally by leveraging the paradigm of Edge Computing (EC). Aided by EC, Federated Learning (FL) has been becoming a practical and popular approach for distributed machine learning over locally distributed data. However, FL faces three critical challenges, i.e., resource constraint, system heterogeneity and context dynamics in EC. To address these challenges, we present a training-efficient FL method, termed FedLamp , by optimizing both the L ocal upd a ting frequency and m odel com p ression ratio in the resource-constrained EC systems. We theoretically analyze the model convergence rate and obtain a convergence upper bound related to the local updating frequency and model compression ratio. Upon the convergence bound, we propose a control algorithm, that adaptively determines diverse and appropriate local updating frequencies and model compression ratios for different edge nodes, so as to reduce the waiting time and enhance the training efficiency. We evaluate the performance of FedLamp through extensive simulation and testbed experiments. Evaluation results show that FedLamp can reduce the traffic consumption by 63% and the completion time by about 52% for achieving the similar test accuracy, compared to the baselines.},
  archive      = {J_TMC},
  author       = {Yang Xu and Yunming Liao and Hongli Xu and Zhenguo Ma and Lun Wang and Jianchun Liu},
  doi          = {10.1109/TMC.2022.3186936},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5675-5689},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive control of local updating and model compression for efficient federated learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AC-SDVN: An access control protocol for video multicast in
software defined vehicular networks. <em>TMC</em>, <em>22</em>(10),
5657–5674. (<a href="https://doi.org/10.1109/TMC.2022.3180809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The way to use limited bandwidth resources to achieve high-quality video services in vehicular networks is an important research topic. A large number of studies have shown that the fast-growing field of software defined networking (SDN) can provide solutions to the problems encountered by traditional IP networks when implementing video multicasting. However, there is no research addressing the security issues for this scenario. In this paper, we explore the application scenarios of video multicast in software defined vehicular networks (SDVN), and propose a secure and effective access control protocol to solve multicast security issues. This protocol realizes the authentication of multicast video requesting vehicles and RSUs. According to the authentication results, the SDN controller constructs multicast paths that only reach legitimate RSUs and vehicles, and only the vehicle passing the authentication can obtain video decryption keys. The protocol resists common attacks and satisfies the security requirements in vehicular networks. In addition, the scheme supports batch verification, which reduces the time cost of authentication, and adopts broadcast encryption technology to effectively reduce the communication load. Compared with related schemes, our protocol performs better in terms of computation and communication cost, packet loss rate, and time delay.},
  archive      = {J_TMC},
  author       = {Xiaoyu Zhang and Hong Zhong and Jie Cui and Chengjie Gu and Irina Bolodurina and Lu Liu},
  doi          = {10.1109/TMC.2022.3180809},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5657-5674},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AC-SDVN: An access control protocol for video multicast in software defined vehicular networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified framework for joint sensing and communication in
resource constrained mobile edge networks. <em>TMC</em>,
<em>22</em>(10), 5643–5656. (<a
href="https://doi.org/10.1109/TMC.2022.3188804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowd sensing (MCS) is a promising paradigm which leverages sensor-embedded mobile devices to collect and share data. The key challenging issues in designing an MCS system include selecting appropriate users to participate in a specific sensing task and designing efficient data sensing and transmission policies for data aggregation. In mobile edge networks, the limitation on network resources including bandwidth and energy affects the design of MCS significantly. Specifically, the limited resources affect whether and how to select users for a sensing task, and the bandwidth allocated to a user affects its data sensing and transmission policies. Since user selection, bandwidth allocation, data sensing and transmission are closely coupled issues in MCS, we focus on designing a unified framework for joint sensing and communication in this paper, by jointly optimizing the aforementioned four policies under resource constraints. Simulation results show that the proposed unified framework significantly outperforms several baseline solutions without considering wireless link vulnerability and/or resource limitations.},
  archive      = {J_TMC},
  author       = {Xiaoqian Li and Gang Feng and Yao Sun and Shuang Qin and Yijing Liu},
  doi          = {10.1109/TMC.2022.3188804},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5643-5656},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A unified framework for joint sensing and communication in resource constrained mobile edge networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A triple real-time trajectory privacy protection mechanism
based on edge computing and blockchain in mobile crowdsourcing.
<em>TMC</em>, <em>22</em>(10), 5625–5642. (<a
href="https://doi.org/10.1109/TMC.2022.3187047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet of Things (IoT) and the rapid popularization of 5 G networks, the data that needs to be processed in Mobile Crowdsourcing (MCS) system is increasing every day. Traditional cloud computing can no longer meet the needs of crowdsourcing for real-time data and processing efficiency, thus, edge computing was born. Edge computing can be calculated at the edge of network so that greatly improve the efficiency and real-time performance of data processing. In addition, most of the existing privacy protection technologies are based on the trusted third parties. Therefore, in view of the semi-trustworthiness of edge servers and the transparency of blockchain, this paper proposes a triple real-time trajectory privacy protection mechanism (T-LGEB) based on edge computing and blockchain. Through combining the localized differential privacy and multiple probability extension mechanism, the T-LGEB mechanism is proposed to send the requests and data to the edge server in this paper. Then, through the spatio-temporal dynamic pseudonym mechanism proposed in the paper, the entire trajectory of task participants is divided into multiple unrelated trajectory segments with different pseudonymous identities in order to protect the trajectory privacy of task participants while ensuring high data availability and real-time data. Through a large number of experiments and comparative analysis on multiple real data sets, the proposed T-LGEB has extremely high privacy protection capabilities and data availability, and the resource consumption caused is relatively low.},
  archive      = {J_TMC},
  author       = {Weilong Wang and Yingjie Wang and Peiyong Duan and Tianen Liu and Xiangrong Tong and Zhipeng Cai},
  doi          = {10.1109/TMC.2022.3187047},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5625-5642},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A triple real-time trajectory privacy protection mechanism based on edge computing and blockchain in mobile crowdsourcing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A phoneme localization based liveness detection for
text-independent speaker verification. <em>TMC</em>, <em>22</em>(10),
5611–5624. (<a href="https://doi.org/10.1109/TMC.2022.3187432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice authentication is drawing increasing attention and becomes an attractive alternative to passwords for mobile authentication. Recent advances in mobile technology further accelerate the adoption of voice biometrics in an array of diverse mobile applications. However, recent studies show that voice authentication is vulnerable to replay attacks, where an adversary can spoof a voice authentication system using a pre-recorded voice sample collected from the victim. In this article, we propose VoiceLive, a liveness detection system for both text-dependent and text-independent voice authentication on smartphones. VoiceLive detects a live user by leveraging the user&#39;s unique vocal system and the stereo recording of smartphones. In particular, utilizing the built-in gyroscope, loudspeaker and microphone, VoiceLive first measures the smartphone&#39;s distance and angle from the user, then it captures the position specific time-difference-of-arrival (TDoA) changes in a sequence of phoneme sounds to the two microphones of the phone, and uses such unique TDoA dynamic which doesn&#39;t exist under replay attacks for liveness detection. VoiceLive is practical as it doesn&#39;t require additional hardware but two-channel stereo recording that is supported by virtually all smartphones. Our experimental evaluation with 12 participants and different types of phones shows that VoiceLive achieves over 99% detection accuracy at around 1% Equal Error Rate (EER) on the text-dependent system and around 99% accuracy and 2% EER on the text-independent one. Results also show that VoiceLive is robust to different phone positions, i.e., the user are free to hold the smartphone with distinct distances and angles.},
  archive      = {J_TMC},
  author       = {Linghan Zhang and Sheng Tan and Yingying Chen and Jie Yang},
  doi          = {10.1109/TMC.2022.3187432},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {5611-5624},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A phoneme localization based liveness detection for text-independent speaker verification},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards energy-fairness in LoRa networks. <em>TMC</em>,
<em>22</em>(9), 5597–5610. (<a
href="https://doi.org/10.1109/TMC.2022.3170461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LoRa has become one of the most promising networking technologies for Internet-of-Things applications. Distant end devices have to use a low data rate to reach a LoRa gateway, causing long in-the-air transmission time and high energy consumption. Compared with the end devices using high data rates, they will drain the batteries much earlier and the network may be broken early. Such an energy unfairness can be mitigated by deploying more gateways. However, with more gateways, more end devices may choose small spreading factors to reach closer gateways, increasing the collision probability. In this paper, we propose a networking solution for LoRa networks, namely EF-LoRa, that can achieve energy fairness among end devices by carefully allocating network resources, including frequency channels, spreading factors and transmission power. We develop a LoRa network model to study the energy consumption of the end devices, considering the unique features of LoRa networks such as the LoRaWAN MAC protocol and capacity limitation of a gateway. We formulate the energy fairness allocation as an optimization problem and propose a greedy allocation algorithm to achieve max-min fairness of energy efficiency. Extensive simulation results show that EF-LoRa can improve the energy fairness by 177.8%, compared to the state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Zhiwei Zhao and Weifeng Gao and Wan Du and Geyong Min and Wenliang Mao and Mukesh Singhal},
  doi          = {10.1109/TMC.2022.3170461},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5597-5610},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards energy-fairness in LoRa networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). To help or disturb: Introduction of crowdsourced WiFi to 5G
networks. <em>TMC</em>, <em>22</em>(9), 5583–5596. (<a
href="https://doi.org/10.1109/TMC.2022.3171181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After upgrading to 5G, a network operator still faces congestion when providing the ubiquitous wireless service to the crowd. To meet users’ ever-increasing demand, some other operators (e.g., Fon) have been developing another crowdsourced WiFi network to combine many users’ home WiFi access points and provide enlarged WiFi coverage to them. While the 5G network experiences negative network externality, the crowdsourced WiFi network helps offload traffic from 5G and its service coverage exhibits positive externality with its subscription number. To our best knowledge, we are the first to investigate how these two heterogeneous networks of diverse network externalities co-exist from an economic perspective. We propose a dynamic game theoretic model to analyze the hybrid interaction among the 5G operator, the crowdsourced WiFi operator, and users. Our user choice model with WiFi’s complementarity for 5G allows users to choose both services, departing from the traditional economics literature where a user chooses one over another alternative. Despite of non-convexity of the operators’ pricing problems, we prove that the 5G operator facing severe congestion may purposely lower his price to encourage users to add-on WiFi to offload, and he benefits from the introduction of crowdsourced WiFi. However, 5G operator with mild congestion tends to charge users more and all the users’ payoffs may decrease.},
  archive      = {J_TMC},
  author       = {Shugang Hao and Lingjie Duan},
  doi          = {10.1109/TMC.2022.3171181},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5583-5596},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {To help or disturb: Introduction of crowdsourced WiFi to 5G networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-dependent visiting trip planning with crowd density
prediction based on internet of things localization. <em>TMC</em>,
<em>22</em>(9), 5568–5582. (<a
href="https://doi.org/10.1109/TMC.2022.3168553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a time-dependent visiting trip planning (TVTP) framework to find the most efficient visiting order and plan the fastest moving paths based on Internet of Things (IoT) localization. The proposed TVTP framework consists of a deep learning based crowd density prediction model and a time-dependent visiting trip planning algorithm. In the developed prediction model, densely connected convolutional networks are explored with spatiotemporal data fusion to further reduce prediction errors. In the designed planning algorithm, visitors are guided to multiple target places at feasible time points to minimize total moving time based on predicted future crowd densities. According to our review of relevant research, this is the first framework that integrates deep learning for crowd density prediction with time-dependent planning for a multi-target visiting trip, which can precisely estimate future moving times based on predicted crowd densities and efficiently plan the optimal visiting order and guiding paths with the shortest total moving time to visit all target places. The open crowd dataset of the Osaka Asia &amp; Pacific Trade Center in Japan is adopted to evaluate the performance of existing works and TVTP. Experimental results show that our framework outperforms existing methods and can accurately predict the future crowd density of indoor people as well as significantly reduce the total moving time in the planned multi-target visiting trip.},
  archive      = {J_TMC},
  author       = {Lien-Wu Chen and Chia-Chun Weng},
  doi          = {10.1109/TMC.2022.3168553},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5568-5582},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Time-dependent visiting trip planning with crowd density prediction based on internet of things localization},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task scheduling in three-dimensional spatial crowdsourcing:
A social welfare perspective. <em>TMC</em>, <em>22</em>(9), 5555–5567.
(<a href="https://doi.org/10.1109/TMC.2022.3175305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Until recently, a novel spatial crowdsourcing paradigm, namely Three-Dimensional (3D) spatial crowdsourcing, has emerged, in which the task requestors and the workers need travel to their designated third-party workplaces, e.g., shared offices, to deliver certain services, such as DiDi station ride-sharing service, Quyundong sport training service in the Online-To-Offline (O2O) applications. In 3D spatial crowdsourcing applications, a core issue is to develop an efficient global tasklist plan, based on the tripartite matching among the three parties, i.e., task requestors, workers and workplaces, which is different from the conventional spatial crowdsourcing. In this context, one key challenge is how to suitably schedule the available workers with the consideration of the interests of all the parties, under the constraint of worker resource. To answer the questions, in this paper, we propose and study a new problem, namely Social-Welfare-driven Task Scheduling ( SWTS ) problem, which strives to schedule the workers’ continuous routines, i.e., successively implementing tasks for different requestors at different workplaces, to promote the social welfare for all the involved parties. We prove our studied problem is NP-hard, and devise two heuristic optimization algorithms to solve it. Finally, we conduct extensive experiments which verify the efficiency and effectiveness of the proposed algorithms on both real and synthetic data sets.},
  archive      = {J_TMC},
  author       = {Liang Wang and Dingqi Yang and Zhiwen Yu and Fei Xiong and Lei Han and Shirui Pan and Bin Guo},
  doi          = {10.1109/TMC.2022.3175305},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5555-5567},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Task scheduling in three-dimensional spatial crowdsourcing: A social welfare perspective},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SplitPlace: AI augmented splitting and placement of
large-scale neural networks in mobile edge environments. <em>TMC</em>,
<em>22</em>(9), 5539–5554. (<a
href="https://doi.org/10.1109/TMC.2022.3177569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning models have become ubiquitous in industry and academia alike. Deep neural networks can solve some of the most complex pattern-recognition problems today, but come with the price of massive compute and memory requirements. This makes the problem of deploying such large-scale neural networks challenging in resource-constrained mobile edge computing platforms, specifically in mission-critical domains like surveillance and healthcare. To solve this, a promising solution is to split resource-hungry neural networks into lightweight disjoint smaller components for pipelined distributed processing. At present, there are two main approaches to do this: semantic and layer-wise splitting. The former partitions a neural network into parallel disjoint models that produce a part of the result, whereas the latter partitions into sequential models that produce intermediate results. However, there is no intelligent algorithm that decides which splitting strategy to use and places such modular splits to edge nodes for optimal performance. To combat this, this work proposes a novel AI-driven online policy, SplitPlace, that uses Multi-Armed-Bandits to intelligently decide between layer and semantic splitting strategies based on the input task&#39;s service deadline demands. SplitPlace places such neural network split fragments on mobile edge devices using decision-aware reinforcement learning for efficient and scalable computing. Moreover, SplitPlace fine-tunes its placement engine to adapt to volatile environments. Our experiments on physical mobile-edge environments with real-world workloads show that SplitPlace can significantly improve the state-of-the-art in terms of average response time, deadline violation rate, inference accuracy, and total reward by up to 46, 69, 3 and 12 percent respectively.},
  archive      = {J_TMC},
  author       = {Shreshth Tuli and Giuliano Casale and Nicholas R. Jennings},
  doi          = {10.1109/TMC.2022.3177569},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5539-5554},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SplitPlace: AI augmented splitting and placement of large-scale neural networks in mobile edge environments},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SensiX: A system for best-effort inference of machine
learning models in multi-device environments. <em>TMC</em>,
<em>22</em>(9), 5525–5538. (<a
href="https://doi.org/10.1109/TMC.2022.3173914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple sensory devices on and around us are on the rise and require us to redesign a system to make an inference of ML models accurate, robust, and efficient at the deployment time. While this multiplicity opens up an exciting opportunity to leverage sensor redundancy and high availability, it is still extremely challenging to benefit from such multiplicity and boost the runtime performance of deployed ML models without requiring model retraining and engineering. From our experience of deploying ML models in multi-device environments, we uncovered two prime caveats, device and data variabilities that affect the runtime performance of ML models. To this end, we develop an ML system that addresses these variabilities without modifying deployed models by building on prior algorithmic work. It decouples model execution from sensor data and employs two essential operations between them: a) device-to-device data translation for principled mapping of training and inference data and b) quality-aware dynamic selection for systematically choosing the execution pipeline as a function of runtime accuracy. We develop and evaluate a prototype system on wearable devices with motion and audio-based models. The experimental results show that ML models achieve a 7-13% increase in runtime accuracy solely by running on top of our system, and the increase goes up to 30% in dynamic environments. This performance gain comes at the expense of 3 mW on the host device.},
  archive      = {J_TMC},
  author       = {Chulhong Min and Akhil Mathur and Alessandro Montanari and Fahim Kawsar},
  doi          = {10.1109/TMC.2022.3173914},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5525-5538},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SensiX: A system for best-effort inference of machine learning models in multi-device environments},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure and efficient coded multi-access edge computing with
generalized graph neural networks. <em>TMC</em>, <em>22</em>(9),
5504–5524. (<a href="https://doi.org/10.1109/TMC.2022.3172117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formulate a novel framework to improve security and utility of the coded multi-access edge computing (MEC) network for Internet of Things (IoT) applications where multiple edge servers (ESs) jointly process raw IoT data to obtain the final network output. To correctly recover the final output even when some processing outputs produced by malicious or malfunctioning ESs are erroneous, the network utilizes coded distributed computing (CDC) that enhances security by adding computational redundancy to the data processed by ESs. Within the framework, we propose an advanced approach to address limitations of contemporary CDC-based systems related to their inability to guarantee security when the number of malicious ESs is large and reduced network utility due to redundant computations. In this approach, the processing loads are allocated to ESs based on deep learning (DL) algorithms to identify the unknown ESs’ types (faithful or malicious) and minimize the load of malicious ESs, thereby optimizing security and utility. The proposed DL algorithms adopt the message passing neural network (NN) – a generalized graph NN with lower complexity and faster convergence than conventional NNs. We prove that our framework yields the optimal security and utility, and verify its superior performance compared with the state-of-the-art schemes.},
  archive      = {J_TMC},
  author       = {Alia Asheralieva and Dusit Niyato},
  doi          = {10.1109/TMC.2022.3172117},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5504-5524},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secure and efficient coded multi-access edge computing with generalized graph neural networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SALIENCE: An unsupervised user adaptation model for multiple
wearable sensors based human activity recognition. <em>TMC</em>,
<em>22</em>(9), 5492–5503. (<a
href="https://doi.org/10.1109/TMC.2022.3171312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised user adaptation aligns the feature distributions of the data from training users and the new user, so a well-trained wearable human activity recognition (WHAR) model can be well adapted to the new user. With the development of wearable sensors, multiple wearable sensors based WHAR is gaining more and more attention. In order to address the challenge that the transferabilities of different sensors are different, we propose SALIENCE (unsupervised u s er a daptation mode l for mult i ple w e arable se n sors based human a c tivity r e cognition) model. It aligns the data of each sensor separately to achieve local alignment, while uniformly aligning the data of all sensors to ensure global alignment. In addition, an attention mechanism is proposed to focus the activity classifier of SALIENCE on the sensors with strong feature discrimination and well distribution alignment. Experiments are conducted on two public WHAR datasets, and the experimental results show that our model can yield a competitive performance.},
  archive      = {J_TMC},
  author       = {Ling Chen and Yi Zhang and Shenghuan Miao and Sirou Zhu and Rong Hu and Liangying Peng and Mingqi Lv},
  doi          = {10.1109/TMC.2022.3171312},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5492-5503},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SALIENCE: An unsupervised user adaptation model for multiple wearable sensors based human activity recognition},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). REVeno: RTT estimation based multipath TCP in 5G multi-RAT
networks. <em>TMC</em>, <em>22</em>(9), 5479–5491. (<a
href="https://doi.org/10.1109/TMC.2022.3178092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G networks were designed to provide sufficient throughput and reliable data communication services. To achieve the targeted QoS requirements of the 5G specifications, the use of mmWaves is essential. However, mmWaves are very vulnerable to signal blockages due to their high frequency. Multipath transmission control protocol (MPTCP) can deal with this problem by transmitting data through multiple subflows using transmission control protocol (TCP). The current congestion control scheme of MPTCP was designed for wired networks and is not suitable for use in wireless networks. In this article, a new MPTCP congestion control algorithm named round trip time (RTT) estimation based Veno (REVeno) is proposed to provide better support for wireless networks by distinguishing between loss due to congestion and wireless channel errors. The proposed REVeno scheme uses a novel backlog estimation formula that considers the total buffer size and parameters that distinguish loss due to congestion and wireless channel errors. The REVeno scheme will use these estimations to minimize the reordering delay by equalizing the equilibrium RTT of all subflows. The simulation results show that the proposed REVeno scheme performs better than the existing schemes in terms of goodput and latency without adversely affecting other concurrent TCP connections in the same network.},
  archive      = {J_TMC},
  author       = {Jaewook Jung and Changsung Lee and Jungsuk Baik and Jong-Moon Chung},
  doi          = {10.1109/TMC.2022.3178092},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5479-5491},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {REVeno: RTT estimation based multipath TCP in 5G multi-RAT networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy-preserving data integrity verification for secure
mobile edge storage. <em>TMC</em>, <em>22</em>(9), 5463–5478. (<a
href="https://doi.org/10.1109/TMC.2022.3174867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) is proposed as an extension of cloud computing in the scenarios where the end devices desire better services in terms of response time. Because the edges are usually owned by individuals or small organizations with limited operation capabilities, the data on the edges are easily corrupted (due to external attacks or internal hardware failures). Therefore, it is essential to verify data integrity i the MEC. We propose two I ntegrity C hecking protocols for the mobile E dge storage, called &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\text{ICE}$&lt;/tex-math&gt;&lt;/inline-formula&gt; -basic and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\text{ICE}$&lt;/tex-math&gt;&lt;/inline-formula&gt; -batch. Our protocols allow a third-party verifier to check the data integrity on the edges without violating users’ data privacy and query pattern privacy. We rigorously prove the security and privacy guarantees of the protocols. In addition, we have investigated how to let the end devices cache some verification tags such that the communication cost between end devices and the cloud can be further reduced when a user connects to multiple edges in sequence. We have implemented a proof-of-concept system that runs &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\text{ICE}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , and extensive experiments are conducted to evaluate the performance of the proposed protocols. The theoretical analysis and experimental results demonstrate the proposed protocols are efficient both in computation and communication.},
  archive      = {J_TMC},
  author       = {Wei Tong and Wenjie Chen and Bingbing Jiang and Fengyuan Xu and Qun Li and Sheng Zhong},
  doi          = {10.1109/TMC.2022.3174867},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5463-5478},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy-preserving data integrity verification for secure mobile edge storage},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Power of redundancy: Surplus client scheduling for
federated learning against user uncertainties. <em>TMC</em>,
<em>22</em>(9), 5449–5462. (<a
href="https://doi.org/10.1109/TMC.2022.3178167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has reshaped the learning paradigm by overcoming privacy concerns and siloed data issues. In FL, an aggregator schedules a set of mobile users (MUs) to collectively train a global model with their local datasets and subsequently aggregates their model updates to obtain a new global model. However, the users have many uncertainties like unstable network connections and volatile availability, which leads to the straggler problem and deteriorates the efficiency of the FL system. Besides, the issue of non-IID datasets hinders the convergence performance of the global model. To hurdle the user uncertainties, we associate a deadline with the decision in each round and partially collect MUs’ updates after the deadline, which can be achieved by considering surplus budget constraints . Moreover, we introduce fairness constraints for the non-IID issue where we ensure that all MUs have chances to be scheduled each round but the MUs with large and diverse local datasets will preferentially be selected. We propose a deadline-aware task replication for surplus client scheduling policy , called FEDDATE-CS . FEDDATE-CS is developed based on a novel contextual-combinatorial multi-armed bandit (CCMAB) learning framework with fairness guarantee. We extend the hypercube-based CCMAB framework by integrating the Lyapunov queuing technique and rigorously prove that FEDDATE-CS achieves a sublinear regret bound when learning the optimal client scheduling solution under uncertainties. Moreover, our FEDDATE-CS provides an &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$[\mathcal {O}(1/V),\mathcal {O}(V)]$&lt;/tex-math&gt;&lt;/inline-formula&gt; regret-fairness tradeoff for any fairness control factor &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$V&amp;gt;0$&lt;/tex-math&gt;&lt;/inline-formula&gt; . We conduct extensive evaluations to verify the significant superiority of FEDDATE-CS over benchmarks.},
  archive      = {J_TMC},
  author       = {Youqi Li and Fan Li and Lixing Chen and Liehuang Zhu and Pan Zhou and Yu Wang},
  doi          = {10.1109/TMC.2022.3178167},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5449-5462},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Power of redundancy: Surplus client scheduling for federated learning against user uncertainties},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PlaceRAN: Optimal placement of virtualized network functions
in beyond 5G radio access networks. <em>TMC</em>, <em>22</em>(9),
5434–5448. (<a href="https://doi.org/10.1109/TMC.2022.3171525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fifth-generation mobile evolution introduces Next-Generation Radio Access Networks (NG-RAN), splitting the RAN protocol stack into the eight disaggregated options combined into three network units, i.e., Central, Distributed, and Radio. The disaggregated units reach full interoperability on Open RAN. Further advances allow the RAN software to be virtualized (vNG-RAN) on top of general-purpose hardware, enabling the management of disaggregated units and protocols as radio functions. The placement of these functions is challenging since the best decision must be based on multiple constraints, e.g., the RAN protocol stack split, routing paths in network topologies with restricted bandwidth and latency, asymmetric computational resources, etc. The literature does not deal with general placement problems with high functional split options and protocol stack analysis. This article proposes the first exact model for positioning radio functions for vNG-RAN planning, named PlaceRAN, as a Binary Integer Linear Programming (BILP) problem. The objective is to minimize the computing resources and maximize the aggregation of radio functions. The evaluation considered two realistic network topologies, and the results reveal that PlaceRAN achieves an optimized high-performance aggregation level. It is flexible for RAN deployment overcoming the network restrictions, and up to date with the most advanced vNG-RAN design and development.},
  archive      = {J_TMC},
  author       = {Fernando Zanferrari Morais and Gabriel Matheus F. de Almeida and Leizer Pinto and Kleber Vieira Cardoso and Luis M. Contreras and Rodrigo da Rosa Righi and Cristiano Bonato Both},
  doi          = {10.1109/TMC.2022.3171525},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5434-5448},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PlaceRAN: Optimal placement of virtualized network functions in beyond 5G radio access networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online estimation and adaptation for random access with
successive interference cancellation. <em>TMC</em>, <em>22</em>(9),
5418–5433. (<a href="https://doi.org/10.1109/TMC.2022.3179240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In slotted random access systems, when multiple users transmit packets simultaneously, owing to the successive interference cancellation (SIC) technique, the access point (AP) is able to decode them through SIC-enabled resolution procedures (SRPs), which may occupy multiple consequent slots. While such an SRP could potentially improve the system throughput, how to fully exploit it in practical systems is still questionable when SIC capability is limited. Moreover, the number of active users contending for the channel varies over time which complicates the random access algorithm design. In order to full exploit the potential of such limited SIC capability and maximize the system throughput, a novel online estimation based on Bayesian approach is introduced to estimate the number of active users in real-time and controls each user&#39;s transmission accordingly. It is shown that the throughput of the proposed algorithm can reach up to 0.693 packets/slot under practical assumptions, which is the first result achieving the throughput limit proved by Yu–Giannakis. It is further shown that the system throughput of 0.594 packets/slot (85.7 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; of the throughput limit) is achievable even when the SIC capability is restricted by two. It is also shown that the proposed online estimation and adaptation framework can be extended to further exploit collision information and the imperfect SIC.},
  archive      = {J_TMC},
  author       = {Sang-Woon Jeon and Hu Jin},
  doi          = {10.1109/TMC.2022.3179240},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5418-5433},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online estimation and adaptation for random access with successive interference cancellation},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Online crowd learning through strategic worker reports.
<em>TMC</em>, <em>22</em>(9), 5406–5417. (<a
href="https://doi.org/10.1109/TMC.2022.3172965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When it is difficult to verify contributed solutions in mobile crowdsourcing, the majority voting mechanism is widely utilized to incentivize distributed workers to provide high-quality and truthful solutions. In the majority voting mechanism, a worker is rewarded based on whether his solution is consistent with the majority. However, most prior related work relies on a strong assumption that workers’ solution accuracy levels are public knowledge, which may not hold in many practical scenarios. We relax such an assumption and propose an online mechanism, which allows the platform to learn the distribution of the workers’ solution accuracy levels via asking workers to report their private accuracy levels (which do not need to be the true values), in addition to deciding their effort levels and solution reporting strategies. The mechanism design is challenging, as neither the workers’ task solutions nor their accuracy reports can be verified. We devise a randomized reward mechanism that computes the workers’ rewards based on their reported accuracy levels, under which the workers obtain rewards if their reported solutions match the majority. We show that our mechanism induces workers to truthfully report their solution accuracy levels in the long run, in which the empirical accuracy distribution (collected from workers’ accuracy reports) converges to the actual accuracy distribution. Moreover, we show that our online mechanism converges faster when the workers are more capable of solving the tasks.},
  archive      = {J_TMC},
  author       = {Chao Huang and Haoran Yu and Jianwei Huang and Randall A. Berry},
  doi          = {10.1109/TMC.2022.3172965},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5406-5417},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online crowd learning through strategic worker reports},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-exit DNN inference acceleration based on
multi-dimensional optimization for edge intelligence. <em>TMC</em>,
<em>22</em>(9), 5389–5405. (<a
href="https://doi.org/10.1109/TMC.2022.3172402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge intelligence, as a prospective paradigm for accelerating DNN inference, is mostly implemented by model partitioning which inevitably incurs the large transmission overhead of DNN’s intermediate data. A popular solution introduces multi-exit DNNs to reduce latency by enabling early exits. However, existing work ignores the correlation between exit settings and synergistic inference, causing incoordination of device-to-edge. To address this issue, this paper first investigates the bottlenecks of executing multi-exit DNNs in edge computing and builds a novel model for inference acceleration with exit selection, model partition, and resource allocation. To tackle the intractable coupling subproblems, we propose a M ulti-exit DNN inference A cceleration framework based on M ulti-dimensional O ptimization (MAMO). In MAMO, the exit selection subproblem is first extracted from the original problem. Then, bidirectional dynamic programming is employed to determine the optimal exit setting for an arbitrary multi-exit DNN. Finally, based on the optimal exit setting, a DRL-based policy is developed to learn joint decisions of model partition and resource allocation. We deploy MAMO on a real-world testbed and evaluate its performance in various scenarios. Extensive experiments show that it can adapt to heterogeneous tasks and dynamic networks, and accelerate DNN inference by up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$13.7\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; compared with the state-of-the-art.},
  archive      = {J_TMC},
  author       = {Fang Dong and Huitian Wang and Dian Shen and Zhaowu Huang and Qiang He and Jinghui Zhang and Liangsheng Wen and Tingting Zhang},
  doi          = {10.1109/TMC.2022.3172402},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5389-5405},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-exit DNN inference acceleration based on multi-dimensional optimization for edge intelligence},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). More than scheduling: Novel and efficient coordination
algorithms for multiple readers in RFID systems. <em>TMC</em>,
<em>22</em>(9), 5375–5388. (<a
href="https://doi.org/10.1109/TMC.2022.3167843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to efficiently coordinate multiple readers to work together is critical for high throughput in RFID systems. Existing researchs focus on designing efficient reader scheduling strategies that arrange adjacent readers to work in different time to avoid signal collisions. However, the impact of unbalanced tag number of readers on tag read throughput is still challenging. In RFID systems, the distribution of tags is usually variable and uneven, making the number of tags covered by each reader (i.e., the load) imbalanced. This imbalance leads to different execution time for readers: the heavily loaded readers take longer time to collect all tags, while the other readers whose finish execution earlier have to wait in vain. To avoid this useless waiting and improve the system throughput, this paper focuses on the load balancing problem of multiple readers, which is an NP-hard problem. In this paper, we design heuristic algorithms to adjust readers’ interrogation regions and efficiently balance their loads. The amazing advantage of our algorithm is that it can be adopted by almost all existing protocols in multi-reader systems, including the reader scheduling protocol, to improve system throughput. Extensive experiments demonstrate that our algorithm can significantly improve the throughput in various scenarios.},
  archive      = {J_TMC},
  author       = {Xuan Liu and Xinning Chen and Qiuying Yang and Shigeng Zhang and Song Guo and Juan Luo and Kenli Li},
  doi          = {10.1109/TMC.2022.3167843},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5375-5388},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {More than scheduling: Novel and efficient coordination algorithms for multiple readers in RFID systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LOKO: Localization-aware roll-out planning for future mobile
networks. <em>TMC</em>, <em>22</em>(9), 5359–5374. (<a
href="https://doi.org/10.1109/TMC.2022.3168076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The roll-out phase of the next generation of mobile networks (5G) has started and operators are required to devise deployment solutions while pursuing localization accuracy maximization. Enabling location-based services is expected to be a unique selling point for service providers now able to deliver critical mobile services, e.g., autonomous driving, public safety, remote operations. In this paper, we propose a novel roll-out base station placement solution that, given a Throughput-Positioning Ratio (TPR) target, selects the location of new-generation base stations (among available candidate sites ) such that the throughput and localization accuracy are jointly maximized. Moving away from the canonical position error bound (PEB) analysis, we develop a realistic framework in which each positioning measurement is affected by errors depending upon the actual wireless channel between the measuring base station and the target device. Our solution, referred to as LOKO, is a fast-converging algorithm that can be readily applied to current 5G (or future) roll-out processes. LOKO is validated by means of an exhaustive simulation campaign considering real existing deployments of a major European network operator as well as synthetic scenarios.},
  archive      = {J_TMC},
  author       = {Antonio Albanese and Vincenzo Sciancalepore and Albert Banchs and Xavier Costa-Pérez},
  doi          = {10.1109/TMC.2022.3168076},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5359-5374},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {LOKO: Localization-aware roll-out planning for future mobile networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning with guarantee via constrained multi-armed bandit:
Theory and network applications. <em>TMC</em>, <em>22</em>(9),
5346–5358. (<a href="https://doi.org/10.1109/TMC.2022.3173792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There have been studies that consider optimizing network applications in an online learning context using multi-armed bandit models. However, existing frameworks are problematic as they only consider finding the optimal decisions to minimize the regret, but neglect the constraints (or guarantee) requirements that may be excessively violated. In this paper, we formulate the stochastic constrained multi-armed bandit model with either “time-varying” or “stochastic” multi-level rewards for network application optimizations with guarantee by taking both regret and violation into consideration. Alongside this model, we design two constrained multi-armed bandit policies, Learning with Guarantee with time-Varying rewards (LG-V) and Learning with Guarantee with Stochastic rewards (LG-S), with provable sub-linear regret and violation bounds. Moreover, we illustrate how our policies can be applied to several emerging network application optimizations , namely, (1) opportunistic multichannel selection, (2) data-guaranteed mobile crowdsensing, and (3) stability-guaranteed crowdsourced transcoding. To show the effectiveness of LG-V and LG-S in optimizing these applications with different requirements, we also conduct extensive simulations by comparing both LG-V and LG-S with existing state-of-the-art policies. We also show the impact of parameter variations, namely, the variations of the guarantee threshold and the number of selected arms, on the regrets and violations of LG-V and LG-S.},
  archive      = {J_TMC},
  author       = {Kechao Cai and Xutong Liu and Yu-Zhen Janice Chen and John C.S. Lui},
  doi          = {10.1109/TMC.2022.3173792},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5346-5358},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Learning with guarantee via constrained multi-armed bandit: Theory and network applications},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Latency versus reliability in LEO mega-constellations:
Terrestrial, aerial, or space relay? <em>TMC</em>, <em>22</em>(9),
5330–5345. (<a href="https://doi.org/10.1109/TMC.2022.3168081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large low earth orbit (LEO) mega-constellation systems have been designed and deployed as a global backbone to provide ubiquitous connectivity across the world. However, due to the high traffic load/congestion arising from the required numerous information relay/forwarding nodes, it is a challenge for LEO mega-constellation systems to set up long-distance connections between two remote terrestrial users for real-time communications, which requires strict low latency. Other than inter-LEO satellite links (ILSL), introducing third-party relays, such as terrestrial, aerial, and satellite relays, is an alternative way to improve the latency performance for wide-area deliveries of real-time traffic. However, the reliability of the transmitted signal will unavoidably degrade, because of the increased path-loss attributed to long-distance relaying transmissions. Then, to reveal the principle that the third-party relays affect the latency and reliability, in this work, an LEO satellite-terrestrial communication scenario is considered, in which two remote terrestrial users communicate with each other via an LEO mega-constellation system. Analysis models are built up to investigate the end-to-end time delay and outage performance while considering different ILSL, terrestrial, aerial, and satellite relay-assisted transmission scenarios. More specifically, by applying geometrical probability theory, exact/approximated closed-form analytical expressions have been derived for average time delay and outage probability under each case, while considering the randomness of the positions of the two terrestrial users and the relays. Finally, numerical results are presented to validate the proposed analytical models, as well as to compare the three relay assistance strategies in terms of time delay and outage probability.},
  archive      = {J_TMC},
  author       = {Gaofeng Pan and Jia Ye and Jianping An and Mohamed-Slim Alouini},
  doi          = {10.1109/TMC.2022.3168081},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5330-5345},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Latency versus reliability in LEO mega-constellations: Terrestrial, aerial, or space relay?},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Game theoretical task offloading for profit maximization in
mobile edge computing. <em>TMC</em>, <em>22</em>(9), 5313–5329. (<a
href="https://doi.org/10.1109/TMC.2022.3175218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel task offloading architecture called Flex-MEC is proposed, which achieves efficient task allocation and scheduling (TAS) between MEC servers. By adding metadata before task data, we redesign the offloading process in Flex-MEC, the TAS planning can be conducted without finishing the task data receiving. Once planning is done the task data can be directly forwarded to the allocated server and executed. This reduces latency compared to the traditional way of transmitting, planning, forwarding and executing sequentially. For TAS planning, a multi-server multi-task allocation and scheduling (MMAS) problem is formulated to maximize the MEC system profit. The MMAS problem is proven as an NP-complete problem, thus is challenging to solve. Then, a distributed scheme and a centralized scheme are proposed to solve the MMAS problem with low complexity. In the distributed scheme, the MMAS problem is converted into a non-cooperative game and the existence of Nash Equilibrium (NE) is proven and a low complexity response update algorithm is proposed to converge to NE. And the centralized scheme is based on a greedy idea and runs on a MEC controller in a centralized way. Verified by experiments, these two schemes can achieve better performance than compared schemes.},
  archive      = {J_TMC},
  author       = {Haojun Teng and Zhetao Li and Kun Cao and Saiqin Long and Song Guo and Anfeng Liu},
  doi          = {10.1109/TMC.2022.3175218},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5313-5329},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Game theoretical task offloading for profit maximization in mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated learning framework with straggling mitigation and
privacy-awareness for AI-based mobile application services.
<em>TMC</em>, <em>22</em>(9), 5296–5312. (<a
href="https://doi.org/10.1109/TMC.2022.3178949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a novel framework to address straggling and privacy issues for federated learning (FL)-based mobile application services, taking into account limited computing/communications resources at mobile users (MUs)/mobile application provider (MAP), privacy cost, the rationality and incentive competition among MUs in contributing data to the MAP. Particularly, the MAP first determines a set of the best MUs for the FL process based on the MUs’ provided information/features. To mitigate straggling problems with privacy-awareness, each selected MU can then encrypt part of local data and upload the encrypted data to the MAP for an encrypted training process, in addition to the local training process. For that, each selected MU can propose a contract to the MAP according to its expected trainable local data and privacy-protected encrypted data. To find the optimal contracts that can maximize utilities of the MAP and all the participating MUs while maintaining high learning quality of the whole system, we first develop a multi-principal one-agent contract-based problem leveraging FL-based multiple utility functions. These utility functions account for the MUs’ privacy cost, the MAP’s limited computing resources, and asymmetric information between the MAP and MUs. Then, we transform the problem into an equivalent low-complexity problem and develop a light-weight iterative algorithm to effectively find the optimal solutions. Experiments with a real-world dataset show that our framework can speed up training time up to 49% and improve prediction accuracy up to 4.6 times while enhancing the network’s social welfare, i.e., total utility of all participating entities, up to 114% under the privacy cost consideration compared with those of baseline methods.},
  archive      = {J_TMC},
  author       = {Yuris Mulya Saputra and Diep N. Nguyen and Dinh Thai Hoang and Quoc-Viet Pham and Eryk Dutkiewicz and Won-Joo Hwang},
  doi          = {10.1109/TMC.2022.3178949},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5296-5312},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Federated learning framework with straggling mitigation and privacy-awareness for AI-based mobile application services},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extending delivery range and decelerating battery aging of
logistics UAVs using public buses. <em>TMC</em>, <em>22</em>(9),
5280–5295. (<a href="https://doi.org/10.1109/TMC.2022.3167040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The battery-powered Unmanned Aerial Vehicle (UAV) is a promising alternative to traditional logistics trucks. Using UAVs can achieve much more speedy, cost-effective, and environment-friendly delivery on an urban scale. However, UAVs suffer from insufficient delivery range and battery aging. This paper presents an innovative logistics UAV scheduling framework using public buses, in which logistics U AVs L and and R echarge its battery on B uses (ULRB) to extend its delivery range and decelerate its fading battery capacity. This work correlates physical layer parameters such as the energy consumption rate, the parcels weight, UAV velocity, the battery temperature to the UAV’s path planning, the battery discharging, and the capacity fading models. Specifically, the ULRB framework consists of a single-UAV scheduling module and a multi-UAV dispatching module. In the single-UAV module, a Markov-based algorithm is utilized to plan the UAV’s flying path to land and dynamically get recharged on the bus. The latter module optimized the delivery progress in a multi-UAV, multi-parcel, and multi-bus scenario. Finally, using a large-scale real-world bus trajectory dataset, extensive evaluations are conducted to verify ULRB. The results show that ULRB can extend the UAV’s delivery range by 5.54× and decelerate the battery aging by 3.26× on average, up to 7.73× and 4.16× in extreme cases. With superior performance, ULRB is envisioned to open up a new direction towards enabling the application of logistics UAVs in smart cities.},
  archive      = {J_TMC},
  author       = {Yan Pan and Qianwu Chen and Nan Zhang and Zhigang Li and Ting Zhu and Qingye Han},
  doi          = {10.1109/TMC.2022.3167040},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5280-5295},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Extending delivery range and decelerating battery aging of logistics UAVs using public buses},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy-efficient hybrid offloading for backscatter-assisted
wirelessly powered MEC with reconfigurable intelligent surfaces.
<em>TMC</em>, <em>22</em>(9), 5262–5279. (<a
href="https://doi.org/10.1109/TMC.2022.3177454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a wireless power transfer (WPT)-based backscatter-mobile edge computing (MEC) network with a reconfigurable intelligent surface (RIS). In this network, wireless devices (WDs) offload task bits and harvest energy, and they can switch between backscatter communication (BC) and active transmission (AT) modes. We exploit the RIS to maximize energy efficiency (EE). To this end, we optimize the time/power allocations, local computing frequencies, execution times, backscattering coefficients, and RIS phase shifts. This goal results in a multi-objective optimization problem (MOOP) with conflicting objectives. Thus, we simultaneously maximize system throughput and minimize energy consumption via the Tchebycheff method, transforming into two single-objective optimization problems (SOOPs). For throughput maximization, we exploit alternating optimization (AO) to yield two sub-problems. For the first one, we derive closed-form resource allocations. For the second one, we design the RIS phase shifts via semi-definite relaxation, a difference of convex functions programming, majorization minimization techniques, and a penalty function to enforce a rank-one solution. For energy minimization, we derive closed-form resource allocations. We demonstrate the gains over several benchmarks. For instance, with a 20-element RIS, EE can be as high as 3 (Mbits/Joule), a 150% improvement over the no-RIS case (achieving only 2 (Mbits/Joule)).},
  archive      = {J_TMC},
  author       = {Shayan Zargari and Chintha Tellambura and Sanjeewa Herath},
  doi          = {10.1109/TMC.2022.3177454},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5262-5279},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient hybrid offloading for backscatter-assisted wirelessly powered MEC with reconfigurable intelligent surfaces},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EmgAuth: Unlocking smartphones with EMG signals.
<em>TMC</em>, <em>22</em>(9), 5248–5261. (<a
href="https://doi.org/10.1109/TMC.2022.3176651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Screen lock is a critical security feature for smartphones to prevent unauthorized access. Although various screen unlocking technologies, including fingerprint and facial recognition, have been widely adopted, they still have some limitations. For example, fingerprints can be stolen by special material stickers and facial recognition systems can be cheated by 3D-printed head models. In this paper, we propose EmgAuth, a novel electromyography(EMG)-based smartphone unlocking system based on the Siamese network. EmgAuth enables users to unlock their smartphones by leveraging the EMG data of the smartphone users collected from Myo armbands. When training the Siamese network, we design a special data augmentation technique to make the system resilient to the rotation of the armband, which makes EmgAuth free of calibration. We conduct extensive experiments including 80 participants and the evaluation results verify that EmgAuth can effectively authenticate users with an average true acceptance rate of 91.81% while keeping the average false acceptance rate of 7.43%. In addition, we also demonstrate that EmgAuth can work well for smartphones with different screen sizes and for different scenarios when users are placing smartphones at different locations and with different orientations. EmgAuth shows great promise to serve as a good supplement for existing screen unlocking systems to improve the safety of smartphones.},
  archive      = {J_TMC},
  author       = {Boyu Fan and Xiang Su and Jianwei Niu and Pan Hui},
  doi          = {10.1109/TMC.2022.3176651},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5248-5261},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EmgAuth: Unlocking smartphones with EMG signals},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ELITE: An intelligent digital twin-based hierarchical
routing scheme for softwarized vehicular networks. <em>TMC</em>,
<em>22</em>(9), 5231–5247. (<a
href="https://doi.org/10.1109/TMC.2022.3179254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-Defined Vehicular Network (SDVN) is a networking architecture that can provide centralized control for vehicular networks. However, the design for routing policies in SDVNs is generally influenced by several limitations, such as frequent topological changes, complex service requests, and long model training time. Intelligent Digital Twin-based Software-Defined Vehicular Networks (IDT-SDVN) can overcome these weaknesses and maximize the advantages of the conventional SDVN architecture by enabling the controller to construct virtual network spaces and provide virtual instances of corresponding physical objects within the Digital Twin (DT). In this paper, we propose a junction-based hierarchical routing scheme in IDT-SDVN, namely, int el ligent d i gital t win hi e rarchical (ELITE) routing. The proposed scheme is conducted in four phases: policy training and generation in the virtual network, and deployment and relay selection in physical networks. First, the policy learning phase employs several parallel agents in DT networks and derives multiple single-target policies. Second, the generation phase combines the learned policies and generates new policies based on complex communication requirements. Third, the deployment phase selects the most suitable generated policy according to the real-time network status and message types. A road path is calculated by the controller based on the selected policy and then sent to the requester vehicle. Finally, the relay selection phase is utilized to determine relay vehicles in a hop-by-hop process along the selected path. Simulation results demonstrate that ELITE achieves substantial improvements in terms of packet delivery ratio, end-to-end delay, and communication overhead compared with its counterparts.},
  archive      = {J_TMC},
  author       = {Liang Zhao and Zhenguo Bi and Ammar Hawbani and Keping Yu and Yan Zhang and Mohsen Guizani},
  doi          = {10.1109/TMC.2022.3179254},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5231-5247},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ELITE: An intelligent digital twin-based hierarchical routing scheme for softwarized vehicular networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient integrity authentication scheme for large-scale
RFID systems. <em>TMC</em>, <em>22</em>(9), 5216–5230. (<a
href="https://doi.org/10.1109/TMC.2022.3172486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Major manufacturers and retailers are increasingly using RFID systems in supply-chain scenarios, where theft of goods during transport typically causes significant economic losses. This paper studies how to achieve time-efficient and secure integrity authentication solutions for RFID systems. We start with a straightforward solution called SecAuth, which uses a secure identity stored on reserved memory to securely authenticate the tags. We then propose a time efficient KTAuth protocol, which designs a verification chain mechanism to efficiently authenticate a large set of tags based on a small set of pre-defined key tags. We point out that the limitation of KTAuth is that it takes too much overhead to write a large block of data to tag memory, which leads to the proposed group selection mechanism. The KTAuth with group selection (KTAuth-GS) could select key tags with a single select command, which helps to quickly identify the key tags and reduces the data writes on them. Experiments and simulation results demonstrate that the proposed KTAuth-GS can defend against counterfeiting attacks by providing more reliable results and reducing the execution time by as much as a factor of 5 when compared with a baseline tag identification protocol.},
  archive      = {J_TMC},
  author       = {Xin Xie and Xiulong Liu and Junxiao Wang and Song Guo and Heng Qi and Keqiu Li},
  doi          = {10.1109/TMC.2022.3172486},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5216-5230},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Efficient integrity authentication scheme for large-scale RFID systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DSW: One-shot learning scheme for device-free acoustic
gesture signals. <em>TMC</em>, <em>22</em>(9), 5198–5215. (<a
href="https://doi.org/10.1109/TMC.2022.3175170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a Dynamic Speed Warping (DSW) algorithm to enable one-shot learning for device-free acoustic gesture signals performed by different users. The design of DSW is based on the observation that the gesture type is determined by the trajectory of hand components rather than the movement speed. By dynamically scaling the speed distribution and tracking the movement distance along the trajectory, DSW can effectively match gesture signals from different domains with a ten-fold difference in speeds. Our experimental results show that DSW can achieve a recognition accuracy of 97% for gestures performed by unknown users while only using one training sample of each gesture type from four training users.},
  archive      = {J_TMC},
  author       = {Xun Wang and Ke Sun and Ting Zhao and Wei Wang and Qing Gu},
  doi          = {10.1109/TMC.2022.3175170},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5198-5215},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DSW: One-shot learning scheme for device-free acoustic gesture signals},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DRX in NR unlicensed for B5G wireless: Modeling and
analysis. <em>TMC</em>, <em>22</em>(9), 5184–5197. (<a
href="https://doi.org/10.1109/TMC.2022.3168510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation in the demand of high data rate and improved performance has urged the wireless vendors to think of extending 5G New Radio (NR) in unlicensed bands. The unlicensed band is typically used by Wi-Fi/Wi-Gig, resulting in the reduced probability of the availability of channel for transmission of data. The User Equipment (UE) has to keep its radio circuitry ON and wait until it gets access to the unlicensed channel again. This process escalates the energy expense of the battery-constrained mobile devices. Discontinuous Reception (DRX) introduced in LTE and 5G can also be used in NR-Unlicensed (NR-U) to reduce the UE&#39;s energy consumption. In this article we introduce a DRX mechanism over NR-U networks for both Standalone (SA) and Non-Standalone (NSA) deployment modes. We used two different flavors, Beam-Search and Beam-Aware, to model the DRX mechanism. Hence, the proposed DRX mechanisms are: Standalone DRX with Beam-Search (SBS-DRX), Standalone DRX with Beam-Aware (SBA-DRX), Non-Standalone DRX with Beam-Search (NBS-DRX), and Non-Standalone DRX with Beam-Aware (NBA-DRX). Semi-Markov based modeling is used to show the estimation of power-saving, average delay, and resource utilization in the proposed NR-U DRX mechanism. Mathematical analysis and simulation results indicate that DRX in NR-U significantly improves the UE&#39;s power-saving, average delay, and resources utilized by the network. The power-saving achieved with SBA-DRX is &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$21.13\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$24.84\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; higher than 5G NR DRX for both Trace 1 and Trace 2, respectively. Moreover, the delay achieved with NBA-DRX is &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$19.16\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; less than NBS-DRX with &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$18\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; less resource utilization.},
  archive      = {J_TMC},
  author       = {Mukesh Kumar Maheshwari and Eshita Rastogi and Abhishek Roy and Navrati Saxena and Dong Ryeol Shin},
  doi          = {10.1109/TMC.2022.3168510},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5184-5197},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DRX in NR unlicensed for B5G wireless: Modeling and analysis},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed pricing and bandwidth allocation in crowdsourced
wireless community networks. <em>TMC</em>, <em>22</em>(9), 5170–5183.
(<a href="https://doi.org/10.1109/TMC.2022.3174000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of global mobile data traffic, Wi-Fi plays an increasingly important role in expanding network capacity. To overcome the geographical coverage limit of Wi-Fi APs, especially for mobile users, the crowdsourced wireless community network has emerged as a cost-effcient way for providing Internet access services. For instance, it is plausible to share their private residential Wi-Fi APs with each other by designing some tailored incentive/pricing mechanisms.Thus motivated, we propose a distributed pricing and bandwidth allocation scheme to maximize the profit of Wi-Fi providers and provide better Internet services to mobile users. Firstly, we study the stationary networks with incomplete information of users and propose distributed pricing and bandwidth allocation algorithms for single-AP regions and AP group regions, respectively. Then, we generalize the study to dynamic networks and explore distributed pricing based on the statistics of users’ mobility. Further, we design an online bandwidth allocation algorithm according to the real-time user information. Simulation results demonstrate that the proposed distributed pricing and bandwidth allocation scheme, comparing with the operator&#39;s pricing scheme, has a better performance on both Wi-Fi APs’ profit and user experience.},
  archive      = {J_TMC},
  author       = {Yongmin Zhang and Cenchen Ji and Nan Qiao and Ju Ren and Yaoxue Zhang and Yuanyuan Yang},
  doi          = {10.1109/TMC.2022.3174000},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5170-5183},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed pricing and bandwidth allocation in crowdsourced wireless community networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disguised as privacy: Data poisoning attacks against
differentially private crowdsensing systems. <em>TMC</em>,
<em>22</em>(9), 5155–5169. (<a
href="https://doi.org/10.1109/TMC.2022.3173642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although crowdsensing has emerged as a popular information collection paradigm, its security and privacy vulnerabilities have come to the forefront in recent years. However, one big limitation of previous research is that the security domain and the privacy domain are typically considered separately. Therefore, it is unclear whether the defense methods in the privacy domain will have unexpected impact on the security domain. To bridge this gap, in this paper, we propose a novel Disguise-based Data Poisoning Attack (DDPA) against the differentially private crowdsensing systems empowered with the truth discovery method. Specifically, we propose a novel stealth strategy, i.e., disguising the malicious behavior as privacy behavior, to avoid being detected by truth discovery methods. With this stealth strategy, the shortcoming of failing to maximize the attack effectiveness is avoided naturally through structuring a bi-level optimization problem, which can be solved with the alternating optimization algorithm. Moreover, we show that the differentially private crowdsensing systems are vulnerable to data poisoning attacks, and enhancing the level of privacy will bring more serious security threats. Finally, the evaluation results on the real-world dataset Emotion and the synthetic dataset SynData demonstrate that DDPA can not only achieve maximum utility damage but also remain undetected.},
  archive      = {J_TMC},
  author       = {Zhetao Li and Zhirun Zheng and Suiming Guo and Bin Guo and Fu Xiao and Kui Ren},
  doi          = {10.1109/TMC.2022.3173642},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5155-5169},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Disguised as privacy: Data poisoning attacks against differentially private crowdsensing systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and analysis of dynamic block-setup reservation
algorithm for 5G network slicing. <em>TMC</em>, <em>22</em>(9),
5140–5154. (<a href="https://doi.org/10.1109/TMC.2022.3169034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 5G, network functions can be scaled out/in dynamically to adjust the capacity for network slices. The scale-out/-in procedure, namely autoscaling, enhances performance by scaling out instances and reduces operational costs by scaling in instances. However, the autoscaling problems in 5G networks are different from those in traditional cloud computing. The 5G network functions must be considered the simultaneous deployment of multiple instances; moreover, the deployment of 5G network functions is more frequent than that of traditional cloud computing. Both the number and timing of deployment will substantially affect the cost-effectiveness of the system. In this paper, we first identify the autoscaling issues specifically based on the 3GPP standards. We develop a low-complexity analytical queuing model to formulate the problem and quantify a set of performance metrics with closed-form solutions. The proposed analytical model and closed-form solutions are cross-validated by extensive simulations. The analytical model offers design insights and theoretical guidelines, helping us study the effectiveness of reservations. We proposed a dynamic block-setup reservation algorithm (DBRA) to find the optimal reserved number and threshold value of network slices. Therefore, mobile operators can balance the system&#39;s cost-effectiveness without large-scaled testing and real deployment, saving cost on time and money.},
  archive      = {J_TMC},
  author       = {Cheng-Ying Hsieh and Tuan Phung-Duc and Yi Ren and Jyh-Cheng Chen},
  doi          = {10.1109/TMC.2022.3169034},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5140-5154},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Design and analysis of dynamic block-setup reservation algorithm for 5G network slicing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Delay-optimal scheduling for integrated mmWave – sub-6 GHz
systems with markovian blockage model. <em>TMC</em>, <em>22</em>(9),
5124–5139. (<a href="https://doi.org/10.1109/TMC.2022.3166990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millimeter wave (mmWave) communication has the potential to achieve very high data rates but is highly vulnerable to blockage. In this paper, we provision an integrated mmWave–sub-6 GHz architecture to combat blockage and intermittent connectivity of the mmWave communications. To this end, we model the mmWave channel as a two-state Markov channel and investigate the problem of scheduling packets across the mmWave and sub-6 GHz interfaces such that the long-term average delay of system is minimized. We prove that the optimal policy is of a threshold-type with state-dependent thresholds, i.e., packets should always be routed to the mmWave interface as long as the number of packets in the system is smaller than the state-dependent threshold. Numerical results demonstrate that under heavy traffic, integrating sub-6 GHz with mmWave can reduce the average delay by over 70%. Moreover, considering the difficulty of tracking the mmWave channel state in practice, we develop heuristics of substituting a single fixed threshold (state-independent) for two state-dependent thresholds. Our simulation results indicate that the replacement only incurs a slight increase in average delay. Moreover, when system parameters are not known, we propose a certainty-equivalence threshold-based learning algorithm, and provide an upper bound on its regret.},
  archive      = {J_TMC},
  author       = {Guidan Yao and Morteza Hashemi and Rahul Singh and Ness B. Shroff},
  doi          = {10.1109/TMC.2022.3166990},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5124-5139},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Delay-optimal scheduling for integrated mmWave – sub-6 GHz systems with markovian blockage model},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Delay-optimal cooperation transmission in remote sensing
satellite networks. <em>TMC</em>, <em>22</em>(9), 5109–5123. (<a
href="https://doi.org/10.1109/TMC.2022.3172848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many remote sensing applications, such as the forest fire monitoring, need to send a large volume of data to the ground with low delay. Therefore, the cooperation transmission , which relies on cooperation among satellites to achieve continuous transmission, emerges as an indispensable technique. Most existing work cannot optimize the delay through dynamic cooperation transmission. In this paper, we investigate how to optimize the delay in remote sensing satellite networks based on cooperation transmission, where cooperation hotspot s refer to the satellites with ground-satellite links to the Earth Stations (ESs). First, we propose the cooperation capability model to quantify capabilities of cooperation hotspots, based on the joint control of the dynamic topology and time-varying available resources . Then, we uniformly model the inter-satellite routing and satellite-ES transmission scheduling, formulate the satellite cooperation transmission problem and prove its NP-hardness. To solve the problem, we propose the delay-optimal cooperation transmission scheme, including the cooperation routing principle based on topology features, the centralized cooperation transmission (CCT) algorithm based on randomized rounding and the distributed cooperation transmission (DCT) based on local information. Both algorithms take advantage of the cooperation capability model and adapt well to the dynamic topology and time-varying available resources. Finally, we formally analyze the approximation ratios and the time complexities of both the CCT and the DCT algorithms. We also prove that the DCT algorithm always setups loop-free paths. NS2-based simulation results demonstrate that our schemes have good scalability, and both CCT and DCT algorithms reduce the end-to-end delay on average by more than 21.77% compared to work in the state-of-the-art, and significantly improve throughput, packet loss rate and flow completion time.},
  archive      = {J_TMC},
  author       = {Long Chen and Feilong Tang and Xu Li and Jiacheng Liu and Yanqin Yang and Jiadi Yu and Yanmin Zhu},
  doi          = {10.1109/TMC.2022.3172848},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5109-5123},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Delay-optimal cooperation transmission in remote sensing satellite networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contextual user-centric task offloading for mobile edge
computing in ultra-dense network. <em>TMC</em>, <em>22</em>(9),
5092–5108. (<a href="https://doi.org/10.1109/TMC.2022.3168355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating mobile edge computing (MEC) in ultra-dense network (UDN) is a key enabler to meet the service demand by allowing smart devices to perform uninterrupted task offloading via densely deployed MEC servers. In most cases, the smart devices randomly move around the whole network. Consequently, the popular “MEC-centralized decision” offloading approach could be inapplicable, as joint decision-making among multiple MEC servers becomes difficult due to time synchronization and information exchange overhead. In this paper, we take a user-centric approach to minimize a long-term delay for a given task duration under a price budget constraint. To address this problem, we develop a novel contextual sleeping bandit learning (CSBL) algorithm, which integrates contextual information and sleeping characteristic to accelerate the learning convergence and leverage Lyapunov optimization to deal with the price budget constraint. Furthermore, we extend to a multiple offloading scenario where multiple MEC servers can be selected in each offloading round and propose a CSBL-multiple (CSBL-M) algorithm to address the exponential increase of the offloading selections. For both CSBL and CSBL-M, we derive the upper bounds of learning regret and provide rigorous proofs that they asymptotically approach the Oracle algorithm within bounded deviations for finite task duration. Simulation results illustrate that our proposed algorithms significantly outperform existing algorithms in both single offloading and multiple offloading scenario.},
  archive      = {J_TMC},
  author       = {Sige Liu and Peng Cheng and Zhuo Chen and Wei Xiang and Branka Vucetic and Yonghui Li},
  doi          = {10.1109/TMC.2022.3168355},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5092-5108},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Contextual user-centric task offloading for mobile edge computing in ultra-dense network},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Configuration-adaptive wireless visual sensing system with
deep reinforcement learning. <em>TMC</em>, <em>22</em>(9), 5078–5091.
(<a href="https://doi.org/10.1109/TMC.2022.3175182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual sensing has been increasingly employed in various industrial applications including manufacturing process monitoring and worker safety monitoring. This paper presents the design and implementation of a wireless camera system, namely, EFCam, which uses low-power wireless communications and edge-fog computing to achieve cordless and energy-efficient visual sensing. The camera performs image pre-processing and offloads the data to a resourceful fog node for advanced processing using deep models. EFCam admits dynamic configurations of several parameters that form a configuration space. It aims to adapt the configuration to maintain desired visual sensing performance of the deep model at the fog node with minimum energy consumption of the camera in image capture, pre-processing, and data communications, under dynamic variations of the monitored process, the application requirement, and wireless channel conditions. However, the adaptation is challenging due to the complex relationships among the involved factors. To address the complexity, we apply deep reinforcement learning to learn the optimal adaptation policy when a fog node supports one or more wireless cameras. Extensive evaluation based on trace-driven simulations and experiments show that EFCam complies with the accuracy and latency requirements with lower energy consumption for a real industrial product object tracking application, compared with five baseline approaches incorporating hysteresis-based and event-triggered adaptation.},
  archive      = {J_TMC},
  author       = {Siyuan Zhou and Duc Van Le and Rui Tan and Joy Qiping Yang and Daren Ho},
  doi          = {10.1109/TMC.2022.3175182},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5078-5091},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Configuration-adaptive wireless visual sensing system with deep reinforcement learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Channel-equalization-HAR: A light-weight convolutional
neural network for wearable sensor based human activity recognition.
<em>TMC</em>, <em>22</em>(9), 5064–5077. (<a
href="https://doi.org/10.1109/TMC.2022.3174816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, human activity recognition (HAR) that uses wearable sensors has become a research hotspot due to its wide applications in a large variety of real-world scenarios including fitness, health-care, and sports tracking. In essence, HAR can be treated as multi-channel time series classification problem, where different channels may come from heterogeneous sensor modalities. Deep learning, especially convolutional neural networks (CNNs) have made major breakthroughs in ubiquitous HAR computing scenario. Various normalization methods have played an indispensable role in prior HAR works, which enable every layer of the network to do learning more independently by normalizing hybrid sensor features. However, normalization tends to produce a ‘channel collapse’ phenomenon, where a large fraction of channels only generates very small values. Most channels are inhibited and contribute very little to activity recognition. As a result, the network has to rely on only a few valid channels, which inevitably impair the generality ability of a network. In this paper, we provide an alternative called Channel Equalization to reactivate these inhibited channels by performing whitening or decorrelation operation, which compels all channels to contribute more or less to feature representation. Experiments conducted on several benchmarks including UCI-HAR, OPPORTUNITY, UniMiB-SHAR, WISDM, PAMAP2, and USC-HAD show that the proposed Channel Equalization module is an impressive alternative of convolution layers, and achieve higher recognition performance to baseline models with simliar computational cost, which significantly surpasses recent state-of-the-arts for activity recongition. To the best of our knowledge, the Channel Equalization is for the first time to be applied in multi-modal HAR scenario. Finally, the actual operation is evaluated on an embedded Raspberry Pi Model 3 B plus platform.},
  archive      = {J_TMC},
  author       = {Wenbo Huang and Lei Zhang and Hao Wu and Fuhong Min and Aiguo Song},
  doi          = {10.1109/TMC.2022.3174816},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5064-5077},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Channel-equalization-HAR: A light-weight convolutional neural network for wearable sensor based human activity recognition},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CEDAN: Cost-effective data aggregation for UAV-enabled IoT
networks. <em>TMC</em>, <em>22</em>(9), 5053–5063. (<a
href="https://doi.org/10.1109/TMC.2022.3172444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the crucial challenges in networked Unmanned Aerial Vehicles (UAVs) is to configure them to serve as aerial base stations (BSs) for collecting data from distributed Internet of Things (IoT) devices in a region devoid of backbone connectivity. To address this challenge, it is required to compute optimized trajectories of UAVs to collect data while considering the different activation patterns of IoT devices. We propose a scheme to optimize the trade-off between the number of covered IoT devices and the travel time of UAVs. The formulated cost minimization problem is the capacitated single depot vehicle routing problem (CSDVRP), which is NP-hard. We propose a solution scheme named Cost-Effective Data Aggregation for UAV-Enabled IoT Networks (CEDAN), which operates in four steps. First, it determines the optimized hovering locations (HLs) for UAVs. Subsequently, CEDAN determines the optimized route adopting Christofides’s approximation algorithm for Travelling Salesman Problem (TSP). Further, a split function produces the optimized trajectories for all UAVs. Finally, a route adjustment algorithm applies the cost function and rearranges the order of visiting each HL. Extensive simulation results depict that the CEDAN outperforms than Clarke-Wright (CW) savings heuristics, CEDAN without route adjustment (CWRA), and Zhan et al. , respectively.},
  archive      = {J_TMC},
  author       = {Abhishek Bera and Sudip Misra and Chandranath Chatterjee and Shiwen Mao},
  doi          = {10.1109/TMC.2022.3172444},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5053-5063},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CEDAN: Cost-effective data aggregation for UAV-enabled IoT networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Borrowing arrows with thatched boats: Exploiting the
reactive primary communications for boosting jamming-assisted proactive
eavesdropping. <em>TMC</em>, <em>22</em>(9), 5035–5052. (<a
href="https://doi.org/10.1109/TMC.2022.3175357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a cognitive information surveillance scenario, where a half-duplex legitimate monitor (E) aims to eavesdrop the frequency division multiple access based suspicious downlink broadcasting communication, which shares the same spectrum with a primary downlink broadcasting system. Specifically, the suspicious transmitter (ST) employs water-filling power allocation over all orthogonal frequency bands (FBs) to maximize the sum suspicious communication rate of all suspicious receivers (SRs), while the primary transmitter (PT) purposely maximizes the minimum communication rate among the primary receivers (PRs). Under this setup, we propose one novel jamming-assisted eavesdropping scheme for E to enhance its eavesdropping performance. In our scheme, instead of implementing passive eavesdropping over all FBs, E picks up certain FBs to jam and eavesdrops over the remaining FBs (due to the half-duplex constraint, E cannot eavesdrop over the FBs it decides to jam), and intends to control its transmit jamming beamforming over the jammed FBs, so as to enhance the interference at the corresponding SRs, even deliberately interfere with the corresponding PRs, such that the PT can reactively readjust its power to further strengthen and reduce its interference to the SRs over the jammed and eavesdroppable FBs, respectively. With this fashion, the ST will be deceived to reallocate more power over the eavesdroppable FBs and then E can acquire the better signal receiving quality accordingly. Our objective is to maximize the sum instantaneous eavesdropping rate at E, by jointly optimizing its jamming set and the corresponding jamming beamformers, subject to the constraints of its power budget and the maximum interference (interference temperature, IT) to the primary system. The optimization problem is non-convex and its approximate and sub-optimal solutions are provided by some convex optimization procedures, along with the optimal and greedy jamming set selections. Moreover, we also investigate the issue of sum ergodic eavesdropping rate maximization, and then interestingly reveal that, if E decides to jam, it should optimally jam over only one FB (such FB can be determined via the simple search) with tolerable maximum power and then eavesdrop over the remaining FBs. Our theoretical and simulation analysis reveals that, under the proposed jamming-assisted eavesdropping scheme, i) generally the obtained sum instantaneous (ergodic) eavesdropping rate of the monitor would monotonically increase and then tend to saturation as the monitor&#39;s power budget increases; ii) the larger the IT threshold is, the more strength the monitor can borrow from the primary system, thus the eavesdropping performance is better; iii) both the position and the number of transmit antennas of the monitor also play the important roles on the sum eavesdropping rate; iv) with the careful jamming set selection and jamming beamformers design, the proposed scheme achieves significant performance compared to competitive benchmarks.},
  archive      = {J_TMC},
  author       = {Guojie Hu and Jiangbo Si and Zan Li},
  doi          = {10.1109/TMC.2022.3175357},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5035-5052},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Borrowing arrows with thatched boats: Exploiting the reactive primary communications for boosting jamming-assisted proactive eavesdropping},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). &lt;Inline-formula&gt;&lt;tex-math notation=“LaTeX”&gt;<span
class="math inline">𝒜ℱ𝒞𝒮:</span>&lt;/tex-math&gt;&lt;mml:math
xmlns:mml=“http://www.w3.org/1998/math/MathML”&gt;&lt;mml:mrow&gt;&lt;mml:mi
mathvariant=“script”&gt;AFCS&lt;/mml:mi&gt;&lt;mml:mo&gt;:&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic
xlink:href=“xiong-ieq1-3178885.gif”
xmlns:xlink=“http://www.w3.org/1999/xlink”/&gt;&lt;/inline-formula&gt;
aggregation-free spatial-temporal mobile community sensing.
<em>TMC</em>, <em>22</em>(9), 5017–5034. (<a
href="https://doi.org/10.1109/TMC.2022.3178885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While spatial-temporal environment monitoring has become an indispensable way to collect data for enabling smart cities and intelligent transportation applications, the cost to deploy, operate and maintain a sensor network with sensors and massive communication infrastructure is too high to bear. Compared to the infrastructure-based sensing approach, community sensing, or namely mobile crowdsensing, that leverage community members’ mobile devices to collect data becomes a feasible way to scale up the spatial-temporal coverage of the sensing system. However, a community sensing system would need to aggregate sensors and location data from community members and thus would raise concerns on privacy and data security. In this paper, we present a novel community sensing paradigm &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {AFCS}$&lt;/tex-math&gt;&lt;/inline-formula&gt; – Sensor and Location Data Aggregation-Free Community Sensing , which is designed to obtain the environment information (e.g., spatial-temporal distributions of air pollution, temperature, and bike-shares) in each subarea of the target area, without aggregating sensor and location data collected by community members. &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {AFCS}$&lt;/tex-math&gt;&lt;/inline-formula&gt; proposes to orchestrate with the Trusted Execution Environments (TEEs) of every community member&#39;s mobile device to cover the communication, computation and storage with spatial-temporal data. Further, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {AFCS}$&lt;/tex-math&gt;&lt;/inline-formula&gt; proposes a novel Decentralized Spatial-Temporal Compressive Sensing framework based on Parallelized Stochastic Gradient Descent . Through learning the latent structure of the spatial-temporal data via decentralized optimization, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {AFCS}$&lt;/tex-math&gt;&lt;/inline-formula&gt; approximates the value of the sensor data in each subarea (both covered and uncovered) for each sensing cycle using the sensor data locally stored in every member&#39;s TEE instance. Experiments based on real-world datasets and the Virtual Mobile Infrastructure (VMI) with TEE emulations demonstrate that &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {AFCS}$&lt;/tex-math&gt;&lt;/inline-formula&gt; exhibits low approximation error (i.e., less than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$0.2 ^\circ$&lt;/tex-math&gt;&lt;/inline-formula&gt; C in city-wide temperature sensing, 10 units of PM2.5 index in urban air pollution sensing, and two bikes in city-wide bike sharing prediction) and performs comparably to (sometimes better than) state-of-the-art algorithms based on the data aggregation and centralized computation.},
  archive      = {J_TMC},
  author       = {Jiang Bian and Haoyi Xiong and Zhiyuan Wang and Jingbo Zhou and Shilei Ji and Hongyang Chen and Daqing Zhang and Dejing Dou},
  doi          = {10.1109/TMC.2022.3178885},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5017-5034},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {AFCS}:$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;AFCS&lt;/mml:mi&gt;&lt;mml:mo&gt;:&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;xiong-ieq1-3178885.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt; aggregation-free spatial-temporal mobile community sensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Accelerating decentralized federated learning in
heterogeneous edge computing. <em>TMC</em>, <em>22</em>(9), 5001–5016.
(<a href="https://doi.org/10.1109/TMC.2022.3178378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In edge computing (EC), federated learning (FL) enables massive devices to collaboratively train AI models without exposing local data. In order to avoid the possible bottleneck of the parameter server (PS) architecture, we concentrate on the decentralized federated learning (DFL), which adopts peer-to-peer (P2P) communication without maintaining a global model. However, due to the intrinsic features of EC, e.g., resource limitation and heterogeneity, network dynamics and non-IID data, DFL with a fixed P2P topology and/or an identical model compression ratio for all workers results in a slow convergence rate. In this paper, we propose an efficient algorithm (termed CoCo ) to accelerate DFL by integrating optimization of topology Co nstruction and model Co mpression. Concretely, we adaptively construct P2P topology and determine specific compression ratios for each worker to conquer the system dynamics and heterogeneity under bandwidth constraints. To reflect how the non-IID data influence the consistency of local models in DFL, we introduce the consensus distance , i.e., the discrepancy between local models, as the quantitative metric to guide the fine-grained operations of the joint optimization. Extensive simulations and testbed experiments show that CoCo achieves 10× speedup, and reduces the communication cost by about &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$50\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; on average, compared with the existing DFL baselines.},
  archive      = {J_TMC},
  author       = {Lun Wang and Yang Xu and Hongli Xu and Min Chen and Liusheng Huang},
  doi          = {10.1109/TMC.2022.3178378},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {5001-5016},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Accelerating decentralized federated learning in heterogeneous edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A stochastic approach for resource prediction error and
bandwidth wastage evaluation in advanced dynamic reservation strategies.
<em>TMC</em>, <em>22</em>(9), 4986–5000. (<a
href="https://doi.org/10.1109/TMC.2022.3176046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies in literature have shown that the bandwidth of an ongoing flow can dynamically change during multimedia sessions and an efficient bandwidth prediction scheme must be employed in order to guarantee the needed Quality of Service. Many contributions in literature focused on some specific reservation schemes for cellular systems, 3G/4G/5G networks, WLAN and so on. However, few of them exploited the trade-off between resource prediction error and bandwidth wastage through a general prediction technique based on the analysis of Cell Stay Time, on the direction probabilities of hand-in and hand-out events of mobile nodes among wireless cells and on the resource over-provisioning due to the uncertain mobility patterns. Our proposed scheme is based on the stochastic computation and characterization of user movements and it is absolutely general. Two novel metrics such as prediction error e and resource wastage u are defined. Moreover, predictive reservation schemes, admission prediction and resource wastage probabilistically associated to the stochastic hand-in/hand-out movement directions are proposed, with an optimization problem for the optimal pre-reservation of bandwidth in wireless system. A threshold-based reservation scheme has been considered as a practical case and it has been evaluated in terms of reservation prediction errors and resource wastage, to prove the practical effectiveness and consistence of the defined theoretical bounds.},
  archive      = {J_TMC},
  author       = {Floriano De Rango and Peppino Fazio},
  doi          = {10.1109/TMC.2022.3176046},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {4986-5000},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A stochastic approach for resource prediction error and bandwidth wastage evaluation in advanced dynamic reservation strategies},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trine: Cloud-edge-device cooperated real-time video analysis
for household applications. <em>TMC</em>, <em>22</em>(8), 4973–4985. (<a
href="https://doi.org/10.1109/TMC.2022.3154721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time mobile video analysis like object detection and tracking is key to various household applications such as AR, cognitive assistance and smart home. Such applications rely on heavy DNN models, which are not suitable for mobile devices due to resource limitation. The long latency of cloud offloading is unacceptable for the real-time requirements, and the direct edge offloading relies on powerful edge servers, which is impractical for household scenarios. To solve this challenge, we take advantage of the computing devices that are low-cost or already exist in our lives, and propose Trine, a cloud-edge-device cooperated framework, in which complicated computation tasks are offloaded from the device to the cloud with the edge as the key bond to coordinate. In addition, due to the heterogeneity of edge devices, which leads to no one-fits-all algorithm that is optimal in all situations, we propose a profile-based algorithm to customize trackers for various edge devices. We implemented Trine on an android phone and three edge devices. The experiments demonstrate that Trine achieves 8-36% higher real-time accuracy and 25-89% higher robustness than state-of-the-art.},
  archive      = {J_TMC},
  author       = {Yi Zhao and Zheng Yang and Xiaowu He and Xinjun Cai and Xin Miao and Qiang Ma},
  doi          = {10.1109/TMC.2022.3154721},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4973-4985},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Trine: Cloud-edge-device cooperated real-time video analysis for household applications},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). To continue transmission or to explore relays: Millimeter
wave D2D communication in presence of dynamic obstacles. <em>TMC</em>,
<em>22</em>(8), 4961–4972. (<a
href="https://doi.org/10.1109/TMC.2022.3160764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millimeter wave (mmWave) device to device (D2D) communication is highly susceptible to obstacles due to severe penetration losses. Dynamic obstacles may cause unpredictable fluctuations to D2D channel quality and hence a D2D relay initially chosen by base station (BS) might undergo failed transmissions resulting in severe packet loss and delay. This local information regarding link quality deterioration needs to be informed to the BS by the user equipments (UEs) which may result in some delay. Also, exploring a new relay on mmWave channel results in significant delay due to directional search. Hence the following optimal sequential decision must be made when packet loss occurs: whether to explore for a new relay link considering exploration cost, or to continue communication via the existing relay. We model this sequential decision problem locally at each UE as partially observable Markov decision process to capture uncertainty in D2D links while minimizing delay. We derive an optimal threshold policy for both positively and negatively correlated links. We also provide a simplified and easy to implement policy based on successive acknowledgment failures for positively correlated links. Through simulation, we validate theoretical findings and demonstrate that our approach outperforms existing state of the art algorithms.},
  archive      = {J_TMC},
  author       = {Durgesh Singh and Arpan Chattopadhyay and Sasthi C. Ghosh},
  doi          = {10.1109/TMC.2022.3160764},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4961-4972},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {To continue transmission or to explore relays: Millimeter wave D2D communication in presence of dynamic obstacles},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tesla-rapture: A lightweight gesture recognition system from
mmWave radar sparse point clouds. <em>TMC</em>, <em>22</em>(8),
4946–4960. (<a href="https://doi.org/10.1109/TMC.2022.3153717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Tesla-Rapture, a gesture recognition system for sparse point clouds generated by mmWave Radars. State of the art gesture recognition models are either too resource consuming or not sufficiently accurate for the integration into real-life scenarios using wearable or constrained equipment such as IoT devices (e.g., Raspberry PI), XR hardware (e.g., HoloLens), or smart-phones. To tackle this issue, we have developed Tesla, a Message Passing Neural Network (MPNN) graph convolution approach for mmWave radar point clouds. The model outperforms the state of the art on three datasets in terms of accuracy while reducing the computational complexity and, hence, the execution time. In particular, the approach, is able to predict a gesture almost 8 times faster than the most accurate competitor. Our performance evaluation in different scenarios (environments, angles, distances) shows that Tesla generalizes well and improves the accuracy up to 20% in challenging scenarios, such as a through-wall setting and sensing at extreme angles. Utilizing Tesla, we develop Tesla-Rapture, a real-time implementation using a mmWave Radar on a Raspberry PI 4 and evaluate its accuracy and time-complexity. We also publish the source code, the trained models, and the implementation of the model for embedded devices.},
  archive      = {J_TMC},
  author       = {Dariush Salami and Ramin Hasibi and Sameera Palipana and Petar Popovski and Tom Michoel and Stephan Sigg},
  doi          = {10.1109/TMC.2022.3153717},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4946-4960},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Tesla-rapture: A lightweight gesture recognition system from mmWave radar sparse point clouds},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SpongeTraining: Achieving high efficiency and accuracy for
wireless edge-assisted online distributed learning. <em>TMC</em>,
<em>22</em>(8), 4930–4945. (<a
href="https://doi.org/10.1109/TMC.2022.3154644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge-assisted Distributed Learning (EDL) is a popular machine learning paradigm that uses a set of distributed edge nodes to collaboratively train a machine learning model using training data. Most of existing works implicitly assume that the fixed amount of training data is pre-collected and dispatched from user devices to edge nodes. In real world, however, training data in edge nodes are collected from user devices through wireless networks, and the volume and distribution of training data in edge nodes could exhibit temporal and spatial fluctuations due to varying wireless situations (e.g., network congestion, link capacity variation). In this way, existing solutions suffer from slow convergence and low accuracy. In this paper, we propose SpongeTraining to achieve high efficiency and accuracy for online EDL. To accommodate to fluctuations in training data, SpongeTraining uses a buffer at each worker to store received training data and adaptively adjusts training batch size and learning rate of each worker based on training data extracted from the buffer. Experiment results based on real-world datasets show that SpongeTraining outperforms existing solutions by accelerating the training process up to 50% for reaching the same training accuracy.},
  archive      = {J_TMC},
  author       = {Zehua Guo and Jiayu Wang and Sen Liu and Jineng Ren and Yang Xu and Yi Wang},
  doi          = {10.1109/TMC.2022.3154644},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4930-4945},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SpongeTraining: Achieving high efficiency and accuracy for wireless edge-assisted online distributed learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SDORP: SDN based opportunistic routing for asynchronous
wireless sensor networks. <em>TMC</em>, <em>22</em>(8), 4912–4929. (<a
href="https://doi.org/10.1109/TMC.2022.3158695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks (WSNs), it is inappropriate to use conventional unicast routing due to the broadcast storm problem and spatial diversity of communication links. Opportunistic Routing (OR) benefits the low duty-cycled WSNs by prioritizing the multiple candidates for each node instead of selecting one node as in conventional unicast routing. OR reduces the sender waiting time, but it also suffers from the duplicate packets problem due to multiple candidates waking up simultaneously. The number of candidates should be restricted to counterbalance between the sender waiting time and duplicate packets. In this paper, software-defined networking (SDN) is adapted for the flexible management of WSNs by allowing the decoupling of the control plane from the sensor nodes. This study presents an SDN based load balanced opportunistic routing for duty-cycled WSNs that addresses two parts. First, the candidates are computed and controlled in the control plane. Second, the metric used to prioritize the candidates considers the average of three probability distributions, namely transmission distance distribution, expected number of hops distribution and residual energy distribution so that more traffic is guided through the nodes with higher priority. Simulation results show that our proposed protocol can significantly improve the network lifetime, routing efficiency, energy consumption, sender waiting time and duplicate packets as compared with the benchmarks.},
  archive      = {J_TMC},
  author       = {Muhammad Umar Farooq and Xingfu Wang and Ammar Hawbani and Liang Zhao and Ahmed Al-Dubai and Omar Busaileh},
  doi          = {10.1109/TMC.2022.3158695},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4912-4929},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SDORP: SDN based opportunistic routing for asynchronous wireless sensor networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reliable dynamic service chain scheduling in 5G networks.
<em>TMC</em>, <em>22</em>(8), 4898–4911. (<a
href="https://doi.org/10.1109/TMC.2022.3157312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key enabler of future 5G network, Service Function Chain (SFC) forwards the traffic flow along a chain of Virtual Network Functions (VNFs) to provide network services flexibility. One of the most important problems in SFC is to deploy the VNFs and schedule arriving requests among computing nodes to achieve low latency and high reliability. Existing works consider a static network and assume that all SFC requests are known in advance, which is impractical. In this paper, we focus on the dynamic 5G network environment where the SFC request arrives randomly following a certain distribution. Computing nodes can redeploy all types of VNF with a time cost. We formulate the problem of SFC scheduling in NFV-enabled 5G network as a mixed integer non-linear programing. The objective is to maximize the number of requests satisfying the latency and reliability constraints. To solve the problem, we propose an efficient algorithm to decide the redundancy of the VNFs while minimizing delay. Then we present a state-of-art Reinforcement Learning (RL) to learn SFC scheduling policy to increase the success rate of SFC requests. The effectiveness of our method is evaluated through extensive simulations. The result shows that our proposed RL solution can increase the success rate by 18.7% over the benchmark algorithms.},
  archive      = {J_TMC},
  author       = {Lei Yang and Junzhong Jia and Hongcai Lin and Jiannong Cao},
  doi          = {10.1109/TMC.2022.3157312},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4898-4911},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reliable dynamic service chain scheduling in 5G networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Private data trading towards range counting queries in
internet of things. <em>TMC</em>, <em>22</em>(8), 4881–4897. (<a
href="https://doi.org/10.1109/TMC.2022.3164325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data collected in Internet of Thing (IoT) systems (IoT data) have stimulated dramatic extension to the boundary of commercialized data statistic analysis, owing to the pervasive availability of low-cost wireless network access and off-the-shelf mobile devices. In such cases, many data consumers post their queries for urban statistic analysis in the system, like the scales of traffics, and then data contributors in IoT networks upload their contents, which can be evaluated by data brokers and responded to data consumers. However, huge volumes of devices bring large scales of data, constituting heavy burdens for data exchange. Even worse, contents in IoT systems are also sensitive as they are usually linked to private physical status of data contributors. The previous studies for IoT data trading fail to provide comprehensive estimation and pricing towards these difficulties. Therefore, this paper proposes a novel framework for the range counting trading over IoT networks by jointly considering data utility, bandwidth consumption, and privacy preservation. The range counting accumulates the number of data items falling in a concerned range of value, providing important information on the underlying data distribution. This paper first proposes a novel sampling-based method with histogram sketching for range counting estimation. The estimator is proved to be unbiased and achieves advanced performance on variance. Then the framework adopts a perturbation mechanism that can further preserve the results under differential privacy. The theoretical analysis shows that the mechanism can guarantee the privacy preservation under a given size of samples and the accuracy requirement of results. Finally, two types of pricing strategies for range counting trading are introduced for different circumstances, providing holistic consideration on how the parameters given in the estimator should be used for data trading. The framework is evaluated by estimating the air pollution levels and the traffic levels with different ranges on the 2014 CityPulse Smart City datasets. The evaluation results demonstrate that our framework can provide more accurate and reliable statistical information, with reduced bandwidth consumption and strengthened privacy preservation.},
  archive      = {J_TMC},
  author       = {Zhipeng Cai and Xu Zheng and Jinbao Wang and Zaobo He},
  doi          = {10.1109/TMC.2022.3164325},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4881-4897},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Private data trading towards range counting queries in internet of things},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PD-FMCW: Push the limit of device-free acoustic sensing
using phase difference in FMCW. <em>TMC</em>, <em>22</em>(8), 4865–4880.
(<a href="https://doi.org/10.1109/TMC.2022.3162631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Device-free acoustic sensing has obsessed with renovating human-computer interaction techniques for all-sized mobile devices in various applications. Recent advances have explored sound signals in different methods to achieve highly accurate and efficient tracking and recognition. However, accuracies of most approaches remain bottlenecked by the limited sampling rate and narrow bandwidth, leading to restrictions and inconvenience in applications. To bridge over the aforementioned daunting barriers, we propose &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf PD-FMCW}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , a novel ultrasound-based device-free tracking scheme that can distinctly improve the resolution of fine-grained sensing to submillimetre level. In its heart lies an original Phase Difference based approach leveraging the Frequency-Modulated Continuous Wave to derive the reflected time delay, thus precisely inferring absolute distance, catering to interaction needs of tinier perception with lower delay. The distance resolution of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf PD-FMCW}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; is only related to the speed of actions and chirp duration. We implement a prototype with effective denoising methods all in the time domain on smartphones. The evaluation results show that &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf PD-FMCW}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; achieves accuracies of 2.5 mm, 3.6 mm, and 2.1 mm in distance change, path length change, and trajectory tracking error respectively. &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf PD-FMCW}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; is also valid in recognizing 2 mm or even tinier micro-movements, which paves the way for more delicate sensing work.},
  archive      = {J_TMC},
  author       = {Haiming Cheng and Wei Lou},
  doi          = {10.1109/TMC.2022.3162631},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4865-4880},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PD-FMCW: Push the limit of device-free acoustic sensing using phase difference in FMCW},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimized controller provisioning in software-defined LEO
satellite networks. <em>TMC</em>, <em>22</em>(8), 4850–4864. (<a
href="https://doi.org/10.1109/TMC.2022.3155657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The controller provisioning, which adjusts the number, locations, and members of satellite controllers adaptive to the dynamic network load and topology, fundamentally impacts the performance of software-defined satellite networks (SDSNs). An ideal provisioning strategy should achieve a low total control overhead throughout the entire satellite operation period, which is extremely challenging since the network load can only be predicted in a short time scale . Existing methods can hardly achieve this goal for they greedily configure controllers in each time slot, where switches have to frequently migrate from one controller to another. In this paper, we focus on achieving globally optimized strategies with only current network load information . We first propose a comprehensive control overhead model and formulate the Controller Provisioning Problem (CPP) in SDSNs as a non-convex integer programming problem. To solve the problem, we propose an approximate algorithm named AROA by introducing a regularization framework and based on randomized rounding. We theoretically derive its competitive ratio. To produce strategies in time for future large satellite constellations, we further propose a more efficient heuristic algorithm HROA. Evaluations on our built simulation system show that our proposed methods significantly outperform related schemes in control overhead, latency, and scalability.},
  archive      = {J_TMC},
  author       = {Xu Li and Feilong Tang and Luoyi Fu and Jiadi Yu and Long Chen and Jiacheng Liu and Yanmin Zhu and Laurence T. Yang},
  doi          = {10.1109/TMC.2022.3155657},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4850-4864},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimized controller provisioning in software-defined LEO satellite networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal trajectories of a UAV base station using
hamilton-jacobi equations. <em>TMC</em>, <em>22</em>(8), 4837–4849. (<a
href="https://doi.org/10.1109/TMC.2022.3156822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of optimizing the trajectory of an Unmanned Aerial Vehicle (UAV). Assuming a traffic intensity map of users to be served, the UAV must travel from a given initial location to a final position within a given duration and serves the traffic on its way. The problem consists in finding the optimal trajectory that minimizes a certain cost depending on the velocity and on the amount of served traffic. We formulate the problem using the framework of Lagrangian mechanics. We derive closed-form formulas for the optimal trajectory when the traffic intensity is quadratic (single-phase) using Hamilton-Jacobi equations. When the traffic intensity is bi-phase, i.e. made of two quadratics, we provide necessary conditions of optimality that allow us to propose a gradient-based algorithm and a new algorithm based on the linear control properties of the quadratic model. These two solutions are of very low complexity because they rely on fast convergence numerical schemes and closed form formulas. These two approaches return a trajectory satisfying the necessary conditions of optimality. At last, we propose a data processing procedure based on a modified K-means algorithm to derive a bi-phase model and an optimal trajectory simulation from real traffic data.},
  archive      = {J_TMC},
  author       = {Marceau Coupechoux and Jérôme Darbon and Jean-Marc Kélif and Marc Sigelle},
  doi          = {10.1109/TMC.2022.3156822},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4837-4849},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal trajectories of a UAV base station using hamilton-jacobi equations},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal network protocol selection for competing flows via
online learning. <em>TMC</em>, <em>22</em>(8), 4822–4836. (<a
href="https://doi.org/10.1109/TMC.2022.3162880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s Internet must support applications with increasingly dynamic and heterogeneous connectivity requirements, such as video streaming and the Internet of Things. Yet current network management practices generally rely on pre-specified network configurations, which may not be able to cope with dynamic application needs. Moreover, even the best-specified policies will find it difficult to cover all possible scenarios, given applications’ increasing heterogeneity and dynamic network conditions, e.g., on volatile wireless links. In this work, we instead propose a model-free learning approach to find the optimal network policies for current network flow requirements. This approach is attractive as comprehensive models do not exist for how different policy choices affect flow performance under changing network conditions. However, it can raise new challenges for online learning algorithms: policy configurations can affect the performance of multiple flows sharing the same network resources, and this performance coupling limits the scalability and optimality of existing online learning algorithms. In this work, we extend multi-armed bandit frameworks to propose new online learning algorithms for protocol selection with provably sublinear regret under certain conditions. We validate the optimality and scalability of our algorithms through data-driven simulations and testbed experiments. (An extended abstract of this work was accepted by IEEE ICNP as a short paper Zhang et al . (2019)).},
  archive      = {J_TMC},
  author       = {Xiaoxi Zhang and Siqi Chen and Yunfan Zhang and Youngbin Im and Maria Gorlatova and Sangtae Ha and Carlee Joe-Wong},
  doi          = {10.1109/TMC.2022.3162880},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4822-4836},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal network protocol selection for competing flows via online learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MyoKey: Inertial motion sensing and gesture-based QWERTY
keyboard for extended realities. <em>TMC</em>, <em>22</em>(8),
4807–4821. (<a href="https://doi.org/10.1109/TMC.2022.3156939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Usability challenges and social acceptance of textual input in a context of extended realities (XR) motivate the research of novel input modalities. We investigate the fusion of inertial measurement unit (IMU) control and surface electromyography (sEMG) gesture recognition applied to text entry using a QWERTY-layout virtual keyboard. We design, implement, and evaluate the proposed multi-modal solution named MyoKey. The user can select characters with a combination of arm movements and hand gestures. MyoKey employs a lightweight convolutional neural network classifier that can be deployed on a mobile device with insignificant inference time. We demonstrate the practicality of interruption-free text entry with MyoKey, by recruiting 12 participants and by testing three sets of grasp micro-gestures in three scenarios: empty hand text input, tripod grasp (e.g., pen), and a cylindrical grasp (e.g., umbrella). With MyoKey, users achieve an average text entry rate of 9.33 words per minute (WPM), 8.76 WPM, and 8.35 WPM for the freehand, tripod grasp, and cylindrical grasp conditions, respectively.},
  archive      = {J_TMC},
  author       = {Kirill A. Shatilov and Young D. Kwon and Lik-Hang Lee and Dimitris Chatzopoulos and Pan Hui},
  doi          = {10.1109/TMC.2022.3156939},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4807-4821},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MyoKey: Inertial motion sensing and gesture-based QWERTY keyboard for extended realities},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-technology cooperative driving: An analysis based on
PLEXE. <em>TMC</em>, <em>22</em>(8), 4792–4806. (<a
href="https://doi.org/10.1109/TMC.2022.3154643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative Driving requires ultra-reliable communications, and it is now clear that no single technology will ever be able to satisfy such stringent requirements, if only because active jamming can kill (almost) any wireless technology. Cooperative driving with multiple communication technologies which complement each other opens new spaces for research and development, but also poses several challenges. The work we present tackles the fallback and recovery mechanisms that the longitudinal controlling system of a platoon of vehicles can implement as a distributed system with multiple communication interfaces. We present a protocol and procedure to correctly compute the safe transition between different controlling algorithms, down to autonomous (or manual) driving when no communication is possible. To empower the study, we also develop a new version of Plexe , which is an integral part of this contribution as the only Open Source, free simulation tool that enables the study of such systems with a modular approach, and that we deem offers the community the possibility of boosting research in this field. The results we present demonstrate the feasibility of safe fallback, but also highlight that such complex systems require careful design choices, as naïve approaches can lead to instabilities or even collisions, and that such design can only be done with appropriate in-silico experiments.},
  archive      = {J_TMC},
  author       = {Michele Segata and Renato Lo Cigno and Tobias Hardes and Julian Heinovski and Max Schettler and Bastian Bloessl and Christoph Sommer and Falko Dressler},
  doi          = {10.1109/TMC.2022.3154643},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4792-4806},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-technology cooperative driving: An analysis based on PLEXE},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Misbehavior detection in wi-fi/LTE coexistence over
unlicensed bands. <em>TMC</em>, <em>22</em>(8), 4773–4791. (<a
href="https://doi.org/10.1109/TMC.2022.3164326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of detecting misbehavior in the coexistence etiquette between LTE and Wi-Fi systems operating in the 5GHz U-NII unlicensed bands. We define selfish misbehavior strategies for the LTE that can yield an unfair share of the spectrum resources. Such strategies are based on manipulating the operational parameters of the LTE-LAA standard, namely the backoff mechanism, the traffic class parameters, the clear channel access (CCA) threshold, and others. Prior methods for detecting misbehavior in homogeneous settings are not applicable in a spectrum sharing scenario because the devices of one system cannot decode the transmissions of another. We develop implicit sensing techniques that can accurately estimate the operational parameters of LTE transmissions under various topological scenarios and without decoding. These techniques apply correlation-based signal detection to infer the required information. Our techniques are validated through experiments on a USRP testbed. We further apply a statistical inference framework for determining deviations of the LTE behavior from the coexistence etiquette. By characterizing the detection and false alarm probabilities, we show that our framework yields high detection accuracy at a very low false alarm rate. Although our methods focus on detecting misbehavior of the LTE system, they can be generalized to detect Wi-Fi misbehavior and to other coexistence scenarios.},
  archive      = {J_TMC},
  author       = {Islam Samy and Xiao Han and Loukas Lazos and Ming Li and Yong Xiao and Marwan Krunz},
  doi          = {10.1109/TMC.2022.3164326},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4773-4791},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Misbehavior detection in wi-Fi/LTE coexistence over unlicensed bands},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximum AoI minimization for target monitoring in
battery-free wireless sensor networks. <em>TMC</em>, <em>22</em>(8),
4754–4772. (<a href="https://doi.org/10.1109/TMC.2022.3161975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age of Information (AoI) has been proposed to measure the freshness of the sensory data for IoT applications. In Battery-free WSNs (BF-WSNs), The AoI minimization data collection problem has been extensively studied. Apart from data collection, target monitoring is also an important application for BF-WSNs. To capture the freshness of the sensory data, the AoI related to targets (The AoI of targets) needs to be considered. To guarantee the performance of the target monitoring system, the maximum AoI of all targets should be minimized. However, existing works mainly investigated the AoI related to nodes (The AoI of nodes), which is different from the AoI of targets. Also, existing energy models are not practical enough for battery-free nodes. To deal with those problems, in this paper, we first propose a more practical energy model. Then the problem of Maximum AoI minimization for Target monitoring in Battery-free WSNs (MTB) is formally defined based on the proposed energy model. A two-stage algorithm is proposed to solve MTB optimally, in which all nodes in the network are scheduled collaboratively to monitor all the targets in the monitoring field. Extensive simulations and real-world experiments verify the high performance of our algorithm and energy model.},
  archive      = {J_TMC},
  author       = {Bingkun Yao and Hong Gao and Yang Zhang and Jinbao Wang and Jianzhong Li},
  doi          = {10.1109/TMC.2022.3161975},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4754-4772},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Maximum AoI minimization for target monitoring in battery-free wireless sensor networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning dynamic app usage graph for next mobile app
recommendation. <em>TMC</em>, <em>22</em>(8), 4742–4753. (<a
href="https://doi.org/10.1109/TMC.2022.3161114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next mobile app recommendation aims to recommend the next app that a user is most likely to use based on the user’s app usage behaviors, which is beneficial for improving user experience, app pre-loading, and system optimization. However, existing works ignore the complex correlations between apps in the app usage sessions. In addition, they do not consider the dynamics of user interests over time. To address these concerns, we propose a novel model named dynamic usage graph network (DUGN) to recommend the next app that a user is most likely to use. To model the complex correlations among apps explicitly, we adopt the dynamic graph structure to learn the dynamics of user interests. Firstly, we extract user interests in each app usage graph by using the hierarchical graph attention mechanism. Secondly, we capture user interests evolving over time, and generate the dynamic user embeddings by modeling the temporal dependencies among multiple app usage graphs. Finally, we obtain the current user interests in the current app usage graph, fuse multiple user interests and generate comprehensive user embeddings for next mobile app recommendation. We conduct experiments on real-world datasets. The results show that our model outperforms the state-of-art recommendation methods.},
  archive      = {J_TMC},
  author       = {Yi Ouyang and Bin Guo and Qianru Wang and Yunji Liang and Zhiwen Yu},
  doi          = {10.1109/TMC.2022.3161114},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4742-4753},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Learning dynamic app usage graph for next mobile app recommendation},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KeepEdge: A knowledge distillation empowered edge
intelligence framework for visual assisted positioning in UAV delivery.
<em>TMC</em>, <em>22</em>(8), 4729–4741. (<a
href="https://doi.org/10.1109/TMC.2022.3157957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Unmanned Aerial Vehicles (UAVs) delivery is being increasingly used in the field of logistics. However, it is highly challenging for a UAV to precisely identify the position for parcel delivering if it is only aided by the GPS, especially in some complex environments with weak signals and high interference. To address this issue, we present a k nowl e dge distillation e m p owered edge intelligence framework, KeepEdge , to achieve visual information-assisted positioning for the last mile UAV delivery services. In our approach, we integrate deep neural networks (DNN) into an edge computing framework to enable edge intelligence which empowers the UAVs to autonomously identify the expected delivery position using visual information. Deploying the DNN model and conducting model inference on UAVs however, requires high computing performance. To manage the trade-off between the limited resources onboard the UAVs and high-performance requirements, here, we employ knowledge distillation to produce a lightweight model with high accuracy based on the full model trained in the Cloud. The lightweight model with significantly lower complexity and less inference latency is used onboard of the UAVs for accurate positioning. Comprehensive experiments show that the proposed framework achieves satisfactory performance for assisted positioning. A real-world case study is also presented to demonstrate the effectiveness of the proposed edge intelligence solution for UAV delivery services.},
  archive      = {J_TMC},
  author       = {Haoyu Luo and Tianxiang Chen and Xuejun Li and Shuangyin Li and Chong Zhang and Gansen Zhao and Xiao Liu},
  doi          = {10.1109/TMC.2022.3157957},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4729-4741},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {KeepEdge: A knowledge distillation empowered edge intelligence framework for visual assisted positioning in UAV delivery},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint traffic offloading and aging control in 5G IoT
networks. <em>TMC</em>, <em>22</em>(8), 4714–4728. (<a
href="https://doi.org/10.1109/TMC.2022.3154089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of 5G cellular technology will evolve as one of the major drivers for the growth of IoT-based applications. In this paper, we consider a Service Provider (SP) that launches a smart city service based on IoT data readings: in order to serve IoT data collected across different locations, the SP dynamically negotiates and rescales bandwidth and service functions. 5G network slicing functions are key to lease appropriate amount of resources over heterogeneous access technologies and different site types. Also, different infrastructure providers will charge slicing service depending on specific access technology supported across sites and IoT data collection patterns. We introduce a pricing mechanism based on Age of Information (AoI) to reduce the cost of SPs. It provides incentives for devices to smooth traffic by shifting part of the traffic load from highly congested and more expensive locations to lesser charged ones, while meeting QoS requirements of the IoT service. The proposed optimal pricing scheme comprises a two-stage decision process, where the SP determines the pricing of each location and devices schedule uploads of collected data based on the optimal uploading policy. Simulations show that the SP attains consistent cost reductions tuning the trade-off between slicing costs and the AoI of uploaded IoT data.},
  archive      = {J_TMC},
  author       = {Naresh Modina and Rachid El-Azouzi and Francesco De Pellegrini and Daniel Sadoc Menasche and Rosa Figueiredo},
  doi          = {10.1109/TMC.2022.3154089},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4714-4728},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint traffic offloading and aging control in 5G IoT networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incentive mechanism for spatial crowdsourcing with unknown
social-aware workers: A three-stage stackelberg game approach.
<em>TMC</em>, <em>22</em>(8), 4698–4713. (<a
href="https://doi.org/10.1109/TMC.2022.3157687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the incentive problem in Spatial Crowdsourcing (SC), where mobile social-aware workers have unknown qualities and can share their answers to tasks via social networks. The objectives are to recruit high-quality workers and maximize all parties’ utilities simultaneously. However, most existing works assume that the qualities of workers are known in advance or cannot take all parties’ utilities into account together, especially having not considered the impact of social networks. Thus, we propose an incentive mechanism based on the multi-armed bandit and three-stage Stackelberg game, called TACT. We first design a greedy arm-pulling scheme to recruit workers, which not only can solve the exploration-exploitation dilemma but also takes workers’ social relations into account. Based on the recruitment results, we further design the utility functions incorporating with social benefits for workers, and model the payment computation problem as a three-stage Stackelberg game among all participants. Next, we derive the optimal strategy group so that each party can maximize its own utility to form a multi-win situation. Moreover, we theoretically prove the unique existence of Stackelberg equilibrium and the worst regret bound. Finally, we conduct extensive simulations on a real trace to corroborate the performance of TACT.},
  archive      = {J_TMC},
  author       = {Yin Xu and Mingjun Xiao and Jie Wu and Sheng Zhang and Guoju Gao},
  doi          = {10.1109/TMC.2022.3157687},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4698-4713},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Incentive mechanism for spatial crowdsourcing with unknown social-aware workers: A three-stage stackelberg game approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid-fidelity: Utilizing IEEE 802.11 MIMO for practical
aggregation of LiFi and WiFi. <em>TMC</em>, <em>22</em>(8), 4682–4697.
(<a href="https://doi.org/10.1109/TMC.2022.3157452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Hy-Fi , a system that aggregates light fidelity (LiFi) and radio frequency (RF)-based communication on the 802.11 (WiFi) physical layer by utilizing the MIMO capabilities in IEEE 802.11-compliant commodity WiFi chips. Hy-Fi is based on two key ideas. First, we use inexpensive commodity hardware to facilitate direct transmission of WiFi waveforms over the optical wireless channel, as this is proposed in the IEEE P802.11bb task group. Second, we use the MIMO signal processing from WiFi to aggregate LiFi and radio signals directly at the physical layer. Hy-Fi was implemented as a prototype and evaluated in a small testbed. Experimental results reveal that our approach offers excellent robustness against signal fading, blockage and external interference in both, the optical and radio channels making it suitable for applications with very strict requirements to the packet delay and loss ratio. Moreover, the two channels, LiFi and RF, can be aggregated to double the link capacity in the best case. Finally, we demonstrate how Hy-Fi could be used as wireless access technology in next-generation indoor enterprise networks providing both high capacity and seamless mobility.},
  archive      = {J_TMC},
  author       = {Anatolij Zubow and Piotr Gawłowicz and Carolin Brunn and Kai Lennert Bober and Volker Jungnickel and Kai Habel and Falko Dressler},
  doi          = {10.1109/TMC.2022.3157452},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4682-4697},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Hybrid-fidelity: Utilizing IEEE 802.11 MIMO for practical aggregation of LiFi and WiFi},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hiring a team from social network: Incentive mechanism
design for two-tiered social mobile crowdsourcing. <em>TMC</em>,
<em>22</em>(8), 4664–4681. (<a
href="https://doi.org/10.1109/TMC.2022.3162108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsourcing has become an efficient paradigm for performing large scale tasks. The incentive mechanism is important for the mobile crowdsourcing system to stimulate participants, and to achieve good service quality. In this paper, we focus on solving the insufficient participation problem for the budget constrained online crowdsourcing system. We present a two-tiered social crowdsourcing architecture, which can enable the selected registered users to recruit their social neighbors by diffusing the tasks to their social circles. We present three system models for two-tiered social crowdsourcing system based on the arrival modes of registered users and social neighbors: offline model, semi-online model, and full-online model. We consider the tasks are associated with different end times. We present an incentive mechanism for each of three system models. Through both rigorous theoretical analysis and extensive simulations, we demonstrate that the proposed incentive mechanisms achieve computational efficiency, individual rationality, budget feasibility, cost truthfulness, and time truthfulness. We further show that our incentive mechanisms for semi-online model and full-online model can obtain averagely 51.1 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; and 39.7 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; value of approximate optimal untruthful offline algorithm, respectively.},
  archive      = {J_TMC},
  author       = {Jia Xu and Zhuangye Luo and Chengcheng Guan and Dejun Yang and Linfeng Liu and Yan Zhang},
  doi          = {10.1109/TMC.2022.3162108},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4664-4681},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Hiring a team from social network: Incentive mechanism design for two-tiered social mobile crowdsourcing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical multiple access for spectrum-energy
opportunistic ambient backscatter wireless networks. <em>TMC</em>,
<em>22</em>(8), 4648–4663. (<a
href="https://doi.org/10.1109/TMC.2022.3158618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, ambient backscatter communication has become a promising technology to support the low-power and low-cost Internet-of-Things (IoT). However, the nondeterministic and sporadic nature of ambient signals makes it a great challenge when designing multiple access in spectrum opportunistic ambient backscatter wireless networks (AmBWNs). Moreover, the stringent energy supply and ultra-low-cost design of the backscatter transmitter make most multiple access schemes no longer suitable for AmBWNs. To effectively share carrier frequency resources for backscattering, we propose a hierarchical multiple access scheme, which allows beamforming based spatial division multiple access among groups, and non-orthogonal multiple access (NOMA) for multiple users access within a group. Consequently, we formulate a multi-objective optimization problem to balance the sum rate and the fairness by exploiting grouping, beamforming, and reflection coefficients. To solve this problem, we employ the matching theory to tackle the grouping problem and achieve the corresponding beamforming. We then reformulate the non-convex reflection coefficient optimization and solve it with successive convex approximation and geometric programming. Our extensive evaluation results demonstrate that the spectrum and energy efficiency, latency, and fairness can be significantly improved with minimal overhead at the transmitter.},
  archive      = {J_TMC},
  author       = {Lanhua Li and Xiaoxia Huang and Yuguang Fang},
  doi          = {10.1109/TMC.2022.3158618},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4648-4663},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Hierarchical multiple access for spectrum-energy opportunistic ambient backscatter wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy efficient sampling policies for edge computing
feedback systems. <em>TMC</em>, <em>22</em>(8), 4634–4647. (<a
href="https://doi.org/10.1109/TMC.2022.3165852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of finding efficient sampling policies in an edge-based feedback system, where sensor samples are offloaded to a back-end server that processes them and generates feedback to a user. Sampling the system at maximum frequency results in the detection of events of interest with minimum delay but incurs higher energy costs due to the communication and processing of redundant samples. On the other hand, lower sampling frequency results in higher delay in detecting the event, thus increasing the idle energy usage and degrading the quality of experience. We quantify this trade-off as a weighted function between the number of samples and the sampling interval. We solve the minimisation problem for exponential and Rayleigh distributions, for the random time to the event of interest. We prove the convexity of the objective functions by using novel techniques, which can be of independent interest elsewhere. We argue that adding an initial offset to the periodic sampling can further reduce the energy consumption and jointly compute the optimum offset and sampling interval. We apply our framework to two practically relevant applications and show energy savings of up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$36\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; when compared to an existing periodic scheme.},
  archive      = {J_TMC},
  author       = {Vishnu Narayanan Moothedath and Jaya Prakash Champati and James Gross},
  doi          = {10.1109/TMC.2022.3165852},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4634-4647},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy efficient sampling policies for edge computing feedback systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Eliciting joint truthful answers and profiles from strategic
workers in mobile crowdsourcing systems. <em>TMC</em>, <em>22</em>(8),
4620–4633. (<a href="https://doi.org/10.1109/TMC.2022.3159228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsourcing has emerged as a promising paradigm that applies the principle of crowdsourcing to perform tasks of mobility requirement. Due to the openness of mobile crowdsourcing, workers may yield low-quality task answers. To alleviate this problem, substantial efforts have been devoted to elicit truthful data from workers. On the other hand, to facilitate task assignment, workers are required to upload the platform their profiles, such as locations and expertise. Therefore, task assignment outcomes and thus mobile crowdsourcing service accuracy is subject to the quality of workers’ self-reported profiles. In this paper, we leverage incentive design to motivate workers to honestly reveal both task answers and their profiles. The challenge is to design one incentive payment for truth elicitation in two kinds of submissions. For this, we first derive the sufficient and necessary conditions for answer truthfulness and profile truthfulness separately. We then construct an incentive optimization problem that incorporates these conditions as constraints. Its optimal solution lists the payment to each worker that elicits answers and profiles jointly. Our proposed mechanism, with a formally proved bounded approximation ratio, ensures that truth-telling is a Bayesian Nash equilibrium. We prototype the mechanism and conduct a series of experiments that involve 30 volunteers to validate the efficacy and efficiency of the proposed mechanism.},
  archive      = {J_TMC},
  author       = {Mingyan Xiao and Wenqiang Jin and Chengkai Li and Ming Li},
  doi          = {10.1109/TMC.2022.3159228},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4620-4633},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Eliciting joint truthful answers and profiles from strategic workers in mobile crowdsourcing systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CrowdFL: Privacy-preserving mobile crowdsensing system via
federated learning. <em>TMC</em>, <em>22</em>(8), 4607–4619. (<a
href="https://doi.org/10.1109/TMC.2022.3157603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging sensing data collection paradigm, mobile crowdsensing (MCS) enjoys good scalability and low deployment cost but raises privacy concerns. In this paper, we propose a privacy-preserving MCS system called CrowdFL by seamlessly integrating federated learning (FL) into MCS. At a high level, in order to protect participants’ privacy and fully explore participants’ computing power, participants in CrowdFL locally process sensing data via FL paradigm and only upload encrypted training models to the server. To this end, we design a secure aggregation algorithm ( SecAgg ) through the threshold Paillier cryptosystem to aggregate training models in an encrypted form. Also, to stimulate participation, we present a hybrid incentive mechanism combining the reverse Vickrey auction and posted pricing mechanism, which is proved to be truthful and fail. Results of theoretical analysis and experimental evaluation on a practical MCS scenario (human activity recognition) show that CrowdFL is effective in protecting participants’ privacy and is efficient in operations. In contrast to existing solutions, CrowdFL is 3× faster in model decryption and improves an order of magnitude in model aggregation.},
  archive      = {J_TMC},
  author       = {Bowen Zhao and Ximeng Liu and Wei-Neng Chen and Robert H. Deng},
  doi          = {10.1109/TMC.2022.3157603},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4607-4619},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CrowdFL: Privacy-preserving mobile crowdsensing system via federated learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CP-link: Exploiting continuous spatio-temporal check-in
patterns for user identity linkage. <em>TMC</em>, <em>22</em>(8),
4594–4606. (<a href="https://doi.org/10.1109/TMC.2022.3157292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the large amount of spatio-temporal data obtained from location-based social networks, the implementation of cross-domain user linkage, also known as the User Identity Linkage (UIL), has attracted increasing research attentions. While most of the existing UIL works discretize the spatio-temporal sparse data when identifying encountering or co-located events for UIL, user’s distinctive behavior patterns implicit in the “check-in” spatio-temporal data with continuous nature pave the way for enhancing UIL performance. In this paper, we propose an approach dubbed CP-Link that exploits user behavior patterns in a continuous way. In CP-Link, the continuous space is divided into irregularly shaped stay regions, and a continuous time-based improved dynamic time warping (IDTW) method is proposed to calculate the similarity. To bridge the gap between the ideal scenario with ample records and the reality with sparse data, we adopt the user-associated location frequent pattern (LFP) model to compensate for the sparse deficiency. Extensive experiments conducted on real-world datasets demonstrate the effectiveness and superiority of CP-Link, which outperforms the state of the arts by more than 20% in terms of the AUC.},
  archive      = {J_TMC},
  author       = {Xiaoqiang Ma and Fengxiang Ding and Kai Peng and Yang Yang and Chen Wang},
  doi          = {10.1109/TMC.2022.3157292},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4594-4606},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CP-link: Exploiting continuous spatio-temporal check-in patterns for user identity linkage},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computation efficiency optimization for millimeter-wave
mobile edge computing networks with NOMA. <em>TMC</em>, <em>22</em>(8),
4578–4593. (<a href="https://doi.org/10.1109/TMC.2022.3164974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the millimeter-wave (mmWave) communications and non-orthogonal multiple access (NOMA) are exploited for mobile edge computing (MEC) networks to improve the performance of task offloading. Aiming at improving the computation efficiency (CE) and ensuring the fairness among users, we study the CE optimization for mmWave-MEC with NOMA, where both the analog beamforming (ABF) and hybrid beamforming (HBF) architectures under the partial offloading mode are considered. First, according to the max-min fairness criterion, the CE optimization problem is formulated to jointly optimize the ABF at the base station and the local resource allocation of each user in mmWave-MEC with ABF. An efficient algorithm based on the penalized successive convex approximation is proposed to solve this non-convex problem. Then, the max-min CE optimization problem in mmWave-MEC with HBF is studied, where the joint design of the HBF at the BS and the local resource allocation of each user is carried out. By using the penalty function and the inexact block coordinate descent method, a feasible optimization algorithm is developed to tackle this challenging problem. Simulation results verify the convergence of the proposed algorithms and show that the proposed resource allocation schemes can improve the system CE effectively, and the mmWave-MEC with HBF scheme can obtain higher CE than that with ABF scheme. Besides, the NOMA scheme exhibits superior performance over the conventional orthogonal multiple access scheme in terms of CE.},
  archive      = {J_TMC},
  author       = {Xiangbin Yu and Fangcheng Xu and Jiali Cai and Xiao-yu Dang and Kezhi Wang},
  doi          = {10.1109/TMC.2022.3164974},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4578-4593},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Computation efficiency optimization for millimeter-wave mobile edge computing networks with NOMA},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comprehensive cost optimization for charger deployment in
multi-hop wireless charging. <em>TMC</em>, <em>22</em>(8), 4563–4577.
(<a href="https://doi.org/10.1109/TMC.2022.3162112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-hop wireless charging technology can largely extend the charging service range of chargers, thus has promising prospect in sustainable energy replenishment for wireless rechargeable sensor network. This paper proposes a new cost criterion, termed comprehensive cost consisting of energy cost and deployment cost, to measure the actual expenditure of wireless charging. We present a multi-hop wireless charging model and formulate the problem of minimizing the comprehensive cost such that the energy demand of all sensor nodes can be fulfilled by the energy capacitated chargers. We propose a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(\ln n+1)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -approximation algorithm for the optimization problem, where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the number of sensor nodes. Then, we propose a straightforward cost sharing mechanism, which ensures that no subset of sensor nodes can benefit by breaking away from the current charging tree for any fixed charger position, to realize the paid charging service of multi-hop wireless charging. Furthermore, to keep the magnetic fields of transmitters from the interfering, the conflict avoidance schemes are proposed in both central and distributed situations. Finally, we discuss the distributed scheme for minimizing the comprehensive cost without support of central server. Through extensive simulations, we demonstrate the significant superiority of the proposed algorithms in terms of comprehensive cost.},
  archive      = {J_TMC},
  author       = {Sixu Wu and Haipeng Dai and Lijie Xu and Linfeng Liu and Fu Xiao and Jia Xu},
  doi          = {10.1109/TMC.2022.3162112},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4563-4577},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Comprehensive cost optimization for charger deployment in multi-hop wireless charging},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BubbleMap: Privilege mapping for behavior-based implicit
authentication systems. <em>TMC</em>, <em>22</em>(8), 4548–4562. (<a
href="https://doi.org/10.1109/TMC.2022.3166454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging users’ behavioral data sampled by various sensors during the identification process, implicit authentication (IA) relieves users from explicit actions such as remembering and entering passwords. Various IA schemes have been proposed based on different behavioral and contextual features such as gait, touch, and GPS. However, existing IA schemes suffer from false positives, i.e., falsely accepting an adversary, and false negatives, i.e., falsely rejecting the legitimate user due to users’ behavior change and noise. To deal with this problem, we propose BubbleMap (BMap), a framework that can be seamlessly incorporated into any existing IA system to balance between security (reducing false positives) and usability (reducing false negatives) as well as reducing the equal error rate (EER). To evaluate the proposed framework, we implemented BMap on five state-of-the-art IA systems. We also conducted an experiment in a real-world environment from 2016 to 2020. Most of the experimental results show that BMap can greatly enhance the IA schemes’ performances in terms of the EER, security, and usability, with a small amount of penalty on energy consumption.},
  archive      = {J_TMC},
  author       = {Yingyuan Yang and Xueli Huang and Jiangnan Li and Jinyuan Stella Sun},
  doi          = {10.1109/TMC.2022.3166454},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4548-4562},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BubbleMap: Privilege mapping for behavior-based implicit authentication systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BLOWN: A blockchain protocol for single-hop wireless
networks under adversarial SINR. <em>TMC</em>, <em>22</em>(8),
4530–4547. (<a href="https://doi.org/10.1109/TMC.2022.3162117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Known as a distributed ledger technology (DLT), blockchain has attracted much attention due to its properties such as decentralization, security, immutability and transparency, and its potential of servicing as an infrastructure for various applications. Blockchain can empower wireless networks with identity management, data integrity, access control, and high-level security. However, previous studies on blockchain-enabled wireless networks mostly focus on proposing architectures or building systems with popular blockchain protocols. Nevertheless, such existing protocols have obvious shortcomings when adopted in wireless networks where nodes may have limited physical resources, may fall short of well-established reliable channels, or may suffer from variable bandwidths impacted by environments or jamming attacks. In this paper, we propose a novel consensus protocol named Proof-of-Channel (PoC) leveraging the natural properties of wireless communications, and develop a permissioned BLOWN protocol (BLOckchain protocol for Wireless Networks) for single-hop wireless networks under an adversarial SINR model. We formalize BLOWN with the universal composition framework and prove its security properties, namely persistence and liveness, as well as its strengths in countering against adversarial jamming, double-spending, and Sybil attacks, which are also demonstrated by extensive simulation studies.},
  archive      = {J_TMC},
  author       = {Minghui Xu and Feng Zhao and Yifei Zou and Chunchi Liu and Xiuzhen Cheng and Falko Dressler},
  doi          = {10.1109/TMC.2022.3162117},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4530-4547},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BLOWN: A blockchain protocol for single-hop wireless networks under adversarial SINR},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). All-day object tracking for unmanned aerial vehicle.
<em>TMC</em>, <em>22</em>(8), 4515–4529. (<a
href="https://doi.org/10.1109/TMC.2022.3162892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) has facilitated a wide range of real-world applications and attracted extensive research in the mobile computing field. Specially, developing real-time robust visual onboard trackers for all-day aerial maneuver can remarkably broaden the scope of intelligent deployment of UAV. However, prior tracking methods have merely focused on robust tracking in the well-illuminated scenes, while ignoring trackers’ capabilities to be deployed in the dark. In darkness, the conditions can be more complex and harsh, easily posing inferior robust tracking or even tracking failure. To this end, this work proposes a novel discriminative correlation filter-based tracker with illumination adaptive and anti-dark capability, namely ADTrack. ADTrack firstly exploits image illuminance information to enable adaptability of the model to the given light condition. Then, by virtue of an efficient enhancer, ADTrack carries out image pretreatment where a target aware mask is generated. Benefiting from the mask, ADTrack aims to solve a novel dual regression problem where dual filters are online trained with mutual constraint. Besides, this work also constructs a UAV nighttime tracking benchmark UAVDark135. Exhaustive experiments on authoritative benchmarks and onboard tests are implemented to validate the superiority and robustness of ADTrack in all-day conditions.},
  archive      = {J_TMC},
  author       = {Bowen Li and Changhong Fu and Fangqiang Ding and Junjie Ye and Fuling Lin},
  doi          = {10.1109/TMC.2022.3162892},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4515-4529},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {All-day object tracking for unmanned aerial vehicle},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Age-optimal low-power status update over time-correlated
fading channel. <em>TMC</em>, <em>22</em>(8), 4500–4514. (<a
href="https://doi.org/10.1109/TMC.2022.3160050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider transmission scheduling in a status update system, where updates are generated periodically and transmitted over a Gilbert-Elliott fading channel. The goal is to minimize the long-run average age of information (AoI) under a long-run average energy constraint. We consider two practical cases to obtain channel state information (CSI): (i) without channel sensing and (ii) with delayed channel sensing. For (i), CSI is revealed by the feedback (ACK/NACK) of a transmission, but when no transmission occurs, CSI is not revealed. Thus, we have to balance tradeoffs across energy, AoI, channel exploration, and channel exploitation. The problem is formulated as a constrained partially observable Markov decision process (POMDP). We show that the optimal policy is a randomized mixture of no more than two stationary deterministic policies each of which is of a threshold-type in the belief on the channel. For (ii), (delayed) CSI is available via channel sensing. Then, the tradeoff is only between the AoI and energy. The problem is formulated as a constrained MDP. The optimal policy is shown to have a similar structure as in (i) but with an AoI associated threshold. With these, we develop an optimal structure-aware algorithm for each case.},
  archive      = {J_TMC},
  author       = {Guidan Yao and Ahmed M. Bedewy and Ness B. Shroff},
  doi          = {10.1109/TMC.2022.3160050},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4500-4514},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Age-optimal low-power status update over time-correlated fading channel},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Age of information in physical-layer network coding enabled
two-way relay networks. <em>TMC</em>, <em>22</em>(8), 4485–4499. (<a
href="https://doi.org/10.1109/TMC.2022.3166155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the information freshness of two-way relay networks (TWRNs) operated with physical-layer network coding (PNC). Information freshness is quantified by age of information (AoI), defined as the time elapsed since the generation time of the latest received information update. PNC reduces the communication latency of TWRNs by turning superimposed electromagnetic waves into network-coded messages so that end users can send update packets to each other more frequently via the relay. While sending update packets more frequently has the potential to reduce AoI, how to handle packet corruption in TWRNs has not been investigated. Specifically, if an old packet is corrupted in any hop of a TWRN, one needs to decide whether to drop or to retransmit the old packet, e.g., a new packet has more recent information but may take more time to be delivered. Therefore, we study the average AoI with and without automatic repeat request (ARQ) in PNC-enabled TWRNs. Interestingly, our analysis shows that neither the non-ARQ scheme nor the pure ARQ scheme achieves a good average AoI. Hence, we put forth an uplink-lost-then-drop (ULTD) protocol that combines packet drop and ARQ. Experiments on software-defined radios indicate that ULTD significantly outperforms non-ARQ and pure ARQ schemes in terms of average AoI, especially when the two end users have imbalanced channel conditions. We believe the insight of ULTD on TWRNs generally applies to other two-hop networks: to achieve high information freshness, when packets are corrupted in the first hop, new packets should be generated and sent (i.e., old packets are discarded); when packets are corrupted in the second hop, old packets should be retransmitted until they are successfully received.},
  archive      = {J_TMC},
  author       = {Haoyuan Pan and Tse-Tin Chan and Victor C. M. Leung and Jianqiang Li},
  doi          = {10.1109/TMC.2022.3166155},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4485-4499},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Age of information in physical-layer network coding enabled two-way relay networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AFall: Wi-fi-based device-free fall detection system using
spatial angle of arrival. <em>TMC</em>, <em>22</em>(8), 4471–4484. (<a
href="https://doi.org/10.1109/TMC.2022.3157666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falling is a common health problem for elderly people. Early detection of falls allows earlier rescue measures to be implemented. Most existing Wi-Fi-based fall detection systems employ learning-based methods, which require large amounts of labeled data for prior training. To address this issue, we in this paper present AFall, a robust model-based fall detection system that does not require prior training for a single person based on Wi-Fi Channel State Information (CSI). Different from previous Wi-Fi-based fall detection systems, we model the relationship between human falls and changes of Angle of Arrival (AoA) of Wi-Fi signals reflected from human body by multiple signal classification (MUSIC) algorithm. In particular, we deploy two receivers in orthogonal spatial layouts to capture diversified AoA information. Since AoA reflected from human body is independent of environments and subjects, the performance of AFall can remain stable when the environment changes slightly, which can meet the daily needs of the elderly people. We implement AFall using commodity Wi-Fi devices and evaluate it in five different indoor environments. The experimental results demonstrate that AFall achieves an average accuracy of 84.31% and an average F1 score of 84.56%.},
  archive      = {J_TMC},
  author       = {Sheng Chen and Wei Yang and Yang Xu and Yangyang Geng and Bangzhou Xin and Liusheng Huang},
  doi          = {10.1109/TMC.2022.3157666},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4471-4484},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AFall: Wi-fi-based device-free fall detection system using spatial angle of arrival},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive video streaming with automatic
quality-of-experience optimization. <em>TMC</em>, <em>22</em>(8),
4456–4470. (<a href="https://doi.org/10.1109/TMC.2022.3161351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video streaming has grown tremendously in recent years and it is now one of the main applications on the Internet. Due to the networks’ inherent bandwidth fluctuations, various rate-adaptive streaming algorithms have been developed to compensate for such fluctuations to improve Quality-of-Experience (QoE). However, in practice, the preference for QoE typically differs significantly across different viewers and there is no systematic way so far to comprehensively incorporate different sets of conflicting QoE objectives into the algorithm design. Thus, it is not surprising that the QoE performance achieved by the existing algorithms is in fact far from optimal. This work aims at attacking the heart of the problem by developing a novel framework called Post Streaming Quality Analysis (PSQA) that can maximize the QoE under any preference through automatically tuning the adaptation logic of the streaming algorithms. Evaluation results show that the QoE achieved by PSQA is substantially better than the existing approaches and in some scenarios even close to optimal. Moreover, PSQA can be readily implemented into real streaming platforms, offering a practical and reliable solution for high-performance streaming services.},
  archive      = {J_TMC},
  author       = {Guanghui Zhang and Jie Zhang and Yan Liu and Haibo Hu and Jack Y. B. Lee and Vaneet Aggarwal},
  doi          = {10.1109/TMC.2022.3161351},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4456-4470},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive video streaming with automatic quality-of-experience optimization},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A task-driven sequential overlapping coalition formation
game for resource allocation in heterogeneous UAV networks.
<em>TMC</em>, <em>22</em>(8), 4439–4455. (<a
href="https://doi.org/10.1109/TMC.2022.3165965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A heterogeneous unmanned aerial vehicle (UAV) network where UAVs carrying different resources form coalition and cooperatively carry out tasks is of crucial importance for fulfilling diverse tasks. However, the existing coalition formation (CF) game model only optimizes the composition of UAVs in a single coalition, which results in disjoined coalitions. In order to tackle this issue, a sequential overlapping coalition formation (OCF) game is proposed by considering the overlapping and complementary relations of resource properties and the task execution order. Moreover, different from the Pareto and selfish orders, a bilateral mutual benefit transfer (BMBT) order is proposed to optimize the cooperative task resource allocation through partial cooperation among overlapping coalition members. Furthermore, using the preference relation between UAVs carrying resources and tasks requiring the same type of resource, a preference gravity-guided tabu search (PGG-TS) algorithm is developed to obtain a stable coalition structure. Numerical results verify that the proposed PGG-TS algorithm increases the average utility of tasks by 12.5% and 38.5% compared with the split-merge preferred OCF algorithm and non-overlapping CF algorithm, respectively. The utility of the proposed BMBT order increases by 25.1% and 34.3% compared with selfish and Pareto orders, respectively.},
  archive      = {J_TMC},
  author       = {Nan Qi and Zanqi Huang and Fuhui Zhou and Qingjiang Shi and Qihui Wu and Ming Xiao},
  doi          = {10.1109/TMC.2022.3165965},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4439-4455},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A task-driven sequential overlapping coalition formation game for resource allocation in heterogeneous UAV networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel framework for cost constrained network sharing.
<em>TMC</em>, <em>22</em>(8), 4422–4438. (<a
href="https://doi.org/10.1109/TMC.2022.3155586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network sharing is widely accepted as a cost effective approach for mobile network deployment. It remains uncertain, however, how regulators will evaluate network sharing agreements (NSA) for future networks in the context of the current competition law. For example, 5G mobile network operators (MNOs) seeking to enter NSAs may risk legal challenges, as regulators have not given MNOs sufficient guidance for self-evaluation of their NSAs. One way for MNOs to reduce the risk of legal challenge is to avoid sharing variable costs in the NSA. However, constraining costs to be non-variable (i.e., fixed) rules out the use of most pricing mechanisms that have been widely adopted for dynamic resource trading between MNOs. In this article, we propose a network sharing framework to allow dynamic resource sharing without the use of resource pricing. To incentivize sharing without pricing, our framework presents sharing as a means for MNOs to differentiate services and better compete in the service market for profit. We evaluate our framework in a duopoly market model and demonstrate the economic and regulatory viability of our framework.},
  archive      = {J_TMC},
  author       = {Eric Ruzomberka and Kwang Taik Kim and Arnob Ghosh and David J. Love and Mung Chiang},
  doi          = {10.1109/TMC.2022.3155586},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4422-4438},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A novel framework for cost constrained network sharing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-user cost-efficient crowd-assisted VR content
delivery solution in 5G-and-beyond heterogeneous networks. <em>TMC</em>,
<em>22</em>(8), 4405–4421. (<a
href="https://doi.org/10.1109/TMC.2022.3162147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The latest evolution of wireless communications enables users to access rich Virtual Reality (VR) services via the Internet, including while on the move. However, providing a premium immersive experience for the massive number of concurrent users with various device configurations is a significant challenge due to the ultra-high data rate and ultra-low delay requirements of VR livecast services. This paper introduces an innovative m ulti-user cost- e fficient c rowd-assisted d elivery and c omputing (MEC-DC) framework, which leverages mobile edge computing and end-user resources to support high performance VR content delivery over 5G-and-beyond heterogeneous networks (5G-HetNets). The proposed MEC-DC framework is based on three main solutions. First is a novel b uffer- n adir-based m ulticast (BNM) mechanism for VR transmissions over 5G-HetNets. BNM ensures smooth and synchronized user viewing experiences by maximizing the average playback buffer-nadir of all participants with stochastic optimization. Second and third are practical distributed algorithms: the cost-efficient m ulticast- a ware t ranscoding o ffloading (MATO) and c rowd- a ssisted d elivery algorithm (CAD) which optimize jointly multicast delivery and video transcoding. The algorithms’ optimality and complexity were investigated. The proposed MATO-CAD solution was evaluated with real datasets, trace-driven numerical simulations, and prototype-based experiments. The trace-driven experimental results showed how the proposed solution provides 18% throughput improvement, the lowest delay, and the best playback freeze ratio in comparison with three other state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Lujie Zhong and Xingyan Chen and Changqiao Xu and Yunxiao Ma and Mu Wang and Yu Zhao and Gabriel-Miro Muntean},
  doi          = {10.1109/TMC.2022.3162147},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4405-4421},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A multi-user cost-efficient crowd-assisted VR content delivery solution in 5G-and-beyond heterogeneous networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A kernel method to nonlinear location estimation with
RSS-based fingerprint. <em>TMC</em>, <em>22</em>(8), 4388–4404. (<a
href="https://doi.org/10.1109/TMC.2022.3162612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a nonlinear location estimation to infer the position of a user holding a smartphone. We consider a large location with &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$M$&lt;/tex-math&gt;&lt;/inline-formula&gt; number of grid points, each grid point is labeled with a unique fingerprint consisting of the received signal strength (RSS) values measured from &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N$&lt;/tex-math&gt;&lt;/inline-formula&gt; number of Bluetooth Low Energy (BLE) beacons. Given the fingerprint observed by the smartphone, the user’s current location can be estimated by finding the top-k similar fingerprints from the list of fingerprints registered in the database. Besides the environmental factors, the dynamicity in holding the smartphone is another source to the variation in fingerprint measurements, yet there are not many studies addressing the fingerprint variability due to dynamic smartphone positions held by human hands during online detection. To this end, we propose a nonlinear location estimation using the kernel method. Specifically, our proposed method comprises of two steps: 1) a beacon selection strategy to select a subset of beacons that is insensitive to the subtle change of holding positions, and 2) a kernel method to compute the similarity between this subset of observed signals and all the fingerprints registered in the database. The experimental results based on large-scale data collected in a complex building indicate a substantial performance gain of our proposed approach in comparison to state-of-the-art methods. The dataset consisting of the signal information collected from the beacons is available online.},
  archive      = {J_TMC},
  author       = {Pai Chet Ng and Petros Spachos and James She and Konstantinos N. Plataniotis},
  doi          = {10.1109/TMC.2022.3162612},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4388-4404},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A kernel method to nonlinear location estimation with RSS-based fingerprint},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning framework for beam selection and power
control in massive MIMO - millimeter-wave communications. <em>TMC</em>,
<em>22</em>(8), 4374–4387. (<a
href="https://doi.org/10.1109/TMC.2022.3159697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fine power control policy and beam alignment is required between the base station (BS) and user equipment (UE) to achieve the promising performance of massive multiple input multiple output (MIMO) in millimeter wave (mmWave) communications. However, obtaining the channel state information (CSI) of mmWave - massive MIMO systems is challenging. In this paper, the beam-steering technique is used to estimate the signal strength from the BS to the user. We propose a novel learning framework to determine the suitable beam for a specific user and the transmit power for minimizing the cost including the transmit power and the unsatisfied rate when the channel is unknown. In addition, we address the missing data problem, and then employ the long-short term memory (LSTM) on the temporal processed inputs to select the suitable beam. Furthermore, we design a learning agent to predict the proper transmit power from the transmitted SSBs taking into account the required transmission rate. We then validate the proposed learning framework on the Deep MIMO dataset constructed based on accurate ray-tracing channels. Numerical results show our proposed framework outperforms the state-of-the-art prediction strategies, and approximates the best performance which is obtained when the CSI is available.},
  archive      = {J_TMC},
  author       = {Ti Ti Nguyen and Kim-Khoa Nguyen},
  doi          = {10.1109/TMC.2022.3159697},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4374-4387},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A deep learning framework for beam selection and power control in massive MIMO - millimeter-wave communications},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep dive into the accuracy of IP geolocation databases
and its impact on online advertising. <em>TMC</em>, <em>22</em>(8),
4359–4373. (<a href="https://doi.org/10.1109/TMC.2022.3166785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quest for every time more personalized Internet experience relies on the enriched contextual information about each user. Online advertising also follows this approach. Among the context information that advertising stakeholders leverage, location information is certainly one of them. However, when this information is not directly available from the end users, advertising stakeholders infer it using geolocation databases, matching IP addresses to a position on earth. The accuracy of this approach has often been questioned in the past: however, the reality check on an advertising stakeholder shows that this technique accounts for a large fraction of the served advertisements. In this paper, we revisit the work in the field, that is mostly from almost one decade ago, through the lenses of big data. More specifically, we, i) benchmark two commercial Internet geolocation databases, evaluate the quality of their information using a ground-truth database of user positions containing over 2 billion samples, ii) analyze the internals of these databases, devising a theoretical upper bound for the quality of the Internet geolocation approach, and iii) we run an empirical study that unveils the monetary impact of this technology by considering the costs associated with a real-world ad impressions dataset.},
  archive      = {J_TMC},
  author       = {Patricia Callejo and Marco Gramaglia and Rubén Cuevas and Ángel Cuevas},
  doi          = {10.1109/TMC.2022.3166785},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {4359-4373},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A deep dive into the accuracy of IP geolocation databases and its impact on online advertising},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WAVE: Edge-device cooperated real-time object detection for
open-air applications. <em>TMC</em>, <em>22</em>(7), 4347–4357. (<a
href="https://doi.org/10.1109/TMC.2022.3150401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CNN based real-time object detection can facilitate various AI applications that need to understand the surroundings via camera, such as autonomous package delivery robots, augmented reality, and intelligent drone applications. Currently, due to the high computation cost of CNN, accurate real-time object detection is only possible when mobile devices can upload video frames to powerful edge servers through high-speed wireless networks like WiFi. However, for many open-air AI applications, the network conditions (such as cellular networks) are usually unfavorable, far from satisfying the network demands of state-of-the-art systems. In this paper, we focus on the challenges incurred by mobile communication networks and propose WAVEcontaining three novel techniques, which are Deep RoI Encoding , Prioritized Parallel Offloading and Fine-grained Offloading Strategy , to realize real-time , robust and low-cost object detection for open-air AI applications. The experimental results show that under LTE networks, WAVE realizes high-accuracy real-time object detection and face recognition and significantly outperforms state-of-the-art systems.},
  archive      = {J_TMC},
  author       = {Liang Dong and Zheng Yang and Xinjun Cai and Yi Zhao and Qiang Ma and Xin Miao},
  doi          = {10.1109/TMC.2022.3150401},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4347-4357},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {WAVE: Edge-device cooperated real-time object detection for open-air applications},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Turbo-HB: A sub-millisecond hybrid beamforming design for 5G
mmWave systems. <em>TMC</em>, <em>22</em>(7), 4332–4346. (<a
href="https://doi.org/10.1109/TMC.2022.3152480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid beamforming (HB) architecture has been widely considered for 5G mmWave systems. It reduces hardware complexity by allowing the number of RF chains to be far fewer than the number of antennas. A major practical challenge for HB is to obtain a beamforming solution in real-time. In 5G NR, new frame structures with short TTIs are employed to support mmWave communications. Under such frame structures, it is necessary to obtain a beamforming solution with a time resolution varying from 1 ms to 125 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu$&lt;/tex-math&gt;&lt;/inline-formula&gt; s – an extremely stringent time requirement considering the complexity involved in HB. In this paper, we present the design and implementation of Turbo-HB – a novel beamforming design under the HB architecture that is capable of offering the beamforming matrices in less than 500 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu$&lt;/tex-math&gt;&lt;/inline-formula&gt; s. The key ideas of Turbo-HB include: (i) reducing the complexity of computation-intensive SVD operations by exploiting channel sparsity at mmWave frequencies, and (ii) achieving large-scale parallel computation with minimal memory access. We implement Turbo-HB on an off-the-shelf Nvidia GPU and conduct extensive experiments. Our experimental results demonstrate that Turbo-HB can obtain a beamforming solution in 500 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu$&lt;/tex-math&gt;&lt;/inline-formula&gt; s for up to 100 RBs and 10 MU-MIMO users on each RB while offering competitive throughput performance compared to state-of-the-art (non-real-time) algorithms.},
  archive      = {J_TMC},
  author       = {Yongce Chen and Yan Huang and Chengzhang Li and Y. Thomas Hou and Wenjing Lou},
  doi          = {10.1109/TMC.2022.3152480},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4332-4346},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Turbo-HB: A sub-millisecond hybrid beamforming design for 5G mmWave systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Truthful user recruitment for cooperative crowdsensing task:
A combinatorial multi-armed bandit approach. <em>TMC</em>,
<em>22</em>(7), 4314–4331. (<a
href="https://doi.org/10.1109/TMC.2022.3153451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Crowdsensing (MCS) is a promising paradigm that recruits users to cooperatively perform a sensing task. When recruiting users, existing works mainly focus on selecting a group of users with the best objective ability, e.g., the user&#39;s probability or frequency of covering the task locations. However, we argue that the task completion effect depends not only on the user&#39;s objective ability, but also on their subjective collaboration likelihood with each other. Furthermore, even though we can find a well-behaved group of users in the single-round scenario, while in the multi-round scenario without enough prior knowledge, we still face the problem of recruiting previously well-behaved user groups (exploitation) or recruiting uncertain user groups (exploration). Additionally, we consider that each user has a different cost, and the platform recruits users under a cost budget; thus, the problem becomes more challenging: users may report fake costs to gain more profits. To address these problems, assuming that the user&#39;s information is known, we first convert the single-round user recruitment problem into the min-cut problem and propose a graph theory based algorithm to find the approximate solution. Then, in the multi-round scenario where the user&#39;s information is estimated from the previous rounds, to balance the trade-off between exploration and exploitation, we propose the multi-round User Recruitment strategy under the budget constraint based on the combinatorial Multi-armed Bandit model (URMB), which is proven to achieve a tight regret bound. Next, we propose a graph-based payment strategy to achieve truthfulness and individual rationality of users. Finally, extensive experiments on three real-world datasets show that URMB always outperforms the state-of-th-art strategies.},
  archive      = {J_TMC},
  author       = {Hengzhi Wang and Yongjian Yang and En Wang and Wenbin Liu and Yuanbo Xu and Jie Wu},
  doi          = {10.1109/TMC.2022.3153451},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4314-4331},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Truthful user recruitment for cooperative crowdsensing task: A combinatorial multi-armed bandit approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards robust task assignment in mobile crowdsensing
systems. <em>TMC</em>, <em>22</em>(7), 4297–4313. (<a
href="https://doi.org/10.1109/TMC.2022.3151190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Crowdsensing (MCS), which assigns outsourced sensing tasks to volunteer workers, has become an appealing paradigm to collaboratively collect data from surrounding environments. However, during actual task implementation, various unpredictable disruptions are usually inevitable, which might cause a task execution failure and thus impair the benefit of MCS systems. Practically, via reactively shifting the pre-determined assignment scheme in real time, it is usually impossible to develop reassignment schemes without a sacrifice of the system performance. Against this background, we turn to an alternative solution, i.e., proactively creating a robust task assignment scheme offline. In this work, we provide the first attempt to investigate an important and realistic R o B ust T ask A ssignment ( RBTA ) problem in MCS systems, and try to strengthen the assignment scheme&#39;s robustness while minimizing the workers’ traveling detour cost simultaneously. By leveraging the workers’ spatiotemporal mobility, we propose an assignment-graph-based approach. First, an assignment graph is constructed to locally model the assignment relationship between the released MCS tasks and available workers. And then, under the framework of evolutionary multi-tasking, we devise a population-based optimization algorithm, namely EMTRA , to effectively achieve adequate Pareto-optimal schemes. Comprehensive experiments on two real-world datasets clearly validate the effectiveness and applicability of our proposed approach.},
  archive      = {J_TMC},
  author       = {Liang Wang and Zhiwen Yu and Kaishun Wu and Dingqi Yang and En Wang and Tian Wang and Yihan Mei and Bin Guo},
  doi          = {10.1109/TMC.2022.3151190},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4297-4313},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards robust task assignment in mobile crowdsensing systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stable service caching in MECs of hierarchical service
markets with uncertain request rates. <em>TMC</em>, <em>22</em>(7),
4279–4296. (<a href="https://doi.org/10.1109/TMC.2022.3149870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-access edge computing (MEC) enables extreme low-latency AI services, such as Augmented Reality (AR) and Virtual Reality (VR), by deploying cloudlets in locations close to users. Meanwhile, a 5G hierarchical service market is emerging with both large-scale and small-scale network service providers competing for both computing and network bandwidth resources of an infrastructure provider. In this paper, we investigate the problem of caching services originally deployed in remote clouds to cloudlets in an MEC network in a hierarchical service market. For the service caching problem, we first propose a novel approximation-restricted framework that guarantees the stability of the 5G service market. Under the proposed framework, we first propose an approximation algorithm with a provable approximation ratio for the problem with non-selfish network service providers. We then design an efficient Stackelberg congestion game with selfish network service providers, and analyze the Price of Anarchy (PoA) of the proposed Stackelberg congestion game to measure the efficiency loss of the game due to selfishness of network service providers. Considering that the request rate of each service may not be given in advance, we study the service caching problem with the uncertainlity of request rates, and propose an approximation algorithm and a Stackelberg game via leveraging the randomized rounding technique. We finally evaluate the performance of the proposed algorithms and mechanisms by both simulations and implementations in a real test-bed. Results show that the performance of our proposed mechanisms achieve around 9.2% less cost than those of existing approaches.},
  archive      = {J_TMC},
  author       = {Zichuan Xu and Qiufen Xia and Lin Wang and Pan Zhou and John C. S. Lui and Weifa Liang and Wenzheng Xu and Guowei Wu},
  doi          = {10.1109/TMC.2022.3149870},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4279-4296},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Stable service caching in MECs of hierarchical service markets with uncertain request rates},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SmartMagnet: Proximity-based access control for IoT devices
with smartphones and magnets. <em>TMC</em>, <em>22</em>(7), 4266–4278.
(<a href="https://doi.org/10.1109/TMC.2022.3149746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ubiquitous smartphones can be powerful tools to access IoT devices. Proximity-based access control (PBAC) is needed such that IoT devices only allow data access by legitimate users in close proximity. Traditional smartphone-based authentication techniques do not satisfy the PBAC requirements. This paper presents SmartMagnet, a novel scheme that combines smartphones and cheap magnets to achieve PBAC for IoT devices. SmartMagnet explores a few cheap, tiny commodity magnets which we propose to attach to or embed into IoT devices, as well as the magnetometer and attitude sensor on commodity smartphones. Each legitimate user performs a self-chosen 3D password gesture near the target IoT device with the enrolled smartphone. Then the system server uses the IoT device’s confidential magnet configuration parameters to reconstruct the user gesture from the magnetometer and attitude sensor data submitted by the smartphone. If the reconstructed gesture matches the stored template of the purported user, the smartphone user is deemed legitimate and allowed access to the IoT device. Extensive experiments confirm the high usability of SmartMagnet and its strong resilience to lost/stolen smartphones and also remote attacks via signal relaying.},
  archive      = {J_TMC},
  author       = {Yan Zhang and Dianqi Han and Ang Li and Jiawei Li and Tao Li and Yanchao Zhang},
  doi          = {10.1109/TMC.2022.3149746},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4266-4278},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SmartMagnet: Proximity-based access control for IoT devices with smartphones and magnets},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revenue maximization: The interplay between personalized
bundle recommendation and wireless content caching. <em>TMC</em>,
<em>22</em>(7), 4253–4265. (<a
href="https://doi.org/10.1109/TMC.2022.3142809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we explore the interplay between personalized bundle recommendation and cache decision on the performance of wireless edge caching networks. A revenue maximization perspective is provided. To this end, we first examine the quantitative impact of bundle recommendation on the content request probability of different users. We then specify the definition of system revenue, showing its dependence on bundle recommendation and caching policies. With that, a joint bundling, caching and recommendation decision problem is formulated to maximize the achievable system revenue, taking into account the constraints of user-distinguished recommendation quality, recommendation amount, and the cache capacity budget. To solve this non-tractable optimization problem, a divide-then-conquer methodology is adopted. Specifically, we first determine the bundle state per user, on which basis we perform the joint bundle recommendation and caching decision-making, wherein several bundling strategies with different time-complexity are devised. Last but not least, we provide detailed properties analysis for our proposed bundling and joint optimization algorithms. Comprehensive numerical simulations validate the performance enhancement of the designed solutions compared to extensive conventional single-item recommendation oriented benchmarks.},
  archive      = {J_TMC},
  author       = {Yaru Fu and Yue Zhang and Angus K. Y. Wong and Tony Q. S. Quek},
  doi          = {10.1109/TMC.2022.3142809},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4253-4265},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Revenue maximization: The interplay between personalized bundle recommendation and wireless content caching},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RedPacketBike: A graph-based demand modeling and
crowd-driven station rebalancing framework for bike sharing systems.
<em>TMC</em>, <em>22</em>(7), 4236–4252. (<a
href="https://doi.org/10.1109/TMC.2022.3145979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bike-sharing systems have been deployed globally. One of the key issues for high-quality bike-sharing systems is to rebalance city-wide stations to maintain bike availability. Traditional strategies, such as repositioning bikes by trucks and volunteers based on historical riding records, usually operate in fixed paths and limited capacities, lacking the flexibility to cope with the highly dynamic and context dependent riding demands, and usually suffer from high costs and long delays. In this work, we propose RedPacketBike, an incentive-driven, crowd-based station rebalancing framework to effectively recruit participants from hybrid fleets (e.g., volunteer riders and hired trucks) based on the accurate forecast of bike demand leveraging deep learning techniques. First, we propose a spatiotemporal clustering method to extract bike demand hotspots from fluctuating bike usage data. Then, we build a context-aware deep neural network named BikeNet to forecast the trends of bike demand hotspots, simultaneously modeling the spatial correlations by graph convolution networks (GCN), the temporal dependencies by long short-term memory networks (RNN), and the contextual factors by autoencoders (AE). Finally, we propose a reinforcement-learning-based method to find optimal station rebalancing schemes by generating station rebalancing tasks with an integer linear programming (ILP) algorithm and allocating tasks to participants from hybrid fleets with dynamic incentive designs and reward expectations. Experiments using real-world bike-sharing system data collected from Citi Bike in New York City and Mobike in Xiamen City validate the performance of our framework, achieving a demand forecast error below 4.171 measured in MAE, and a 17.2% improvement of station availability by simulations with real-world parameter settings, outperforming the state-of-the-art baselines.},
  archive      = {J_TMC},
  author       = {Hang Zhu and Tieqi Shou and Ruiying Guo and Zhihan Jiang and Zeyu Wang and Zhiyuan Wang and Zhiyong Yu and Weijie Zhang and Cheng Wang and Longbiao Chen},
  doi          = {10.1109/TMC.2022.3145979},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4236-4252},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RedPacketBike: A graph-based demand modeling and crowd-driven station rebalancing framework for bike sharing systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognizing hand gestures using solar cells. <em>TMC</em>,
<em>22</em>(7), 4223–4235. (<a
href="https://doi.org/10.1109/TMC.2022.3148143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design a system, SolarGest, which can recognize hand gestures near a solar-powered device by analyzing the patterns of the photocurrent. SolarGest is based on the observation that each gesture interferes with incident light rays on the solar panel in a unique way, leaving its discernible signature in harvested photocurrent. Using solar energy harvesting laws, we develop a model to optimize design and usage of SolarGest. To further improve the robustness of SolarGest under non-deterministic operating conditions, we combine dynamic time warping with Z-score transformation in a signal processing pipeline to pre-process each gesture waveform before it is analyzed for classification. We evaluate SolarGest with both conventional opaque solar cells as well as emerging see-through transparent cells. Our experiments demonstrate that SolarGest achieves 99% for six gestures with a single cell and 95% for fifteen gesture with a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$2\times 2$&lt;/tex-math&gt;&lt;/inline-formula&gt; solar cell array. The power measuement study suggests that SolarGest consume 44% less power compared to light sensor based systems.},
  archive      = {J_TMC},
  author       = {Dong Ma and Guohao Lan and Changshuo Hu and Mahbub Hassan and Wen Hu and Mushfika B. Upama and Ashraf Uddin and Moustafa Youssef},
  doi          = {10.1109/TMC.2022.3148143},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4223-4235},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Recognizing hand gestures using solar cells},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Privacy preservation in multi-cloud secure data fusion for
infectious-disease analysis. <em>TMC</em>, <em>22</em>(7), 4212–4222.
(<a href="https://doi.org/10.1109/TMC.2022.3145745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is often observed that people&#39;s data are scattered across various organizations and these data can be used to generate usable insights when integrated. However, data fusion from multiple data hosting sites could put user privacy at risk albeit with some security mechanisms. This paper studies a data-analytic platform that adopts the Kulldorff scan statistic to determine infectious-disease spatial hotspots by integrating and analyzing users’ health and location data that are respectively stored in two clouds. We examine the privacy threats to this platform which has a key-oblivious inner product encryption (KOIPE) mechanism in place to ensure that only coarse-grained statistical data is revealed to the honest-but-curious (HbC) entity. To protect user privacy from the designed inference attack, we exploit a game-theoretic approach to incentivize users to form anonymous clusters with a quantitative privacy guarantee. We conduct extensive simulations based on real-life datasets to demonstrate the performance of our scheme in terms of design overhead and privacy level.},
  archive      = {J_TMC},
  author       = {Jianqing Liu and Chi Zhang and Kaiping Xue and Yuguang Fang},
  doi          = {10.1109/TMC.2022.3145745},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4212-4222},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy preservation in multi-cloud secure data fusion for infectious-disease analysis},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Placement and allocation of virtual network functions:
Multi-dimensional case. <em>TMC</em>, <em>22</em>(7), 4195–4211. (<a
href="https://doi.org/10.1109/TMC.2022.3151908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network function virtualization (NFV) is an emerging design paradigm that replaces physical middlebox devices with software modules running on general purpose commodity servers. While gradually transitioning to NFV, Internet service providers face the problem of where to introduce NFV in order to make the most benefit of that; here, we measure the benefit by the amount of traffic that can be served in an NFV-enabled network. This problem is non-trivial as it is composed of two challenging subproblems: 1) placement of nodes to support virtual network functions (referred to as VNF-nodes); 2) allocation of the VNF-nodes’ resources to network flows. These two subproblems must be jointly considered to satisfy the objective of serving the maximum amount of traffic. This problem has been studied for the one-dimensional setting, where all network flows require one network function, which requires a unit of resource to process a unit of flow. In this work, we consider the multi-dimensional setting, where flows must be processed by multiple network functions, which require a different amount of each resource to process a unit of flow. The multi-dimensional setting introduces new challenges in addition to those of the one-dimensional setting (e.g., NP-hardness and non-submodularity) and also makes the resource allocation subproblem a multi-dimensional generalization of the generalized assignment problem with assignment restrictions. To address these difficulties, we propose a novel two-level relaxation method that allows us to draw a connection to the sequence submodular theory and utilize the property of sequence submodularity along with the primal-dual technique to design two approximation algorithms. We further prove that the proposed algorithms have a non-trivial approximation ratio that depends on the number of VNF-nodes, resources, and a measure of the available resource compared to flow demand. Finally, we perform trace-driven simulations to show the effectiveness of the proposed algorithms.},
  archive      = {J_TMC},
  author       = {Gamal Sallam and Zizhan Zheng and Bo Ji},
  doi          = {10.1109/TMC.2022.3151908},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4195-4211},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Placement and allocation of virtual network functions: Multi-dimensional case},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing aggregation frequency for hierarchical model
training in heterogeneous edge computing. <em>TMC</em>, <em>22</em>(7),
4181–4194. (<a href="https://doi.org/10.1109/TMC.2022.3149584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has been widely used for distributed machine learning in edge computing. In FL, the model parameters are iteratively aggregated from the clients to a central server, which is inclined to be the communication bottleneck and single point of failure. To solve these drawbacks, hierarchical model training frameworks like Hierarchical Federated Learning (HFL) and E-Tree learning have been proposed. One of the most challenging problems in the hierarchical model training framework is optimizing the aggregation frequencies of the edge devices at various levels. Because, in an edge computing environment, heterogeneity in the resource can introduce synchronization delays caused by waiting for slow workers and significantly impact the training performance. This paper tackles the problem with weak synchronization where edge devices on the same level have different frequencies on local updates and/or model aggregations. Existing works based on weak synchronization lack solutions to quantitatively determine the aggregation frequencies of each edge device. Thus, we propose a resource-based aggregation frequency controlling method, termed RAF, which determines the optimal aggregation frequencies of edge devices to minimize the loss function according to heterogeneous resources. Our proposed method can alleviate the waiting time and fully utilize the resources of the edge devices. Besides, RAF dynamically adjusts the aggregation frequencies at different phases during the model training to achieve fast convergence speed and high accuracy. We evaluated the performance of RAF via extensive experiments with real datasets on our self-developed edge computing testbed. Evaluation results demonstrate that RAF outperforms the benchmark approaches in terms of learning accuracy and convergence speed.},
  archive      = {J_TMC},
  author       = {Lei Yang and Yingqi Gan and Jiannong Cao and Zhenyu Wang},
  doi          = {10.1109/TMC.2022.3149584},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4181-4194},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimizing aggregation frequency for hierarchical model training in heterogeneous edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online service request duplicating for vehicular
applications. <em>TMC</em>, <em>22</em>(7), 4168–4180. (<a
href="https://doi.org/10.1109/TMC.2022.3148170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicles on roads have increasingly powerful computing capabilities and edge nodes are being widely deployed. They can work together to provide computing services for onboard driving systems, passengers, and pedestrians. Typical applications in vehicular systems have service requirements such as low latency and high reliability. Most studies in vehicular networks concerning latency and reliability focus on vehicular communication at the network level. Based on these fundamental works, an increasing proportion of vehicles boast complex applications that require service-level end-to-end performance guarantees. Several works guarantee service-level latency or reliability while new and innovative applications are demanding a joint optimization of the above two metrics. To address the critical challenges induced by the joint modeling of latency and reliability, system uncertainty, and performance and cost trade-off, we employ service request duplication to ensure both latency and reliability performance at the service level. We propose an online learning-based service request duplication algorithm based on a multi-armed bandit framework and Lyapunov optimization theory. The proposed algorithm achieves an upper-bounded regret compared to the oracle algorithm. Simulations are based on real-world datasets and the results demonstrate that the proposed algorithm outperforms the benchmarks.},
  archive      = {J_TMC},
  author       = {Qing Li and Xiao Ma and Ao Zhou and Changhee Joo and Shangguang Wang},
  doi          = {10.1109/TMC.2022.3148170},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4168-4180},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online service request duplicating for vehicular applications},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online optimal service selection, resource allocation and
task offloading for multi-access edge computing: A utility-based
approach. <em>TMC</em>, <em>22</em>(7), 4150–4167. (<a
href="https://doi.org/10.1109/TMC.2022.3152493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-access edge computing promises satisfactory user experience by offloading tasks to the MEC server deployed at the network edge. However, since the MEC server is often resource-limited as compared to the cloud infrastructure, how to efficiently utilize its resources for system performance optimization becomes a challenge. In this paper, we study this problem with the aim at maximizing user&#39;s QoE through jointly optimizing service selection, computation resource allocation and task offloading decision, which is less studied in existing literature. We formulate a mixed-integer nonlinear programming problem (MINLP) for the task and propose a utility-based approach together with a low-complexity resource-efficiency based heuristic to address the problem. We consider realistic settings, where centralized solutions may not apply and an optimal mechanism needs to adapt as system operates. A distributed algorithm based on the Lagrangian-dual based decomposition theory is proposed, and we prove all sub-problems derived can be efficiently solved. In line with the current VM technology, we develop a cost-aware online algorithm that explicitly incorporates the cost of service switches into service selection and resource allocation. We evaluate our mechanism through both synthetic and trace-driven simulations, and results indicate they are effective as compared to representative baseline algorithms.},
  archive      = {J_TMC},
  author       = {Weibo Chu and Peijie Yu and Zhiwen Yu and John C.S. Lui and Yi Lin},
  doi          = {10.1109/TMC.2022.3152493},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4150-4167},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online optimal service selection, resource allocation and task offloading for multi-access edge computing: A utility-based approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the performance analysis of epidemic routing in
non-sparse delay tolerant networks. <em>TMC</em>, <em>22</em>(7),
4134–4149. (<a href="https://doi.org/10.1109/TMC.2022.3144683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the behavior of epidemic routing in a delay tolerant network as a function of node density. Focusing on the probability of successful delivery to a destination within a deadline (PS), we show that PS experiences a phase transition as node density increases. Specifically, we prove that PS exhibits a phase transition when nodes are placed according to a Poisson process and allowed to move according to independent and identical processes with limited speed. We then propose four fluid approximations to evaluate the performance of epidemic routing in non-sparse networks. An ordinary differential equation (ODE) is proposed for supercritical networks based on approximation of the infection rate as a function of time. Other ODEs are based on the approximation of the pairwise infection rate . Two of them, one for subcritical networks and another for supercritical networks, use the pairwise infection rate as a function of the number of infected nodes. The other ODE uses pairwise infection rate as a function of time, and can be applied for both subcritical and supercritical networks achieving good accuracy. The ODE for subcritical networks is accurate when density is not close to the percolation critical density. Moreover, the ODEs that target only supercritical regime are accurate.},
  archive      = {J_TMC},
  author       = {Leila Rashidi and Don Towsley and Arman Mohseni-Kabir and Ali Movaghar},
  doi          = {10.1109/TMC.2022.3144683},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4134-4149},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the performance analysis of epidemic routing in non-sparse delay tolerant networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the improvement of cellular coverage maps by filtering
MDT measurements. <em>TMC</em>, <em>22</em>(7), 4119–4133. (<a
href="https://doi.org/10.1109/TMC.2022.3142740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular networks are constantly evolving, driven by changes in user behavior and device capabilities. To ensure that networks adapt to these changes, it is of vital importance for mobile operators to have a good understanding of how well their network meets subscriber needs. For this purpose, the Minimization of Drive Test (MDT) feature has been standardized, allowing operators the cost-effective provision of geolocated network performance statistics and radio events. However, in practice, positioning errors severely limit the potential of MDT measurements. In this paper, an in-depth analysis of a large MDT dataset taken from a commercial Long-Term Evolution (LTE) network shows for the first time several sources of positioning errors in MDT measurements not previously reported in the literature. To address these, a novel heuristic filtering algorithm is proposed to discard samples with inaccurate location data. Method assessment is done by checking the impact of filtering on the coverage map built with a real MDT dataset. Results show that the proposed filtering method significantly improves the accuracy of coverage maps by eliminating unreliable measurements.},
  archive      = {J_TMC},
  author       = {Joaquín M. Sánchez-Martín and Matías Toril and Volker Wille and Carolina Gijón and Mariano Fernández-Navarro},
  doi          = {10.1109/TMC.2022.3142740},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4119-4133},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the improvement of cellular coverage maps by filtering MDT measurements},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the impact of recharging behavior on mobility.
<em>TMC</em>, <em>22</em>(7), 4103–4118. (<a
href="https://doi.org/10.1109/TMC.2022.3141930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the behavior of mobile users that, upon depletion of their device&#39;s energy due to communication, can detour from their regular path, in order to reach a location where the device can be recharged. We develop abstractions of this recharging behavior and analytically derive a charging-aware mobility model. The device is viewed as a mobile node. Based on the Palm inversion formula, we derive the (integral-form) stationary probability density function of the node&#39;s location, subject to attraction exerted by one charger in a bounded convex area. The analytical and numerical results demonstrate the distortion effect the charger has on the spatial node distribution. We observe, and explain, a counter-intuitive effect whereby the node density exhibits peaks that are asymmetric, coupled with a relative decrease of the density around the charger area. In addition, we provide a method to approximate the probability density function when multiple chargers are deployed. We examine the accuracy of this approximation and comment on its limitations.},
  archive      = {J_TMC},
  author       = {Wanxin Gao and Ioanis Nikolaidis and Janelle J. Harms},
  doi          = {10.1109/TMC.2022.3141930},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4103-4118},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the impact of recharging behavior on mobility},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonlinear online incentive mechanism design in edge
computing systems with energy budget. <em>TMC</em>, <em>22</em>(7),
4086–4102. (<a href="https://doi.org/10.1109/TMC.2022.3148034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider task offloading in edge computing systems, where tasks are offloaded by the base station to resourceful mobile users. With the consideration of unique characteristics in practical edge computing systems, such as dynamic arrival of computation tasks, and energy constraints at battery-powered mobile users, we formulate an incentive mechanism design problem by jointly optimizing task offloading decisions, and allocation of both communications (i.e., power and bandwidth), and computation resources. In order to tackle the nonlinear issue in the designed mechanism, a novel online incentive mechanism is proposed. We first convert the original mechanism design problem into several one-shot design problems by temporally removing the energy constraint. Then, we propose a new mechanism design framework, called the Integrate Rounding Scheme based Maxima-in-distributional Range (IRSM), and based on that, design a new incentive mechanism for each one-shot problem. Finally, we reconsider energy constraints to design a new nonlinear online incentive mechanism by rationally combining the previously derived one-shot ones. Theoretical analyses show that our proposed nonlinear online incentive mechanism can guarantee individual rationality, truthfulness, a sound competitive ratio, and computational efficiency. We further conduct comprehensive simulations to validate the effectiveness and superiority of our proposed mechanism.},
  archive      = {J_TMC},
  author       = {Gang Li and Jun Cai and Xianfu Chen and Zhou Su},
  doi          = {10.1109/TMC.2022.3148034},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4086-4102},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Nonlinear online incentive mechanism design in edge computing systems with energy budget},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Near-optimal and collaborative service caching in mobile
edge clouds. <em>TMC</em>, <em>22</em>(7), 4070–4085. (<a
href="https://doi.org/10.1109/TMC.2022.3144175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of 5G technology, mobile edge computing is emerging as an enabling technique to reduce the response latency of network services by deploying cloudlets at 5G base stations to form mobile edge cloud (MEC) networks. Network service providers now shift their services from remote clouds to cloudlets of MEC networks in the proximity of users. However, the permanent placement of network services into an MEC network is not economic due to limited computing and bandwidth resources imposed on its cloudlets. A smart way is to cache frequently demanded services from remote clouds to cloudlets of the MEC network. In this paper, we study the problem of service caching in an MEC network under a service market with multiple network service providers competing for both computation and bandwidth resources in terms of Virtual Machines (VMs) in the MEC network. We first propose an Integer Linear Program (ILP) solution and a randomized rounding algorithm, for the problem without VM sharing among different network service providers. We then devise a distributed and stable game-theoretical mechanism for the problem with VM sharing among network service providers, with the aim to minimize the social cost of all network service providers, through introducing a novel cost sharing model and a coalition formation game. We also analyze the performance guarantee of the proposed mechanism, Strong Price of Anarchy (SPoA). We third consider the cost- and delay-sensitive service caching problem with temporal VM sharing, and propose a mechanism with provable SPoA. We finally evaluate the performance through extensive simulations and a real world test-bed implementation. Experimental results demonstrate that the proposed algorithms outperform existing approaches by achieving at least &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$40\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; lower social cost via service caching and resource sharing among different network service providers.},
  archive      = {J_TMC},
  author       = {Zichuan Xu and Lizhen Zhou and Sid Chi-Kin Chau and Weifa Liang and Haipeng Dai and Lixing Chen and Wenzheng Xu and Qiufen Xia and Pan Zhou},
  doi          = {10.1109/TMC.2022.3144175},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4070-4085},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Near-optimal and collaborative service caching in mobile edge clouds},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-UAV navigation for partially observable communication
coverage by graph reinforcement learning. <em>TMC</em>, <em>22</em>(7),
4056–4069. (<a href="https://doi.org/10.1109/TMC.2022.3146881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we aim to design a deep reinforcement learning (DRL) based control solution to navigating a swarm of unmanned aerial vehicles (UAVs) to fly around an unexplored target area under partial observation, which serves as Mobile Base Stations (MBSs) providing optimal communication coverage for the ground mobile users. To handle the information loss caused by the partial observability, we introduce a novel network architecture named Deep Recurrent Graph Network (DRGN), which could obtain extra spatial information through graph-convolution based inter-UAV communication, and utilize historical features with a recurrent unit. Based on DRGN and maximum-entropy learning, we propose a stochastic DRL policy named Soft Deep Recurrent Graph Network (SDRGN). In SDRGN, a heuristic reward function is elaborated, which is based on the local information of each UAV instead of the global information; thus, SDRGN reduces the training cost and enables distributed online learning. We conducted extensive experiments to design the structure of DRGN and examine the performance of SDRGN. The simulation results show that the proposed model outperforms four state-of-the-art DRL-based approaches and three heuristic baselines, and demonstrate the scalability, transferability, robustness, and interpretability of SDRGN.},
  archive      = {J_TMC},
  author       = {Zhenhui Ye and Ke Wang and Yining Chen and Xiaohong Jiang and Guanghua Song},
  doi          = {10.1109/TMC.2022.3146881},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4056-4069},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-UAV navigation for partially observable communication coverage by graph reinforcement learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modifiable areal unit problem on grided mobile crowd
sensing: Analysis and restoration. <em>TMC</em>, <em>22</em>(7),
4044–4055. (<a href="https://doi.org/10.1109/TMC.2022.3147474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregating crowd density in grids from big mobile datasets is a basic but critical work in urban computing and mobile computing. The error of position estimation in raw mobile data, including spatial deviation and temporal deviation, is inevitable and directly impacts the accuracy of aggregated crowd density results. In this case, a key modifiable areal unit problem is raised to understand the relationship among the crowd density accuracy, raw mobile data error, grid shape, and size, but few studies focused on it. This paper analyzes this modifiable areal unit problem of the error in crowd density estimation from big mobility data. By regarding the error as the result of a convolution operation, an optimization model based restoration method was proposed to fix the error of the estimated result, and we analyzed the restoration effect under different circumstances by several simulation experiments. A real application for grided population distribution map construction and restoration from Call Detail Record was conducted to prove the reliability of the whole analysis, which demonstrates the restoration method can reduce the error by nearly 40% under certain conditions.},
  archive      = {J_TMC},
  author       = {Yuhao Yao and Haoran Zhang and Defan Feng and Jinyu Chen and Wenjing Li and Ryosuke Shibasaki and Xuan Song},
  doi          = {10.1109/TMC.2022.3147474},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4044-4055},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Modifiable areal unit problem on grided mobile crowd sensing: Analysis and restoration},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Membership inference attack and defense for wireless signal
classifiers with deep learning. <em>TMC</em>, <em>22</em>(7), 4032–4043.
(<a href="https://doi.org/10.1109/TMC.2022.3148690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An over-the-air membership inference attack (MIA) is presented to leak private information from a wireless signal classifier. Machine learning (ML) provides powerful means to classify wireless signals, e.g., for PHY-layer authentication. As an adversarial machine learning attack, the MIA infers whether a signal of interest has been used in the training data of a target classifier. This private information incorporates waveform, channel, and device characteristics, and if leaked, can be exploited by an adversary to identify vulnerabilities of the underlying ML model (e.g., to infiltrate the PHY-layer authentication). One challenge for the over-the-air MIA is that the received signals and consequently the RF fingerprints at the adversary and the intended receiver differ due to the discrepancy in channel conditions. Therefore, the adversary first builds a surrogate classifier by observing the spectrum and then launches the black-box MIA on this classifier. The MIA results (based on both simulations and over-the-air software-defined radio (SDR) experiments) show that the adversary can reliably infer signals (and potentially the radio and channel information) used to build the target classifier. Therefore, a proactive defense is developed against the MIA by building a shadow MIA model and fooling the adversary. This defense can successfully reduce the MIA accuracy and prevent information leakage from the wireless signal classifier. Moreover, this defense does not reduce the accuracy of signal classification.},
  archive      = {J_TMC},
  author       = {Yi Shi and Yalin E. Sagduyu},
  doi          = {10.1109/TMC.2022.3148690},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4032-4043},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Membership inference attack and defense for wireless signal classifiers with deep learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). JoLo: Multi-device joint localization based on wireless data
fusion. <em>TMC</em>, <em>22</em>(7), 4016–4031. (<a
href="https://doi.org/10.1109/TMC.2022.3150758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many indoor localization techniques have been widely investigated. As the proportion of people with multiple mobile devices is increasing, an interesting research challenge arising from this growth is how to integrate data from multiple devices carried by a mobile user for localizing her/him. This work designs a multi-device joint localization system, called JoLo , to realize the idea using a group of off-the-shelf mobile devices carried by a user. The proposed system collects wireless fingerprints at the predefined training locations in the environment. Then, the system fuses the real-time wireless measurements observed by the multiple devices of a user into a summary list for localization reference. Finally, three fusion-based positioning algorithms are proposed to determine the user&#39;s location based on the fused summary list. The three proposed algorithms reduce mean distance errors in localization to less than one meter in a lab environment. One of the fusion-based algorithms, namely cluster-based DF algorithm, can even improve the performance by 50% on average compared to the existing single-device localization techniques.},
  archive      = {J_TMC},
  author       = {Sok-Ian Sou and Fang-Jing Wu and Wen-Chun Wu},
  doi          = {10.1109/TMC.2022.3150758},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4016-4031},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {JoLo: Multi-device joint localization based on wireless data fusion},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint task offloading and resource allocation for
energy-constrained mobile edge computing. <em>TMC</em>, <em>22</em>(7),
4000–4015. (<a href="https://doi.org/10.1109/TMC.2022.3150432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of task offloading and resource allocation in mobile edge computing (MEC). To maintain satisfactory quality of experience (QoE) of end-users, mobile devices (MDs) may offload their tasks to edge servers based on the allocated computation (e.g., CPU/GPU cycles and storage) and wireless resources (e.g., bandwidth). However, these resources could not be effectively utilized unless an encouraging resource allocation scheme can be proposed. What’s worse, task offloading incurs additional MEC energy consumption, which inevitably violate the long-term MEC energy budget. Considering these two challenges, we propose an online joint offloading and resource allocation (JORA) framework under the long-term MEC energy constraint, aiming at guaranteeing the end-users’ QoE. To achieve this, we leverage Lyapunov optimization to exploit the optimality of the long-term QoE maximization problem. By constructing an energy deficit queue to guide energy consumption, the problem can be solved in a real-time manner. On this basis, we propose online JORA methods in both centralized and distributed manners. Furthermore, we prove that our proposed methods enable the achievement of the close-to-optimal performance while satisfying the long-term MEC energy constraint. In addition, we conduct extensive simulations and the results show superiority in performance over other methods.},
  archive      = {J_TMC},
  author       = {Hongbo Jiang and Xingxia Dai and Zhu Xiao and Arun Iyengar},
  doi          = {10.1109/TMC.2022.3150432},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {4000-4015},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint task offloading and resource allocation for energy-constrained mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint scheduling of participants, local iterations, and
radio resources for fair federated learning over mobile edge networks.
<em>TMC</em>, <em>22</em>(7), 3985–3999. (<a
href="https://doi.org/10.1109/TMC.2022.3148208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) provides a promising way to train a machine learning model among mobile devices without collecting their raw data to a central node. During training, proper devices are selected to participate in the training process to avoid model unfairness. In a mobile edge network, participant selection must be considered together with three factors: non-iid datasets possessed by devices, tunable local iterations on devices, and radio resource allocation to counter the impact of time-varying channel conditions on parameter transmissions. Since datasets of devices are given, to ensure model fairness and achieve fast convergence in the FL training process, participants, local iterations, and radio resources must be scheduled jointly in each iteration of FL training. In this paper, the joint scheduling problem is analyzed and formulated. Since it is NP-hard, a heuristic scheduling method called PALORA is designed to conduct joint scheduling of participants, local iterations, and radio resources. PALORA consists of three sequentially interactive function blocks: 1) a pointer network embedded deep reinforcement learning method to select participants, 2) an estimation algorithm to determine the numbers of local iterations, and 3) a breadth-first search method to allocate radio resources to the selected participants. PALORA is evaluated via extensive simulations based on real-world datasets. Results show that it significantly outperforms benchmark approaches.},
  archive      = {J_TMC},
  author       = {Jiawei Zhang and Suhong Chen and Xiaochen Zhou and Xudong Wang and Yi-Bing Lin},
  doi          = {10.1109/TMC.2022.3148208},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3985-3999},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint scheduling of participants, local iterations, and radio resources for fair federated learning over mobile edge networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable AI-based large-scale 3D pathloss prediction
model for enabling emerging self-driving networks. <em>TMC</em>,
<em>22</em>(7), 3967–3984. (<a
href="https://doi.org/10.1109/TMC.2022.3147191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern wireless communication systems, radio propagation modeling to estimate pathloss has always been a fundamental task in system design and optimization. The state-of-the-art empirical propagation models are based on measurements in specific environments and limited in their ability to capture idiosyncrasies of various propagation environments. To cope with this problem, ray-tracing based solutions are used in commercial planning tools, but they tend to be extremely time-consuming and expensive. We propose a Machine Learning (ML)-based model that leverages novel key predictors for estimating pathloss. By quantitatively evaluating the ability of various ML algorithms in terms of predictive, generalization and computational performance, our results show that Light Gradient Boosting Machine (LightGBM) algorithm overall outperforms others, even with sparse training data, by providing a 65% increase in prediction accuracy as compared to empirical models and 13x decrease in prediction time as compared to ray-tracing. To address the interpretability challenge that thwarts the adoption of most Machine Learning (ML)-based models, we perform extensive secondary analysis using SHapley Additive exPlanations (SHAP) method, yielding many practically useful insights that can be leveraged for intelligently tuning the network configuration, selective enrichment of training data in real networks and for building lighter ML-based propagation model to enable low-latency use-cases.},
  archive      = {J_TMC},
  author       = {Usama Masood and Hasan Farooq and Ali Imran and Adnan Abu-Dayya},
  doi          = {10.1109/TMC.2022.3147191},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3967-3984},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Interpretable AI-based large-scale 3D pathloss prediction model for enabling emerging self-driving networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Indoor localization system with NLOS mitigation based on
self-training. <em>TMC</em>, <em>22</em>(7), 3952–3966. (<a
href="https://doi.org/10.1109/TMC.2022.3148338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-awareness has become a fundamental requirement for multiple emerging applications with the rapid development of wireless technologies. The high-accuracy ranging enabled by ultra-wide bandwidth (UWB) signals is often deteriorated by clocks imperfections and non-line-of-sight (NLOS) propagation. Existing supervised learning methods for NLOS identification and mitigation are time-consuming, labor-intensive, and cost-inefficient due to the need for training data acquisition and label assignment. This paper presents an indoor localization system that enables NLOS mitigation based on self-training. The system provides a general information fusion framework that integrates map, inertial sensors, and UWB measurements, where the weak labels for UWB measurements are produced and iteratively refined by multi-sensory information fusion for self-training. In addition, the system utilizes the maximum likelihood ranging estimator that considers the impact of clock drift. The effectiveness of the proposed system is demonstrated via extensive experimentation in multiple real-world environments, e.g., the proposed methods reduce the NLOS ranging error by 80% and result in a 90th localization error percentile of 0.5 meters in a complex indoor environment.},
  archive      = {J_TMC},
  author       = {Yanru Huang and Santiago Mazuelas and Feng Ge and Yuan Shen},
  doi          = {10.1109/TMC.2022.3148338},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3952-3966},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Indoor localization system with NLOS mitigation based on self-training},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Handwriting recognition system leveraging vibration signal
on smartphones. <em>TMC</em>, <em>22</em>(7), 3940–3951. (<a
href="https://doi.org/10.1109/TMC.2022.3148172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency of human-computer interaction is greatly hindered by the small size of the touch screens on mobile devices, such as smart phones and watches. This has prompted widespread interest in handwriting recognition systems, which can be divided into active and passive systems. Active systems require additional hardware devices to perceive movements of handwriting or the tracking accuracy is not adequate for handwriting recognition. Passive methods use the acoustic signal of pen rubbing and are susceptible to environmental noise (above 60 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$dB$&lt;/tex-math&gt;&lt;/inline-formula&gt; ). This paper presents a novel handwriting recognition system based on vibration signals detected by the built-in accelerometer of smartphones. The proposed scheme is implemented in three stages: signal segmentation, signal recognition, and word suggestion. VibWriter is highly resistant to interferences since the normal environmental noise (below 70 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$dB$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) will not cause the vibration of the accelerometer. Extensive experiments demonstrated the efficacy of the system in terms of accuracy in letter recognition (75.3%), word recognition (86.4%) and number recognition (79%) in a variety of writing positions under a variety of environmental conditions.},
  archive      = {J_TMC},
  author       = {Dian Ding and Lanqing Yang and Yi-Chao Chen and Guangtao Xue},
  doi          = {10.1109/TMC.2022.3148172},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3940-3951},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Handwriting recognition system leveraging vibration signal on smartphones},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FDOE: Exploit concurrent communication opportunities in
full-duplex wireless mesh networks. <em>TMC</em>, <em>22</em>(7),
3925–3939. (<a href="https://doi.org/10.1109/TMC.2022.3144128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, full-duplex communications in a single frequency channel have become a practical technology. However, existing full-duplex medium access control (MAC) protocols can hardly take full advantages of full-duplex transmission opportunities, because they are not capable of adding one more half-duplex link on an on-going half-duplex link to form a full-duplex link. Besides, the exposed-node issue in multi-hop wireless networks limits flexible establishment of full-duplex links. Such limitations waste full-duplex transmission opportunities, and thus degrade network performance. In this paper, an efficient full-duplex link establishment protocol called full-duplex opportunity exploitation (FDOE) is developed to exploit full-duplex transmission opportunities in a wireless mesh network. FDOE leverages rateless coding and pseudo-noise (PN) sequences to establish a full-duplex link whenever a full-duplex transmission opportunity is available. Such a distinct feature leads to significant improvement of network performance. FDOE is evaluated through theoretical analysis and extensive simulations. Performance results show that FDOE exploits full-duplex transmission opportunities efficiently in wireless mesh networks, and thus significantly outperforms existing MAC protocols.},
  archive      = {J_TMC},
  author       = {Mengxin Yu and Aimin Tang and Xudong Wang and Jinnan Liu},
  doi          = {10.1109/TMC.2022.3144128},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3925-3939},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FDOE: Exploit concurrent communication opportunities in full-duplex wireless mesh networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enabling long-term cooperation in cross-silo federated
learning: A repeated game perspective. <em>TMC</em>, <em>22</em>(7),
3910–3924. (<a href="https://doi.org/10.1109/TMC.2022.3148263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-silo federated learning (FL) is a distributed learning approach where clients of the same interest train a global model cooperatively while keeping their local data private. The success of a cross-silo FL process requires active participation of many clients. Different from cross-device FL, clients in cross-silo FL are usually organizations or companies which may execute multiple cross-silo FL processes repeatedly due to their time-varying local data sets, and aim to optimize their long-term benefits by selfishly choosing their participation levels. While there has been some work on incentivizing clients to join FL, the analysis of clients’ long-term selfish participation behaviors in cross-silo FL remains largely unexplored. In this paper, we analyze the selfish participation behaviors of heterogeneous clients in cross-silo FL. Specifically, we model clients’ long-term selfish participation behaviors as an infinitely repeated game, with the stage game being a selfish participation game in one cross-silo FL process (SPFL). For the stage game SPFL, we derive the unique Nash equilibrium (NE), and propose a distributed algorithm for each client to calculate its equilibrium participation strategy. We show that at the NE, clients fall into at most three categories: (i) free riders who do not perform local model training, (ii) a unique partial contributor (if exists) who performs model training with part of its local data, and (iii) contributors who perform model training with all their local data. The existence of free riders has a detrimental effect on achieving a good global model and sustaining other clients’ long-term participation. For the long-term interactions among clients, we derive a cooperative strategy for clients which minimizes the number of free riders while increasing the amount of local data for model training. We show that enforced by a punishment strategy, such a cooperative strategy is a subgame perfect Nash equilibrium (SPNE) of the infinitely repeated game, under which some clients who are free riders at the NE of the stage game choose to be (partial) contributors. We further propose an algorithm to calculate the optimal SPNE which minimizes the number of free riders while maximizing the amount of local data for model training. Simulation results show that our derived optimal SPNE can effectively reduce the number of free riders by up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$99.3\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; and increase the amount of local data for model training by up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$82.3\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Ning Zhang and Qian Ma and Xu Chen},
  doi          = {10.1109/TMC.2022.3148263},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3910-3924},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enabling long-term cooperation in cross-silo federated learning: A repeated game perspective},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EAR: An edge-assisted and energy-efficient mobile augmented
reality framework. <em>TMC</em>, <em>22</em>(7), 3898–3909. (<a
href="https://doi.org/10.1109/TMC.2022.3144879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Augmented Reality (MAR) apps may cause short battery life due to high-quality virtual objects rendered in the augmented environment. State-of-the-art solutions propose to balance energy consumption and user-experience using a static set of decimated object versions within the app. However, they do not consider that each object has unique characteristics, which highly influence how the user-perceived quality changes according to user-object distance and triangle count. As a result, they may lead to limited energy savings, a high storage overhead, and a high burden on the MAR app developer. In this paper, we propose eAR, an edge-assisted autonomous and energy-efficient framework for MAR apps designed to solve the limitations of state-of-the-art solutions. eAR features an offline software running on an edge server that leverages Image Quality Assessment (IQA) to model user-perceived quality for each virtual object in terms of triangle count and user-object distance. In addition, eAR features a runtime lightweight optimization algorithm that dynamically decides the most energy-efficient virtual object triangle count to request from the edge server based on (i) the per-object models of user-perceived quality, (ii) energy consumption models for mobile GPU and network interface, and (iii) a user path prediction system that estimates near-future user-object distances. eAR is completely autonomous and can be easily integrated into most MAR apps as an open-source library. Our results show that eAR can help reduce energy consumption by up to 16.5% while reducing storage overhead by almost 60% compared to existing schemes, with minimal MAR app developer effort and minimal impact on user-perceived quality.},
  archive      = {J_TMC},
  author       = {Niloofar Didar and Marco Brocanelli},
  doi          = {10.1109/TMC.2022.3144879},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3898-3909},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EAR: An edge-assisted and energy-efficient mobile augmented reality framework},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DRL-based V2V computation offloading for blockchain-enabled
vehicular networks. <em>TMC</em>, <em>22</em>(7), 3882–3897. (<a
href="https://doi.org/10.1109/TMC.2022.3153346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular edge computing (VEC) is an effective method to increase the computing capability of vehicles, where vehicles share their idle computing resources with each other. However, due to the high mobility of vehicles, it is challenging to design an optimal task allocation policy that adapts to the dynamic vehicular environment. Further, vehicular computation offloading often occurs between unfamiliar vehicles, how to motivate vehicles to share their computing resources while guaranteeing the reliability of resource allocation in task offloading is one main challenge. In this paper, we propose a blockchain-enabled VEC framework to ensure the reliability and efficiency of vehicle-to-vehicle (V2V) task offloading. Specifically, we develop a deep reinforcement learning (DRL)-based computation offloading scheme for the smart contract of blockchain, where task vehicles can offload part of computation-intensive tasks to neighboring vehicles. To ensure the security and reliability in task offloading, we evaluate the reliability of vehicles in resource allocation by blockchain. Moreover, we propose an enhanced consensus algorithm based on practical Byzantine fault tolerance (PBFT), and design a consensus nodes selection algorithm to improve the efficiency of consensus and motivate base stations to improve reliability in task allocation. Simulation results validate the effectiveness of our proposed scheme for blockchain-enabled VEC.},
  archive      = {J_TMC},
  author       = {Jinming Shi and Jun Du and Yuan Shen and Jian Wang and Jian Yuan and Zhu Han},
  doi          = {10.1109/TMC.2022.3153346},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3882-3897},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DRL-based V2V computation offloading for blockchain-enabled vehicular networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep reinforcement learning based approach for online
service placement and computation resource allocation in edge computing.
<em>TMC</em>, <em>22</em>(7), 3870–3881. (<a
href="https://doi.org/10.1109/TMC.2022.3148254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the urgent emergence of computation-intensive intelligent applications on end devices, edge computing has been put forward as an extension of cloud computing, to satisfy the low-latency requirements of these applications. To process heterogenous computation tasks on an edge node, the corresponding services should be placed in advance, including installing softwares and caching databases/libraries. Considering the limited storage space and computation resources on the edge node, services should be elaborately selected and deployed on the edge node and its computation resources should be carefully allocated to placed services, according to the arrivals of computation workloads. The joint service placement and computation resource allocation problem is particularly complicated, in terms of considering the stochastic arrivals of tasks, the additional latency incurred by service migration, and the waiting time of unprocessed tasks. Benefiting from deep reinforcement learning, we propose a novel approach based on parameterized deep Q networks to make the joint service placement and computation resource allocation decisions, with the objective of minimizing the total latency of tasks in a long term. Extensive simulations are conducted to evaluate the convergence and performance achieved by our proposed approach.},
  archive      = {J_TMC},
  author       = {Tong Liu and Shenggang Ni and Xiaoqiang Li and Yanmin Zhu and Linghe Kong and Yuanyuan Yang},
  doi          = {10.1109/TMC.2022.3148254},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3870-3881},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Deep reinforcement learning based approach for online service placement and computation resource allocation in edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative virtual 3D object modeling for mobile
augmented reality streaming services over 5G networks. <em>TMC</em>,
<em>22</em>(7), 3855–3869. (<a
href="https://doi.org/10.1109/TMC.2022.3149543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a collaborative virtual 3D object modeling system for mobile augmented reality (AR) streaming services over 5G networks. The objective of the proposed system is to provide AR streaming services with low latency and high virtual object quality by effectively leveraging mobile edge cloud (MEC) and device-to-device (D2D) communication. MEC is utilized to perform computation-intensive 3D object modeling, such as virtual object slicing and mesh simplification, with abundant computing and storage resources. D2D communication is also utilized to reduce transmission delay by sharing virtual objects of interest among adjacent users. To achieve this goal, we propose a part-segment quality selection algorithm that can control the quality of each part segment and the transmission source by considering the user&#39;s network condition. In the proposed system, all elements in the AR cloud, MEC, and mobile device are technically integrated to work together seamlessly. Finally, the proposed system is fully implemented using well-known open-source frameworks, including WebGL and AR.js. The system was then examined in real wireless network environments. The experimental results demonstrate the performance of the proposed system. The proposed system outperforms conventional systems in terms of service latency and visual 3D object quality.},
  archive      = {J_TMC},
  author       = {Gi Seok Park and Ryeong Hwan Kim and Hwangjun Song},
  doi          = {10.1109/TMC.2022.3149543},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3855-3869},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collaborative virtual 3D object modeling for mobile augmented reality streaming services over 5G networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CEC: A containerized edge computing framework for dynamic
resource provisioning. <em>TMC</em>, <em>22</em>(7), 3840–3854. (<a
href="https://doi.org/10.1109/TMC.2022.3147800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Container has been widely used in application development and management systems. However, there are two major challenges faced in the real deployment at edge servers. The varying workload of service requests and the startup delay of containers force a flexible resource provisioning scheme in containerized edge computing. To this end, we propose CEC , a containerized edge computing framework for dynamic resource provisioning, and especially for the smart connected community where exists multiple intelligent applications. CEC integrates workload prediction and resource pre-provisioning to enable low latency of user service requests and high utilization of edge resources. First, we present an online periodic request prediction algorithm. Then, we designed a control-based resource pre-provisioning algorithm based on the predicted request distribution, which is a self-adaptive controller to tune the resource for containers. We evaluate the performance of CEC by simulation and system experiments. The simulation experiment shows that the prediction accuracy of the proposed algorithm is higher than other two prediction algorithms. The testbed experiments demonstrate that the control-based resource pre-provisioning algorithm has low service latency and high resource utilization compared with baselines.},
  archive      = {J_TMC},
  author       = {Shihong Hu and Weisong Shi and Guanghui Li},
  doi          = {10.1109/TMC.2022.3147800},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3840-3854},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CEC: A containerized edge computing framework for dynamic resource provisioning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient heterogeneous edge-cloud learning framework for
spectrum data compression. <em>TMC</em>, <em>22</em>(7), 3823–3839. (<a
href="https://doi.org/10.1109/TMC.2022.3153049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrum data compression with a high-rate compression and accurate reconstruction is of crucial importance for reducing the ultra-large data transmission from the edge sensors to the cloud for establishing high-quality spectrum maps. However, the current methods ignore the imbalanced edge-cloud computation resources and cannot tackle the outlier signals, resulting in significant challenges for achieving effective compression. Therefore, we develop an efficient heterogeneous edge-cloud learning framework. In the framework, paralleled methods compress normal data and outlier data distinctively based on their different structure information. Meanwhile, those methods are asymmetric for achieving low-cost compression at the edge and accurate reconstruction on the cloud. Based on the framework, we propose an outlier-processable attention-based asymmetric compression algorithm. A novel attention-based asymmetric convolutional neural network performs the normal data compression while a non-linear outlier compression algorithm realizes the outlier data compression. Compared with the state-of-the-art schemes in real-world settings, our proposed framework’s convergence speed increases by 120% . Meanwhile, our framework’s reconstruction accuracy increases by 68.42% under the interfered environments while maintaining superior compression speed and comprehensive performance. We also confirm our framework’s generalization ability to transfer among different tasks by deploying it under various spectrum environments.},
  archive      = {J_TMC},
  author       = {Guangyu Wu and Fuhui Zhou and Guoru Ding and Qihui Wu and Xiang-Yang Li},
  doi          = {10.1109/TMC.2022.3153049},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3823-3839},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An efficient heterogeneous edge-cloud learning framework for spectrum data compression},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Accelerating federated learning with cluster construction
and hierarchical aggregation. <em>TMC</em>, <em>22</em>(7), 3805–3822.
(<a href="https://doi.org/10.1109/TMC.2022.3147792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has emerged in edge computing to address the limited bandwidth and privacy concerns of traditional cloud-based training. However, the existing FL mechanisms may lead to a long training time and consume massive communication resources. In this paper, we propose an efficient FL mechanism, namely FedCH, to accelerate FL in heterogeneous edge computing. Different from existing works which adopt the pre-defined system architecture and train models in a synchronous or asynchronous manner, FedCH will construct a special cluster topology and perform hierarchical aggregation for training. Specifically, FedCH arranges all clients into multiple clusters based on their heterogeneous training capacities. The clients in one cluster synchronously forward their local updates to the cluster header for aggregation, while all cluster headers take the asynchronous method for global aggregation. Our analysis shows that the convergence bound depends on the number of clusters and the training epochs. We propose efficient algorithms to determine the optimal number of clusters with resource budgets and then construct the cluster topology to address the client heterogeneity. Extensive experiments on both physical platform and simulated environment show that FedCH reduces the completion time by 49.5-79.5% and the network traffic by 57.4-80.8%, compared with the existing FL mechanisms.},
  archive      = {J_TMC},
  author       = {Zhiyuan Wang and Hongli Xu and Jianchun Liu and Yang Xu and He Huang and Yangming Zhao},
  doi          = {10.1109/TMC.2022.3147792},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3805-3822},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Accelerating federated learning with cluster construction and hierarchical aggregation},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A UAV-assisted multi-task allocation method for mobile crowd
sensing. <em>TMC</em>, <em>22</em>(7), 3790–3804. (<a
href="https://doi.org/10.1109/TMC.2022.3147871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowd sensing (MCS) with human participants has been proposed as an efficient way of collecting data for smart cities applications. However, there often exist situations where humans are not able or reluctant to reach the target areas, due to for example traffic jams or bad road conditions. One solution is to complement manual data collection with autonomous data collection using unmanned aerial vehicles (UAVs) equipped with various sensors. In this paper, we focus on the scenarios of UAV-assisted MCS and propose a task allocation method, called “UMA” ( U AV-assisted M ulti-task A llocation method) to optimize the sensing coverage and data quality. The method incentivizes human participants to contribute sensing data from nearby points of interest (PoIs), with a limited budget. Meanwhile, the method jointly considers the optimization of task assignment and trajectory scheduling. It schedules the trajectories of UAVs, considering the locations of human participants, other UAVs and PoIs which are rarely visited by human participants. In detail, UAVs take care of two tasks in our proposal. One is to calibrate the data collected by the human participants whom the UAVs come across along their trajectories. The other is to collect data from the PoIs which are not covered by other UAVs or human participants. We apply deep reinforcement learning to schedule UAVs moving trajectories and sensing activities in order to minimize the overall energy cost. We evaluate the proposed scheme via simulation using two real data sets. The results show that our proposal outperforms the compared methods, in terms of coverage completed ratio, calibrating ratio, energy efficiency, and task fairness.},
  archive      = {J_TMC},
  author       = {Hui Gao and Jianhao Feng and Yu Xiao and Bo Zhang and Wendong Wang},
  doi          = {10.1109/TMC.2022.3147871},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3790-3804},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A UAV-assisted multi-task allocation method for mobile crowd sensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A predictive frame transmission scheme for cloud gaming in
mobile edge cloudlet systems. <em>TMC</em>, <em>22</em>(7), 3774–3789.
(<a href="https://doi.org/10.1109/TMC.2022.3149056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud gaming is promising yet poses big challenges to wireless communications, due to its stringent requirements for low response delay and high reliability. In this paper, we propose a predictive frame transmission scheme (PFT) in cloud gaming, to predict and pre-transmit future game frames to users. The PFT scheme takes full advantage of good network states to transmit the predicted frames, which consequently reduces the frame loss rate (FLR) against the network dynamics. We first model a FLR minimization problem in the single-user system with the PFT scheme, which allocates packets to carry the predicted frames. The upper and lower bounds of FLR are derived, respectively. Then, we study the system with Markovian property, and derive the optimal packet allocation policy via Markov Decision Process. A near-optimal policy is also proposed with low-complexity. The PFT scheme is further extended to the multi-server multi-user scenario, in which the users are adaptively scheduled to multiple servers based on their different requirements. Finally, we extend the policy to fit the scenario without direct knowledge of the network state by exploiting the packet loss rate estimation. We set up a practical testbed to evaluate the proposed PFT scheme, showing the capability of decreasing the mean FLR from &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$7\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$1\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Tianchu Zhao and Sheng Zhou and Yuxuan Sun and Zhisheng Niu},
  doi          = {10.1109/TMC.2022.3149056},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3774-3789},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A predictive frame transmission scheme for cloud gaming in mobile edge cloudlet systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel visual indoor positioning method with efficient
image deblurring. <em>TMC</em>, <em>22</em>(7), 3757–3773. (<a
href="https://doi.org/10.1109/TMC.2022.3143502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to improve the accuracy of visual indoor positioning, an efficient deep multi-patch network based image deblurring algorithm (DMPID) is proposed to eliminate the effect of blurred images on the positioning accuracy. Meanwhile, the self-sorting visual word based image retrieval algorithm and the block based improved eight-point method are also proposed in this paper to improve the retrieval accuracy and positioning accuracy. The proposed image deblurring algorithm adopts the deep multi-patch network and the weight selective sharing scheme to acquire the deblurred images. Then, we propose the self-sorting visual word and add two additional elements representing the relative spatial information into every obtained feature point to utilize the intrinsic relationships between extracted features and physical positions in order to improve the retrieval accuracy. Meanwhile, the visual word filtering is also employed to eliminate redundant visual words and reduce the time consumption of image retrieval. Finally, the position estimation of query camera can be achieved by the epipolar constraint based on the improved eight-point method. Simulation results and performance analysis show that the proposed method can restore the image details effectively and improve the accuracy of visual indoor positioning.},
  archive      = {J_TMC},
  author       = {Shuang Jia and Lin Ma and Songxiang Yang and Danyang Qin},
  doi          = {10.1109/TMC.2022.3143502},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3757-3773},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A novel visual indoor positioning method with efficient image deblurring},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A MAC protocol design for maximizing end-to-end throughput
and fairness guarantee in chain-based multi-hop wireless backhaul
networks. <em>TMC</em>, <em>22</em>(7), 3743–3756. (<a
href="https://doi.org/10.1109/TMC.2022.3142027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chain-based multi-hop wireless backhaul networks (WBN) have attracted considerable attention in next-generation networks since they can cost-effectively extend the service coverage area. The major challenge pertaining to such networks is the designing of a high-performance medium access control (MAC) scheme to raise the end-to-end throughput and ensure fairness. In this paper, we propose a novel MAC protocol that is aimed at resolving the well-known location-dependent unfairness problem of chain-based networks, maximizing spatial reuse, and most importantly, achieving exceptional end-to-end throughput. Our scheme provides an elaborate control mini-slots design that resolves the different-relay-traffic-load problem of nodes at various positions near or far from the gateway and further provides local-traffic fairness among all nodes. Moreover, based on the traffic analysis, we provide a four-node group-transmission methodology. By using the neighbor-nodes echoes (broadcasts) the reservation-signals design, the chain-based WBN is allowed to extend to numerous nodes for concurrent and collision-free data transmission through distributed scheduling. Extensive simulation and analytic results also demonstrate that our proposed MAC scheme achieves exceptional system throughput which is approximately 1.6 times better than previous works for a four-node-chain network and also attains high system performance under a wide range of traffic loads and various system parameters.},
  archive      = {J_TMC},
  author       = {I-Fen Chao and Wei-Sheng Hsu},
  doi          = {10.1109/TMC.2022.3142027},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {3743-3756},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A MAC protocol design for maximizing end-to-end throughput and fairness guarantee in chain-based multi-hop wireless backhaul networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Single-target real-time passive WiFi tracking. <em>TMC</em>,
<em>22</em>(6), 3724–3742. (<a
href="https://doi.org/10.1109/TMC.2022.3141115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Device-free human tracking is an essential ingredient for ubiquitous wireless sensing. Recent passive WiFi tracking systems face the challenges of inaccurate separation of dynamic human components and time-consuming estimation of multi-dimensional signal parameters. In this work, we present a scheme named Wi Fi D oppler F requency S hift ( WiDFS ), which can achieve single-target real-time passive tracking using channel state information (CSI) collected from commercial-off-the-shelf (COTS) WiFi devices. We consider the typical system setup including a transmitter with a single antenna and a receiver with three antennas; while our scheme can be readily extended to another setup. To remove the impact of transceiver asynchronization, we first apply CSI cross-correlation between each RX antenna pair. We then combine them to estimate a Doppler frequency shift (DFS) in a short-time window. After that, we leverage the DFS estimate to separate dynamic human components from CSI self-correlation terms of each antenna, thereby separately calculating angle-of-arrival (AoA) and human reflection distance for tracking. In addition, a hardware calibration algorithm is presented to refine the spacing between RX antennas and eliminate the hardware-related phase differences between them. A prototype demonstrates that WiDFS can achieve real-time tracking with a median position error of 72.32 cm in multipath-rich environments.},
  archive      = {J_TMC},
  author       = {Zhongqin Wang and J. Andrew Zhang and Min Xu and Y. Jay Guo},
  doi          = {10.1109/TMC.2022.3141115},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3724-3742},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Single-target real-time passive WiFi tracking},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utility-aware legitimacy detection of mobile crowdsensing
tasks via knowledge-based self organizing feature map. <em>TMC</em>,
<em>22</em>(6), 3706–3723. (<a
href="https://doi.org/10.1109/TMC.2021.3136236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mobile Crowdsensing (MCS), fake tasks can drain significant amount of resources. This paper proposes a new methodology to determine a proper time window for the training dataset and the impact of the accuracy of task legitimacy detection on the MCS campaign performance. To reach the desired performance, the task legitimacy detection is utilized in such a way that while legitimate tasks are kept, the fake tasks are eliminated as much as possible in the MCS platform through machine learning (ML) prediction. The proposed methodology is evaluated for legitimacy detection under multiple ML methods. Moreover, a knowledge-based fake task detection technique with effective feature selection is formulated to ensure fake tasks are filtered at the MCS servers. Detection accuracy is improved by using shorter time frame in training and longer time frame in prediction. The overall performance improvement based on profit, cost, legitimate tasks loss ratio, and fake tasks elimination ratio has been achieved under three different sizes of training datasets to verify the efficiency of the proposed methodology. Moreover, Prior Knowledge Input with Self-Organizing Feature Map outperforms the conventional legitimacy detection by 5.48%, 12.11% and 58.05% in terms of test accuracy, profit and cost under the small dataset, respectively.},
  archive      = {J_TMC},
  author       = {Murat Simsek and Burak Kantarci and Azzedine Boukerche},
  doi          = {10.1109/TMC.2021.3136236},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3706-3723},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Utility-aware legitimacy detection of mobile crowdsensing tasks via knowledge-based self organizing feature map},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). User-oriented edge node grouping in mobile edge computing.
<em>TMC</em>, <em>22</em>(6), 3691–3705. (<a
href="https://doi.org/10.1109/TMC.2021.3139362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile edge computing networks, densely deployed access points are empowered with computation and storage capacities. This brings benefits of enlarged edge capacity, ultra-low latency, and reduced backhaul congestion. This paper concerns edge node grouping in mobile edge computing, where multiple edge nodes serve one end user cooperatively to enhance user experience. Most existing studies focus on centralized schemes that have to collect global information and thus induce high overhead. Although some recent studies propose efficient decentralized schemes, most of them did not consider the system uncertainty from both the wireless environment and other users. To tackle the aforementioned problems, we first formulate the edge node grouping problem as a game that is proved to be an exact potential game with a unique Nash equilibrium. Then, we propose a novel decentralized learning-based edge node grouping algorithm, which guides users to make decisions by learning from historical feedback. Furthermore, we investigate two extended scenarios by generalizing our computation model and communication model, respectively. We further prove that our algorithms converge to the Nash equilibrium with upper-bounded learning loss. Simulation results show that our mechanisms can achieve up to 96.99% of the oracle benchmark.},
  archive      = {J_TMC},
  author       = {Qing Li and Xiao Ma and Ao Zhou and Xiapu Luo and Fangchun Yang and Shangguang Wang},
  doi          = {10.1109/TMC.2021.3139362},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3691-3705},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {User-oriented edge node grouping in mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic-aware resource allocation for multi-user
beamforming. <em>TMC</em>, <em>22</em>(6), 3677–3690. (<a
href="https://doi.org/10.1109/TMC.2022.3141787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G New Radio (NR), a new radio access technology, has been proposed to enhance the flexibility, scalability, and efficiency of 5G networks. By leveraging phased-array antennas, a base station (BS) can adaptively form multiple directional beams to serve geo-distributed user equipments (UEs) concurrently. However, the imperfect beam pattern of a phased-array antenna may create side lobes, leading to inter-beam interference . While recent efforts have focused on beam selection that mitigates inter-beam interference and maximizes the sum-rate, we notice that the selected beams may not be fully utilized in an OFDMA-based system. The root cause is that only a fixed set of beams can be configured at a time to serve a wide frequency band but some resource blocks (i.e., subcarriers) may not be able to be allocated to any UEs due to limited traffic demands. To address the above resource underutilization problem, this paper presents traffic-aware joint beam configuration and resource allocation , which explicitly considers user traffic demands and configures beams that can optimally utilize the spectrum resources. We derive an approximation model that produces a suboptimal solution solvable by open-source solvers and further develop a low-complexity greedy algorithm for large-scale networks. Our simulation results show that the proposed traffic-aware allocation and beam configuration scheme achieves better utilization, especially when users have heterogeneous traffic demands. The overall effective throughput can be significantly enhanced as compared to conventional sum-rate maximization allocation.},
  archive      = {J_TMC},
  author       = {Yu-Hsuan Liu and Kate Ching-Ju Lin},
  doi          = {10.1109/TMC.2022.3141787},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3677-3690},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Traffic-aware resource allocation for multi-user beamforming},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic modeling of beam management in mmWave vehicular
networks. <em>TMC</em>, <em>22</em>(6), 3665–3676. (<a
href="https://doi.org/10.1109/TMC.2021.3138449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobility management is a major challenge for millimeter-wave (mmWave) cellular networks. In particular, directional beamforming in mmWave devices renders high-speed mobility support very complex. This complexity, however, is not limited to system design but also the performance estimation and evaluation. Hence, some have turned their attention to stochastic modeling of mmWave vehicular communication to derive closed-form expressions that can characterize the coverage and rate behavior of the network. In this article, we model and analyze the beam management for mmWave vehicular networks. To the best of our knowledge, this is the first work that goes beyond coverage and rate analysis. Specifically, we focus on a multi-lane divided highway scenario in which base stations and vehicles are present on both sides of the highway. In addition to providing analytical expressions for the average number of beam switching and handover events, we provide design insights for the operators to fine-tune their network through more informed choice of system parameters, including the number of resources dedicated to channel feedback and beam alignment operations.},
  archive      = {J_TMC},
  author       = {Somayeh Aghashahi and Samaneh Aghashahi and Zolfa Zeinalpour-Yazdi and Aliakbar Tadaion and Arash Asadi},
  doi          = {10.1109/TMC.2021.3138449},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3665-3676},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Stochastic modeling of beam management in mmWave vehicular networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SIDE: Self driving drones embrace uncertainty. <em>TMC</em>,
<em>22</em>(6), 3650–3664. (<a
href="https://doi.org/10.1109/TMC.2021.3135894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerial drones are increasingly used to perform monitoring tasks in a large number of applications. Current solutions to trajectory planning rely on perfect knowledge of ongoing events requiring inspection. Nevertheless, in many scenarios the events’ time and position can only be estimated with some uncertainty . Unlike previous work, we consider critical scenarios where a squad of drones is required to autonomously inspect an area of interest under uncertainty of time and location of target events. The main goal of the squad is to ensure maximum coverage of event monitoring with minimum average inspection delay. With no initial knowledge, the drones share their local observations of the environment and apply the Parzen-Rosenblatt approach to manage a dynamic probabilistic map of ongoing events. This map is integrated into a virtual force approach for a joint solution to distributed dynamic trajectory planning and collision avoidance. Through extensive simulations and real-field experiments, we compare our proposal against AC-GAP , a state-of-art solution for UAVs, and Sweep , a sweep-based algorithm for multiple robots. We show that our proposal discovers new events 30-40 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; faster than the other algorithms, and outperforms them in terms of percentage of visited events and inspection delay, under a wide variety of scenarios.},
  archive      = {J_TMC},
  author       = {Novella Bartolini and Andrea Coletta and Gaia Maselli},
  doi          = {10.1109/TMC.2021.3135894},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3650-3664},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SIDE: Self driving drones embrace uncertainty},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Server placement for edge computing: A robust submodular
maximization approach. <em>TMC</em>, <em>22</em>(6), 3634–3649. (<a
href="https://doi.org/10.1109/TMC.2021.3136868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the problem of R obust S erver P lacement (RSP) for edge computing, i.e., in the presence of uncertain edge server failures, how to determine a server placement strategy to maximize the expected overall workload that can be served by edge servers. We mathematically formulate the RSP problem in the form of robust max-min optimization, derived from two consequentially equivalent transformations of the problem that does not consider robustness and followed by a robust conversion. RSP is challenging to solve, because the explicit expression of the objective function in RSP is hard to obtain, and it is a robust max-min problem with knapsack constraints, which is still an unexplored problem in the literature. We reveal that the objective function is monotone submodular, and propose two solutions to RSP. First, after proving that the involved constraints form a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$p$&lt;/tex-math&gt;&lt;/inline-formula&gt; -independence system constraint, where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$p$&lt;/tex-math&gt;&lt;/inline-formula&gt; is a parameter determined by the coefficients in the knapsack constraints, we propose an algorithm that achieves a provable approximation ratio in polynomial time. Second, we prove that one of the knapsack constraints is a matroid contraint, and propose another polynomial time algorithm with a better approximation ratio. Furthermore, we discuss the applicability of the aforementioned algorithms to the case with an additional server number constraint. Both synthetic and trace-driven simulation results show that, given any maximum number of server failures, our proposed algorithms outperform four state-of-the-art algorithms and approaches the optimal solution, which applies exhaustive exponential searches, while the proposed latter algorithm brings extra performance gains compared with the former one.},
  archive      = {J_TMC},
  author       = {Yuben Qu and Lihao Wang and Haipeng Dai and Weijun Wang and Chao Dong and Fan Wu and Song Guo},
  doi          = {10.1109/TMC.2021.3136868},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3634-3649},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Server placement for edge computing: A robust submodular maximization approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). QoE assessment model based on continuous deep learning for
video in wireless networks. <em>TMC</em>, <em>22</em>(6), 3619–3633. (<a
href="https://doi.org/10.1109/TMC.2021.3133949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality of experience (QoE) is a vital metric that indicates how well the wireless network provides transmission services to users, while quality of service (QoS) help better configure the network parameters for higher performance. The evaluation time of QoE is usually several orders of magnitude larger than that of QoS, because QoE is the perception of users over a period of time, but QoS can be collected every millisecond. Therefore, the implementation of QoE/QoS mapping model can help us obtain QoE by collecting the QoS measurements, and perform QoE-based network configurations with smaller time granularity. Many studies are made to obtain the QoS to QoE mapping, including the use of machine learning (ML) methods. However, traditional ML-based regression methods for QoE/QoS mapping face the challenge of high regression error and catastrophic forgetting in dealing with continuously arriving data. In this paper, we propose a novel QoE model based on continual deep learning in wireless network. This model is formed with two deep neural networks (DNNs) concatenated. The first DNN classifies data into different subsets, which are then fed into the second DNN for regression. The second DNN dynamically form the corresponding subnets, each with nodes and connections adaptively selected in each new time period with new arriving data. We solve the catastrophic forgetting problem with the use of node splitting and hidden state augmentation. Our proposed learning framework greatly reduces the regression error to as low as 0.9314%. The experimental results demonstrate that our proposed model reduces the root mean square error (RMSE) by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$21 \sim 86$&lt;/tex-math&gt;&lt;/inline-formula&gt; times compared with several existing approaches, specially, the testing error of our proposed model is more than 80 times lower than that of traditional DNN. Compared with other DNN-based cascade models, our proposed method provides good performance in both training time and RMSE.},
  archive      = {J_TMC},
  author       = {Xuewen Liu and Gang Chuai and Xin Wang and Zhiwei Xu and Weidong Gao},
  doi          = {10.1109/TMC.2021.3133949},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3619-3633},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {QoE assessment model based on continuous deep learning for video in wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy-preserving ranked spatial keyword query in mobile
cloud-assisted fog computing. <em>TMC</em>, <em>22</em>(6), 3604–3618.
(<a href="https://doi.org/10.1109/TMC.2021.3134711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of GPS-equipped mobile devices in cloud-assisted fog computing scenarios, massive spatio-textual data is generated and outsourced to cloud servers for storage and analysis. Existing privacy-preserving range query or ranked keyword search schemes does not support a unified index, and are just applicable for the symmetric environment where all users sharing the same secret key. To solve this issue, we propose a P rivacy-preserving R anked S patial keyword Q uery in mobile cloud-assisted F og computing (PRSQ-F). Specifically, we design a novel comparable product encoding strategy that combines both spatial and textual conditions tightly to retrieve the objects in query range and with the highest textual similarity. Then, we use a new conversion protocol and attribute-based encryption to support privacy-preserving retrieval and malicious user traceability in the asymmetric environment where different query users have different keys. Furthermore, we construct an R-tree-based index to achieve faster-than-linear retrieval. Our formal security analysis shows that data security can be guaranteed. Our empirical experiments using a real-world dataset demonstrate the efficiency and feasibility of PRSQ-F.},
  archive      = {J_TMC},
  author       = {Qiuyun Tong and Yinbin Miao and Hongwei Li and Ximeng Liu and Robert H. Deng},
  doi          = {10.1109/TMC.2021.3134711},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3604-3618},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy-preserving ranked spatial keyword query in mobile cloud-assisted fog computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Placing wireless chargers with limited mobility.
<em>TMC</em>, <em>22</em>(6), 3589–3603. (<a
href="https://doi.org/10.1109/TMC.2021.3136967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several recent works have studied mobile charging under the “one-to-many” charging pattern where a single charger can charge multiple devices simultaneously. However, most of them focus on path planning and charging time allocation, but overlook the underlying dependence of the charging efficiency on initial deployment positions of chargers. This paper studies the problem of P lacing directional w I reless chargers with L imited m O bili T y (PILOT), that is, maximize the overall charging utility for a set of static rechargeable devices on a 2D plane by determining deployment positions, stop positions and orientations, and portions of time for all deployed chargers that can move in a limited area after their deployment. To the best of our knowledge, we are the first to study placement of mobile directional chargers under the “one-to-many” pattern. To address PILOT, we propose a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(\frac{1}{2}-\epsilon)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -approximation algorithm. First, we present a method to approximate nonlinear charging power of chargers, and further propose an approach to construct Maximal Covered Set uniform subareas to reduce the infinite continuous search space for stop positions and orientations to a finite discrete one. Second, we present geometrical techniques to further reduce the infinite solution space for candidate deployment positions to a finite one without performance loss, and transform PILOT to a mixed integer nonlinear programming problem. Finally, we propose a linear programming based greedy algorithm to address it. Simulation and experimental results show that our algorithm outperforms six comparison algorithms by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$19.74 \% \sim 500.01 \%$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Haipeng Dai and Xiaoyu Wang and Xuzhen Lin and Rong Gu and Shuyu Shi and Yunhuai Liu and Wanchun Dou and Guihai Chen},
  doi          = {10.1109/TMC.2021.3136967},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3589-3603},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Placing wireless chargers with limited mobility},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal multicasting in millimeter wave 5G NR with
multi-beam directional antennas. <em>TMC</em>, <em>22</em>(6),
3572–3588. (<a href="https://doi.org/10.1109/TMC.2021.3136298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The support of multicast communications in the fifth-generation (5G) New Radio (NR) system poses unique challenges to system designers. Particularly, the highly directional antennas do not allow to serve all the user equipment devices (UEs) that belong to the same multicast session in a single transmission. The capability of modern antenna arrays to utilize multiple beams simultaneously, with potentially varying half-power beamwidth, adds a new degree of freedom to the UE scheduling. This work addresses the challenge of optimal multicasting in 5G millimeter wave (mmWave) systems by presenting a globally optimal solution for multi-beam antenna operation. The optimization problem is formulated as a special case of multi-period variable cost and size bin packing problem that allows to not impose any constraints on the number of the beams and their configurations. We also propose heuristic solutions having polynomial time complexity. Our results show that for small cell radii of up to 100 meters, a single beam is always utilized. For higher cell coverage and practical ranges of the number of users (5-50), the optimal number of beams is upper bounded by 3.},
  archive      = {J_TMC},
  author       = {Nadezhda Chukhno and Olga Chukhno and Dmitri Moltchanov and Antonella Molinaro and Yuliya Gaidamaka and Konstantin Samouylov and Yevgeni Koucheryavy and Giuseppe Araniti},
  doi          = {10.1109/TMC.2021.3136298},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3572-3588},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal multicasting in millimeter wave 5G NR with multi-beam directional antennas},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online control of service function chainings across
geo-distributed datacenters. <em>TMC</em>, <em>22</em>(6), 3558–3571.
(<a href="https://doi.org/10.1109/TMC.2021.3135535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Function Virtualization (NFV) provides the possibility to implement complex network functions from dedicated hardware to software instances called Virtual Network Functions (VNF) by leveraging the virtualization technology. Service Function Chaining (SFC) is therefore defined as a chain-ordered set of placed VNFs that handles the traffic of the delivery and control of a specific application. Due to the advantages of flexibility, efficiency, scalability, and short deployment cycles, NFV has been widely recognized as the next-generation network service provisioning paradigm. In this paper, we study the problem of online SFC control across geo-distributed datacenters, which is to dynamically place required VNFs on datacenter nodes and find routing paths between each adjacent VNF pair for each NFV service flow that varies over time. To that end, we first formulate this problem as an offline optimization problem whose goal is to minimize the average delay such that each datacenter&#39;s average cost does not exceed a given expense value. Considering that the offline optimization requires complete offline network information which is difficult to obtain or predict in practice, we present an online SFC control framework without requiring any future information about the traffic demands. More specifically, we leverage the Lyapunov optimization technique to formulate the problem as a series of one-time slot offline optimization problems and then apply a primal-decomposition method to solve each one-time slot problem. Simulation results reveal that our proposed online SFC control framework can efficiently reduce long-term average delay while keeping datacenter&#39;s long-term average cost consumption low.},
  archive      = {J_TMC},
  author       = {Song Yang and Fan Li and Zhi Zhou and Xu Chen and Yu Wang and Xiaoming Fu},
  doi          = {10.1109/TMC.2021.3135535},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3558-3571},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online control of service function chainings across geo-distributed datacenters},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the estimation of spatial density from mobile network
operator data. <em>TMC</em>, <em>22</em>(6), 3541–3557. (<a
href="https://doi.org/10.1109/TMC.2021.3134561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We tackle the problem of estimating the spatial distribution of mobile phones from Mobile Network Operator (MNO) data, namely Call Detail Record (CDR) or signalling data. The process of transforming MNO data to a density map requires geolocating radio cells to determine their spatial footprint. Traditional geolocation solutions rely on Voronoi tessellations and approximate cell footprints by mutually disjoint regions. Recently, some pioneering work started to consider more elaborate geolocation methods with partially overlapping (non-disjoint) cell footprints coupled with a probabilistic model for phone-to-cell association. Estimating the spatial density in such a probabilistic setup is currently an open research problem and is the focus of the present work. We start by reviewing three different estimation methods proposed in literature and provide novel analytical insights that unveil some key aspects of their mutual relationships and properties. Furthermore, we develop a novel estimation approach for which a closed-form solution can be given. Numerical results based on semi-synthetic data are presented to assess the relative accuracy of each method. Our results indicate that the estimators based on overlapping cells have the potential to improve spatial accuracy over traditional approaches based on Voronoi tessellations.},
  archive      = {J_TMC},
  author       = {Fabio Ricciato and Angelo Coluccia},
  doi          = {10.1109/TMC.2021.3134561},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3541-3557},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the estimation of spatial density from mobile network operator data},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Near optimal charging schedule for 3-d wireless rechargeable
sensor networks. <em>TMC</em>, <em>22</em>(6), 3525–3540. (<a
href="https://doi.org/10.1109/TMC.2021.3137308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless rechargeable sensor networks (WRSNs) have become a hot research issue owing to the breakthrough of wireless power transfer (WPT) technology. Previous theoretical schemes are mostly designed for 2-D networks, and few of them are tailored for 3-D scenarios, making them not suitable for wide adoptions in practical applications. In this paper, we address the issue of how to serve a 3-D WRSN with an unmanned aerial vehicle (UAV). Our main concern is to maximize the charged energy for sensors supplied by the UAV, which has energy constraints. We respectively develop a spatial discretization scheme to construct a finite feasible set of charging spots for the UAV in a 3-D environment and a temporal discretization scheme to determine the appropriate charging duration for each charging spot. Then, we reduce the problem into a submodular maximization problem with routing constraints and present a cost-efficient algorithm (CEA) with a provable approximation ratio to solve it. Finally, test-bed experiments are conducted to show the feasibility of our schemes in practical scenarios. Extensive simulations are taken to verify the superior performance of our algorithm in charged energy and robustness. The charged energy of our scheme outperforms other competing methods by at least &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$18.2\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Chi Lin and Wei Yang and Haipeng Dai and Teng Li and Yi Wang and Lei Wang and Guowei Wu and Qiang Zhang},
  doi          = {10.1109/TMC.2021.3137308},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3525-3540},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Near optimal charging schedule for 3-D wireless rechargeable sensor networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MVPose: Realtime multi-person pose estimation using motion
vector on mobile devices. <em>TMC</em>, <em>22</em>(6), 3508–3524. (<a
href="https://doi.org/10.1109/TMC.2021.3139940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present MVPose, a novel system designed to enable real-time multi-person pose estimation (PE) on commodity mobile devices, which consists of three novel techniques. First, MVPose takes a motion-vector-based approach to fast and accurately track the human keypoints across consecutive frames, rather than running expensive human-detection model and pose-estimation model for every frame. Second, MVPose designs a mobile-friendly PE model that uses lightweight feature extractors and multi-stage network to significantly reduce the latency of pose estimation without compromising the model accuracy. Third, MVPose leverages the heterogeneous computing resources of both CPU and GPU to execute the pose estimation model for multiple persons in parallel, which further reduces the total latency. We present extensive experiments to evaluate the effectiveness of the proposed tecniques by implemented the MVPose on five off-the-shelf commercial smartphones. Evaluation results show that MVPose achieves over 30 frames per second PE with 4 persons per frame, which significantly outperforms the state-of-the-art baseline, with a speedup of up to 5.7× and 3.8× in latency on CPU and GPU, respectively. Compared with baseline, MVPose achieves an improvement of 10.1% in multi-person PE accuracy. Furthermore, MVPose achieves up to 74.3% and 57.6% energy-per-frame saving on average in comparison with the baseline on mobile CPU and GPU, respectively.},
  archive      = {J_TMC},
  author       = {Jinrui Zhang and Deyu Zhang and Huan Yang and Yunxin Liu and Ju Ren and Xiaohui Xu and Fucheng Jia and Yaoxue Zhang},
  doi          = {10.1109/TMC.2021.3139940},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3508-3524},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MVPose: Realtime multi-person pose estimation using motion vector on mobile devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MPKIX: Towards more accountable and secure internet
application services via mobile networked systems. <em>TMC</em>,
<em>22</em>(6), 3489–3507. (<a
href="https://doi.org/10.1109/TMC.2022.3141694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, both Internet Application Service (IAS) providers and users face various security threats and legal issues. Due to the lack of reliable user information verification mechanisms, adversaries can abuse IASs to launch various cyberattacks, such as misinformation distributing and phishing, by using fake user accounts. IAS providers may thus inadvertently offer inappropriate content to restricted users, thereby suffering a serious risk of prosecution under local or international laws. Also, IAS users may suffer from nefarious ID theft attacks. In this paper, we proposed a novel security framework, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf MPKIX}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , designated as Mobile-assisted PKIX (Public-Key Infrastructure X.509). &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf MPKIX}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; secures both IAS providers and users by leveraging the broadly used PKIX services and mobile networked systems. It not only provides IAS providers with a reliable user verification mechanism while simultaneously enabling cross-IAS user privacy protection, but also largely mitigates the possibility of ID theft attacks and benefits other involved parties, such as cellular network operators and PKIX service providers. We further conduct a security analysis of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf MPKIX}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; and implement an &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf MPKIX}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; prototype. The evaluation results based on the prototype confirm the effectiveness and efficiency of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf MPKIX}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; with low overhead.},
  archive      = {J_TMC},
  author       = {Tian Xie and Sihan Wang and Xinyu Lei and Jingwen Shi and Guan-Hua Tu and Chi-Yu Li},
  doi          = {10.1109/TMC.2022.3141694},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3489-3507},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MPKIX: Towards more accountable and secure internet application services via mobile networked systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Measurement of a large-scale short-video service over mobile
and wireless networks. <em>TMC</em>, <em>22</em>(6), 3472–3488. (<a
href="https://doi.org/10.1109/TMC.2021.3139893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-video sharing services have seen explosive growth in recent years. Compared to conventional video sharing platforms, these have very different characteristics which are far from well-understood. This work aims at filling the gap by measuring and analyzing detailed application-level performance data from a top-10 short video service in China. The application-level data offered detailed and rare insights into many performance metrics of the service, which are otherwise inaccessible to external measurements. The service has a scale of over one billion daily views just for the mobile and wireless segments of the service. Our datasets covered over 22 billion video playbacks, over 100 million video files, served by over 5,000 servers to users across 35 provinces and 13 ISPs in China. We analyzed three aspects of the service: (a) video content characteristics; (b) network analytics; and (c) video streaming analytics. Our results revealed significant differences from conventional video-sharing platforms. These findings will have implications for system designs at all levels. The data also enabled us to conduct an indirect network performance measurement of mobile and wireless network services across China, as experienced by the service. These results offer rare insights into mobile and wireless networks&#39; real-world performance in a large country.},
  archive      = {J_TMC},
  author       = {Yuming Zhang and Yan Liu and Lingfeng Guo and Jack Y. B. Lee},
  doi          = {10.1109/TMC.2021.3139893},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3472-3488},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Measurement of a large-scale short-video service over mobile and wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locomotion mode recognition using sensory data with noisy
labels: A deep learning approach. <em>TMC</em>, <em>22</em>(6),
3460–3471. (<a href="https://doi.org/10.1109/TMC.2021.3135878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Availability of various sensors in the smartphone makes it easier and convenient to collect the data of human locomotion activities. A recognition approach can utilize this sensory data for recognizing a locomotion mode of a user such as a bicycle, bike, car, etc. Such recognition of locomotion modes helps in the precise estimation of transportation expenditure, travel time, and appropriate journey planning. The accuracy of the recognition approaches heavily relies on the training dataset having correctly annotated labels. These labels are usually assigned using crowdsourcing or web-based queries for economic and fast annotation. However, the annotation generates abundant noisy labels in the dataset. This paper proposes a locomotion mode recognition approach capable of handling noisy labels in the training dataset. The approach builds an ensemble model by developing three different deep learning-based models, namely conventional, noise adaptive, and noise corrective, to handle different concentrations of noisy labels. The ensemble model not only improves the recognition performance but also helps in estimating the concentration of noisy labels. Experimental results demonstrate the effectiveness of the proposed approach on collected and existing datasets.},
  archive      = {J_TMC},
  author       = {Rahul Mishra and Ashish Gupta and Hari Prabhat Gupta},
  doi          = {10.1109/TMC.2021.3135878},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3460-3471},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Locomotion mode recognition using sensory data with noisy labels: A deep learning approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Layer dependency-aware learning scheduling algorithms for
containers in mobile edge computing. <em>TMC</em>, <em>22</em>(6),
3444–3459. (<a href="https://doi.org/10.1109/TMC.2021.3139995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the features of lightweight and easy deployment, the use of containers has emerged as a promising approach for Mobile Edge Computing (MEC). Before running the container, an image composed of several layers must exist locally. However, it has been conspicuously neglected by existing work that task scheduling at the granularity of the layer instead of the image can significantly reduce the task completion time to further meet the real-time requirement and resource efficiency in resource-limited MEC. To bridge the gap, considering the complex dependency between layers and images, a novel layer dependency-aware container scheduling algorithm is proposed to reduce the total task completion time. Specifically: 1) We model the online layer dependency-aware scheduling problem for containers in a heterogeneous MEC, considering the layer download time and task computation time. 2) A policy gradient algorithm is proposed to solve this problem, and the high-dimensional and low-dimensional relations for layer dependencies are extracted with improved action selection. 3) Experiments based on the real-world data trace show that the proposed algorithm outperforms the image-based and layer-based baseline algorithms by 54% and 19% on average, respectively.},
  archive      = {J_TMC},
  author       = {Zhiqing Tang and Jiong Lou and Weijia Jia},
  doi          = {10.1109/TMC.2021.3139995},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3444-3459},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Layer dependency-aware learning scheduling algorithms for containers in mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large-scale computation offloading using a multi-agent
reinforcement learning in heterogeneous multi-access edge computing.
<em>TMC</em>, <em>22</em>(6), 3425–3443. (<a
href="https://doi.org/10.1109/TMC.2022.3141080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, existing computation offloading methods have provided extremely low service latency for mobile users (MUs) in multi-access edge computing (MEC). However, this remains a challenge in large-scale mixed cooperative-competitive MUs heterogeneous MEC environments. Moreover, existing methods focus more on all offloaded tasks handled by static resource allocation MEC servers (ESs) within a time interval, ignoring on-demand requirements of heterogeneous tasks, resulting in many tasks being dropped or wasting resources, especially for latency-sensitive tasks. To address these issues, we present a decentralized computation offloading solution based on the Attention-weighted Recurrent Multi-Agent Actor-Critic (ARMAAC). First, we design a recurrent actor-critic framework to assist MU agents in remembering historical resource allocation information of ESs to better understand the future state of ESs, especially in dynamic resource allocation. Second, an attention mechanism is introduced to compress the joint observation space dimension of all MUs agent to adapt to large-scale MUs. Finally, the actor-critic framework with double centralized critics and Dueling network is redesigned considering the instability and convergence difficulties caused by the sensitive relationship between the actor and critic networks. The experiments show that ARMAAC improves task completion rates and reduces average system cost by 11.01% &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 14.03% and 10.45% &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 15.56% compared with baselines.},
  archive      = {J_TMC},
  author       = {Zhen Gao and Lei Yang and Yu Dai},
  doi          = {10.1109/TMC.2022.3141080},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3425-3443},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Large-scale computation offloading using a multi-agent reinforcement learning in heterogeneous multi-access edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Keystroke recognition with the tapping sound recorded by
mobile phone microphones. <em>TMC</em>, <em>22</em>(6), 3407–3424. (<a
href="https://doi.org/10.1109/TMC.2021.3137229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile phones nowadays are equipped with at least dual microphones. We find when a user is typing on a phone, the sounds generated from the vibration caused by finger’s tapping on the screen surface can be captured by both microphones, and these recorded sounds alone are informative enough to localize the user’s keystrokes. This ability can be leveraged to enable useful application designs, while it also raises a crucial privacy risk that the private information typed by users on mobile phones has a great potential to be leaked through such a recognition ability. In this paper, we address two key design issues and demonstrate, more importantly alarm people, that this risk is possible, which could be related to many of us when we use our mobile phones. We implement our proposed techniques in a prototype system and conduct extensive experiments. The evaluation results indicate promising successful rates for more than 4000 keystrokes from different users on various types of mobile phones.},
  archive      = {J_TMC},
  author       = {Zhen Xiao and Tao Chen and Yang Liu and Jiao Li and Zhenjiang Li},
  doi          = {10.1109/TMC.2021.3137229},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3407-3424},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Keystroke recognition with the tapping sound recorded by mobile phone microphones},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint sleep and rate scheduling with booting costs for
energy harvesting communication systems. <em>TMC</em>, <em>22</em>(6),
3391–3406. (<a href="https://doi.org/10.1109/TMC.2021.3135865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In energy harvesting communication systems, it is possible for a transmitter to schedule the transmission by jointly scaling the rate and turning the transmitter ON/OFF adaptively. Such a joint rate and sleep schedule can greatly increase the throughput achieved by the transmitter with battery constraints. However, most existing works on joint rate and sleep scheduling assume the transition between different states does not have any cost, i.e., energy or time consumption. This is not realistic while the energy and time needed for booting a transmitter, i.e., turning a transmitter from OFF to ON, are not small enough to be ignored in most cases. In this paper, we investigate the joint rate and sleep scheduling on system throughput with more general booting consumption considered in energy harvesting communication systems. We first identify the structural properties of the optimal solution for the model with booting consumption considered. Inspired by these observations, we develop an optimal offline algorithm and an online heuristic algorithm to solve the problem. Experimental results from simulations and real tests show that the proposed algorithms can achieve much higher throughput on average in a realistic energy harvesting communication system, compared to those algorithms that only consider rate scheduling or ignore the booting consumption.},
  archive      = {J_TMC},
  author       = {Guangli Dai and Weiwei Wu and Kai Liu and Feng Shan and Jianping Wang and Xueyong Xu and Junzhou Luo},
  doi          = {10.1109/TMC.2021.3135865},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3391-3406},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint sleep and rate scheduling with booting costs for energy harvesting communication systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint client selection and bandwidth allocation algorithm
for federated learning. <em>TMC</em>, <em>22</em>(6), 3380–3390. (<a
href="https://doi.org/10.1109/TMC.2021.3136611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning (FL), if the participating mobile devices have low computing power and poor wireless channel conditions and/or they do not have sufficient data for various classes, a long convergence time is required to achieve the desired model accuracy. To address this problem, we first formulate a constrained Markov decision process (CMDP) problem that aims to minimize the average time of rounds while maintaining the numbers of trained data and trained data classes above certain numbers. To obtain the optimal scheduling policy, the formulated CMDP problem is converted into an equivalent linear programming (LP). Additionally, to overcome the problem of the curse of dimensionality in CMDP, we develop a joint client selection and bandwidth allocation algorithm (J-CSBA) that jointly selects appropriate mobile devices and allocates suitable amount of bandwidth to them at each round by considering their data information, computing power, and channel gain. Evaluation results validate that J-CSBA can reduce the convergence time by up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$49\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; compared to a conventional random scheme.},
  archive      = {J_TMC},
  author       = {Haneul Ko and Jaewook Lee and Sangwon Seo and Sangheon Pack and Victor C. M. Leung},
  doi          = {10.1109/TMC.2021.3136611},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3380-3390},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint client selection and bandwidth allocation algorithm for federated learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). In-vehicle phone localization for prevention of distracted
driving. <em>TMC</em>, <em>22</em>(6), 3365–3379. (<a
href="https://doi.org/10.1109/TMC.2022.3141019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new in-vehicle phone localization scheme, called DAPL ( D etection and A larming of in-vehicle P hone Location ), is proposed to determine the locations of smartphones inside a moving car, with the goal of preventing smartphone-distracted driving. DAPL operates on commodity smartphones and cars, and does not require additional special/dedicated hardware to be installed inside the car, making its deployment easy and attractive to users and carmakers. Even when a phone is moved from one location to another inside a moving car, DAPL will detect this movement, acquire the sensor data, and estimate the phone&#39;s destination location. DAPL captures the trajectory of each phone movement, the change of magnetic field, and the RSSI readings from the Bluetooth transceiver built in most cars, and then estimates the phone&#39;s destination location by matching the trajectory with the variation of magnetic field and the Bluetooth RSSI readings. Our extensive experimentation has shown DAPL to achieve an average of 91.71% accuracy of in-car phone localization at low energy overhead, i.e., &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$&amp;lt;$&lt;/tex-math&gt;&lt;/inline-formula&gt; 2.5% reduction of actual usage (screen-on) time.},
  archive      = {J_TMC},
  author       = {Chun-Yu Chen and Kang G. Shin},
  doi          = {10.1109/TMC.2022.3141019},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3365-3379},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {In-vehicle phone localization for prevention of distracted driving},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IBAC: An intelligent dynamic bandwidth channel access
avoiding outside warning range problem. <em>TMC</em>, <em>22</em>(6),
3350–3364. (<a href="https://doi.org/10.1109/TMC.2022.3141010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IEEE 802.11ax uses the concept of primary and secondary channels, leading to the Dynamic Bandwidth Channel Access (DBCA) mechanism. By applying DBCA, a wireless station can select a wider channel bandwidth, such as &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$40/80/160$&lt;/tex-math&gt;&lt;/inline-formula&gt; MHz, by applying the channel bonding feature. However, during channel bonding, inappropriate bandwidth selection can cause collisions. Therefore, to avoid collisions, a well-developed media access control (MAC) protocol is crucial to effectively utilize the channel bonding mechanism. In this paper, we address a collision scenario, called Outside Warning Range Problem (OWRP) , that may occur during DBCA when a wireless station interferes with another wireless station after channel bonding is performed. Therefore, we propose a MAC layer mechanism, Intelligent Bonding Avoiding Collision (IBAC) , that adapts the channel bonding level in DBCA in order to avoid the OWRP. We first design a theoretical model based on Markov chains for DBCA while avoiding the OWRP. Based on this model, we design a Thompson sampling based Bayesian approach to select the best possible channel bonding level intelligently. We analyze the performance of the IBAC through simulations where it is observed that, comparing to other competing mechanisms, the proposed approach can enhance the network performance significantly while avoiding the OWRP.},
  archive      = {J_TMC},
  author       = {Raja Karmakar and Georges Kaddoum},
  doi          = {10.1109/TMC.2022.3141010},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3350-3364},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {IBAC: An intelligent dynamic bandwidth channel access avoiding outside warning range problem},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GPU based high definition parallel video codec optimization
in mobile device. <em>TMC</em>, <em>22</em>(6), 3333–3349. (<a
href="https://doi.org/10.1109/TMC.2021.3139907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of various intelligent device and the rapid development of wireless network communication technology, most people prefer to use video applications on smart devices. However, the main challenges when using video codec technology on mobile devices are: 1) The explosive growth of multimedia applications has caused the allocation of computing resources to become an important issue; 2) high power consumption and limited battery power; 3) high cpu utilization causes the system to be unresponsive. In this paper, a G PU based H igh Definition P arallel V ideo C odec (GHPVC) is proposed, which is a low energy consumption and high efficient video codec on mobile devices. First, Frame Data Management model and Prediction Model Selector model are proposed in order to get higher data transmission efficiency and parallel execution efficiency. Second, a GPU based Parallel ME module is proposed because the ME module is the most power-consuming and computationally intensive module in video codec. The GHPVC is proposed on the basis of conforming to the H.264 standard. Moreover and experimentally evaluated for different GPU devices on different mobile devices. Experimental results show that compared with the existing H.264 scheme, the proposed GHPVC not only has significant improvement in codec performance, but also effectively reduces energy consumption and CPU utilization.},
  archive      = {J_TMC},
  author       = {Baichuan Su and Bo Cheng and Junliang Chen},
  doi          = {10.1109/TMC.2021.3139907},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3333-3349},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {GPU based high definition parallel video codec optimization in mobile device},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedHAR: Semi-supervised online learning for personalized
federated human activity recognition. <em>TMC</em>, <em>22</em>(6),
3318–3332. (<a href="https://doi.org/10.1109/TMC.2021.3136853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of smartphone sensors and wearable devices has enabled a new paradigm for smart human activity recognition (HAR), which has a broad range of applications in healthcare and smart cities. However, there are four challenges, privacy preservation , label scarcity , real-timing , and heterogeneity patterns , to be addressed before HAR can be more applicable in real-world scenarios. To this end, in this paper, we propose a personalized federated HAR framework, named FedHAR , to overcome all the above obstacles. Specially, as federated learning, FedHAR performs distributed learning, which allows training data to be kept local to protect users’ privacy. Also, for each client without activity labels, in FedHAR , we design an algorithm to compute unsupervised gradients under the consistency training proposition and an unsupervised gradient aggregation strategy is developed for overcoming the concept drift and convergence instability issues in online federated learning process. Finally, extensive experiments are conducted using two diverse real-world HAR datasets to show the advantages of FedHAR over state-of-the-art methods. In addition, when fine-tuning each unlabeled client, personalized FedHAR can achieve additional 10% improvement across all metrics on average.},
  archive      = {J_TMC},
  author       = {Hongzheng Yu and Zekai Chen and Xiao Zhang and Xu Chen and Fuzhen Zhuang and Hui Xiong and Xiuzhen Cheng},
  doi          = {10.1109/TMC.2021.3136853},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3318-3332},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FedHAR: Semi-supervised online learning for personalized federated human activity recognition},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-anonymous off-line electronic cash for mobile payment.
<em>TMC</em>, <em>22</em>(6), 3303–3317. (<a
href="https://doi.org/10.1109/TMC.2021.3135301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile devices have become near-ubiquitous tools in our daily lives. Following this trend, mobile commence is developed rapidly which in turns stimulates interests in mobile payment. Some prominent examples include Google’s Wallet, WeChat Pay, and Apple Pay. Most of these technologies, however, are designed for users to be able to pay conveniently to the business. In other words, they are designed with the business to user model in mind. Besides, an active network connection with an external payment server is required either from payer or payee during transaction. Our work intends to supplement existing solutions, which allows payment to be made in an off-line and dual-anonymous manner. In doing so, a dual-anonymous off-line electronic cash scheme is proposed by utilizing BBS+ signature. The feature of our scheme is dual-anonymous payment, which means that both the payer and the payee in any transaction cannot be identified even all other users and the payment server collude. Through security proof and performance analysis, we also demonstrate that the security of the proposed scheme can be reduced to standard assumptions and it is suitable for applications in mobile commerce.},
  archive      = {J_TMC},
  author       = {Jianbing Ni and Man Ho Au and Wei Wu and Xiapu Luo and Xiaodong Lin and Xuemin Sherman Shen},
  doi          = {10.1109/TMC.2021.3135301},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3303-3317},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dual-anonymous off-line electronic cash for mobile payment},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DistPreserv: Maintaining user distribution for
privacy-preserving location-based services. <em>TMC</em>,
<em>22</em>(6), 3287–3302. (<a
href="https://doi.org/10.1109/TMC.2022.3141398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-Based Services (LBSs) are one of the most frequently used mobile applications in the modern society. Geo-Indistinguishability (Geo-Ind) is a promising privacy protection model for LBSs since it can provide formal security guarantees for location privacy. However, Geo-Ind undermines the statistical location distribution of users on the LBS server because of perturbed locations, thereby disabling the server to provide distribution-based services (e.g., traffic congestion maps). To overcome this issue, we give a privacy definition, called DistPreserv, to enable the LBS server to acquire valid location distributions while providing users with strict location protection. Then we propose a privacy-preserving LBS scheme to benefit both users and the server, in which a location perturbation mechanism is designed to achieve the given definition under the guide of the incentive compatibility, and a retrieval area determination method is presented to ensure query accuracy of users by using the dynamic programming on the two-dimensional map plane. Finally, we theoretically prove that the designed mechanism can achieve the definition of DistPreserv and the property of incentive compatibility. Experimental explorations using a real-world dataset indicate that our proposal prominently improves the availability of users’ location distributions by over 90%, while providing high precision and recall of queries.},
  archive      = {J_TMC},
  author       = {Yanbing Ren and Xinghua Li and Yinbin Miao and Robert H. Deng and Jian Weng and Siqi Ma and Jianfeng Ma},
  doi          = {10.1109/TMC.2022.3141398},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3287-3302},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DistPreserv: Maintaining user distribution for privacy-preserving location-based services},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepVehicleSense: An energy-efficient transportation mode
recognition leveraging staged deep learning over sound samples.
<em>TMC</em>, <em>22</em>(6), 3270–3286. (<a
href="https://doi.org/10.1109/TMC.2022.3141392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new transportation mode recognition system for smartphones called DeepVehicleSense, which is widely applicable to mobile context-aware services. DeepVehicleSense aims at achieving three performance objectives: high accuracy, low latency, and low power consumption at once by exploiting sound characteristics captured from the built-in microphone while being on candidate transportations. To attain high energy efficiency, DeepVehicleSense adopts hierarchical accelerometer-based triggers that minimize the activation of the microphone of smartphones. Further, to achieve high accuracy and low latency, DeepVehicleSense makes use of non-linear filters that can best extract the transportation sound samples. For recognition of five different transportation modes, we design a deep learning based sound classifier using a novel deep neural network architecture with multiple branches. Our staged inference technique can significantly reduce runtime and energy consumption while maintaining high accuracy for the majority of samples. Through 263-hour datasets collected by seven different Android phone models, we demonstrate that DeepVehicleSense achieves the recognition accuracy of 97.44% with only sound samples of 2 seconds at the power consumption of 35.08 mW on average for all-day monitoring.},
  archive      = {J_TMC},
  author       = {Sungyong Lee and Jinsung Lee and Kyunghan Lee},
  doi          = {10.1109/TMC.2022.3141392},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3270-3286},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DeepVehicleSense: An energy-efficient transportation mode recognition leveraging staged deep learning over sound samples},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Context-aware beam tracking for 5G mmWave V2I
communications. <em>TMC</em>, <em>22</em>(6), 3257–3269. (<a
href="https://doi.org/10.1109/TMC.2021.3137957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicles’ mobility causes frequent beam misalignments in millimeter wave (mmWave) vehicle-to-infrastructure (V2I) communications. In 5G systems, beam sweeping is done repeatedly to track a vehicle&#39;s mobility and maintain high-quality beam selection. Despite extensive studies on mmWave communications, there are still insufficient discussions on when to trigger beam sweeping for beam tracking. Triggering beam sweeping at an inappropriate time can either incur unnecessary overhead or degrade communication performance due to outdated beam selection. Based on this observation, we explore the problem of making beam-sweeping decisions for 5G mmWave vehicular communications. Considering the regularity in vehicle mobility, we propose a C ontext- a ware standa r d-compati B le b e am upd a te sche m e ( CarBeam ) to help the base station determine when to trigger beam sweeping by exploiting the noisy and quantized beam-specific layer-1 reference signal received power feedback from the vehicle. Unlike prior work, CarBeam only exploits the procedures and signaling supported in the current 5G beam management framework. Moreover, it can adapt its beam-sweeping decisions to vehicles&#39;s mobility for efficient beam tracking. The effectiveness of CarBeam is evaluated and demonstrated using the vehicle traces from the TAPASCologne project.},
  archive      = {J_TMC},
  author       = {Haichuan Ding and Kang G. Shin},
  doi          = {10.1109/TMC.2021.3137957},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3257-3269},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Context-aware beam tracking for 5G mmWave V2I communications},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computation offloading and service caching in heterogeneous
MEC wireless networks. <em>TMC</em>, <em>22</em>(6), 3241–3256. (<a
href="https://doi.org/10.1109/TMC.2021.3136595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) can dramatically promote the computation capability and prolong the lifetime of mobile users (MUs) by offloading computation-intensive tasks to edge cloud. In this paper, a spatial-random two-tier heterogeneous network (HetNet) is modelled to feature random node distribution, where the small-cell base stations (SBSs) and the macro base stations (MBSs) are cascaded with servers with different levels of computing and storage capacity. Only a certain type of application services and finite number of offloaded tasks can be cached and processed in the resource-limited edge server. For that setup, we investigate the performance of two offloading strategies corresponding to integrated access and backhaul (IAB)-enabled MEC networks and traditional cellular MEC networks. Using tools from stochastic geometry and queuing theory, we derive the average delay for the two different strategies, in order to better understand the influence of IAB on MEC networks. Simulations results are provided to verify the derived expressions and to reveal various system-level insights.},
  archive      = {J_TMC},
  author       = {Yongqiang Zhang and Mustafa A. Kishk and Mohamed-Slim Alouini},
  doi          = {10.1109/TMC.2021.3136595},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3241-3256},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Computation offloading and service caching in heterogeneous MEC wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoLoRa: Enabling multi-packet reception in LoRa networks.
<em>TMC</em>, <em>22</em>(6), 3224–3240. (<a
href="https://doi.org/10.1109/TMC.2021.3138495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LoRa, as a representative Low-Power Wide Area Network (LPWAN) technology, has emerged as a promising platform for connecting the Internet of Things (IoTs). It enables low-rate communications over upto tens of kilometers with a 10-year battery lifetime. However, practical LoRa deployments suffer from collisions, given the dense deployment of devices and the wide coverage area. We propose CoLoRa, an approach to decompose large numbers of concurrent transmissions from one collision and enable multi-packet reception in LoRa networks. At the heart of CoLoRa, we utilize the packet time offset to disentangle collided packets. CoLoRa incorporates several novel techniques to address practical challenges. (1) We translate time offset, which is difficult to measure, to frequency features that can be reliably measured. (2) We propose a method to extract peak features from low-SNR LoRa signals iteratively. (3) We address frequency shift incurred by carrier frequency offset and time offset for LoRa decoding. We implement CoLoRa on USRP N210 and evaluate its performance in both indoor and outdoor networks. CoLoRa is implemented in software at the base station, and it can work for COTS LoRa nodes. The evaluations show that CoLoRa improves the network throughput by 3.4× compared with Choir and 14× compared with LoRaWAN.},
  archive      = {J_TMC},
  author       = {Shuai Tong and Zhenqiang Xu and Jiliang Wang},
  doi          = {10.1109/TMC.2021.3138495},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3224-3240},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CoLoRa: Enabling multi-packet reception in LoRa networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boost spectrum prediction with temporal-frequency fusion
network via transfer learning. <em>TMC</em>, <em>22</em>(6), 3209–3223.
(<a href="https://doi.org/10.1109/TMC.2021.3136941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling and predicting the radio spectrum is vital for spectrum management, such as spectrum sharing and anomaly detection. Nevertheless, the precise spectrum prediction is challenging due to the interference from both intra-spectrum and external factors. To tackle these complex internal and external correlations, we develop a model named TF &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; AN, consisting of three components: 1) a robust signal detection algorithm based on image processing, 2) an attention-based Long Short-term Memory network to capture the temporal-frequency correlations, 3) a generalized fusion module to take the heterogeneous external factors into account. This structure shows prominent effectiveness for spectrum prediction on a single monitoring station with sufficient data. However, when the data derived from a single station is insufficient, the performance of the deep learning model will decline a lot. Considering that more than one monitoring station is deployed in practice, the new challenge becomes how to enhance our model by leveraging the data from multiple stations or frequency bands. Therefore, we further propose T-TF &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; AN, a transfer learning-based framework for data augmentation and knowledge sharing in spectrum prediction. Compared to TF &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; AN, better performance is achieved. Besides, the model interpretability and training efficiency are also discussed with two case studies, respectively.},
  archive      = {J_TMC},
  author       = {Kehan Li and Chao Li and Jiming Chen and Qiming Zhang and Zebo Liu and Shibo He},
  doi          = {10.1109/TMC.2021.3136941},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3209-3223},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Boost spectrum prediction with temporal-frequency fusion network via transfer learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Blockchain-aided edge computing market: Smart contract and
consensus mechanisms. <em>TMC</em>, <em>22</em>(6), 3193–3208. (<a
href="https://doi.org/10.1109/TMC.2021.3140080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building upon the prevailing concept of edge computing (EC), a distributed EC market requires decentralized and verified transaction management to trade computing resources. Towards this goal, we study a blockchain-aided EC market wherein each data service operator (DSO) rents a group of edge computing nodes (ECNs) and leases the ECNs to the user terminals (UTs) to provide computation offloading services. A trustworthiness model is introduced to evaluate the quality of each network entity throughout the transactions. We develop a two-level trading mechanism over smart contract to enable the automatic and efficient transactions among the network entities and provide high quality services. First, we propose a smart contract based matching mechanism to establish the renting association between the DSOs and ECNs with the aim of maximizing the social welfare. Second, we propose a social welfare improved double auction (SWIDA) mechanism to build up the leasing association between the DSOs and UTs, and determine the pricing of the winners. We show that the proposed double auction mechanism can achieve individual rationality, balanced budget, truthfulness in expectation, and an improved social welfare than the benchmark mechanisms. Moreover, we put forth a trustworthiness driven Proof-of-Stake (PoS) consensus mechanism to enable verified transaction and fair allocation of block generation reward. Following the principle of PoS, we formulate the block generation as a coalitional game, wherein each stakeholder votes according to its trustworthiness and coinage, and shares the reward among the coalition according to the Shapley values. The simulation results show that the proposed PoS consensus mechanism can reduce the wealth inequality among the network entities compared with the conventional consensus mechanisms.},
  archive      = {J_TMC},
  author       = {Yu Du and Zhe Wang and Jun Li and Long Shi and Dushantha Nalin K. Jayakody and Quan Chen and Wen Chen and Zhu Han},
  doi          = {10.1109/TMC.2021.3140080},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3193-3208},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Blockchain-aided edge computing market: Smart contract and consensus mechanisms},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond legitimacy, also with identity: Your smart earphones
know who you are quietly. <em>TMC</em>, <em>22</em>(6), 3179–3192. (<a
href="https://doi.org/10.1109/TMC.2021.3134654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User authentication and identification on smart devices has great significance in keeping data privacy and recommending personalized services. With the rising popularity of smart earphones recently, they open up a new world for users to enjoy music individually, but also bring about privacy concerns at the same time. Existing few research works propose positive sensing systems that emit and receive inaudible acoustic signals to authenticate users. However, they share shortcomings of intrusiveness to users, high power consumption, and purely focusing on authentication. Instead, in this paper, we propose a passive sensing system called &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf EarID}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; with low-cost customized earphones which attains user authentication and identification at once. It makes use of a embedded microphone to sense body sounds spread out through ear canals and extract ‘fingerprints’ as a novel biometric feature. With self-designed earphones, we design a deep learning-based real-time data processing pipeline and cope with external interference. Extensive experiments under different real-world settings show that &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf EarID}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; can achieve a rather low false acceptance rate of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$3.4\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; for user authentication and a high &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$F1$&lt;/tex-math&gt;&lt;/inline-formula&gt; score of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$95.5\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; for legitimate user identification.},
  archive      = {J_TMC},
  author       = {Yongpan Zou and Haibo Lei and Kaishun Wu},
  doi          = {10.1109/TMC.2021.3134654},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3179-3192},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Beyond legitimacy, also with identity: Your smart earphones know who you are quietly},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balloons in the sky: Unveiling the characteristics and
trade-offs of the google loon service. <em>TMC</em>, <em>22</em>(6),
3165–3178. (<a href="https://doi.org/10.1109/TMC.2021.3135976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Google&#39;s Loon &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^{TM}$&lt;/tex-math&gt;&lt;/inline-formula&gt; initiative aims at covering rural or underdeveloped areas via fleets of high-altitude balloons supporting LTE connectivity. But how effective and stable can be the coverage provided by a network deployed via propulsion-free balloons, floating in the sky, and only loosely controllable through altitude variations? To provide some insights on the relevant performance and trade-offs, in this paper we gather real-world data from publicly available flight tracking services, and we analyze coverage and service stability in three past deployment scenarios. Besides employing a variety of metrics related to spatial and temporal coverage, we also assess service continuity, by also leveraging recently proposed “meaningful availability” metrics. While our analyses show that balloons are certainly a cost-effective way to provide a better-than-nothing and delay-tolerant service, there is yet no empirical evidence that an increase in the number of overlapping balloons may be rewarded with a substantial performance increase — in other words, we suspect that guaranteeing coverage and service stability levels comparable to that of a terrestrial cellular network is a challenging goal.},
  archive      = {J_TMC},
  author       = {Pablo Serrano and Marco Gramaglia and Francesco Mancini and Luca Chiaraviglio and Giuseppe Bianchi},
  doi          = {10.1109/TMC.2021.3135976},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3165-3178},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Balloons in the sky: Unveiling the characteristics and trade-offs of the google loon service},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoProfile: An intelligent profile switching system for
smartphones. <em>TMC</em>, <em>22</em>(6), 3151–3164. (<a
href="https://doi.org/10.1109/TMC.2022.3141205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphones have been the necessities for us due to their advanced computing capabilities and ubiquitous connectivity to our daily lives. However, they also produce many negative influences, such as ring noise, nuisance calls, which interrupt people’s attention when working. It would be user-friendly if smartphones can automatically sense the surroundings and dynamically work at an appropriate profile to prevent their ringing from disturbing people in some special circumstances. To address this issue, in this paper, we propose a novel smartphone profile switching system, called AutoProfile, which combines the techniques of acoustic sensing, walk detection and machine learning to automatically and dynamically change smartphones’ profiles in different scenarios. We develop a new compact ambient sound scheme for feature extraction, named DWT &amp; MFCC fingerprint, which can effectively distinguish between different social scenarios and outperforms the existing method. To evaluate the performance of AutoProfile, we conduct experiments in 8 scenarios and take multiple influence factors into consideration. The results demonstrate that AutoProfile can realize overall recognition accuracies of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$91.4 \;\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$90.6 \;\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; when using Random Forest and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -nearest Neighbors classifiers, respectively. Moreover, since AutoProfile senses the ambient sound passively, it does not create additional noise compared with some active acoustic sensing schemes. In addition, the power consumption of AutoProfile is acceptable, and thus AutoProfile can be tailored as a background service of smartphones to make them become “smarter”.},
  archive      = {J_TMC},
  author       = {Wei Yang and Sheng Chen and Zhengyang Wang and Yang Xu and Liusheng Huang},
  doi          = {10.1109/TMC.2022.3141205},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3151-3164},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AutoProfile: An intelligent profile switching system for smartphones},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An information-centric in-network caching scheme for
5G-enabled internet of connected vehicles. <em>TMC</em>, <em>22</em>(6),
3137–3150. (<a href="https://doi.org/10.1109/TMC.2021.3137219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing on-board demand for intelligent connected vehicles (ICVs), the fifth-generation (5G) wireless systems are being massively utilized in vehicular networks. As an essential component, content retrieval in the ICV provides a basis for vehicle-to-vehicle or vehicle-to-infrastructure data interaction for many applications. However, content access is still subject to performance degradation due to congested communication channels, diverse requests patterns, and intermittent network connectivity. To mitigate these issues, in-network caching in 5G-enabled ICV has been leveraged to benefit content access by allowing edge nodes to store content for data generators. In this paper, we propose an in-network caching scheme to support various provisions of data sharing in the ICVs by exploring the advantages of information-centric networks (ICN). We first divide each on-board service into several content units. Then, we place these units at the ICV and small cell base stations (SBSs) to reduce the content retrieval delay, further model the proposed system as an integer nonlinear program (INLP) and attain the optimal QoE (Quality of Experience) by placing content units at appropriate cache entities. Finally, we verify the effectiveness and correctness of our proposed model through extensive simulations.},
  archive      = {J_TMC},
  author       = {Cong Wang and Chen Chen and QingQi Pei and Zhiyuan Jiang and Shugong Xu},
  doi          = {10.1109/TMC.2021.3137219},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3137-3150},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An information-centric in-network caching scheme for 5G-enabled internet of connected vehicles},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Age of information in wireless networks: Spatiotemporal
analysis and locally adaptive power control. <em>TMC</em>,
<em>22</em>(6), 3123–3136. (<a
href="https://doi.org/10.1109/TMC.2021.3139666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The boom in Internet of Things has spawned many real-time applications, which have stringent requirements for the timeliness of information delivery. As a result, age of information (AoI) has emerged as a metric to evaluate information freshness at the destination and aroused widespread attention from both academia and industry. In this paper, we develop a theoretical framework to evaluate the statistics of AoI, including its average and violation probability, in wireless networks under different types of sources and updating patterns. The analyses account for the randomness that arises from both the spatial deployment and temporal queueing dynamics, and its accuracy is verified through simulations. Based on the analytical results, we design a locally adaptive power control policy to optimize the sum of average AoI of all nodes, which allows each node to assign transmit power according to its local observation. The proposed scheme has low implementation complexity. Numerical results show that the proposed power control policy can significantly improve information freshness. The scheme is well adapted to variants of network environment and heterogeneous source-destination distance. Further, we evaluate the effect of the retransmission mechanism and updating patterns on the AoI performance.},
  archive      = {J_TMC},
  author       = {Meiyan Song and Howard H. Yang and Hangguan Shan and Jemin Lee and Tony Q. S. Quek},
  doi          = {10.1109/TMC.2021.3139666},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {3123-3136},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Age of information in wireless networks: Spatiotemporal analysis and locally adaptive power control},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Workload re-allocation for edge computing with server
collaboration: A cooperative queueing game approach. <em>TMC</em>,
<em>22</em>(5), 3095–3111. (<a
href="https://doi.org/10.1109/TMC.2021.3128887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a long-term workload management problem for multi-server edge computing with server collaboration is studied. In the considered model, mobile users’ computation-intensive tasks are generated dynamically over the time and offloaded to associated edge servers according to pre-determined subscription agreements. Upon receiving the subscribed workload, each edge server can then decide to whether participate in server collaboration for enabling workload re-allocation (i.e., workload exchange) with other heterogeneously configured edge servers. Unlike most of the existing work, this paper takes into account both competitions and collaborations among strategic edge servers in sharing their computing capacities. To achieve the equilibrium for each edge server in minimizing its expected cost (including energy consumption, delay, transmission, configuration and pricing costs), a joint optimization is formulated for determining i) its amount of workload to undertake, ii) compensation price charged from peers, and iii) computing speed to adopt. To efficiently solve this problem, we propose a novel cooperative queueing game approach, which integrates a convex optimization, a core cost sharing scheme and a mapping rule. Theoretical analyses and extensive simulations are conducted to evaluate the performance of the proposed solution, and demonstrate its superiority over counterparts.},
  archive      = {J_TMC},
  author       = {Changyan Yi and Jun Cai and Tong Zhang and Kun Zhu and Bing Chen and Qiang Wu},
  doi          = {10.1109/TMC.2021.3128887},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {3095-3111},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Workload re-allocation for edge computing with server collaboration: A cooperative queueing game approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Workload characterization and traffic analysis for
reconfigurable intelligent surfaces within 6G wireless systems.
<em>TMC</em>, <em>22</em>(5), 3079–3094. (<a
href="https://doi.org/10.1109/TMC.2021.3124638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programmable metasurfaces constitute an emerging paradigm, envisaged to become a key enabling technology for Reconfigurable Intelligent Surfaces (RIS) due to their powerful control over electromagnetic waves. The HyperSurface (HSF) paradigm takes one step further by embedding a network of customized integrated circuit (IC) controllers within the device with the aim of adding intelligence, connectivity, and autonomy. However, little is known about the traffic that the network needs to support as the target electromagnetic function or boundary conditions change. In this paper, the framework of a methodology is introduced to characterize the workload of programmable metasurfaces which is then used to analyze the beam steering HSFs. The workload characterization leads to many useful insights into traffic behavior, including the spatio-temporal load incurred and the HSF limitations in terms of fine-grained tracking of moving targets. It is observed that the traffic is inherently bursty with an uneven spatial distribution of load and that finer resolution comes at the cost of an increased but less bursty load. An indoor mobility model indicates reasonable signaling load on the deployed surfaces. Finally, a statistical analysis on the traffic patterns is performed, showing that the incoming traffic can be well represented by an ON-OFF model.},
  archive      = {J_TMC},
  author       = {Taqwa Saeed and Sergi Abadal and Christos Liaskos and Andreas Pitsillides and Hamidreza Taghvaee and Albert Cabellos-Aparicio and Vassos Soteriou and Eduard Alarcón and Ian F. Akyildiz and Marios Lestas},
  doi          = {10.1109/TMC.2021.3124638},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {3079-3094},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Workload characterization and traffic analysis for reconfigurable intelligent surfaces within 6G wireless systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WiTraj: Robust indoor motion tracking with WiFi signals.
<em>TMC</em>, <em>22</em>(5), 3062–3078. (<a
href="https://doi.org/10.1109/TMC.2021.3133114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WiFi-based device-free motion tracking systems track persons without requiring them to carry any device. Existing work has explored signal parameters such as time-of-flight (ToF), angle-of-arrival (AoA), and Doppler-frequency-shift (DFS) extracted from WiFi channel state information (CSI) to locate and track people in a room. However, they are not robust due to unreliable estimation of signal parameters. ToF and AoA estimations are not accurate for current standards-compliant WiFi devices that typically have only two antennas and limited channel bandwidth. On the other hand, DFS can be extracted relatively easily on current devices but is susceptible to the high noise level and random phase offset in CSI measurement, which results in a speed-sign-ambiguity problem and renders ambiguous walking speeds. This paper proposes WiTraj, a device-free indoor motion tracking system using commodity WiFi devices. WiTraj improves tracking robustness from three aspects: 1) It significantly improves DFS estimation quality by using the ratio of the CSI from two antennas of each receiver, 2) To better track human walking, it leverages multiple receivers placed at different viewing angles to capture human walking and then intelligently combines the best views to achieve a robust trajectory reconstruction, and, 3) It differentiates walking from in-place activities, which are typically interleaved in daily life, so that non-walking activities do not cause tracking errors. Experiments show that WiTraj can significantly improve tracking accuracy in typical environments compared to existing DFS-based systems. Evaluations across 9 participants and 3 different environments show that the median tracking error &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$&amp;lt;2.5\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; for typical room-sized trajectories.},
  archive      = {J_TMC},
  author       = {Dan Wu and Youwei Zeng and Ruiyang Gao and Shenjie Li and Yang Li and Rahul C. Shah and Hong Lu and Daqing Zhang},
  doi          = {10.1109/TMC.2021.3133114},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {3062-3078},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {WiTraj: Robust indoor motion tracking with WiFi signals},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards nonintrusive and secure mobile two-factor
authentication on wearables. <em>TMC</em>, <em>22</em>(5), 3046–3061.
(<a href="https://doi.org/10.1109/TMC.2021.3133275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile devices are promising to apply two-factor authentication to improve system security. Existing solutions have certain limits of requiring extra user effort, which might seriously affect user experience and delay authentication time. In this paper, we propose PPGPass, a novel mobile two-factor authentication system, which leverages Photoplethysmography (PPG) sensors available in most wrist-worn wearables. PPGPass simultaneously performs a password/pattern/signature authentication and a physiological-based authentication. To realize both nonintrusive and secure, we design a two-stage algorithm to separate clean heartbeat signals from PPG signals contaminated by motion artifacts so that users do not have to deliberately keep their bodies still. In addition, to deal with noncancelable issues when biometrics are compromised, we design a repeatable and non-invertible method to generate cancelable feature templates as alternative credentials. We leverage the great power of Random Forest and Support Vector Data Description to detect adversaries and verify a user&#39;s identity. To the best of our knowledge, PPGPass is the first nonintrusive and secure mobile two-factor authentication based on PPG sensors. Extensive experiments demonstrate that PPGPass can achieve the false acceptance rate of 3.11% and the false recognition rate of 3.71%, which confirms its high effectiveness, security, and usability.},
  archive      = {J_TMC},
  author       = {Yetong Cao and Fan Li and Qian Zhang and Song Yang and Yu Wang},
  doi          = {10.1109/TMC.2021.3133275},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {3046-3061},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards nonintrusive and secure mobile two-factor authentication on wearables},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards 3D centimeter-level passive gesture tracking with
two WiFi links. <em>TMC</em>, <em>22</em>(5), 3031–3045. (<a
href="https://doi.org/10.1109/TMC.2021.3123694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WiFi-based passive gesture tracking plays a crucial role in promoting human-computer interface, due to its pervasive availability and cost-effectiveness. Prior works focus on tracking gestures on 2D sensing plane by aggregating multiple WiFi links (typically 2), with Uniform Linear Arrays (ULAs). However, gestures actually contain 3D spatial information instead of just 2D, thus interpreting the 3D traces as 2D may lead to enormous tracking errors. This paper aims at exploring the possibility of passively tracking 3D hand traces likewise leveraging two WiFi links with standard 3-element ULAs, and presents a generic 3D centimeter-level passive gesture tracking system, called CentiTrack-3D. To this end, we make two key observations: (1) The ULA-resolved angle contains the integrated information of the azimuth and elevation in 3D space, despite its inability to estimate azimuth and elevation separately. (2) The radial motion deviating from the sensing plane also leads to length variations of paths. Motivated by the observations, a 3D tracking model named Chaos is elaborately designed to deduce the hand 3D coordinates, so as to track the traces. Extensive experiments yield that CentiTrack-3D achieves an overall median tracking granularity of 2.5 cm in 3D space in case of diverse users and environment conditions.},
  archive      = {J_TMC},
  author       = {Zijun Han and Zhaoming Lu and Xiangming Wen and Lingchao Guo and Jingbo Zhao},
  doi          = {10.1109/TMC.2021.3123694},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {3031-3045},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards 3D centimeter-level passive gesture tracking with two WiFi links},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Throughput maximization of delay-aware DNN inference in edge
computing by exploring DNN model partitioning and inference parallelism.
<em>TMC</em>, <em>22</em>(5), 3017–3030. (<a
href="https://doi.org/10.1109/TMC.2021.3125949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) has emerged as a promising paradigm catering to overwhelming explosions of mobile applications, by offloading compute-intensive tasks to MEC networks for processing. The surging of deep learning brings new vigor and vitality to shape the prospect of intelligent Internet of Things (IoT), and edge intelligence arises to provision real-time deep neural network (DNN) inference services for users. To accelerate the processing of the DNN inference of a user request in an MEC network, the DNN inference model usually can be partitioned into two connected parts: one part is processed in the local IoT device of the request, and another part is processed in a cloudlet (edge server) in the MEC network. Also, the DNN inference can be further accelerated by allocating multiple threads of the cloudlet to which the request is assigned. In this paper, we study a novel delay-aware DNN inference throughput maximization problem with the aim to maximize the number of delay-aware DNN service requests admitted, by accelerating each DNN inference through jointly exploring DNN partitioning and multi-thread execution parallelism. Specifically, we consider the problem under both offline and online request arrival settings: a set of DNN inference requests is given in advance, and a sequence of DNN inference requests arrives one by one without the knowledge of future arrivals, respectively. We first show that the defined problems are NP-hard. We then devise a novel constant approximation algorithm for the problem under the offline setting. We also propose an online algorithm with a provable competitive ratio for the problem under the online setting. We finally evaluate the performance of the proposed algorithms through experimental simulations. Experimental results demonstrate that the proposed algorithms are promising},
  archive      = {J_TMC},
  author       = {Jing Li and Weifa Liang and Yuchen Li and Zichuan Xu and Xiaohua Jia and Song Guo},
  doi          = {10.1109/TMC.2021.3125949},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {3017-3030},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Throughput maximization of delay-aware DNN inference in edge computing by exploring DNN model partitioning and inference parallelism},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Streaming from the air: Enabling drone-sourced video
streaming applications on 5G open-RAN architectures. <em>TMC</em>,
<em>22</em>(5), 3004–3016. (<a
href="https://doi.org/10.1109/TMC.2021.3129094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enabling high data-rate uplink cellular connectivity for drones is a challenging problem, since a flying drone has a higher likelihood of having line-of-sight propagation to base stations that terrestrial UEs normally do not have line-of-sight to. This may result in uplink inter-cell interference and uplink performance degradation for the neighboring ground UEs when drones transmit at high data-rates (e.g., video streaming). We address this problem from a cellular operator’s standpoint to support drone-sourced video streaming of a point of interest. We propose a low-complexity, closed-loop control system for Open-RAN architectures that jointly optimizes the drone’s location in space and its transmission directionality to support video streaming and minimize its uplink interference impact on the network. We prototype and experimentally evaluate the proposed control system on a dedicated outdoor multi-cell RAN testbed, which is the first measurement campaign of its kind. Furthermore, we perform a large-scale simulation assessment of the proposed control system using the actual cell deployment topologies and cell load profiles of a major US cellular carrier. The proposed Open-RAN control scheme achieves an average &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$19\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; network capacity gain over traditional BS-constrained control solutions and satisfies the application data-rate requirements of the drone (e.g., to stream an HD video).},
  archive      = {J_TMC},
  author       = {Lorenzo Bertizzolo and Tuyen X. Tran and John Buczek and Bharath Balasubramanian and Rittwik Jana and Yu Zhou and Tommaso Melodia},
  doi          = {10.1109/TMC.2021.3129094},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {3004-3016},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Streaming from the air: Enabling drone-sourced video streaming applications on 5G open-RAN architectures},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Strategic information revelation mechanism in crowdsourcing
applications without verification. <em>TMC</em>, <em>22</em>(5),
2989–3003. (<a href="https://doi.org/10.1109/TMC.2021.3131445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a crowdsourcing problem, where a platform aims to incentivize distributed workers to provide high-quality and truthful solutions that are not verifiable. We focus on a largely overlooked yet pratically important asymmetric information scenario, where the platform knows more information regarding workers’ average solution accuracy and can strategically reveal such information to workers. Workers will utilize the announced information to determine the likelihood of obtaining a reward. We first study the case where the platform and workers share the same prior regarding the average worker accuracy (but only the platform observes the realized value). We consider two types of workers: (1) naive workers who fully trust the platform&#39;s announcement, and (2) strategic workers who update prior belief based on the announcement. For naive workers, we show that the platform should always announce a high average accuracy to maximize its payoff. However, this is not always optimal when facing strategic workers, and the platform may benefit from announcing an average accuracy lower than the actual value. We further study the more challenging non-common prior case, and show the counter-intuitive result that when the platform is uninformed of the workers’ prior, both the platform payoff and the social welfare may decrease as the high accuracy workers’ solutions become more accurate.},
  archive      = {J_TMC},
  author       = {Chao Huang and Haoran Yu and Jianwei Huang and Randall A. Berry},
  doi          = {10.1109/TMC.2021.3131445},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2989-3003},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Strategic information revelation mechanism in crowdsourcing applications without verification},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reusing delivery drones for urban crowdsensing.
<em>TMC</em>, <em>22</em>(5), 2972–2988. (<a
href="https://doi.org/10.1109/TMC.2021.3127212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the increasing number and massive coverage, delivery drones, equipped with various sensors, have demonstrated significant but unexplored potentials for large-scale and low-cost urban sensing during package delivery. In this paper, we propose novel studies on the reutilization of such delivery drone resources to fill this void in urban crowdsensing. Accounting for interdependency between flying/sensing and drone delivery weight, we jointly optimize route selection, sensing time, and delivery weight allocation, to maximize delivery and sensing utility under drones’ energy constraints. This problem is formulated as a non-convex mixed-integer non-Linear programming problem, which is proved to be NP-hard. To address this intricate problem, we propose near-optimal algorithms that leverage the equivalent objective function construction, the local search scheme, and the alternating iteration technique. Theoretical analysis indicates that our algorithms can achieve &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\frac{1}{4+\varepsilon }$&lt;/tex-math&gt;&lt;/inline-formula&gt; -approximation ratio (where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\varepsilon$&lt;/tex-math&gt;&lt;/inline-formula&gt; is an arbitrarily small positive parameter) and the convergence guarantee in polynomial time, for the scenarios of fixed and adjustable delivery weights, respectively. Extensive trace-based simulations, field experiments, and the real-world application demonstrate that ours can significantly improve the delivery &amp; sensing utility by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$124.7\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; and the energy utilization rate by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$72.2\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; on average, compared with the drone delivery without reusing.},
  archive      = {J_TMC},
  author       = {Chaocan Xiang and Yanlin Zhou and Haipeng Dai and Yuben Qu and Suining He and Chao Chen and Panlong Yang},
  doi          = {10.1109/TMC.2021.3127212},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2972-2988},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reusing delivery drones for urban crowdsensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Providing worst-case latency guarantees with collaborative
edge servers. <em>TMC</em>, <em>22</em>(5), 2955–2971. (<a
href="https://doi.org/10.1109/TMC.2021.3133306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) is a promising computing paradigm that provides cloud computing services in proximity to end users. Due to the bursty and spatially imbalanced arrival of computation tasks, the workload on different edge servers may vary wildly. To improve the Quality of Experience (QoE), peer offloading has been proposed as an effective cooperation method that offloads tasks from busy edge servers to idle ones. Although the average latency has been extensively considered in the design of peer offloading strategies, the worst-case latency, a common Quality of Service (QoS) requirement that is usually demanded by latency-sensitive applications, yet receives much less attention. In this paper, we study the task scheduling among collaborative edge servers and propose an online algorithm that aims to maximize the system utility under the worst-case latency requirement and long-term energy consumption constraints. Both theoretical analysis and simulation results demonstrate that our algorithm performs well under various situations.},
  archive      = {J_TMC},
  author       = {Xingqiu He and Sheng Wang and Xiong Wang},
  doi          = {10.1109/TMC.2021.3133306},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2955-2971},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Providing worst-case latency guarantees with collaborative edge servers},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PhaseAnti: An anti-interference WiFi-based activity
recognition system using interference-independent phase component.
<em>TMC</em>, <em>22</em>(5), 2938–2954. (<a
href="https://doi.org/10.1109/TMC.2021.3127721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by a wide range of essential applications, significant achievements have recently been made to explore WiFi-based Human Activity Recognition (HAR) techniques that utilize the information collected by commercial off-the-shelf (COTS) WiFi infrastructures to infer human activities without the need for the subject to carry any devices. Although existing WiFi-based HAR systems achieve satisfactory performance in some instances, they are faced with a severe challenge that the impacts of ubiquitous Co-channel Interference (CCI) on WiFi signals are inevitable. This downgrades the performance of these HAR systems significantly. To address this challenge, we propose PhaseAnti in this paper, a novel WiFi-based HAR system to exploit the CCI-independent phase component, Nonlinear Phase Error Variation (NLPEV), of WiFi Channel State Information (CSI) to cope with the negative effects of CCI. The stability of NLPEV data and the sensibility of this component to motions are rigorously analyzed. Furthermore, validated by extensive properly designed experiments, this phase component across subcarriers is invariant under various CCI scenarios while sufficiently distinct for different motions. Therefore, the NLPEV data can be used and processed effectively to perform HAR in CCI scenarios. Extensive experiments with various daily activities in different indoor rooms demonstrate the superior effectiveness and generalizability of the proposed PhaseAnti system under various CCI scenarios. Specifically, PhaseAnti achieves a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ 96.5\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; recognition accuracy rate (RAR) on average in different CCI scenarios, which can improve up to a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ 16.7\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; RAR compared with the amplitude component in the presence of CCI. Furthermore, the recognition speed is 10.3 × faster than the state-of-the-art solution.},
  archive      = {J_TMC},
  author       = {Jinyang Huang and Bin Liu and Chenglin Miao and Yan Lu and Qijia Zheng and Yu Wu and Jiancun Liu and Lu Su and Chang Wen Chen},
  doi          = {10.1109/TMC.2021.3127721},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2938-2954},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PhaseAnti: An anti-interference WiFi-based activity recognition system using interference-independent phase component},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Path planning for adaptive CSI map construction with A3C in
dynamic environments. <em>TMC</em>, <em>22</em>(5), 2925–2937. (<a
href="https://doi.org/10.1109/TMC.2021.3131318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand of Location-Based Service, the fingerprint localization based on Channel State Information (CSI) has become a vital positioning technology because it has easy implementation, low device cost and adequate accuracy which benefits from fine-grained information provided by CSI. However, the main drawback is that the approach has to construct the fingerprint map manually during the off-line stage, which is tedious and time-consuming. In this paper, we propose a novel data collection strategy for path planning based on reinforcement learning, namely Asynchronous Advantage Actor-Critic (A3C). Given the limited exploration step length, it needs to maximize the informative CSI data for reducing manual cost. We collect a small amount of real data in advance to predict the rewards of all sampling points by multivariate Gaussian process and mutual information. Then the optimization problem is transformed into a sequential decision process, which can exploit the informative path by A3C. We complete the proposed algorithm in two real-world dynamic environments and extensive experiments verify its performance. Compared to coverage path planning and several existing algorithms, our system not only can achieve similar indoor localization accuracy, but also reduce the CSI collection task.},
  archive      = {J_TMC},
  author       = {Xiaoqiang Zhu and Tie Qiu and Wenyu Qu and Xiaobo Zhou and Yifan Wang and Dapeng Oliver Wu},
  doi          = {10.1109/TMC.2021.3131318},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2925-2937},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Path planning for adaptive CSI map construction with A3C in dynamic environments},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Orchestrating energy-efficient vRANs: Bayesian learning and
experimental results. <em>TMC</em>, <em>22</em>(5), 2910–2924. (<a
href="https://doi.org/10.1109/TMC.2021.3123794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtualized base stations (vBS) can be implemented in diverse commodity platforms and are expected to bring unprecedented operational flexibility and cost efficiency to the next generation of cellular networks. However, their widespread adoption is hampered by their complex configuration options that affect in a non-traditional fashion both their performance and their power consumption. Following an in-depth experimental analysis in a bespoke testbed, we characterize the vBS power consumption profile and reveal previously unknown couplings between their various control knobs. Motivated by these findings, we develop a Bayesian learning framework for the orchestration of vBSs and design two novel algorithms: ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$i$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) BP-vRAN, which employs online learning to balance the vBS performance and energy consumption, and ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ii$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) SBP-vRAN, which augments our optimization approach with safe controls that maximize performance while respecting hard power constraints. We show that our approaches are data-efficient , i.e., converge an order of magnitude faster than state-of-the-art Deep Reinforcement Learning methods, and achieve optimal performance. We demonstrate the efficacy of these solutions in an experimental prototype using real traffic traces.},
  archive      = {J_TMC},
  author       = {Jose A. Ayala-Romero and Andres Garcia-Saavedra and Xavier Costa-Perez and George Iosifidis},
  doi          = {10.1109/TMC.2021.3123794},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2910-2924},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Orchestrating energy-efficient vRANs: Bayesian learning and experimental results},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online organizing large-scale heterogeneous tasks and
multi-skilled participants in mobile crowdsensing. <em>TMC</em>,
<em>22</em>(5), 2892–2909. (<a
href="https://doi.org/10.1109/TMC.2021.3132616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online gathering large-scale heterogeneous tasks and multi-skilled participant can make the tasks and participants to be shared in real time. However, their online gathering will bring many intractable objective requirements, which makes task-participant matching become extremely complex. To cope well with the gathering, we design a hierarchy tree and time-series queue to organize tasks and participants. The data structures we designed can effectively meet all requirements that are brought due to tasks and participants gathering online. In addition, based on the designed data structures, we study online large-scale heterogeneous task allocation problem from three aspects: the computing pattern, the tree creation method, and the extension of matching strategy. Our best method (TsPY) is based on parallel computing in the computing pattern, adopts time first and then space in the tree creation method, and increases the short-distance first strategy in the matching strategy. Finally, we conducted detailed experiments under the conditions of different participant geographical distributions (i.e., uniform distribution, Gaussian distribution, and check-in empirical distribution), different sensing methods (i.e., participatory sensing and opportunistic sensing), and different recommendation methods (i.e., point recommendation and trajectory recommendation). The experimental results show that TsPY has a good performance in multiple indicators such as algorithm running time, task-participant matching rate, participant travel distance, and redundant tasks removed. Compared with serial computing, parallel computing can reduce the algorithm running time by more than 66% on average in our experimental environment. Compared with space first and then time, creating a tree based on time first and then space can increase task-participant matching rate by more than 13% on average. Increasing the short-distance first strategy can reduce the participant travel distance by more than 4% on average.},
  archive      = {J_TMC},
  author       = {Lei Han and Zhiwen Yu and Zhiyong Yu and Liang Wang and Houchun Yin and Bin Guo},
  doi          = {10.1109/TMC.2021.3132616},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2892-2909},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online organizing large-scale heterogeneous tasks and multi-skilled participants in mobile crowdsensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On-device deep multi-task inference via multi-task zipping.
<em>TMC</em>, <em>22</em>(5), 2878–2891. (<a
href="https://doi.org/10.1109/TMC.2021.3124306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future mobile devices are anticipated to perceive, understand and react to the world on their own by running multiple correlated deep neural networks locally on-device. Yet the complexity of these deep models needs to be trimmed down both within-model and cross-model to fit in mobile storage and memory. Previous studies squeeze the redundancy within a single model. In this work, we aim to reduce the redundancy across multiple models. We propose Multi-Task Zipping (MTZ), a framework to automatically merge correlated, pre-trained deep neural networks for cross-model compression. Central in MTZ is a layer-wise neuron sharing and incoming weight updating scheme that induces a minimal change in the error function. MTZ inherits information from each model and demands light retraining to re-boost the accuracy of individual tasks. MTZ supports typical network layers (fully-connected, convolutional and residual) and applies to inference tasks with different input domains. Evaluations show that MTZ can fully merge the hidden layers of two VGG-16 networks with a 3.18% increase in the test error averaged on ImageNet for object classification and CelebA for facial attribute classification, or share &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$39.61\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; parameters between the two networks with &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$&amp;lt;0.5\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; increase in the test errors. The number of iterations to retrain the combined network is at least &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$17.8\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; lower than that of training a single VGG-16 network. Moreover, MTZ can effectively merge nine residual networks for diverse inference tasks and models for different input domains. And with the model merged by MTZ, the latency to switch between these tasks on memory-constrained devices is reduced by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$8.71{\times}$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Xiaoxi He and Xu Wang and Zimu Zhou and Jiahang Wu and Zheng Yang and Lothar Thiele},
  doi          = {10.1109/TMC.2021.3124306},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2878-2891},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On-device deep multi-task inference via multi-task zipping},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On DoF conservation in MIMO interference cancellation based
on signal strength in the eigenspace. <em>TMC</em>, <em>22</em>(5),
2862–2877. (<a href="https://doi.org/10.1109/TMC.2021.3126449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Degree-of-freedom (DoF)-based models have been proven to be highly successful in modeling and analysis of MIMO systems. Among existing DoF-based models, the number of DoFs used for interference cancellation (IC) is solely based on the number of interfering data streams. However, from both experimental and simulation results, we find that signal strengths of an interference link vary significantly in different directions in the eigenspace. In this paper, we exploit the difference in interference signal strengths in the eigenspace and perform IC with DoFs only on those directions with strong signals. To differentiate interference signal strengths on an interference link, we introduce a novel concept called “effective rank threshold.” Based on this threshold, DoFs are consumed only to cancel strong interferences in the eigenspace while weak interferences are treated as noise in throughput calculation. To better understand the benefits of this approach, we study a fundamental trade-off between network throughput and effective rank threshold for an MU-MIMO network. Our simulation results show that network throughput under optimal rank threshold is significantly higher than that under existing DoF IC models. To ensure the new DoF IC model is feasible at PHY layer, we propose an algorithm to set the weights for all nodes that can offer our desired DoF allocation.},
  archive      = {J_TMC},
  author       = {Yongce Chen and Shaoran Li and Chengzhang Li and Huacheng Zeng and Brian Jalaian and Y. Thomas Hou and Wenjing Lou},
  doi          = {10.1109/TMC.2021.3126449},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2862-2877},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On DoF conservation in MIMO interference cancellation based on signal strength in the eigenspace},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nothing wasted: Full contribution enforcement in federated
edge learning. <em>TMC</em>, <em>22</em>(5), 2850–2861. (<a
href="https://doi.org/10.1109/TMC.2021.3123195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive amount of data generated at the network edge makes mobile edge computing an essential technology to support real-time applications, calling for powerful data processing and analysis provided by machine learning (ML) techniques. In particular, federated edge learning (FEL) becomes prominent in securing the privacy of data owners by keeping the data locally used to train ML models. Existing studies on FEL either utilize in-process optimization or remove unqualified participants in advance. In this paper, we enhance the collaboration from all edge devices in FEL to guarantee that the ML model is trained using all available local data to accelerate the learning process. To that aim, we propose a collective extortion (CE) strategy under the imperfect-information multi-player FEL game, which is proved to be effective in helping the server efficiently elicit the full contribution of all devices without worrying about suffering from any economic loss. Technically, our proposed CE strategy extends the classical extortion strategy in controlling the proportionate share of expected utilities for a single opponent to the swiftly homogeneous control over a group of players, which further presents an attractive trait of being impartial for all participants. Moreover, the CE strategy enriches the game theory hierarchy, facilitating a wider application scope of the extortion strategy. Both theoretical analysis and experimental evaluations validate the effectiveness and fairness of our proposed scheme.},
  archive      = {J_TMC},
  author       = {Qin Hu and Shengling Wang and Zehui Xiong and Xiuzhen Cheng},
  doi          = {10.1109/TMC.2021.3123195},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2850-2861},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Nothing wasted: Full contribution enforcement in federated edge learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MVSTGN: A multi-view spatial-temporal graph network for
cellular traffic prediction. <em>TMC</em>, <em>22</em>(5), 2837–2849.
(<a href="https://doi.org/10.1109/TMC.2021.3129796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely and accurate cellular traffic prediction is difficult to achieve due to the complex spatial-temporal characteristics of cellular traffic. The latest approaches mainly aim to model local spatial-temporal dependencies of cellular traffic based on deep learning techniques but lack the consideration of diverse global spatial-temporal correlations hidden in cellular traffic. To tackle this issue, we propose a novel multi-view spatial-temporal graph network (MVSTGN), which combines attention and convolution mechanisms into traffic pattern analysis, enabling the comprehensive excavation of spatial-temporal characteristics. Specifically, the MVSTGN realizes the above statement from three spatial-temporal views: 1) From a global spatial view, two spatial attention modules are proposed to capture the global spatial correlations between different regions at node and trend levels; 2) From a global temporal view, a temporal attention module is employed to capture and encode global temporal correlations between traffic at different times; 3) From a local spatial-temporal view, a dense convolution module is developed to further excavate the local spatial-temporal dependencies in cellular traffic. Consequently, a successful cellular traffic prediction strategy is constructed to fully explore the spatial-temporal characteristics from multiple views. The experimental results on a popular real-world cellular traffic dataset demonstrate that the MVSTGN achieves obvious improvements over baselines.},
  archive      = {J_TMC},
  author       = {Yang Yao and Bo Gu and Zhou Su and Mohsen Guizani},
  doi          = {10.1109/TMC.2021.3129796},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2837-2849},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MVSTGN: A multi-view spatial-temporal graph network for cellular traffic prediction},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective approach for user association to improve
load balancing and blockage in millimeter wave cellular networks.
<em>TMC</em>, <em>22</em>(5), 2818–2836. (<a
href="https://doi.org/10.1109/TMC.2021.3122972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the leading enabling technologies of 5G wireless networks is to use the millimeter wave spectrum band. Despite its large and wide frequency bandwidth, the obtained data rate can be diminished due to link blockage in this frequency band. In this paper, we formulate a bi-objective optimization problem to optimize user association in cellular networks with millimeter wave enabled base stations. The two objectives to minimize are maximum base station utility and blockage score (to indicate the chance of a link getting blocked). We simulate three different scalarization methods to turn a bi-objective vector into a scalar. Since the combinatorial bi-objective problem is NP-Hard, we conduct Lagrangian dual analysis on all of the scalarization methods. Solving the dual problem decreases the time complexity of the solver algorithm, but the solution has a distance from the optimal point created by solving the primal. We also solve the primal optimization problem with a single objective optimization tool. Compared to the time complexity of the primal problem of scalarization methods, the time complexities of solutions to the dual problems are lower. The results show that our solution to the bi-objective optimization problem has a better outcome in terms of the number of link blockage and the maximum base station utility compared to optimizing each objective alone.},
  archive      = {J_TMC},
  author       = {Masoud Zarifneshat and Proteek Roy and Li Xiao},
  doi          = {10.1109/TMC.2021.3122972},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2818-2836},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-objective approach for user association to improve load balancing and blockage in millimeter wave cellular networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mobile measurement of a dynamic field via compressed
sensing. <em>TMC</em>, <em>22</em>(5), 2802–2817. (<a
href="https://doi.org/10.1109/TMC.2021.3125201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, measuring dynamic signals at points of interest (POIs) using a mobile agent is considered, where the agent is required to repeatedly measure at and transit between the POIs. Dynamic field sensing is needed in areas ranging from nanomechanical mapping of live sample to crop monitoring. Existing work on mobile sensing, however, has been focused on cooperatively tracking one or few known or unknown POIs, whereas the dynamics of the signals is ignored. Challenges arise from capturing and recovering the dynamics at each POI by using the data intermittently measured by the mobile agent, resulting in temporal-spatial coupling in mobile sensing. Moreover, trade off between the sensing cost and the performance needs to be addressed. We propose a compressed-sensing based approach to tackle this problem. First, a check-and-removal process based on random permutation and partition of the measurement periods is developed to avoid the temporal-spatial coupling under the agent speed constraint. Then a shuffle-and-pair process based on the simulate-annealing is proposed to minimize the transition distance while preserving the performance. It is shown that the distribution of the measurement periods between the POIs converges. The proposed approach is illustrated through a simulation study of measuring the temperature-dependent nanomechanical variations of a polymer sample.},
  archive      = {J_TMC},
  author       = {Tianwei Li and Qingze Zou},
  doi          = {10.1109/TMC.2021.3125201},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2802-2817},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobile measurement of a dynamic field via compressed sensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MagneComm+: Near-field electromagnetic induction
communication with magnetometer. <em>TMC</em>, <em>22</em>(5),
2789–2801. (<a href="https://doi.org/10.1109/TMC.2021.3133481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Near-field communication (NFC) technology emerges as a vital role with appealing benefits for users to improve mobile device’s functionality. Although today’s most smartphones and smartwatches come with NFC support, other mobile devices (e.g., PC and laptops) and IoT devices that don’t equip with dedicated radio modules cannot take advantage of wide-scale NFC capability. We design and develop MagneComm+ , an NFC-like implementation scheme without dedicated hardware and propose a novel near-field communication protocol that is applicable to almost all mobile devices and IoT devices. The key idea is to utilize the electromagnetic induction (EMI) signal emitted from the computing devices (e.g., CPUs) and captured by magnetometers on mobile devices for communication. We tackle challenges in data encoding/decoding , preamble detection , retransmission and error correction , multi-transmitter , and full-duplex schemes, to efficiently generate and reliably receive EMI signal with the hardware available on devices. We prototype MagneComm+ on both between laptops and smartphones, as well as between two laptops with an external magnetometer. Extensive evaluation results show that our MagneComm+ supports around &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$10~cm$&lt;/tex-math&gt;&lt;mml:math&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;mml:mspace width=&quot;3.33333pt&quot;/&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;pan-ieq1-3133481.gif&quot;/&gt;&lt;/inline-formula&gt; communication distance with average 110 bps (bit per second) data rate on the normal-speed mode, and maximum 17.28 kbps on the full-speed mode.},
  archive      = {J_TMC},
  author       = {Guangtao Xue and Hao Pan and Yi-Chao Chen and Xiaoyu Ji and Jiadi Yu},
  doi          = {10.1109/TMC.2021.3133481},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2789-2801},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MagneComm+: Near-field electromagnetic induction communication with magnetometer},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint access point placement and power-channel-resource-unit
assignment for IEEE 802.11ax-based dense WiFi network with QoS
requirements. <em>TMC</em>, <em>22</em>(5), 2771–2788. (<a
href="https://doi.org/10.1109/TMC.2021.3129596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IEEE 802.11ax is the standard for the new generation WiFi networks. In this paper, we formulate the problem of joint access point (AP) placement and power-channel-resource unit assignment for 802.11ax-based dense WiFi. The objective is to minimize the number of APs. Two quality-of-service (QoS) requirements are to be fulfilled: (1) a two-tier throughput requirement which ensures that the throughput of each station is good enough, and (2) a fault tolerance requirement which ensures that the stations could still use WiFi even when some APs fail. We prove that this problem is NP-hard. To tackle this problem, we first develop an analytic model to derive the throughput of each station under the OFDMA mechanism and a widely used interference model. We then design a heuristic algorithm to find high-quality solutions with polynomial time complexity. Simulation results under both fixed-user and mobile-user cases show that: (1) when the area is small (50 × 50 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\rm m^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; ), our algorithm gives the optimal solutions; when the area is larger (80 × 60 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\rm m^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; ), our algorithm can reduce the number of APs by 34.9-87.7% as compared to the Random and Greedy algorithms. (2) Our algorithm can always get feasible solutions that fulfill the QoS requirements.},
  archive      = {J_TMC},
  author       = {Shuwei Qiu and Xiaowen Chu and Yiu-Wing Leung and Joseph Kee-Yin Ng},
  doi          = {10.1109/TMC.2021.3129596},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2771-2788},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint access point placement and power-channel-resource-unit assignment for IEEE 802.11ax-based dense WiFi network with QoS requirements},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HearFit+: Personalized fitness monitoring via audio signals
on smart speakers. <em>TMC</em>, <em>22</em>(5), 2756–2770. (<a
href="https://doi.org/10.1109/TMC.2021.3125684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fitness can help to strengthen muscles, increase resistance to diseases, and improve body shape. Nowadays, a great number of people choose to exercise at home/office rather than at the gym due to lack of time. However, it is difficult for them to get good fitness effects without professional guidance. Motivated by this, we propose the first personalized fitness monitoring system, HearFit &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;/inline-formula&gt; , using smart speakers at home/office. We explore the feasibility of using acoustic sensing to monitor fitness. We design a fitness detection method based on Doppler shift and adopt the short time energy to segment fitness actions. Based on deep learning, HearFit &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;/inline-formula&gt; can perform fitness classification and user identification at the same time. Combined with incremental learning, users can easily add new actions. We design 4 evaluation metrics (i.e., duration, intensity, continuity, and smoothness) to help users to improve fitness effects. Through extensive experiments including over 9,000 actions of 10 types of fitness from 12 volunteers, HearFit &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;/inline-formula&gt; can achieve an average accuracy of 96.13% on fitness classification and 91% accuracy for user identification. All volunteers confirm that HearFit &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^+$&lt;/tex-math&gt;&lt;/inline-formula&gt; can help improve the fitness effect in various environments.},
  archive      = {J_TMC},
  author       = {Yadong Xie and Fan Li and Yue Wu and Yu Wang},
  doi          = {10.1109/TMC.2021.3125684},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2756-2770},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HearFit+: Personalized fitness monitoring via audio signals on smart speakers},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HA2RS: HTTP adaptive augmented reality streaming system.
<em>TMC</em>, <em>22</em>(5), 2741–2755. (<a
href="https://doi.org/10.1109/TMC.2021.3132665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel HTTP adaptive augmented reality (AR) streaming system. The goal of the proposed system is to provide high quality AR streaming services with low latency through a time-varying wireless network. In the proposed system, we employ a progressive mesh technique to enhance the scalability of AR streaming services, and adopt the metafile structure to support various attributes of progressive meshes necessary for rendering, displaying, and scheduling according to wireless network conditions. Based on this metafile, the proposed system requests the next chunk among AR contents to improve human visual perceptual quality considering the displaying scale values of AR contents on the screen. The proposed system is fully implemented by using well-known open sources (e.g., Android, OpenCV, OpenGL, and Nexus) and C/C++. Finally, the system is examined in real wireless network environments.},
  archive      = {J_TMC},
  author       = {Hyunmin Noh and Hwangjun Song},
  doi          = {10.1109/TMC.2021.3132665},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2741-2755},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HA2RS: HTTP adaptive augmented reality streaming system},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fronthaul-aware scheduling strategies for dynamic modulation
compression in next generation RANs. <em>TMC</em>, <em>22</em>(5),
2725–2740. (<a href="https://doi.org/10.1109/TMC.2021.3128700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next generation Radio Access Networks (RANs) consider virtualized architectures in which base station functions are distributed in different logical nodes, connected through fronthaul (FH) links. To reduce the FH deployment costs and the required FH capacity, operators may install a single FH link shared among multiple cells and exploit key enabling techniques, such as modulation compression, to reduce FH data. In shared FH capacity scenarios, it is essential to provide efficient methods to control and optimize the FH resources’ utilization with limited impact on the air interface performance. In this paper, a multi-cell multi-user scenario with a shared FH link across multiple cells is considered. We focus on optimizing the resource allocation and modulation compression of each user, in a centralized and dynamic manner, aiming to maximize the air interface performance subject to a shared FH capacity constraint. The problem is formulated as a convex optimization problem, which allows deriving the optimal resource allocation and modulation compression per user. Then, we evaluate the proposed FH-aware scheduling methods against baseline holistic strategies over an end-to-end dynamic 5G NR system-level simulator based on ns-3. Under a tight available FH capacity, results show gains that vary from 16% to 567% in different percentile statistics of the user-perceived throughput.},
  archive      = {J_TMC},
  author       = {Sandra Lagén and Xavier Gelabert and Lorenza Giupponi and Andreas Hansson},
  doi          = {10.1109/TMC.2021.3128700},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2725-2740},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fronthaul-aware scheduling strategies for dynamic modulation compression in next generation RANs},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy-efficient overlay protocol for BLE beacon-based mesh
network. <em>TMC</em>, <em>22</em>(5), 2709–2724. (<a
href="https://doi.org/10.1109/TMC.2021.3133538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bluetooth Low Energy (BLE) beacons are designed to operate for years on a coin-cell battery. However, the formation of a mesh network, overlaying on the existing Bluetooth Low Energy (BLE) beacons infrastructure, can severely degrade the lifetime of underlying beacons owing to the excessive current drawn by the scanning event. Even though we can sustain the lifetime of the underlying beacon with duty-cycle scanning, such duty-cycle scanning imposes another challenge to the overlay mesh in disseminating the packet. To this end, this paper proposes a novel overlay protocol that: 1) employs duty-cycle scanning to guarantee the lifetime of the underlying beacon, while 2) defining a set of scanning policies to increase the packet dissemination rate through the overlay mesh network. The duty-cycle scanning defines the scanning time slot based on the lowest feasible duty cycle unveiled through a comprehensive analysis of energy consumed by advertising and scanning events. The scanning policies, on the other hand, allow each node to explore all possible time slots before locking their scanning event to a particular time slot that is most likely to hear the incoming packet. Extensive experiments with practical implementation demonstrate the feasibility of our proposed overlay mesh for real-world use cases.},
  archive      = {J_TMC},
  author       = {Pai Chet Ng and James She and Petros Spachos},
  doi          = {10.1109/TMC.2021.3133538},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2709-2724},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient overlay protocol for BLE beacon-based mesh network},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Embracing channel estimation in multi-packet reception of
ZigBee. <em>TMC</em>, <em>22</em>(5), 2693–2708. (<a
href="https://doi.org/10.1109/TMC.2021.3131472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a low-power and low-cost wireless protocol, the promising ZigBee has been widely used in sensor networks and cyber-physical systems. Since ZigBee based networks usually adopt tree or cluster topology, the convergecast scenarios are common in which multiple transmitters send packets to one receiver, leading to the severe collision problem. The conventional ZigBee adopts carrier sense multiple access with collisions avoidance to avoid collisions, which introduces additional time/energy overhead. The state-of-the-art methods resolve collisions instead of avoidance, in which mZig decomposes a collision by the collision itself and reZig decodes a collision by comparing with reference waveforms. However, mZig falls into high decoding errors only exploiting the signal amplitudes while reZig incurs high computational complexity for waveform comparison. In this paper, we propose CmZig to embrace channel estimation in multiple-packet reception (MPR) of ZigBee, which effectively improves MPR via lightweight computing used for channel estimation and collision decomposition. First, CmZig enables accurate collision decomposition with low computational complexity, which uses the estimated channel parameters modeling both signal amplitudes and phases. Second, CmZig adopts reference waveform comparison only for collisions without chip-level time offsets, instead of the complex machine learning based method. We implement CmZig on USRP-N210 and establish a six-node testbed. Results show that CmZig achieves a bit error rate in the order of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$10^{-3}$&lt;/tex-math&gt;&lt;/inline-formula&gt; and more than 80% packet reception rate, which outperforms state-of-the-art mZig.},
  archive      = {J_TMC},
  author       = {Zhe Wang and Linghe Kong and Xue Liu and Guihai Chen},
  doi          = {10.1109/TMC.2021.3131472},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2693-2708},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Embracing channel estimation in multi-packet reception of ZigBee},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Elliptic localization of a moving object by transmitter at
unknown position and velocity: A semidefinite relaxation approach.
<em>TMC</em>, <em>22</em>(5), 2675–2692. (<a
href="https://doi.org/10.1109/TMC.2021.3123330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the elliptic localization for moving object problem from time delay (TD) and Doppler frequency shift (DFS) measurements, where the transmitter position and velocity are unknown. The transmitter is not perfectly time synchronized such that unknown offsets exist in the TD and DFS measurements. We propose to jointly estimate the object and transmitter positions and velocities and the offsets. Using the TD and DFS measurements from both the indirect and direct paths between the transmitter and the receivers, we formulate a non-convex weighted least squares (WLS) problem. Local convergence may occur when solving the non-convex WLS problem, implying that good estimate is not guaranteed. Thus, we relax the non-convex WLS problem into a convex semidefinite program by applying semidefinite relaxation (SDR). Moreover, we theoretically show that the performance can be improved by using multiple transmitters as compared to that using single transmitter, although more unknown parameters are introduced. We then extend the proposed SDR method to handle the multiple transmitters case. Finally, the mean square error analysis is provided to show that the proposed WLS method reaches the Cramer-Rao lower bound accuracy under small Gaussian noise condition. Simulation results validate the theoretical analysis and show the superior performance over the existing methods.},
  archive      = {J_TMC},
  author       = {Gang Wang and Ruichao Zheng and K. C. Ho},
  doi          = {10.1109/TMC.2021.3123330},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2675-2692},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Elliptic localization of a moving object by transmitter at unknown position and velocity: A semidefinite relaxation approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic reservation of edge servers via deep reinforcement
learning for connected vehicles. <em>TMC</em>, <em>22</em>(5),
2661–2674. (<a href="https://doi.org/10.1109/TMC.2021.3123135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is promising for connected vehicles. As vehicles move, their resource demands for edge servers vary. Thus, it is necessary to reserve edge servers dynamically to meet variable demands. Existing schemes of edge-server reservation usually rely on statistical information of resource demands to make reservations; they are infeasible for connected vehicles, since such schemes are not adaptive to time-varying demands. To this end, a spatio-temporal reinforcement learning scheme called DeepReserve is developed to learn variable demands and then conduct edge-server reservation. Its design is based on the deep deterministic policy gradient algorithm of deep reinforcement learning (DRL), but is featured with several enhancements. First, the fully-connected neural network in DRL is replaced by a convolutional LSTM (ConvLSTM) network to extract spatio-temporal features of resource demands, which highly improves the prediction accuracy of resource demands. Thus, the actions in DRL (i.e., reservation decisions) can adapt to future demands. Second, an action amender is designed to ensure the actions selected by the neural network follow the spatio-temporal correlation. Finally, a training method called DR-Train is designed to stabilize the training procedure for different traffic patterns. DeepReserve is evaluated through extensive experiments on real-world datasets. Results show that it outperforms state-of-the-art approaches.},
  archive      = {J_TMC},
  author       = {Jiawei Zhang and Suhong Chen and Xudong Wang and Yifei Zhu},
  doi          = {10.1109/TMC.2021.3123135},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2661-2674},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic reservation of edge servers via deep reinforcement learning for connected vehicles},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic preamble resource distribution for random access in
5G new radio systems. <em>TMC</em>, <em>22</em>(5), 2645–2660. (<a
href="https://doi.org/10.1109/TMC.2021.3122983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millimeter wave (mmWave) spectrum promises unprecedented data rates in 5G New Radio (NR). However, mmWave links are susceptible to severe path and propagation losses. Implementation of directional antennas that can manifest multiple beams becomes necessary at 5G base stations (gNBs) and User Equipments (UEs). Random access procedure (RAP), which is the first stage to establish connections to gNB, in its current state would be inadequate for such systems. To support RAP, 5G NR introduced mapping of different subsets of preambles in Physical Random Access Channel (PRACH) to different beams. We explore changes in RAP due to preamble-beam mapping and present a novel online algorithm to dynamically distribute preambles amongst beams to achieve fair access opportunities. The proposed algorithm can also eliminate overload problem of the beams with large UE population especially for high arrival rates. We extend the proposed algorithm to be applicable for RAP with access class barring mechanism which enables UEs to transmit a preamble with an optimal probability and, therefore, reduce access congestion. Through extensive simulations, we validate the efficiency of our proposed algorithms in providing fair channel access opportunities, improving throughput (or stability region), and reducing access delay when the system has high rate of UE arrivals and has unbalanced UE arrivals over different beams.},
  archive      = {J_TMC},
  author       = {Mamta Agiwal and Jie Liu and Hu Jin},
  doi          = {10.1109/TMC.2021.3122983},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2645-2660},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic preamble resource distribution for random access in 5G new radio systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic computation offloading and server deployment for
UAV-enabled multi-access edge computing. <em>TMC</em>, <em>22</em>(5),
2628–2644. (<a href="https://doi.org/10.1109/TMC.2021.3129785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the increasing demand of real-time mobile application processing, Multi-access Edge Computing (MEC) has been envisioned as a promising paradigm for pushing computational resources to network edges. In this paper, we investigate an MEC network enabled by Unmanned Aerial Vehicles (UAV), and consider both the multi-user computation offloading and edge server deployment to minimize the system-wide computation cost under dynamic environment, where users generate tasks according to time-varying probabilities. We decompose the minimization problem by formulating two stochastic games for multi-user computation offloading and edge server deployment respectively, and prove that each formulated stochastic game has at least one Nash Equilibrium (NE). Two learning algorithms are proposed to reach the NEs with polynomial-time computational complexities. We further incorporate these two algorithms into a chess-like asynchronous updating algorithm to solve the system-wide computation cost minimization problem. Finally, performance evaluations based on real-world data are conducted and analyzed, corroborating that the proposed algorithms can achieve efficient computation offloading coupled with proper server deployment under dynamic environment for multiple users and MEC servers.},
  archive      = {J_TMC},
  author       = {Zhaolong Ning and Yuxuan Yang and Xiaojie Wang and Lei Guo and Xinbo Gao and Song Guo and Guoyin Wang},
  doi          = {10.1109/TMC.2021.3129785},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2628-2644},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic computation offloading and server deployment for UAV-enabled multi-access edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Downlink decoding based accurate measurement of LTE spectrum
tenancy. <em>TMC</em>, <em>22</em>(5), 2613–2627. (<a
href="https://doi.org/10.1109/TMC.2021.3125569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile networks are embracing Dynamic Spectrum Access (DSA) to unleash data capacities of spectrum holes caused by tidal traffic. Being the largest mobile system, LTE has been standardized to operate in the DSA mode where the knowledge on the spectrum tenancy of LTE systems is required. Although there exists rich literature on spectrum sensing, measurement and modeling, they cannot satisfy the needs of accurately acquiring the spectrum tenancy of LTE systems. This is because most traditional measurements only provide inaccurate tenancy in coarse granularities, and therefore models built upon them are defective. To enable the precise discovery of spectrum assignments of an LTE cell from an outsider perspective, we build U-CIMAN to U n C over spectrum occupancy and user I nformation in M obile A ccess N etworks. The LTE protocol fields parsed by U-CIMAN not only accurately reveal the spectrum occupancy at the same granularity with LTE scheduling, but also provide important details associated with spectrum usage, i.e., rough user locations and traffic types. Besides insightful observations based on measurements enabled by U-CIMAN, we propose to characterize LTE spectrum occupancy using Vector Autoregression that captures the statistical distributions of spectrum tenancy intervals in multiple channels and the correlations among them.},
  archive      = {J_TMC},
  author       = {Rui Zou and Wenye Wang},
  doi          = {10.1109/TMC.2021.3125569},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2613-2627},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Downlink decoding based accurate measurement of LTE spectrum tenancy},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially-private deep learning with directional noise.
<em>TMC</em>, <em>22</em>(5), 2599–2612. (<a
href="https://doi.org/10.1109/TMC.2021.3130060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of deep learning applications, the privacy of training data has become a major concern as the data sources may be sensitive. Recent studies have found that deep learning models are vulnerable to privacy attacks, which are able to infer private training data from model parameters. To mitigate such attacks, differential privacy has been proposed to preserve data privacy by adding randomized noise to these models. However, since deep learning models usually consist of a large number of parameters and complicated layered structures, an overwhelming amount of noise is often inserted, which significantly degrades model accuracy. We seek a better tradeoff between model utility and data privacy, by choosing directions of noise w.r.t. the utility subspace. We propose an optimized mechanism for differentially-private stochastic gradient descent, and derive a closed-form solution. The form of the solution makes the mechanism ready to be deployed in real-world deep learning systems. Experimental results on a variety of models, datasets, and privacy settings show that our proposed mechanism achieves higher accuracies at the same privacy guarantee compared to the state-of-the-art methods. Further, we extend the privacy guarantee to a mutual information bound, and propose a general form to the utility-privacy problem.},
  archive      = {J_TMC},
  author       = {Liyao Xiang and Weiting Li and Jungang Yang and Xinbing Wang and Baochun Li},
  doi          = {10.1109/TMC.2021.3130060},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2599-2612},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Differentially-private deep learning with directional noise},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decentralized inference with graph neural networks in
wireless communication systems. <em>TMC</em>, <em>22</em>(5), 2582–2598.
(<a href="https://doi.org/10.1109/TMC.2021.3125793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) is an efficient neural network model for graph data and is widely used in different fields, including wireless communications. Different from other neural network models, GNN can be implemented in a decentralized manner during the inference stage with information exchanges among neighbors, making it a potentially powerful tool for decentralized control in wireless communication systems. The main bottleneck, however, is wireless channel impairments that deteriorate the prediction robustness of GNN. To overcome this obstacle, we analyze and enhance the robustness of the decentralized GNN during the inference stage in different wireless communication systems in this paper. Specifically, using a GNN binary classifier as an example, we first develop a methodology to verify whether the predictions are robust. Then, we analyze the performance of the decentralized GNN binary classifier in both uncoded and coded wireless communication systems. To remedy imperfect wireless transmission and enhance the prediction robustness, we further propose novel retransmission mechanisms for the above two communication systems, respectively. Through simulations on the synthetic graph data, we validate our analysis, verify the effectiveness of the proposed retransmission mechanisms, and provide some insights for practical implementation.},
  archive      = {J_TMC},
  author       = {Mengyuan Lee and Guanding Yu and Huaiyu Dai},
  doi          = {10.1109/TMC.2021.3125793},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2582-2598},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Decentralized inference with graph neural networks in wireless communication systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data poisoning attacks and defenses in dynamic crowdsourcing
with online data quality learning. <em>TMC</em>, <em>22</em>(5),
2569–2581. (<a href="https://doi.org/10.1109/TMC.2021.3133365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing has found a wide variety of applications, including spectrum sensing, traffic monitoring, as well as data annotation for machine learning based data analytics. To improve data accuracy and cost-effectiveness, workers’ data quality can be learned from their data in an online manner, which can be used for task assignment and data aggregation. However, crowdsourcing is vulnerable to data poisoning attacks, where the attacker reports malicious data to reduce aggregated data accuracy. In this paper, we study malicious data attacks on dynamic crowdsourcing where tasks are assigned and performed sequentially, and we explore online quality learning as a defense mechanism against the attack by finding malicious workers with low quality. We first focus on the asymptotic setting where workers’ quality is accurately learned by the requester, based on which we then turn to the general non-asymptotic setting where the quality is estimated online with errors. For each setting, we first characterize the conditions under which the attack strategy can effectively reduce the aggregated data accuracy. Our results show that the malicious noise variance needs to be within a certain range for the attack to be effective. Then we analyze the harm of effective attack strategies. It reveals that the regret of the online quality learning algorithm can be substantially increased from &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {O}(\log ^2T)$&lt;/tex-math&gt;&lt;/inline-formula&gt; (upper bound) to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\Omega (T)$&lt;/tex-math&gt;&lt;/inline-formula&gt; (lower bound) due to effective attacks. To further mitigate the attack, we also study median and maximum influence of estimation based data aggregation as defense mechanisms. Our results provide useful insights on the impacts of data poisoning attacks when online quality learning is used to defend against the attack. We evaluate the proposed attacks and defenses via extensive simulation results based on real-world data, which demonstrate the effectiveness of the attacks and defenses.},
  archive      = {J_TMC},
  author       = {Yuxi Zhao and Xiaowen Gong and Fuhong Lin and Xu Chen},
  doi          = {10.1109/TMC.2021.3133365},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2569-2581},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Data poisoning attacks and defenses in dynamic crowdsourcing with online data quality learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CRISIS: Cyber-physical social distancing based on
multi-modal data from mobile devices. <em>TMC</em>, <em>22</em>(5),
2551–2568. (<a href="https://doi.org/10.1109/TMC.2021.3126604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal sensors on mobile devices (e.g., smart watches and smartphones) have been widely used to ubiquitously perceive human mobility and body motions for understanding social interactions between people. This work investigates the correlations between the multi-modal data observed by mobile devices and social closeness among people along their trajectories. To close the gap between cyber-world data distances and physical-world social closeness, this work quantifies the cyber distances between multi-modal data. The human mobility traces and body motions are modeled as cyber signatures based on ambient Wi-Fi access points and accelerometer data observed by mobile devices that explicitly indicate the mobility similarity and movement similarity between people. To verify the merits of modeled cyber distances, we design the localization-free CybeR-physIcal Social dIStancing (CRISIS) system that detects if two persons are physically non-separate (i.e., not social distancing) due to close social interactions (e.g., taking similar mobility traces simultaneously or having a handshake with physical contact). Extensive experiments are conducted in two small-scale environments and a large-scale environment with different densities of Wi-Fi networks and diverse mobility and movement scenarios. The experimental results indicate that our approach is not affected by uncertain environmental conditions and human mobility with an overall detection accuracy of 98.41% in complex mobility scenarios. Furthermore, extensive statistical analysis based on 2-dimensional (2D) and 3-dimensional (3D) mobility datasets indicates that the proposed cyber distances are robust and well-synchronized with physical proximity levels.},
  archive      = {J_TMC},
  author       = {Yunfeng Huang and Fang-Jing Wu},
  doi          = {10.1109/TMC.2021.3126604},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2551-2568},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CRISIS: Cyber-physical social distancing based on multi-modal data from mobile devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cognitive RF–FSO fronthaul assignment in cell-free and
user-centric mMIMO networks. <em>TMC</em>, <em>22</em>(5), 2537–2550.
(<a href="https://doi.org/10.1109/TMC.2021.3132575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell-free massive MIMO (CF-mMIMO) network and its user-centric (UC) version are considered as promising techniques for the next generations of wireless networks. However, fronthaul and backhaul assignments are challenging issues in these networks. In this paper, energy efficiencies of uplink transmission for the CF- and UC-mMIMO networks are studied, wherein access points (APs) are connected to aggregation nodes (ANs) through radio frequency (RF) and/or free-space optic (FSO) fronthauls, and the ANs are connected to a central processing unit via fiber backhauls. The achievable data rates are derived by taking into account the effects of hardware non-ideality at the APs and ANs, FSO alignment and weather conditions. To have a robust and energy-efficient network, especially in the presence of FSO misalignment and adverse weather conditions, first, a cognitive RF–FSO fronthaul assignment algorithm is proposed at the cost of sharing the available RF bandwidth between the access and fronthaul links. Then, optimal power allocations at the users and APs are investigated, and two analytical approaches are proposed to solve the non-convex optimization problem. Through numerical results, we have discussed how utilizing the cognitive RF–FSO fronthaul assignment achieves higher energy efficiency compared to that of FSO-only, RF-only, or simultaneously using RF and FSO fronthaul links, e.g., achieving up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$198\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; higher energy efficiency under unfavorable conditions. Moreover, the effects of FSO misalignment, weather conditions, and power allocations on the networks’ performances are discussed.},
  archive      = {J_TMC},
  author       = {Pouya Agheli and Mohammad Javad Emadi and Hamzeh Beyranvand},
  doi          = {10.1109/TMC.2021.3132575},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2537-2550},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cognitive RF–FSO fronthaul assignment in cell-free and user-centric mMIMO networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AlexNet classifier and support vector regressor for
scheduling and power control in multimedia heterogeneous networks.
<em>TMC</em>, <em>22</em>(5), 2520–2536. (<a
href="https://doi.org/10.1109/TMC.2021.3123200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the downlink transmission of a two-tier heterogeneous network (HetNet) is considered in which a macro base station (MBS) serves the macro users using orthogonal frequency division multiple access (OFDMA) and small base stations (SBSs) serve the small-cell users through multi-carrier non-orthogonal multiple access (MC-NOMA) and joint transmission (JT). In particular, assuming the subcarriers are already allocated to macro users, the problem of scheduling (i.e., joint user association and subcarrier allocation) and power control is studied with the goal of maximizing the total users’ perceived quality-of -experience (QoE) for small-cell users, while a minimum data rate for macro users is guaranteed. To solve the joint optimization problem, a near-optimal and computationally efficient two-phase solution approach is proposed based on the tools from optimization and machine learning (ML). In the first phase, the optimization problem is solved to obtain the scheduling decisions and transmit power variables. In the second phase, the optimized scheduling decisions and transmit power variables serve as training samples for an AlexNet classifier and support vector regressor (SVR), respectively. Simulation results reveal that the integration of JT into MC-NOMA, outperforms the conventional MC-NOMA scheme by up to 24%, 19%, and 21% for the web, video and audio multimedia services, respectively. Compared to a conventional convolutional neural network, our results demonstrate that for the web, video, and audio-services, AlexNet increases the scheduling prediction accuracy up to 14%, 11%, and 17%, while SVR increases the power prediction accuracy up to 8%, 7%, and 12%, respectively.},
  archive      = {J_TMC},
  author       = {Hosein Zarini and Ata Khalili and Hina Tabassum and Mehdi Rasti and Walid Saad},
  doi          = {10.1109/TMC.2021.3123200},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2520-2536},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AlexNet classifier and support vector regressor for scheduling and power control in multimedia heterogeneous networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AirText: One-handed text entry in the air for COTS
smartwatches. <em>TMC</em>, <em>22</em>(5), 2506–2519. (<a
href="https://doi.org/10.1109/TMC.2021.3130036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text entry for smartwatches is a useful service for many applications like sending text messages and replying emails. Traditional touchscreen-based approaches are two-handed text entry methods, that could be cumbersome when the user is performing other tasks with one hand. Therefore, we propose AirText, the first one-handed text entry method which achieves accurate and practical handwriting in the air for commercial smartwatches. By analyzing the inertial readings from the smartwatch worn on the wrist, AirText is able to accurately recognize the in-air handwritten characters. However, the wrist movements, which produce the inertial readings, are harmful to the user to focus on the screen. In order to address this challenge, AirText uses a novel cross-modal supervision design to achieve accurate character recognition from small wrist movements. AirText further includes a novel word recommendation method to speed up the text entry. We implement AirText on five smartwatches and evaluate its performance extensively with eight volunteers and more than 25,000 in-air handwritten characters. Results show that AirText outperforms two baseline methods and achieves comparable text entry speed as two-handed approaches.},
  archive      = {J_TMC},
  author       = {Yi Gao and Siyu Zeng and Ji Zhao and Wenxin Liu and Wei Dong},
  doi          = {10.1109/TMC.2021.3130036},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2506-2519},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AirText: One-handed text entry in the air for COTS smartwatches},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A distributed deep reinforcement learning technique for
application placement in edge and fog computing environments.
<em>TMC</em>, <em>22</em>(5), 2491–2505. (<a
href="https://doi.org/10.1109/TMC.2021.3123165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog/Edge computing is a novel computing paradigm supporting resource-constrained Internet of Things (IoT) devices by placement of their tasks on edge and/or cloud servers. Recently, several Deep Reinforcement Learning (DRL)-based placement techniques have been proposed in fog/edge computing environments, which are only suitable for centralized setups. The training of well-performed DRL agents requires manifold training data while obtaining training data is costly. Hence, these centralized DRL-based techniques lack generalizability and quick adaptability, thus failing to efficiently tackle application placement problems. Moreover, many IoT applications are modeled as Directed Acyclic Graphs (DAGs) with diverse topologies. Satisfying dependencies of DAG-based IoT applications incur additional constraints and increase the complexity of placement problem. To overcome these challenges, we propose an actor-critic-based distributed application placement technique, working based on the IMPortance weighted Actor-Learner Architectures (IMPALA). IMPALA is known for efficient distributed experience trajectory generation that significantly reduces exploration costs of agents. Besides, it uses an adaptive off-policy correction method for faster convergence to optimal solutions. Our technique uses recurrent layers to capture temporal behaviors of input data and a replay buffer to improve the sample efficiency. The performance results, obtained from simulation and testbed experiments, demonstrate that our technique significantly improves execution cost of IoT applications up to 30% compared to its counterparts.},
  archive      = {J_TMC},
  author       = {Mohammad Goudarzi and Marimuthu Palaniswami and Rajkumar Buyya},
  doi          = {10.1109/TMC.2021.3123165},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {2491-2505},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A distributed deep reinforcement learning technique for application placement in edge and fog computing environments},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tracing truth and rumor diffusions over mobile social
networks: Who are the initiators? <em>TMC</em>, <em>22</em>(4),
2473–2490. (<a href="https://doi.org/10.1109/TMC.2021.3119362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of mobile devices, each user is able to conveniently acquire messages from others, and share diverse forms of information, like texts, images, or videos through online mobile apps. The full freedom of speech makes a great amount of truth (i.e., true information) and rumor (i.e., false information) propagate rapidly in a hybrid way through mobile platforms. As a huge variety of information floods pouring over us each day, identifying the authenticity of massive events becomes a necessary task to maintain the stability of Mobile Social Networks (MSNs). An important way to realize it is to trace their diffusions and make judgements according to the reliability of sources. With this regard, this paper proposes a diffusion model that characterizes the simultaneous diffusion of both truth and rumor in realistic MSNs, and makes the first attempt to figure out their respective sources. The problem of interest can be stated as: Given an outcome of cascade of both truth and rumor in MSNs, i.e., a set of nodes that might be the ignorant, the spreader of truth or rumor, or simply the silent receiver, how can we infer both truth sources and rumor sources? Different from previous sources detection works considering single type of nodes, the interplay between truth diffusions and rumor diffusions makes the conventional methods not work. To answer this question, we aim to maximize the similarity index , i.e., the number of nodes possessing the same states between the resulting network triggered by our estimated sources with the proposed diffusion model and the given observation network. Compared with existing techniques to trace diffusions of truth or rumor, it is much harder to find two kinds of sets at the same time, including truth sources and rumor sources, due to two primary reasons: (i) our biset optimization makes the submodularity techniques fail; (ii) our objective function is proven to be non-bisubmodular. To overcome above limitations, we first convert the objective similarity index into a bisubmodular function by virtue of set covering. Based on this, we propose an approximation algorithm called Truth and Rumor Sources Detection (TRSD) algorithm via multiple reverse samplings with a provable &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\frac{1}{4(1+\epsilon)^2}$&lt;/tex-math&gt;&lt;/inline-formula&gt; approximation ratio. Further, a novel “time reversal” sources optimization strategy is proposed to converge the number of output sources from TRSD to a steady state. The effectiveness of our models and algorithms are empirical validated in two various datasets, from which we observe an up to 15% of similarity index gain as well as a narrowed down gap 0.6% to the ground truth.},
  archive      = {J_TMC},
  author       = {Shan Qu and Hui Xu and Luoyi Fu and Huan Long and Xinbing Wang and Guihai Chen and Chenghu Zhou},
  doi          = {10.1109/TMC.2021.3119362},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2473-2490},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Tracing truth and rumor diffusions over mobile social networks: Who are the initiators?},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TIUI: Touching live video for telepresence operation.
<em>TMC</em>, <em>22</em>(4), 2458–2472. (<a
href="https://doi.org/10.1109/TMC.2021.3112559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework for telepresence operation by touching live video on a touchscreen. Our goal is to enable users to use a smartpad to teleoperate everyday objects by touching the objects’ live video they are watching. To this end, we coined the term “teleinteractive device” to describe such an object with an identity, an actuator, and a communication network. We developed a touchable live video image-based user interface (TIUI) that empowers users to teleoperate any teleinteractive device by touching its live video with touchscreen gestures. The TIUI contains four modules — touch, control, recognition, and knowledge — to perform live video understanding, communication, and control for telepresence operation. We implemented a telepresence operation system that consists of a telepresence robot and teleinteractive devices at a local site, a smartpad with the TIUI at a remote site, and communication networks connecting the two sites. We demonstrated potential applications of the system in remotely controlling telepresence robots, opening doors with access control panels, and pushing power wheelchairs. We conducted user studies to show the effectiveness of the proposed framework.},
  archive      = {J_TMC},
  author       = {Yunde Jia and Yanmei Dong and Bin Xu and Che Sun},
  doi          = {10.1109/TMC.2021.3112559},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2458-2472},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {TIUI: Touching live video for telepresence operation},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal correlation enhanced multiuser detection for uplink
grant-free NOMA. <em>TMC</em>, <em>22</em>(4), 2446–2457. (<a
href="https://doi.org/10.1109/TMC.2021.3111890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressed sensing (CS) has been identified as a good candidate for user detection in grant-free non-orthogonal multiple access (NOMA) by exploiting the inherent sparsity of user activity. However, most of the existing CS-based user detection schemes do not fully utilize the temporal correlation of user activity in NOMA and rely heavily on the unrealistic assumption that the number of active users is known in advance. To address these issues, we propose a temporal correlation enhanced multiuser detection scheme to achieve efficient and pragmatic multiuser detection. First, using 1-bit memory to piggyback the information on whether the active users still have data to transmit, the base station can realize that the active users in the current time slot will turn to be silent or remain active. Then, to make explicit use of the temporal correlation of active user sets, a cross validation based adaptive subspace pursuit (CVASP) algorithm is developed by utilizing the reported information on prior active users. The proposed CVASP is a highly practical algorithm that does not require any prior knowledge of the number of active users or the noise level, as the cross validation technique could properly determine the stopping condition. Extensive simulation results demonstrate that the proposed mechanism could achieve almost the same performance as compared to the existing state of art CS-based multiuser detection algorithms while eliminating the need for any prior knowledge.},
  archive      = {J_TMC},
  author       = {Liantao Wu and Peng Sun and Zhibo Wang and Yang Yang and Zhi Wang},
  doi          = {10.1109/TMC.2021.3111890},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2446-2457},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Temporal correlation enhanced multiuser detection for uplink grant-free NOMA},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task partitioning and offloading in DNN-task enabled mobile
edge computing networks. <em>TMC</em>, <em>22</em>(4), 2435–2445. (<a
href="https://doi.org/10.1109/TMC.2021.3114193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network (DNN)-task enabled mobile edge computing (MEC) is gaining ubiquity due to outstanding performance of artificial intelligence. By virtue of characteristics of DNN, this paper develops a joint design of task partitioning and offloading for a DNN-task enabled MEC network that consists of a single server and multiple mobile devices (MDs), where the server and each MD employ the well-trained DNNs for task computation. The main contributions of this paper are as follows: First, we propose a layer-level computation partitioning strategy for DNN to partition each MD&#39;s task into the subtasks that are either locally computed at the MD or offloaded to the server. Second, we develop a delay prediction model for DNN to characterize the computation delay of each subtask at the MD and the server. Third, we design a slot model and a dynamic pricing strategy for the server to efficiently schedule the offloaded subtasks. Fourth, we jointly optimize the design of task partitioning and offloading to minimize each MD&#39;s cost that includes the computation delay, the energy consumption, and the price paid to the server. In particular, we propose two distributed algorithms based on the aggregative game theory to solve the optimization problem. Finally, numerical results demonstrate that the proposed scheme is scalable to different types of DNNs and shows the superiority over the baseline schemes in terms of processing delay and energy consumption.},
  archive      = {J_TMC},
  author       = {Mingjin Gao and Rujing Shen and Long Shi and Wen Qi and Jun Li and Yonghui Li},
  doi          = {10.1109/TMC.2021.3114193},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2435-2445},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Task partitioning and offloading in DNN-task enabled mobile edge computing networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sweep-to-unlock: Fingerprinting smartphones based on
loudspeaker roll-off characteristics. <em>TMC</em>, <em>22</em>(4),
2417–2434. (<a href="https://doi.org/10.1109/TMC.2021.3119987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprinting smartphones based on acoustic characteristics of their loudspeaker may have a number of applications in device-to-device authentication as well as in forensic investigations. In this work we propose an efficient fingerprinting methodology by using the roll-off characteristics of the device speaker, i.e., the transition between the low and high stopbands to the passband segment of the speaker. We extract roll-off characteristics from sweep signals, also know as chirps, that are commonly used in practice to test speaker response. This procedure appears to be more stable against variations of the volume level and allows the use of simple linear approximations, which are intuitive and easy to compute, in order to extract the fingerprint. To increase detection accuracy, on the basis of the proven performance of deep learning techniques, a convolutional and a bi-directional long short term memory neural network are further proposed and their performance demonstrated for authentication purposes. While numerous applications may be envisioned, we specifically focus on the use of speaker characteristics in relation to in-vehicle infotainment units, checking if recordings from these units can be used to fingerprint a specific phone.},
  archive      = {J_TMC},
  author       = {Adriana Berdich and Bogdan Groza and René Mayrhofer and Efrat Levy and Asaf Shabtai and Yuval Elovici},
  doi          = {10.1109/TMC.2021.3119987},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2417-2434},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Sweep-to-unlock: Fingerprinting smartphones based on loudspeaker roll-off characteristics},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic digital-twin service demand with edge response:
An incentive-based congestion control approach. <em>TMC</em>,
<em>22</em>(4), 2402–2416. (<a
href="https://doi.org/10.1109/TMC.2021.3122013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of Digital Twin Edge Networks (DTENs) achieves the mapping of real physical entities to digital models of cyberspace. By offloading real-time mobile data to Mobile Edge Computing (MEC) servers for processing and modeling, communication-efficient Digital Twin (DT) services could be achieved. However, the spatio-temporal dynamic DT service demand stochastically generated by mobile users easily causes service congestion, which challenges the long-term DT service stability. Meanwhile, current DT services still lack long-term effective incentive designs for participants. To solve these issues, we design an incentive-based congestion control scheme for stochastic demand response in DTENs. First, we adopt the Lyapunov optimization theory to decompose the long-term congestion control decision into a sequence of online edge association decisions, with no need for future system information. We then present a contract-based incentive design to optimize the long-term profit of the DT service provider, comprehensively considering the delay sensitivity, incentive compatibility, and individual rationality. Finally, experimental simulations are carried out to verify the superiority of the proposed scheme with the base station dataset of Shanghai Telecom. Theoretical and simulation analysis demonstrates that compared with benchmarks, our scheme could effectively avoid long-term service congestion with an arbitrarily near-optimal profit.},
  archive      = {J_TMC},
  author       = {Xi Lin and Jun Wu and Jianhua Li and Wu Yang and Mohsen Guizani},
  doi          = {10.1109/TMC.2021.3122013},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2402-2416},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Stochastic digital-twin service demand with edge response: An incentive-based congestion control approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Secure transmission by leveraging multiple intelligent
reflecting surfaces in MISO systems. <em>TMC</em>, <em>22</em>(4),
2387–2401. (<a href="https://doi.org/10.1109/TMC.2021.3114167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advance of Intelligent Reflecting Surface (IRS) introduces a new dimension for secure communications by reconfiguring the transmission environments. In this paper, we devise a secure transmission scheme for multi-user Mutiple-Input Single-Output systems by leveraging multiple collaborative IRSs. Specifically, to guarantee the worst-case achievable secrecy rate among multiple legitimate users, we formulate a max-min problem that can be solved by an alternating optimization method to decouple it into multiple sub-problems. Based on semidefinite relaxation and successive convex approximation, each sub-problem can be further converted into convex problem and easily solved. Extensive experimental results demonstrate that our proposed scheme can adapt to complex scenarios for multiple users and achieve significant gain in terms of achievable secrecy rate. Compared to the traditional single IRS scheme, the proposed scheme can achieve better performance at the range of 2.4-6.4 bps/Hz with the increase in the number of reflecting elements in the multi-user scenarios. We also evaluate the gap between the secrecy rate for our proposed scheme under continuous phase shift/amplitude control and discrete phase shift/amplitude control, and our results show that the secrecy rate obtained from discrete approximation method converges to that achieved from the proposed scheme when increasing the discretization granularity.},
  archive      = {J_TMC},
  author       = {Jian Li and Lan Zhang and Kaiping Xue and Yuguang Fang and Qibin Sun},
  doi          = {10.1109/TMC.2021.3114167},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2387-2401},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secure transmission by leveraging multiple intelligent reflecting surfaces in MISO systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SecGreen: Secrecy ensured power optimization scheme for
software-defined connected IoV. <em>TMC</em>, <em>22</em>(4), 2370–2386.
(<a href="https://doi.org/10.1109/TMC.2021.3116954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-Defined Internet of Vehicles (SD-IoV) is an emerging technology that is being used in modern intelligent transportation systems (ITS). The ultimate goal of SD-IoV is to provide seamless connectivity to the end-users with low latency and high-speed data transfer. However, due to the increase in the density of the connected IoV using an open channel, i.e., the Internet, the foremost challenges of high power consumption and secure data transfer are inevitable in such an environment. An external eavesdropper may intercept the transmitted message to access the legitimate information over the public channel, i.e., the Internet. Most of the solutions reported in the literature to tackle these issues may not be applicable in the SD-IoV environment due to high computation and communication costs. Motivated from this, in this paper, the problems of high power consumption and secure data transfer in SD-IoV are formulated using mixed-integer non-linear programming (MINLP) with associated constraints. To solve the aforementioned problem, we propose a joint power optimization and secrecy ensured scheme known as SecGreen . SecGreen has an efficient energy harvesting algorithm using simultaneous wireless information and power transfer (SWIPT) to maximize the energy efficiency. Moreover, to mitigate various security attacks, a resilient lightweight secrecy association protocol is designed between vehicle and trusted gateway node of SD-IoV so that only trusted vehicles can communicate with each other and with the nearest base stations. The secrecy association protocol uses security primitives such as– physically unclonable function (PUF), one-way hash function, and bitwise exclusive OR (XOR) operations which are suitable for energy-constraint sensors in SD-IoV. The performance of the SecGreen is compared with the existing schemes, Stable &amp;amp; Scalable Link Optimization (SSLO), and Secure &amp;amp; Energy-Efficient Blockchain-enabled (SEEB) respectively. The result shows that when the number of packets across the subchannel increases, the energy consumption increases. Also, the result shows that the proposed scheme attains 22.5% and 20.34% better energy efficiency as compared to SSLO and SEEB schemes, respectively. In addition, the SecGreen scheme achieves 37.48% and 32.15% higher throughput as compared to SSLO and SEEB schemes. The results obtained show the superior performance of the proposed SecGreen scheme in comparison to these existing competitive schemes in the literature.},
  archive      = {J_TMC},
  author       = {Rajat Chaudhary and Neeraj Kumar},
  doi          = {10.1109/TMC.2021.3116954},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2370-2386},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SecGreen: Secrecy ensured power optimization scheme for software-defined connected IoV},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable phase-coherent beam-training for dense
millimeter-wave networks. <em>TMC</em>, <em>22</em>(4), 2353–2369. (<a
href="https://doi.org/10.1109/TMC.2021.3122584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mm-wave communications use analog beamforming techniques, which steer the signal energy in a desired direction, to overcome the high path-loss at such frequencies. To determine the direction in which to steer, mm-wave standards such as IEEE 802.11ad specify beam training mechanisms for both access points as well as client stations. However, the overhead of the beam training limits scalability as the density of network deployments increases and mobile devices that require constant re-training are supported. We design SPIDER, a low-overhead beam-training mechanism where only access points actively participate in the training and stations perform passive compressive estimation of the angle-of-arrival. To this end, stations carry out phase-coherent measurements by switching through multiple receive beam patterns on a time-scale of tens of nanoseconds when receiving a packet preamble. Since no suitable testbed platforms exist that support such fast antenna reconfiguration, we design a high-performance, full-bandwidth FPGA-based testbed platform for flexible mm-wave experimentation, that we make available as open source. The performance analysis with this testbed shows that our algorithm achieves highly accurate angle estimation used to drive the beam steering decisions and reduces overhead by an order of magnitude compared to IEEE 802.11ad beam training.},
  archive      = {J_TMC},
  author       = {Dolores Garcia and Jesus O. Lacruz and Pablo Jiménez Mateo and Joan Palacios and Rafael Ruiz and Joerg Widmer},
  doi          = {10.1109/TMC.2021.3122584},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2353-2369},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Scalable phase-coherent beam-training for dense millimeter-wave networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Radio and computing resource allocation in co-located edge
computing: A generalized nash equilibrium model. <em>TMC</em>,
<em>22</em>(4), 2340–2352. (<a
href="https://doi.org/10.1109/TMC.2021.3120520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Network Operators (MNO) can reduce their Capital and Operational Expenditure (CAPEX) and (OPEX) with the help of tower sharing approach by utilizing the physical infrastructure equipped by a third party tower provider to expand their network coverage. Moreover, Computing Resource Providers (CRP) are also setting up their micro-datacenters at tower stations to provide the Multi-access Edge Computing (MEC) services by cooperating with tower providers. Since both the communication and computing services contribute to the task offloading in MEC, the resource allocation has become a challenging problem. In this paper, we formulate the joint uplink, downlink, and computing resources allocation problem in which the objectives of both MNOs and CRP are to minimize their OPEX. The task offloading is modeled as a network of queues where the end-to-end latency is calculated based on the performance of the queue network. Then, the formulated problem is transformed into a Generalized Nash Equilibrium Problem (GNEP) to capture the conflicting interests in the resource allocation among MNOs and CRP. To solve the formulated GNEP efficiently, two decentralized algorithms are proposed by introducing the penalty parameters to the coupling constraints. In addition, the convergence and performance of the algorithms on different parameters are analyzed.},
  archive      = {J_TMC},
  author       = {Chit Wutyee Zaw and Nguyen H. Tran and Zhu Han and Choong Seon Hong},
  doi          = {10.1109/TMC.2021.3120520},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2340-2352},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Radio and computing resource allocation in co-located edge computing: A generalized nash equilibrium model},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). P2AE: Preserving privacy, accuracy, and efficiency in
location-dependent mobile crowdsensing. <em>TMC</em>, <em>22</em>(4),
2323–2339. (<a href="https://doi.org/10.1109/TMC.2021.3112394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread prevalence of smart devices, mobile crowdsensing (MCS) becomes a new trend to encourage mobile nodes to participate in cooperative data collection in various Internet of Things (IoT) applications. In location-dependent MCS, location information of mobile nodes are collected and analyzed by service provider to assist in task allocation. If the service provider is not fully trusted, mobile node&#39;s privacy is leaked and accessed by unauthorized parties. How to preserve privacy while maintaining task allocation accuracy and efficiency becomes challenging. To this end, we propose a learning-based mechanism that involves two parts: 1) privacy-preserving task release and task allocation; 2) accurate and efficient task allocation. In the first part, we design a location-based symmetric key generator, which enables two parties to self-generate a symmetric key without depending on fully trusted authorities. By utilizing this key generator and Proxy Re-encryption, we propose a privacy preserving protocol to protect location information in task release and task allocation. In the second part, we design a reinforcement learning based task allocation algorithm to optimize the winners selection, which obtains high accuracy and efficiency. The performance analysis reveals that our proposed mechanism achieves accurate and efficient task allocation while preserving privacy in location-dependent MCS.},
  archive      = {J_TMC},
  author       = {Yili Jiang and Kuan Zhang and Yi Qian and Liang Zhou},
  doi          = {10.1109/TMC.2021.3112394},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2323-2339},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {P2AE: Preserving privacy, accuracy, and efficiency in location-dependent mobile crowdsensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing cross-line dispatching for minimum electric bus
fleet. <em>TMC</em>, <em>22</em>(4), 2307–2322. (<a
href="https://doi.org/10.1109/TMC.2021.3119421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the increasing popularity of electric buses (e-buses) around the globe due to their environment friendly nature. However, various factors, such as the prohibitive purchasing costs and the scarcity of large-scale charging facilities, hinder the wider adoption of e-buses. Thus, to effectively cut the cost of building and maintaining urban e-bus systems, we optimize the dispatching strategy for urban e-bus systems to satisfy public transportation demands with the minimum e-bus fleet. Specifically, we propose to systematically exploit at city-scale cross-line dispatching, a smart dispatching strategy allowing one bus to serve multiple bus lines when necessary. Technically, we construct a novel and generalizable graph-theoretic model for urban e-bus systems integrating e-buses non-negligible charging time, the spatio-temporal constraints of bus trips, and various other real-world factors. We prove that it is NP-hard, and has no &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(2-\epsilon)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -approximation algorithm. Next, we propose a polynomial-time algorithm solving the problem with a guaranteed approximation ratio. Furthermore, we conduct extensive experiments on a large-scale real-world bus dataset from Shenzhen, China, which validate the effectiveness of our algorithms. As shown by our experimental results, to serve 300 bus lines, our dispatching strategy needs 38.2% less e-buses than the one currently used in practice.},
  archive      = {J_TMC},
  author       = {Chonghuan Wang and Yiwen Song and Guiyun Fan and Haiming Jin and Lu Su and Fan Zhang and Xinbing Wang},
  doi          = {10.1109/TMC.2021.3119421},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2307-2322},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimizing cross-line dispatching for minimum electric bus fleet},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OL-EUA: Online user allocation for NOMA-based mobile edge
computing. <em>TMC</em>, <em>22</em>(4), 2295–2306. (<a
href="https://doi.org/10.1109/TMC.2021.3112941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) raises a variety of new challenges for app vendors, including the Edge User Allocation (EUA) problem. EUA aims to allocate as many app users as possible in an MEC system to minimum edge servers in the system. In non-orthogonal multiple access (NOMA)-based MEC system, multiple app users can be allocated to the same subchannel on an edge server through transmit power allocation based on their intra-cell and inter-cell interference. However, allocating excessive app users to the same subchannel may result in severe interference and consequently impact app users’ data rates. In addition, in an MEC system, app users join and depart randomly, and thus need to be allocated in an online manner. Existing EUA approaches suffer from poor performance in dynamic real-world NOMA-based MEC systems because they allocate app users in an offline manner and do not consider the complication caused by NOMA. In this paper, we propose OL-EUA, an OnLine approach for solving dynamic EUA problems in NOMA-based MEC systems. Its performance is theoretically analyzed and experimentally evaluated on a public dataset.},
  archive      = {J_TMC},
  author       = {Guangming Cui and Qiang He and Xiaoyu Xia and Feifei Chen and Fang Dong and Hai Jin and Yun Yang},
  doi          = {10.1109/TMC.2021.3112941},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2295-2306},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {OL-EUA: Online user allocation for NOMA-based mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New routing protocol for reliability to intelligent
transportation communication. <em>TMC</em>, <em>22</em>(4), 2281–2294.
(<a href="https://doi.org/10.1109/TMC.2021.3116157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) a paradigm that brought several new communication technologies, allowing more ubiquity and real-time applications. This innovation sped up the implementation of intelligent transportation systems in smart cities. However, the use of these technologies needs the original routing protocols. The latters must meet real-time application requirements, such as reduced transmission delay, minimal packet loss, and less power consumption. This paper comes up with a novel solution LoRaWAN-based Geographic Routing Protocol (LGRP) using a multi-criteria metric taking into account delay, packet loss, distance, and relative velocity. The hybridization of LoRaWAN with 802.11p technologies is introduced to overcome challenges of urban scenarios in our protocol achievement. We carry out the routing protocol using the Network Simulator 3 (NS-3). Then, we assess its effectiveness in comparison with the greedy perimeter stateless routing (GPSR), the Ad hoc On-Demand Distance Vector (AODV), the Cross-Layer Weighted Position-based Routing (CLWPR), and the blended OpenFlow-Optimized Link State Routing (Centralized). The simulation results show that the proposed routing protocol outmatches the comparative ones in packet delivery and end-to-end delay.},
  archive      = {J_TMC},
  author       = {Lamia Elgaroui and Samuel Pierre and Steven Chamberland},
  doi          = {10.1109/TMC.2021.3116157},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2281-2294},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {New routing protocol for reliability to intelligent transportation communication},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multichannel neighbor discovery in bluetooth low energy
networks: Modeling and performance analysis. <em>TMC</em>,
<em>22</em>(4), 2262–2280. (<a
href="https://doi.org/10.1109/TMC.2021.3113349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bluetooth Low Energy (BLE) has become one of the enabling wireless technologies to facilitate the Internet of Things. Neighbor discovery is critical in BLE communications. BLE uses multiple (three) channels in neighbor discovery. It is challenging to achieve low-latency and low-energy-consumption BLE neighbor discovery due to the lack of analytical models for multichannel neighbor discovery. In this paper, we study BLE multichannel neighbor discovery for two advertising modes specified by BLE: periodic deterministic advertising (PDA) and pseudo-random delay advertising (RDA). We build two generic models, BLE 3-Circle model and BLE 1-Circle model, for characterizing BLE multichannel neighbor discovery. For PDA mode, we present a necessary and sufficient condition for BLE multichannel neighbor discovery, and provide a guideline for parameter setting. With the guideline, we derive the expected discovery latency in closed form, and demonstrate that the expected discovery latency is very close to a theoretical lower bound. For RDA mode, we build an analytical model based on Markov chain to accurately compute the expected discovery latency. Simulation and experimental results show accuracy of our analytical works. Interestingly, our parameter setting guideline works well for both PDA and RDA modes.},
  archive      = {J_TMC},
  author       = {Zhong Shen and Qinghai Yang and Hai Jiang},
  doi          = {10.1109/TMC.2021.3113349},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2262-2280},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multichannel neighbor discovery in bluetooth low energy networks: Modeling and performance analysis},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Measuring micrometer-level vibrations with mmWave radar.
<em>TMC</em>, <em>22</em>(4), 2248–2261. (<a
href="https://doi.org/10.1109/TMC.2021.3118349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vibration measurement is a crucial task in industrial systems, where vibration characteristics reflect health conditions and indicate anomalies of the devices. Previous approaches either work in an intrusive manner or fail to capture the micrometer-level vibrations. In this work, we propose mmVib, a practical approach to measure micrometer-level vibrations with mmWave radar. First, we derive a metric called Vibration Signal-to-Noise Ratio (VSNR) that highlights the directions of reducing measurement errors of tiny vibrations. Then, we introduce the design of mmVib based on the concept of Multi-Signal Consolidation (MSC) for the error reduction and multi-object measurement. We implement a prototype of mmVib, and the experiments show that it achieves &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$3.946\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; relative amplitude error and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$0.02487\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; relative frequency error in median. Typically, the average amplitude error is only &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$3.174um$&lt;/tex-math&gt;&lt;/inline-formula&gt; when measuring the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$100um$&lt;/tex-math&gt;&lt;/inline-formula&gt; -amplitude vibration at around 5 meters. Compared to two existing mmWave-based approaches, mmVib reduces the 80th-percentile amplitude error by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$69.21\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$97.99\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; respectively.},
  archive      = {J_TMC},
  author       = {Junchen Guo and Yuan He and Chengkun Jiang and Meng Jin and Shuai Li and Jia Zhang and Rui Xi and Yunhao Liu},
  doi          = {10.1109/TMC.2021.3118349},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2248-2261},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Measuring micrometer-level vibrations with mmWave radar},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Latency minimization for mobile edge computing networks.
<em>TMC</em>, <em>22</em>(4), 2233–2247. (<a
href="https://doi.org/10.1109/TMC.2021.3117511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of data-intensive mobile applications is causing latency to become an issue in mobile edge computing (MEC) systems. In this work, we propose a novel methodology that optimizes communication, computation, and caching configurations in MEC to minimize the mean latency experienced by mobile devices. Transmission and computation processes are modeled using M/G/1 queues to account for service rates and warm-up times. Our caching scheme includes time variables for each file at each edge server in determining when to discard files from storage. We theoretically analyze the latency experienced by mobile devices due to communication, computation, and caching, showing how MEC system latency depends on the offloading decisions of mobile devices, bandwidth and CPU resources, and expiration times of files in the storage of edge servers. Our method for solving the latency minimization problem consists of two main components: iNner cOnVex Approximation (NOVA) to deal with non-convexity in the optimization, and an online algorithm for preventing cache storage violations as new tasks arrive and are serviced by the MEC system. Simulation results show that our algorithm outperforms several baselines in minimizing latency, and verify the benefit of including different resource allocation variables in our optimization.},
  archive      = {J_TMC},
  author       = {Chang-Lin Chen and Christopher G. Brinton and Vaneet Aggarwal},
  doi          = {10.1109/TMC.2021.3117511},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2233-2247},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Latency minimization for mobile edge computing networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Latency aware transmission scheduling for steerable free
space optics. <em>TMC</em>, <em>22</em>(4), 2221–2232. (<a
href="https://doi.org/10.1109/TMC.2021.3115809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Free space optics (FSO), which uses light as the carrier to transmit data in free space, has been demonstrated as a secure and high-speed solution for long distance and line-of-sight wireless communications. Applying FSO as fronthaul/backhaul communications between base stations (BSs) and the gateway can significantly increase the fronthaul/backhaul link capacity. Traditionally, the gateway has to be equipped with multiple FSO transceivers, each of which is used to communicate with a BS by establishing a dedicated FSO. In this paper, we propose to use a steerable FSO system, where the gateway is equipped with a steerable FSO transceiver to communicate with multiple FSO transceivers at different BSs in a time division multiplexing manner. Applying the steerable FSO system can reduce the number of FSO transceivers at the gateway, and thus reduce the capital cost of implementing an FSO based fronthaul/backhaul network. We formulate the transmission scheduling problem in the steerable FSO system to optimize the active time for each FSO link associated with the steerable FSO transceiver such that the overall delay of transmitting a packet from geo-distributed BSs to the steerable FSO transceiver at the gateway is minimized, while guaranteeing the latency requirements of the BSs. We propose the la T ency a W are transm I ssion S cheduling for s T eerable FSO (TWIST) algorithm, which is designed based on Sequential Quadratic Programming, to efficiently solve the proposed problem. The performance of TWIST is validated via extensive simulations.},
  archive      = {J_TMC},
  author       = {Xiang Sun and Liangkun Yu and Tianrun Zhang},
  doi          = {10.1109/TMC.2021.3115809},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2221-2232},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Latency aware transmission scheduling for steerable free space optics},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interference analysis in non-poisson networks under
spatially correlated shadowing. <em>TMC</em>, <em>22</em>(4), 2205–2220.
(<a href="https://doi.org/10.1109/TMC.2021.3116314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial correlations that appear in mobile wireless networks, such as the correlations of node locations and shadowing effects, significantly affect the characteristics of interference, which may degrade the performance of various wireless network systems. In this paper, we theoretically analyze the statistical and temporal characteristics of interference in a network where the node locations and shadowing are spatially correlated. We model the correlation of the node locations by two types of non-Poisson point processes: determinantal point processes (DPPs) for modeling repulsiveness and doubly Poisson cluster processes (DPCPs) for modeling attractiveness . Furthermore, we consider Gudmundson&#39;s model for the spatial correlation of shadowing. Using this model and assuming an i.i.d. mobility of nodes, we analyze the variance along with the spatial and temporal correlations of interference. Since the exact expressions are in non-analytical forms, we derive their simple closed-form asymptotic formulas when the variance of the shadowing is large. The results show a readable relationship between the characteristics of interference and various system parameters. This relationship can be used for realistic modeling and better understanding of various wireless network systems under spatially correlated shadowing. Moreover, we discuss various numerical examples and demonstrate that the obtained asymptotic expressions achieve tight approximation.},
  archive      = {J_TMC},
  author       = {Tatsuaki Kimura},
  doi          = {10.1109/TMC.2021.3116314},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2205-2220},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Interference analysis in non-poisson networks under spatially correlated shadowing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GSMAC: GAN-based signal map construction with active
crowdsourcing. <em>TMC</em>, <em>22</em>(4), 2190–2204. (<a
href="https://doi.org/10.1109/TMC.2021.3120057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the dawn of 5G network, a new set of requirements for site spectrum monitoring, location-based services (LBS), network construction, and cellular planning are emerging, all of which are relying on fine-grained signal map. Although with significant importance, the traditional signal map construction, e.g., through full site survey, could be time-consuming and labor-intensive as the signal varies frequently over time and the accuracy requirement grows rapidly with the emergence of new applications. The state-of-the arts usually employ crowdsourcing scheme and matrix completion algorithm to solve the dilemma. However, the crowdsourcing scheme usually suffers from uneven distributed and inadequate participants, while the matrix completion methods do not take the specific signal map features into account, thus suffering from sub-optimal recovery results. To this end, in this paper, we study how to effectively reconstruct and update the signal map in the case of partially measured signal maps with smaller cost and propose a GAN-based active signal map reconstruction method (GSMAC). Our method is mainly innovative in two parts: GSMC, GAN-based signal map construction, and ACS, an active crowdsourcing scheme. Specifically, GSMC can effectively update the signal map with only a small number of observations while also fully using the incomplete historical signals to effectively update the signal map online. Meanwhile, ACS consists of a reinforce learning-based active query mechanism which quantitatively evaluates the most valuable measurement site for reconstruction, which further reduces the measurement cost to minimum. The simulation results and real implemented data driven experiments demonstrate the advantages and effectiveness of our approach in both accuracy and cost.},
  archive      = {J_TMC},
  author       = {Yanchao Zhao and Chengyong Liu and Kun Zhu and Sheng Zhang and Jie Wu},
  doi          = {10.1109/TMC.2021.3120057},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2190-2204},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {GSMAC: GAN-based signal map construction with active crowdsourcing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-grained and real-time gesture recognition by using IMU
sensors. <em>TMC</em>, <em>22</em>(4), 2177–2189. (<a
href="https://doi.org/10.1109/TMC.2021.3120475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture recognition by using Inertial Measurement Unit (IMU) sensors plays an important role in various Internet of Things (IOT) applications, e.g., smart home, intelligent medical system and so on. Traditional technologies usually utilize machine learning algorithms to train different gestures during the offline phase, then recognize the gesture during the online phase. However, such technologies cannot recognize these gestures without prior training. Even for the same gesture, with different gesture amplitude may result in unsuccessful recognition. Also if we change the person to perform the same gesture, the algorithms fails. In order to overcome these drawbacks, we propose an approach, which will be able to track the human body motion in real-time and also recognize complicated gestures. It utilizes the accelerometer information and proposes comprehensive localization algorithms for each deployed sensor attached on the human body. Then, it takes the correlation and limitation among body parts into account to recognize the gesture. Our experiments results show that, the successful recognition rate of our algorithm is 100%. Furthermore, any part of the human body can be well tracked, the tracking accuracy can reach &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$0.06m$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Dian Zhang and Zexiong Liao and Wen Xie and Xiaofeng Wu and Haoran Xie and Jiang Xiao and Landu Jiang},
  doi          = {10.1109/TMC.2021.3120475},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2177-2189},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fine-grained and real-time gesture recognition by using IMU sensors},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy-constrained online scheduling for
satellite-terrestrial integrated networks. <em>TMC</em>, <em>22</em>(4),
2163–2176. (<a href="https://doi.org/10.1109/TMC.2021.3116075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In satellite-terrestrial integrated networks, it is a common practice to schedule real-time tasks from low Earth orbit (LEO) satellites to ground stations (GSs) for data processing. However, the joint task scheduling and resource allocation under unknown environment dynamics (e.g., transmission latency) remains to be a challenging problem. First, the tradeoff between task latencies and energy consumption should be carefully considered when making decisions to minimize task latencies under time-averaged energy consumption constraints. Second, to learn the environment uncertainties and minimize the system performance loss (i.e., regret) in terms of task latencies, both online feedback and offline history should be leveraged efficiently, and the accompanying exploration-exploitation tradeoff should be dealt with in a proper way. In this article, we formulate the joint task scheduling and resource allocation problem as a constrained combinatorial multi-armed bandit (CMAB) problem. To solve the problem, by integrating online learning, online control, and offline historical information, we propose a Task scheduling and Resource allocation scheme with Data-driven Bandit Learning called TRDBL . Our theoretical and numerical results show that TRDBL achieves a sublinear time-averaged regret while satisfying the time-averaged energy consumption constraints.},
  archive      = {J_TMC},
  author       = {Xin Gao and Jingye Wang and Xi Huang and Qiuyu Leng and Ziyu Shao and Yang Yang},
  doi          = {10.1109/TMC.2021.3116075},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2163-2176},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-constrained online scheduling for satellite-terrestrial integrated networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient dependent task offloading for multiple
applications in MEC-cloud system. <em>TMC</em>, <em>22</em>(4),
2147–2162. (<a href="https://doi.org/10.1109/TMC.2021.3119200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of versatile mobile applications, offloading compute-intensive tasks to the MEC/Cloud becomes a dramatic technique due to the limited resources and high user experience requirements at mobile devices. However, most existing works design their task offloading schemes without considering the dependence of tasks and the orchestration of the MEC and Cloud, and thus may limit the system performance. In this paper, we propose a dependent task offloading framework for multiple mobile applications, named COFE, where mobile devices can offload their compute-intensive tasks with dependent constraints to the MEC-Cloud system. It can assign the offloaded tasks to the MEC and Cloud adaptively to improve the user experience. Based on COFE, we formulate the task offloading problem as an average makespan minimization problem, which is proved to be NP-hard. Then, we propose a heuristic ranking-based algorithm to assign the offloaded tasks according to their bottom levels. Theoretical analysis proves the stability of the system under the proposed algorithm and extensive simulations validate that the proposed algorithm can significantly reduce the average makespan and deadline violation probabilities of offloaded applications.},
  archive      = {J_TMC},
  author       = {Jiagang Liu and Ju Ren and Yongmin Zhang and Xuhong Peng and Yaoxue Zhang and Yuanyuan Yang},
  doi          = {10.1109/TMC.2021.3119200},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2147-2162},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Efficient dependent task offloading for multiple applications in MEC-cloud system},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic UAV deployment for differentiated services: A
multi-agent imitation learning based approach. <em>TMC</em>,
<em>22</em>(4), 2131–2146. (<a
href="https://doi.org/10.1109/TMC.2021.3116236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) have been utilized to serve on-ground users with various services, e.g., computing, communication and caching, due to their mobility and flexibility. The main focus of many recent studies on UAVs is to deploy a set of homogeneous UAVs with identical capabilities controlled by one UAV owner/company to provide services. However, little attention has been paid to the issue of how to enable different UAV owners to provide services with differentiated service capabilities in a shared area. To address this issue, we propose a multi-agent imitation learning enabled UAV deployment approach to maximize both profits of UAV owners and utilities of on-ground users. Specially, a Markov game is formulated among UAV owners and we prove that a Nash equilibrium exists based on the full knowledge of the system. For online scheduling with incomplete information, we design agent policies by imitating the behaviors of corresponding experts. A novel neural network model, integrating convolutional neural networks, generative adversarial networks and a gradient-based policy, can be trained and executed in a fully decentralized manner with a guaranteed &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\epsilon$&lt;/tex-math&gt;&lt;/inline-formula&gt; -Nash equilibrium. Performance results show that our algorithm has significant superiority in terms of average profits, utilities and execution time compared with other representative algorithms.},
  archive      = {J_TMC},
  author       = {Xiaojie Wang and Zhaolong Ning and Song Guo and Miaowen Wen and Lei Guo and H. Vincent Poor},
  doi          = {10.1109/TMC.2021.3116236},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2131-2146},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic UAV deployment for differentiated services: A multi-agent imitation learning based approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic task scheduling in cloud-assisted mobile edge
computing. <em>TMC</em>, <em>22</em>(4), 2116–2130. (<a
href="https://doi.org/10.1109/TMC.2021.3115262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud-assisted mobile edge computing system is a critical architecture to process computation-intensive and delay-sensitive mobile applications in close proximity to mobile users with high resource efficiency. Due to the heterogenous dynamics of task arrivals at edge nodes and the distributed nature of the system, the workloads of edge nodes are prone to be unbalanced, which can cause high task response time and resource cost. This paper solves the dynamic task scheduling problem in cloud-assisted mobile edge computing (including both peer task scheduling among edge nodes and cross-layer task scheduling from edge nodes to the cloud), aiming at minimizing average task response time within resource budget limit. To overcome the challenges of task arrival dynamics, edge node heterogeneity, and computation-communication delay tradeoff, we propose a W ater-f i lling Based D ynamic T a sk S cheduling (WiDaS) algorithm. WiDaS dynamically tunes the usage of cloud resources based on the Lyapunov optimization method and efficiently schedules mobile tasks among edge nodes (and the cloud) by exploiting the idea of water filling. Extensive simulations are conducted to evaluate WiDaS under a trace-driven traffic pattern and two mathematic traffic patterns. The results demonstrate that WiDaS shows two-fold benefits of efficiency and effectiveness. In terms of efficiency, WiDaS can achieve the approximate results with the KKT-based algorithm while reducing the computation complexity from exponential order to polynomial order. In terms of effectiveness, WiDaS can reduce the average task response time by up to 64.4% and 47.2% over the Fair-ratio and the Edge-first algorithm.},
  archive      = {J_TMC},
  author       = {Xiao Ma and Ao Zhou and Shan Zhang and Qing Li and Alex X. Liu and Shangguang Wang},
  doi          = {10.1109/TMC.2021.3115262},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2116-2130},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic task scheduling in cloud-assisted mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic federated learning-based economic framework for
internet-of-vehicles. <em>TMC</em>, <em>22</em>(4), 2100–2115. (<a
href="https://doi.org/10.1109/TMC.2021.3122436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) can empower Internet-of-Vehicles (IoV) networks by leveraging smart vehicles (SVs) to participate in the learning process with minimum data exchanges and privacy disclosure. The collected data and learned knowledge can help the vehicular service provider (VSP) improve the global model accuracy, e.g., for road safety as well as better profits for both VSP and participating SVs. Nonetheless, there exist major challenges when implementing the FL in IoV networks, such as dynamic activities and diverse quality-of-information (QoI) from a large number of SVs, VSP&#39;s limited payment budget, and profit competition among SVs. In this paper, we propose a novel dynamic FL-based economic framework for an IoV network to address these challenges. Specifically, the VSP first implements an SV selection method to determine a set of the best SVs for the FL process according to the significance of their current locations and information history at each learning round. Then, each selected SV can collect on-road information and propose a payment contract to the VSP based on its collected QoI. For that, we develop a multi-principal one-agent contract-based policy to maximize the profits of the VSP and learning SVs under the VSP&#39;s limited payment budget and asymmetric information between the VSP and SVs. Through experimental results using real-world on-road datasets, we show that our framework can converge 57% faster (even with only 10% of active SVs in the network) and obtain much higher social welfare of the network (up to 27.2 times) compared with those of other baseline FL methods.},
  archive      = {J_TMC},
  author       = {Yuris Mulya Saputra and Dinh Thai Hoang and Diep N. Nguyen and Le-Nam Tran and Shimin Gong and Eryk Dutkiewicz},
  doi          = {10.1109/TMC.2021.3122436},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2100-2115},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic federated learning-based economic framework for internet-of-vehicles},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed design of wireless powered fog computing
networks with binary computation offloading. <em>TMC</em>,
<em>22</em>(4), 2084–2099. (<a
href="https://doi.org/10.1109/TMC.2021.3115348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a multi-user wireless powered fog computing (FC) network, where multiple energy-limited wireless sensor devices (WSDs) first harvest energy from a nearby hybrid access point (HAP), and then compute their tasks locally (i.e., the local computing (LC) mode) or offload the tasks to the HAP (i.e., the FC mode) via a binary offloading policy. In order to pursue the green computing network design, an optimization problem is formulated to minimize the transmit power at the HAP by jointly optimizing the time allocation ratio and the computing mode selection vector, under the energy causality constraints and the WSDs’ computing rate requirements constraints. To efficiently solve the formulated non-convex problem in a distributed manner, it is first transformed into an approximate form, and then an alternating direction method of multipliers (ADMM)-based algorithm is designed to solve the transformed problem, based on which the successive convex approximation (SCA) is adopted to improve the approximating precision in an iterative way. With the proposed ADMM-based distributed algorithm, each WSD is able to optimize its computing mode and offloading time with local channel state information (CSI), which thus is more suitable for large-scale networks. For comparison, a channel-sorting-based (CSB) centralized algorithm with global CSI is also presented, and the computational complexities of the proposed ADMM-based algorithm and the CSB algorithm are analyzed. Simulation results show that the proposed distributed algorithm achieves a comparable performance with the CSB centralized algorithm and the exhaustive search method. It is also observed that to minimize the transmit power at the HAP, the WSDs with the better channel quality are inclined to select the LC mode, which is much different from traditional sum-computation-rate maximization design.},
  archive      = {J_TMC},
  author       = {Han Li and Ke Xiong and Yang Lu and Bo Gao and Pingyi Fan and Khaled Ben Letaief},
  doi          = {10.1109/TMC.2021.3115348},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2084-2099},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed design of wireless powered fog computing networks with binary computation offloading},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Detecting engine anomalies using batteries. <em>TMC</em>,
<em>22</em>(4), 2069–2083. (<a
href="https://doi.org/10.1109/TMC.2021.3119919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automotive industry is increasingly deploying software solutions to provide value-added features for vehicles, especially in the era of vehicle electrification and automation. However, the ever-increasing cyber components of vehicles (i.e., computation, communication, and control) incur new risks of anomalies, as evident by the millions of vehicle recalls by different automakers. To mitigate these risks, we design the B-Diag , a battery-based diagnostic system detects engine anomalies with a cyber-physical approach. The core idea of B-Diag is to diagnose engines using the physically-induced correlations between battery voltage and engine variables, which is captured as a customized 3-layer correlation graph and a set of data-driven norm models describing the edges thereof. The design of B-Diag is steered by a dataset collected with a prototype system when driving a 2018 Subaru Crosstrek in real-life for over three months. Our evaluation shows B-Diag to detect anomalies of 17 engine variables with a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$&amp;gt;$&lt;/tex-math&gt;&lt;/inline-formula&gt; &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$86\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; (up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$100\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) accuracy.},
  archive      = {J_TMC},
  author       = {Yiqin Wang and Linghe Kong and Siyu Lin and Liang He},
  doi          = {10.1109/TMC.2021.3119919},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2069-2083},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Detecting engine anomalies using batteries},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and optimization of solar-powered shared electric
autonomous vehicle system for smart cities. <em>TMC</em>,
<em>22</em>(4), 2053–2068. (<a
href="https://doi.org/10.1109/TMC.2021.3116805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart transportation shall address utility waste, traffic congestion, and air pollution problems with least human intervention in future smart cities. To realize the sustainable operation of smart transportation, we leverage solar-harvesting charging stations and rooftops to power electric autonomous vehicles(AVs) solely via design. With a fixed budget, our framework first optimizes the locations of charging stations based on historical spatial-temporal solar energy distribution and usage patterns, achieving &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(2+\epsilon)$&lt;/tex-math&gt;&lt;/inline-formula&gt; factor to the optimal. Then a stochastic algorithm is proposed to update the locations online to adapt to any shift in the distribution. Based on the deployment, a strategy is developed to assign energy requests in order to minimize their traveling distance to stations while not depleting their energy storage. Equipped with extra harvesting capability, we also optimize route planning to achieve a reasonable balance between energy consumed and harvested en-route. As a promising application, utility optimization of shared electric AVs is discussed, and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(2k\!+\!1)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -approx algorithm is proposed to manage &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; vehicles simultaneously. Our extensive simulations demonstrate the algorithm can approach the optimal solution within 10-15% approximation error, improve the operating range of vehicles by up to 2-3 times, and improve the utility by more than 50% compared to other competitive strategies.},
  archive      = {J_TMC},
  author       = {Pengzhan Zhou and Cong Wang and Yuanyuan Yang},
  doi          = {10.1109/TMC.2021.3116805},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2053-2068},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Design and optimization of solar-powered shared electric autonomous vehicle system for smart cities},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Delay-sensitive energy-efficient UAV crowdsensing by deep
reinforcement learning. <em>TMC</em>, <em>22</em>(4), 2038–2052. (<a
href="https://doi.org/10.1109/TMC.2021.3113052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing (MCS) by unmanned aerial vehicles (UAVs) servicing delay-sensitive applications becomes popular by navigating a group of UAVs to take advantage of their equipped high-precision sensors and durability for data collection in harsh environments. In this paper, we aim to simultaneously maximize collected data amount, geographical fairness, and minimize the energy consumption of all UAVs, as well as to guarantee the data freshness by setting a deadline in each timeslot. Specifically, we propose a centralized control, distributed execution framework by decentralized deep reinforcement learning (DRL) for delay-sensitive and energy-efficient UAV crowdsensing, called “DRL-eFresh”. It includes a synchronous computational architecture with GRU sequential modeling to generate multi-UAV navigation decisions. Also, we derive an optimal time allocation solution for data collection while considering all UAV efforts and avoiding much data dropout due to limited data upload time and wireless data rate. Simulation results show that DRL-eFresh significantly improves the energy efficiency, as compared to the best baseline DPPO, by 14% and 22% on average when varying different sensing ranges and number of PoIs, respectively.},
  archive      = {J_TMC},
  author       = {Zipeng Dai and Chi Harold Liu and Rui Han and Guoren Wang and Kin K. Leung and Jian Tang},
  doi          = {10.1109/TMC.2021.3113052},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2038-2052},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Delay-sensitive energy-efficient UAV crowdsensing by deep reinforcement learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative task offloading and block mining in
blockchain-based edge computing with multi-agent deep reinforcement
learning. <em>TMC</em>, <em>22</em>(4), 2021–2037. (<a
href="https://doi.org/10.1109/TMC.2021.3120050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convergence of mobile edge computing (MEC) and blockchain is transforming the current computing services in mobile networks, by offering task offloading solutions with security enhancement empowered by blockchain mining. Nevertheless, these important enabling technologies have been studied separately in most existing works. This article proposes a novel cooperative task offloading and block mining (TOBM) scheme for a blockchain-based MEC system where each edge device not only handles data tasks but also deals with block mining for improving the system utility. To address the latency issues caused by the blockchain operation in MEC, we develop a new Proof-of-Reputation consensus mechanism based on a lightweight block verification strategy. A multi-objective function is then formulated to maximize the system utility of the blockchain-based MEC system, by jointly optimizing offloading decision, channel selection, transmit power allocation, and computational resource allocation. We propose a novel distributed deep reinforcement learning-based approach by using a multi-agent deep deterministic policy gradient algorithm. We then develop a game-theoretic solution to model the offloading and mining competition among edge devices as a potential game, and prove the existence of a pure Nash equilibrium. Simulation results demonstrate the significant system utility improvements of our proposed scheme over baseline approaches.},
  archive      = {J_TMC},
  author       = {Dinh C. Nguyen and Ming Ding and Pubudu N. Pathirana and Aruna Seneviratne and Jun Li and H. Vincent Poor},
  doi          = {10.1109/TMC.2021.3120050},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2021-2037},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cooperative task offloading and block mining in blockchain-based edge computing with multi-agent deep reinforcement learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative orchestration of multi-domain edges from a
connected, cooperative and automated mobility (CCAM) perspective.
<em>TMC</em>, <em>22</em>(4), 2001–2020. (<a
href="https://doi.org/10.1109/TMC.2021.3118058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 5G ecosystem is comprised of the cellular 5G System, as well as a managed and orchestrated infrastructure providing virtualized network and service functions. The automotive industry with its stringent requirements for connected vehicles is a promising and yet challenging consumer of such 5G ecosystem. Deployment of service instances at distributed cloud resources of cellular network infrastructure edges enables localized low-latency access to these services from moving vehicles but comes along with challenges, such as the need for fast reconfiguration of the distributed deployment according to mobility pattern and associated service and resource demand. In this paper, we investigate a solution for the collaborative orchestration of services for Connected, Cooperative and Automated Mobility (CCAM) within such 5G ecosystem. A key objective is the service continuity for a highly dynamic automotive scenario, achieved by the associated management and orchestration of these services in distributed edge clouds. The proposed solution leverages a multi-tier orchestration system as well as localized management and protocol operations for collaborative edge resources. By means of both analytical and experimental evaluations, the paper draws conclusions on the gain in accelerating orchestration decisions and enforcements, while balancing associated protocol and computational load over the highly distributed and multi-layered orchestration system.},
  archive      = {J_TMC},
  author       = {Nina Slamnik-Kriještorac and Girma M. Yilma and Marco Liebsch and F. Zarrar Yousaf and Johann M. Marquez-Barja},
  doi          = {10.1109/TMC.2021.3118058},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {2001-2020},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collaborative orchestration of multi-domain edges from a connected, cooperative and automated mobility (CCAM) perspective},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Capitalize your data: Optimal selling mechanisms for IoT
data exchange. <em>TMC</em>, <em>22</em>(4), 1988–2000. (<a
href="https://doi.org/10.1109/TMC.2021.3113387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More and more IoT data is being traded online in cloud-based data marketplaces due to the fast-growing market demand. Within the current data selling mechanisms, data consumers have difficulties in making purchasing decisions due to uncertain IoT data quality and inflexible pricing interface. To resolve these issues, potential solutions could be to launch data demonstrations and release free sampling data to reduce the uncertainty about data quality, and to charge based on the volume of data actually used to enable flexible pricing. However, there is still no clear understanding of economic benefits of these mechanisms. In this paper, we design the optimal data selling mechanisms for IoT data exchange, and derive the following two results. First, whether to deploy a data demonstration and how much free sampling data to release depend on the extent of data consumers&#39; inaccuracy perceptions for data quality, which varies over a wide range in IoT applications. We found that the data vendor has no incentive to conduct these strategies if data consumers extremely overestimate data quality. Second, although flexible data pricing mechanisms provide convenience for real-time and streaming IoT data exchange, it brings less economic benefits to the data vendor compared with the fixed pricing scheme, which sells the whole data set with a fixed price. We evaluate the optimal selling mechanisms on a real-world Taxi GPS data set, and evaluation results verify the insights derived from our theoretical analysis.},
  archive      = {J_TMC},
  author       = {Qinya Li and Zun Li and Zhenzhe Zheng and Fan Wu and Shaojie Tang and Zhao Zhang and Guihai Chen},
  doi          = {10.1109/TMC.2021.3113387},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1988-2000},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Capitalize your data: Optimal selling mechanisms for IoT data exchange},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximated assignment algorithms for unordered and ordered
tasks in data shared MEC systems. <em>TMC</em>, <em>22</em>(4),
1968–1987. (<a href="https://doi.org/10.1109/TMC.2021.3112466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The appearance of Mobile Edge Computing (MEC) successfully solves the bottlenecks of traditional Cloud based networks. Since mobile edges, e.g., base stations, and mobile devices have certain data processing capabilities, it is not necessary to offload all the tasks to the cloud for handling. Therefore, it is quite important to decide the optimal task assignment in MEC systems, and a series of algorithms have been proposed. However, the existing algorithms ignored the data distribution during task assignment, so that their applied ranges are quite limit. Considering the data sharing is quite important in a MEC system, this paper studies task assignment algorithms in Data Shared Mobile Edge Computing Systems in detail. Specifically, three algorithms are proposed to deal with the unordered and ordered holistic tasks respectively. Meanwhile, the situation that the tasks are divisible is also considered, and two algorithms for rearranging the divisible tasks are proposed for different optimization goals. The hardness of the problem, the correctness, complexities, and ratio bounds of the proposed algorithms are analyzed theoretically. Finally, extensive experimental results are carried out. Both theoretical analysis and experiment results show that all the proposed algorithms have high performance in terms of latency, satisfied rate, and energy consumption.},
  archive      = {J_TMC},
  author       = {Siyao Cheng and Jiayan Huang and Zhenyue Chen and Jie Liu and Jianzhong Li},
  doi          = {10.1109/TMC.2021.3112466},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1968-1987},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Approximated assignment algorithms for unordered and ordered tasks in data shared MEC systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated cloud-edge-device adaptive deep learning
service for cross-platform web. <em>TMC</em>, <em>22</em>(4), 1950–1967.
(<a href="https://doi.org/10.1109/TMC.2021.3122279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning shows great promise in providing more intelligence to the cross-platform web. However, insufficient infrastructure, heavy models, and intensive computation limit the use of deep learning with low-performing web browsers. We propose DeepAdapter, an integrated cloud-edge-device framework that ties the edge, the remote cloud, with the device by cross-platform web technology for adaptive deep learning services towards lower latency, lower mobile energy, and higher system throughput. DeepAdapter consists of context-aware pruning, service updating, and online scheduling. First, the offline pruning module provides a context-aware pruning algorithm that incorporates the latency, the network condition, and the device&#39;s computing capability to fit various contexts. Second, the service updating module optimizes branch model cache on the edge for massive mobile users and updates the new model pruning requirements. Third, the online scheduling module matches optimal branch models for mobile users. Also, a two-stage DRL-based online scheduling method named DeepScheduler can handle high concurrent requests between edge centers and remote cloud by designing the reward prediction model. Extensive experiments show that DeepAdapter can decrease average latency by 1.33x, reduce average mobile energy by 1.4x, and improve system throughput by 2.1x with considerable accuracy.},
  archive      = {J_TMC},
  author       = {Yakun Huang and Xiuquan Qiao and Jian Tang and Pei Ren and Ling Liu and Calton Pu and Junliang Chen},
  doi          = {10.1109/TMC.2021.3122279},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1950-1967},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An integrated cloud-edge-device adaptive deep learning service for cross-platform web},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive relay selection strategy in underwater acoustic
cooperative networks: A hierarchical adversarial bandit learning
approach. <em>TMC</em>, <em>22</em>(4), 1938–1949. (<a
href="https://doi.org/10.1109/TMC.2021.3112967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relay selection solutions for underwater acoustic cooperative networks suffer significant performance degradation as they fail to adapt to incomplete information, noisy interference and overwhelming dynamics. To address this challenge, a hierarchical adversarial multi-armed bandit learning framework by proposing an online reward estimation layer is designed to improve adaptive relay decision control. In online reward estimation layer, adaptive Kalman filter estimator is developed to properly handle noisy observation to support accurate reward. Meanwhile, an online predict mechanism is projected for all relays to enrich learning information. Furthermore, based on estimate error variance, an adaptive exploration structure is developed to accelerate the balance between exploration and exploitation. All gathered information are exploited to learn relay quality for the decision-making. Accordingly, we present a Hierarchical Adversarial Bandit Learning (HABL) algorithm to fully exploit the heuristic interaction between the hierarchical framework. HABL integrates reward estimation, information prediction, adaptive exploration and decision making carefully in a holistic algorithm to maximize the learning efficiency. Thereby, the HABL-based relay selection algorithm has higher system throughput and lower communication cost. Further, we rigorously analyze the convergence of HABL algorithm and give its upper bound on the cumulative regret. Finally, extensive simulations elucidate the effectiveness of the HABL.},
  archive      = {J_TMC},
  author       = {Haihong Zhao and Xinbin Li and Song Han and Lei Yan and Junzhi Yu},
  doi          = {10.1109/TMC.2021.3112967},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1938-1949},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive relay selection strategy in underwater acoustic cooperative networks: A hierarchical adversarial bandit learning approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Achieving real-time spectrum sharing in 5G underlay
coexistence with channel uncertainty. <em>TMC</em>, <em>22</em>(4),
1922–1937. (<a href="https://doi.org/10.1109/TMC.2021.3120945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underlay coexistence is a spectrum efficient mechanism to roll out 5G picocells within a macrocell on the same spectrum. Due to a lack of cooperation between the primary users (PUs) in the macrocell and secondary users (SUs) in the picocells, it is impossible to have complete knowledge of channel conditions between them. Under such a circumstance, chance-constrained programming (CCP) has been shown to be an ideal optimization tool to address such a channel uncertainty. However, solutions to CCP are computationally intensive and cannot meet 5G’s timing requirement (125 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu s$&lt;/tex-math&gt;&lt;/inline-formula&gt; ). To address this problem, we propose a novel scheduler called GPU-based Underlay Coexistence (GUC) with the goal of finding an approximate solution to CCP in real-time. The essence of GUC is to decompose the original optimization problem into a large number of small subproblems that are suitable for parallel computation on GPU platforms. By selecting a subset of promising subproblems and solving them in parallel with fast algorithms, we are able to leverage GPU parallel computing and develop a real-time solution. Through extensive experiments, we show that GUC meets the 125 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu s$&lt;/tex-math&gt;&lt;/inline-formula&gt; requirement while achieving 90% optimality on average.},
  archive      = {J_TMC},
  author       = {Shaoran Li and Yan Huang and Chengzhang Li and Y. Thomas Hou and Wenjing Lou and Brian A. Jalaian and Stephen Russell},
  doi          = {10.1109/TMC.2021.3120945},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1922-1937},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Achieving real-time spectrum sharing in 5G underlay coexistence with channel uncertainty},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A power saving scheme for IEEE 802.15.3d THz wireless
communication links. <em>TMC</em>, <em>22</em>(4), 1912–1921. (<a
href="https://doi.org/10.1109/TMC.2021.3112532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Terahertz (THz) band spans the frequencies lying between 0.1 and 10 THz and represents the gap between millimeter waves and Infrared bands. THz will play an influential role in mitigating the spectrum resources shortage to meet the exponential growth of services and wireless devices. Standardization activities are being carried out to regulate the THz band&#39;s exploitation under the IEEE 802.15 standardization project. Despite the generous bandwidth, THz communications suffer from high pathloss and attenuation due to Molecular Absorption. As such, THz systems need to use extra power, suitable antennas, and enhanced signal processing and communication techniques to compensate for different signal attenuation sources. In this paper, we propose a new operation mode for the IEEE standard 802.15 to save the power transmission requirement while achieving the required data rate. Hence, less battery or antenna size is needed to support the same communication link quality. To this end, we optimize the power, modulation scheme, and channel allocation to minimize the total transmitted power keeping a minimum quality-of-service. Moreover, the design captures the effect of humidity on the system performance.},
  archive      = {J_TMC},
  author       = {Wafa Hedhly and Osama Amin and Basem Shihada and Mohamed-Slim Alouini},
  doi          = {10.1109/TMC.2021.3112532},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1912-1921},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A power saving scheme for IEEE 802.15.3d THz wireless communication links},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A portable and convenient system for unknown liquid
identification with smartphone vibration. <em>TMC</em>, <em>22</em>(4),
1894–1911. (<a href="https://doi.org/10.1109/TMC.2021.3121332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional liquid identification instruments are often unavailable to the general public. This paper shows the feasibility of identifying unknown liquids with commercial lightweight devices, such as a smartphone. The wisdom arises from the fact that different liquid molecules have various viscosity coefficients, so they need to overcome dissimilitude energy barriers during relative motion. With this intuition in mind, we introduce a novel model that measures liquids’ viscosity based on active vibration. The idea sounds straightforward, yet, it is challenging to build up a robust system utilizing the built-in accelerometer in smartphones. Practical issues include under-sampling, self-interference, and volume change impact. Instead of using machine learning techniques, we tackle these issues through multiple signal processing stages to reconstruct the original signals and cancel out the interference. Our approach achieved the liquid viscosity estimates with a mean relative error of 2.3% and distinguish 30 kinds of liquid with an average accuracy of 97.33%.},
  archive      = {J_TMC},
  author       = {Yongzhi Huang and Kaixin Chen and Yandao Huang and Lu Wang and Kaishun Wu},
  doi          = {10.1109/TMC.2021.3121332},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1894-1911},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A portable and convenient system for unknown liquid identification with smartphone vibration},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A fast, reliable, opportunistic broadcast scheme with
mitigation of internal interference in VANETs. <em>TMC</em>,
<em>22</em>(4), 1880–1893. (<a
href="https://doi.org/10.1109/TMC.2021.3119015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In VANETs, it is important to support fast and reliable multi-hop broadcast for safety-related applications. The performance of multi-hop broadcast schemes is greatly affected by relay selection strategies. However, the relationship between the relay selection strategies and the expected broadcast performance has not been fully characterized yet. Furthermore, conventional broadcast schemes usually attempt to minimize the waiting time difference between adjacent relay candidates to reduce the waiting time overhead, which makes the relay selection process vulnerable to internal interference, occurring due to retransmissions from previous forwarders and transmissions from redundant relays. In this paper, we jointly take both of the relay selection and the internal interference mitigation into account and propose a fast, reliable, opportunistic multi-hop broadcast scheme, in which we utilize a novel metric called the expected broadcast speed in relay selection and propose a delayed retransmission mechanism to mitigate the adverse effect of retransmissions from previous forwarders and an expected redundancy probability based mechanism to mitigate the adverse effect of redundant relays. The performance evaluation results show that the proposed scheme yields the best broadcast performance among the four schemes in terms of the broadcast coverage ratio and the end-to-end delivery latency.},
  archive      = {J_TMC},
  author       = {Hui Zhang and Xinming Zhang and Dan Keun Sung},
  doi          = {10.1109/TMC.2021.3119015},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1880-1893},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A fast, reliable, opportunistic broadcast scheme with mitigation of internal interference in VANETs},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bayesian approach to the design of backhauling topology
for 5G IAB networks. <em>TMC</em>, <em>22</em>(4), 1867–1879. (<a
href="https://doi.org/10.1109/TMC.2021.3118958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the backhauling topology of an integrated and backhaul (IAB) network is designed to sustain bursty traffic with the highest probability. To ensure sequential DU-MT or MT-DU transmissions, the topology is characterized by a directed acyclic graph (DAG). First, the Bayes&#39; theorem is used to transform the probability of sustaining the UE traffic into the probability of generating a DAG, and then the transformed problem is decomposed into two subproblems: 1) The link traffic load is determined under the condition that a DAG is formed; 2) Based on the link traffic load, the links that are critical for sustaining the UE traffic are identified, and then a new DAG is generated by maximizing the joint probability of links in the new DAG. Given random initial DAG, the two subproblems are iteratively solved until obtaining a final DAG. Theoretical analysis validates that the above iterative procedures converge to a single DAG, and simulations confirm that the convergence can be achieved within tens of iterations. Simulation results also show that the backhauling approach developed in this paper can support 56.41% higher traffic variations and achieve a 29.32% lower average hop-count than the existing topology generation schemes.},
  archive      = {J_TMC},
  author       = {Cheng Huang and Xudong Wang},
  doi          = {10.1109/TMC.2021.3118958},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1867-1879},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A bayesian approach to the design of backhauling topology for 5G IAB networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using surrogate models and data assimilation for efficient
mobile simulations. <em>TMC</em>, <em>22</em>(3), 1856–1866. (<a
href="https://doi.org/10.1109/TMC.2021.3108750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical simulations on mobile devices are an important tool for engineers and decision makers in the field. However, providing simulation results on mobile devices is challenging due to the complexity of the simulation, requiring remote server resources and distributed mobile computation. The additional large size of multi-dimensional simulation results leads to the insufficient performance of existing approaches, especially when the bandwidth of wireless communication is scarce. In this article, we present an optimized novel approach utilizing surrogate models and data assimilation techniques to reduce the communication overhead. Evaluations show that our approach is up to 6.5 times faster than streaming results from the server while still meeting required quality constraints.},
  archive      = {J_TMC},
  author       = {Christoph Dibak and Wolfgang Nowak and Frank Dürr and Kurt Rothermel},
  doi          = {10.1109/TMC.2021.3108750},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1856-1866},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Using surrogate models and data assimilation for efficient mobile simulations},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). User identification leveraging whispered sound for wearable
devices. <em>TMC</em>, <em>22</em>(3), 1841–1855. (<a
href="https://doi.org/10.1109/TMC.2021.3112528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasingly popular usage of wearable devices provides users with the ability to continuously track their health conditions or physical activities. For instance, the photoplethysmography (PPG) sensor embedded on smart watches could be utilized to collect sensing data, which can be mined to monitor people&#39;s heart rate or hand gestures. Such system is however vulnerable to user spoofing, in which a user distributes his/her device to other users such that the data collected from these users could be claimed to be his/her own. Thus, it is critical to identify the user for many wearable devices, allowing the sensing data to be labeled properly. Existing approaches mainly focus on targeting the unlocking of mobile devices or performing continuous user verification based on the human&#39;s behavior traits. In this paper, we propose a user identification system by leveraging the user&#39;s whispered sound to mitigate user spoofing for wearable devices. Our system exploits the contact microphone placed into contact with the body to capture the user&#39;s whispered sound which travels through the person&#39;s body for user identification. Given the captured acoustic data, our system first identifies frames which contain whispered events from the recording. Our system then calculates acoustic features from the identified whispered frames to determine whether the voice is collected when the microphone is on the body. Moreover, to make our system robust, we assign different quality weights to the whisper&#39;s phonemes by considering their consistency (i.e., intra user&#39;s differences) and distinctiveness (i.e., inter user&#39;s differences) simultaneously. Our experiments demonstrate that our user identification system is robust and accurate across various scenarios.},
  archive      = {J_TMC},
  author       = {Yanzhi Ren and Zhourong Zheng and Sibo Xu and Hongwei Li},
  doi          = {10.1109/TMC.2021.3112528},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1841-1855},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {User identification leveraging whispered sound for wearable devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Throughput prediction using machine learning in LTE and 5G
networks. <em>TMC</em>, <em>22</em>(3), 1825–1840. (<a
href="https://doi.org/10.1109/TMC.2021.3099397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of novel cellular network technologies, within 5G, are envisioned as key enablers of a new set of use-cases, including industrial automation, intelligent transportation, and tactile internet. The critical nature of the traffic requirements ranges from ultra-reliable communications, massive connectivity, and enhanced mobile broadband. Thus, the growing research on cellular network monitoring and prediction aims for ensuring a satisfied user-base and fulfillment of service level agreements. The scope of this study is to develop an approach for predicting the cellular link throughput of end-users, with a goal to benchmark the performance of network slices. First, we report and analyze a measurement study involving real-life cases, such as driving in urban, sub-urban, and rural areas, as well as tests in large crowded areas. Second, we develop machine learning models using lower-layer metrics, describing the radio environment, to predict the available throughput. The models are initially validated on the LTE network and then applied to a non-standalone 5G network. Finally, we suggest scaling the proposed model into the future standalone 5G network. We have achieved 93 and 84 percent &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$R^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; accuracy, with 0.06 and 0.17 mean squared error, in predicting the end-user&#39;s throughput in LTE and non-standalone 5G network, respectively.},
  archive      = {J_TMC},
  author       = {Dimitar Minovski and Niclas Ögren and Karan Mitra and Christer Åhlund},
  doi          = {10.1109/TMC.2021.3099397},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1825-1840},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Throughput prediction using machine learning in LTE and 5G networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthesis of large-scale instant IoT networks. <em>TMC</em>,
<em>22</em>(3), 1810–1824. (<a
href="https://doi.org/10.1109/TMC.2021.3099005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While most networks have long lifetimes, temporary network infrastructure is often useful for special events, pop-up retail, or disaster response. An instant IoT network is one that is rapidly constructed, used for a few days, then dismantled. We consider the synthesis of instant IoT networks in urban settings. This synthesis problem must satisfy complex and competing constraints: sensor coverage, line-of-sight visibility, and network connectivity. The central challenge in our synthesis problem is quickly scaling to large regions while producing cost-effective solutions. We explore two qualitatively different representations of the synthesis problems using satisfiability modulo convex optimization (SMC), and mixed-integer linear programming (MILP). The former is more expressive, for our problem, than the latter, but is less well-suited for solving optimization problems like ours. We show how to express our network synthesis in these frameworks. To scale to problem sizes beyond what these frameworks are capable of, we develop a hierarchical synthesis technique that independently synthesizes networks in sub-regions of the deployment area, then combines these. We find that, while MILP outperforms SMC in some settings for smaller problem sizes, the fact that SMC&#39;s expressivity matches our problem ensures that it uniformly generates better quality solutions at larger problem sizes.},
  archive      = {J_TMC},
  author       = {Pradipta Ghosh and Jonathan Bunton and Dimitrios Pylorof and Marcos A. M. Vieira and Kevin Chan and Ramesh Govindan and Gaurav S. Sukhatme and Paulo Tabuada and Gunjan Verma},
  doi          = {10.1109/TMC.2021.3099005},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1810-1824},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Synthesis of large-scale instant IoT networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ShakeReader: “Read” UHF RFID using smartphone. <em>TMC</em>,
<em>22</em>(3), 1793–1809. (<a
href="https://doi.org/10.1109/TMC.2021.3098818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {UHF RFID technology has become increasingly popular in stores, since it can quickly read a large number of RFID tags from afar. The deployed RFID infrastructure, however, does not directly benefit smartphone users in stores, mainly because smartphones cannot read UHF RFID tags or fetch relevant information. This article aims to bridge the gap and allow users to ‘read’ UHF RFID tags using their smartphones, without any hardware modification to either deployed RFID systems or smartphone hardware. To ‘read’ an interested tag, a user makes a predefined smartphone gesture in front of an interested tag. The smartphone gesture causes changes in 1) RFID measurement data captured by RFID infrastructure, and 2) motion sensor data captured by the user&#39;s smartphone. By matching the two data, our system (named ShakeReader ) can pair the interested tag with the corresponding smartphone, thereby enabling the smartphone to indirectly ‘read’ the interested tag. We build a novel reflector polarization model to analyze the impact of smartphone gesture to RFID backscattered signals. We enhance the basic version of ShakeReader [7] by improving its performance in densely deployed scenarios. Experimental results show that ShakeReader can accurately pair interested tags with their corresponding smartphones with an accuracy of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${&amp;gt;}96.3\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Kaiyan Cui and Yanwen Wang and Yuanqing Zheng and Jinsong Han},
  doi          = {10.1109/TMC.2021.3098818},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1793-1809},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ShakeReader: ‘Read’ UHF RFID using smartphone},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sensing and communication co-design for status update in
multiaccess wireless networks. <em>TMC</em>, <em>22</em>(3), 1779–1792.
(<a href="https://doi.org/10.1109/TMC.2021.3108544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sensing and communication layers are both integral parts of the Internet-of-Things. Most of recent studies on sensory status update treat the information sensing and sensory data communication problems separately (i.e., a decoupled approach) and optimize specific latency metrics such as age of information relying on simplified models of communication networks or sensory traffic. In this paper, we propose a deeply integrated sensing and communication scheduling ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {S}^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) framework based on status-error-triggered update, focusing specifically on multiaccess wireless networks. We first analyze a motivating example consisting of two-state Markov sensors, showing that when both optimized, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {S}^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; outperforms the decoupled approach significantly. For sensors with random-walk state transitions, the closed-form Whittle&#39;s index with arbitrary status tracking error functions is presented and the indexability is established. Furthermore, a mean-field approach is applied such that the decentralized status update medium access control design is solved explicitly, for both homogeneous nodes and heterogeneous nodes in terms of status transition behaviors. According to the numerical results, the performance of the proposed &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {S}^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; scheme is close to the optimum and better than the decoupled approach. In addition, a potential application of dynamic Channel State Information (CSI) update is presented, with CSI generated by a commercial ray-tracing simulator.},
  archive      = {J_TMC},
  author       = {Fei Peng and Zhiyuan Jiang and Sheng Zhou and Zhisheng Niu and Shunqing Zhang},
  doi          = {10.1109/TMC.2021.3108544},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1779-1792},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Sensing and communication co-design for status update in multiaccess wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure crowdsensed data trading based on blockchain.
<em>TMC</em>, <em>22</em>(3), 1763–1778. (<a
href="https://doi.org/10.1109/TMC.2021.3107187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsensed Data Trading (CDT) is a novel data trading paradigm, in which each data consumer can publicize its data demand as some crowdsensing tasks, and some mobile users (i.e., data sellers) can compete for these tasks, collect the corresponding data, and sell the results to the consumers. Existing CDT systems generally depend on a data trading broker, which will inevitably cause data consumers’ concerns on the trustworthiness of the systems and truthfulness of the data. To address this problem, we propose a B lockchain-based C rowdsensed D ata T rading (BCDT) system, mainly containing a smart contract, called BCDToken. First, we replace the data trading broker with blockchain to guarantee the trustworthiness of the data trading. Meanwhile, BCDToken adopts Blockchain-based Reverse Auction (BRA) to assign sensing tasks to data sellers. The BRA mechansim holds truthfulness and individual rationality, which can ensure the data sellers to report data collection costs honestly and prevent sellers to manipulate the auction. Moreover, we implement a Secure Truth Discovery and reliability Rating (STDR) mechanism in BCDToken based on homomorphic cryptography, which can incentivize sellers to upload the truthful data and consumers to rate truthfully the reliabilities of sellers based on the collected data without revealing any privacy of data. Additionally, we also deploy BCDToken on an Ethereum test network to demonstrate its practicability and significant performances.},
  archive      = {J_TMC},
  author       = {Baoyi An and Mingjun Xiao and An Liu and Yun Xu and Xiangliang Zhang and Qing Li},
  doi          = {10.1109/TMC.2021.3107187},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1763-1778},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secure crowdsensed data trading based on blockchain},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safety warning! Decentralised and automated incentives for
disqualified drivers auditing in ride-hailing services. <em>TMC</em>,
<em>22</em>(3), 1748–1762. (<a
href="https://doi.org/10.1109/TMC.2021.3108012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 2011, the private ride-hailing companies Didi (2019), Uber (2019) and Lyft (2021) have expanded into more and more cities. These ride-hailing services (RHS) bring convenience to our life; however, at the same time they, also raise security concerns for users. For example, several recent news items show that a considerable number of registered drivers whose licenses have been revoked are still taking RHS orders on the respective platforms; this phenomenon directly leads to insecurity on part of its users and the bad reputation of the ride-hailing service provider (SP). The traditional solution to solve this problem is to periodically check the validity of the drivers’ licenses; however, it is a considerably time-consuming and costly process since the SPs have to manually interact with the governing authorities. Therefore, in this paper, we have presented an auditable self-sovereign identity system (named AudiSSI), which provides an efficient approach for the SPs to manage their registered drivers’ qualifications in a decentralized and automatic manner. Further, using smart contract technology, we propose a safety guarantee insurance in the form of an auditing contract to enable the RHS rider to check their driver&#39;s qualifications before the trip starts and get incentives once they detect a disqualified driver. We designed an incentive mechanism and have provided a game theoretical analysis. Finally, we implemented a prototype of AudiSSI and deployed it on Hyperledger Indy and Fabric to show that self-sovereign identity system for RHS driver with qualification auditing is efficient and technically feasible.},
  archive      = {J_TMC},
  author       = {Youshui Lu and Jingning Zhang and Yong Qi and Saiyu Qi and Yue Li and Hongyu Song and Yuhao Liu},
  doi          = {10.1109/TMC.2021.3108012},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1748-1762},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Safety warning! decentralised and automated incentives for disqualified drivers auditing in ride-hailing services},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RTHop: Real-time hop-by-hop mobile network routing by
decentralized learning with semantic attention. <em>TMC</em>,
<em>22</em>(3), 1731–1747. (<a
href="https://doi.org/10.1109/TMC.2021.3105963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-access Edge Computing and ubiquitous smart devices help serve end-users efficiently by providing emerging edge-deployed services. On the other hand, more heavy and time-varying traffic loads are generated in mobile edge networks, so that an efficient traffic forwarding mechanism is highly required to handle the routing problem in complex and highly dynamic edge environments. Thus, Deep Reinforcement Learning (DRL) is introduced since it can work in a model-free approach. However, previous centralized DRL-based methods work in a turn-based way that mismatches the real-time property of routing. In this paper, we propose a real-time and distributed learning approach, RTHop, to adapt to the volatile environment and realize a hop-by-hop routing. The Multi-Agent Deep Reinforcement Learning (MADRL) and the Real-Time Markov Decision Process (RTMDP) are used to alleviate network congestion and maximize the utilization of network resources. By joining with the self-attention mechanism, RTHop obtains the semantics from elements of the network state to help agents learn the importance of each element on routing. Experiment results show that RTHop not only overcomes the weakness of conventional turn-based DRL methods but also achieves the increase of delivered packet ratios and effective throughput compared with other routing methods.},
  archive      = {J_TMC},
  author       = {Bo He and Jingyu Wang and Qi Qi and Haifeng Sun and Jianxin Liao},
  doi          = {10.1109/TMC.2021.3105963},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1731-1747},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RTHop: Real-time hop-by-hop mobile network routing by decentralized learning with semantic attention},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust RFID-based respiration monitoring in dynamic
environments. <em>TMC</em>, <em>22</em>(3), 1717–1730. (<a
href="https://doi.org/10.1109/TMC.2021.3106954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Respiration monitoring (RM) is crucial for tracking various health problems. Recently, RFID has been widely employed for lightweight and low-cost RM. However, existing RFID-based RM systems are designed for static environments where no people move around the monitored person. While, in practice, most environments are dynamic with people moving nearby, which introduces dynamic multipath signals and significantly distorts the respiration signal, leading to inaccurate RM. In this paper, we aim to realize accurate RFID-based RM in dynamic environments. Our observations show that multipath signals can result in a similar pattern to respiration, which leads to mis-detection of apnea and inaccurate respiration rate estimation. To address this issue, we first measure the respiration anomaly in the signal spectrogram to detect apnea. Second, we successfully remove the multipath effect for respiration rate estimation inspired by the intrinsic features of human respiration. Specifically, compared with people’s moving pattern, respiration pattern is regular and periodic. By transforming a normal respiration cycle into a matched filter, real respiration cycles can be extracted from the noisy RFID signal, which can be applied to estimate the respiration rate via peak detection scheme. The experiments show that our system achieves the average error of 4.2% and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$0.51\ bpm$&lt;/tex-math&gt;&lt;/inline-formula&gt; for apnea detection and respiration rate estimation in dynamic environments, respectively.},
  archive      = {J_TMC},
  author       = {Yanni Yang and Jiannong Cao and Yanwen Wang},
  doi          = {10.1109/TMC.2021.3106954},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1717-1730},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust RFID-based respiration monitoring in dynamic environments},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PROCS: Power routing and current scheduling in multi-relay
magnetic MIMO WPT system. <em>TMC</em>, <em>22</em>(3), 1702–1716. (<a
href="https://doi.org/10.1109/TMC.2021.3108482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonant coupling wireless power transfer (MRC-WPT) enables convenient device-charging. When MIMO MRC-WPT system incorporated with multiple relay components, both relay On-Off state (i.e., power routing ) and TX current (i.e., current scheduling ) could be adjusted for improving charging efficiency and distance. Previous approaches need the collaboration and feedback from the energy receiver (RX), achieved using side-channels, e.g., Bluetooth, which is time/energy-consuming. In this work we propose, design, and implement a multi-relay MIMO MRC-WPT system, and design an almost optimum joint optimization of P ower RO uting and C urrent S cheduling method named PROCS , without relying on any feedback from RX. We carefully decompose the joint optimization problem into two subproblems without affecting the overall optimality of the combined solution. For current scheduling subproblem, we propose an almost-optimum RX-feedback independent solution. For power routing subproblem, we first design a greedy algorithm with &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\frac{1}{2}$&lt;/tex-math&gt;&lt;/inline-formula&gt; approximation ratio, and then design a DQN based method to further improve its effectiveness. We prototype our system and evaluate it with extensive experiments. Our results demonstrate the effectiveness of the proposed algorithms. The achieved power transfer efficiency (PTE) on average is &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$3.2X$&lt;/tex-math&gt;&lt;/inline-formula&gt; , &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$1.43X$&lt;/tex-math&gt;&lt;/inline-formula&gt; , &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$1.34X$&lt;/tex-math&gt;&lt;/inline-formula&gt; , and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$7.3X$&lt;/tex-math&gt;&lt;/inline-formula&gt; over the other four strategies: Without relay, with non-adjustable relays, greed based, and shortest-path based ones.},
  archive      = {J_TMC},
  author       = {Hao Zhou and Jialin Deng and Wenxiong Hua and Xiang Cui and Xiang-Yang Li and Panlong Yang},
  doi          = {10.1109/TMC.2021.3108482},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1702-1716},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PROCS: Power routing and current scheduling in multi-relay magnetic MIMO WPT system},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pilot spoofing attack detection and localization with mobile
eavesdropper. <em>TMC</em>, <em>22</em>(3), 1688–1701. (<a
href="https://doi.org/10.1109/TMC.2021.3107300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the public nature of wireless environments, legitimate communication systems are generally under the threat of Pilot Spoofing Attack (PSA). The malicious user may manipulate channel estimation by emitting the same pilot information, leading to the biased estimation of Channel State Information (CSI) and the degraded secrecy capacity. Although various methods have been proposed for combating PSA, the ubiquitous mobility of legitimate and malicious users introduces complex time-varying characteristics, making previous static PSA detection methods less attractive. In this paper, we present a novel location-awareness dynamical PSA detection mechanism. To model the complex dynamical behaviors, a Random Finite Set (RFS) is formulated to jointly describe the mobile positions and uncertain attack status. On this basis, we design a joint PSA detection and user localization algorithm relying on the sequential Bayesian inference. As such, the inherent correlations in mobile patterns can be exploited to effectively enhance PSA detection probability and localization accuracy. Numerical simulation results validate that the new method significantly improves PSA detection and CSI estimation accuracy compared with state-of-the-art counterparts, therefore the information leakage problem is greatly alleviated. Our new approach thus has the great potential in the emerging mobile scenarios by effectively enhancing the physical-layer secured transmissions.},
  archive      = {J_TMC},
  author       = {Yiwen Tao and Xiang Wang and Bin Li and Chenglin Zhao},
  doi          = {10.1109/TMC.2021.3107300},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1688-1701},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Pilot spoofing attack detection and localization with mobile eavesdropper},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization of flow allocation in asynchronous
deterministic 5G transport networks by leveraging data analytics.
<em>TMC</em>, <em>22</em>(3), 1672–1687. (<a
href="https://doi.org/10.1109/TMC.2021.3099979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-Sensitive Networking (TSN) and Deterministic Networking (DetNet) technologies are increasingly recognized as key levers of the future 5G transport networks (TNs) due to their capabilities for providing deterministic Quality-of-Service and enabling the coexistence of critical and best-effort services. Additionally, they rely on programmable and cost-effective Ethernet-based forwarding planes. This article addresses the flow allocation problem in 5G backhaul networks realized as asynchronous TSN networks, whose building block is the Asynchronous Traffic Shaper. We propose an offline solution, dubbed “Next Generation Transport Network Optimizer” (NEPTUNO), that combines exact optimization methods and heuristic techniques and leverages data analytics to solve the flow allocation problem. NEPTUNO aims to maximize the flow acceptance ratio while guaranteeing the deterministic Quality-of-Service requirements of the critical flows. We carried out a performance evaluation of NEPTUNO regarding the degree of optimality, execution time, and flow rejection ratio. Furthermore, we compare NEPTUNO with a novel online baseline solution for two different optimization goals. Online methods compute the flow&#39;s allocation configuration right after the flow arrives at the network, whereas offline solutions like NEPTUNO compute a long-term configuration allocation for the whole network. Our results highlight the potential of data analytics for the self-optimization of the future 5G TNs.},
  archive      = {J_TMC},
  author       = {Jonathan Prados-Garzon and Tarik Taleb and Miloud Bagaa},
  doi          = {10.1109/TMC.2021.3099979},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1672-1687},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimization of flow allocation in asynchronous deterministic 5G transport networks by leveraging data analytics},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the &lt;inline-formula&gt;&lt;tex-math
notation=“LaTeX”&gt;<span
class="math inline"><em>k</em></span>&lt;/tex-math&gt;&lt;mml:math
xmlns:mml=“http://www.w3.org/1998/math/MathML”&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic
xlink:href=“koufos-ieq1-3108067.gif”
xmlns:xlink=“http://www.w3.org/1999/xlink”/&gt;&lt;/inline-formula&gt;
nearest-neighbor path distance from the typical intersection in the
manhattan poisson line cox process. <em>TMC</em>, <em>22</em>(3),
1659–1671. (<a href="https://doi.org/10.1109/TMC.2021.3108067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we calculate the exact cumulative distribution function (CDF) of the path distance (L1 norm) between a randomly selected intersection and the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; th nearest node of the Cox point process driven by the Manhattan Poisson line process. The CDF is expressed as a sum over the integer partition function &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$p\!\left(k\right)$&lt;/tex-math&gt;&lt;/inline-formula&gt; , which allows us to numerically evaluate the CDF in a simple manner. The distance distributions can be used to study the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -coverage of broadcast signals in intelligent transportation systems (ITS) transmitted from a road side unit (RSU) that is located at an intersection. They can also be insightful for network dimensioning in urban vehicle-to-everything (V2X) systems, because they can yield the exact distribution of network load within a cell, provided that the RSU is located at an intersection. Finally, they can find useful applications in other branches of science like spatial databases, emergency response planning, and districting. We corroborate the applicability of the distance distribution model using the map of an urban area.},
  archive      = {J_TMC},
  author       = {Konstantinos Koufos and Harpreet S. Dhillon and Mehrdad Dianati and Carl P. Dettmann},
  doi          = {10.1109/TMC.2021.3108067},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1659-1671},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;koufos-ieq1-3108067.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt; nearest-neighbor path distance from the typical intersection in the manhattan poisson line cox process},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OL-MEDC: An online approach for cost-effective data caching
in mobile edge computing systems. <em>TMC</em>, <em>22</em>(3),
1646–1658. (<a href="https://doi.org/10.1109/TMC.2021.3107918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) has emerged to overcome the inability of cloud computing to offer low latency services. It allows popular data to be cached on edge servers deployed within users’ geographic proximity. However, the storage resources on edge servers are constrained due to their limited physical sizes. Existing studies of edge caching have predominantly focused on maximizing caching performance from the mobile network operator&#39;s perspective, e.g., maximizing data retrieval success rate, minimizing system energy consumption, balancing the overall caching workload, etc. App vendors, as key stakeholders in MEC systems, need to maximize the caching revenue, considering the cost incurred and the benefit produced. We investigate this novel Mobile Edge Data Caching (MEDC) problem from the app vendor&#39;s perspective, and prove its &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {NP}$&lt;/tex-math&gt;&lt;/inline-formula&gt; -hardness. We then propose Online MEDC (OL-MEDC), an approach that formulates MEDC strategies for app vendors, without requiring future information about data demands. Its performance is theoretically analyzed and experimentally evaluated. The experimental results demonstrate that OL-MEDC outperforms state-of-the-art approaches by at least 20.41% on average.},
  archive      = {J_TMC},
  author       = {Xiaoyu Xia and Feifei Chen and Qiang He and Guangming Cui and John Grundy and Mohamed Abdelrazek and Athman Bouguettaya and Hai Jin},
  doi          = {10.1109/TMC.2021.3107918},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1646-1658},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {OL-MEDC: An online approach for cost-effective data caching in mobile edge computing systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Network friendly recommendations: Optimizing for long
viewing sessions. <em>TMC</em>, <em>22</em>(3), 1633–1645. (<a
href="https://doi.org/10.1109/TMC.2021.3109727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Caching algorithms try to predict content popularity, and place the content closer to the users. Additionally, nowadays requests are increasingly driven by recommendation systems (RS). These important trends, point to the following: make RSs favor locally cached content , this way operators reduce network costs, and users get better streaming rates. Nevertheless, this process should preserve the quality of the recommendations (QoR). In this work, we propose a Markov Chain model for a stochastic, recommendation-driven sequence of requests, and formulate the problem of selecting high quality recommendations that minimize the network cost in the long run . While the original optimization problem is non-convex, it can be convexified through a series of transformations. Moreover, we extend our framework for users who show preference in some positions of the recommendations’ list. To our best knowledge, this is the first work to provide an optimal polynomial-time algorithm for these problems. Finally, testing our algorithms on real datasets suggests significant potential, e.g., &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$2\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; improvement compared to baseline recommendations, and 80% compared to a greedy network-friendly-RS (which optimizes the cost for I.I.D. requests), while preserving at least 90% of the original QoR. Finally, we show that taking position preference into account leads to additional performance gains.},
  archive      = {J_TMC},
  author       = {Theodoros Giannakas and Pavlos Sermpezis and Thrasyvoulos Spyropoulos},
  doi          = {10.1109/TMC.2021.3109727},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1633-1645},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Network friendly recommendations: Optimizing for long viewing sessions},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-UAV placement and user association in uplink MIMO
ultra-dense wireless networks. <em>TMC</em>, <em>22</em>(3), 1615–1632.
(<a href="https://doi.org/10.1109/TMC.2021.3108960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an Unmanned Aerial Vehicle (UAV)-enabled network consisting of smart mobile devices and multiple UAVs as aerial base stations in a Multiple-Input Multiple-Output (MIMO) architecture. Mobile devices are partitioned into several clusters and offload their tasks to the UAV servers via the Non-Orthogonal Multiple Access (NOMA) protocol. The main goal of the paper is to jointly maximize the number of served terrestrial users and their scheduling. Moreover, the number of UAV servers and their 3D placement are optimized. To this end, we formulate an optimization problem subject to some Quality of Service (QoS) constraints. The resulting problem is non-convex and intractable to solve. Therefore, we break the problem into two subproblems. We propose an efficient algorithm based on machine learning to solve the first subproblem, i.e., optimizing the number of UAVs and their 3D placements, and the user association. Different from existing literature, our proposed algorithm can achieve low computational complexity and fast convergence. The second subproblem, the user scheduling, is non-convex too. We utilize the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\ell _p$&lt;/tex-math&gt;&lt;/inline-formula&gt; -norm concept to find a convex upper bound for the subproblem and optimize the user scheduling by applying the Successive Convex Approximation (SCA) algorithm. The aforementioned process is performed iteratively until the overall algorithm converges and a near-optimal solution is achieved for the optimization problem. Moreover, the computational complexity of the proposed scheme is analyzed. Finally, we evaluate the performance of our proposed algorithm via the simulation results. Regarding fast convergence and low computational complexity of the proposed algorithm, its superior performance is confirmed through numerical results.},
  archive      = {J_TMC},
  author       = {Nima Nouri and Fahimeh Fazel and Jamshid Abouei and Konstantinos N. Plataniotis},
  doi          = {10.1109/TMC.2021.3108960},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1615-1632},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-UAV placement and user association in uplink MIMO ultra-dense wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-UAV cooperative trajectory for servicing dynamic
demands and charging battery. <em>TMC</em>, <em>22</em>(3), 1599–1614.
(<a href="https://doi.org/10.1109/TMC.2021.3110299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) technology is a promising solution for providing high-quality mobile services (e.g., edge computing, fast Internet connection, and local caching) to ground users, where a UAV with limited service coverage travels among multiple geographical user locations (e.g., hotspots) for servicing their demands locally. How to dynamically determine a UAV swarm&#39;s cooperative path planning to best meet many users’ spatio-temporally distributed demands is an important question but is unaddressed in the literature. To our best knowledge, this paper is the first to design and analyze cooperative path planning algorithms of a large UAV swarm for optimally servicing many spatial locations, where ground users’ demands are released dynamically in the long time horizon. Regarding a single UAV&#39;s path planning design, we manage to substantially simplify the traditional dynamic program and propose an optimal algorithm of low computation complexity, which is only polynomial with respect to both the numbers of spatial locations and user demands. After coordinating a large number &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$K$&lt;/tex-math&gt;&lt;/inline-formula&gt; of UAVs, this simplified dynamic optimization problem becomes intractable and we alternatively present a fast iterative cooperation algorithm with provable approximation ratio &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$1-(1-\frac{1}{K})^{K}$&lt;/tex-math&gt;&lt;/inline-formula&gt; in the worst case, which is proved to obviously outperform the traditional approach of partitioning UAVs to serve different location clusters separately. To relax UAVs’ battery capacity limit for sustainable service provisioning, we further allow UAVs to travel to charging stations in the mean time and thus jointly design UAVs’ path planning over users’ locations and charging stations. Despite of the problem difficulty, for the optimal solution, we successfully transform the problem to an integer linear program by creating novel directed acyclic graph of the UAV-state transition diagram, and propose an iterative algorithm with constant approximation ratio. Finally, we validate the theoretical results by extensive simulations.},
  archive      = {J_TMC},
  author       = {Kai Wang and Xiao Zhang and Lingjie Duan and Jun Tie},
  doi          = {10.1109/TMC.2021.3110299},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1599-1614},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-UAV cooperative trajectory for servicing dynamic demands and charging battery},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mobility load management in cellular networks: A deep
reinforcement learning approach. <em>TMC</em>, <em>22</em>(3),
1581–1598. (<a href="https://doi.org/10.1109/TMC.2021.3107458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing traffic among cellular networks is very challenging due to many factors. Nevertheless, the explosive growth of mobile data traffic necessitates addressing this problem. Due to the problem complexity, data-driven self-optimized load balancing techniques are leading contenders. In this work, we propose a comprehensive deep reinforcement learning (RL) framework for steering the cell individual offset (CIO) as a means for mobility load management. The state of the LTE network is represented via a subset of key performance indicators (KPIs), all of which are readily available to network operators. We provide a diverse set of reward functions to satisfy the operators’ needs. For a small number of cells, we propose using a deep Q-learning technique. We then introduce various enhancements to the vanilla deep Q-learning to reduce bias and generalization errors. Next, we propose the use of actor-critic RL methods, including Deep Deterministic Policy Gradient (DDPG) and twin delayed deep deterministic policy gradient (TD3) schemes, for optimizing CIOs for a large number of cells. We provide extensive simulation results to assess the efficacy of our methods. Our results show substantial improvements in terms of downlink throughput and non-blocked users at the expense of negligible channel quality degradation.},
  archive      = {J_TMC},
  author       = {Ghada Alsuhli and Karim Banawan and Kareem Attiah and Ayman Elezabi and Karim G. Seddik and Ayman Gaber and Mohamed Zaki and Yasser Gadallah},
  doi          = {10.1109/TMC.2021.3107458},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1581-1598},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobility load management in cellular networks: A deep reinforcement learning approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MapFi: Autonomous mapping of wi-fi infrastructure for indoor
localization. <em>TMC</em>, <em>22</em>(3), 1566–1580. (<a
href="https://doi.org/10.1109/TMC.2021.3108155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi CSI-based indoor localization systems can realize decimeter-level localization accuracy. However, these systems require that the location and antenna array orientation of Wi-Fi Access Point (AP) are known in advance, which makes it impractical for large-scale deployment. In this paper, we present MapFi, which can realize autonomous mapping of Wi-Fi infrastructure without labor-intensive site survey. To this end, we focus on addressing three problems. First, as there will be diverse layouts of devices and antennas with respective to numerous and heterogeneous Wi-Fi APs, we propose a general method to estimate AoA and generate the Wi-Fi map. Second, while the existing systems can provide a promising median localization accuracy, tail performance is usually far worse. Consequently, we develop a revision method to reduce tail errors. Third, when deployed in large-scale indoor environment, obstacles and long-distance communication might incur failed CSI collection. Therefore, we segment Wi-Fi APs into groups and finally merge these groups to generate the global Wi-Fi map. We conduct experiments in different scenarios to verify the proposed methods. The experimental results show that we can realize the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$80\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; localization error within &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$1.15m$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$0.74m$&lt;/tex-math&gt;&lt;/inline-formula&gt; in office room and open space respectively, which is as accurate as localization systems requiring known Wi-Fi map.},
  archive      = {J_TMC},
  author       = {Xinyu Tong and Han Wang and Xiulong Liu and Wenyu Qu},
  doi          = {10.1109/TMC.2021.3108155},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1566-1580},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MapFi: Autonomous mapping of wi-fi infrastructure for indoor localization},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight and secure face-based active authentication for
mobile users. <em>TMC</em>, <em>22</em>(3), 1551–1565. (<a
href="https://doi.org/10.1109/TMC.2021.3106256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Authentication (AA) systems continuously authenticate users on smartphones. With high quality front-facing cameras available on recent smartphones, face-based active authentication emerges as a good candidate for AA systems. On the other hand, secure authentication of mobile users is a big concern in biometric systems. Mobile match-on-card (MMOC) technique takes advantage of SIM/eSIM card as a secure element (SE) to protect biometric templates and verify users isolated from the smartphone&#39;s environment. However, resource limitations of smart cards make MMOC authentication hard to implement. In this paper, we propose two system architectures for MMOC face-based AA systems. In Cloud-assisted MMOC architecture (CA-MMOC), we use cloud resources for model selection and training. Full MMOC architecture (F-MMOC) relies only on SIM/eSIM card&#39;s resources for enrollment and verification. A quantization scheme is proposed to make the authentication system implementable on SIM cards, plus a speed-up technique to reduce on-card execution time. Using a public mobile video dataset, we evaluate the proposed system. Our evaluation results show that the proposed MMOC authentication achieves high accuracy in real-time with a small memory footprint on SIM, and is suitable for cross-platform authentication. We also implement the CA-MMOC system on a real smartphone and evaluate the system&#39;s performance overhead in terms of power consumption, CPU and memory usage.},
  archive      = {J_TMC},
  author       = {Sepehr Keykhaie and Samuel Pierre},
  doi          = {10.1109/TMC.2021.3106256},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1551-1565},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Lightweight and secure face-based active authentication for mobile users},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Jamming-resilient message dissemination in wireless
networks. <em>TMC</em>, <em>22</em>(3), 1536–1550. (<a
href="https://doi.org/10.1109/TMC.2021.3108004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper initiates the study for the basic primitive of distributed message dissemination in multi-hop wireless networks under a strong adversarial jamming model. Specifically, the message dissemination problem is to deliver a message initiating at a source node to the whole network. An efficient algorithm for message dissemination can be an important building block for solving a variety of high-level network tasks. We consider the hard non-spontaneous wakeup case, where a node only wakes up when it receives a message. Under the realistic SINR model and a strong adversarial jamming model that removes the budget constraint commonly adopted in previous work by the adversary, we present a distributed randomized algorithm that can accomplish message dissemination in &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathscr {T}(O(D(\log n+\log R)))$&lt;/tex-math&gt;&lt;/inline-formula&gt; time slots with a high probability performance guarantee, where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathscr {T}(U)$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the number of time slots in the interval from the beginning of the algorithm&#39;s execution that contains &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$U$&lt;/tex-math&gt;&lt;/inline-formula&gt; unjammed time slots, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the number of nodes in the network, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$D$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the network diameter, and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$R$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the distance with respect to which the network is connected. Our algorithm is shown to be almost asymptotically optimal by the lower bound &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\Omega (D\log n)$&lt;/tex-math&gt;&lt;/inline-formula&gt; for non-spontaneous message dissemination in networks without jamming.},
  archive      = {J_TMC},
  author       = {Yifei Zou and Dongxiao Yu and Pengfei Hu and Jiguo Yu and Xiuzhen Cheng and Prasant Mohapatra},
  doi          = {10.1109/TMC.2021.3108004},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1536-1550},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Jamming-resilient message dissemination in wireless networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving end-to-end throughput in multi-hop wireless
networks with cut-through capability. <em>TMC</em>, <em>22</em>(3),
1521–1535. (<a href="https://doi.org/10.1109/TMC.2021.3109901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless cut-through transmission, based on in-band full-duplex (FD) technique, has a great potential to improve the end-to-end throughput of a multi-hop wireless network via enabling simultaneous multi-hop relaying transmissions in the same frequency band. Different from single-hop relaying transmission in traditional half-duplex multi-hop network, cut-through transmission has multiple relaying transmission modes, which makes it more difficult to achieve the maximum end-to-end throughput via improving the spatial reuse in a multi-hop wireless network. The goal of this paper is to improve the end-to-end throughput in multi-hop wireless networks with cut-through capability. In particular, we first establish an effective analytical model and find that the achievable end-to-end throughput is mainly determined by the cut-through mode, the spatial reuse factor, the protocol overhead, and the channel rate. Then, we give a comprehensive analysis for these factors in a string-topology multi-hop wireless network. In order to improve the end-to-end throughput in a practical distributed multi-hop wireless network, we design a low-overhead distributed medium access control (MAC) protocol, and propose a transmit-delay mechanism to improve spatial reuse and link scheduling. Furthermore, we design an algorithm to adaptively select the transmission parameters, including the cut-through mode, the spatial reuse factor, and the channel rate. Extensive simulations show that the proposed MAC design can effectively improve the end-to-end throughput by more than 55 percent, compared with the state-of-the-art protocol.},
  archive      = {J_TMC},
  author       = {Shengbo Liu and Liqun Fu},
  doi          = {10.1109/TMC.2021.3109901},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1521-1535},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Improving end-to-end throughput in multi-hop wireless networks with cut-through capability},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast batch reading densely deployed QR codes. <em>TMC</em>,
<em>22</em>(3), 1507–1520. (<a
href="https://doi.org/10.1109/TMC.2021.3106763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents BatchQR, a mobile APP that can batch read densely arranged QR codes attached to caps of the tubes and vials in clinical and biological labs. BatchQR could work in two modes: photo mode and preview mode, which are respectively suitable for scenarios that favor one-time batch processing capacity and real-time tracking performance. For the photo mode, we first propose an IFFT based lightweight code detection mechanism, which can adaptively adjust operating parameters to identify densely arranged QR codes in practice. We propose an image refocus mechanism to deal with blurs/distorts that may appear in the photo, and a lightweight learning based classifier to filter out falsely detected QR codes. We further optimize BatchQR by enabling batch reading in the preview mode of the camera, which is more in line with common usage habits. To this end, we develop a QR code tracking algorithm based on Kalman filtering, which keeps track of each code image dynamically. We also design a parallel acceleration mechanism based on multi-core CPU and GPU, which significantly mitigates the end-to-end delay. Comprehensive experimental results show that BatchQR can read up to 160 Version 1-H QR codes in one shot, with 95 percent accuracy and 100-400ms delay, which is only 0.1 percent of the time consumed by the regular QR code reader in the same situation.},
  archive      = {J_TMC},
  author       = {Xiaohua Tian and Shaofei Qin and Binyao Jiang and Yuan Gao and Xinbing Wang},
  doi          = {10.1109/TMC.2021.3106763},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1507-1520},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fast batch reading densely deployed QR codes},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EPNS: Efficient privacy-preserving intelligent traffic
navigation from multiparty delegated computation in cloud-assisted
VANETs. <em>TMC</em>, <em>22</em>(3), 1491–1506. (<a
href="https://doi.org/10.1109/TMC.2021.3110718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time navigation is an essential service in many applications, such as intelligent transportation and crowdsensing. There are, however, considerations (e.g., the potential of location privacy breach for vehicular users) in real-time navigation services. We observe that most existing state-of-the-art approaches utilize either pseudonyms or public key fully homomorphic encryption (FHE) to protect location privacy. The former (pseudonym-based approach) relies on an online certificate authority (CA) to update pseudonym certificates periodically, and FHE-based approaches incur significant computational/communication overheads. In this paper, a new cryptographic primitive, coined efficient multiparty delegated computation (MPDC), is proposed, where any one-way trapdoor permutation is required to perform in constant time (e.g., twice in our context) on each resource-constrained data provider for the encryption of (multiple) messages in a batch. We also remark that MPDC is designed to support secure evaluations (e.g., addition, multiplication, equality, and less than operations) over ciphertexts encrypted under multiple keys associated with different entities. Building on MPDC, we devise a lightweight privacy-preserving real-time intelligent traffic navigation scheme (EPNS) for cloud-assisted vehicular ad hoc networks (VANETs). The proposed approach facilitates the prediction of an optimal driving route, in terms of the shortest time from source to destination. In other words, EPNS securely evaluates the auto-regression moving average (ARMA) model with spatiotemporal correlations of high accuracy and efficiency. Therefore, neither vehicular users’ private location information nor the navigation result will be disclosed, even in the presence of colluding semi-trusted cloud server (or cryptography service provider, CSP) and unauthorized users. Finally, we prove the security and demonstrate the utility of both MPDC and EPNS.},
  archive      = {J_TMC},
  author       = {Jun Zhou and Shiying Chen and Kim-Kwang Raymond Choo and Zhenfu Cao and Xiaolei Dong},
  doi          = {10.1109/TMC.2021.3110718},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1491-1506},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EPNS: Efficient privacy-preserving intelligent traffic navigation from multiparty delegated computation in cloud-assisted VANETs},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient resource scheduling for interference alleviation
in dynamic coexisting WBANs. <em>TMC</em>, <em>22</em>(3), 1479–1490.
(<a href="https://doi.org/10.1109/TMC.2021.3110235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interference is a serious problem in Wireless Body Area Networks (WBANs) and heavily weakens system performance. In this paper, we propose an exchange-free resource scheduling scheme to overcome the interference of dynamic coexisting WBANs. For each data transmission period, we design a transmission channel/slot allocation scheme based on a Latin square, where each character denotes a specific combination of a channel and a time slot. For each data retransmission period, we design a retransmission time-slot selection scheme based on a hash function, in which the unique identity information of the collided node is used to calculate the retransmission slot. Compared with existing solutions, our work has two key advantages. First, all nodes can independently allocate and coordinate resources rather than exchange information with each other in traditional methods, and thus guaranteeing strong adaptability to the fast changes of WBANs. Second, the contention-free resource allocation pattern is implemented for both the data transmission period as well as the data retransmission period, and thus guaranteeing no intra-WBAN interference and extremely low probability of inter-WBAN interference. Our simulation results show that interferences can be well addressed based on the metrics of the packet loss rate, throughput, power dissipation, and data delivery delay.},
  archive      = {J_TMC},
  author       = {Ling Fan and Xuxun Liu and Huan Zhou and Victor C. M. Leung and Jian Su and Alex X. Liu},
  doi          = {10.1109/TMC.2021.3110235},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1479-1490},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Efficient resource scheduling for interference alleviation in dynamic coexisting WBANs},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge intelligence for adaptive multimedia streaming in
heterogeneous internet of vehicles. <em>TMC</em>, <em>22</em>(3),
1464–1478. (<a href="https://doi.org/10.1109/TMC.2021.3106147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) is envisioned as a promising solution to real-time services in Internet of Vehicles (IoV) by enabling edge caching, computing and communication. However, it is still challenging to implement multimedia streaming in MEC-based IoV due to dynamic vehicular environments and heterogeneous network resources. In this paper, we present an MEC-based architecture for adaptive-bitrate-based (ABR) multimedia streaming in IoV, where each multimedia file is segmented into multiple chunks encoded with different bitrate levels. Then, we formulate a joint resource optimization (JRO) problem by synthesizing heterogeneous edge cache and communication resource constraints, which aims at achieving both smooth play and high-quality service by optimizing chunk placement and transmission. For chunk placement, a multi-armed bandit (MAB) algorithm is proposed for online scheduling with low overhead but slow convergence. Further, a deep-Q-learning algorithm is proposed to improve cache reward and speed up convergence by using replay memory for repeatedly training. For chunk transmission, we design an adaptive-quality-based chunk selection (AQCS) algorithm, which determines bandwidth allocation and quality level based on a benefit function incorporating quality level, available playback time, and freezing delay. Lastly, we build the simulation model and give comprehensive performance evaluation, which demonstrates the superiority of proposed algorithms.},
  archive      = {J_TMC},
  author       = {Penglin Dai and Feng Song and Kai Liu and Yueyue Dai and Pan Zhou and Songtao Guo},
  doi          = {10.1109/TMC.2021.3106147},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1464-1478},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Edge intelligence for adaptive multimedia streaming in heterogeneous internet of vehicles},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Demand response in NOMA-based mobile edge computing: A
two-phase game-theoretical approach. <em>TMC</em>, <em>22</em>(3),
1449–1463. (<a href="https://doi.org/10.1109/TMC.2021.3108581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC), as a key technology that facilitates 5G networks, provides a new and prospective mobile computing paradigm that allows the deployment of edge servers at base stations geographically close to mobile users to reduce their end-to-end network latency. Similar to cloud servers, edge servers running 24/7 in an MEC system consume a large amount of energy, contribute a significant proportion of global carbon emissions, and thus require demand response management. Demand response has been widely employed to reduce energy consumption at data centers. However, existing demand response approaches for data centers are rendered obsolete by the new and unique characteristics of MEC systems: 1) proximity constraint - mobile users can be served by neighbor edge servers only; 2) latency constraint - mobile users’ workloads should be processed by their neighbor edge servers to ensure low latency; and 3) capacity constraint - edge servers have limited computing and communication resources to serve mobile users. Demand response for MEC is further complicated by the non-orthogonal multiple access (NOMA) scheme - the emerging radio access scheme for 5G. Communication resources like channels and transmit power in the NOMA-based MEC system must be systematically considered with computing resources like CPU, memory and storage to fulfill mobile users’ resource demands. This paper makes the first attempt to tackle this Edge Demand Response (EDR) problem. We first formulate this problem and prove its &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {NP}$&lt;/tex-math&gt;&lt;/inline-formula&gt; -hardness. Then, we propose a two-phase game-theoretical approach, named EDRGame, to solve the EDR problem. Its performance is theoretically analyzed and experimentally evaluated against three baseline approaches and two state-of-the-art approaches on a widely-used real-world dataset. The results show that it solves the EDR problem effectively and efficiently.},
  archive      = {J_TMC},
  author       = {Guangming Cui and Qiang He and Xiaoyu Xia and Feifei Chen and Tao Gu and Hai Jin and Yun Yang},
  doi          = {10.1109/TMC.2021.3108581},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1449-1463},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Demand response in NOMA-based mobile edge computing: A two-phase game-theoretical approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning video analytics through edge computing and
neural processing units on mobile devices. <em>TMC</em>, <em>22</em>(3),
1433–1448. (<a href="https://doi.org/10.1109/TMC.2021.3105953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many mobile applications have been developed to apply deep learning for video analytics. Although these advanced deep learning models can provide us with better results, they also suffer from the high computational overhead which means longer delay and more energy consumption when running on mobile devices. To address this issue, we propose a framework called FastVA, which supports deep learning video analytics through edge processing and Neural Processing Unit (NPU) in mobile. The major challenge is to determine when to offload the computation and when to use NPU. Based on the processing time and accuracy requirement of the mobile application, we study three problems: Max-Accuracy where the goal is to maximize the accuracy under some time constraints, Max-Utility where the goal is to maximize the utility which is a weighted function of processing time and accuracy, and Min-Energy where the goal is to minimize the energy under some time and accuracy constraints. We formulate them as integer programming problems and propose heuristics based solutions. We have implemented FastVA on smartphones and demonstrated its effectiveness through extensive evaluations.},
  archive      = {J_TMC},
  author       = {Tianxiang Tan and Guohong Cao},
  doi          = {10.1109/TMC.2021.3105953},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1433-1448},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Deep learning video analytics through edge computing and neural processing units on mobile devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Deduplication-oriented mutual-assisted cooperative video
upload for mobile crowd sensing. <em>TMC</em>, <em>22</em>(3),
1417–1432. (<a href="https://doi.org/10.1109/TMC.2021.3111535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of portable embedded cameras makes it easy for mobile users to collaboratively collect environmental sensing videos in network-underdeveloped or disaster-affected zones. Compared with in other scenes, the video upload in disaster areas is more challenging due to intermittent wireless connections and moving transmission destinations. Deduplication (redundancy elimination) and cooperative video transmission are two effective ways to ensure timely video collection in damaged networks. However, deduplication in mobile crowd sensing (MSC) is primarily performed on texts and images. Furthermore, most of deduplication technologies require global information and are separated from video transmission routing. To solve such problems, this paper proposes a collaborative upload method of sensing videos, which performs the local video deduplication without excessive comparisons and feature exchanges. Also, we combine the two-round deduplication with the content-aware dynamic routing to avoid the propagation of redundant items caused by the content-free video routing. Besides, we integrate a novel mutual-assisted mechanism into our method to motivate relay cooperation and achieve load balance. We formulate the deduplication-supported collaborative video upload as a multi-stage decision problem. To tackle the time-varying destinations and the local deduplication during transmission in the decision problem, we develop a stepwise Mutual-Assisted Video Upload Algorithm (MAVUA) to route videos and remove duplicates. Extensive numerical validations are conducted to compare MAVUA with the existing algorithms. The numerical results demonstrate that MAVUA can save roughly 11% transmission time and achieve 80% load balancing improvement.},
  archive      = {J_TMC},
  author       = {Ying Wang and Quyuan Wang and Songtao Guo and Yuanyuan Yang},
  doi          = {10.1109/TMC.2021.3111535},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1417-1432},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Deduplication-oriented mutual-assisted cooperative video upload for mobile crowd sensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CrowdPatrol: A mobile crowdsensing framework for traffic
violation hotspot patrolling. <em>TMC</em>, <em>22</em>(3), 1401–1416.
(<a href="https://doi.org/10.1109/TMC.2021.3110592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic violations have become one of the major threats to urban transportation systems, undermining human safety and causing economic losses. To alleviate this problem, crowd-based patrol forces including traffic police and voluntary participants have been employed in many cities. To adaptively optimize patrol routes with limited manpower, it is essential to be aware of traffic violation hotspots. Traditionally, traffic violation hotspots are directly inferred from experience, and existing patrol routes are usually fixed. In this paper, we propose a mobile crowdsensing-based framework to dynamically infer traffic violation hotspots and adaptively schedule crowd patrol routes. Specifically, we first extract traffic violation-prone locations from heterogeneous crowd-sensed data and propose a spatiotemporal context-aware self-adaptive learning model (CSTA) to infer traffic violation hotspots. Then, we propose a tensor-based integer linear problem modeling method (TILP) to adaptively find optimal patrol routes under human labor constraints. Experiments on real-world data from two Chinese cities (Xiamen and Chengdu) show that our approach accurately infers traffic violation hotspots with F1-scores above 90% in both cities, and generates patrol routes with relative coverage ratios above 85%, significantly outperforming baseline methods.},
  archive      = {J_TMC},
  author       = {Zhihan Jiang and Hang Zhu and Binbin Zhou and Chenhui Lu and Mingfei Sun and Xiaojuan Ma and Xiaoliang Fan and Cheng Wang and Longbiao Chen},
  doi          = {10.1109/TMC.2021.3110592},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1401-1416},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CrowdPatrol: A mobile crowdsensing framework for traffic violation hotspot patrolling},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cost-driven data caching in edge-based content delivery
networks. <em>TMC</em>, <em>22</em>(3), 1384–1400. (<a
href="https://doi.org/10.1109/TMC.2021.3108150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study a data caching problem in edge-based content delivery network (CDN) where a data item is shared between service requests. Instead of improving the hit ratio with respect to limited capacity as in traditional case, we study the problem based on a semi-homogeneous (semi-homo) cost model in the edge-based CDN with monetary cost reduction as a goal. The cost model is semi-homo in the sense that all pairs of caching nodes have the same transfer cost, but each has its own caching cost rate. In particular, given a stream of requests &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\mathcal R}$&lt;/tex-math&gt;&lt;/inline-formula&gt; to a shared data item in the edge network, we present a shortest-path based optimal off-line caching algorithm that can minimize the total transfer and caching costs within &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(mn)$&lt;/tex-math&gt;&lt;/inline-formula&gt; time ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$m:$&lt;/tex-math&gt;&lt;/inline-formula&gt; the number of network nodes, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n:$&lt;/tex-math&gt;&lt;/inline-formula&gt; the length of request stream) in a proactive fashion. While for the online case, by extending the anticipatory caching idea, we also propose a 2-competitive online reactive caching algorithm and show its tightness by giving a lower bound of the competitive ratio as &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$2-o(1)$&lt;/tex-math&gt;&lt;/inline-formula&gt; for any deterministic online algorithm. Finally, to combine the advantages of both algorithms and evaluate our findings, we also design a hybrid algorithm. Our trace-based empirical studies show that the proposed algorithms not only improve the previous results in both time complexity and competitive ratio, but also relax the cost model to semi-homogeneity, rendering the algorithms more practical in reality. We provably achieve these results with our deep insights into the problem and careful analysis of the solutions, together with a prototype framework.},
  archive      = {J_TMC},
  author       = {Yang Wang and Hao Dai and Xinxin Han and Pengfei Wang and Yong Zhang and Chengzhong Xu},
  doi          = {10.1109/TMC.2021.3108150},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1384-1400},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cost-driven data caching in edge-based content delivery networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chase or wait: Dynamic UAV deployment to learn and catch
time-varying user activities. <em>TMC</em>, <em>22</em>(3), 1369–1383.
(<a href="https://doi.org/10.1109/TMC.2021.3107027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) technology is a promising solution for rapidly providing wireless communication services to ground users, where a UAV has limited service coverage and needs to fly through users at different locations for serving them locally. The existing UAV deployment studies largely assume the users’ demands do not change during UAV deployment. When the users’ demands dynamically change over time, the key challenge is how to adapt the UAV deployment strategy to the partial and even outdated observations on the users’ activities given the UAV&#39;s flying speed limit. In this paper, we study dynamic UAV deployment to learn and adapt to the time-varying user activities, where the activity pattern of a user (if out of the UAV service coverage) is hidden from the UAV and follows a time-slotted Markov chain that switches between active and idle states. We formulate the learning-and-adaption based UAV deployment problem as a partially observable Markov decision process (POMDP) to maximize the total discounted hit rate of active users, where the UAV decides for itself whether to chase an active user in a distant location (with delayed reward) or to wait for the idle user in the current location to return to the active state (with smaller service probability) over time. We show there is a fundamental delay-reward tradeoff, and prove that the UAV will optimally follow a threshold-based policy by waiting at an idle user for a time threshold before moving to another user. We also show the UAV is more likely to move if the temporal correlation of each user&#39;s idling pattern is stronger or the travel distance between users is shorter. Furthermore, we extend to a more general scenario where the UAV does not even know the parameters of each user&#39;s temporal activity distribution, and apply Q-learning to develop another threshold-based deployment policy for a multi-user scenario.},
  archive      = {J_TMC},
  author       = {Zhe Wang and Lingjie Duan},
  doi          = {10.1109/TMC.2021.3107027},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1369-1383},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Chase or wait: Dynamic UAV deployment to learn and catch time-varying user activities},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binarized neural network for edge intelligence of
sensor-based human activity recognition. <em>TMC</em>, <em>22</em>(3),
1356–1368. (<a href="https://doi.org/10.1109/TMC.2021.3109940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wide diversity of sensors has been applied in human activity recognition. These sensors generate enormous amounts of data during human activity monitoring. Server-based computing and cloud computing require to upload all sensor data to servers/clouds for data processing and analysis. The long-distance data traveling between sensors and servers increases the costs of bandwidth and latency. However, human activity recognition has a high demand for real-time processing. Recently, edge computing is surging to solve this problem by moving computation and data storage closer to the sensors, rather than relying on a central server/cloud. Most human activity recognition is conducted by artificial intelligence, which requires intensive computation and high power consumption. Edge servers are usually designed for low power, low cost, and low computation. They do not support computation-intensive deep learning algorithms or result in high latency. Fortunately, the development of binarized neural networks enables edge intelligence, which supports AI running at the network edge for real-time applications. In this paper, we implement a binarized neural network ( BinaryDilatedDenseNet ) to enable low-latency and low-memory human activity recognition at the network edge. We applied the BinaryDilatedDenseNet on three sensor-based human activity recognition datasets and evaluated it with four metrics. In comparison, the BinaryDilatedDenseNet outperforms the related work and other three binarized neural networks in overall and saves &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$10\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; memory and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$4.5\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; – &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$8\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; inference time compared to the FPDilatedDenseNet(the full-precision version of the BinaryDilatedDenseNet).},
  archive      = {J_TMC},
  author       = {Fei Luo and Salabat Khan and Yandao Huang and Kaishun Wu},
  doi          = {10.1109/TMC.2021.3109940},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1356-1368},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Binarized neural network for edge intelligence of sensor-based human activity recognition},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AoI minimization data collection scheduling for battery-free
wireless sensor networks. <em>TMC</em>, <em>22</em>(3), 1343–1355. (<a
href="https://doi.org/10.1109/TMC.2021.3106013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age of Information (AoI) is a new metric for measuring the freshness of sensory data in wireless sensor networks. The Battery-Free Wireless Sensor Network (BF-WSN) is proposed to break through the lifetime limitation of battery-powered wireless sensor networks. However, the emerging BF-WSN also brings challenges to the minimization of AoI, on account of its energy characteristics. In this paper, we investigate the AoI minimization data collection scheduling problem for BF-WSNs. The off-the-shelf works for the AoI minimization data collection scheduling problem either focus on simple networks with no more than three nodes or assume that battery-free sensor nodes have specific energy harvesting process, such as Bernoulli process and Poisson process. Different from these works, we first consider the AoI minimization data collection scheduling for one-hop BF-WSNs with multiple battery-free sensor nodes transmitting their sensory data to the sink node, where the energy harvesting processes of battery-free sensor nodes are non-specific. We propose the optimal offline algorithm and the online algorithm for the problem, respectively. The optimality of the offline algorithm and the competitive ratio of the online algorithm are theoretical proved and analyzed. Numerical results are provided to verify the performances of the proposed algorithms.},
  archive      = {J_TMC},
  author       = {Tongxin Zhu and Jianzhong Li and Hong Gao and Yingshu Li and Zhipeng Cai},
  doi          = {10.1109/TMC.2021.3106013},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1343-1355},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AoI minimization data collection scheduling for battery-free wireless sensor networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). An efficient cooperative transmission based opportunistic
broadcast scheme in VANETs. <em>TMC</em>, <em>22</em>(3), 1327–1342. (<a
href="https://doi.org/10.1109/TMC.2021.3105982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vehicular ad hoc networks (VANETs), quick and reliable multi-hop broadcasting is important for the dissemination of emergency warning messages. By scheduling multiple nodes to transmit messages concurrently and cooperatively, cooperative transmission based broadcast schemes may yield much better broadcast performance than conventional broadcast schemes. However, a cooperative transmission requires multiple relays to achieve strict synchronization on both time and frequency, which may induce high cost for a cooperative transmission process. In this paper, we analyze the cost and benefit of a cooperative transmission for data broadcasting in vehicular networks, and introduce a new metric called the single-hop broadcast efficiency (SBE) to evaluate the overall broadcast performance. We propose an efficient, non-deterministic cooperation mechanism to reduce the cooperation cost. The mechanism maximizes the expected broadcast performance by selecting cooperators with the largest expected SBE value for a lead relay, and initiates cooperative broadcasting process when the expected SBE value is larger than that of a single-relay based broadcasting. Based on the non-deterministic mechanism, we propose an efficient, cooperative transmission based opportunistic broadcast (ECTOB) scheme which further utilizes rebroadcast to improve the reliability of the broadcast scheme. Simulation results show that the proposed scheme outperforms the conventional ones.},
  archive      = {J_TMC},
  author       = {Hui Zhang and Xinming Zhang and Dan Keun Sung},
  doi          = {10.1109/TMC.2021.3105982},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1327-1342},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An efficient cooperative transmission based opportunistic broadcast scheme in VANETs},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive user-managed service placement for mobile edge
computing via contextual multi-armed bandit learning. <em>TMC</em>,
<em>22</em>(3), 1313–1326. (<a
href="https://doi.org/10.1109/TMC.2021.3106746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC), envisioned as a cloud extension, pushes cloud resource from the network core to the network edge, thereby meeting the stringent service requirements of many emerging computation-intensive mobile applications. Many existing works have focused on studying the system-wide MEC service placement issues, personalized service performance optimization yet receives much less attention. As motivated, in this paper we propose a novel adaptive user-managed service placement mechanism, which jointly optimizes a user&#39;s perceived-latency and service migration cost, weighted by user-specific preferences. We first formulate the user-managed dynamic service placement process with limited system information as a contextual multi-armed bandit learning problem. In particular, we investigate both cases without and with neighboring edge feedbacks, where the later considers edge information sharing for more informed decision making. For both cases, we design lightweight Thompson-sampling based online learning algorithms, which can efficiently assist the user to make adaptive service placement decisions. We further conduct a novel information-directed theoretical analysis on the regret bound of the proposed online learning algorithms and reveal the structural impact of edge information sharing. Extensive evaluations demonstrate the superior performance gain of the proposed adaptive user-managed service placement mechanism over existing learning schemes.},
  archive      = {J_TMC},
  author       = {Tao Ouyang and Xu Chen and Zhi Zhou and Rui Li and Xin Tang},
  doi          = {10.1109/TMC.2021.3106746},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1313-1326},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive user-managed service placement for mobile edge computing via contextual multi-armed bandit learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive and heterogeneity-aware coded cooperative
computation at the edge. <em>TMC</em>, <em>22</em>(3), 1301–1312. (<a
href="https://doi.org/10.1109/TMC.2021.3106250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative computation is a promising approach for localized data processing at the edge, e.g., for Internet of Things (IoT). Cooperative computation advocates that computationally intensive tasks in a device could be divided into sub-tasks, and offloaded to other devices or servers in close proximity. However, exploiting the potential of cooperative computation is challenging mainly due to the heterogeneous and time-varying nature of edge devices. Coded computation, which advocates mixing data in sub-tasks by employing erasure codes and offloading these sub-tasks to other devices for computation, is recently gaining interest, thanks to its higher reliability, smaller delay, and lower communication costs. In this article, we develop a coded cooperative computation framework, which we name Coded Cooperative Computation Protocol ( C3P ), by taking into account the heterogeneous and time-varying resources of edge devices. C3P dynamically offloads coded sub-tasks to helpers and is adaptive to time-varying resources. We show that (i) task completion delay of C3P is very close to optimal coded cooperative computation solutions, (ii) the efficiency of C3P in terms of resource utilization is higher than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$99\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; , and (iii) C3P improves task completion delay significantly as compared to baselines via both simulations and in a testbed consisting of real Android-based smartphones.},
  archive      = {J_TMC},
  author       = {Yasaman Keshtkarjahromi and Yuxuan Xing and Hulya Seferoglu},
  doi          = {10.1109/TMC.2021.3106250},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1301-1312},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive and heterogeneity-aware coded cooperative computation at the edge},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel software defined radio for practical, mobile
crowdsourced spectrum sensing. <em>TMC</em>, <em>22</em>(3), 1289–1300.
(<a href="https://doi.org/10.1109/TMC.2021.3107409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defined radios (SDRs) are often used in the experimental evaluation of next-generation wireless technologies. While crowdsourced spectrum monitoring is an important component of future spectrum-agile technologies, there is no clear way to test it in the real world, i.e., with hundreds of users each carrying an SDR while uploading data to a cloud-based controller. Current fully functional SDRs are bulky, with components connected via wires, and last at most hours on a single battery charge. To address these needs, we design and develop a compact, portable, untethered, and inexpensive SDR we call Sitara . Our SDR interfaces with a mobile device over Bluetooth 5 and can function standalone or as a client to a central command and control server. It transmits and receives common waveforms, uploads IQ samples or processed receiver data through a mobile device to a server for remote processing and performs spectrum sensing functions. We present results from a user study involving more than 100 participants to evaluate Sitara in a hypothetical large-scale crowdsourced spectrum monitoring application. We also present a comparative analysis of Sitara to related crowdsensing systems with a particular emphasis on the role of incentives and user participation.},
  archive      = {J_TMC},
  author       = {Phillip Smith and Anh Luong and Shamik Sarkar and Harsimran Singh and Aarti Singh and Neal Patwari and Sneha Kasera and Kurt Derr},
  doi          = {10.1109/TMC.2021.3107409},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1289-1300},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A novel software defined radio for practical, mobile crowdsourced spectrum sensing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A co-scheduling framework for DNN models on mobile and edge
devices with heterogeneous hardware. <em>TMC</em>, <em>22</em>(3),
1275–1288. (<a href="https://doi.org/10.1109/TMC.2021.3107424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of more and more powerful chipsets and hardware and the rise of Artificial Intelligence of Things (AIoT), there is a growing trend for bringing Deep Neural Network (DNN) models to empower mobile and edge devices with intelligence such that they can support attractive AI applications on the edge in a real-time or near real-time manner. To leverage heterogeneous computational resources (such as CPU, GPU, DSP, etc) to effectively and efficiently support concurrent inference of multiple DNN models on a mobile or edge device, we propose a novel online Co-Scheduling framework based on deep REinforcement Learning (DRL), which we call COSREL. COSREL has the following desirable features: 1) it achieves significant speedup over commonly-used methods by efficiently utilizing all the computational resources on heterogeneous hardware; 2) it leverages emerging Deep Reinforcement Learning (DRL) to make dynamic and wise online scheduling decisions based on system runtime state; 3) it is capable of making a good tradeoff among inference latency, throughput and energy efficiency; and 4) it makes no changes to given DNN models, thus preserves their accuracies. To validate and evaluate COSREL, we conduct extensive experiments on an off-the-shelf Android smartphone with widely-used DNN models to compare it with three commonly-used baselines. Our experimental results show that 1) COSREL consistently and significantly outperforms all the baselines in terms of both throughput and latency; and 2) COSREL is generally superior to all the baselines in terms of energy efficiency.},
  archive      = {J_TMC},
  author       = {Zhiyuan Xu and Dejun Yang and Chengxiang Yin and Jian Tang and Yanzhi Wang and Guoliang Xue},
  doi          = {10.1109/TMC.2021.3107424},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1275-1288},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A co-scheduling framework for DNN models on mobile and edge devices with heterogeneous hardware},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 5G multi-band numerology-based TDD RAN slicing for
throughput and latency sensitive services. <em>TMC</em>, <em>22</em>(3),
1263–1274. (<a href="https://doi.org/10.1109/TMC.2021.3106323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extensively examines the impact of the numerology schemes on a sliced TDD radio access network. The slices are multiplexed over both the sub-6 GHz and mmWave bands. The incorporation of numerology schemes into network slicing, the impact of which has yet to be explored, will be highly instrumental in realizing the future 5G and 6G networks. Thus, this work demonstrates the enhanced capabilities of sliced networks utilizing numerology. To that end, two optimization problems are formulated, one to maximize the downlink average spectral efficiency of a throughput-sensitive slice, and the other to minimize the uplink transmission power of the users of the latency-sensitive slice. This work optimizes key parameters such as duplex ratio, numerology scheme and optimally allocates power and bandwidth under numerology-enabled slicing. The comparative analyses highlight that for high-throughput applications, lower numerology schemes are significantly more spectrally efficient and can often achieve throughputs characteristic of higher schemes. On the other hand, the higher schemes are the best choice for the minimization of user transmission power and latency, which are crucial in energy-efficient communications and edge computing applications, respectively.},
  archive      = {J_TMC},
  author       = {Abdullah Hossain and Nirwan Ansari},
  doi          = {10.1109/TMC.2021.3106323},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1263-1274},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {5G multi-band numerology-based TDD RAN slicing for throughput and latency sensitive services},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flying among stars: Jamming-resilient channel selection for
UAVs through aerial constellations. <em>TMC</em>, <em>22</em>(3),
1246–1262. (<a href="https://doi.org/10.1109/TMC.2021.3102883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless communication between an unmanned aerial vehicle (UAV) and the ground base station is susceptible to adversarial jamming. In such situations, it is important for the UAV to indicate a new channel to the BS. This paper describes a method of creating spatial codes that map the chosen channel to the location of the UAVs in space, wherein the latter physically traverses the space from a given so called ”constellation points” to another. These points create patterns in the sky, analogous to modulation constellations in classical wireless communications, and are detected at the BS through a millimeter-wave radar sensor. A constellation point represents a distinct n-bit field mapped to a specific channel, allowing simultaneous frequency switching at both ends without any RF transmissions. The main contributions of this paper are: (i) We conduct experimental studies to demonstrate how such constellations may be formed using COTS UAVs and mmWave sensors, (ii) We develop a theoretical framework that maps a desired constellation design to error and band switching time, including multi-user scenario-specific challenges, (iii) We compare our approach against current FHSS technology and (iv) We experimentally demonstrate jamming resilient communications and validate system goodput for links formed by UAV-mounted software defined radios.},
  archive      = {J_TMC},
  author       = {Guillem Reus-Muns and Mithun Diddi and Chetna Singhal and Hanumant Singh and Kaushik Roy Chowdhury},
  doi          = {10.1109/TMC.2021.3102883},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1246-1262},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Flying among stars: Jamming-resilient channel selection for UAVs through aerial constellations},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VECMAN: A framework for energy-aware resource management in
vehicular edge computing systems. <em>TMC</em>, <em>22</em>(2),
1231–1245. (<a href="https://doi.org/10.1109/TMC.2021.3089338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Vehicular Edge Computing (VEC) systems, the computing resources of connected Electric Vehicles (EV) are used to fulfill the low-latency computation requirements of vehicles. However, local execution of heavy workloads may drain a considerable amount of energy in EVs. One promising way to improve the energy efficiency is to share and coordinate computing resources among connected EVs. However, the uncertainties in the future location of vehicles make it hard to decide which vehicles participate in resource sharing and how long they share their resources so that all participants benefit from resource sharing. In this paper, we propose VECMAN, a framework for energy-aware resource management in VEC systems composed of two algorithms: (i) a resource selector algorithm that determines the participating vehicles and the duration of resource sharing period; and (ii) an energy manager algorithm that manages computing resources of the participating vehicles with the aim of minimizing the computational energy consumption. We evaluate the proposed algorithms and show that they considerably reduce the vehicles’ computational energy consumption compared to the state-of-the-art baselines. Specifically, our algorithms achieve between 7 and 18 percent energy savings compared to a baseline that executes workload locally and an average of 13 percent energy savings compared to a baseline that offloads vehicles’ workloads to RSUs.},
  archive      = {J_TMC},
  author       = {Tayebeh Bahreini and Marco Brocanelli and Daniel Grosu},
  doi          = {10.1109/TMC.2021.3089338},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1231-1245},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {VECMAN: A framework for energy-aware resource management in vehicular edge computing systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding the long-term evolution of mobile app usage.
<em>TMC</em>, <em>22</em>(2), 1213–1230. (<a
href="https://doi.org/10.1109/TMC.2021.3098664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of smartphones has promoted the popularity of mobile apps in recent years. Although significant effort has been made to understand mobile app usage, existing studies are based primarily on short-term datasets with a limited time span, e.g., a few months. Therefore, many basic facts about the long-term evolution of mobile app usage are unknown. In this paper, we study how mobile app usage evolves over a long-term period. We first introduce an app usage collection platform named carat, from which we have gathered app usage records of 1,465 users from 2012 to 2017. We then conduct the first study on the long-term evolution processes on a macro-level, i.e., app-category, and micro-level, i.e., individual app. We discover that, on both levels, there is a growth stage enabled by the introduction of new technologies. Then there is a plateau stage caused by high correlations between app categories and a Pareto effect in individual app usage, respectively. Additionally, the evolution of individual app usage undergoes an elimination stage due to fierce intra-category competition. The inter-diversity of app-category and individual app usage exhibits opposing trends: app-category usage assimilates while individual app usage diversifies. Nevertheless, the intra-diversity of both app-category and app usage declines over time. Also, we demonstrate the country barriers of app category usage. We further investigate how different demographics affect the evolutionary processes of app usage. Our study provides useful implications for app developers, market intermediaries, and service providers.},
  archive      = {J_TMC},
  author       = {Tong Li and Yali Fan and Yong Li and Sasu Tarkoma and Pan Hui},
  doi          = {10.1109/TMC.2021.3098664},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1213-1230},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Understanding the long-term evolution of mobile app usage},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Towards privacy-driven truthful incentives for mobile
crowdsensing under untrusted platform. <em>TMC</em>, <em>22</em>(2),
1198–1212. (<a href="https://doi.org/10.1109/TMC.2021.3093552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reverse auction-based incentive mechanisms have been commonly proposed to stimulate mobile users to participate in crowdsensing, where users submit bids to the platform to compete for interested tasks. Recent works pointed out that bid is a private information which can reveal sensitive information of users (e.g., location privacy), and proposed bidding-preserving mechanisms with differential privacy against inference attack. However, all these mechanisms rely on a trusted platform, and would fail in bid protection completely when the platform is untrusted. In this paper, we design novel privacy-preserving incentive mechanisms to protect users’ true bid information against the honest-but-curious platform while minimizing the social cost of winner selection. To this end, instead of uploading the true bid to the platform, a differentially private bid obfuscation function is designed with the exponential mechanism, which helps each user to obfuscate bids locally and submit obfuscated bids to the platform. Two solutions are proposed for the platform to solve the winner selection problem with the obfuscated information, which is proved to be NP-hard. Moreover, we further propose a novel task-bid pair protection truthful incentive mechanism to further prevent privacy leakage from the set of interested tasks, where each user encrypts his interested tasks via homomorphic encryption locally, and an encrypted task clustering method is proposed to group users with the same interested tasks into the same cluster for winner selection with users’ encrypted task-bid pairs. Both of theoretical analysis and extensive experiments demonstrate the effectiveness of proposed mechanisms against the untrusted platform.},
  archive      = {J_TMC},
  author       = {Zhibo Wang and Jingxin Li and Jiahui Hu and Ju Ren and Qian Wang and Zhetao Li and Yanjun Li},
  doi          = {10.1109/TMC.2021.3093552},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1198-1212},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards privacy-driven truthful incentives for mobile crowdsensing under untrusted platform},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Touch-to-access device authentication for indoor smart
objects. <em>TMC</em>, <em>22</em>(2), 1185–1197. (<a
href="https://doi.org/10.1109/TMC.2021.3089497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents TouchAuth, a new touch-to-access device authentication approach using induced body electric potentials (iBEPs) caused by the indoor ambient electric field that is mainly emitted from the building&#39;s electrical network. The design of TouchAuth is based on the electrostatics of iBEP generation and a resulting property, i.e., the iBEPs at two close locations on the same human body are similar, whereas those from different human bodies are distinct. Extensive experiments verify the above property and show that TouchAuth achieves high-profile receiver operating characteristics in implementing the touch-to-access policy. Our experiments also show that a range of possible interfering sources including appliances’ electromagnetic emanations and noise injections into the power network do not affect the performance of TouchAuth. A key advantage of TouchAuth is that the iBEP sensing requires a simple analog-to-digital converter only, which is widely available on microcontrollers. Compared with the existing approaches including intra-body communication and physiological sensing, TouchAuth is a low-cost, faster, and easy-to-use approach for authorized users to access the smart objects found in indoor environments.},
  archive      = {J_TMC},
  author       = {Zhenyu Yan and Qun Song and Rui Tan},
  doi          = {10.1109/TMC.2021.3089497},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1185-1197},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Touch-to-access device authentication for indoor smart objects},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RF-badge: Vital sign-based authentication via RFID tag array
on badges. <em>TMC</em>, <em>22</em>(2), 1170–1184. (<a
href="https://doi.org/10.1109/TMC.2021.3097912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, authentication systems are usually required to provide continuous, contactless, and non-intrusive services. In this paper, we propose RF-Badge , a vital sign-based authentication scheme on human subjects to meet the above requirements by using RFID technology. We consider two biometric features with individual diversity to characterize the vital sign of users, including the movement effect from respiration and the reflection effect from organs, especially the heart. To derive the movement effect from respiration, we build a phase-based geometric model to restore the fine-grained badge moving trace as the feature. To derive the reflection effect from human internal organs, we extract the reflection signal from the original signal and generate the spectrum as the feature. Besides, to deal with the feature deviation in different physical conditions of users, we propose a multi-condition network (MCNet) to further guarantee the generalization of RF-Badge. We implement a prototype system and evaluate the performance in real environments. The experiment results show that our system achieves the average false positive rate (FPR) of 3.9 percent and false negative rate (FNR) of 3.3 percent for continuous authentication within four signal cycles.},
  archive      = {J_TMC},
  author       = {Jingyi Ning and Lei Xie and Chuyu Wang and Yanling Bu and Fengyuan Xu and Da-Wei Zhou and Sanglu Lu and Baoliu Ye},
  doi          = {10.1109/TMC.2021.3097912},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1170-1184},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RF-badge: Vital sign-based authentication via RFID tag array on badges},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Receive only necessary: Efficient tag category
identification in large-scale RFID systems. <em>TMC</em>,
<em>22</em>(2), 1157–1169. (<a
href="https://doi.org/10.1109/TMC.2021.3093858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RFID systems have been widely deployed for various applications such as inventory control, retail management, and object tracking. In many scenarios, coarse-grained system management of tag categories is more common than traditional system management of individual tags. Existing works on tag category management require knowing category IDs in advance, however, few protocols have been specially designed to obtain category IDs in multi-category RFID systems. In this paper, we propose CIP , a time-efficient protocol specially designed to collect category IDs in multi-category RFID systems. The challenge in solving this problem is to avoid repeatedly collecting category IDs from multiple tags belonging to the same category. We address this challenge by squeezing tags in the same category into the same time slot and letting them reply to the reader simultaneously. Considering that the reader may receive signals from different tags in a slot, we exploit the Manchester coding to decode the aggregated signals. With this design, CIP collects each category ID only once and thus achieves high time efficiency by avoiding redundant identification of the same category ID. We further enhance CIP by utilizing the lightweight vectors to specify the order of tags’ replying and avoid useless slots. Rigorous theoretical analysis is presented to optimize the performance of CIP and guidelines on how to set optimal parameters to minimize the overall execution time are given. We conduct extensive experiments to evaluate the performance of our protocols. The experimental results show that our protocols can significantly improve time efficiency by 67 percent when compared with the state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Xuan Liu and Jiangjin Yin and Shigeng Zhang and Kenli Li and Song Guo},
  doi          = {10.1109/TMC.2021.3093858},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1157-1169},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Receive only necessary: Efficient tag category identification in large-scale RFID systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PRAM: A practical sybil-proof auction mechanism for dynamic
spectrum access with untruthful attackers. <em>TMC</em>, <em>22</em>(2),
1143–1156. (<a href="https://doi.org/10.1109/TMC.2021.3090103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Auction is becoming increasingly popular for dynamic spectrum access (DSA), while it is extremely vulnerable to sybil attacks. Existing studies on sybil-proof DSA auction impractically assume that attackers bid truthfully based on true appraisals. This paper, for the first time, considers untruthful attackers and investigates the sybil-proof auction design in such more hazardous scenarios. To justify the new assumption, we first show that attackers obtain higher utilities by bidding untruthfully, especially in networks with inadequate channels. Based on this novel finding, we then design a practical sybil attack model named EqualSumBid Sybil, where attackers follow an equal-sum rule (i.e., the sum bid value of the multiple identities of an attacker equals the bid value when it bids with only one identity) instead of their true appraisals. To ensure efficient DSA under the new attack, we finally propose the PRAM, a Practical sybil-pRoof Auction Mechanism, where suspicious identity merging and bid-independent bidder sorting methods are introduced to alleviate the effect of untruthfulness on spectrum auction. Furthermore, winner selection and payment methods are designed to resist the EqualSumBid Sybil attack. Theoretical analyses and numerical results show that PRAM not only resists the EqualSumBid Sybil attack but also achieves individual rationality and truthfulness.},
  archive      = {J_TMC},
  author       = {Xuewen Dong and Yuanyu Zhang and Yuanxiong Guo and Yanmin Gong and Yulong Shen and Jianfeng Ma},
  doi          = {10.1109/TMC.2021.3090103},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1143-1156},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PRAM: A practical sybil-proof auction mechanism for dynamic spectrum access with untruthful attackers},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance modelling and quantitative analysis of vehicular
edge computing with bursty task arrivals. <em>TMC</em>, <em>22</em>(2),
1129–1142. (<a href="https://doi.org/10.1109/TMC.2021.3087013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantitative performance analysis plays a critical role in assessing the capability of vehicular edge computing (VEC) systems to meet the requirements of vehicular applications. However, developing accurate analytical models for VEC systems is extremely challenging due to the unique features of intelligent vehicular applications. Specifically, recent work revealed that the tasks generated by intelligent vehicular applications exhibit a high degree of burstiness, rendering the existing models that were designed based on the assumption of the non-bursty Poisson process unsuitable for VEC systems. To fill this gap, we developed an original analytical model to investigate the performance of VEC systems with bursty task arrivals. To facilitate vehicle cooperation, a new priority-based resource allocation scheme is exploited to schedule the tasks of vehicular applications, which are modelled by a Markov Modulated Poisson Process (MMPP). Next, a multi-state Markov chain is established to investigate the impact of load sharing strategy on the performance of VEC systems. Then, the end-to-end transmission latency is derived based on the proposed model. Comprehensive experiments are conducted to validate the accuracy of this analytical model under various system configurations. Furthermore, the developed model is used as a cost-effective tool to investigate the performance bottleneck of VEC systems.},
  archive      = {J_TMC},
  author       = {Wang Miao and Geyong Min and Xu Zhang and Zhiwei Zhao and Jia Hu},
  doi          = {10.1109/TMC.2021.3087013},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1129-1142},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Performance modelling and quantitative analysis of vehicular edge computing with bursty task arrivals},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online radio access technology selection algorithms in a 5G
multi-RAT network. <em>TMC</em>, <em>22</em>(2), 1110–1128. (<a
href="https://doi.org/10.1109/TMC.2021.3096968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s wireless networks, a variety of Radio Access Technologies (RATs) are present. However, each RAT being controlled individually leads to suboptimal utilization of network resources. Due to the remarkable growth of data traffic, interworking among different RATs is becoming necessary to overcome the problem of suboptimal resource utilization. Users can be offloaded from one RAT to another based on loads of different networks, channel conditions and priority of users. We consider the optimal RAT selection problem in a Fifth Generation (5G) New Radio (NR)-Wireless Fidelity (WiFi) network where we aim to maximize the total system throughput subject to constraints on the blocking probability of high priority users and the offloading probability of low priority users. The problem is formulated as a Constrained Markov Decision Process (CMDP). We reduce the effective dimensionality of the action space by eliminating the provably suboptimal actions. We propose low-complexity online heuristics for RAT selection which can operate without the knowledge regarding the statistics of system dynamics. Network Simulator-3 (ns-3) simulations reveal that the proposed algorithms outperform traditional RAT selection algorithms under realistic network scenarios including user mobility.},
  archive      = {J_TMC},
  author       = {Arghyadip Roy and Prasanna Chaporkar and Abhay Karandikar and Pranav Jha},
  doi          = {10.1109/TMC.2021.3096968},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1110-1128},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online radio access technology selection algorithms in a 5G multi-RAT network},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). No seeing is also believing: Electromagnetic-emission-based
application guessing attacks via smartphones. <em>TMC</em>,
<em>22</em>(2), 1095–1109. (<a
href="https://doi.org/10.1109/TMC.2021.3092209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile devices have emerged as the most popular platforms to access information. However, they have also become a major concern of privacy violation and previous researches have demonstrated various approaches to infer user privacy based on mobile devices. In this paper, we study the electromagnetic (EM) emission of a laptop that could be harvested by a commercial-off-the-shelf (COTS) mobile device, e.g., a smartphone. We propose MagAttack , which exploits the electromagnetic side channel of a laptop to guess user activities, i.e., application launching and application operation. The key insight of MagAttack is that applications are discrepant in essence due to the different compositions of instructions, which can be reflected on the CPU power consumption, and thus the corresponding EM emissions. MagAttack is challenging since that EM signals are noisy due to the dynamics of applications and the limited sampling rate of the built-in magnetometers in COTS mobile devices. We overcome these challenges and convert noisy coarse-grained EM signals to robust fine-grained features. We implement MagAttack on both an iOS and an Android smartphone without any hardware modification, and evaluate its performance with 30 popular applications, 30 YouTube videos, and 50 top websites in China. The results demonstrate that MagAttack can recognize aforementioned 30 applications with an average accuracy of 98.6 percent, and identify which video out of the 30 candidates being played with an average accuracy of 97.5 percent and visiting which website among the 50 candidates with an average accuracy of 90.4 percent.},
  archive      = {J_TMC},
  author       = {Xiaoyu Ji and Yushi Cheng and Wenyuan Xu and Yuehan Chi and Hao Pan and Zhuangdi Zhu and Chuang-Wen You and Yi-Chao Chen and Lili Qiu},
  doi          = {10.1109/TMC.2021.3092209},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1095-1109},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {No seeing is also believing: Electromagnetic-emission-based application guessing attacks via smartphones},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-task allocation in mobile crowd sensing with mobility
prediction. <em>TMC</em>, <em>22</em>(2), 1081–1094. (<a
href="https://doi.org/10.1109/TMC.2021.3088291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowd sensing (MCS) is a popular sensing paradigm that leverages the power of massive mobile workers to perform various location-based sensing tasks. To assign workers with suitable tasks, recent research works investigated mobility prediction methods based on probabilistic and statistical models to estimate the worker’s moving behavior, based on which the allocation algorithm is designed to match workers with tasks such that workers do not need to deviate from their daily routes and tasks can be completed as many as possible. In this paper, we propose a new multi-task allocation method based on mobility prediction, which differs from the existing works by (1) making use of workers’ historical trajectories more comprehensively by using the fuzzy logic system to obtain more accurate mobility prediction and (2) designing a global heuristic searching algorithm to optimize the overall task completion rate based on the mobility prediction result, which jointly considers workers’ and tasks’ spatiotemporal features. We evaluate the proposed prediction method and task allocation algorithm using two real-world datasets. The experimental results validate the effectiveness of the proposed methods compared against baselines.},
  archive      = {J_TMC},
  author       = {Jinyi Zhang and Xinglin Zhang},
  doi          = {10.1109/TMC.2021.3088291},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1081-1094},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-task allocation in mobile crowd sensing with mobility prediction},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Motion parameter estimation for mobile sources using
semidefinite programming. <em>TMC</em>, <em>22</em>(2), 1066–1080. (<a
href="https://doi.org/10.1109/TMC.2021.3084595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the motion parameter estimation problem using time difference of arrival (TDOA) measurements, where a mobile source starts from an initial position with constant velocity. The problem is formulated as three non-convex constrained weighted least squares (CWLS) problems. Owing to their non-convex nature, local convergence may occur when solving them by an iterative algorithm, implying good estimates are not guaranteed. We propose to solve these CWLS problems by applying semidefinite relaxation (SDR) to generate three different semidefinite programming (SDP) problems, namely, the motion unconstrained semidefinite programming (MU-SDP), motion constrained semidefinite programming (MC-SDP), and motion parameter direct semidefinite programming (MPD-SDP). The MU-SDP, MC-SDP, and MPD-SDP methods are then extended to the scenario of unknown propagation speed (PS), which is common in underwater and underground localizations. Specifically, for this scenario, the two-step MU-SDP, two-step MC-SDP, and two-step MPD-SDP methods are designed to keep the relaxed SDP problems tight by introducing the penalty function. Simulation results show that MU-SDP performs worse than MC-SDP and MPD-SDP owing to the ignorance of the motion equation, and MC-SDP and MPD-SDP are able to reach the Cramér-Rao lower bound (CRLB) accuracy.},
  archive      = {J_TMC},
  author       = {Xiaoping Wu and Hengnian Qi},
  doi          = {10.1109/TMC.2021.3084595},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1066-1080},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Motion parameter estimation for mobile sources using semidefinite programming},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximization of value of service for mobile collaborative
computing through situation-aware task offloading. <em>TMC</em>,
<em>22</em>(2), 1049–1065. (<a
href="https://doi.org/10.1109/TMC.2021.3086687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile collaborative computing (MCC) is an emerging platform for effectively improving the quality of mobile service by exploiting the idling computational resources in distributed mobile devices (MDs) through peer-to-peer task offloading. Recently, diverse MCC applications have been developed to provide multiple functional benefits and individualized value to users. In this paper, we propose to use a new concept of value of service (VoS) to represent the total value of all tasks and devices with respect to their performance including latency and energy consumption. To improve service provisioning under fast-varying conditions, a situation-aware offloading scheme is proposed to maximize VoS by opportunistically leveraging the changing resource availability conditions. Specifically, we consider a collaborative computing system where a user can offload input data of computation to other available MDs. VoS maximization for two popular offloading scenarios, i.e., binary and partial offloading, are formulated separately. Decision making of binary offloading is an NP-hard problem and solved by a novel heuristic algorithm which achieves suboptimal solution in polynomial time. Partial offloading is formulated as a non-convex problem involving task partition decision. By exploiting the unique characteristics of the problem, we propose an adapted barrier method (ABM) which achieves significant improvements in convergence efficiency.},
  archive      = {J_TMC},
  author       = {Ruitao Chen and Xianbin Wang},
  doi          = {10.1109/TMC.2021.3086687},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1049-1065},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Maximization of value of service for mobile collaborative computing through situation-aware task offloading},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Matrix gaussian mechanisms for differentially-private
learning. <em>TMC</em>, <em>22</em>(2), 1036–1048. (<a
href="https://doi.org/10.1109/TMC.2021.3093316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide deployment of machine learning algorithms has become a severe threat to user data privacy. As the learning data is of high dimensionality and high orders, preserving its privacy is intrinsically hard. Conventional differential privacy mechanisms often incur significant utility decline as they are designed for scalar values from the start. We recognize that it is because conventional approaches do not take the data structural information into account, and fail to provide sufficient privacy or utility. As the main novelty of this work, we propose Matrix Gaussian Mechanism (MGM), a new &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ (\epsilon,\delta)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -differential privacy mechanism for preserving learning data privacy. By imposing the unimodal distributions on the noise, we introduce two mechanisms based on MGM with an improved utility. We further show that with the utility space available, the proposed mechanisms can be instantiated with optimized utility, and has a closed-form solution scalable to large-scale problems. We experimentally show that our mechanisms, applied to privacy-preserving federated learning, are superior than the state-of-the-art differential privacy mechanisms in utility.},
  archive      = {J_TMC},
  author       = {Jungang Yang and Liyao Xiang and Jiahao Yu and Xinbing Wang and Bin Guo and Zhetao Li and Baochun Li},
  doi          = {10.1109/TMC.2021.3093316},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1036-1048},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Matrix gaussian mechanisms for differentially-private learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Location-aware wireless resource allocation in
industrial-like environment. <em>TMC</em>, <em>22</em>(2), 1025–1035.
(<a href="https://doi.org/10.1109/TMC.2021.3088058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of the fourth Industrial Revolution (Industry 4.0) requires wireless networked solutions to connect machines. However, the industrial environment is notorious for being averse to wireless communication, with traditional wireless resource mechanisms prone to errors because of metallic objects. In this work, we propose to exploit the knowledge of location to derive context information and dynamically allocate wireless resources in time and space to target devices. We exploit the spatial geometry of the Access Points (APs) and we introduce a statistical model that maps the user position’s spatial distribution to an angle error distribution and derive a hypothesis test to declare if the link is under metallic blockage or not. In order to avoid changes to the client side and operate with a single interface radio, we use the same wireless network both for positioning and scheduling. We experimentally show that our system can localize four mobile robots deployed in a very harsh environment with metal obstacles and reflections. Context information applied to wireless resources protocol help increasing up to 40 percent of the network throughput in the above industrial-like scenario.},
  archive      = {J_TMC},
  author       = {Maurizio Rea and Domenico Giustiniano},
  doi          = {10.1109/TMC.2021.3088058},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1025-1035},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Location-aware wireless resource allocation in industrial-like environment},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locate, tell, and guide: Enabling public cameras to navigate
the public. <em>TMC</em>, <em>22</em>(2), 1010–1024. (<a
href="https://doi.org/10.1109/TMC.2021.3092725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor navigation is essential to a wide spectrum of applications in the era of mobile computing. Existing vision-based technologies suffer from both start-up costs and the absence of semantic information for navigation. We observe an opportunity to leverage pervasively deployed surveillance cameras to deal with the above drawbacks and revisit the problem of indoor navigation with a fresh perspective. In this paper, we propose iSAT , a system that enables public surveillance cameras, as indoor navigating satellites, to locate users on the floorplan, tell users with semantic information about the surrounding environment, and guide users with navigation instructions. However, enabling public cameras to navigate is non-trivial due to 3 factors: absence of real scale, disparity of camera perspective, and lack of semantic information. To overcome these challenges, iSAT leverages POI-assisted framework and adopts a novel coordinate transformation algorithm to associate public and mobile cameras, and further attaches semantic information to user location. Extensive experiments in 4 different scenarios show that iSAT achieves a localization accuracy of 0.48m and a navigation success rate of 90.5 percent, outperforming the state-of-th-art systems by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$&amp;gt; 30\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; . Benefiting from our solution, all areas with public cameras can upgrade to smart spaces with visual navigation services.},
  archive      = {J_TMC},
  author       = {Guoxuan Chi and Jingao Xu and Jialin Zhang and Qian Zhang and Qiang Ma and Zheng Yang},
  doi          = {10.1109/TMC.2021.3092725},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {1010-1024},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Locate, tell, and guide: Enabling public cameras to navigate the public},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to harness bandwidth with multipath congestion
control and scheduling. <em>TMC</em>, <em>22</em>(2), 996–1009. (<a
href="https://doi.org/10.1109/TMC.2021.3085598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multipath TCP (MPTCP) has emerged as a facilitator for harnessing and pooling available bandwidth in wireless/wireline communication networks and in data centers. Existing implementations of MPTCP such as, Linked Increase Algorithm (LIA), Opportunistic LIA (OLIA) and BAlanced LInked Adaptation (BALIA) include separate algorithms for congestion control and packet scheduling, with pre-selected control parameters. We propose a Deep Q-Learning (DQL) based framework for joint congestion control and packet scheduling for MPTCP. At the heart of the solution is an intelligent agent for interface, learning and actuation, which learns from experience optimal congestion control and scheduling mechanism using DQL techniques with policy gradients. We provide a rigorous stability analysis of system dynamics which provides important practical design insights. In addition, the proposed DQL-MPTCP algorithm utilizes the ‘recurrent neural network’ and integrates it with ‘long short-term memory’ for continuously i) learning dynamic behavior of subflows (paths) and ii) responding promptly to their behavior using prioritized experience replay. With extensive emulations, we show that the proposed DQL-based MPTCP algorithm outperforms MPTCP LIA, OLIA and BALIA algorithms. Moreover, the DQL-MPTCP algorithm is robust to time-varying network characteristics, and provides dynamic exploration and exploitation of paths.},
  archive      = {J_TMC},
  author       = {Shiva Raj Pokhrel and Anwar Walid},
  doi          = {10.1109/TMC.2021.3085598},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {996-1009},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Learning to harness bandwidth with multipath congestion control and scheduling},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint management of compute and radio resources in mobile
edge computing: A market equilibrium approach. <em>TMC</em>,
<em>22</em>(2), 983–995. (<a
href="https://doi.org/10.1109/TMC.2021.3091764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing has been recently introduced to bring computational capabilities closer to end-users of modern network-based services, supporting existing and future delay-sensitive applications by effectively addressing the high propagation delay issue that affects cloud computing. However, the problem of efficiently and fairly managing the system resources presents particular challenges due to the limited capacity of both edge nodes and wireless access networks and the heterogeneity of resources and services’ requirements. To this end, we propose a techno-economic market where service providers act as buyers, securing both radio and computing resources to execute their associated end-users’ jobs while being constrained by a budget limit. We design an allocation mechanism that employs convex programming to find the unique market equilibrium point that maximizes fairness while ensuring that all buyers receive their preferred resource bundle. Additionally, we derive theoretical properties that confirm how the market equilibrium approach strikes a balance between fairness and efficiency. We also propose alternative allocation mechanisms and give a comparison with the market-based mechanism. Finally, we conduct simulations to numerically analyze and compare the performance of the mechanisms and confirm the market model&#39;s theoretical properties.},
  archive      = {J_TMC},
  author       = {Eugenio Moro and Ilario Filippini},
  doi          = {10.1109/TMC.2021.3091764},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {983-995},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint management of compute and radio resources in mobile edge computing: A market equilibrium approach},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). In-situ fish heart-rate estimation and feeding event
detection using an implantable biologger. <em>TMC</em>, <em>22</em>(2),
968–982. (<a href="https://doi.org/10.1109/TMC.2021.3086496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring of physiology and behavior of marine animals living undisturbed in their natural habitats can provide valuable information about their well-being and response to environmental stressors. We focus on detecting the feeding behavior in predatory fish using implantable biologgers that record and analyze electrocardiogram (ECG) signals. We propose a novel processing pipeline for resource-constrained embedded systems that can infer higher-level information, such as heart-rate and feeding events, from the ECG signals in situ. Our main contributions are in proposing efficient event detection algorithms that can reliably detect fish feeding events from noisy heart-rate data based on the unique statistical properties of feeding-induced changes in the heart-rate. We evaluate our approaches using an in-house biologger that we surgically implant in twelve coral trout fish and use to collect data during an experiment for a period of ten weeks and show that our signal processing pipeline performs well with noisy ECG signals overall. Specifically, our heart-rate estimation algorithm achieves errors of less than one beat per minute even in scenarios where popular algorithms used by domain specialists perform poorly. Furthermore, our feeding detection algorithms offer improved accuracy compared with the state-of-the-art algorithms while requiring significantly reduced computational and energy resources. We implement the proposed heart-rate estimation and feeding detection algorithms on the biologger and evaluate the associated system overhead. The results show that our proposed heart-rate estimation and feeding detection algorithms can run in-situ on the biologger as they demand rather small computational and energy resources that can conveniently be provisioned. This work is an important first step towards developing effective tools for long-term monitoring of high-level parameters pertaining to the health and behavior of marine animals in the wild.},
  archive      = {J_TMC},
  author       = {Yiran Shen and Reza Arablouei and Frank de Hoog and Hao Xing and Jacques Malan and James Sharp and Sara Shouri and Timothy D. Clark and Carine Lefevre and Frederieke Kroon and Andrea Severati and Brano Kusy},
  doi          = {10.1109/TMC.2021.3086496},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {968-982},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {In-situ fish heart-rate estimation and feeding event detection using an implantable biologger},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incentive-driven proactive application deployment and
pricing on distributed edges. <em>TMC</em>, <em>22</em>(2), 951–967. (<a
href="https://doi.org/10.1109/TMC.2021.3096860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications deployed on edge servers improve users’ experience, when compared to deployments on cloud servers. Existing works usually assume that a central scheduler helps in making decisions, but they are often inefficient, inaccurate, or time-consuming. In this paper, we present a proactive application deployment system, which consists of three modules (i.e., incentive, profit, and latency). Based on the architecture of a fully distributed edge network, our system includes SELL, a Spontaneous Edge depLoyment aLgorithm in the incentive module. SELL lets edge servers compete with each other in a two-stage Stackelberg game to win deployment rights, and the winners get paid for their deployment efforts. The other two modules help recursively adjust service prices and deployment intentions in view of their own profits. Simulations on the proactive edge application deployment system demonstrate that SELL can help an application provider find appropriate edge servers to deploy applications while maximizing the profits for both parties in a low latency.},
  archive      = {J_TMC},
  author       = {Shuiguang Deng and Yishan Chen and Gong Chen and Shouling Ji and Jianwei Yin and Albert Y. Zomaya},
  doi          = {10.1109/TMC.2021.3096860},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {951-967},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Incentive-driven proactive application deployment and pricing on distributed edges},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implicit multimodal crowdsourcing for joint RF and
geomagnetic fingerprinting. <em>TMC</em>, <em>22</em>(2), 935–950. (<a
href="https://doi.org/10.1109/TMC.2021.3088268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In fingerprint-based indoor localization, fusing radio frequency (RF) and geomagnetic signals has been shown to achieve promising results. To efficiently collect fingerprints, implicit crowdsourcing can be used, where signals sampled by pedestrians are automatically labeled with their locations on a map. Previous work on crowdsourced fingerprinting is often based on a single signal, which is susceptible to signal bias and labeling error. We study, for the first time, implicit multimodal crowdsourcing for joint RF and geomagnetic fingerprinting. The scheme, termed UbiFin, exploits the spatial correlation among RF, geomagnetic, and motion signals to mitigate the impact of sensor noise, leading to highly accurate and robust fingerprinting without the need for any explicit manual intervention. Using clustering and dynamic programming, UbiFin correlates spatially different signals and filters effectively mislabeled signals. We conduct extensive experiments on our campus and a large multi-story shopping mall. Efficient and simple to implement, UbiFin outperforms other state-of-the-art crowdsourcing schemes to construct RF and geomagnetic fingerprints in terms of accuracy and robustness (cutting fingerprint error by 40 percent in general).},
  archive      = {J_TMC},
  author       = {Jiajie Tan and Hang Wu and Ka-Ho Chow and S.-H. Gary Chan},
  doi          = {10.1109/TMC.2021.3088268},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {935-950},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Implicit multimodal crowdsourcing for joint RF and geomagnetic fingerprinting},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). H2K: A heartbeat-based key generation framework for ECG and
PPG signals. <em>TMC</em>, <em>22</em>(2), 923–934. (<a
href="https://doi.org/10.1109/TMC.2021.3096384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless body area network is a key enabler for connected healthcare but recent cyberattacks have compromised its security and trustworthiness. This paper investigates heartbeat-based key generation to secure body area networks. The interpulse intervals (IPIs) between any two adjacent peaks of heartbeat signals are random and state-of-the-art literature has demonstrated that IPI is a good random source to be extracted as cryptographic keys. Heartbeat signals can be measured by electrocardiography (ECG) and photoplethysmography (PPG) sensors. A general heartbeat-based key generation framework applicable to both ECG and PPG signals is proposed. A robust peak detection algorithm is designed to capture noisy peaks and a simple yet efficient IPI alignment algorithm to align the common IPIs. A key establishment protocol is used to convert analog IPIs to digital binaries and reconcile them between legitimate devices. We evaluate the performance for both ECG signals from an online public database, MIT PhysioBank, and PPG signals collected from our testbed. The results demonstrate that our algorithm is robust and heartbeat-based key generation can be completed for both ECG and PPG signals. We finally create a PPG-based prototype and a demonstration video to show the practicality of our framework.},
  archive      = {J_TMC},
  author       = {Junqing Zhang and Yushi Zheng and Weitao Xu and Yingying Chen},
  doi          = {10.1109/TMC.2021.3096384},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {923-934},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {H2K: A heartbeat-based key generation framework for ECG and PPG signals},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). : Mobility-driven integration of heterogeneous urban
cyber-physical systems under disruptive events. <em>TMC</em>,
<em>22</em>(2), 906–922. (<a
href="https://doi.org/10.1109/TMC.2021.3091324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of cities, heterogeneous urban cyber-physical systems are designed to improve citizens’ experience, e.g., navigation and delivery service. However, the integration of services is not designed for disruptive events, an oversight that has rippling effects on service quality. For example, urban transportation systems consist of multiple transport modes that have complementary characteristics of capacities, speeds, and costs, facilitating smooth passenger transfers by planned schedules. Such integration may experience significantly increased delays during disruptions. Current solutions rely on a substitute service to transport passengers from and to affected areas using ad-hoc schedules and static routes, which are inefficient and do not utilize mobility patterns of mobile systems, e.g., dynamic passenger demand. To coordinate heterogeneous transportation systems under disruptions, we design a service to automatically select and integrate part of three systems (subway, bus, and taxi) using systems’ mobility patterns, e.g., predicted supply and demand. The service is presented in a normal version, eRoute, considering both subway and bus, and in a version taking taxis into account, called enhanced eRoute. We implement and evaluate eRoute with datasets including subway, bus and taxi, and a fare collection system. The data-driven evaluation results show that eRoute improves the ratio of served passengers per time interval by up to 11.5 times and reduces the average traveling time by up to 82.1 percent compared with existing solutions.},
  archive      = {J_TMC},
  author       = {Yukun Yuan and Desheng Zhang and Fei Miao and John A. Stankovic and Tian He and George J. Pappas and Shan Lin},
  doi          = {10.1109/TMC.2021.3091324},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {906-922},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {: Mobility-driven integration of heterogeneous urban cyber-physical systems under disruptive events},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy-efficient service migration for multi-user
heterogeneous dense cellular networks. <em>TMC</em>, <em>22</em>(2),
890–905. (<a href="https://doi.org/10.1109/TMC.2021.3087198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) is a key enabler for ultra-low latency in heterogeneous dense cellular networks in the 5G era and beyond, by deploying services at the network edge. Due to high user mobility, the services are usually migrated to follow the users by predicting the user trajectory to achieve a balance between energy consumption and service latency. However, service migration for multi-user heterogeneous dense cellular networks is challenging because (1) the user trajectory prediction, which is crucial for service migration, becomes intractable with a large number of users, and (2) making service migration decisions for each user independently is subjected to interference among the users. Therefore, in this study, we formulated the service migration of all the users in MEC-enabled heterogeneous dense cellular networks as an optimization problem, with the objective of minimizing the average energy consumption while satisfying the service latency requirements, taking into account the interference among different users. Next, we developed an efficient energy-efficient online algorithm based on the Lyapunov and particle swarm optimizations, called EGO, to resolve the original problem without predicting the trajectories of the users. Finally, a series of simulations based on real-world mobility traces of vehicles in Bologna were conducted to establish the superiority of the EGO algorithm over state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Xiaobo Zhou and Shuxin Ge and Tie Qiu and Keqiu Li and Mohammed Atiquzzaman},
  doi          = {10.1109/TMC.2021.3087198},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {890-905},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient service migration for multi-user heterogeneous dense cellular networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge-powered assisted driving for connected cars.
<em>TMC</em>, <em>22</em>(2), 874–889. (<a
href="https://doi.org/10.1109/TMC.2021.3084291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assisted driving for connected cars is one of the main applications that 5G-and-beyond networks shall support. In this work, we propose an assisted driving system leveraging the synergy between connected vehicles and the edge of the network infrastructure, in order to envision global traffic policies that can effectively drive local decisions. Local decisions concern individual vehicles, e.g., which vehicle should perform a lane-change manoeuvre and when; global decisions, instead, involve whole traffic flows. Such decisions are made at different time scales by different entities, which are integrated within an edge-based architecture and can share information. In particular, we leverage a queuing-based model and formulate an optimization problem to make global decisions on traffic flows. To cope with the problem complexity, we then develop an iterative, linear-time complexity algorithm called Bottleneck Hunting (BH). We show the performance of our solution using a realistic simulation framework, integrating a Python engine with ns-3 and SUMO, and considering two relevant services, namely, lane change assistance and navigation, in a real-world scenario. Results demonstrate that our solution leads to a reduction of the vehicles’ travel times by 66 percent in the case of lane change assistance and by 20 percent for navigation, compared to traditional, local-coordination approaches.},
  archive      = {J_TMC},
  author       = {Francesco Malandrino and Carla Fabiana Chiasserini and Gian Michele Dell’Aera},
  doi          = {10.1109/TMC.2021.3084291},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {874-889},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Edge-powered assisted driving for connected cars},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual pricing optimization for live video streaming in mobile
edge computing with joint user association and resource management.
<em>TMC</em>, <em>22</em>(2), 858–873. (<a
href="https://doi.org/10.1109/TMC.2021.3089229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile live video streaming is expected to become mainstream in the fifth generation (5G) mobile networks. To boost the Quality of Experience (QoE) of streaming services, the integration of Scalable Video Coding (SVC) with Mobile Edge Computing (MEC) becomes a natural candidate due to its scalability and the reliable transmission supports for real-time interactions. However, it still takes efforts to integrate MEC into video streaming services to exploit its full potentials. We find that the efficiency of the MEC-enabled cellular system can be significantly improved when the requests of users can be redirected to proper MEC servers through optimal user associations. In light of this observation, we jointly address the caching placement, video quality decision, and user association problem in the live video streaming service. Since the proposed nonlinear integer optimization problem is NP-hard, we first develop a two-step approach from a Lagrangian optimization under the dual pricing specification. Further, to have a computation-efficient solution and less performance loss, we provide a one-step Lagrangian dual pricing algorithm by the convex transformation of non-convex constraints. The simulations show that the service quality of live video streaming can be remarkably enhanced by the proposed algorithms in the MEC-enabled cellular system.},
  archive      = {J_TMC},
  author       = {Wei-Yu Chen and Po-Yu Chou and Chih-Yu Wang and Ren-Hung Hwang and Wen-Tsuen Chen},
  doi          = {10.1109/TMC.2021.3089229},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {858-873},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dual pricing optimization for live video streaming in mobile edge computing with joint user association and resource management},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of microsleep events with a behind-the-ear
wearable system. <em>TMC</em>, <em>22</em>(2), 841–857. (<a
href="https://doi.org/10.1109/TMC.2021.3090829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every year, the U.S. economy loses more than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\$}$&lt;/tex-math&gt;&lt;/inline-formula&gt; 411 billion because of work performance reduction, injuries, and traffic accidents caused by microsleep. To mitigate microsleep&#39;s consequences, an unobtrusive, reliable, and socially acceptable microsleep detection solution throughout the day, every day is required. Unfortunately, existing solutions do not meet these requirements. In this paper, we propose WAKE, a novel behind-the-ear wearable device for microsleep detection. By monitoring biosignals from the brain, eye movements, facial muscle contractions, and sweat gland activities from behind the user&#39;s ears, WAKE can detect microsleep with a high temporal resolution. We introduce a Three-fold Cascaded Amplifying (3CA) technique to tame the motion artifacts and environmental noises for capturing high fidelity signals. Through our prototyping, we show that WAKE can suppress motion and environmental noise in real-time by 9.74-19.47 dB while walking, driving, or staying in different environments, ensuring that the biosignals are captured reliably. We evaluated WAKE using gold-standard devices on 19 sleep-deprived and narcoleptic subjects. The Leave-One-Subject-Out Cross-Validation results show the feasibility of WAKE in microsleep detection on an unseen subject with average precision and recall of 76 and 85 percent, respectively.},
  archive      = {J_TMC},
  author       = {Nhat Pham and Tuan Dinh and Taeho Kim and Zohreh Raghebi and Nam Bui and Hoang Truong and Tuan Nguyen and Farnoush Banaei-Kashani and Ann Halbower and Thang Dinh and Phuc Nguyen and Tam Vu},
  doi          = {10.1109/TMC.2021.3090829},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {841-857},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Detection of microsleep events with a behind-the-ear wearable system},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepAPP: A deep reinforcement learning framework for mobile
application usage prediction. <em>TMC</em>, <em>22</em>(2), 824–840. (<a
href="https://doi.org/10.1109/TMC.2021.3093619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to predict a set of apps a user will open on her mobile device in the next time slot. Such an information is essential for many smartphone operations, e.g., app pre-loading and content pre-caching, to improve user experience. However, it is hard to build an explicit model that accurately captures the complex environment context and predicts a set of apps at one time. This paper presents a deep reinforcement learning framework, named as DeepAPP, which learns a model-free predictive neural network from historical app usage data. Meanwhile, an online updating strategy is designed to adapt the predictive network to the time-varying app usage behavior. To transform DeepAPP into a practical deep reinforcement learning system, several challenges are addressed by developing a context representation method for complex contextual environment, a general agent for overcoming data sparsity and a lightweight personalized agent for minimizing the prediction time. Extensive experiments on a large-scale anonymized app usage dataset reveal that DeepAPP provides high accuracy (precision 70.6 percent and recall of 62.4 percent) and reduces the prediction time of the state-of-the-art by 6.58×. A field experiment of 29 participants demonstrates DeepAPP can effectively reduce launch time of apps.},
  archive      = {J_TMC},
  author       = {Zhihao Shen and Kang Yang and Xi Zhao and Jianhua Zou and Wan Du},
  doi          = {10.1109/TMC.2021.3093619},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {824-840},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DeepAPP: A deep reinforcement learning framework for mobile application usage prediction},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven transportation network company vehicle
scheduling with users’ location differential privacy preservation.
<em>TMC</em>, <em>22</em>(2), 813–823. (<a
href="https://doi.org/10.1109/TMC.2021.3091148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of mobile devices with global positioning system (GPS), transportation network company (TNC) service has become an indispensable option of people&#39;s daily commute. However, it also provides opportunities for malicious parties to compromise TNC users’ location privacy. There are great challenges to preserve TNC users’ location privacy while improving the revenue of TNC and its quality of service (QoS). To address this issue, we propose a novel scheme to schedule the TNC vehicles while preserving the TNC users’ location differential privacy. Briefly, we add high dimensional Laplace noises to guarantee the TNC users’ geo-indistinguishability. Due to the differential private obfuscation, the demand for TNC vehicles in an area becomes uncertain. Thus, we employ the data-driven approach to characterize users’ demand uncertainty, formulate the TNC&#39;s revenue maximization problem into risk-averse stochastic programming, and provide corresponding feasible solutions. Using the released public data of Didi Chuxing, we conduct extensive simulations to evaluate the performance of the proposed scheduling scheme and compare the results under different &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\zeta$&lt;/tex-math&gt;&lt;/inline-formula&gt; -structure metrics. The results show that the proposed scheme can efficiently schedule the TNC vehicles, maximize the TNC&#39;s revenue and provide a better service for TNC users while protecting the TNC users’ location privacy.},
  archive      = {J_TMC},
  author       = {Xinyue Zhang and Jingyi Wang and Haijun Zhang and Lixin Li and Miao Pan and Zhu Han},
  doi          = {10.1109/TMC.2021.3091148},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {813-823},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Data-driven transportation network company vehicle scheduling with users’ location differential privacy preservation},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collective influence maximization in mobile social networks.
<em>TMC</em>, <em>22</em>(2), 797–812. (<a
href="https://doi.org/10.1109/TMC.2021.3092434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The omnipresence of information cascading process in mobile social networking applications makes the identification of a small set &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$S$&lt;/tex-math&gt;&lt;/inline-formula&gt; of influential users, which is widely believed to trigger the information outbreak, always an crucial issue in various applications such as the mobile advertising and viral marketing. Formulated as Influence maximization (IM) in 2003, this NP-hard problem has received a multitude of studies with diverse angles. However, these works often unable to provide reliable solutions, due to the loss of an exact metric for evaluating users’ contributions on information cascading in the state-of-the-art sampling based IM schemes. In this paper, we evaluate users in IM based on the collective influence (CI), a metric on the structural features of the users in network graph that reflects the contributions of the users’ neighborhoods on shaping collective dynamics of the users over the whole network. For conducting the influencer identification under probabilistic diffusion model based on the CI, we specify a quantified structural feature of the most influential users from the scope of diffusion over the whole network, and reveal that the structural influence power (CI value) of each user is a weighted cumulation of the diffusion probabilities from neighbors within certain hops. Utilizing CI, we design a novel algorithm which identifies the influencers via iteratively choosing the users with top CI values. Moreover, we point out that directly computing CI values requires to traverse the network which is originally represented by a high-dimensional matrix, and leads to huge complexity of influencer identification. To improve scalability, we further trade precision for efficiency by incorporating network embedding, a dimensionality reduction technology for networks, into algorithm design, and propose a minor variant, where CI is jointly recapitulated by low-dimensional user representations and user degrees. The superiority of our algorithms is empirically validated over 8 datasets, with an increment in influence size up to 50 percent and a comparable or even less running time comparing with existing baselines.},
  archive      = {J_TMC},
  author       = {Xudong Wu and Luoyi Fu and Shuaiqi Wang and Bo Jiang and Xinbing Wang and Guihai Chen},
  doi          = {10.1109/TMC.2021.3092434},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {797-812},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collective influence maximization in mobile social networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Camouflage learning: Feature value obscuring ambient
intelligence for constrained devices. <em>TMC</em>, <em>22</em>(2),
781–796. (<a href="https://doi.org/10.1109/TMC.2021.3092271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ambient intelligence demands collaboration schemes for distributed constrained devices which are not only highly energy efficient in distributed sensing, processing and communication, but which also respect data privacy. Traditional algorithms for distributed processing suffer in Ambient intelligence domains either from limited data privacy, or from their excessive processing demands for constrained distributed devices. In this paper, we present Camouflage learning, a distributed machine learning scheme that obscures the trained model via probabilistic collaboration using physical-layer computation offloading and demonstrate the feasibility of the approach on backscatter communication prototypes and in comparison with Federated learning. We show that Camouflage learning is more energy efficient than traditional schemes and that it requires less communication overhead while reducing the computation load through physical-layer computation offloading. The scheme is synchronization-agnostic and thus appropriate for sharply constrained, synchronization-incapable devices. We demonstrate model training and inference on four distinct datasets and investigate the performance of the scheme with respect to communication range, impact of challenging communication environments, power consumption, and the backscatter hardware prototype.},
  archive      = {J_TMC},
  author       = {Le Ngu Nguyen and Stephan Sigg and Jari Lietzen and Rainhard Dieter Findling and Kalle Ruttik},
  doi          = {10.1109/TMC.2021.3092271},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {781-796},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Camouflage learning: Feature value obscuring ambient intelligence for constrained devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boost sum-product performance for multiuser detection in
mMTC at millimeter wave. <em>TMC</em>, <em>22</em>(2), 765–780. (<a
href="https://doi.org/10.1109/TMC.2021.3089359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the multiuser detection (MUD) problem, i.e., how to separate and decode colliding data streams, in the uplink of massive Machine Type Communications (mMTC) at millimeter wave (mmWave). Operating on factor-graphs by passing messages, the sum-product algorithm and its variants are widely applied in many other scenarios. However, in this paper, we find that their performance in mMTC at mmWave could be dramatically degraded due to the ill-conditioned MUD channel gain matrix and the existence of enormous short cycles in their corresponding factor-graphs, which are caused by the limited scattering of mmWave and the sharing of a same codebook for error correction among densely located user equipments. Assuming LDPC codes are used for error correction, we further propose a novel sum-product based approach to dealing with the MUD problem in mMTC at mmWave. It first leverages the propagation characteristics of mmWave to optimize the factor-graph for MUD by removing short cycles based on node-split and node-contraction, and then takes a dynamic-programming based method to approximate the messages passing on the resulted factor-graph, which can achieve a higher decoding accuracy. Extensive simulation results show that our approach outperforms the state-of-the-art sum-product based approaches significantly.},
  archive      = {J_TMC},
  author       = {Tao Huang and Baoliu Ye and Bin Tang and Lei Xie and Sanglu Lu and Song Guo},
  doi          = {10.1109/TMC.2021.3089359},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {765-780},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Boost sum-product performance for multiuser detection in mMTC at millimeter wave},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auction-and-learning based lagrange coded computing model
for privacy-preserving, secure, and resilient mobile edge computing.
<em>TMC</em>, <em>22</em>(2), 744–764. (<a
href="https://doi.org/10.1109/TMC.2021.3097380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design a novel encoding model based on Lagrange coded computing (LCC) for private, secure, and resilient distributed mobile edge computing (MEC) systems, where multiple base stations (BSs) act as “masters” offloading their computations to edge nodes acting as “workers”. A two-fold objective of the scheme is: i) efficient allocation of computing tasks to the workers; ii) providing the workers with appropriate incentives to complete their tasks. As such, each master must decide on its offloading requests to the workers including the allocated tasks and service fees to be paid. This problem is complex due to the following reasons: i) masters can be privately-owned or managed by different operators, i.e., there is no communication and no coordination among them; ii) workers are heterogeneous non-dedicated nodes with limited and nondeterministic transmission and computing resources. As a result, the masters must compete for constrained resources of workers in a stochastic partially-observable environment. To address this problem, we define the interactions between masters and workers as a direct stochastic first-price-sealed-bid (FPSB) auction. To analyze the auction, we represent it as a stochastic Bayesian game and develop a Bayesian learning framework to perfect the auction solution.},
  archive      = {J_TMC},
  author       = {Alia Asheralieva and Dusit Niyato and Zehui Xiong},
  doi          = {10.1109/TMC.2021.3097380},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {744-764},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Auction-and-learning based lagrange coded computing model for privacy-preserving, secure, and resilient mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimized LTE-based technique for drone base station
dynamic 3D placement and resource allocation in delay-sensitive M2M
networks. <em>TMC</em>, <em>22</em>(2), 732–743. (<a
href="https://doi.org/10.1109/TMC.2021.3089329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones are expected to facilitate extending wireless networks’ access for both human users and smart machine-type-communication devices (MTCDs) with strict and diverse quality of service (QoS) requirements. In this paper, we propose an optimal solution for the dynamic placement of an LTE drone-mounted base station to maximize the coverage of the MTCDs deployed over a large geographical area. The resulting technique jointly optimizes the drone&#39;s 3D positioning to maximize coverage and allocates the network resources in such a way that gives high priority to the delay-sensitive machine-to-machine (M2M) traffic. This optimization algorithm determines the optimal bound of the solution. Since it cannot be used in real-time operations due to its computational complexity, we also introduce a heuristic technique that offers a near-optimal solution with much reduced complexity. We conduct several simulation evaluations to assess the proposed techniques. These results are compared to those of other drone placement approaches. The comparisons show that the proposed techniques offer significantly better results in the communication coverage while fulfilling the diverse QoS requirements of the deployed M2M network. Moreover, the heuristic-based technique is shown to succeed in finding solutions close to the optimal bound with a considerable reduction of complexity over the exact algorithm.},
  archive      = {J_TMC},
  author       = {Ahmed Fahim and Yasser Gadallah},
  doi          = {10.1109/TMC.2021.3089329},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {732-743},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An optimized LTE-based technique for drone base station dynamic 3D placement and resource allocation in delay-sensitive M2M networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient missing tag identification approach in RFID
collisions. <em>TMC</em>, <em>22</em>(2), 720–731. (<a
href="https://doi.org/10.1109/TMC.2021.3085820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio frequency identification technology has been widely used to verify the presence of items in many applications such as warehouse management and supply chain logistics. In these applications, the challenge of how to timely identify the missing tags (namely tag searching or missing tag identification) is a key focus. Existing missing tag identification solutions have not achieved their full potentials because collision slots have not been well explored. In this paper, we propose an approach named collision resolving based missing tag identification (CR-MTI) to break through the performance bottleneck of existing missing tag identification protocols. In CR-MTI, multiple tags are allowed to respond with different binary strings in a collision slot. Then, the reader can verify them together by using the bit tracking technology and particularly designed string, thereby significantly improve the time efficiency. CR-MTI also reduces the number of messages transmitted by the reader using customized coding. We further explore the optimal parameter settings to maximize the performance of our proposed CR-MTI. Extensive simulation results show that our proposed CR-MTI outperforms prior art in terms of time efficiency, total executive time and communication complexity.},
  archive      = {J_TMC},
  author       = {Jian Su and Zhengguo Sheng and Alex X. Liu and Zhangjie Fu and Chenxi Huang},
  doi          = {10.1109/TMC.2021.3085820},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {720-731},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An efficient missing tag identification approach in RFID collisions},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ambassy: A runtime framework to delegate trusted
applications in an ARM/FPGA hybrid system. <em>TMC</em>, <em>22</em>(2),
708–719. (<a href="https://doi.org/10.1109/TMC.2021.3086143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many mobile systems run on ARM-based devices today. People use these for increasingly diverse yet security-sensitive applications. ARM has adopted a security model to tackle this threat, where they manage private information in an isolated trusted execution environment (TEE) provided by TrustZone . This TrustZone-based model has been proven effective, but due to security concerns, it is available solely for the vendor&#39;s applications, thereby hindering the broad use of TrustZone. Consequently, we propose a runtime framework backed by TrustZone to construct a secondary TEE. Ambassy has its residence built on an on-chip field-programmable gate array (FPGA), which is a standard component in an ARM/FPGA hybrid system readily available on the market today. This study, to the best of our knowledge, is the first attempt to broaden the use of TrustZone by using an FPGA to build a secondary TEE for arbitrary third-parties, which otherwise should be expelled to the Normal World. This paper describes many design challenges that we have overcome to fully implement Ambassy on an FPGA. Our experiments demonstrate the practicality of Ambassy by presenting the security analysis and performance results of third-party application samples. The samples all run safely on Ambassy , with shorter execution times than regular TEE applications in TrustZone (by a factor of 5.5–52).},
  archive      = {J_TMC},
  author       = {Dongil Hwang and Sanzhar Yeleuov and Jiwon Seo and Minu Chung and Hyungon Moon and Yunheung Paek},
  doi          = {10.1109/TMC.2021.3086143},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {708-719},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Ambassy: A runtime framework to delegate trusted applications in an ARM/FPGA hybrid system},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive preamble embedding with MIMO to support
user-defined functionalities in WLANs. <em>TMC</em>, <em>22</em>(2),
691–707. (<a href="https://doi.org/10.1109/TMC.2021.3095459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the Wi-Fi technology transitions into its sixth generation (Wi-Fi 6), there is a growing consensus on the need to support security and coordination functions at the Physical (PHY) layer. In contrast to the costly approach of extending the PHY-layer header to support new functions (e.g., Spatial Reuse field in the Wi-Fi 6 frame), we propose to turn specific parts of the frame preamble into a reliable data field while maintaining its primary functions. Specifically, in this paper, we develop a scheme called extensible preamble modulation (eP-Mod) for 802.11n/ac/ax protocols that are built on multiple-input-multiple-output (MIMO) and orthogonal frequency-division multiplexing (OFDM). For each frame, eP-Mod can embed up to 144 user bits into the 802.11ac preamble of an &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$8\times 8$&lt;/tex-math&gt;&lt;/inline-formula&gt; MIMO &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$40\;$&lt;/tex-math&gt;&lt;/inline-formula&gt; MHz transmission. The proposed scheme is adaptive to channel conditions and enables several promising PHY-layer services, such as PHY-layer encryption and channel/device authentication, and PHY-layer signaling. At the same time, it allows legacy ( eP-Mod -unaware) devices to continue to process the received preamble as normal by guaranteeing that the proposed preamble waveforms satisfy the structural properties of a standardized preamble. Through numerical analysis, extensive simulations, and hardware experiments, we validate the practicality and reliability of eP-Mod .},
  archive      = {J_TMC},
  author       = {Zhengguang Zhang and Hanif Rahbari and Marwan Krunz},
  doi          = {10.1109/TMC.2021.3095459},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {691-707},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive preamble embedding with MIMO to support user-defined functionalities in WLANs},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive asynchronous federated learning in
resource-constrained edge computing. <em>TMC</em>, <em>22</em>(2),
674–690. (<a href="https://doi.org/10.1109/TMC.2021.3096846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has been widely adopted to train machine learning models over massive data in edge computing. However, machine learning faces critical challenges, e.g., data imbalance, edge dynamics, and resource constraints, in edge computing. The existing FL solutions cannot well cope with data imbalance or edge dynamics, and may cause high resource cost. In this paper, we propose an adaptive asynchronous federated learning (AAFL) mechanism. To deal with edge dynamics, a certain fraction &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\alpha$&lt;/tex-math&gt;&lt;/inline-formula&gt; of all local updates will be aggregated by their arrival order at the parameter server in each epoch. Moreover, the system can intelligently vary the number of local updated models for global model aggregation in different epochs with network situations. We then propose experience-driven algorithms based on deep reinforcement learning (DRL) to adaptively determine the optimal value of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\alpha$&lt;/tex-math&gt;&lt;/inline-formula&gt; in each epoch for two cases of AAFL, single learning task and multiple learning tasks, so as to achieve less completion time of training under resource constraints. Extensive experiments on the classical models and datasets show high effectiveness of the proposed algorithms. Specifically, AAFL can reduce the completion time by about 70 percent and improve the learning accuracy by about 28 percent under resource constraints, compared with the state-of-the-art solutions.},
  archive      = {J_TMC},
  author       = {Jianchun Liu and Hongli Xu and Lun Wang and Yang Xu and Chen Qian and Jinyang Huang and He Huang},
  doi          = {10.1109/TMC.2021.3096846},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {674-690},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive asynchronous federated learning in resource-constrained edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active acoustic sensing for “hearing” temperature under
acoustic interference. <em>TMC</em>, <em>22</em>(2), 661–673. (<a
href="https://doi.org/10.1109/TMC.2021.3096792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though measuring ambient temperature is often deemed as an easy job, collecting large-scale temperature readings in real-time is still a formidable task. The recent boom of network-ready (mobile) devices and the subsequent mobile crowdsourcing applications do offer an opportunity to accomplish this task, yet equipping commodity devices with ambient temperature sensing capability is highly non-trivial and hence has never been achieved. In this paper, we propose Ac o u stic T h e rmometer (AcuTe+) as an interference-resilient ambient temperature sensor empowered by a single commodity smartphone. AcuTe+ utilizes on-board dual microphones to estimate air-borne sound propagation speed, thereby deriving ambient temperature. To accurately estimate sound propagation speed, we leverage the phase of chirp signals to circumvent the low sample rate on commodity hardware. In addition, we propose to use both structure-borne and air-borne propagations to address the multipath problem. Most importantly, we equip AcuTe+ with a mask-based desnoising algorithm to handle intensive acoustic interference. As a mobile, economical, highly accurate sensor, AcuTe+ may potentially enable many relevant applications, in particular large-scale indoor/outdoor temperature monitoring in real-time. We have conducted extensive experiments on AcuTe+; the results demonstrate a median error of 0.6 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^\circ$&lt;/tex-math&gt;&lt;/inline-formula&gt; C even under severe acoustic interference (overall median 0.3 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^\circ$&lt;/tex-math&gt;&lt;/inline-formula&gt; C), and they also showcase the practical ability of AcuTe+ in real-time distributed temperature sensing.},
  archive      = {J_TMC},
  author       = {Chao Cai and Henglin Pu and Liyuan Ye and Hongbo Jiang and Jun Luo},
  doi          = {10.1109/TMC.2021.3096792},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {661-673},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Active acoustic sensing for “Hearing” temperature under acoustic interference},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Acoustic software defined platform: A versatile sensing and
general benchmarking platform. <em>TMC</em>, <em>22</em>(2), 647–660.
(<a href="https://doi.org/10.1109/TMC.2021.3093259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acoustic sensing has attracted significant attention recently, thanks to the pervasive availability of device support. However, adopting consumer-grade devices (e.g., smartphones) to deploy acoustic sensing applications faces the challenge of device/OS heterogeneity. Researchers have to pay tremendous efforts in tackling platform-dependent details even in simply accessing raw audio samples, thus losing focus on innovating sensing algorithms. To this end, this paper presents the first Acoustic Software Defined Platform (ASDP): a versatile sensing and general benchmarking platform. ASDP encompasses several customized acoustic modules running on a ubiquitous computing board, backed by a dedicated software framework. It is superior to commodity devices in controlling and reconfiguring physical layer settings, thus offering much better usability. The tailored software framework abstracts platform details and provides user-friendly interface for fast prototyping, while maintaining adequate programmability. To demonstrate the usefulness of ASDP, we showcase several relevant applications based on it. The promising outcomes make us believe that the release of our ASDP could greatly advance acoustic sensing research.},
  archive      = {J_TMC},
  author       = {Chao Cai and Henglin Pu and Menglan Hu and Rong Zheng and Jun Luo},
  doi          = {10.1109/TMC.2021.3093259},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {647-660},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Acoustic software defined platform: A versatile sensing and general benchmarking platform},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Acceptance-aware mobile crowdsourcing worker recruitment in
social networks. <em>TMC</em>, <em>22</em>(2), 634–646. (<a
href="https://doi.org/10.1109/TMC.2021.3090764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing prominence of smart mobile devices, an innovative distributed computing paradigm, namely Mobile Crowdsourcing (MCS), has emerged. By directly recruiting skilled workers, MCS exploits the power of the crowd to complete location-dependent tasks. Currently, based on online social networks, a new and complementary worker recruitment mode, i.e., socially aware MCS, has been proposed to effectively enlarge worker pool and enhance task execution quality, by harnessing underlying social relationships. In this paper, we propose and develop a novel worker recruitment game in socially aware MCS, i.e., A cceptance-aware W orker R ecruitment ( AWR ). To accommodate MCS task invitation diffusion over social networks, we design a Random Diffusion model, where workers randomly propagate task invitations to social neighbors, and receivers independently make a decision whether to accept or not. Based on the diffusion model, we formulate the AWR game as a combinatorial optimization problem, which strives to search a subset of seed workers to maximize overall task acceptance under a pre-given incentive budget. We prove its NP hardness, and devise a meta-heuristic-based evolutionary approach named MA-RAWR to balance exploration and exploitation during the search process. Comprehensive experiments using two real-world data sets clearly validate the effectiveness and efficiency of our proposed approach.},
  archive      = {J_TMC},
  author       = {Liang Wang and Dingqi Yang and Zhiwen Yu and Qi Han and En Wang and Kuang Zhou and Bin Guo},
  doi          = {10.1109/TMC.2021.3090764},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {634-646},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Acceptance-aware mobile crowdsourcing worker recruitment in social networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A reciprocal charging mechanism for electric vehicular
networks in charging-station-absent zones. <em>TMC</em>, <em>22</em>(2),
621–633. (<a href="https://doi.org/10.1109/TMC.2021.3096328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electric vehicles (EVs), as promising components of sustainable and eco-friendly transportation systems, are being widely adopted to reduce the consumption of fossil fuel and the pollution of environments. EVs are usually equipped with wireless communication modules to support the vehicle to vehicle (V2V) communications, and thus an electric vehicular network (EVN) is constituted. However, the electric energy of EVs is extremely limited, and some EVs are possible to exhaust their electric energy before reaching the destinations. More seriously, when the EVs travel into the zones without any charging stations, they cannot be timely charged. With the rapid developments of wireless charging technologies (such as magnetic resonance) and graphene supercapacitor technologies, the reciprocal charges between EVs become feasible, i.e., the EVs with insufficient energy (IEVs) can be charged by the EVs with surplus energy (SEVs). In this paper, the strategies of selecting the local-optimal SEVs for IEVs and rescheduling their travel routes are investigated, and a distributed Reciprocal Charging Mechanism (RCM) is proposed. Both mechanism analysis and simulation results demonstrate the performance superiority of RCM. Specifically, with the proposed reciprocal charging mechanism, IEVs can be charged by SEVs in a charging-station-absent zone, and the electric energy consumption can be approximatively minimized.},
  archive      = {J_TMC},
  author       = {Linfeng Liu and Houqian Zhang and Jiagao Wu},
  doi          = {10.1109/TMC.2021.3096328},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {621-633},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A reciprocal charging mechanism for electric vehicular networks in charging-station-absent zones},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WiDE: WiFi distance based group profiling via machine
learning. <em>TMC</em>, <em>22</em>(1), 607–620. (<a
href="https://doi.org/10.1109/TMC.2021.3073848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop WiDE, a WiFi-distance estimation based group profiling system using LightGBM. Given the uploaded WiFi information by users, WiDE can automatically learn powerful hidden features from the proposed features for between-user distance estimation, and infer group membership with the estimated distance. For each group, WiDE classifies the mobility level, and recognizes the group structure by applying the multi-dimensional scaling technique on the matrix of distance between pairwise users within the same group. We first validate the performance of between-user distance estimation via conducting extensive experiments in a three-floor campus building and a shopping center, and the results show that WiDE outperforms other machine learning based approaches for between-user distance estimation, with the average absolute error (AAE) of 0.69m and 1.14m for the campus building and shopping center, respectively, and the corridor identification accuracy for the campus building is over 99 percent. In addition, the experiments in the shopping center show that our approach can accurately detect groups, classify group mobility into fine-grained level and recognize the group structure.},
  archive      = {J_TMC},
  author       = {Guoyin Jiang and Minglei Li and Xingjun Liu and Wenping Liu and Yufu Jia and Hongbo Jiang and Junli Lei and Fu Xiao and Kai Zhang},
  doi          = {10.1109/TMC.2021.3073848},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {607-620},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {WiDE: WiFi distance based group profiling via machine learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VocalPrint: A mmWave-based unmediated vocal sensing system
for secure authentication. <em>TMC</em>, <em>22</em>(1), 589–606. (<a
href="https://doi.org/10.1109/TMC.2021.3084971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuing growth of voice-controlled devices, voice metrics have been widely used for user identification. However, voice biometrics is vulnerable to replay attacks and ambient noise. We identify that the fundamental vulnerability in voice biometrics is rooted in its indirect sensing modality (e.g., microphone). In this paper, we present VocalPrint , a resilient mmWave interrogation system which directly captures and analyzes the vocal vibrations for user authentication. Specifically, VocalPrint exploits the unique disturbance of the skin-reflect radio frequency (RF) signals around the near-throat region of the user, caused by the vocal vibrations. The complex ambient noise is isolated from the RF signal using a novel resilience-aware clutter suppression approach for preserving fine-grained vocal biometric properties. Afterward, we extract the vocal tract and vocal source features and input them into an ensemble classifier for authentication. VocalPrint is practical as it allows the effortless transition to a smartphone while having sufficient usability due to its non-contact nature. Our experimental results from 41 participants with different interrogation distances, orientations, and body motions show that VocalPrint achieves over 96 percent authentication accuracy even under unfavorable conditions. We demonstrate the resilience of our system against complex noise interference and spoof attacks of various threat levels.},
  archive      = {J_TMC},
  author       = {Huining Li and Chenhan Xu and Aditya Singh Rathore and Zhengxiong Li and Hanbin Zhang and Chen Song and Kun Wang and Lu Su and Feng Lin and Kui Ren and Wenyao Xu},
  doi          = {10.1109/TMC.2021.3084971},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {589-606},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {VocalPrint: A mmWave-based unmediated vocal sensing system for secure authentication},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tuatara: Location-driven power-adaptive communication for
wireless body area networks. <em>TMC</em>, <em>22</em>(1), 574–588. (<a
href="https://doi.org/10.1109/TMC.2021.3070296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio links in wireless body area networks (WBANs) suffer from both short-term and long-term variations due to the dynamic network topology and frequent blockage caused by body movements, making it challenging to achieve reliable, energy-efficient and real-time data communication. Through experiments with TelosB motes, we observe a strong positive relationship between the channel quality and the location of the sensor node relative to the gateway. Motivated by this observation, we design Tuatara, a novel power-aware communication protocol that allows each sensor node to dynamically adjust its transmission power based on the channel status inferred from its instant location, aiming to save energy, reduce interference, and improve communication reliability. Combining the orientations measured by motion sensors with the anatomical constraints of body movements, each sensor node can locally estimate its instant location relative to the gateway. Based on a probabilistic model, power level selection is converted to calculate the optimal probability of selecting each power level at a given location, with the objective of minimizing the transmission cost. A learning scheme is designed to adaptively update the power level selection probabilities, making Tuatara self-adaptable to changes in the signal propagation environment. Experimental results demonstrate that Tuatara outperforms the state-of-the-art protocols in various scenarios, with performance close to that of the optimal power selection solution even in scenarios where the packet rate is very low.},
  archive      = {J_TMC},
  author       = {Abbas Arghavani and Haibo Zhang and Zhiyi Huang and Yawen Chen and Zhenxiang Chen},
  doi          = {10.1109/TMC.2021.3070296},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {574-588},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Tuatara: Location-driven power-adaptive communication for wireless body area networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trimming mobile applications for bandwidth-challenged
networks in developing regions. <em>TMC</em>, <em>22</em>(1), 556–573.
(<a href="https://doi.org/10.1109/TMC.2021.3088121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite continuous efforts to build and update mobile network infrastructure, mobile devices in developing regions continue to be constrained by limited bandwidth. Unfortunately, this coincides with a period of unprecedented growth in the sizes of mobile applications. Thus it is becoming prohibitively expensive for users in developing regions to download and update mobile apps critical to their economic and educational development. Unchecked, these trends can further contribute to a large and growing global digital divide. Our goal is to better understand the source of this rapid growth in mobile app code size, whether it is reflective of new functionality, and identify steps that can be taken to make existing mobile apps more friendly to bandwidth constrained mobile networks. We hypothesize that much of this growth in mobile apps is due to poor resource/code management, and do not reflect proportional increases in functionality. Our hypothesis is partially validated by mini-programs, apps with extremely small footprints gaining popularity in Chinese mobile platforms. Here, we use functionally equivalent pairs of mini-programs and Android apps to identify potential sources of “bloat,” i.e., inefficient uses of code or resources that contribute to large package sizes. We analyze a large sample of popular Android apps and quantify instances of code and resource bloat. We develop techniques for automated code and resource trimming, and successfully validate them on a large set of Android apps. We hope our results will lead to continued efforts to streamline mobile apps, making them easier to access and maintain for users in developing regions.},
  archive      = {J_TMC},
  author       = {Qinge Xie and Qingyuan Gong and Xinlei He and Yang Chen and Xin Wang and Haitao Zheng and Ben Y. Zhao},
  doi          = {10.1109/TMC.2021.3088121},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {556-573},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Trimming mobile applications for bandwidth-challenged networks in developing regions},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward multiple federated learning services resource sharing
in mobile edge networks. <em>TMC</em>, <em>22</em>(1), 541–555. (<a
href="https://doi.org/10.1109/TMC.2021.3085979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning is a new learning scheme for collaborative training a shared prediction model while keeping data locally on participating devices. In this paper, we study a new model of multiple federated learning services at the multi-access edge computing server. Accordingly, the sharing of CPU resources among learning services at each mobile device for the local training process and allocating communication resources among mobile devices for exchanging learning information must be considered. Furthermore, the convergence performance of different learning services depends on the hyper-learning rate parameter that needs to be precisely decided. Towards this end, we propose a joint resource optimization and hyper-learning rate control problem, namely &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf MS-FEDL}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , regarding the energy consumption of mobile devices and overall learning time. We design a centralized algorithm based on the block coordinate descent method and a decentralized JP-miADMM algorithm for solving the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\sf MS-FEDL}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; problem. Different from the centralized approach, the decentralized approach requires many iterations to obtain but it allows each learning service to independently manage the local resource and learning process without revealing the learning service information. Our simulation results demonstrate the convergence performance of our proposed algorithms and the superior performance of our proposed algorithms compared to the heuristic strategy.},
  archive      = {J_TMC},
  author       = {Minh N. H. Nguyen and Nguyen H. Tran and Yan Kyaw Tun and Zhu Han and Choong Seon Hong},
  doi          = {10.1109/TMC.2021.3085979},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {541-555},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Toward multiple federated learning services resource sharing in mobile edge networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SOAR: Smart online aggregated reservation for mobile edge
computing brokerage services. <em>TMC</em>, <em>22</em>(1), 527–540. (<a
href="https://doi.org/10.1109/TMC.2021.3075947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of MEC services, MEC brokers will emerge to facilitate the purchase and management of resources for individual MEC users. Both data communication and computing resources offered by MEC service providers can be purchased by pay-as-you-go (PAYG) or reserved plans. Besides data and computing plans for each type of resource, we also consider combo plans specifically designed for MEC services covering both resources. In this paper, we propose a smart online aggregated reservation (SOAR) framework for MEC brokers to minimize their cost of reserving resources for multiple users without the knowledge of future demands. In our framework, a task aggregation algorithm is designed to aggregate the users’ demands in each PAYG billing cycle to improve the plan utilization, and plan reservation algorithms are proposed to decide when to reserve which plans. The performance gap (competitive ratio) between SOAR and optimal solution which knows all future demands in advance, is analyzed and derived in closed-form. The performance gap is proved to be the minimum among all deterministic online algorithms. Trace-driven simulations verify the cost advantage of our SOAR framework, which can save nearly 40 percent of cost for users through the brokerage service.},
  archive      = {J_TMC},
  author       = {Shizhe Zang and Wei Bao and Phee Lep Yeoh and Branka Vucetic and Yonghui Li},
  doi          = {10.1109/TMC.2021.3075947},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {527-540},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SOAR: Smart online aggregated reservation for mobile edge computing brokerage services},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure voice interactions with smart devices. <em>TMC</em>,
<em>22</em>(1), 515–526. (<a
href="https://doi.org/10.1109/TMC.2021.3069981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice interaction, as an emerging human-computer interaction method, has gained great popularity, especially on smart devices. However, due to the open nature of voice signals, voice interaction may cause privacy leakage. In this paper, we propose a novel scheme, called SeVI , to protect voice interaction from being deliberately or unintentionally eavesdropped. SeVI actively generates jamming noise of superior characteristics, while a user is performing voice interaction with his/her device, so that attackers cannot obtain the voice contents of the user. Meanwhile, the device leverages the prior knowledge of the generated noise to adaptively cancel received noise, even when the device usage environment is changing due to movement, so that the user voice interactions are unaffected. SeVI relies on only normal microphone and speakers and can be implemented as light-weight software. We have implemented SeVI on a commercial off-the-shelf (COTS) smartphone and conducted extensive real-world experiments. The results demonstrate that SeVI can defend both online eavesdropping attacks and offline digital signal processing (DSP) analysis attacks.},
  archive      = {J_TMC},
  author       = {Hongzi Zhu and Xiao Wang and Yi Jiang and Shan Chang and Xudong Wang},
  doi          = {10.1109/TMC.2021.3069981},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {515-526},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secure voice interactions with smart devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Robust task offloading in dynamic edge computing.
<em>TMC</em>, <em>22</em>(1), 500–514. (<a
href="https://doi.org/10.1109/TMC.2021.3068748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-access edge computing achieves better application responsiveness by offloading tasks from end devices to edge servers installed at the vicinity. Practical scenarios, such as post-disaster rescuing and battlefield monitoring, make it attractive to use end devices themselves as edge servers. This, however, introduces a new challenge: Due to mobility and power limitation, the set of edge servers becomes dynamic. As some servers fail, the tasks that run on them will also fail. This paper introduces a new dynamic edge computing model and conducts the first study on robust task offloading which is tolerant to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$h$&lt;/tex-math&gt;&lt;/inline-formula&gt; server failures. We propose online primal-dual algorithms that offload tasks as they arrive. We evaluate the performance of our robust task offloading solutions through extensive simulations based on real task sets. The results show that our proposed solutions can well handle edge dynamics and achieve near optimal throughput (above 95 percent) compared to the optimal offline benchmark algorithm.},
  archive      = {J_TMC},
  author       = {Haibo Wang and Hongli Xu and He Huang and Min Chen and Shigang Chen},
  doi          = {10.1109/TMC.2021.3068748},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {500-514},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust task offloading in dynamic edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RF-based human activity recognition using signal adapted
convolutional neural network. <em>TMC</em>, <em>22</em>(1), 487–499. (<a
href="https://doi.org/10.1109/TMC.2021.3073969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) plays a critical role in a wide range of real-world applications, and it is traditionally achieved via wearable sensing. Recently, to avoid the burden and discomfort caused by wearable devices, device-free approaches exploiting radio-frequency (RF) signals arise as a promising alternative for HAR. Most of the latest device-free approaches require training a large deep neural network model in either time or frequency domain, entailing extensive storage to contain the model and intensive computations to infer human activities. Consequently, even with some major advances on device-free HAR, current device-free approaches are still far from practical in real-world scenarios where the computation and storage resources possessed by, for example, edge devices, are limited. To overcome these weaknesses, we introduce HAR-SAnet which is a novel RF-based HAR framework. It adopts an original signal adapted convolutional neural network architecture: instead of feeding the handcraft features of RF signals into a classifier, HAR-SAnet fuses them adaptively from both time and frequency domains to design an end-to-end neural network model. We apply point-wise grouped convolution and depth-wise separable convolutions to confine the model scale and to speed up the inference execution time. The experiment results show that the recognition accuracy of HAR-SAnet substantially outperforms the state-of-the-art algorithms and systems.},
  archive      = {J_TMC},
  author       = {Zhe Chen and Chao Cai and Tianyue Zheng and Jun Luo and Jie Xiong and Xin Wang},
  doi          = {10.1109/TMC.2021.3073969},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {487-499},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RF-based human activity recognition using signal adapted convolutional neural network},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time in-network image compression via distributed
dictionary learning. <em>TMC</em>, <em>22</em>(1), 472–486. (<a
href="https://doi.org/10.1109/TMC.2021.3072066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-camera networks are increasingly becoming pervasive in many monitoring and surveillance applications, and have attracted much attention in distributed systems with collaborative, real-time decision-making capabilities. While in-network data compression brings significant energy savings in camera nodes, signal representation using sparse approximations and overcomplete dictionaries have been shown to outperform traditional compression methods. In this work, an end-to-end and real-time solution is designed and implemented to enable energy-efficient and robust dictionary learning in distributed camera networks by leveraging the spatial correlation of the collected multimedia data. Traditional distributed dictionary learning relies on consensus-building algorithms, which involve communicating with neighboring nodes until convergence is achieved. Existing methods, however, do not exploit spatial correlations in camera networks for improved energy efficiency. In contrast, low-computational-complexity metrics are employed in this work to quantify and exploit the spatial correlation across camera nodes in a wireless network for efficient distributed dictionary learning and in-network image compression. The performance of the proposed approach is validated through extensive simulations on public datasets as well as via real-world experiments on a testbed composed of Raspberry Pi nodes.},
  archive      = {J_TMC},
  author       = {Parul Pandey and Mehdi Rahmati and Waheed U. Bajwa and Dario Pompili},
  doi          = {10.1109/TMC.2021.3072066},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {472-486},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Real-time in-network image compression via distributed dictionary learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantifying worker reliability for crowdsensing
applications: Robust feedback rating and convergence. <em>TMC</em>,
<em>22</em>(1), 459–471. (<a
href="https://doi.org/10.1109/TMC.2021.3072477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worker reliability estimation is a fundamental problem in crowdsensing applications. This paper proposes a robust feedback rating approach to estimate worker reliability explicitly. In this approach, the requester provides a feedback rating to reflect the quality of the sensor data submitted by each worker. The aggregation of each worker&#39;s historical feedback ratings serves as a reliability estimate. The challenges are: (1) Feedback ratings are subjected to noise; (2) Workers’ cognitive bias in task selection leads to sensor data quality variations. We develop a mathematical model to quantify rating noise from requesters and the degree of cognitive bias of workers in task selection. We derive sufficient conditions, under which the aggregate rating is asymptotically accurate in estimating worker reliability, via stochastic approximation techniques. These conditions identify a class of asymptotically accurate rating aggregation rules for crowdsensing applications. We further derive the minimum number of ratings needed to guarantee a given reliability estimation accuracy, via martingale theory. Via extensive experiments: (1) We reveal fundamental understandings on how various factors such as rating noise influence the minimum number of ratings needed to achieve certain accuracy; (2) We show that our feedback rating approach improves air quality index estimation accuracy by as high as 50 percent over the a typical baseline algorithm.},
  archive      = {J_TMC},
  author       = {Hong Xie and John C. S. Lui},
  doi          = {10.1109/TMC.2021.3072477},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {459-471},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Quantifying worker reliability for crowdsensing applications: Robust feedback rating and convergence},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). QoE-aware efficient content distribution scheme for
satellite-terrestrial networks. <em>TMC</em>, <em>22</em>(1), 443–458.
(<a href="https://doi.org/10.1109/TMC.2021.3074917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The satellite-terrestrial networks (STN) utilize the spacious coverage and low transmission latency of the Low Earth Orbit (LEO) constellation to transfer requested content for subscribers especially in remote areas. With the development of storage and computing capacity of satellite onboard equipment, it is considered promising to leverage in-network caching technology on STN to improve content distribution efficiency. However, traditional caching and distribution schemes are not suitable in STN, considering dynamic satellite propagation links and time-varying topology. More specifically, the unevenness of user distribution heightens difficulties for assurance of user quality of experience. To address these problems, we first propose a density-based network division algorithm. The STN is divided into a series of blocks with different sizes to amortize the data delivery costs. To deploy the caching satellites, we analyze the link connectivity and propose an approximate minimum coverage vertex set algorithm. Then, a novel cache node selection algorithm is designed for optimal subscriber matching. On the basis of time-varying network model, the STN cache content updating mechanism is derived to enable a stable and sustainable quality of user experience. The simulation results demonstrate that the proposed user-oriented STN content distribution scheme can obviously reduce the average propagation delay and network load under different network conditions and has better stability and self-adaptability under continuous time variation.},
  archive      = {J_TMC},
  author       = {Dingde Jiang and Feng Wang and Zhihan Lv and Shahid Mumtaz and Saba Al-Rubaye and Antonios Tsourdos and Octavia Dobre},
  doi          = {10.1109/TMC.2021.3074917},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {443-458},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {QoE-aware efficient content distribution scheme for satellite-terrestrial networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Profit sharing for data producer and intermediate parties in
data trading over pervasive edge computing environments. <em>TMC</em>,
<em>22</em>(1), 429–442. (<a
href="https://doi.org/10.1109/TMC.2021.3073669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovative edge devices (e.g., smartphones, IoT devices) are becoming much more pervasive in our daily lives. With powerful sensing and computing capabilities, users can generate massive amounts of data. A new business model has emerged where data producers can sell their data to consumers directly to make money. However, how to protect the profit of the data producer from rogue consumers that may resell without authorization remains challenging. In this paper, we propose a smart-contract based protocol to protect the profit of the data producer while allowing consumers to resell the data legitimately. The protocol ensures the revenue is shared with the data producer over authorized reselling, and detects any unauthorized reselling. We also introduce a data relay process that can enhance data accessibility in wireless edge networks. We formulate a revenue sharing problem to maximize the profit of both the data producer and resellers/relayers. We formulate the problem into a two-stage Stackelberg game and determine a ratio to share the reselling revenue between the data producer and resellers/relayers. Extensive simulations show that with resellers and relayers, our mechanism can achieve up to 49.5 percent higher profit for the data producer and resellers/relayers.},
  archive      = {J_TMC},
  author       = {Yaodong Huang and Yiming Zeng and Fan Ye and Yuanyuan Yang},
  doi          = {10.1109/TMC.2021.3073669},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {429-442},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Profit sharing for data producer and intermediate parties in data trading over pervasive edge computing environments},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy-preserving travel time prediction with uncertainty
using GPS trace data. <em>TMC</em>, <em>22</em>(1), 417–428. (<a
href="https://doi.org/10.1109/TMC.2021.3074865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of GPS technology and mobile devices has led to a massive accumulation of location data, bringing considerable benefits to individuals and society. One of the major usages of such data is travel time prediction, a typical service provided by GPS navigation devices and apps. Meanwhile, the constant collection and analysis of the individual location data also pose unprecedented privacy threats. We leverage the notion of geo-indistinguishability, an extension of differential privacy to the location privacy setting, and propose a procedure for privacy-preserving travel time prediction without collecting actual individual GPS trace data. We propose new concepts to examine the impact of geo-indistinguishability-based sanitization on the usefulness of GPS traces and provide analytical and experimental utility analysis for privacy-preserving travel time prediction. We also propose new metrics to measure the adversary error in learning individual GPS traces from the collected sanitized data. Our experiment results suggest that the proposed procedure provides travel time prediction with satisfactory accuracy at reasonably small privacy costs.},
  archive      = {J_TMC},
  author       = {Fang Liu and Dong Wang and Zhengquan Xu},
  doi          = {10.1109/TMC.2021.3074865},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {417-428},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy-preserving travel time prediction with uncertainty using GPS trace data},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predictive estimation of optimal signal strength from drones
over IoT frameworks in smart cities. <em>TMC</em>, <em>22</em>(1),
402–416. (<a href="https://doi.org/10.1109/TMC.2021.3074442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of drones, the Internet of Things (IoT), and Artificial Intelligence (AI) domains can produce exceptional solutions to today complex problems in smart cities. A drone, which essentially is a data-gathering robot, can access geographical areas that are difficult, unsafe, or even impossible for humans to reach. Besides, communicating amongst themselves, such drones need to be in constant contact with other ground-based agents such as IoT sensors, robots, and humans. In this paper, an intelligent technique is proposed to predict the signal strength from a drone to IoT devices in smart cities in order to maintain the network connectivity, provide the desired quality of service (QoS), and identify the drone coverage area. An artificial neural network (ANN) based efficient and accurate solution is proposed to predict the signal strength from a drone based on several pertinent factors such as drone altitude, path loss, distance, transmitter height, receiver height, transmitted power, and signal frequency. Furthermore, the signal strength estimates are then used to predict the drone flying path. The findings show that the proposed ANN technique has achieved a good agreement with the validation data generated via simulations, yielding determination coefficient &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$R^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; to be 0.96 and 0.98, for variation in drone altitude and distance from a drone, respectively. Therefore, the proposed ANN technique is reliable, useful, and fast to estimate the signal strength, determine the optimal drone flying path, and predict the next location based on received signal strength.},
  archive      = {J_TMC},
  author       = {Saeed Hamood Alsamhi and Faris. A. Almalki and Ou Ma and Mohammad Samar Ansari and Brian Lee},
  doi          = {10.1109/TMC.2021.3074442},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {402-416},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Predictive estimation of optimal signal strength from drones over IoT frameworks in smart cities},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Post-streaming wastage analysis – a data wastage aware
framework in mobile video streaming. <em>TMC</em>, <em>22</em>(1),
389–401. (<a href="https://doi.org/10.1109/TMC.2021.3069764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile video streaming is now ubiquitous among mobile users. This work investigates a less studied and yet significant problem in mobile video streaming – data wastage, i.e., some downloaded video data may not be played back but discarded by video players due to early departure or video skip, thus the bandwidth consumed in transferring them is wasted. Our measurements show that data wastage is significant in practice, e.g., 25.2 percent∼51.7 percent of video data downloaded are in fact wasted. Moreover, substantial data wastage exists not only in current commercial streaming platforms, but also in state-of-the-art adaptive streaming systems proposed in the literature. This work develops a new post-streaming wastage analysis (PSWA) framework to tackle this problem by converting existing adaptive streaming algorithms into data wastage aware versions. PSWA enables the streaming vendors to explicitly control the tradeoff between data wastage and quality-of-experience (QoE). Extensive evaluations show that PSWA can reduce data wastage significantly (e.g., 80 percent) without any adverse impact on QoE. Moreover, it has strong robustness to perform consistently across a wide range of networks. PSWA can be readily implemented into current streaming platforms, and thus offers a practical solution to data wastage for mobile streaming services.},
  archive      = {J_TMC},
  author       = {Guanghui Zhang and Ke Liu and Haibo Hu and Vaneet Aggarwal and Jack Y. B. Lee},
  doi          = {10.1109/TMC.2021.3069764},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {389-401},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Post-streaming wastage analysis – a data wastage aware framework in mobile video streaming},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Personalized activity recognition using partially available
target data. <em>TMC</em>, <em>22</em>(1), 374–388. (<a
href="https://doi.org/10.1109/TMC.2021.3071434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed a growing body of research on autonomous activity recognition models for use in deployment of mobile systems in new settings such as when a wearable system is adopted by a new user. Current research, however, lacks comprehensive frameworks for transfer learning. Specifically, it lacks the ability to deal with partially available data in new settings. To address these limitations, we propose OptiMapper , a novel uninformed cross-subject transfer learning framework for activity recognition. OptiMapper is a combinatorial optimization framework that extracts abstract knowledge across subjects and utilizes this knowledge for developing a personalized and accurate activity recognition model in new subjects. To this end, a novel community-detection-based clustering of unlabeled data is proposed that uses the target user data to construct a network of unannotated sensor observations. The clusters of these target observations are then mapped onto the source clusters using a complete bipartite graph model. In the next step, the mapped labels are conditionally fused with the prediction of a base learner to create a personalized and labeled training dataset for the target user. We present two instantiations of OptiMapper. The first instantiation, which is applicable for transfer learning across domains with identical activity labels, performs a one-to-one bipartite mapping between clusters of the source and target users. The second instantiation performs optimal many-to-one mapping between the source clusters and those of the target. The many-to-one mapping allows us to find an optimal mapping even when the target dataset does not contain sufficient instances of all activity classes. We show that this type of cross-domain mapping can be formulated as a transportation problem and solved optimally. We evaluate our transfer learning techniques on several activity recognition datasets. Our results show that the proposed community detection approach can achieve, on average, 69 percent utilization of the datasets for clustering with an overall clustering accuracy of 87.5 percent. Our results also suggest that the proposed transfer learning algorithms can achieve up to 22.5 percent improvement in the activity recognition accuracy, compared to the state-of-the-art techniques. The experimental results also demonstrate high and sustained performance even in presence of partial data.},
  archive      = {J_TMC},
  author       = {Ramin Fallahzadeh and Zhila Esna Ashari and Parastoo Alinia and Hassan Ghasemzadeh},
  doi          = {10.1109/TMC.2021.3071434},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {374-388},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Personalized activity recognition using partially available target data},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online zero-cost learning: Optimizing large scale network
rare threats simulation. <em>TMC</em>, <em>22</em>(1), 356–373. (<a
href="https://doi.org/10.1109/TMC.2021.3074920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To provide fast and accurate risk evaluation on network rare threats, importance sampling (IS) is widely used in the rare threat simulation; however, it becomes costly to deal with many rare threats simultaneously. For example, a rare threat can be the failure to provide quality-of-service (QoS) guarantees to a critical network flow. Considering network providers often need to deal with many critical flows (i.e., rare threats) simultaneously, if using IS, network providers have to simulate each rare threat with its customized importance distribution individually. To reduce such simulation cost, we propose an efficient mixture importance distribution to simulate multiple rare threats, and then formulate a mixture importance sampling optimization problem (MISO) to select the optimal mixture. We first show that it is challenging to locate the optimal mixture for the “ search direction ” is computationally expensive to evaluate. We then formulate an online learning (OL) framework to estimate the “ search direction ” and learn the optimal mixture from simulation samples of threats. And our OL framework has a “ zero learning cost ” as the samples generated in the learn phase can be reused to provide accurate estimation on the rare threats. We develop two multi-armed bandit OL algorithms so as to: (1) Minimize the sum of estimation variances with a regret of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(\ln T)^2 {/} T$&lt;/tex-math&gt;&lt;/inline-formula&gt; ; and (2) Minimize the simulation cost with a regret of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sqrt{\ln T {/} T}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$T$&lt;/tex-math&gt;&lt;/inline-formula&gt; denotes the number of simulation samples. We demonstrate the versatility of our method on different network applications. When compared with the uniform mixture IS, our method reduces cost measures (i.e., sum of estimation variances and simulation cost) by as high as 61.6 percent in the Internet backbone network scenario.},
  archive      = {J_TMC},
  author       = {Tingwei Liu and Hong Xie and John C. S. Lui},
  doi          = {10.1109/TMC.2021.3074920},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {356-373},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online zero-cost learning: Optimizing large scale network rare threats simulation},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On goodness of WiFi based monitoring of sleep vital signs in
the wild. <em>TMC</em>, <em>22</em>(1), 341–355. (<a
href="https://doi.org/10.1109/TMC.2021.3077533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WiFi channel state information (CSI) has emerged as a plausible modality for sensing different human vital signs, i.e., respiration and body motion, as a function of modulated wireless signals that travel between WiFi devices. Although a remarkable proposition, most of the existing research in this space struggles to withstand robust performance beyond experimental conditions. To this end, we take a careful look at the dynamics of WiFi signals under human respiration and body motions in the wild. We first characterize the WiFi signal components—multipath and signal subspace—that are modulated by human respiration and body motions. We extrapolate on a set of transformations, including first-order differentiation, max-min normalization and component projections, that faithfully explains and quantifies the dynamics of respiration and body motions on WiFi signals. Grounded in this characterization, we propose two methods: 1) a respiration tracking technique that models the peak dynamics observed in the time-varying signal subspace and 2) a body-motion tracking technique built with a multi-dimensional clustering of evolving signal subspace. Finally, we reflect on the manifestation of these techniques in a practical sleep monitoring application. Our systematic evaluation with over 550 hours of data from 5 users covering both line-of-sight (LOS) and non-line-of-sight (NLOS) settings shows that the proposed techniques can achieve comparable performance to purpose-built pulse-Doppler radar.},
  archive      = {J_TMC},
  author       = {Kamran Ali and Mohammed Alloulah and Fahim Kawsar and Alex X. Liu},
  doi          = {10.1109/TMC.2021.3077533},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {341-355},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On goodness of WiFi based monitoring of sleep vital signs in the wild},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mobility-aware computation offloading in edge computing
using machine learning. <em>TMC</em>, <em>22</em>(1), 328–340. (<a
href="https://doi.org/10.1109/TMC.2021.3085527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloudlets are resource-rich computing infrastructures of edge computing that are located at physical proximity of users to provide one-hop, high-bandwidth wireless access to additional computational resources. They enable computation offloading for user applications, which compensates for the resource limitation of user devices by providing ultra-low latency processing for their applications. Although the computation capability of user devices is dramatically augmented by offloading, spatio-temporal uncertainties due to user mobility and changes in application specifications bring the most challenging obstacles in deciding where to offload to provide minimum latency. In this paper, we focus on these challenges by designing efficient offloading approaches that take into account these uncertainties and dynamics in order to minimize the turnaround time of the applications, which is constituted by offloading latency, migration delay, and execution time. We first formulate this NP-hard problem as an integer programming model to obtain optimal offloading decisions. We tackle its intractability by designing two novel offloading approaches, called S-OAMC and G-OAMC, that fully assign applications to cloudlets by considering their expected future locations and specifications predicted by Matrix Completion, a machine learning method. S-OAMC is a sampling-based approximation dynamic programming approach that enhances scalability and obtains near-optimal solutions. G-OAMC is a fast greedy-based approach for finding low-turnaround time offloading decisions. We conduct extensive experiments to assess the performance of our proposed approaches. The results show that S-OAMC and G-OAMC lead to near-optimal turnaround time in a reasonable time, and they both obtain low migration rates.},
  archive      = {J_TMC},
  author       = {Erfan Farhangi Maleki and Lena Mashayekhy and Seyed Morteza Nabavinejad},
  doi          = {10.1109/TMC.2021.3085527},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {328-340},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobility-aware computation offloading in edge computing using machine learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MagAuth: Secure and usable two-factor authentication with
magnetic wrist wearables. <em>TMC</em>, <em>22</em>(1), 311–327. (<a
href="https://doi.org/10.1109/TMC.2021.3072598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure and usable user authentication is the first line of defense against cyber attacks on smart end-user devices. Advanced hacking techniques pose severe threats to the traditional authentication systems based on the password/PIN/fingerprint. We propose MagAuth, a secure and usable two-factor authentication scheme with commercial off-the-shelf (COTS) wrist wearables with magnetic strap bands to enhance the security and usability of password-based authentication for mobile touchscreen devices. In MagAuth, a user enrolls a self-chosen unlock pattern or touch gesture into his touchscreen device by performing it with the same hand the magnetic wrist wearable is on. The chosen unlock pattern or touch gesture serves as the first authentication factor, and the user’s behavioral features manifested in the magnetic field changes during his finger movement correspond to the second factor. The user can unlock his touchscreen device only when both authentication factors can be validated. Comprehensive user experiments confirm the high security and usability of MagAuth. In particular, MagAuth achieves an average true-positive rate up to 96.3 percent and a false-positive rate no larger than 8.4 percent. Moreover, we show that MagAuth is highly resilient to various attacks.},
  archive      = {J_TMC},
  author       = {Yan Zhang and Dianqi Han and Ang Li and Lili Zhang and Tao Li and Yanchao Zhang},
  doi          = {10.1109/TMC.2021.3072598},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {311-327},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MagAuth: Secure and usable two-factor authentication with magnetic wrist wearables},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Jamming in eavesdropping on throughput maximization in green
cognitive radio networks. <em>TMC</em>, <em>22</em>(1), 299–310. (<a
href="https://doi.org/10.1109/TMC.2021.3068797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work considers a cognitive radio (CR) network consisting of a set of CR transmit-receive node pairs, one fusion center (FC), multiple primary user emulation attack (PUEA) nodes, an eavesdropper ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$E_{av}$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) node and a set of friendly jammers used for protection of CR data transmission from eavesdropping. At the initial time slot of the frame, simultaneous energy harvesting (EH) and spectrum sensing are done through power splitting (PS) mode. CR transmit nodes then amplify and forward the sensed samples of both the primary user (PU) and the PUEA to the FC for cooperative spectrum sensing (CSS). Based on the CSS decision, CR transmit nodes either perform EH over the entire duration or make an opportunistic data transmission in time division mode. The closed form expressions of the optimal sensing duration, power allocation factor and transmit power for each secondary user (SU) are found. The sum secondary throughput of the network is maximized under the constraints of meeting the sensing reliability of the PU, individual energy causality for each SU and the best selected jammer, interference at the PU receiver, individual secondary and secrecy outage probability. Simulation results show a performance gain on the maximum value of the sum secondary throughput by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 17.56 and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 49.69 percent over the existing works.},
  archive      = {J_TMC},
  author       = {Avik Banerjee and Santi P. Maity},
  doi          = {10.1109/TMC.2021.3068797},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {299-310},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Jamming in eavesdropping on throughput maximization in green cognitive radio networks},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implementation of short-packet physical-layer network
coding. <em>TMC</em>, <em>22</em>(1), 284–298. (<a
href="https://doi.org/10.1109/TMC.2021.3071329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the implementation and experimental evaluation of a short-packet physical-layer network coding (PNC) system. Implementation of short-packet PNC systems is challenging. First, short packets may have only a few pilot symbols for synchronization and channel estimation purposes. Increasing the number of pilots increases the overhead; decreasing the number of pilots, on the other hand, degrades the packet error rate performance. Second, many short-packet systems are meant for applications with very stringent delay requirements. Employing advanced but complex PNC channel decoding may result in unacceptable delay due to the processing delay. This work presents a low-complexity and low-overhead physical-layer design of OFDM-based short-packet PNC systems, implemented over the software-defined radio platform. Our design makes use of only a small number of pilots (without separate OFDM preamble symbols) to address issues such as slot synchronization, packet detection, carrier frequency offsets, and mismatched channel state information. Our design employs reduced-complexity XOR channel decoding based code-aided parameter estimation (that includes synchronization and channel estimation) to compensate for the limitations imposed by having a small number of pilots. This is the first demonstration that provides a practical framework for applying PNC to short-packet communications.},
  archive      = {J_TMC},
  author       = {Shakeel Salamat Ullah and Soung Chang Liew and Gianluigi Liva and Taotao Wang},
  doi          = {10.1109/TMC.2021.3071329},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {284-298},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Implementation of short-packet physical-layer network coding},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Friend-as-learner: Socially-driven trustworthy and efficient
wireless federated edge learning. <em>TMC</em>, <em>22</em>(1), 269–283.
(<a href="https://doi.org/10.1109/TMC.2021.3074816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, wireless edge networks have realized intelligent operation and management with edge artificial intelligence (AI) techniques (i.e., federated edge learning). However, the trustworthiness and effective incentive mechanisms of federated edge learning (FEL) have not been fully studied. Thus, the current FEL framework will still suffer untrustworthy or low-quality learning parameters from malicious or inactive learners, which undermines the viability and stability of FEL. To address these challenges, the potential social attributes among edge devices and their users can be exploited, while not included in previous works. In this paper, we propose a novel S ocial F ederated E dge L earning framework (SFEL) over wireless networks, which recruits trustworthy social friends as learning partners. First, we build a social graph model to find like-minded friends, comprehensively considering the mutual trust and learning task similarity. Besides, we propose a social effect based incentive mechanism for better personal federated learning behaviors with both complete and incomplete information. Finally, we conduct extensive simulations with the Erdos-Renyi random network, the Facebook network, and the classic MNIST/CIFAR-10 datasets. Simulation results demonstrate our framework could realize trustworthy and efficient federated learning over wireless edge networks, and it is superior to the existing FEL incentive mechanisms that ignore social effects.},
  archive      = {J_TMC},
  author       = {Xi Lin and Jun Wu and Jianhua Li and Xi Zheng and Gaolei Li},
  doi          = {10.1109/TMC.2021.3074816},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {269-283},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Friend-as-learner: Socially-driven trustworthy and efficient wireless federated edge learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FLORA: Fuzzy based load-balanced opportunistic routing for
asynchronous duty-cycled WSNs. <em>TMC</em>, <em>22</em>(1), 253–268.
(<a href="https://doi.org/10.1109/TMC.2021.3074739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many opportunistic routing (OR) schemes treat network nodes equally, neglecting the fact that the nodes close to the sink undertake more duties than the rest of the network nodes. Therefore, the nodes located at different positions should play different roles during the routing process. Moreover, considering various Quality-of-Service (QoS) requirements, the routing decision in OR is affected by multiple network attributes. The majority of these OR schemes fail to contemplate multiple network attributes while making routing decisions. To address the aforesaid issues, this paper presents a novel protocol that runs in three steps. First, each node defines a Routing Zone (RZ) to route packets toward the sink. Second, the nodes within RZ are prioritized based on the competency value obtained through a novel model that employs Modified Analytic Hierarchy Process (MAHP) and Fuzzy Logic techniques. Finally, one of the forwarders is selected as the final relay node after forwarders coordination. Through extensive experimental simulations, it is confirmed that FLORA achieves better performance compared to its counterparts in terms of energy consumption, overhead packets, waiting times, packet delivery ratio, and network lifetime.},
  archive      = {J_TMC},
  author       = {Weiqi Wu and Xingfu Wang and Ammar Hawbani and Ping Liu and Liang Zhao and Ahmed Al-Dubai},
  doi          = {10.1109/TMC.2021.3074739},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {253-268},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FLORA: Fuzzy based load-balanced opportunistic routing for asynchronous duty-cycled WSNs},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy-efficient multi-access mobile edge computing with
secrecy provisioning. <em>TMC</em>, <em>22</em>(1), 237–252. (<a
href="https://doi.org/10.1109/TMC.2021.3068902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the wide deployment of heterogeneous radio access networks (RANs) in the past decades, the emerging paradigm of multi-access mobile edge computing, which allows mobile terminals to simultaneously offload the computation-workloads to several different edge-computing servers via multi-RANs, has provided a promising scheme for enabling the computation-intensive mobile Internet services in future wireless systems. The broadcasting nature of radio transmission, however, may lead to a potential secrecy-outage during the offloading transmission. In this paper, we thus investigate the energy-efficient multi-access mobile edge computing with secrecy provisioning. Specifically, we first investigate the scenario of one wireless device&#39;s (WD&#39;s) multi-access offloading subject to a malicious node&#39;s eavesdropping. By characterizing the WD&#39;s secrecy based throughput in its offloading transmission, we formulate a joint optimization of the WD&#39;s multi-access computation offloading, secrecy provisioning, and offloading-transmission duration, with the objective of minimizing the WD&#39;s total energy consumption, while providing a guaranteed secrecy-outage during offloading and a guaranteed overall-latency in completing the WD&#39;s workload. Despite the non-convexity of this joint optimization problem, we exploit its layered structure and propose an efficient algorithm for solving it. Based on the study on the single-WD scenario, we further investigate the scenario of multiple WDs, in which a group of WDs sequentially execute the multi-access computation offloading, while subject to a malicious node&#39;s eavesdropping. Taking the coupling effect among different WDs into account, we propose a swapping-heuristic based algorithm (that uses our proposed single-WD algorithm as a subroutine) for finding the ordering of the WDs to execute the multi-access computation offloading, with the objective of minimizing all WDs’ total energy consumption. Extensive numerical results are provided to validate the effectiveness and efficiency of our proposed algorithms. The results demonstrate that our algorithms can outperform some conventional fixed offloading scheduling scheme and randomized offloading ordering scheme.},
  archive      = {J_TMC},
  author       = {Li Ping Qian and Yuan Wu and Ningning Yu and Daohang Wang and Fuli Jiang and Weijia Jia},
  doi          = {10.1109/TMC.2021.3068902},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {237-252},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient multi-access mobile edge computing with secrecy provisioning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enabling content-centric device-to-device communication in
the millimeter-wave band. <em>TMC</em>, <em>22</em>(1), 222–236. (<a
href="https://doi.org/10.1109/TMC.2021.3071468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth in wireless traffic and mobility of devices have congested the core network significantly. This bottleneck, along with spectrum scarcity, made the conventional cellular networks insufficient for the dissemination of large contents. The ability of content-centric networking (CCN) and device-to-device (D2D) communication in offloading the network and huge unlicensed spectrum at millimeter-wave (mmWave) band, make the integration of CCN with D2D communication in the mmWave band a viable solution to improve the network&#39;s throughput. In this paper, we propose a novel scheme that enables efficient initialization of CCN-based D2D networks in the mmWave band through addressing decentralized D2D peer association and antenna beamwidth selection. The proposed scheme considers mmWave characteristics such as directional communication and blockage susceptibility. We propose a heuristic peer association algorithm to associate D2D users using context information, including link stability time and content availability. We model the beamwidth selection problem as a potential game and propose a synchronous log-linear learning algorithm to obtain the game&#39;s optimal Nash equilibrium. The performance of the proposed scheme in terms of data throughput and transmission efficiency is evaluated through extensive simulations. Simulation results show that the proposed scheme improves network performance significantly and outperforms other methods in the literature.},
  archive      = {J_TMC},
  author       = {Niloofar Bahadori and Mahmoud Nabil and Brian Kelley and Abdollah Homaifar},
  doi          = {10.1109/TMC.2021.3071468},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {222-236},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enabling content-centric device-to-device communication in the millimeter-wave band},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed cooperation under uncertainty in drone-based
wireless networks: A bayesian coalitional game. <em>TMC</em>,
<em>22</em>(1), 206–221. (<a
href="https://doi.org/10.1109/TMC.2021.3073772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the resource sharing problem in a drone-based wireless network by considering a distributed control setting under uncertainty (e.g., due to lack of full information). The drones cooperate in serving the users while pooling their spectrum and energy resources in the absence of prior knowledge about different system characteristics such as the amount of available power at the other drones. Compared to the state-of-the-art research in drone-based wireless networks, which is mainly based on the assumption of accurate global information availability at every drone, our setting is realistic and practical. We cast the efficient resource pooling problem as a Bayesian cooperative game in which the agents (drones) engage in a coalition formation process, where the goal is to maximize the overall transmission rate of the network. The drones update their beliefs by using a novel technique that combines the maximum likelihood estimation with Kullback-Leibler divergence. We propose a decision-making strategy for repeated coalition formation that converges to a stable coalition structure. We analyze the performance of the proposed approach by both theoretical analysis and simulations. We provide the comparison of our scheme with the baseline and the socially optimal solution obtained from the exhaustive search. Simulation results demonstrate the superior performance of the proposed method in terms of the sum-rate of the network, the individual rate of the drones, and convergence properties.},
  archive      = {J_TMC},
  author       = {Vandana Mittal and Setareh Maghsudi and Ekram Hossain},
  doi          = {10.1109/TMC.2021.3073772},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {206-221},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed cooperation under uncertainty in drone-based wireless networks: A bayesian coalitional game},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distillation-based semi-supervised federated learning for
communication-efficient collaborative training with non-IID private
data. <em>TMC</em>, <em>22</em>(1), 191–205. (<a
href="https://doi.org/10.1109/TMC.2021.3070013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops a federated learning (FL) framework overcoming largely incremental communication costs due to model sizes in typical frameworks without compromising model performance. To this end, based on the idea of leveraging an unlabeled open dataset, we propose a distillation-based semi-supervised FL (DS-FL) algorithm that exchanges the outputs of local models among mobile devices, instead of model parameter exchange employed by the typical frameworks. In DS-FL, the communication cost depends only on the output dimensions of the models and does not scale up according to the model size. The exchanged model outputs are used to label each sample of the open dataset, which creates an additionally labeled dataset. Based on the new dataset, local models are further trained, and model performance is enhanced owing to the data augmentation effect. We further highlight that in DS-FL, the heterogeneity of the devices’ dataset leads to ambiguous of each data sample and lowing of the training convergence. To prevent this, we propose entropy reduction averaging, where the aggregated model outputs are intentionally sharpened. Moreover, extensive experiments show that DS-FL reduces communication costs up to 99 percent relative to those of the FL benchmark while achieving similar or higher classification accuracy.},
  archive      = {J_TMC},
  author       = {Sohei Itahara and Takayuki Nishio and Yusuke Koda and Masahiro Morikura and Koji Yamamoto},
  doi          = {10.1109/TMC.2021.3070013},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {191-205},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distillation-based semi-supervised federated learning for communication-efficient collaborative training with non-IID private data},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data offloading in UAV-assisted multi-access edge computing
systems under resource uncertainty. <em>TMC</em>, <em>22</em>(1),
175–190. (<a href="https://doi.org/10.1109/TMC.2021.3069911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel data offloading decision-making framework is proposed, where users have the option to partially offload their data to a complex Multi-access Edge Computing (MEC) environment, consisting of both ground and UAV-mounted MEC servers. The problem is treated under the perspective of risk-aware user behavior as captured via prospect-theoretic utility functions, while accounting for the inherent computing environment uncertainties. The UAV-mounted MEC servers act as a common pool of resources with potentially superior but uncertain payoff for the users, while the local computation and ground server alternatives constitute safe and guaranteed options, respectively. The optimal user task offloading to the available computing choices is formulated as a maximization problem of each user’s satisfaction, and confronted as a non-cooperative game. The existence and uniqueness of a Pure Nash Equilibrium (PNE) are proven, and convergence to the PNE is shown. Detailed numerical results highlight the convergence of the system to the PNE in few only iterations, while the impact of user behavior heterogeneity is evaluated. The introduced framework’s consideration of the user risk-aware characteristics and computing uncertainties, results to a sophisticated exploitation of the system resources, which in turn leads to superior users’ experienced performance compared to alternative approaches.},
  archive      = {J_TMC},
  author       = {Pavlos Athanasios Apostolopoulos and Georgios Fragkos and Eirini Eleni Tsiropoulou and Symeon Papavassiliou},
  doi          = {10.1109/TMC.2021.3069911},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {175-190},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Data offloading in UAV-assisted multi-access edge computing systems under resource uncertainty},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data collection maximization in IoT-sensor networks via an
energy-constrained UAV. <em>TMC</em>, <em>22</em>(1), 159–174. (<a
href="https://doi.org/10.1109/TMC.2021.3084972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study sensing data collection of IoT devices in a sparse IoT-sensor network, using an energy-constrained Unmanned Aerial Vehicle (UAV), where the sensory data is stored in IoT devices while the IoT devices may or may not be within the transmission range of each other. We formulate two novel data collection problems to fully or partially collect data stored from IoT devices using the UAV, by finding a closed tour for the UAV that consists of hovering locations and the sojourn duration at each of the hovering locations such that the accumulative volume of data collected within the tour is maximized, subject to the energy capacity on the UAV, where the UAV consumes energy on both hovering for data collection and flying from one hovering location to another hovering location. To this end, we first propose a novel data collection framework that enables the UAV to collect sensory data from multiple IoT devices simultaneously if these IoT devices are within the coverage range of the UAV, through adopting the orthogonal frequency division multiple access (OFDMA) technique. We then formulate two data collection maximization problems to deal with full or partial data collection from IoT devices at each hovering location, and show that both defined problems are NP-hard. We instead devise approximation and heuristic algorithms for the problems. We finally evaluate the performance of the proposed algorithms through experimental simulations. Simulation results demonstrated that the proposed algorithms are promising.},
  archive      = {J_TMC},
  author       = {Yuchen Li and Weifa Liang and Wenzheng Xu and Zichuan Xu and Xiaohua Jia and Yinlong Xu and Haibin Kan},
  doi          = {10.1109/TMC.2021.3084972},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {159-174},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Data collection maximization in IoT-sensor networks via an energy-constrained UAV},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross layer resource allocation in h-CRAN with spectrum and
energy cooperation. <em>TMC</em>, <em>22</em>(1), 145–158. (<a
href="https://doi.org/10.1109/TMC.2021.3075816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G and beyond wireless networks are the upcoming evolution for the current cellular networks to provide the essential requirement of future demands such as high data rate, low energy consumption, and low latency to provide seamless communication for the emerging applications. Heterogeneous cloud radio access network (H-CRAN) is envisioned as a new trend of 5G that uses the advantages of heterogeneous and cloud radio access networks to enhance both spectral and energy efficiency. In this paper, building on the notion of effective capacity (EC), we propose a framework in orthogonal frequency division multiple access (OFDMA)- non-orthogonal multiple access (NOMA) based H-CRAN to meet these demands simultaneously. Our proposed approach is to maximize the effective energy efficiency (EEE) while considering spectrum and power cooperation between a macro base station (MBS) and radio remote heads (RRHs). To solve the formulated problem and to make it more tractable, we transform the original problem into an equivalent subtractive form via Dinkelbach algorithm. Afterward, the combinational framework of distributed stable matching and successive convex algorithm (SCA) is then adopted to obtain the solution of the equivalent problem. Hereby, we propose an efficient resource allocation scheme to maximize energy efficiency while maintaining the delay quality of service (QoS) requirements for all users. The simulation results show that the proposed algorithm can provide a non-trivial trade-off between delay and energy efficiency in OFDMA-NOMA based H-CRAN systems in terms of EC and EEE and the spectrum and power cooperation improves EEE of the proposed network. Moreover, our proposed solution complexity is much lower than the optimal solution and it suffers a very limited gap compared to the optimal method.},
  archive      = {J_TMC},
  author       = {Nazanin Moosavi and Mahnaz Sinaie and Paeiz Azmi and Pin-Hsun Lin and Eduard Jorswieck},
  doi          = {10.1109/TMC.2021.3075816},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {145-158},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cross layer resource allocation in H-CRAN with spectrum and energy cooperation},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collusion-resistant worker recruitment in crowdsourcing
systems. <em>TMC</em>, <em>22</em>(1), 129–144. (<a
href="https://doi.org/10.1109/TMC.2021.3071093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the wake of the Web 2.0, crowdsourcing has emerged as a promising approach to maintain a flexible workforce for human intelligence tasks. To stimulate worker participation, many reverse auction-based incentive mechanisms have been proposed. Designing auctions that discourage workers from cheating and instead encouraging them to reveal their true cost information has drawn significant attention. However, the existing efforts have been focusing on tackling individual cheating misbehaviors, while the scenarios that workers strategically form collusion coalitions and rig their bids together to manipulate auction outcomes have received little attention. To fill this gap, in this work we develop a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(t,p)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -collusion resistant scheme that ensures no coalition of weighted cardinality &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$t$&lt;/tex-math&gt;&lt;/inline-formula&gt; can improve its group utility by coordinating the bids at a probability of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$p$&lt;/tex-math&gt;&lt;/inline-formula&gt; . This paper takes into account the unique features of crowdsourcing, such as diverse worker types and reputations, in the design. The proposed scheme can suppress a broad spectrum of collusion strategies. Besides, desirable properties, including &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$p$&lt;/tex-math&gt;&lt;/inline-formula&gt; -truthfulness and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$p$&lt;/tex-math&gt;&lt;/inline-formula&gt; -individual rationality, are also achieved. To provide a comprehensive evaluation, we first analytically prove our scheme&#39;s collusion resistance and then experimentally verify our analytical conclusion using a real-world dataset. Our experimental results show that the baseline scheme, where none of the critical properties is guaranteed, costs up to 20.1 times the optimal payment in an ideal case where no collusion exists, while our final scheme is merely 4.9 times the optimal payment.},
  archive      = {J_TMC},
  author       = {Mingyan Xiao and Wenqiang Jin and Ming Li and Lei Yang and Arun Thapa and Pan Li},
  doi          = {10.1109/TMC.2021.3071093},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {129-144},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collusion-resistant worker recruitment in crowdsourcing systems},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BLS-location: A wireless fingerprint localization algorithm
based on broad learning. <em>TMC</em>, <em>22</em>(1), 115–128. (<a
href="https://doi.org/10.1109/TMC.2021.3073005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth in the demand for location-based services in indoor environments, wireless fingerprint localization has attracted increasing attention because of its high precision and easy implementation. However, an effective method does not exist owing to the problems of data loss, noise interference in the fingerprint database, and being time-consuming during the offline training phase. Therefore, this paper presents a novel indoor wireless fingerprint localization algorithm, termed BLS-Location, based on a broad learning system (BLS) that utilizes channel state information (CSI) to overcome the aforementioned problems. It includes an offline training phase and an online localization phase. In the offline training phase, the Kalman filter and the expectation-maximization (EM) algorithm are utilized for completing and denoising the data. Moreover, principal component analysis (PCA) is used to reconstruct the CSI data to reduce complexity and train the weights by BLS. In the online localization phase, we employ a novel probabilistic method based on the regression results of BLS to obtain the estimated location. The experimental results show that BLS-Location can significantly reduce the training time with a high accuracy, compared to several machine learning algorithms and four existing methods in two representative indoor environments.},
  archive      = {J_TMC},
  author       = {Xiaoqiang Zhu and Tie Qiu and Wenyu Qu and Xiaobo Zhou and Mohammed Atiquzzaman and Dapeng Oliver Wu},
  doi          = {10.1109/TMC.2021.3073005},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {115-128},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BLS-location: A wireless fingerprint localization algorithm based on broad learning},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Blockchain-based secure key management for mobile edge
computing. <em>TMC</em>, <em>22</em>(1), 100–114. (<a
href="https://doi.org/10.1109/TMC.2021.3068717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) is a promising edge technology to provide high bandwidth and low latency shared services and resources to mobile users. However, the MEC infrastructure raises major security concerns when the shared resources involve sensitive and private data of users. This paper proposes a novel blockchain-based key management scheme for MEC that is essential for ensuring secure group communication among the mobile devices as they dynamically move from one subnetwork to another. In the proposed scheme, when a mobile device joins a subnetwork, it first generates lightweight key pairs for digital signature and communication, and broadcasts its public key to neighbouring peer users in the subnetwork blockchain. The blockchain miner in the subnetwork packs all the public key of mobile devices into a block that will be sent to other users in the subnetwork. This enables the mobile device to communicate with its peers in the subnetwork by encrypting the data with the public key stored in the blockchain. When the mobile device moves to another subnetwork in the tree network, all the mobile devices of the new subnetwork can quickly verify its identity by checking its record in the local or higher hierarchy subnetwork blockchain. Furthermore, when the mobile device leaves the subnetwork, it does not need to do anything and its records will remain in the blockchain which is an append-only database. Theoretical security analysis shows that the proposed scheme can defend against the 51 percent attack and malicious entities in the blockchain network utilizing Proof-of-Work consensus mechanism. Moreover, the backward and forward secrecy is also preserved. Experimental results demonstrate that the proposed scheme outperforms two baselines in terms of computation, communication and storage.},
  archive      = {J_TMC},
  author       = {Jiaxing Li and Jigang Wu and Long Chen and Jin Li and Siew-Kei Lam},
  doi          = {10.1109/TMC.2021.3068717},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {100-114},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Blockchain-based secure key management for mobile edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BlockAIM: A neural network-based intelligent middleware for
large-scale IoT data placement decisions. <em>TMC</em>, <em>22</em>(1),
84–99. (<a href="https://doi.org/10.1109/TMC.2021.3071576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current Internet of Things (IoT) infrastructures rely on cloud storage however, relying on a single cloud provider puts limitations on the IoT applications and Service Level Agreement (SLA) requirements. Recently, multiple decentralized storage solutions (e.g., based on blockchains) have entered the market with distinct architecture, Quality of Service (QoS) parameters and at lower price compared to the cloud storage. In this work, we introduce BAM: a neural network-based middleware designed for intelligent selection of storage technology for IoT applications. We first propose a blockchain-based data placement protocol and theoretically model a decision optimization problem, which jointly considers cloud, multi-cloud and decentralized storage technologies to select the appropriate medium to store large-scale IoT data, while ensuring data integrity, traceability, auditability and decision verifiability. We then propose a neural network-based maintenance reconfiguration, which aims to optimize the computational complexity of the middleware design along with the blockchain transaction and storage overhead by learning and predicting the applications parameters. We also propose the aggregation rate feedback functionality in our design and model it as a linear optimization problem to improve data quality and precision. Finally, we provide a reference implementation and perform extensive experiments, which demonstrate the effectiveness of the proposed design.},
  archive      = {J_TMC},
  author       = {Syed Muhammad Danish and Kaiwen Zhang and Hans-Arno Jacobsen},
  doi          = {10.1109/TMC.2021.3071576},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {84-99},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BlockAIM: A neural network-based intelligent middleware for large-scale IoT data placement decisions},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AirSync: Time synchronization for large-scale IoT networks
using aircraft signals. <em>TMC</em>, <em>22</em>(1), 69–83. (<a
href="https://doi.org/10.1109/TMC.2021.3070644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prosperity of Internet of Things (IoT) brings forth the deployment of large-scale sensing systems such as smart cities. To enable the collaboration tasks among distributed devices, time synchronization is crucial. However, due to the long-range and device heterogeneity, accurate time synchronization for a large-scale IoT network is challenging. Existing GPS or NTP solutions either require an outdoor environment or only have low and unstable accuracy. In this paper, we propose AirSync, a novel synchronization method that leverages the widely existed aircraft signals, ADS-B, to synchronize large-scale IoT networks with nodes even in indoor environments. But ADS-B messages have no time stamp and cannot provide a reference time. We leverage the continuity of aircraft movements to estimate the aircraft traveling time. Then devices that observe common aircraft moving segments can calculate their time offset. To obtain the time skew, we propose a combined aircraft linear regression method. We also design a transitive synchronization for devices that cannot observe common aircraft. Besides, we also design a duty-cycled ADS-B message collection method for resource-limited IoT devices. We implement a prototype of AirSync and evaluate its performance in various real-world environments. The results show that AirSync can obtain the sub-ms accuracy.},
  archive      = {J_TMC},
  author       = {Shaopeng Zhu and Xiaolong Zheng and Liang Liu and Huadong Ma},
  doi          = {10.1109/TMC.2021.3070644},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {69-83},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AirSync: Time synchronization for large-scale IoT networks using aircraft signals},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Age optimal information gathering and dissemination on
graphs. <em>TMC</em>, <em>22</em>(1), 54–68. (<a
href="https://doi.org/10.1109/TMC.2021.3076755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of timely exchange of updates between a central station and a set of ground terminals &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$V$&lt;/tex-math&gt;&lt;/inline-formula&gt; , via a mobile agent that traverses across the ground terminals along a mobility graph &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$G = (V, E)$&lt;/tex-math&gt;&lt;/inline-formula&gt; . We design the trajectory of the mobile agent to minimize average-peak and average age of information (AoI), two recently proposed metrics for measuring timeliness of information. We consider randomized trajectories, in which the mobile agent travels from terminal &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$i$&lt;/tex-math&gt;&lt;/inline-formula&gt; to terminal &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$j$&lt;/tex-math&gt;&lt;/inline-formula&gt; with probability &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$P_{i,j}$&lt;/tex-math&gt;&lt;/inline-formula&gt; . For the information gathering problem, we show that a randomized trajectory is average-peak age optimal and factor- &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$8\mathcal {H}$&lt;/tex-math&gt;&lt;/inline-formula&gt; average age optimal, where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {H}$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the mixing time of the randomized trajectory on the mobility graph &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$G$&lt;/tex-math&gt;&lt;/inline-formula&gt; . We also show that the average age minimization problem is NP-hard. For the information dissemination problem, we prove that the same randomized trajectory is factor- &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$O(\mathcal {H})$&lt;/tex-math&gt;&lt;/inline-formula&gt; average-peak and average age optimal. Moreover, we propose an age-based trajectory, which utilizes information about current age at terminals, and show that it is factor-2 average age optimal in a symmetric setting.},
  archive      = {J_TMC},
  author       = {Vishrant Tripathi and Rajat Talak and Eytan Modiano},
  doi          = {10.1109/TMC.2021.3076755},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {54-68},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Age optimal information gathering and dissemination on graphs},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive batch size for federated learning in
resource-constrained edge computing. <em>TMC</em>, <em>22</em>(1),
37–53. (<a href="https://doi.org/10.1109/TMC.2021.3075291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging Federated Learning (FL) enables IoT devices to collaboratively learn a shared model based on their local datasets. However, due to end devices’ heterogeneity, it will magnify the inherent synchronization barrier issue of FL and result in non-negligible waiting time when local models are trained with the identical batch size. Moreover, the useless waiting time will further lead to a great strain on devices’ limited battery life. Herein, we aim to alleviate the negative impact of synchronization barrier through adaptive batch size during model training. When using different batch sizes, stability and convergence of the global model should be enforced by assigning appropriate learning rates on different devices. Therefore, we first study the relationship between batch size and learning rate, and formulate a scaling rule to guide the setting of learning rate in terms of batch size. Then we theoretically analyze the convergence rate of global model and obtain a convergence upper bound. On these bases, we propose an efficient algorithm that adaptively adjusts batch size with scaled learning rate for heterogeneous devices to reduce the waiting time and save battery life. We conduct extensive simulations and testbed experiments, and the experimental results demonstrate the effectiveness of our method.},
  archive      = {J_TMC},
  author       = {Zhenguo Ma and Yang Xu and Hongli Xu and Zeyu Meng and Liusheng Huang and Yinxing Xue},
  doi          = {10.1109/TMC.2021.3075291},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {37-53},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive batch size for federated learning in resource-constrained edge computing},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A framework for behavioral biometric authentication using
deep metric learning on mobile devices. <em>TMC</em>, <em>22</em>(1),
19–36. (<a href="https://doi.org/10.1109/TMC.2021.3072608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile authentication using behavioral biometrics has been an active area of research. Existing research relies on building machine learning classifiers to recognize an individual’s unique patterns. However, these classifiers are not powerful enough to learn the discriminative features. When implemented on the mobile devices, they face new challenges from the behavioral dynamics, data privacy and side-channel leaks. To address these challenges, we present a new framework to incorporate training on battery-powered mobile devices, so private data never leaves the device and training can be flexibly scheduled to adapt the behavioral patterns at runtime. We re-formulate the classification problem into deep metric learning to improve the discriminative power and design an effective countermeasure to thwart side-channel leaks by embedding a noise signature in the sensing signals without sacrificing too much usability. The experiments demonstrate authentication accuracy over 95 percent on three public datasets, a sheer 15 percent gain from multi-class classification with less data and robustness against brute-force and side-channel attacks with 99 and 90 percent success, respectively. We show the feasibility of training with mobile CPUs, where training 100 epochs takes less than 10 mins and can be boosted 3-5 times with feature transfer. Finally, we profile memory, energy and computational overhead. Our results indicate that training consumes lower energy than watching videos and slightly higher energy than playing games.},
  archive      = {J_TMC},
  author       = {Cong Wang and Yanru Xiao and Xing Gao and Li Li and Jun Wang},
  doi          = {10.1109/TMC.2021.3072608},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {19-36},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A framework for behavioral biometric authentication using deep metric learning on mobile devices},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cooperative defense framework against application-level
DDoS attacks on mobile edge computing services. <em>TMC</em>,
<em>22</em>(1), 1–18. (<a
href="https://doi.org/10.1109/TMC.2021.3086219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC), extending computing services from cloud to edge, is recognized as one of key pillars to facilitate real-time services and tackle backhaul bottleneck. However, it is not economically efficient to attach intensive security appliances to every MEC node to defend application-level DDoS attacks and ensure the availability of services. Thus, we explore the elasticity of security defense among MEC nodes by proposing a COoperative DEfense ( CODE ) framework for MEC, referred to as CODE4MEC . CODE4MEC aims to adapt to traffic changes by coordinating container-carried defensive resources among cooperative MEC nodes in an automatic way. Towards this aim, we propose four control plane functions to enable a life-cycle management for CODE4MEC, namely, CODE triggering, scheduling, coordination and releasing. However, an effective CODE4MEC requires non-trivial algorithmic schemes, in particular for CODE scheduling and coordination functions. We thus design an online combinatorial auction mechanism for real-time CODE scheduling, and prove a tighter performance bound relative to prior arts. As for CODE coordination, a flow-based traffic and context information coordination scheme is proposed to enable classical defense schemes to work properly and efficiently. Finally, using a combination of real testbed and simulation evaluations, we validate the effectiveness of CODE4MEC.},
  archive      = {J_TMC},
  author       = {Hongjia Li and Chang Yang and Liming Wang and Nirwan Ansari and Ding Tang and Xueqing Huang and Zhen Xu and Dan Hu},
  doi          = {10.1109/TMC.2021.3086219},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A cooperative defense framework against application-level DDoS attacks on mobile edge computing services},
  volume       = {22},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
