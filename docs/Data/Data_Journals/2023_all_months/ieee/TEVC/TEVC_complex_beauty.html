<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TEVC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tevc---138">TEVC - 138</h2>
<ul>
<li><details>
<summary>
(2023). History-guided hill exploration for evolutionary
computation. <em>TEVC</em>, <em>27</em>(6), 1962–1975. (<a
href="https://doi.org/10.1109/TEVC.2023.3250347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although evolutionary computing (EC) methods are stochastic optimization methods, it is usually difficult to find the global optimum by restarting the methods when the population converges to a local optimum. A major reason is that many optimization problems have basins of attraction (BoAs) that differ widely in shape and size, and the population always prefers to converge toward BoAs that are easy to search. Although heuristic restart based on tabu search is a theoretically feasible idea to solve this problem, existing EC methods with heuristic restart are difficult to avoid repetitive search results while maintaining search efficiency. This article tries to overcome the dilemma by online learning the BoAs and proposes a search mode called history-guided hill exploration (HGHE). In the search mode, evaluated solutions are used to help separate the search space into hill regions which correspond to the BoAs, and a classical EC method is used to locate the optimum in each hill region. An instance algorithm for continuous optimization named HGHE differential evolution (HGHE-DE) is proposed to verify the effectiveness of HGHE. Experimental results prove that HGHE-DE can continuously discover unidentified BoAs and locate optima in identified BoAs.},
  archive      = {J_TEVC},
  author       = {Junchen Wang and Changhe Li and Sanyou Zeng and Shengxiang Yang},
  doi          = {10.1109/TEVC.2023.3250347},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1962-1975},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {History-guided hill exploration for evolutionary computation},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on learnable evolutionary algorithms for scalable
multiobjective optimization. <em>TEVC</em>, <em>27</em>(6), 1941–1961.
(<a href="https://doi.org/10.1109/TEVC.2023.3250350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent decades have witnessed great advancements in multiobjective evolutionary algorithms (MOEAs) for multiobjective optimization problems (MOPs). However, these progressively improved MOEAs have not necessarily been equipped with scalable and learnable problem-solving strategies for new and grand challenges brought by the scaling-up MOPs with continuously increasing complexity from diverse aspects, mainly, including expensive cost of function evaluations, many objectives, large-scale search space, time-varying environments, and multitask. Under different scenarios, divergent thinking is required in designing new powerful MOEAs for solving them effectively. In this context, research studies on learnable MOEAs with machine learning techniques have received extensive attention in the field of evolutionary computation. This article begins with a general taxonomy of scaling-up MOPs and learnable MOEAs, followed by an analysis of the challenges that these MOPs pose to traditional MOEAs. Then, we synthetically overview recent advances of learnable MOEAs in solving various scaling-up MOPs, focusing primarily on four attractive directions (i.e., learnable evolutionary discriminators for environmental selection, learnable evolutionary generators for reproduction, learnable evolutionary evaluators for function evaluations, and learnable evolutionary transfer modules for sharing or reusing optimization experience). The insight of learnable MOEAs is offered to readers as a reference to the general track of the efforts in this field.},
  archive      = {J_TEVC},
  author       = {Songbai Liu and Qiuzhen Lin and Jianqiang Li and Kay Chen Tan},
  doi          = {10.1109/TEVC.2023.3250350},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1941-1961},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey on learnable evolutionary algorithms for scalable multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Obfuscating community structure in complex network with
evolutionary divide-and-conquer strategy. <em>TEVC</em>, <em>27</em>(6),
1926–1940. (<a href="https://doi.org/10.1109/TEVC.2023.3242051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the number of social network users grows exponentially with increasingly complex profiles, community detection algorithms play a critical role in user portrait analysis. The associated privacy concerns, however, have not sufficiently received the attention that it deserves. In this work, we investigate methods for obfuscating the original community structure by modifying a small number of connections imperceptibly so as to protect the privacy of users. The existing evolutionary models have some successes in this type of NP-hard problem but can only be applied to small-scale datasets, rendering them inadequate for real-world applications. To alleviate this problem, we propose an original and novel CoeCo, a cooperative evolutionary community obfuscation model. In CoeCo, we leverage the divide-and-conquer strategy and put forward a co-evolutionary optimization algorithm suitable for community structure, in which two different fitness functions promote each other to find the optimal edge set. In addition, the motif hypergraph and permanence are used to improve population initialization. The experimental results indicate that our proposed method can achieve excellent efficacy in obfuscating community structure and also greatly reduces running time.},
  archive      = {J_TEVC},
  author       = {Jie Zhao and Kang Hao Cheong},
  doi          = {10.1109/TEVC.2023.3242051},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1926-1940},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Obfuscating community structure in complex network with evolutionary divide-and-conquer strategy},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiobjective differential evolution algorithm balancing
multiple stakeholders for low-carbon order scheduling in e-waste
recycling. <em>TEVC</em>, <em>27</em>(6), 1912–1925. (<a
href="https://doi.org/10.1109/TEVC.2023.3237336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Order scheduling is an important part of the e-waste recycling process, which can influence the quantity and efficiency of the recycling. With the sustainable development of e-waste recycling, low-carbon order scheduling becomes a significant and challenging reverse logistics scheduling problem. However, it is difficult to obtain an effective low-carbon order schedule considering the conflicting interests of the multiple stakeholders, including enterprises, drivers, customers, and governments. To address this issue, a multiobjective order scheduling model (MOOSM) and a multiobjective differential evolution algorithm balancing multiple stakeholders (MODE-MS) are proposed in this article. First, to embody the interests of different stakeholders, three time-dependent key variables are calculated by the road congestion and vehicle load, including the velocity, traveling time, and carbon emission. Second, with the above key variables, a five-objective order scheduling model is formulated to describe the low-carbon order scheduling problem in e-waste recycling. Third, for solving the MOOSM, a multiobjective differential evolution algorithm based on an adaptive evolutionary search strategy is developed to obtain the low-carbon and stakeholders satisfied scheduling schemes. The experimental results validate the feasibility of MOOSM and the effectiveness of MODE-MS. By comparing with four state-of-the-art algorithms, the advantages of the proposed MODE-MS are further demonstrated in solving the low-carbon order scheduling.},
  archive      = {J_TEVC},
  author       = {Ying Hou and Yilin Wu and Honggui Han},
  doi          = {10.1109/TEVC.2023.3237336},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1912-1925},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective differential evolution algorithm balancing multiple stakeholders for low-carbon order scheduling in E-waste recycling},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SFE: A simple, fast, and efficient feature selection
algorithm for high-dimensional data. <em>TEVC</em>, <em>27</em>(6),
1896–1911. (<a href="https://doi.org/10.1109/TEVC.2023.3238420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a new feature selection (FS) algorithm, called simple, fast, and efficient (SFE), is proposed for high-dimensional datasets. The SFE algorithm performs its search process using a search agent and two operators: 1) nonselection and 2) selection. It comprises two phases: 1) exploration and 2) exploitation. In the exploration phase, the nonselection operator performs a global search in the entire problem search space for the irrelevant, redundant, trivial, and noisy features and changes the status of the features from selected mode to nonselected mode. In the exploitation phase, the selection operator searches the problem search space for the features with a high impact on the classification results and changes the status of the features from nonselected mode to selected mode. The proposed SFE is successful in FS from high-dimensional datasets. However, after reducing the dimensionality of a dataset, its performance cannot be increased significantly. In these situations, an evolutionary computational method could be used to find a more efficient subset of features in the new and reduced search space. To overcome this issue, this article proposes a hybrid algorithm, SFE-PSO (particle swarm optimization) to find an optimal feature subset. The efficiency and effectiveness of the SFE and the SFE-PSO for FS are compared on 40 high-dimensional datasets. Their performances were compared with six recently proposed FS algorithms. The results obtained indicate that the two proposed algorithms significantly outperform the other algorithms and can be used as efficient and effective algorithms in selecting features from high-dimensional datasets.},
  archive      = {J_TEVC},
  author       = {Behrouz Ahadzadeh and Moloud Abdar and Fatemeh Safara and Abbas Khosravi and Mohammad Bagher Menhaj and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1109/TEVC.2023.3238420},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1896-1911},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {SFE: A simple, fast, and efficient feature selection algorithm for high-dimensional data},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interaction-based prediction for dynamic multiobjective
optimization. <em>TEVC</em>, <em>27</em>(6), 1881–1895. (<a
href="https://doi.org/10.1109/TEVC.2023.3234113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization poses great challenges to evolutionary algorithms due to the change of optimal solutions or Pareto front with time. Learning-based methods are popular to extract the changing pattern of optimal solutions for predicting new solutions. They tend to use all variables as features (i.e., inputs) to build prediction models. However, there are usually some irrelevant and redundant variables, which increase training difficulty and decrease prediction accuracy. This article proposes a new interaction-based prediction (IP) method, which captures the correlation of variables with prediction targets and selects the most relevant variables to build prediction models using neural networks. In particular, the interaction between variables is detected to remove redundant variables. In addition, a correction procedure is developed to further improve predicted solutions according to the prediction error in past environments. The predicted solutions are used to update the population according to a specifically designed update strategy. Integrating the IP method into the framework of multiobjective evolutionary algorithm based on decomposition (MOEA/D), a new algorithm named IP-DMOEA is put forward. Experimental results on a typical dynamic multiobjective test suite demonstrate the better performance of the proposed IP-DMOEA than state-of-the-art algorithms in terms of convergence speed and solution quality. The proposed IP-DMOEA is also successfully applied to the multirobot task scheduling problem.},
  archive      = {J_TEVC},
  author       = {Xiao-Fang Liu and Xin-Xin Xu and Zhi-Hui Zhan and Yongchun Fang and Jun Zhang},
  doi          = {10.1109/TEVC.2023.3234113},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1881-1895},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Interaction-based prediction for dynamic multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive ant colony optimization with node clustering for
the multidepot vehicle routing problem. <em>TEVC</em>, <em>27</em>(6),
1866–1880. (<a href="https://doi.org/10.1109/TEVC.2022.3230042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article deals with the novel metaheuristic algorithm based on the ant colony optimization (ACO) principle. It implements several novel mechanisms that improve its overall performance, lower the optimization time, and reduce the negative behavior which is typically connected with ACO-based algorithms (such as prematurely falling into local optima, or the impact of setting of control parameters on the convergence for different problem configurations). The most significant novel techniques, implemented for the first time to solve the multidepot vehicle routing problem (MDVRP), are as follows: 1) node clustering where transition vertices are organized into a set of candidate lists called clusters and 2) adaptive pheromone evaporation which is adapted during optimization according to the diversity of the population of ant solutions (measured by information entropy). Moreover, a new termination condition, based also on the population diversity, is formulated. The effectiveness of the proposed algorithm for the MDVRP is evaluated via a set of experiments on 23 well-known benchmark instances. Performance is compared with several state-of-the-art metaheuristic methods; the results show that the proposed algorithm outperforms these methods in most cases. Furthermore, the novel mechanisms are analyzed and discussed from points of view of performance, optimization time, and convergence. The findings achieved in this article bring new contributions to the very popular ACO-based algorithms; they can be applied to solve not only the MDVRP, but also, if adapted, to related complex NP-hard problems.},
  archive      = {J_TEVC},
  author       = {Petr Stodola and Jan Nohel},
  doi          = {10.1109/TEVC.2022.3230042},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1866-1880},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Adaptive ant colony optimization with node clustering for the multidepot vehicle routing problem},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain generalization-based dynamic multiobjective
optimization: A case study on disassembly line balancing. <em>TEVC</em>,
<em>27</em>(6), 1851–1865. (<a
href="https://doi.org/10.1109/TEVC.2022.3233642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of disassembly lines is to disassemble end-of-life products in a remanufacturing field. The disassembly line balancing problem (DLBP) considers how to allocate disassembly operations to operators on the disassembly line to optimize predetermined goals, such as cycle time. In practice, various environmental uncertainties (e.g., uncertain product quality) exist in the disassembly line. These uncertainties entail DLBP essentially a dynamic multiobjective optimization problem (DMOP). This study presents a dynamic DLBP (D-DLB) to model the effect of environmental uncertainties on the assignment of disassembly operations. Furthermore, a prediction-based dynamic optimization algorithm, termed domain generalization-based dynamic multiobjective evolutionary algorithm (DG-DMOEA), combining meta-learning with multiobjective optimization, is proposed to solve D-DLB. In DG-DMOEA, a meta-learning algorithm is employed to learn the parameters of a solution-generative model from the Pareto-optimal sets (POSs) in all historical environments. Subsequently, the solution-generative model is applied to generate a high-quality initial population that can assist multiobjective optimization algorithms in finding the POS in the new environment faster. Since no information in the new environment is required, learning can begin before the new environment arrives, significantly reducing computational time. Moreover, different solution-generative models can be designed for different DMOPs. Therefore, DG-DMOEA can thoroughly combine real-world problem properties to represent knowledge. The experimental results show that, compared with state-of-the-art methods, DG-DMOEA can considerably improve the quality of solutions and significantly enhance the ability to react quickly to environmental changes.},
  archive      = {J_TEVC},
  author       = {Yilin Fang and Fubo Liu and Miqing Li and Hao Cui},
  doi          = {10.1109/TEVC.2022.3233642},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1851-1865},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Domain generalization-based dynamic multiobjective optimization: A case study on disassembly line balancing},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bilevel optimization via collaborations among lower-level
optimization tasks. <em>TEVC</em>, <em>27</em>(6), 1837–1850. (<a
href="https://doi.org/10.1109/TEVC.2022.3233409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilevel metaheuristics have been widely used for bilevel optimization. However, recent studies have indicated that most bilevel metaheuristics are inefficient since they perform the lower-level optimization task for each upper-level solution independently and neglect the relationship among lower-level optimization tasks. In this article, we develop a bilevel metaheuristic with the collaborations among lower-level optimization tasks. Specifically, a population is evolved to solve the lower-level optimization tasks for all upper-level solutions collaboratively at each generation. In the population, each solution is associated with a lower-level optimization task. In such a way, all lower-level optimization tasks can be solved in a single run. To capture the individual features of different lower-level optimization tasks, we construct a lower-level search distribution for each lower-level optimization task based on all solutions in the population. In addition, an information-sharing mechanism is proposed to share good solutions among lower-level optimization tasks. Experiments on two sets of test problems and three practical applications demonstrate that our proposed algorithm performs better than other bilevel metaheuristics in comparison.},
  archive      = {J_TEVC},
  author       = {Pei-Qiu Huang and Qingfu Zhang and Yong Wang},
  doi          = {10.1109/TEVC.2022.3233409},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1837-1850},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Bilevel optimization via collaborations among lower-level optimization tasks},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An expensive many-objective optimization algorithm based on
efficient expected hypervolume improvement. <em>TEVC</em>,
<em>27</em>(6), 1822–1836. (<a
href="https://doi.org/10.1109/TEVC.2022.3228516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected hypervolume improvement (EHVI) is one of the most popular infill criteria for multiobjective optimization problems. Although it has a significant advantage in exploring potential Pareto-optimal solutions, it has rarely been applied in many-objective problems due to its high computational cost. To address this issue, this article proposes an expensive many-objective optimization algorithm based on the framework of nondominated sorting genetic algorithm III (NSGA-III) and assisted by the kriging surrogate models. In the proposed algorithm, the Monte Carlo sampling (MCS) method for EHVI estimation is improved by importance sampling, in which only one sampling process is required during the entire optimization process using a uniform distribution in normalized objective space. Considering the predicted uncertainty from the kriging model, an uncertainty-assisted nondominated sorting approach is proposed to substitute for the conventional approach in NSGA-III. In the proposed method, the predicted uncertainty is incorporated into the objective space as one independent dimension for nondominated sorting, which can enable the exploration of potential points with desirable EHVI values. In addition, the proposed algorithm considers the diversity of the solutions by de-emphasizing the pursuit of the best EHVI. The experimental results on benchmark problems demonstrate that the proposed EHVI calculation method can save computational costs compared with MCS and indicate the superiority of the proposed algorithm over the others.},
  archive      = {J_TEVC},
  author       = {Yong Pang and Yitang Wang and Shuai Zhang and Xiaonan Lai and Wei Sun and Xueguan Song},
  doi          = {10.1109/TEVC.2022.3228516},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1822-1836},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An expensive many-objective optimization algorithm based on efficient expected hypervolume improvement},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary minimization of traffic congestion.
<em>TEVC</em>, <em>27</em>(6), 1809–1821. (<a
href="https://doi.org/10.1109/TEVC.2022.3228750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion is a major issue that can be solved by suggesting drivers alternative routes they are willing to take. This concept has been formalized as a strategic routing problem in which a single alternative route is suggested to an existing one. We extend this formalization and introduce the multiple-routes (MRs) problem, which is given a start and destination and aims at finding up to $n$ different routes that the drivers strategically disperse over, minimizing the overall travel time of the system. Due to the NP -hard nature of the problem, we introduce the MRs evolutionary algorithm (MREA) as a heuristic solver. We study several mutation and crossover operators and evaluate them on real-world data of Berlin, Germany. We find that a combination of all operators yields the best result, reducing the overall travel time by a factor between 1.8 and 3, in the median, compared to all drivers taking the fastest route. 6mm]Please cite reference [2] in the text of the paper. It was removed from the abstract as having reference in an abstract is contrary to IEEE journal style.For the base case $n=2$ , we compare our MREA to the highly tailored optimal solver by Bläsius et al. (2020), and show that, in the median, our approach finds solutions of quality at least 99.69\% of an optimal solution while only requiring 40\% of the time.},
  archive      = {J_TEVC},
  author       = {Maximilian Böther and Leon Schiller and Philipp Fischbeck and Louise Molitor and Martin S. Krejca and Tobias Friedrich},
  doi          = {10.1109/TEVC.2022.3228750},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1809-1821},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary minimization of traffic congestion},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-aided evolution for optimization. <em>TEVC</em>,
<em>27</em>(6), 1794–1808. (<a
href="https://doi.org/10.1109/TEVC.2022.3232776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning and optimization are the two essential abilities of human beings for problem solving. Similarly, computer scientists have made great efforts to design artificial neural network (ANN) and evolutionary computation (EC) to simulate the learning ability and the optimization ability for solving real-world problems, respectively. These have been two essential branches in artificial intelligence (AI) and computer science. However, in humans, learning and optimization are usually integrated together for problem solving. Therefore, how to efficiently integrate these two abilities together to develop powerful AI remains a significant but challenging issue. Motivated by this, this article proposes a novel learning-aided evolutionary optimization (LEO) framework that plus learning and evolution for solving optimization problems. The LEO is integrated with the evolution knowledge learned by ANN from the evolution process of EC to promote optimization efficiency. The LEO framework is applied to both classical EC algorithms and some state-of-the-art EC algorithms including a champion algorithm, with benchmarking against the IEEE Congress on EC competition data. The experimental results show that the LEO can significantly enhance the existing EC algorithms to better solve both single-objective and multi-/many-objective global optimization problems, suggesting that learning plus evolution is more intelligent for problem solving. Moreover, the experimental results have also validated the time efficiency of the LEO, where the additional time cost for using LEO is greatly deserved. Therefore, the promising LEO can lead to a new and more efficient paradigm for EC algorithms to solve global optimization problems by plus learning and evolution.},
  archive      = {J_TEVC},
  author       = {Zhi-Hui Zhan and Jian-Yu Li and Sam Kwong and Jun Zhang},
  doi          = {10.1109/TEVC.2022.3232776},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1794-1808},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning-aided evolution for optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interindividual correlation and dimension-based dual
learning for dynamic multiobjective optimization. <em>TEVC</em>,
<em>27</em>(6), 1780–1793. (<a
href="https://doi.org/10.1109/TEVC.2023.3235196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) are characterized by their multiple objectives, constraints, and parameters that may change over time. The challenge in solving DMOPs is how to track the varying Pareto-optimal solution sets quickly and accurately. Therefore, an interindividual correlation and dimension-based dual-learning method is proposed in this article. Two learning strategies, decomposition-based interindividual correlation transfer learning (DICTL) and dimension-wise learning (DL), are developed to, respectively, generate one-half of the initial population in the new environment. More specifically, DICTL learns the interindividual correlation from the final population of the adjacent environment and then transfers it to the new environment, aiming to maintain the diversity and distribution of the predicted population. While DL extracts the changing pattern of dynamic environments from the high-quality solutions of historical environments in the perspective of variable dimension, trying to improve the quality of the population and accelerate the convergence. The designed two learning strategies (DICTL&amp;DL) work complementarily and collaboratively to make the algorithm adapt to dynamic environments better and faster. Comprehensive experiments have been conducted by comparing the proposed method with four state-of-the-art algorithms on 14 benchmark problems. The results demonstrate the superiority of the proposed method.},
  archive      = {J_TEVC},
  author       = {Li Yan and Wenlong Qi and Jing Liang and Boyang Qu and Kunjie Yu and Caitong Yue and Xuzhao Chai},
  doi          = {10.1109/TEVC.2023.3235196},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1780-1793},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Interindividual correlation and dimension-based dual learning for dynamic multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Surrogate-assisted differential evolution with adaptive
multisubspace search for large-scale expensive optimization.
<em>TEVC</em>, <em>27</em>(6), 1765–1779. (<a
href="https://doi.org/10.1109/TEVC.2022.3226837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world industrial engineering optimization problems often have a large number of decision variables. Most existing large-scale evolutionary algorithms (EAs) need a large number of function evaluations to achieve high-quality solutions. However, the function evaluations can be computationally intensive for many of these problems, particularly, which makes large-scale expensive optimization challenging. To address this challenge, surrogate-assisted EAs based on the divide-and-conquer strategy have been proposed and shown to be promising. Following this line of research, we propose a surrogate-assisted differential evolution algorithm with adaptive multisubspace search for large-scale expensive optimization to take full advantage of the population and the surrogate mechanism. The proposed algorithm constructs multisubspace based on principal component analysis and random decision variable selection, and searches adaptively in the constructed subspaces with three search strategies. The experimental results on a set of large-scale expensive test problems have demonstrated its superiority over three state-of-the-art algorithms on the optimization problems with up to 1000 decision variables.},
  archive      = {J_TEVC},
  author       = {Haoran Gu and Handing Wang and Yaochu Jin},
  doi          = {10.1109/TEVC.2022.3226837},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1765-1779},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Surrogate-assisted differential evolution with adaptive multisubspace search for large-scale expensive optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A knowledge guided transfer strategy for evolutionary
dynamic multiobjective optimization. <em>TEVC</em>, <em>27</em>(6),
1750–1764. (<a href="https://doi.org/10.1109/TEVC.2022.3222844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key task in dynamic multiobjective optimization problems (DMOPs) is to find Pareto-optima closer to the true one as soon as possible once a new environment occurs. Previous dynamic multiobjective evolutionary algorithms (DMOEAs) normally focus on DMOPs with regular environmental changes, but neglect widespread random one, limiting their applications in real-world fields. To address this issue, a knowledge guided transfer strategy (KTS)-based DMOEA is proposed in this article. First, knowledge described as a two-tuple is extracted under each historical environment and preserved to a knowledge pool. Redundant knowledge is recognized and adaptively removed so as to guarantee the diversity of the pool. Second, a knowledge matching strategy is developed to re-evaluate the representative of each stored knowledge under a new environment, with the purpose of finding the most valuable one to promote positive knowledge transfer. Third, an improved knowledge transfer mechanism based on subspace alignment is introduced. By integrating it with the knowledge reuse mechanism, a hybrid transfer strategy is constructed to adaptively select the most suitable one in terms of the similarity degree of selected knowledge on the current environment, and then generate a new initial population. Experiments on 20 benchmark problems demonstrate that the KTS outperforms five state-of-the-art algorithms, achieving good versatility in solving DMOPs with both regular and random changes.},
  archive      = {J_TEVC},
  author       = {Yinan Guo and Guoyu Chen and Min Jiang and Dunwei Gong and Jing Liang},
  doi          = {10.1109/TEVC.2022.3222844},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1750-1764},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A knowledge guided transfer strategy for evolutionary dynamic multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble multifactorial evolution with biased skill-factor
inheritance for many-task optimization. <em>TEVC</em>, <em>27</em>(6),
1735–1749. (<a href="https://doi.org/10.1109/TEVC.2022.3227120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current years have witnessed an increment in the number of research activities on improving the efficacy of multitasking algorithms for tackling challenging optimization problems. However, current approaches often present two potential problems. First, although tasks may have different characteristics, existing literature usually utilizes only one search operator for all of them. Second, while multitasking environments comprise tasks of varying difficulty, previous proposals treat them equally. This article proposes an algorithm named ensemble multifactorial evolution with biased skill-factor inheritance (EME-BI) for optimizing a large number of tasks simultaneously. In EME-BI, an effective parameter adaptation based on the knowledge transfer quality with biased skill-factor inheritance mechanism is designed to minimize negative transfer and allocate generated offspring to tasks that need resources. Besides, instead of using only one fixed search operator, EME-BI can automatically select the most appropriate one for each task at each evolutionary stage. Finally, the proposed algorithm is armed with a dynamically adjusted population size to promote exploitation. Empirical studies on various many-task benchmark problems and a real-world problem are conducted to verify the efficiency of EME-BI. The results portrayed that EME-BI achieves highly competitive performance compared to several state-of-the-art algorithms regarding the solution quality, convergence trend, and computation time. This proposal also won first prize at the CEC2021 Competition on Evolutionary Multitask Optimization, multitask single-objective optimization.},
  archive      = {J_TEVC},
  author       = {Binh Huynh Thi Thanh and Le Van Cuong and Ta Bao Thang and Nguyen Hoang Long},
  doi          = {10.1109/TEVC.2022.3227120},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1735-1749},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Ensemble multifactorial evolution with biased skill-factor inheritance for many-task optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A decomposition method for both additively and nonadditively
separable problems. <em>TEVC</em>, <em>27</em>(6), 1720–1734. (<a
href="https://doi.org/10.1109/TEVC.2022.3218375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem decomposition is crucial for coping with large-scale global optimization problems, which relies heavily on highly precise variable grouping methods. The state-of-the-art decomposition methods identify separability based on the finite differences principle, which is valid only for additively separable functions but not applicable to nonadditively separable functions. Therefore, we need to investigate separability in more depth in order to propose a more general principle and design more universal decomposition methods. In this article, we conduct a comprehensive theoretical investigation on separability, the core of which is proposing an innovative separability identification principle: the minimum points shift principle. By utilizing the new principle, we develop a general separability grouping (GSG) method that can handle both additively and nonadditively separable functions with high accuracy. In addition, we design a new set of benchmark functions based on nonadditive separability, which compensates for the lack of nonadditively separable functions in the previous test suites. Extensive experiments demonstrate that the proposed GSG achieves high grouping accuracy on both new and CEC series benchmark problems, especially on nonadditively separable problems Finally, we verify that the proposed GSG can effectively improve the optimization performance of nonadditively separable problems through optimization experiments.},
  archive      = {J_TEVC},
  author       = {Minyang Chen and Wei Du and Yang Tang and Yaochu Jin and Gary G. Yen},
  doi          = {10.1109/TEVC.2022.3218375},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1720-1734},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A decomposition method for both additively and nonadditively separable problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Task relatedness-based multitask genetic programming for
dynamic flexible job shop scheduling. <em>TEVC</em>, <em>27</em>(6),
1705–1719. (<a href="https://doi.org/10.1109/TEVC.2022.3199783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multitask learning has been successfully used in handling multiple related tasks simultaneously. In reality, there are often many tasks to be solved together, and the relatedness between them is unknown in advance. In this article, we focus on the multitask genetic programming (GP) for the dynamic flexible job shop scheduling (DFJSS) problems, and address two challenges. The first is how to measure the relatedness between tasks accurately. The second is how to select task pairs to transfer knowledge during the multitask learning process. To measure the relatedness between DFJSS tasks, we propose a new relatedness metric based on the behavior distributions of the variable-length GP individuals. In addition, for more effective knowledge transfer, we develop an adaptive strategy to choose the most suitable assisted task for the target task based on the relatedness information between tasks. The findings show that in all of the multitask scenarios studied, the proposed algorithm can substantially increase the effectiveness of the learned scheduling heuristics for all the desired tasks. The effectiveness of the proposed algorithm has also been verified by the analysis of task relatedness and structures of the evolved scheduling heuristics, and the discussions of population diversity and knowledge transfer.},
  archive      = {J_TEVC},
  author       = {Fangfang Zhang and Yi Mei and Su Nguyen and Kay Chen Tan and Mengjie Zhang},
  doi          = {10.1109/TEVC.2022.3199783},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1705-1719},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Task relatedness-based multitask genetic programming for dynamic flexible job shop scheduling},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved local search method for large-scale hypervolume
subset selection. <em>TEVC</em>, <em>27</em>(6), 1690–1704. (<a
href="https://doi.org/10.1109/TEVC.2022.3219081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypervolume subset selection (HSS) has received considerable attention in the field of evolutionary multiobjective optimization (EMO). It aims to select a representative subset from a candidate solution set so that the hypervolume (HV) of the selected subset is maximized. A number of HSS methods have been proposed in the literature, attempting to either reduce the computation time of subset selection or improve the subset quality (i.e., the HV of the selected subset). However, when selecting from a large candidate set (e.g., from hundreds of thousands of candidate solutions), most HSS methods fail to strike a balance between the computation time and the subset quality. In this article, we propose a new local search HSS method and its extended version. Three strategies are proposed. The first two strategies are applied to the proposed method to obtain a good subset within a small computation time, and the third one is applied to the extended version to further improve the obtained subset. The experimental results on various candidate sets demonstrate that the proposed method and its extended version are much more efficient and effective than the existing HSS methods.},
  archive      = {J_TEVC},
  author       = {Yang Nan and Ke Shang and Hisao Ishibuchi and Linjun He},
  doi          = {10.1109/TEVC.2022.3219081},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1690-1704},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An improved local search method for large-scale hypervolume subset selection},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The competing genes evolutionary algorithm: Avoiding genetic
drift through competition, local search, and majority voting.
<em>TEVC</em>, <em>27</em>(6), 1678–1689. (<a
href="https://doi.org/10.1109/TEVC.2022.3229038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An estimation-of-distribution algorithm is an evolutionary algorithm that uses a probabilistic model to represent its population. It iteratively draws solutions from its model and, considering their fitnesses, uses these solutions to update the model’s parameters. However, there is a risk of reinforcing random noise from sampling back into the model—a problem termed genetic drift. We propose the competing genes evolutionary algorithm that optimizes a fitness function over a binary search space and avoids this problem by updating only one model parameter at a time. The algorithm uses the model not only to sample solutions but also to select a parameter in each iteration that it pins to a value for the rest of the search process. We obtain upper bounds on the number of fitness evaluations the algorithm needs to solve well-known benchmark functions as a function of its population size and observe better or comparable results to other evolutionary algorithms. We attribute these favorable results to the algorithm’s efficient use of its samples to explore its dwindling search space. We also introduce two variants of the algorithm. The first version eliminates the need to preset the number of solutions to sample per iteration, and the second seeks to escape local optima. We provide evidence that these variants achieve their goals.},
  archive      = {J_TEVC},
  author       = {Adetunji David Ajimakin and V. Susheela Devi},
  doi          = {10.1109/TEVC.2022.3229038},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1678-1689},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {The competing genes evolutionary algorithm: Avoiding genetic drift through competition, local search, and majority voting},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multiscenario optimization evolutionary algorithm based on
transfer framework. <em>TEVC</em>, <em>27</em>(6), 1663–1677. (<a
href="https://doi.org/10.1109/TEVC.2022.3211643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiscenario optimization problems involve multiple scenarios to be optimized simultaneously, where each scenario corresponds to a multiobjective optimization problem with specific operating conditions. The goal is to find a group of public compromised optimal solutions (PCOSs) achieving compromised optimal in every scenario. This type of optimization problems widely exists in real-world applications, but the research on it is few. In this article, a Multiscenario Optimization Evolutionary Algorithm based on a transfer framework is proposed. In one iteration, for each scenario, its knee solutions are recognized as its transfer candidates and are used to construct a constraint hyperplane, which determines whether transfer candidates from other scenarios can be the transferable solutions in this underlying scenario. Then, among all transfer candidates, those accepted by all scenarios are identified as the PCOSs and stored in archive. Afterwards, the archive updating process is applied to guarantee the optimality of solutions in archive and control the size of archive. Finally, each scenario’s accepted transferable solutions are utilized in its offspring generation, thus achieving information transfer between different scenarios. Experimental results on a group of benchmark functions verify the superiority of the proposed design in terms of both optimality and computational efficiency over existing approaches.},
  archive      = {J_TEVC},
  author       = {Shanlin Jiang and Gary G. Yen and Zhenan He},
  doi          = {10.1109/TEVC.2022.3211643},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1663-1677},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A multiscenario optimization evolutionary algorithm based on transfer framework},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoDock koto: A gradient boosting differential evolution
for molecular docking. <em>TEVC</em>, <em>27</em>(6), 1648–1662. (<a
href="https://doi.org/10.1109/TEVC.2022.3225632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular docking plays a vital role in modern drug discovery, by supporting predictions of the binding modes and affinities of ligands at the binding site of target proteins. Several docking programs have been developed for both commercial and academic applications. Typically, a docking program’s performance depends on the sampling algorithm used to generate the ligand’s potential conformations and the scoring function applied to evaluate and rank these conformations. Evolutionary algorithms are widely used as sampling algorithms in docking programs. However, both the linkage problem and the dimensionality degenerate the search ability of evolutionary algorithms in the docking process. Therefore, a newly designed docking program named AutoDock Koto was developed in this study, which adopts a novel gradient boosting differential evolution algorithm to effectively address these issues. Experimental results show that compared with commonly used docking programs, AutoDock Koto yields dramatic improvements in docking performance based on an extensive dataset of 285 protein–ligand complexes. In addition, due to its strong docking ability, AutoDock Koto was used to identify potential drugs for COVID-19 based on a virtual screening of all approved drugs in our experiments. Sixteen drugs are found to possess low binding energy to the main target protease of SARS-CoV-2 and, thus, have the potential to treat COVID-19 as antiviral drugs. The source code of AutoDock Koto can be downloaded for free from https://github.com/codezhouj/Molecular_Docking .},
  archive      = {J_TEVC},
  author       = {Junkai Ji and Jin Zhou and Zhangfan Yang and Qiuzhen Lin and Carlos A. Coello Coello},
  doi          = {10.1109/TEVC.2022.3225632},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1648-1662},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {AutoDock koto: A gradient boosting differential evolution for molecular docking},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-objective genetic programming algorithm with α
dominance and archive for uncertain capacitated arc routing problem.
<em>TEVC</em>, <em>27</em>(6), 1633–1647. (<a
href="https://doi.org/10.1109/TEVC.2022.3195165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertain capacitated arc routing problem (UCARP) is an important combinatorial optimization problem with many applications in the real world. Genetic programming hyper-heuristic has been successfully used to automatically evolve routing policies, which can make real-time routing decisions for UCARPs. It is desired to evolve routing policies that are both effective and small/simple to be easily understood. The effectiveness and size are two potentially conflicting objectives. A further challenge is the objective selection bias issue, i.e., it is much more likely to obtain small but ineffective routing policies than the effective ones that are typically large. In this article, we propose a new multiobjective genetic programming algorithm to evolve effective and small routing policies. The new algorithm employs the α dominance strategy with a newly proposed α adaptation scheme to address the objective selection bias issue. In addition, it contains a new archive strategy to prevent the loss of promising individuals due to the rotation of training instances. The experimental results showed that the newly proposed algorithm can evolve significantly better routing policies than the current state-of-the-art algorithms for UCARP in terms of both effectiveness and size. We have also analyzed the evolved routing policies to show better interpretability.},
  archive      = {J_TEVC},
  author       = {Shaolin Wang and Yi Mei and Mengjie Zhang},
  doi          = {10.1109/TEVC.2022.3195165},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1633-1647},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A multi-objective genetic programming algorithm with α dominance and archive for uncertain capacitated arc routing problem},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OPTION: OPTImization algorithm benchmarking ONtology.
<em>TEVC</em>, <em>27</em>(6), 1618–1632. (<a
href="https://doi.org/10.1109/TEVC.2022.3232844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many optimization algorithm benchmarking platforms allow users to share their experimental data to promote reproducible and reusable research. However, different platforms use different data models and formats, which drastically complicates the identification of relevant datasets, their interpretation, and their interoperability. Therefore, a semantically rich, ontology-based, machine-readable data model that can be used by different platforms is highly desirable. In this article, we report on the development of such an ontology, which we call OPTION (OPTImization algorithm benchmarking ONtology). Our ontology provides the vocabulary needed for semantic annotation of the core entities involved in the benchmarking process, such as algorithms, problems, and evaluation measures. It also provides means for automatic data integration, improved interoperability, and powerful querying capabilities, thereby increasing the value of the benchmarking data. We demonstrate the utility of OPTION, by annotating and querying a corpus of benchmark performance data from the BBOB collection of the COCO framework and yet another black-box optimization benchmark (YABBOB) family of the Nevergrad environment. In addition, we integrate features of the BBOB functional performance landscape into the OPTION knowledge base (KB) using publicly available datasets with exploratory landscape analysis. Finally, we integrate the OPTION KB into the IOHprofiler environment and provide users with the ability to perform a meta-analysis of performance data.},
  archive      = {J_TEVC},
  author       = {Ana Kostovska and Diederick Vermetten and Carola Doerr and Sašo Džeroski and Panče Panov and Tome Eftimov},
  doi          = {10.1109/TEVC.2022.3232844},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1618-1632},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {OPTION: OPTImization algorithm benchmarking ONtology},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decomposition-based lin–kernighan heuristic with
neighborhood structure transfer for multi/many-objective traveling
salesman problem. <em>TEVC</em>, <em>27</em>(6), 1604–1617. (<a
href="https://doi.org/10.1109/TEVC.2022.3215174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi/many-objective traveling salesman problem (MOTSP), which is NP-hard, can be found in many real-world applications. The Lin–Kernighan (LK) algorithm, as one of the most successful local search (LS) methods for the single-objective traveling salesman problem, adopts a variable neighborhood LS. However, LK cannot be directly applied to the decomposition-based multiobjective optimization framework due to its incapability of effective knowledge transfer among different subproblems, especially for problems with more than two objectives. In this article, we propose an algorithm, called decomposition-based multiobjective LK heuristic with neighborhood structure transfer (NST-MOLK) for MOTSP. In NST-MOLK, the knowledge of a neighborhood structure has been transferred to enhance the efficiency and effectiveness of LK. The experimental studies have been conducted on both benchmark and real-world instances constructed based on the flight prices of seven airlines and 266 airports of different cities in China. Experimental results show that NST-MOLK outperforms both classical and state-of-the-art algorithms significantly. It has also been verified that neighborhood structure transfer can effectively improve the performance of NST-MOLK.},
  archive      = {J_TEVC},
  author       = {Xinye Cai and Kang Wang and Yi Mei and Zhenhua Li and Jun Zhao and Qingfu Zhang},
  doi          = {10.1109/TEVC.2022.3215174},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1604-1617},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Decomposition-based Lin–Kernighan heuristic with neighborhood structure transfer for Multi/Many-objective traveling salesman problem},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A learning-based multipopulation evolutionary optimization
for flexible job shop scheduling problem with finite transportation
resources. <em>TEVC</em>, <em>27</em>(6), 1590–1603. (<a
href="https://doi.org/10.1109/TEVC.2022.3219238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many practical manufacturing systems, transportation equipment such as automated guided vehicles (AGVs) is widely adopted to transfer jobs and realize the collaboration of different machines, but is often ignored in current researches. In this article, we address the flexible job shop scheduling problem with finite transportation resources (FJSP-Ts). Considering the difficulties caused by the introduction of transportation and the NP-hard nature, the evolutionary algorithm (EA) is adopted as a solution approach. To this end, a learning-based multipopulation evolutionary optimization (LMEO) is proposed to deal with the FJSP-T. First, the multipopulation strategy is introduced and a cooperation-based initialization is designed by combining several heuristics to guarantee the quality and diversity of the initial population. Second, a reinforcement learning (RL)-based mating selection is proposed to realize the cooperation of different subpopulations by selecting appropriate individuals for evolutionary search. Then, a specific local search inspired by the problem properties is designed to enhance the exploitation capability of the LMEO. Moreover, a statistical learning-based replacement is designed to maintain the quality and diversity of the population. Extensive experiments are conducted to test the performances of the LMEO. The statistical comparison shows that the LMEO is superior to the state-of-the-art algorithms in solving the FJSP-T in terms of solution quality and robustness.},
  archive      = {J_TEVC},
  author       = {Zixiao Pan and Ling Wang and Jie Zheng and Jing-Fang Chen and Xing Wang},
  doi          = {10.1109/TEVC.2022.3219238},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1590-1603},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A learning-based multipopulation evolutionary optimization for flexible job shop scheduling problem with finite transportation resources},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-fuzzy-classifier-based evolutionary algorithm for
expensive multiobjective optimization. <em>TEVC</em>, <em>27</em>(6),
1575–1589. (<a href="https://doi.org/10.1109/TEVC.2022.3195668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective evolutionary algorithms (MOEAs) have been widely used to solve multiobjective optimization problems (MOPs). Conventional MOEAs usually require a large number of function evaluations (FEs) for evaluating the quality of solutions. However, only a limited number of FEs are affordable in many real-world optimization problems, where the FEs are computationally or economically expensive. The use of a large number of FEs decreases the effectiveness of MOEAs in solving these problems. This article proposes a dual-fuzzy-classifier-based surrogate model (DFC) and a DFC-based MOEA (DFC-MOEA) framework for expensive optimization problems. The DFC model is used for offspring preselection to choose high-quality offspring solutions and for categorization to divide unevaluated solutions into three categories. In the proposed framework, two fuzzy classifiers are built to predict the quality of each unevaluated solution. To strike a balance between convergence and diversity, one classifier is designed for predicting the dominance relation of unevaluated solutions (i.e., convergence), and another classifier is designed for predicting the crowdedness of unevaluated solutions (i.e., diversity). The integration of the proposed framework in three different types of MOEAs (i.e., a dominance-based MOEA, an indicator-based MOEA, and a decomposition-based MOEA) demonstrates its usefulness in handling expensive optimization problems. Comprehensive experiments on four well-known test suites and several real-world optimization problems demonstrate that the proposed framework is able to improve the performance of MOEAs under a limited number of FEs.},
  archive      = {J_TEVC},
  author       = {Jinyuan Zhang and Linjun He and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2022.3195668},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1575-1589},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Dual-fuzzy-classifier-based evolutionary algorithm for expensive multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary algorithm-based attack strategy with swarm
robots in denied environments. <em>TEVC</em>, <em>27</em>(6), 1562–1574.
(<a href="https://doi.org/10.1109/TEVC.2022.3194349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An attack–defense confrontation problem arises from a robot swarm attacking a territory protected by another one. In denied environments, global positioning and communication are hardly available. It becomes difficult for a swarm to realize collaboration and handle confrontation against another. Commonly used deep reinforcement learning (DRL) relies on pretraining, which is time consuming and has strong environmental dependence, especially in denied environments. To study attack strategies in denied environments, this work proposes a novel evolutionary algorithm (EA)-based attack strategy with Swarm Robots for the first time. Each robot obtains its situation information by perceiving its nearby peers and enemies. Such information is utilized to evaluate the benefits or threats of a robot’s next perceptible attack positions. Then, each robot uses EA to optimize its fitness function and searches for its optimal position. A collision-avoidance strategy is integrated into the algorithm. Hence, a robot swarm realizes collaboration and handles confrontation as long as each robot can sense its surroundings. They utilize their own sensors to detect others locally without using global positioning and communication devices. The experimental result analyses show that the EA-based attack strategy has better scalability and more potential in solving large-scale confrontational problems than the DRL-based algorithms. Rationales of the proposed method are presented to show the great capability of the proposed method.},
  archive      = {J_TEVC},
  author       = {Huan Liu and JunQi Zhang and Peng Zu and MengChu Zhou},
  doi          = {10.1109/TEVC.2022.3194349},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {6},
  pages        = {1562-1574},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary algorithm-based attack strategy with swarm robots in denied environments},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A steady-state algorithm for solving expensive
multiobjective optimization problems with nonparallelizable evaluations.
<em>TEVC</em>, <em>27</em>(5), 1544–1558. (<a
href="https://doi.org/10.1109/TEVC.2022.3219062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expensive multiobjective optimization problems (EMOPs) refer to those wherein evaluation of each candidate solution incurs a significant cost. To solve such problems within a limited number of solution evaluations, surrogate-assisted evolutionary algorithms (SAEAs) are often used. However, existing SAEAs typically operate in a generational framework wherein multiple solutions are identified for evaluation in each generation. There exist relatively few proposals in steady-state framework, wherein only a single solution is evaluated in each iteration. The development of such algorithms is crucial to efficiently solve EMOPs for which the evaluation of candidate designs cannot be parallelized. Furthermore, regardless of the framework used, the performance of current SAEAs tends to degrade when the Pareto front (PF) of the problem has irregularities, such as extremely concave/convex segments, even for 2/3-objective problems. To contextualize the motivation of this study, the performance of a few state-of-the-art SAEAs is first demonstrated on some such selected problems. Then, to address the above research gaps, we propose a surrogate-assisted steady-state EA (SASSEA), which incorporates a number of novel elements, including: 1) effective use of model uncertainty information to aid the search, including the use of the probabilistic dominance and Mahalanobis distance; 2) two-step infill identification using nondominance (ND) and distance-based selection; and 3) a shadow ND mechanism to avoid repeated selection and evaluation of dominated solutions. The efficacy of the proposed approach is demonstrated through extensive benchmarking on a range of test problems. It shows competitive performance relative to many state-of-the-art SAEAs, including both steady-state and generational approaches.},
  archive      = {J_TEVC},
  author       = {Kamrul Hasan Rahi and Hemant Kumar Singh and Tapabrata Ray},
  doi          = {10.1109/TEVC.2022.3219062},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1544-1558},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A steady-state algorithm for solving expensive multiobjective optimization problems with nonparallelizable evaluations},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-dimensional space modeling-based differential evolution
for large-scale global optimization problems. <em>TEVC</em>,
<em>27</em>(5), 1529–1543. (<a
href="https://doi.org/10.1109/TEVC.2022.3227440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale global optimization (LSGO) has been an active research field. Part of this interest is supported by its application to cutting-edge research, such as Deep Learning, Big Data, and complex real-world problems, such as image encryption, real-time traffic management, and more. However, the high dimensionality makes solving LSGO a significant challenge. Some recent research deal with the high dimensionality by mapping the optimization process to a reduced alternative space. Nonetheless, these works suffer from the changes in the search space topology and the loss of information caused by the dimensionality reduction. This article proposes a hybrid metaheuristic, so-called low-dimensional space modeling-based differential evolution (LSMDE), that uses the singular value decomposition to build a low-dimensional search space from the features of candidate solutions generated by a new SHADE-based algorithm (GM-SHADE). GM-SHADE combines a Gaussian mixture model (GMM) and two specialized local algorithms: 1) MTS-LS1 and 2) L-BFGS-B, to promote a better exploration of the reduced search space. GMM mitigates the loss of information in mapping high-dimensional individuals to low-dimensional individuals. Furthermore, the proposal does not require prior knowledge of the search space topology, which makes it more flexible and adaptable to different LSGO problems. The results indicate that LSMDE is the most efficient method to deal with partially separable functions compared to other state-of-the-art algorithms and has the best overall performance in two of the three proposed experiments. Experimental results also show that the new approach achieves competitive results for nonseparable and overlapping functions on the most recent test suite for LSGO problems.},
  archive      = {J_TEVC},
  author       = {Thiago Henrique Lemos Fonseca and Silvia Modesto Nassar and Alexandre César Muniz de Oliveira and Bruno Agard},
  doi          = {10.1109/TEVC.2022.3227440},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1529-1543},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Low-dimensional space modeling-based differential evolution for large-scale global optimization problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bi-objective knowledge transfer framework for evolutionary
many-task optimization. <em>TEVC</em>, <em>27</em>(5), 1514–1528. (<a
href="https://doi.org/10.1109/TEVC.2022.3210783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-task problem (MaTOP) is a kind of challenging multitask optimization problem with more than three tasks. Two significant issues in solving MaTOPs are measuring intertask similarity and transferring knowledge among similar tasks. However, most existing algorithms only use a single similarity measurement, which cannot accurately measure the intertask similarity because the intertask similarity is a concept with multiple different aspects. To address this limitation, this article proposes a bi-objective knowledge transfer (BoKT) framework, which aims first to accurately measure different types of intertask similarity using two different measurements and second to effectively transfer knowledge with different types of similarity via specific strategies. To achieve the first goal, a bi-objective measurement is designed to measure intertask similarity from two different aspects, including shape similarity and domain similarity. To achieve the second goal, a similarity-based adaptive knowledge transfer strategy is designed to choose the suitable knowledge transfer strategy based on the type of intertask similarity. We compare the BoKT framework-based algorithms with several state-of-the-art algorithms on two challenging many-task optimization test suites with 16 instances and on real-world MaTOPs with up to 500 tasks. The experimental results show that the proposed algorithms generally outperform the compared algorithms.},
  archive      = {J_TEVC},
  author       = {Yi Jiang and Zhi-Hui Zhan and Kay Chen Tan and Jun Zhang},
  doi          = {10.1109/TEVC.2022.3210783},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1514-1528},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A bi-objective knowledge transfer framework for evolutionary many-task optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental recursive ranking grouping for large-scale
global optimization. <em>TEVC</em>, <em>27</em>(5), 1498–1513. (<a
href="https://doi.org/10.1109/TEVC.2022.3216968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world optimization problems may have a different underlying structure. In black-box optimization, the dependencies between decision variables remain unknown. However, some techniques can discover such interactions accurately. In large-scale global optimization (LSGO), problems are high dimensional. It was shown effective to decompose LSGO problems into subproblems and optimize them separately. The effectiveness of such approaches may be highly dependent on the accuracy of problem decomposition. Many state-of-the-art decomposition strategies are derived from differential grouping (DG). However, if a given problem consists of nonadditively separable subproblems, DG-based strategies may discover many nonexisting interactions. On the other hand, monotonicity checking strategies proposed so far do not report nonexisting interactions for any separable subproblems but may miss discovering many of the existing ones. Therefore, we propose incremental recursive ranking grouping (IRRG) that suffers from none of these flaws. IRRG consumes more fitness function evaluations than the recent DG-based propositions, e.g., recursive DG 3 (RDG3). Nevertheless, the effectiveness of the considered cooperative co-evolution frameworks after embedding IRRG or RDG3 was similar for problems with additively separable subproblems that are suitable for RDG3. After replacing the additive separability with nonadditive, embedding IRRG leads to results of significantly higher quality.},
  archive      = {J_TEVC},
  author       = {Marcin Michal Komarnicki and Michal Witold Przewozniczek and Halina Kwasnicka and Krzysztof Walkowiak},
  doi          = {10.1109/TEVC.2022.3216968},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1498-1513},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Incremental recursive ranking grouping for large-scale global optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decomposition-based multiobjective optimization algorithms
with adaptively adjusting weight vectors and neighborhoods.
<em>TEVC</em>, <em>27</em>(5), 1485–1497. (<a
href="https://doi.org/10.1109/TEVC.2022.3201890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decomposition-based multiobjective optimization algorithm (MOEA/D) is an effective method of solving a multiobjective optimization problem (MOP). The main idea of MOEA/D is that the objectives are weighted through different vectors to form different subproblems, and an optimal solution set is obtained by co-evolution in a certain neighborhood. However, with the increase of objectives, the number of nondominated solutions increases exponentially, resulting in the deteriorated capability of searching for optimal solutions. In addition, for an optimization problem with the complex Pareto front (PF), the selection pressure of nondominated solutions is insufficient. To make evolution more efficient, an MOEA/D with adaptively adjusting weight vectors and neighborhoods (MOEA/D-AAWNs) is developed in this article. First, the evolutionary direction of each subproblem is analyzed and the Sparsity function (Spa) is proposed to measure the population density on the PF. By using Spa, a method of generating uniform vectors is presented to improve the diversity of solutions. Besides, a method of adaptively adjusting neighborhoods is given. It adjusts neighborhoods according to the number of iterations and the Spa value of its corresponding subproblem. In this way, the computational resource can be effectively allocated, leading to the improvement in evolutionary efficiency. The proposed algorithm is applied to solve a series of benchmark optimization instances, and the experimental results show that the proposed algorithm outperforms comparison algorithms in runtime, convergence, and diversity.},
  archive      = {J_TEVC},
  author       = {Qian Zhao and Yinan Guo and Xiangjuan Yao and Dunwei Gong},
  doi          = {10.1109/TEVC.2022.3201890},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1485-1497},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Decomposition-based multiobjective optimization algorithms with adaptively adjusting weight vectors and neighborhoods},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel evolutionary algorithm for energy-efficient
scheduling in flexible job shops. <em>TEVC</em>, <em>27</em>(5),
1470–1484. (<a href="https://doi.org/10.1109/TEVC.2022.3222791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving productivity at the expense of heavy energy consumption is often no longer possible in modern manufacturing industries. Through efficient scheduling technologies, however, we are able to still maintain high productivity while reducing energy costs. This article addresses a flexible job shop scheduling problem under time-of-use electricity tariffs with the objective of minimizing total energy consumption while considering a predefined makespan constraint. We propose a novel two-individual-based evolutionary (TIE) algorithm, which incorporates several distinguishing features, such as a tabu search procedure, a topological order-based recombination operator, a new neighborhood structure for this specific problem, and an approximate neighborhood evaluation method. Extensive experiments are conducted on widely used benchmark instances, which show that the proposed TIE outperforms traditional trajectory-based and population-based methods. We also analyze the key features of TIE to identify its critical success factors, and discuss the impact of varying key parameters of the problem to derive practical insights.},
  archive      = {J_TEVC},
  author       = {Junwen Ding and Stéphane Dauzère-Pérès and Liji Shen and Zhipeng Lü},
  doi          = {10.1109/TEVC.2022.3222791},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1470-1484},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A novel evolutionary algorithm for energy-efficient scheduling in flexible job shops},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing diversity by local subset selection in
evolutionary multiobjective optimization. <em>TEVC</em>, <em>27</em>(5),
1456–1469. (<a href="https://doi.org/10.1109/TEVC.2022.3194211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main target of multiobjective evolutionary algorithms (MOEAs) is to find a set of evenly distributed nondominated solutions that approximate the Pareto front (PF) of a multiobjective optimization problem (MOP). This means that the approximated set should be as close to the PF as possible, and as diverse as possible. The former is usually called a convergence criterion and the latter is called a diversity criterion. A variety of strategies have been proposed to meet the two criteria. However, as far as the diversity criterion is concerned, it is still a challenge to achieve an evenly distributed approximation set with different sizes for a problem with a complicated PF shape. To deal with this challenge, we propose a local subset selection (LSS) -based environmental selection for evolutionary multiobjective optimization in this article. LSS considers the environmental selection as a subset selection problem by choosing promising solutions from the combination of the parent and offspring populations. In LSS, a potential energy function is utilized as the objective function, which provides a heavy selection pressure on diversity as well as has low computational complexity. Furthermore, to balance search efficiency and quality, a local search strategy is used in LSS to make full use of objective information for acceleration. The proposed LSS strategy is embedded into some state-of-the-art Pareto-domination-based MOEAs, and the experimental results suggest that LSS can produce shape-invariant and evenly distributed nondominated sets with different population sizes.},
  archive      = {J_TEVC},
  author       = {Zihan Wang and Bochao Mao and Hao Hao and Wenjing Hong and Chunyun Xiao and Aimin Zhou},
  doi          = {10.1109/TEVC.2022.3194211},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1456-1469},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Enhancing diversity by local subset selection in evolutionary multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differential evolution with domain transform. <em>TEVC</em>,
<em>27</em>(5), 1440–1455. (<a
href="https://doi.org/10.1109/TEVC.2022.3220424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although a significant advancement of differential evolution (DE) for global optimization has been witnessed in the past two decades, the problems of premature convergence and stagnation are still open questions that hinder the performance. Both are likely to occur on complicated multimodal functions, but the phenomena differ. Premature convergence refers to a rapid loss of population diversity when attracted to a local minimum while stagnation happens even though the population is diverse. To deal with these problems, this article proposes a domain transform (DT) methodology. Different from existing fitness analysis which mainly utilizes the original fitness landscape information, DT yields a transformed fitness landscape with transform operation to the frequency domain and inverse transform operation back to the solution domain, between which the first few highest frequencies are removed. With the deletion operation, the transformed fitness landscape becomes smoother and facilitates the escape from local minima and stagnation on complicated multimodal functions. Simulation results show that DT significantly improves the population successful update rate and population convergence. The constructed DTDE algorithm consequently exhibits remarkable improvements on the baseline algorithm and outperforms several state-of-the-art DE variants. DT has also been extended for noisy optimization and it performs better than the baseline, the classic resampling method, state-of-the-art DE variants, as well as several popular noisy evolutionary optimization algorithms.},
  archive      = {J_TEVC},
  author       = {Sheng Xin Zhang and Yi Nan Wen and Yu Hong Liu and Li Ming Zheng and Shao Yong Zheng},
  doi          = {10.1109/TEVC.2022.3220424},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1440-1455},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Differential evolution with domain transform},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An instance space analysis of constrained multiobjective
optimization problems. <em>TEVC</em>, <em>27</em>(5), 1427–1439. (<a
href="https://doi.org/10.1109/TEVC.2022.3208595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems (CMOPs) are generally more challenging than unconstrained problems. This in part can be attributed to the infeasible region generated by the constraint functions, the interaction between constraints and objectives, or both. In this article, we explore the relationship between the performance of constrained multiobjective evolutionary algorithms (CMOEAs) and the instance characteristics of CMOP using instance space analysis (ISA). To do this, we extend recent work on Landscape Analysis features for characterizing CMOPs. Specifically, we introduce new features to describe the multiobjective-violation landscape, formed by the interaction between constraint violation and multiobjective fitness. The detailed evaluation of the algorithm footprints, spanning eight CMOP benchmark suites and 15 CMOEAs, demonstrates that ISA effectively captures the strength and weakness of the CMOEAs. We conclude that two characteristics, the isolation of nondominate set and the correlation between constraints and objectives evolvability, have the greatest impact on algorithm performance. However, the current benchmarks problems lack of diversity to represent the real-world problems and to fully reveal the efficacy of CMOEAs evaluated.},
  archive      = {J_TEVC},
  author       = {Hanan Alsouly and Michael Kirley and Mario Andrés Muñoz},
  doi          = {10.1109/TEVC.2022.3208595},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1427-1439},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An instance space analysis of constrained multiobjective optimization problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A niching regression adaptive memetic algorithm for
multimodal optimization of the euclidean traveling salesman problem.
<em>TEVC</em>, <em>27</em>(5), 1413–1426. (<a
href="https://doi.org/10.1109/TEVC.2022.3211954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) has been studied for many years. In particular, the multimodal optimization of the TSP is important for practical applications, because decision-makers can select the best candidate based on current conditions and requirements. In the Euclidean TSP, there are $n$ points in $\mathbb {R}^{d}$ space with Euclidean distance between any two points, that is, $d(x, y) =||x-y||_{2}$ . The goal is to find a tour of minimum length visiting each point. In this article, we only focus on the case that $d=2$ . Recently, in order to efficiently handle the multimodal optimization of the TSP, some methods have been developed to deal with it. Nevertheless, these methods usually perform poorly for large-scale cases. In this article, we propose a niching regression adaptive memetic algorithm (MA) to handle the multimodal optimization of the Euclidean TSP. We use the MA as the baseline algorithm and incorporate the neighborhood strategy to maintain the population diversity. In addition, we design a novel regression partition initialization and adaptive parameter control to enhance our algorithm, and propose the concept of the redundant individual to improve the search efficiency. To validate the performance of the proposed algorithm, we comprehensively conduct experiments on the multimodal optimization of TSP benchmark and the well-known TSPLIB library. The experimental results reveal that the proposed method outperforms other methods, especially for large-scale cases.},
  archive      = {J_TEVC},
  author       = {Shi-Jie Jian and Sun-Yuan Hsieh},
  doi          = {10.1109/TEVC.2022.3211954},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1413-1426},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A niching regression adaptive memetic algorithm for multimodal optimization of the euclidean traveling salesman problem},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A correlation-guided layered prediction approach for
evolutionary dynamic multiobjective optimization. <em>TEVC</em>,
<em>27</em>(5), 1398–1412. (<a
href="https://doi.org/10.1109/TEVC.2022.3193287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving dynamic multiobjective optimization problems (DMOPs) by evolutionary algorithms, the historical moving directions of some special points along the Pareto front, such as the center and knee points, are widely employed to predict the Pareto-optimal solutions (POSs). However, special points may be impacted by certain individuals with a large direction deviation, and thus, mislead the tracking of dynamic POS. To solve this issue, a correlation-guided layered prediction approach for solving DMOPs is proposed in this article, where multiple prediction models are integrated by considering the correlation of individuals’ moving directions. To be specific, the population is clustered into three subpopulations (i.e., high, mid, and low correlation) by correlation analysis to perform different prediction behaviors. The high correlation subpopulation aims to predict the moving direction via a linear prediction model. The mid correlation subpopulation is devoted to predicting the manifold change of POS by self-adaptively using the direction and length correction models. The diversity preservation is considered by the low correlation subpopulation. While the three subpopulations focus on different optimization tasks, they also cooperate to track the dynamic POS. The comprehensive experimental results on a variety of benchmark test problems demonstrate the superiority of the proposed approach, as compared with some state-of-the-art prediction-based dynamic multiobjective algorithms.},
  archive      = {J_TEVC},
  author       = {Kunjie Yu and Dezheng Zhang and Jing Liang and Ke Chen and Caitong Yue and Kangjia Qiao and Ling Wang},
  doi          = {10.1109/TEVC.2022.3193287},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1398-1412},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A correlation-guided layered prediction approach for evolutionary dynamic multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Run time analysis for random local search on generalized
majority functions. <em>TEVC</em>, <em>27</em>(5), 1385–1397. (<a
href="https://doi.org/10.1109/TEVC.2022.3216349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Run time analysis of evolutionary algorithms recently makes significant progress in linking algorithm performance to algorithm parameters. However, settings that study the impact of problem parameters are rare. The recently proposed W-model provides a good framework for such analyses, generating pseudo-Boolean optimization problems with tunable properties. We initiate theoretical research of the W-model by studying how one of its properties—neutrality—influences the run time of random local search (RLS). Neutrality creates plateaus in the search space by first performing a majority vote for subsets of the solution candidate and then evaluating the smaller dimensional string via a low-level fitness function. We prove upper bounds for the expected run time of RLS on this $\mathrm{M{\scriptstyle AJORITY}}$ problem for its entire parameter spectrum. To this end, we provide a theorem, applicable to many optimization algorithms, that links the run time of $\mathrm{M{\scriptstyle AJORITY}}$ with its symmetric version $\mathrm{H{\scriptstyle AS}M{\scriptstyle AJORITY}}$ , where a sufficient majority is needed to optimize the subset. We also introduce a generalized version of classic drift theorems as well as a generalized version of Wald&#39;s equation, both of which we believe to be of independent interest.},
  archive      = {J_TEVC},
  author       = {Carola Doerr and Martin S. Krejca},
  doi          = {10.1109/TEVC.2022.3216349},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1385-1397},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Run time analysis for random local search on generalized majority functions},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiobjective-based constraint-handling technique for
evolutionary constrained multiobjective optimization: A new perspective.
<em>TEVC</em>, <em>27</em>(5), 1370–1384. (<a
href="https://doi.org/10.1109/TEVC.2022.3194729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective-based constraint-handling techniques are popular in evolutionary constrained single-objective optimization. However, most of these techniques run into troubles when dealing with constrained multiobjective optimization problems (CMOPs). That is, they have difficulty optimizing too many objective functions, are ineffective in maintaining population diversity, or are challenged in establishing appropriate additional objective functions. As a remedy to these limitations, we propose a novel technique called NRC for handling CMOPs. The novelty of NRC lies in its three sorting procedures: 1) nondominated sorting; 2) reversed nondominated sorting; and 3) constrained crowding distance sorting, which are performed in sequence to provide driving forces toward the Pareto front (PF) of a transformed unconstrained multiobjective optimization problem (treating the overall constraint violation as an additional objective function), the boundary front, and the constrained PF, respectively. With the combination of these three different forces, NRC can conveniently approach the desired PF from diverse search directions. The effectiveness of NRC is experimentally verified. Also, we incorporate NRC into a two-archive mechanism and develop a novel constrained multiobjective evolutionary algorithm, called NRC2. Comprehensive experiments on 49 benchmark CMOPs and 21 real-world ones demonstrate that NRC2 is significantly superior or comparable to six state-of-the-art constrained evolutionary multiobjective optimizers on most test instances.},
  archive      = {J_TEVC},
  author       = {Zhi-Zhong Liu and Yunchuan Qin and Wu Song and Jinyuan Zhang and Kenli Li},
  doi          = {10.1109/TEVC.2022.3194729},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1370-1384},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective-based constraint-handling technique for evolutionary constrained multiobjective optimization: A new perspective},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Difficulty and contribution-based cooperative coevolution
for large-scale optimization. <em>TEVC</em>, <em>27</em>(5), 1355–1369.
(<a href="https://doi.org/10.1109/TEVC.2022.3201691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative coevolution (CC) is a paradigm equipped with the divide-and-conquer strategy for solving large-scale optimization problems (LSOPs). Currently, the computational resource allocation schemes of most CC could be divided into two categories, namely, equal allocation to all subproblems and preference allocation to the subproblems with a large contribution. However, the difficult subproblems are not carefully considered by the existing computational resource allocation schemes. For these subproblems, the investment of computational resources cannot quickly improve the fitness value, which leads to their small early contribution and being neglected. In this article, we comprehensively analyze the imbalanced nature of the subproblems from their difficulty and contribution in LSOPs. First, we propose a method to quantify the optimization difficulty of the problems during the evolution process, which considers both the difficulty of the fitness landscape and the behaviors of the optimization algorithm. Then, we propose a novel both difficulty and contribution-based CC framework, called DCCC, which encourages the allocation of the computational resources to more contributing and more difficult subproblems. DCCC is tested on the CEC’2010 and CEC’2013 large-scale optimization benchmarks, and is compared with several typical CC frameworks and state-of-the-art large-scale optimization algorithms. The experimental results demonstrate that DCCC is very competitive.},
  archive      = {J_TEVC},
  author       = {Peilan Xu and Wenjian Luo and Xin Lin and Yatong Chang and Ke Tang},
  doi          = {10.1109/TEVC.2022.3201691},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1355-1369},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Difficulty and contribution-based cooperative coevolution for large-scale optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple populations for multiple objectives framework with
bias sorting for many-objective optimization. <em>TEVC</em>,
<em>27</em>(5), 1340–1354. (<a
href="https://doi.org/10.1109/TEVC.2022.3212058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convergence and diversity enhancement of multiobjective evolutionary algorithms (MOEAs) to efficiently solve many-objective optimization problems (MaOPs) is an active topic in evolutionary computation. By considering the advantages of the multiple populations for multiple objectives (MPMO) framework in solving multiobjective optimization problems and even MaOPs, this article proposes an MPMO-based algorithm with a bias sorting (BS) method (termed MPMO-BS) for solving MaOPs to achieve both good convergence and diversity performance. For convergence, the BS method is applied to each population of the MPMO framework to enhance the role of nondominated sorting by biasedly paying more attention to the objective optimized by the corresponding population. This way, all the populations in the MPMO framework evolve together to promote the convergence performance on all objectives of the MaOP. For diversity, an elite learning strategy is adopted to generate locally mutated solutions, and a reference vector-based maintenance method is adopted to preserve diverse solutions. The performance of the proposed MPMO-BS algorithm is assessed on 29 widely used MaOP test problems and two real-world application problems. The experimental results show its high effectiveness and competitiveness when compared with seven state-of-the-art MOEAs for many-objective optimization.},
  archive      = {J_TEVC},
  author       = {Qi-Te Yang and Zhi-Hui Zhan and Sam Kwong and Jun Zhang},
  doi          = {10.1109/TEVC.2022.3212058},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1340-1354},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiple populations for multiple objectives framework with bias sorting for many-objective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterexample-driven genetic programming for symbolic
regression with formal constraints. <em>TEVC</em>, <em>27</em>(5),
1327–1339. (<a href="https://doi.org/10.1109/TEVC.2022.3205286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In symbolic regression with formal constraints, the conventional formulation of regression problem is extended with desired properties of the target model, like symmetry, monotonicity, or convexity. We present a genetic programming algorithm that solves such problems using a satisfiability modulo theories solver to formally verify the candidate solutions. The essence of the method consists in collecting the counterexamples resulting from model verification and using them to improve search guidance. The method is exact upon successful termination, the produced model is guaranteed to meet the specified constraints. We compare the effectiveness of the proposed method with standard constraint-agnostic machine learning regression algorithms on a range of benchmarks and demonstrate that it outperforms them on several performance indicators.},
  archive      = {J_TEVC},
  author       = {Iwo Błądek and Krzysztof Krawiec},
  doi          = {10.1109/TEVC.2022.3205286},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1327-1339},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Counterexample-driven genetic programming for symbolic regression with formal constraints},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A competitive and cooperative swarm optimizer for
constrained multiobjective optimization problems. <em>TEVC</em>,
<em>27</em>(5), 1313–1326. (<a
href="https://doi.org/10.1109/TEVC.2022.3199775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving multiobjective optimization problems (MOPs) through metaheuristic methods gets considerable attention. Based on the classical variation operators, several enhanced operators, as well as multiobjective optimization evolutionary algorithms, have been developed. Among these operators, the competitive swarm optimizer (CSO) exhibits promising performance. However, it encounters difficulties when tackling constrained MOPs (CMOPs) with large objective spaces or complex infeasible regions. In this article, a competitive and cooperative swarm optimizer is proposed, which contains two particle update strategies: 1) the CSO provides faster convergence speed to accelerate the approximation of the Pareto front and 2) the cooperative swarm optimizer suggests a mutual-learning strategy to enhance the ability to jump out of local feasible regions or local optima. We also present a new algorithm for CMOPs. The results on four benchmark suites with 47 instances demonstrate the superiority of our approach compared with other state-of-the-art methods. Additionally, its effectiveness on large-scale CMOPs has also been verified.},
  archive      = {J_TEVC},
  author       = {Fei Ming and Wenyin Gong and Dongcheng Li and Ling Wang and Liang Gao},
  doi          = {10.1109/TEVC.2022.3199775},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1313-1326},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A competitive and cooperative swarm optimizer for constrained multiobjective optimization problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Particle swarm optimization for compact neural architecture
search for image classification. <em>TEVC</em>, <em>27</em>(5),
1298–1312. (<a href="https://doi.org/10.1109/TEVC.2022.3217290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are a superb computing paradigm in deep learning, and their architectures are considered to be the key to performance breakthroughs in various tasks. Recently, neural architecture search (NAS) methods have been proposed to automate the process of network architecture design, many of which have discovered novel CNN architectures that are superior to human-designed ones. However, most of the current NAS methods suffer from either prohibitively high computational complexity of resulting architectures which have inadvertently affected the deep model deployment, or limitations which impede the flexibility of architecture design. To address these deficiencies, this work proposes an evolutionary computation (EC)-based method for compact and flexible NAS. A valuable search space with parameter-efficient mobile-inverted bottleneck convolution blocks as the primitive components is proposed to ensure the initial quality of the compact architectures. In addition, a two-level variable-length particle swarm optimization (PSO) approach is devised to evolve both the microarchitecture and macroarchitecture of CNNs. Furthermore, this study proposes an effective scheme by integrating multiple computationally reduced methods to greatly speed up the evaluation process. Experimental results on the CIFAR-10, CIFAR-100, and ImageNet datasets show the superiority of the proposed method against the state-of-the-art algorithms in terms of the classification performance, search cost, and resulting architecture complexity.},
  archive      = {J_TEVC},
  author       = {Junhao Huang and Bing Xue and Yanan Sun and Mengjie Zhang and Gary G. Yen},
  doi          = {10.1109/TEVC.2022.3217290},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1298-1312},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Particle swarm optimization for compact neural architecture search for image classification},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A first runtime analysis of the NSGA-II on a multimodal
problem. <em>TEVC</em>, <em>27</em>(5), 1288–1297. (<a
href="https://doi.org/10.1109/TEVC.2023.3250552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Very recently, the first mathematical runtime analyses of the multiobjective evolutionary optimizer nondominated sorting genetic algorithm II (NSGA-II) have been conducted. We continue this line of research with a first runtime analysis of this algorithm on a benchmark problem consisting of multimodal objectives. We prove that if the population size $N$ is at least four times the size of the Pareto front, then the NSGA-II with four standard ways to select parents, bitwise mutation, and crossover with rate less than one, optimizes the OneJumpZeroJump benchmark with jump size $2 \le k \le n/4$ in time $O(N n^{k})$ . When using fast mutation instead of bitwise mutation this guarantee improves by a factor of $k^{\Omega (k)}$ . Overall, this work shows that the NSGA-II copes with the local optima of the OneJumpZeroJump problem at least as well as the global SEMO algorithm.},
  archive      = {J_TEVC},
  author       = {Benjamin Doerr and Zhongdi Qu},
  doi          = {10.1109/TEVC.2023.3250552},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1288-1297},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A first runtime analysis of the NSGA-II on a multimodal problem},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Paradox-free analysis for comparing the performance of
optimization algorithms. <em>TEVC</em>, <em>27</em>(5), 1275–1287. (<a
href="https://doi.org/10.1109/TEVC.2022.3199647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical comparison serves as a major tool in evaluating the performance of optimization algorithms, especially nondeterministic algorithms, but existing methods may suffer from a “cycle ranking” paradox and/or a “survival of the nonfittest” paradox. This article searches for paradox-free data analysis methods for numerical comparison. It is discovered that a class of sufficient conditions exist for designing paradox-free analysis. Rigorous modeling and deduction are applied to a class of profile methods employing a filter. It is thus further discovered and proven that algorithm-independent filter conditions can prevent cycle ranking and survival of nonfittest paradoxes from occurring. By adopting an algorithm-independent filter, popular profile methods such as the “modified data profile method,” “the accuracy profile method,” and “the operational characteristics zones method” can be paradox free in comparing or benchmarking the performance of optimization algorithms.},
  archive      = {J_TEVC},
  author       = {Yuan Yan and Qunfeng Liu and Yun Li},
  doi          = {10.1109/TEVC.2022.3199647},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1275-1287},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Paradox-free analysis for comparing the performance of optimization algorithms},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybridization of evolutionary algorithm and deep
reinforcement learning for multiobjective orienteering optimization.
<em>TEVC</em>, <em>27</em>(5), 1260–1274. (<a
href="https://doi.org/10.1109/TEVC.2022.3199045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective orienteering problems (MO-OPs) are classical multiobjective routing problems and have received much attention in recent decades. This study seeks to solve MO-OPs through a problem-decomposition framework, that is, an MO-OP is decomposed into a multiobjective knapsack problem (MOKP) and a traveling salesman problem (TSP). The MOKP and TSP are then solved by a multiobjective evolutionary algorithm (MOEA) and a deep reinforcement learning (DRL) method, respectively. While the MOEA module is for selecting cities, the DRL module is for planning a Hamiltonian path for these cities. An iterative use of these two modules drives the population toward the Pareto front of MO-OPs. The effectiveness of the proposed method is compared against NSGA-II and NSGA-III on various types of MO-OP instances. Experimental results show that our method performs best on almost all the test instances and has shown strong generalization ability.},
  archive      = {J_TEVC},
  author       = {Wei Liu and Rui Wang and Tao Zhang and Kaiwen Li and Wenhua Li and Hisao Ishibuchi and Xiangke Liao},
  doi          = {10.1109/TEVC.2022.3199045},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1260-1274},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Hybridization of evolutionary algorithm and deep reinforcement learning for multiobjective orienteering optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting implicit and explicit averaging for noisy
optimization. <em>TEVC</em>, <em>27</em>(5), 1250–1259. (<a
href="https://doi.org/10.1109/TEVC.2022.3201090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explicit and implicit averaging are two well-known strategies for noisy optimization. Both strategies can counteract the disruptive effect of noise; however, a critical question remains: which one is more efficient? This question has been raised in many studies, with conflicting preferences and, in some cases, findings. Nevertheless, theoretical findings on the noisy sphere problem with additive Gaussian noise supports the superiority of implicit averaging, which may have had a strong impact on the preference of implicit averaging in more recent evolutionary methods for noisy optimization. This study speculates that the analytically supported superiority of implicit averaging relies on specific features of the noisy sphere problem with additive noise, which cannot be generalized to other problems. It enumerates these features and designs controlled numerical experiments to investigate this potential reliance. Each experiment gradually suppresses one specific feature, and the progress rate is numerically calculated for different values of the sample size given a fixed evaluation budget. Our empirical results indicate that for a wide range of noise strength and evaluation budget per iteration, the more these specific features are suppressed, the more the optimal averaging strategy deviates from implicit toward explicit averaging, which confirms our speculations. Consequently, the optimal sample size, which is regarded as the tradeoff between implicit and explicit averaging, depends on the problem characteristics and should be learned during optimization for maximum efficiency.},
  archive      = {J_TEVC},
  author       = {Ali Ahrari and Saber Elsayed and Ruhul Sarker and Daryl Essam and Carlos A. Coello Coello},
  doi          = {10.1109/TEVC.2022.3201090},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1250-1259},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Revisiting implicit and explicit averaging for noisy optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive reference vector-based interval multiobjective
evolutionary algorithm. <em>TEVC</em>, <em>27</em>(5), 1235–1249. (<a
href="https://doi.org/10.1109/TEVC.2022.3193294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some real-world optimization problems, the parameters of an objective function may be expressed as intervals, such as the benefit of a project and the driving speed of a robot. An optimization problem involving interval parameters and multiple conflicting objectives is termed as a multiobjective optimization problem with interval parameters (IMOP). Few studies have addressed IMOPs compared to deterministic multiobjective optimization at present. In addition, the uncertainty involved in the problems raises higher demands on the diversity and efficiency of an algorithm. Therefore, an adaptive reference vector-based interval multiobjective evolutionary algorithm in the framework of MOEA/D (IMOEA/D) was proposed in this article. First, an IMOP is decomposed into a number of subproblems with interval parameters by setting an interval-valued reference point and constructing interval-valued scalar functions. Following that, an ensemble scheme for evaluating interval individuals is developed via the rank sum ratio method. Finally, reference vectors are adaptively adjusted based on the interval crowding distance to enhance the distribution of a population. The proposed IMOEA/D was tested on 20 benchmark IMOPs as well as a scheduling problem of underwater wireless sensor networks, and compared with four state-of-the-art interval MOEAs. The empirical results demonstrate its superior performance and strong competitiveness.},
  archive      = {J_TEVC},
  author       = {Xingjia Gan and Jing Sun and Dunwei Gong and Dongbao Jia and Hongwei Dai and Zhaoman Zhong},
  doi          = {10.1109/TEVC.2022.3193294},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1235-1249},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An adaptive reference vector-based interval multiobjective evolutionary algorithm},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative double-layer genetic programming hyper-heuristic
for online container terminal truck dispatching. <em>TEVC</em>,
<em>27</em>(5), 1220–1234. (<a
href="https://doi.org/10.1109/TEVC.2022.3209985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a marine container terminal, truck dispatching is a crucial problem that impacts the operation efficiency of the whole port. Traditionally, this problem is formulated as an offline optimization problem, whose solutions are, however, impractical for most real-world scenarios primarily because of the uncertainties of dynamic events in both yard operations and seaside loading–unloading operations. These solutions are either unattractive or infeasible to execute. Herein, for more intelligent handling of these uncertainties and dynamics, a novel cooperative double-layer genetic programming hyper-heuristic (CD-GPHH) is proposed to tackle this challenging online optimization problem. In this new CD-GPHH, a novel scenario genetic programming (GP) approach is added on top of a traditional GP method that chooses among different GP heuristics for different scenarios to facilitate optimized truck dispatching. In contrast to traditional arithmetic GP (AGP) and GP with logic operators (LGP) which only evolve on one population, our CD-GPHH method separates the scenario and the calculation into two populations, which improved the quality of solutions in multiscenario problems while reducing the search space. Experimental results show that our CD-GPHH dominates AGP and LGP in solving a multiscenario function fitting problem as well as a truck dispatching problem in a container terminal.},
  archive      = {J_TEVC},
  author       = {Xinan Chen and Ruibin Bai and Rong Qu and Haibo Dong},
  doi          = {10.1109/TEVC.2022.3209985},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1220-1234},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Cooperative double-layer genetic programming hyper-heuristic for online container terminal truck dispatching},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multistage algorithm for solving multiobjective
optimization problems with multiconstraints. <em>TEVC</em>,
<em>27</em>(5), 1207–1219. (<a
href="https://doi.org/10.1109/TEVC.2022.3224600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are usually multiple constraints in constrained multiobjective optimization. Those constraints reduce the feasible area of the constrained multiobjective optimization problems (CMOPs) and make it difficult for current multiobjective optimization algorithms (CMOEAs) to obtain satisfactory feasible solutions. In order to solve this problem, this article studies the relationship between constraints, then obtains the priority between constraints according to the relationship between the pareto front (PF) of the single constraint and their common PF. Meanwhile, this article proposes a multistage CMOEA and applies this priority, which can save computing resources while helping the algorithm converge. The proposed algorithm completely abandons the feasibility in the early stage to better explore the objective space, and obtains the priority of constraints according to the relationship. Then, the algorithm evaluates a single constraint in the medium stage to further explore the objective space according to this priority, and abandons the evaluation of some less important constraints according to the relationship to save the evaluation times. At the end stage of the algorithm, the feasibility will be fully considered to improve the quality of the solutions obtained in the first two stages, and finally get the solutions with good convergence, feasibility, and diversity. The results on five CMOP suites and three real-world CMOPs show that the algorithm proposed in this article can have strong competitiveness in existing constrained multiobjective optimization.},
  archive      = {J_TEVC},
  author       = {Ruiqing Sun and Juan Zou and Yuan Liu and Shengxiang Yang and Jinhua Zheng},
  doi          = {10.1109/TEVC.2022.3224600},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1207-1219},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A multistage algorithm for solving multiobjective optimization problems with multiconstraints},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Instance-rotation-based surrogate in genetic programming
with brood recombination for dynamic job-shop scheduling. <em>TEVC</em>,
<em>27</em>(5), 1192–1206. (<a
href="https://doi.org/10.1109/TEVC.2022.3180693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) has achieved great success for learning scheduling heuristics in dynamic job-shop scheduling (JSS). In theory, generating a large number of offspring for GP, known as brood recombination, can improve its heuristic generation ability. However, it is time consuming to evaluate extra individuals. Phenotypic characterization-based surrogates with K-nearest neighbors have been successfully used for GP to preselect only promising individuals for real fitness evaluations in dynamic JSS. However, sample individuals used by surrogate are from only the current generation, since the fitness of individuals across generations is not comparable due to the rotation of training instances. The surrogate cannot accurately estimate the fitness of an offspring that is far away from all the limited sample individuals at the current generation. This article proposes an effective instance-rotation-based surrogate to address the above issue. Specifically, the surrogate uses the samples extracted from individuals across multiple generations with different instances. More importantly, we propose a fitness mapping strategy to make the fitness evaluated by different instances comparable. The results show that the GP with brood recombination and the proposed surrogate can significantly improve the quality of scheduling heuristics. The results also reveal that the proposed algorithm has successfully reduced the number of omitted promising offspring due to the higher accuracy of the surrogate. The samples in the new surrogate spread better in the phenotypic space, and the nearest neighbor tends to be closer to the predicted offspring. This makes the estimated fitness more accurate.},
  archive      = {J_TEVC},
  author       = {Fangfang Zhang and Yi Mei and Su Nguyen and Kay Chen Tan and Mengjie Zhang},
  doi          = {10.1109/TEVC.2022.3180693},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1192-1206},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Instance-rotation-based surrogate in genetic programming with brood recombination for dynamic job-shop scheduling},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relation between objective space normalization and weight
vector scaling in decomposition-based multiobjective evolutionary
algorithms. <em>TEVC</em>, <em>27</em>(5), 1177–1191. (<a
href="https://doi.org/10.1109/TEVC.2022.3192100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world multiobjective optimization problems (MOPs) usually have conflicting and differently scaled objectives. To deal with such problems, objective space normalization is widely used in the multiobjective evolutionary algorithm (MOEA) design, especially, in the design of decomposition-based MOEAs. It has been demonstrated that uniformly distributed solutions can be obtained for badly scaled MOPs by decomposition-based MOEAs with objective space normalization. Recently, weight vector scaling has also been used for badly scaled MOPs. In some studies, it was argued that weight vector scaling and objective space normalization are essentially the same when applied to decomposition-based MOEAs. In this article, we theoretically and empirically show the relation between objective space normalization and weight vector scaling. Our results demonstrate that similarities and differences between the two methods depend on the choice of a scalarizing function. How the choice between normalization and weight vector scaling affects decomposition-based MOEAs with solution assignment mechanisms is also analyzed.},
  archive      = {J_TEVC},
  author       = {Linjun He and Ke Shang and Yang Nan and Hisao Ishibuchi and Dipti Srinivasan},
  doi          = {10.1109/TEVC.2022.3192100},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1177-1191},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Relation between objective space normalization and weight vector scaling in decomposition-based multiobjective evolutionary algorithms},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Surrogate-assisted evolutionary q-learning for black-box
dynamic time-linkage optimization problems. <em>TEVC</em>,
<em>27</em>(5), 1162–1176. (<a
href="https://doi.org/10.1109/TEVC.2022.3179256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic time-linkage optimization problems (DTPs) are special dynamic optimization problems (DOPs) with the time-linkage property. The environment of DTPs changes not only over time but also depends on the previous applied solutions. DTPs are hardly solved by existing dynamic evolutionary algorithms because they ignore the time-linkage property. In fact, they can be viewed as multiple decision-making problems and solved by reinforcement learning (RL). However, only some discrete DTPs are solved by RL-based evolutionary optimization algorithms with the assumption of observable objective functions. In this work, we propose a dynamic evolutionary optimization algorithm using surrogate-assisted $Q$ -learning for continuous black-box DTPs. To observe the states of black-box DTPs, the state extraction and prediction methods are applied after the search process at each time step. Based on the learned information, a surrogate-assisted $Q$ -learning is introduced to evaluate and select candidate solutions in the continuous decision space in a long-term consideration. We evaluate the components of our proposed algorithm on various benchmark problems to study their behaviors. Results of comparative experiments indicate that the proposed algorithm outperforms other compared algorithms and performs robustly on DTPs with up to 30 decision variables and different dynamic changes.},
  archive      = {J_TEVC},
  author       = {Tuo Zhang and Handing Wang and Bo Yuan and Yaochu Jin and Xin Yao},
  doi          = {10.1109/TEVC.2022.3179256},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {5},
  pages        = {1162-1176},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Surrogate-assisted evolutionary Q-learning for black-box dynamic time-linkage optimization problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HV-net: Hypervolume approximation based on DeepSets.
<em>TEVC</em>, <em>27</em>(4), 1154–1160. (<a
href="https://doi.org/10.1109/TEVC.2022.3181306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this letter, we propose HV-Net, a new method for hypervolume approximation in evolutionary multiobjective optimization. The basic idea of HV-Net is to use DeepSets, a deep neural network with permutation invariant property, to approximate the hypervolume of a nondominated solution set. The input of HV-Net is a nondominated solution set in the objective space, and the output is an approximated hypervolume value of this solution set. The performance of HV-Net is evaluated through computational experiments by comparing it with two commonly used hypervolume approximation methods (i.e., point-based method and line-based method). Our experimental results show that HV-Net outperforms the other two methods in terms of both the approximation error and the runtime, which shows the potential of using deep learning techniques for hypervolume approximation.},
  archive      = {J_TEVC},
  author       = {Ke Shang and Weiyu Chen and Weiduo Liao and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2022.3181306},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1154-1160},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {HV-net: Hypervolume approximation based on DeepSets},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effects of archive size on computation time and solution
quality for multiobjective optimization. <em>TEVC</em>, <em>27</em>(4),
1145–1153. (<a href="https://doi.org/10.1109/TEVC.2022.3219521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An unbounded external archive has been used to store all nondominated solutions found by an evolutionary multiobjective optimization algorithm in some studies. It has been shown that a selected solution subset from the stored solutions is often better than the final population. However, the use of the unbounded archive is not always realistic. When the number of examined solutions is huge, we must prespecify the archive size. In this study, we examine the effects of the archive size on three aspects: 1) the quality of the selected final solution set; 2) the total computation time for the archive maintenance and the final solution set selection; and 3) the required memory size. Unsurprisingly, the increase of the archive size improves the final solution set quality. Interestingly, the total computation time of a medium-size archive is much larger than that of a small-size archive and a huge-size archive (e.g., an unbounded archive). To decrease the computation time, we examine two ideas: 1) periodical archive update and 2) archiving only in later generations. Compared with updating the archive at every generation, the first idea can obtain almost the same final solution set quality using a much shorter computation time at the cost of a slight increase of the memory size. The second idea drastically decreases the computation time at the cost of a slight deterioration of the final solution set quality. Based on our experimental results, some suggestions are given about how to appropriately choose an archiving strategy and an archive size.},
  archive      = {J_TEVC},
  author       = {Tianye Shu and Ke Shang and Hisao Ishibuchi and Yang Nan},
  doi          = {10.1109/TEVC.2022.3219521},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1145-1153},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Effects of archive size on computation time and solution quality for multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting overlapping areas in unbalanced high-dimensional
data using neighborhood rough set and genetic programming.
<em>TEVC</em>, <em>27</em>(4), 1130–1144. (<a
href="https://doi.org/10.1109/TEVC.2022.3203862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unbalanced classification has attracted widespread interest because of its broad applications. However, due to mainly the uneven class distribution, constructed classifiers are usually biased toward the majority class, and thereby perform terribly on the minority class. Unfortunately, the minority class is often the class of interest in many real-world applications. High dimensionality often further degrades the classification performance, making it more complicated to address the class imbalance issue. Genetic programming (GP) has been applied to construct classifiers, which can simultaneously select good-quality features to improve the classification performance. To handle the class imbalance issue, cost-sensitive GP classifiers treat the minority class as being more important than the majority class, but this may cause an accuracy decrease in overlapping areas where the prior probabilities of the two classes are almost the same. To date, most cost-sensitive classification methods have not been specifically investigated how the impacts of overlapping areas on cost-sensitive classifiers can be avoided. In this study, we propose a new cost-sensitive GP method, where rough set theory is employed to detect overlapping areas before training cost-sensitive classifiers for classification with unbalanced high-dimensional data. The proposed method is compared with 46 popular classification methods, including 10 GP methods and 36 non-GP methods on 14 datasets that are unbalanced and high dimensional. The experimental results indicate that the proposed method performs better than the compared methods in almost all cases.},
  archive      = {J_TEVC},
  author       = {Wenbin Pei and Bing Xue and Lin Shang and Mengjie Zhang},
  doi          = {10.1109/TEVC.2022.3203862},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1130-1144},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Detecting overlapping areas in unbalanced high-dimensional data using neighborhood rough set and genetic programming},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiobjective differential evolution with speciation for
constrained multimodal multiobjective optimization. <em>TEVC</em>,
<em>27</em>(4), 1115–1129. (<a
href="https://doi.org/10.1109/TEVC.2022.3194253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel differential evolution algorithm for solving constrained multimodal multiobjective optimization problems (CMMOPs), which may have multiple feasible Pareto-optimal solutions with identical objective vectors. In CMMOPs, due to the coexistence of multimodality and constraints, it is difficult for current algorithms to perform well in both objective and decision spaces. The proposed algorithm uses the speciation mechanism to induce niches preserving more feasible Pareto-optimal solutions and adopts an improved environment selection criterion to enhance diversity. The algorithm can not only obtain feasible solutions but also retain more well-distributed feasible Pareto-optimal solutions. Moreover, a set of constrained multimodal multiobjective test functions is developed. All these test functions have multimodal characteristics and contain multiple constraints. Meanwhile, this article proposes a new indicator, which comprehensively considers the feasibility, convergence, and diversity of a solution set. The effectiveness of the proposed method is verified by comparing with the state-of-the-art algorithms on both test functions and real-world location-selection problem.},
  archive      = {J_TEVC},
  author       = {Jing Liang and Hongyu Lin and Caitong Yue and Kunjie Yu and Ying Guo and Kangjia Qiao},
  doi          = {10.1109/TEVC.2022.3194253},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1115-1129},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective differential evolution with speciation for constrained multimodal multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic in vivo computation for learning-based
nanobiosensing in time-varying biological landscapes. <em>TEVC</em>,
<em>27</em>(4), 1100–1114. (<a
href="https://doi.org/10.1109/TEVC.2022.3198086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have recently proposed a framework of in vivo computation (IVC) which transforms the early tumor sensing problem into a computational problem. In the framework, a tumor-triggered biological gradient field (BGF) guides the swarm-intelligence-assisted targeting process, where externally manipulable and trackable magnetic nanorobots act as computational agents for the optimization procedure. As BGF can be viewed as an objective function which is utilized to define the fitness landscape for the agents, the inherent attributes of BGF are critical to the IVC process. All our previous investigations are based on the hypothesis that the BGF landscape remains time invariant during the tumor-targeting process, which results in a static function optimization problem. However, the properties of internal environment, such as the flow state of body fluid, will naturally lead to time-dependent variation of BGF, which means that the targeting process should be modeled as a dynamic function optimization problem. Based on this consideration, we focus on dynamic IVC by considering different variation patterns of BGF in this article. Two computational intelligence strategies named “swarm-based learning” and “individual-based learning” are proposed for dealing with the turbulence of the fitness estimation caused by the BGF variation. The in silico experiments and statistical results demonstrate the effectiveness of the proposed strategies. In addition, the above process is conducted in a 3-D search space, where the tumor vascular network is generated by an invasion percolation algorithm, which is more realistic compared to the 2-D search space in our previous works.},
  archive      = {J_TEVC},
  author       = {Shaolong Shi and Yifan Chen and Jurong Ding and Qiang Liu and Qingfu Zhang},
  doi          = {10.1109/TEVC.2022.3198086},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1100-1114},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Dynamic in vivo computation for learning-based nanobiosensing in time-varying biological landscapes},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A performance indicator-based infill criterion for expensive
multi-/many-objective optimization. <em>TEVC</em>, <em>27</em>(4),
1085–1099. (<a href="https://doi.org/10.1109/TEVC.2023.3237605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In surrogate-assisted multi-/many-objective evolutionary optimization, each solution normally has an approximated value on each objective, resulting in increased difficulties in selecting solutions for expensive objective evaluations due to complicated tradeoff between different objectives and accumulated uncertainty in the approximation of the objective functions. Thus, it is highly challenging to design an efficient model management strategy for surrogate-assisted expensive multi-/many-objective optimization. In this article, a surrogate model is built for each objective function, based on which a set of promising candidate solutions are found. Additionally, a Gaussian process model is constructed to approximate a newly designed performance indicator measuring both convergence and diversity properties of individual solutions. Finally, the solution of the found candidate solutions having the maximum expected improvement in terms of the performance indicator is selected for evaluation using the expensive objective functions. Comparative experiments are conducted on 3-, 5-, and 10-objective DTLZ, WFG, and MaF test functions, as well as two real-world applications. The experimental results show that the proposed method is competitive compared to five state-of-the-art surrogate-assisted evolutionary algorithms for expensive multi-/many-objective optimization.},
  archive      = {J_TEVC},
  author       = {Shufen Qin and Chaoli Sun and Qiqi Liu and Yaochu Jin},
  doi          = {10.1109/TEVC.2023.3237605},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1085-1099},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A performance indicator-based infill criterion for expensive multi-/Many-objective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated design of metaheuristics using reinforcement
learning within a novel general search framework. <em>TEVC</em>,
<em>27</em>(4), 1072–1084. (<a
href="https://doi.org/10.1109/TEVC.2022.3197298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms have been investigated intensively to address highly complex combinatorial optimization problems. However, most metaheuristic algorithms have been designed manually by researchers of different expertise without a consistent framework. This article proposes a general search framework (GSF) to formulate in a unified way a range of different metaheuristics. With generic algorithmic components, including selection heuristics and evolution operators, the unified GSF aims to serve as the basis of analyzing algorithmic components for automated algorithm design. With the established new GSF, two reinforcement learning (RL)-based methods, deep $Q$ -network based and proximal policy optimization-based methods, have been developed to automatically design a new general population-based algorithm. The proposed RL-based methods are able to intelligently select and combine appropriate algorithmic components during different stages of the optimization process. The effectiveness and generalization of the proposed RL-based methods are validated comprehensively across different benchmark instances of the capacitated vehicle routing problem with time windows. This study contributes to making a key step toward automated algorithm design with a general framework supporting fundamental analysis by effective machine learning.},
  archive      = {J_TEVC},
  author       = {Wenjie Yi and Rong Qu and Licheng Jiao and Ben Niu},
  doi          = {10.1109/TEVC.2022.3197298},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1072-1084},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Automated design of metaheuristics using reinforcement learning within a novel general search framework},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConCS: A continual classifier system for continual learning
of multiple boolean problems. <em>TEVC</em>, <em>27</em>(4), 1057–1071.
(<a href="https://doi.org/10.1109/TEVC.2022.3210872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human intelligence can simultaneously process many tasks with the ability to accumulate and reuse knowledge. Recent advances in artificial intelligence, such as transfer, multitask, and layered learning, seek to replicate these abilities. However, humans must specify the task order, which is often difficult particularly with uncertain domain knowledge. This work introduces a continual-learning system (ConCS), such that given an open-ended set of problems once each is solved its solution can contribute to solving further problems. The hypothesis is that the evolutionary computation approach of learning classifier systems (LCSs) can form this system due to its niched, cooperative rules. A collaboration of parallel LCSs identifies sets of patterns linking features to classes that can be reused in related problems automatically. Results from distinct Boolean and integer classification problems, with varying interrelations, show that by combining knowledge from simple problems, complex problems can be solved at increasing scales. 100\% accuracy is achieved for the problems tested regardless of the order of task presentation. This includes intractable problems for previous approaches, e.g., $n$ -bit Majority-on. A major contribution is that human guidance is now unnecessary to determine the task learning order. Furthermore, the system automatically generates the curricula for learning the most difficult tasks.},
  archive      = {J_TEVC},
  author       = {Trung B. Nguyen and Will N. Browne and Mengjie Zhang},
  doi          = {10.1109/TEVC.2022.3210872},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1057-1071},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {ConCS: A continual classifier system for continual learning of multiple boolean problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary multitasking for optimization based on
generative strategies. <em>TEVC</em>, <em>27</em>(4), 1042–1056. (<a
href="https://doi.org/10.1109/TEVC.2022.3189029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking (EMT) is one of the emerging topics in evolutionary computation. EMT can solve multiple related optimization tasks simultaneously and enhance the optimization of each task via knowledge sharing among tasks. Many EMT algorithms have been proposed and achieved success in various problems, yet EMT for multiobjective optimization remains a big challenge. The existing multiobjective EMT algorithms tend to suffer from slow convergence and difficulty in generating high-quality knowledge. To alleviate these issues, this article proposes a new EMT algorithm, namely, EMT-GS for multiobjective optimization based on two generative strategies. Particularly, generative adversarial networks (GANs) and inertial differential evolution (IDE) are introduced to generate transferable knowledge and offspring, respectively. A GAN is trained periodically for each source-target task pair, based on which helpful knowledge is generated from the source task and transferred to boost the solving of the target task. To accelerate the population convergence, the IDE strategy is put forward to generate offspring in a promising direction according to the individuals from the previous generation and the transferred knowledge. The performance of EMT-GS is validated on three multitasking multiobjective benchmark problems. The experimental results highlight the excellent competitiveness of EMT-GS compared to other state-of-the-art multiobjective EMT algorithms.},
  archive      = {J_TEVC},
  author       = {Zhengping Liang and Yingmiao Zhu and Xiyu Wang and Zhi Li and Zexuan Zhu},
  doi          = {10.1109/TEVC.2022.3189029},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1042-1056},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multitasking for optimization based on generative strategies},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic variable reduction. <em>TEVC</em>, <em>27</em>(4),
1027–1041. (<a href="https://doi.org/10.1109/TEVC.2022.3199413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variable reduction strategy (VRS) is an effective method to accelerate the optimization process of evolutionary algorithms (EAs) by simplifying the corresponding optimization problems. Unfortunately, the VRS is manually realized in a trial-and-error manner currently. To boost the efficiency of VRS and enable a more extensive application, we propose a variable reduction optimization problem (VROP) to represent a decision space with the smallest sets of variables. Thereafter, a heuristic rule-based automatic variable reduction algorithm (AVRA) is designed to address the VROP. AVRA sequentially reduces variables by considering several sophisticated designed heuristic rules, which search for a variable that can be utilized to represent as many variables as possible and that can be represented by the smallest set of variables possible. With AVRA, the decision variables of an optimization problem can be automatically grouped into reduced variables and core variables, where core variables can represent reduced variables and the entire decision space. During the optimization process, we only need to search the core variables to optimize the problem. Therefore, the dimensionality of the decision space can be reduced by AVRA, subsequently, simplifying the complexity of the problem and improving the search efficiency of EAs. To testify the effectiveness of AVRA, we blend AVRA with several promising EAs to solve two types of challenging problems: 1) continuous equality-constrained optimization problems and 2) nonlinear equations systems. Extensive experiments verify that an EA with AVRA outperforms the standard EA.},
  archive      = {J_TEVC},
  author       = {Aijuan Song and Guohua Wu and Ponnuthurai Nagaratnam Suganthan and Witold Pedrycz},
  doi          = {10.1109/TEVC.2022.3199413},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1027-1041},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Automatic variable reduction},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multitask particle swarm optimization with dynamic on-demand
allocation. <em>TEVC</em>, <em>27</em>(4), 1015–1026. (<a
href="https://doi.org/10.1109/TEVC.2022.3187512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multitask optimization aims to solve multiple optimization problems in parallel utilizing a single population. However, if the computing resources are limited, allocating the same computing resources to different tasks will cause resource waste and make complex tasks difficult to converge to the optimal solution. To address this issue, a multitask particle swarm optimization with a dynamic on-demand allocation strategy (MTPSO-DA) is proposed to dynamically allocate computing resources. First, a task complexity index, based on convergence rate and contribution rate, is designed to evaluate the difficulty of solving different tasks. Then, the complexity of different tasks can be evaluated in real time. Second, the skill factor of the particle is extended to a time-varying matrix according to the task complexity index. Then, the recently captured feedback is stored to determine the computational resource demands of the task. Third, an on-demand allocation strategy, based on the time-varying matrix, is developed to obtain the skill factor probability vector utilizing the attenuation accumulation method. Then, computing resources can be allocated dynamically among different tasks. Finally, some comparative experiments are conducted based on the benchmark problem to evaluate the superiority of the MTPSO-DA algorithm. The results indicate that the proposed MTPSO-DA algorithm can achieve dynamic resource allocation.},
  archive      = {J_TEVC},
  author       = {Honggui Han and Xing Bai and Ying Hou and Junfei Qiao},
  doi          = {10.1109/TEVC.2022.3187512},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1015-1026},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multitask particle swarm optimization with dynamic on-demand allocation},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient way of introducing gender into evolutionary
algorithms. <em>TEVC</em>, <em>27</em>(4), 1005–1014. (<a
href="https://doi.org/10.1109/TEVC.2022.3192481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms have been extensively used for numerous optimization problems with great success in the past years. They mimic nature’s process of evolution to find solutions to a large range of mathematical problems. In this work a new strategy is suggested to introduce gender, defined by a characteristic of an individual, that is easy to implement in evolutionary algorithms, as long as they are based on evaluating a fitness function. The new method outperforms comparable evolutionary approaches without gender for all standard test problems considered. The present study shows that with increasing problem complexity the performance of this gender variant increases to more than double the success rates while keeping the computational effort at about the same level and still being clearly better for easy problems. Additionally, in the mean, the new method results in better fitness values for all presented cases.},
  archive      = {J_TEVC},
  author       = {Christian Kasten and Julian Fahr and Markus Klein},
  doi          = {10.1109/TEVC.2022.3192481},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {1005-1014},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An efficient way of introducing gender into evolutionary algorithms},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domination-based selection and shift-based density
estimation for constrained multiobjective optimization. <em>TEVC</em>,
<em>27</em>(4), 993–1004. (<a
href="https://doi.org/10.1109/TEVC.2022.3190401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing constraints and objective functions in constrained evolutionary multiobjective optimization is not an easy task. Overemphasis on constraints satisfaction may easily lead to the search to get stuck in local optimal regions, and overemphasis on objectives optimization may lead to substantial search resources wasted on infeasible regions. This article proposes a constrained multiobjective optimization algorithm, called CMOEA-SDE, aiming to achieve a good balance between the above two issues. To do so, CMOEA-SDE presents a strictly constrained dominance relation and a constrained shift-based density estimation strategy. Specifically, the former defines a new dominance relation that considers both constraint satisfaction and the objective functions. It favors good feasible solutions but still leaves room for infeasible solutions to be selected. Unlike most density estimation methods, which only consider the diversity of solutions, our shift-based density estimator covers both the feasibility and the diversity of solutions. That is, our estimator shifts the solutions’ positions based on the extent of the constraints they violate so that solutions violating constraints more severely are shifted to crowded areas, thus being eliminated early. Systematic experiments were conducted on four benchmark test suites and six real-world constrained multiobjective optimization problems. The experimental results suggest that the proposed algorithm can achieve very competitive performance against state-of-the-art constrained multiobjective evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Jinlong Zhou and Yinggui Zhang and Jinhua Zheng and Miqing Li},
  doi          = {10.1109/TEVC.2022.3190401},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {993-1004},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Domination-based selection and shift-based density estimation for constrained multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequency fitness assignment: Optimization without bias for
good solutions can be efficient. <em>TEVC</em>, <em>27</em>(4), 980–992.
(<a href="https://doi.org/10.1109/TEVC.2022.3191698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fitness assignment process transforms the features (such as the objective value) of a candidate solution to a scalar fitness, which then is the basis for selection. Under frequency fitness assignment (FFA), the fitness corresponding to an objective value is its encounter frequency in selection steps and is subject to minimization. FFA creates algorithms that are not biased toward better solutions and are invariant under all injective transformations of the objective function value. We investigate the impact of FFA on the performance of two theory inspired, state-of-the-art evolutionary algorithms, the Greedy (2+1) GA and the self-adjusting $(1+(\lambda,\lambda))$ GA. FFA improves their performance significantly on some problems that are hard for them. In our experiments, one FFA-based algorithm exhibited mean runtimes that appear to be polynomial on the theory-based benchmark problems in our study, including traps, jumps, and plateaus. We propose two hybrid approaches that use both direct and FFA-based optimization and find that they perform well. All FFA-based algorithms also perform better on satisfiability problems than any of the pure algorithm variants.},
  archive      = {J_TEVC},
  author       = {Thomas Weise and Zhize Wu and Xinlu Li and Yan Chen and Jörg Lässig},
  doi          = {10.1109/TEVC.2022.3191698},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {980-992},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Frequency fitness assignment: Optimization without bias for good solutions can be efficient},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gene targeting differential evolution: A simple and
efficient method for large-scale optimization. <em>TEVC</em>,
<em>27</em>(4), 964–979. (<a
href="https://doi.org/10.1109/TEVC.2022.3185665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale optimization problems (LSOPs) are challenging because the algorithm is difficult in balancing too many dimensions and in escaping from trapped bottleneck dimensions. To improve solutions, this article introduces targeted modification to the certain values in the bottleneck dimensions. Analogous to gene targeting (GT) in biotechnology, we experiment on targeting the specific genes in the candidate solution to improve its trait in differential evolution (DE). We propose a simple and efficient method, called GT-based DE (GTDE), to solve LSOPs. In the algorithm design, a simple GT-based modification is developed to perform on the best individual, comprising probabilistically targeting the location of bottleneck dimensions, constructing a homologous targeting vector, and inserting the targeting vector into the best individual. In this way, all the bottleneck dimensions of the best individual can be probabilistically targeted and modified to break the bottleneck and to provide global guidance for more optimal evolution. Note that the GT is only performed on the globally best individual and is just carried out as a simple operator that is added to the standard DE. Experimental studies compare the GTDE with some other state-of-the-art large-scale optimization algorithms, including the winners of CEC2010, CEC2012, CEC2013, and CEC2018 competitions on large-scale optimization. The results show that the GTDE is efficient and performs better than or at least comparable to the others in solving LSOPs.},
  archive      = {J_TEVC},
  author       = {Zi-Jia Wang and Jun-Rong Jian and Zhi-Hui Zhan and Yun Li and Sam Kwong and Jun Zhang},
  doi          = {10.1109/TEVC.2022.3185665},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {964-979},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Gene targeting differential evolution: A simple and efficient method for large-scale optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature extraction for recommendation of constrained
multiobjective evolutionary algorithms. <em>TEVC</em>, <em>27</em>(4),
949–963. (<a href="https://doi.org/10.1109/TEVC.2022.3186667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolutionary algorithm recommendation is catching increasing attention when solving practical application problems since different algorithms often perform differently on different problems. To achieve the algorithm recommendation, extracting effective features to accurately characterize the problems is necessary, which is related to the feature extraction problem. So far, most feature extraction methods focus on single-objective optimization problems, and only a few studies are conducted on multiobjective optimization problems and constrained optimization problems, let alone constrained multiobjective optimization problems (CMOPs) that are widely encountered in the real world. To fill the gap, this article proposes an evolution-based constrained multiobjective feature extraction method (ECMOFE), in which the information generated in the evolutionary process is leveraged to form the feature matrix. To be specific, we create two populations to, respectively, optimize constraints and objectives for some generations. Furthermore, two complementary evolutionary operators are used to generate offspring for each population. In the environmental selection, the successful rate of offspring individuals generated by each operator of each population is recorded to form the feature matrix. Then, a dimension reduction method is designed to compress the size of the feature matrix. By the above process, the feature vector that can reflect the global relationship between constraints and objectives and the difficulty of the CMOP is formed. Based on the formed features, several algorithm recommendation methods are built on the basis of classifiers. The results based on multiple metrics show the effectiveness of the proposed ECMOFE.},
  archive      = {J_TEVC},
  author       = {Kangjia Qiao and Kunjie Yu and Boyang Qu and Jing Liang and Caitong Yue and Xuanxuan Ban},
  doi          = {10.1109/TEVC.2022.3186667},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {949-963},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Feature extraction for recommendation of constrained multiobjective evolutionary algorithms},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Theory of (1+1) ES on SPHERE revisited. <em>TEVC</em>,
<em>27</em>(4), 938–948. (<a
href="https://doi.org/10.1109/TEVC.2022.3217524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of evolutionary algorithms on continuous space gravitates around the evolution strategy with one individual, adaptive mutation, and elitist selection, optimizing the symmetric, quadratic SPHERE function. The classic, normal mutation theory consists of three main building-blocks: 1) a two-term formula for the local (constant mutation) expected progress; 2) an exponential formula for the global behavior of the (adaptive mutation) algorithm; and 3) linear convergence time with respect to both space dimension $n$ and (logarithm of) initial distance to optimum. We show that the three main results still hold if we replace the normal mutation with uniform inside the sphere and also with the sum of two uniforms. That makes the case for an important conclusion: the linear convergence time of the algorithm is not a consequence of the normal mutation, but of the elitist selection and 1/5 success rule. A simplified version of the 1/5-rule allows also for an intuitive representation of the algorithm, as a sequence of constant-mutation, independent, and identical (expected) length cycles.},
  archive      = {J_TEVC},
  author       = {Alexandru Agapie and Ovidiu Solomon and Luiza Bădin},
  doi          = {10.1109/TEVC.2022.3217524},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {938-948},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Theory of (1+1) ES on SPHERE revisited},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A localized high-fidelity-dominance-based many-objective
evolutionary algorithm. <em>TEVC</em>, <em>27</em>(4), 923–937. (<a
href="https://doi.org/10.1109/TEVC.2022.3188064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practicality of Pareto-dominance in solving many-objective optimization problems becomes questionable due to its inability to factor the critical human decision-making (HDM) elements, including the number of better objectives, the degree of betterment in objectives, and objectives’ relative preference. Relevant dominance principles are recently proposed to incorporate the first two HDM elements, often with the need for new tunable parameters. This article proposes a high-fidelity-dominance principle that factors all the three HDM elements, explicitly and simultaneously, and without requiring tuning of any parameter. This principle has been implemented in a reference-vector-based framework, leading to a computationally efficient many-objective evolutionary algorithm (MaOEA), namely, localized high-fidelity-dominance-based EA (LHFiD). Critically, LHFiD also has an inbuilt mechanism for on-the-fly determination of the timing for: 1) intermittent Nadir point estimation that enables faster convergence and 2) its self-termination that bears practically utility. This article is based on an extensive study involving 41 912 experiments, in which the proposed LHFiD approach is compared with the existing competitive MaOEAs. This article reports statistically better performance in about 60\% instances, making it practical and worthy of further investigation and application.},
  archive      = {J_TEVC},
  author       = {Dhish Kumar Saxena and Sukrit Mittal and Sarang Kapoor and Kalyanmoy Deb},
  doi          = {10.1109/TEVC.2022.3188064},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {923-937},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A localized high-fidelity-dominance-based many-objective evolutionary algorithm},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Objective-constraint mutual-guided surrogate-based particle
swarm optimization for expensive constrained multimodal problems.
<em>TEVC</em>, <em>27</em>(4), 908–922. (<a
href="https://doi.org/10.1109/TEVC.2022.3182810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expensive constraint multimodal optimization problems (ECMMOPs) have such characteristics as expensive objectives and constraints, and multiple optimal modalities simultaneously, which pose severe challenges to evolutionary optimization methods. This article studies an objective-constraint mutual-guided surrogate-assisted particle swarm optimization algorithm for the kind of problem, aiming to discover multiple competing feasible optimal solutions at a lower calculation cost. The algorithm designs first a new two-layer cooperative surrogate model framework based on heterogeneous database to effectively adjust the prediction accuracies of objective surrogates and constraint surrogates on different search regions. An objective-constraint mutual-guided partial evaluation strategy (O-C-PES) is developed to generate high-quality infilling samples for objective and constraint surrogates, respectively, based on which the number of unnecessary real evaluations can be significantly reduced. Moreover, a position feature-guided hybrid update mechanism (PF-HUM) is proposed to find more optimal solutions by searching excellent infeasible and feasible areas at the same time, and a feasible ratio-driven local search (FR-LS) strategy is proposed to improve the algorithm’s exploitation. Compared with four existing surrogate-assisted evolutionary algorithms (EAs) and one constraint multimodal EAs on 21 benchmark problems and three engineering instances, experiment results show that the proposed algorithm can simultaneously obtain multiple highly-competitive feasible optimal solutions with less computational cost.},
  archive      = {J_TEVC},
  author       = {Yong Zhang and Xin-Fang Ji and Xiao-Zhi Gao and Dun-Wei Gong and Xiao-Yan Sun},
  doi          = {10.1109/TEVC.2022.3182810},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {908-922},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Objective-constraint mutual-guided surrogate-based particle swarm optimization for expensive constrained multimodal problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discretization-based feature selection as a bilevel
optimization problem. <em>TEVC</em>, <em>27</em>(4), 893–907. (<a
href="https://doi.org/10.1109/TEVC.2022.3192113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discretization-based feature selection (DBFS) approaches have shown interesting results when using several metaheuristic algorithms, such as particle swarm optimization (PSO), genetic algorithm (GA), ant colony optimization (ACO), etc. However, these methods share the same shortcoming which consists in encoding the problem solution as a sequence of cut-points. From this cut-points vector, the decision of deleting or selecting any feature is induced. Indeed, the number of generated cut-points varies from one feature to another. Thus, the higher the number of cut-points, the higher the probability of selecting the considered feature; and vice versa. This fact leads to the deletion of possibly important features having a single or a low number of cut-points, such as the infection rate, the glycemia level, and the blood pressure. In order to solve the issue of the dependency relation between the feature selection (or removal) event and the number of its generated potential cut-points, we propose to model the DBFS task as a bilevel optimization problem and then solve it using an improved version of an existing co-evolutionary algorithm, named I-CEMBA. The latter ensures the variation of the number of features during the migration process in order to deal with the multimodality aspect. The resulting algorithm, termed bilevel discretization-based feature selection (Bi-DFS), performs selection at the upper level while discretization is done at the lower level. The experimental results on several high-dimensional datasets show that Bi-DFS outperforms relevant state-of-the-art methods in terms of classification accuracy, generalization ability, and feature selection bias.},
  archive      = {J_TEVC},
  author       = {Rihab Said and Maha Elarbi and Slim Bechikh and Carlos Artemio Coello Coello and Lamjed Ben Said},
  doi          = {10.1109/TEVC.2022.3192113},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {893-907},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Discretization-based feature selection as a bilevel optimization problem},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Island transpeciation: A co-evolutionary neural architecture
search, applied to country-scale air-quality forecasting. <em>TEVC</em>,
<em>27</em>(4), 878–892. (<a
href="https://doi.org/10.1109/TEVC.2022.3189500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution causes around 400 000 premature deaths per year in Europe due to Particulate Matter, nitrogen oxides, and ground-level ozone pollutants. Multiple-input multiple-output nonlinear auto-regressive exogenous deep neural networks are frequently used to predict a day before, air-quality pollution incidents, at a country scale. With complexity and data sizes increasing, finding performant models becomes harder. We propose island transpeciation to optimize hyperparameters and architectures. Unlike using a single optimizer, island transpeciation combines results from multiple optimizers, to consistently provide excellent performance. Moreover, we show that island transpeciation outperforms random model search and other previous modeling efforts. Island transpeciation is a neural architecture search that uses co-evolution (genes), to combine (transpeciation) populations of incompatible optimizers (species) organized in island formations. In island transpeciation, architecture search is parallelized and utilizes a distributed pool of hardware resources. We have successfully used these techniques to predict next-day ozone concentrations across the Belgian territory.},
  archive      = {J_TEVC},
  author       = {Konstantinos Theodorakos and Oscar Mauricio Agudelo and Joachim Schreurs and Johan A. K. Suykens and Bart De Moor},
  doi          = {10.1109/TEVC.2022.3189500},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {878-892},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Island transpeciation: A co-evolutionary neural architecture search, applied to country-scale air-quality forecasting},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary multitasking for large-scale multiobjective
optimization. <em>TEVC</em>, <em>27</em>(4), 863–877. (<a
href="https://doi.org/10.1109/TEVC.2022.3166482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary transfer optimization (ETO) has been becoming a hot research topic in the field of evolutionary computation, which is based on the fact that knowledge learning and transfer across the related optimization exercises can improve the efficiency of others. However, rare studies employ ETO to solve large-scale multiobjective optimization problems (LMOPs). To fill this research gap, this article proposes a new multitasking ETO algorithm via a powerful transfer learning model to simultaneously solve multiple LMOPs. In particular, inspired by adversarial domain adaptation in transfer learning, a discriminative reconstruction network (DRN) model (containing an encoder, a decoder, and a classifier) is created for each LMOP. At each generation, the DRN is trained by the currently obtained nondominated solutions for all LMOPs via backpropagation with gradient descent. With this well-trained DRN model, the proposed algorithm can transfer the solutions of source LMOPs directly to the target LMOP for assisting its optimization, can evaluate the correlation between the source and target LMOPs to control the transfer of solutions, and can learn a dimensional-reduced Pareto-optimal subspace of the target LMOP to improve the efficiency of transfer optimization in the large-scale search space. Moreover, we propose a real-world multitasking LMOP suite to simulate the training of deep neural networks (DNNs) on multiple different classification tasks. Finally, the effectiveness of the proposed algorithm has been validated in this real-world problem suite and the other two synthetic problem suites.},
  archive      = {J_TEVC},
  author       = {Songbai Liu and Qiuzhen Lin and Liang Feng and Ka-Chun Wong and Kay Chen Tan},
  doi          = {10.1109/TEVC.2022.3166482},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {863-877},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multitasking for large-scale multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigating unfairness via evolutionary multiobjective
ensemble learning. <em>TEVC</em>, <em>27</em>(4), 848–862. (<a
href="https://doi.org/10.1109/TEVC.2022.3209544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature of mitigating unfairness in machine learning (ML), many fairness measures are designed to evaluate predictions of learning models and also utilized to guide the training of fair models. It has been theoretically and empirically shown that there exist conflicts and inconsistencies among accuracy and multiple fairness measures. Optimizing one or several fairness measures may sacrifice or deteriorate other measures. Two key questions should be considered: 1) how to simultaneously optimize accuracy and multiple fairness measures and 2) how to optimize all the considered fairness measures more effectively. In this article, we view the mitigating unfairness problem as a multiobjective learning problem, considering the conflicts among fairness measures. A multiobjective evolutionary learning framework is used to simultaneously optimize several metrics (including accuracy and multiple fairness measures) of ML models. Then, ensembles are constructed based on the learning models in order to automatically balance different metrics. Empirical results on eight well-known datasets demonstrate that compared with the state-of-the-art approaches for mitigating unfairness, our proposed algorithm can provide decision makers with better tradeoffs among accuracy and multiple fairness metrics. Furthermore, the high-quality models generated by the framework can be used to construct an ensemble to automatically achieve a better tradeoff among all the considered fairness metrics than other ensemble methods.},
  archive      = {J_TEVC},
  author       = {Qingquan Zhang and Jialin Liu and Zeqi Zhang and Junyi Wen and Bifei Mao and Xin Yao},
  doi          = {10.1109/TEVC.2022.3209544},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {848-862},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Mitigating unfairness via evolutionary multiobjective ensemble learning},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Query-efficient generation of adversarial examples for
defensive DNNs via multiobjective optimization. <em>TEVC</em>,
<em>27</em>(4), 832–847. (<a
href="https://doi.org/10.1109/TEVC.2022.3231460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent vulnerability of deep neural networks (DNNs), the adversarial example (AE) attack has become a serious threat to intelligent systems, e.g., the failure cause of an image classification system. Different to existing works, in this article we are interested in the generation of AEs for DNNs with defensive mechanisms. To make the attack more practical, we exploit a query-based method to generate image AEs in a black-box attack setting. Considering that the generation of AEs is inherently a constrained optimization problem, this article first formulates three objectives regarding defensive DNNs, i.e., attack effectiveness, attack evasiveness and attack coverage. Then, this article proposes a query-efficient AE attack based on the genetic algorithm (GA) and particle swarm optimization (PSO) to address the perturbation optimization problem. To improve the efficiency of search and query, AE-specific operators including block-level and pixel-level crossovers, discrete perturbation mutation and direction-driven reproduction are designed within the GA-based search framework. In addition, predication-based adaptation of reproduction-related parameters is implemented to speed up the search convergence. PSO-based jumping process is further devised to avoid stuck in local optimum. Benchmark-based experiments evaluated the efficiency of our method, which can achieve an attack success rate of 100\% with averagely 52.95\% reduced queries in contrast to existing black-box attacks on nondefensive models. For defensive DNN models, our method can obtain top attack performance with the query reduction up to 70.92\% comparing with the candidates.},
  archive      = {J_TEVC},
  author       = {Wei Jiang and Shen You and Jinyu Zhan and Xupeng Wang and Hong Lei and Deepak Adhikari},
  doi          = {10.1109/TEVC.2022.3231460},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {832-847},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Query-efficient generation of adversarial examples for defensive DNNs via multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary multiobjective clustering over multiple
conflicting data views. <em>TEVC</em>, <em>27</em>(4), 817–831. (<a
href="https://doi.org/10.1109/TEVC.2022.3220187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview data analysis provides an effective means to integrate the distinct information sources which are inherent to many applications. Data clustering in a multiview setting specifically aims to identify the most appropriate grouping for a collection of entities, where those entities (or their relationships) can be described from multiple perspectives. Leveraging recent advances in multiobjective clustering, we propose a new evolutionary method to tackle this challenge. Designed around a flexible and unbiased solution representation, together with strategies based on the minimum spanning tree and neighborhood relations, our algorithm optimizes multiple objectives simultaneously to effectively explore the space of candidate tradeoffs between the data views. Through a series of experiments, we investigate the suitability of our proposal in the context of a bioinformatics application, clustering of plausible protein structures, and a diverse set of synthetic problems. The specific case of two data views is considered in this article. The evaluation with respect to a variety of reference approaches demonstrates the effectiveness of our method in discovering high-quality partitions in a multiview setting. Robustness against unreliable data sources and the ability to automatically determine the number of clusters are additional advantages evidenced by the results obtained.},
  archive      = {J_TEVC},
  author       = {Mario Garza-Fabre and Julia Handl and Adán José-García},
  doi          = {10.1109/TEVC.2022.3220187},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {817-831},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multiobjective clustering over multiple conflicting data views},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An evolutionary multitasking algorithm with multiple
filtering for high-dimensional feature selection. <em>TEVC</em>,
<em>27</em>(4), 802–816. (<a
href="https://doi.org/10.1109/TEVC.2023.3254155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, evolutionary multitasking (EMT) has been successfully used in the field of high-dimensional classification. However, the generation of multiple tasks in the existing EMT-based feature selection (FS) methods is relatively simple, using only the Relief- ${F}$ method to collect related features with similar importance into one task, which cannot provide more diversified tasks for knowledge transfer. Thus, this article devises a new EMT algorithm for FS in high-dimensional classification, which first adopts different filtering methods to produce multiple tasks and then modifies a competitive swarm optimizer (CSO) to efficiently solve these related tasks via knowledge transfer. First, a diversified multiple task generation method is designed based on multiple filtering methods, which generates several relevant low-dimensional FS tasks by eliminating irrelevant features. In this way, useful knowledge for solving simple and relevant tasks can be transferred to simplify and speed up the solution of the original high-dimensional FS task. Then, a CSO is modified to simultaneously solve these relevant FS tasks by transferring useful knowledge among them. Numerous empirical results demonstrate that the proposed EMT-based FS method can obtain a better feature subset than several state-of-the-art FS methods on 18 high-dimensional datasets.},
  archive      = {J_TEVC},
  author       = {Lingjie Li and Manlin Xuan and Qiuzhen Lin and Min Jiang and Zhong Ming and Kay Chen Tan},
  doi          = {10.1109/TEVC.2023.3254155},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {802-816},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An evolutionary multitasking algorithm with multiple filtering for high-dimensional feature selection},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Region purity-based local feature selection: A
multiobjective perspective. <em>TEVC</em>, <em>27</em>(4), 787–801. (<a
href="https://doi.org/10.1109/TEVC.2022.3222297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contrast to the traditional feature selection (FS), local FS (LFS) partitions the whole sample space and obtains the feature subset for each local region. However, most existing LFS algorithms lack a problem-specific objective function and instead simply apply the distance-like objective function, which limits their classification performance. In addition, obtaining a good LFS model is essentially a multiobjective optimization problem. Therefore, in this article, we propose a region purity (RP)-based LFS (RP-LFS) where, besides the proportion of the selected features and region-based distance metric, we design a novel objective function, RP, from the perspective of combining local features with classifiers. To solve the RP-LFS, an improved nondominated sorting genetic algorithm III is proposed. Specifically, a network-inspired crossover operator and a quick bit mutation are applied, which can improve the ability to search for better solutions. A regional feature sharing strategy between different local models is developed, which can preserve more effective features. Experimental studies on 11 UCI datasets and nine high-dimensional datasets validate the effectiveness of our proposed RP. In comparison with various state-of-the-art FS and LFS algorithms, RP-LFS can achieve very competitive classification accuracy while obtaining a reduced feature subset size.},
  archive      = {J_TEVC},
  author       = {Yu Zhou and Yan Qiu and Sam Kwong},
  doi          = {10.1109/TEVC.2022.3222297},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {787-801},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Region purity-based local feature selection: A multiobjective perspective},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural architecture search based on a multi-objective
evolutionary algorithm with probability stack. <em>TEVC</em>,
<em>27</em>(4), 778–786. (<a
href="https://doi.org/10.1109/TEVC.2023.3252612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of deep neural networks, many research fields, such as image classification, object detection, speech recognition, natural language processing, machine translation, and automatic driving, have made major breakthroughs in technology and the research achievements have been successfully applied in many real-life applications. Combining evolutionary computation and neural architecture search (NAS) is an important approach to improve the performance of deep neural networks. Usually, the related researchers only focus on precision. Thus, the searched neural architectures always perform poorly in the other indexes such as time cost. In this article, a multi-objective evolutionary algorithm with a probability stack (MOEA-PS) is proposed for NAS, which considers the two objects of precision and time consumption. MOEA-PS uses an adjacency list to represent the internal structure of deep neural networks. Besides, a unique mechanism is introduced into the multi-objective genetic algorithm to guide the process of crossover and mutation when generating offspring. Furthermore, the structure blocks are stacked using a proxy model to generate deep neural networks. The results of the experiments on Cifar-10 and Cifar-100 demonstrate that the proposed algorithm has a similar error rate compared with the most advanced NAS algorithms, but the time cost is lower. Finally, the network structure searched on Cifar-10 is transferred directly to the ImageNet dataset, which can achieve 73.6\% classification accuracy.},
  archive      = {J_TEVC},
  author       = {Yu Xue and Chen Chen and Adam Słowik},
  doi          = {10.1109/TEVC.2023.3252612},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {778-786},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Neural architecture search based on a multi-objective evolutionary algorithm with probability stack},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reduced-space multistream classification based on
multiobjective evolutionary optimization. <em>TEVC</em>, <em>27</em>(4),
764–777. (<a href="https://doi.org/10.1109/TEVC.2022.3232466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traditional data stream mining, classification models are typically trained on labeled samples from a single source. However, in real-world scenarios, obtaining accurate labels is very hard and expensive, especially, when multiple data streams are concurrently sampled from an environment or the same process. To address this issue, multistream classification is proposed, in which a data stream with biased labels (called the source stream) is leveraged to train a suitable model for prediction over another stream with unlabeled samples (called the target stream). Despite the growing research in this field, previous multistream classification methods are mostly designed for single-source stream scenarios. However, various source streams contain diverse data distributions, providing more valuable information for building a more accurate model. In addition, previous works construct classification models in the original shared feature space, ignoring the effect of redundant or low-quality features on the classification performance. This may produce inefficient knowledge transfer across streams. In view of this, a reduced-space multistream classification based on multiobjective evolutionary optimization is proposed in this article. First, a multiobjective evolutionary optimization is employed to seek the most valuable feature subset shared in the source and target domains, with the purpose of narrowing the distribution difference between source and target streams. Following that, a Gaussian mixture model-based weighting mechanism for source samples is presented. More especially, two drift adaptation methods are proposed to address asynchronous drift. Experimental results on benchmark datasets show that the proposed method outperforms other comparative methods on classification accuracy and G-mean.},
  archive      = {J_TEVC},
  author       = {Botao Jiao and Yinan Guo and Shengxiang Yang and Jiayang Pu and Dunwei Gong},
  doi          = {10.1109/TEVC.2022.3232466},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {764-777},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Reduced-space multistream classification based on multiobjective evolutionary optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interactive evolutionary multiobjective optimization via
learning to rank. <em>TEVC</em>, <em>27</em>(4), 749–763. (<a
href="https://doi.org/10.1109/TEVC.2023.3234269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical multicriterion decision making, it is cumbersome if a decision maker (DM) is asked to choose among a set of tradeoff alternatives covering the whole Pareto-optimal front. This is a paradox in conventional evolutionary multiobjective optimization (EMO) that always aim to achieve a well balance between convergence and diversity. In essence, the ultimate goal of multiobjective optimization is to help a DM identify solution(s) of interest (SOI) achieving satisfactory tradeoffs among multiple conflicting criteria. Bearing this in mind, this article develops a framework for designing preference-based EMO algorithms to find SOI in an interactive manner. Its core idea is to involve human in the loop of EMO. After every several iterations, the DM is invited to elicit her feedback with regard to a couple of incumbent candidates. By collecting such information, her preference is progressively learned by a learning-to-rank neural network and then applied to guide the baseline EMO algorithm. Note that this framework is so general that any existing EMO algorithm can be applied in a plug-in manner. Experiments on 48 benchmark test problems with up to ten objectives and a real-world multiobjective robot control problem fully demonstrate the effectiveness of our proposed algorithms for finding SOI.},
  archive      = {J_TEVC},
  author       = {Ke Li and Guiyu Lai and Xin Yao},
  doi          = {10.1109/TEVC.2023.3234269},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {749-763},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Interactive evolutionary multiobjective optimization via learning to rank},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guest editorial special issue on multiobjective evolutionary
optimization in machine learning. <em>TEVC</em>, <em>27</em>(4),
746–748. (<a href="https://doi.org/10.1109/TEVC.2023.3292528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are very pleased to introduce this special issue on multiobjective evolutionary optimization for machine learning (MOML). Optimization is at the heart of many machine-learning techniques. However, there is still room to exploit optimization in machine learning. Every machine-learning technique has hyperparameters that can be tuned using evolutionary computation and optimization, considering normally multiple criteria, such as bias, variance, complexity, and fairness in model selection. Multiobjective evolutionary optimization can help meet these criteria for optimizing machine-learning models. Some of the existing approaches address these multiple criteria by transforming the problem into a single-objective optimization problem. However, multiobjective optimization models are able to outperform single-objective ones in contributing to multiple intended objectives (criteria). In recent years, evolutionary computation has been shown to be the premier method for solving multiobjective optimization problems (MOPs), producing both optimal and diverse solutions beyond the capabilities of other heuristics. This is particularly true for very large solution spaces, which is the case in real-world machine-learning problems with many features.},
  archive      = {J_TEVC},
  author       = {Uwe Aickelin and Hadi Akbarzadeh Khorshidi and Rong Qu and Hadi Charkhgard},
  doi          = {10.1109/TEVC.2023.3292528},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {4},
  pages        = {746-748},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Guest editorial special issue on multiobjective evolutionary optimization in machine learning},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Community detection in multiplex networks based on
evolutionary multitask optimization and evolutionary clustering
ensemble. <em>TEVC</em>, <em>27</em>(3), 728–742. (<a
href="https://doi.org/10.1109/TEVC.2022.3184988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection in multiplex networks is an emerging research topic in the field of network science. Existing methods usually ignore the similarities among component layers of a multiplex network when detecting its community structures, which decreases the detection efficiency. In this article, we decompose the community detection in multiplex networks into two problems and propose a novel algorithm that can detect both the specific community partition for each component layer (layer-level community structure) and the composite community structure shared by all layers. First, by specifying the modularity optimization on a network layer as an optimization task, we model the layer-level community detection as a multitask optimization (MTO) problem and employ an evolutionary MTO algorithm to solve it. In this way, the topology correlations among different layers can be utilized to facilitate the community detection. Second, we propose an evolutionary clustering ensemble method to find the composite community structure based on the layer-level community partitions and the multiplex network. The proposed method is tested on both synthetic and real-world benchmark networks and compared with classical and state-of-the-art algorithms. Experimental results show that the proposed algorithm has superior community detection performances on multiplex networks.},
  archive      = {J_TEVC},
  author       = {Chao Lyu and Yuhui Shi and Lijun Sun and Chin-Teng Lin},
  doi          = {10.1109/TEVC.2022.3184988},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {728-742},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Community detection in multiplex networks based on evolutionary multitask optimization and evolutionary clustering ensemble},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary sampling agent for expensive problems.
<em>TEVC</em>, <em>27</em>(3), 716–727. (<a
href="https://doi.org/10.1109/TEVC.2022.3177605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven evolutionary algorithms are widely studied for their ability to solve expensive optimization problems in engineering and science. This article introduces a novel optimization framework to solve costly optimization problems, called the evolutionary sampling agent (ESA). ESA considers the optimization algorithm as an agent, which operates on four different characteristics of evolutionary sampling strategies to search the global optimum. Among these four evolutionary sampling strategies, the first strategy prefers exploration, the second and the fourth strategies use different local search methods preferring exploitation, and the third strategy integrates good genes from historical solutions. ESA consists of two layers of learning mechanisms. On the one hand, the evolutionary sampling strategies use historical data to construct surrogate models to efficiently sample a candidate solution. On the other hand, the agent adjusts the probability of selecting different sampling strategies through the feedback information received in the optimization process. Seven benchmark functions with 30, 50, and 100 dimensions were adopted. Compared with the other state-of-the-art methods, the results show that ESA yields a promising performance for expensive problems.},
  archive      = {J_TEVC},
  author       = {Huixiang Zhen and Wenyin Gong and Ling Wang},
  doi          = {10.1109/TEVC.2022.3177605},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {716-727},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary sampling agent for expensive problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A stigmergy-based island model for dynamic evaluation of
constraint-handling techniques and differential evolution algorithms.
<em>TEVC</em>, <em>27</em>(3), 701–715. (<a
href="https://doi.org/10.1109/TEVC.2022.3178968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A nontrivial task is to choose an evolutionary algorithm (EA) and a constraint-handling technique, among countless possibilities, leading to a robust and efficient mechanism to solve constrained optimization problems (COPs). The main motivation of this article is to automate the decision on the EA coupled with a constraint-handling technique able to find the best performance in solving COPs. From this issue, this work proposes a methodology based on the stigmergy island model (IM), where EAs and constraint-handling techniques are distributed throughout the islands, and their performances are dynamically evaluated along the evolutionary process to guide the migration of solutions between them. The stigmergy IM is a strategy for implementing the hybrid IMs dynamically and adaptively, inspired by the natural phenomenon of stigmergy. According to the EAs applied on the islands, the weighted connections and distribution of solutions between islands are adjusted over migrations. The proposed model, which is the main contribution of this work, identifies and explores the most suitable algorithm for COPs among those applied in the initial topology. In this sense, different hybrid alternatives based on different differential evolution algorithms and constraint-handling techniques are presented to evaluate the performance of the proposed IM.},
  archive      = {J_TEVC},
  author       = {Grasiele Regina Duarte and Beatriz Souza Leite Pires de Lima and Afonso Celso de Castro Lemonge},
  doi          = {10.1109/TEVC.2022.3178968},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {701-715},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A stigmergy-based island model for dynamic evaluation of constraint-handling techniques and differential evolution algorithms},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative coevolutionary CMA-ES with landscape-aware
grouping in noisy environments. <em>TEVC</em>, <em>27</em>(3), 686–700.
(<a href="https://doi.org/10.1109/TEVC.2022.3180224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world optimization tasks suffer from noise. So far, the research on noise-tolerant optimization algorithms is still restricted to low-dimensional problems with less than 100 decision variables. In reality, many problems are high dimensional. Cooperative coevolutionary (CC) algorithms based on a divide-and-conquer strategy are promising in solving complex high-dimensional problems. However, noisy fitness evaluations pose a challenge in problem decomposition for CC. The state-of-the-art grouping methods, such as differential grouping (DG) and recursive DG, are unable to work properly in noisy environments. Because it is impossible to distinguish whether the change of one variable’s difference value is caused by noise or the perturbation of its interacting variables. As a result, every pair of variables will be identified as nonseparable in these methods. In this article, we study how to group decision variables with the covariance matrix adaptation evolution strategy (CMA-ES) in noisy environments and subsequently propose a landscape-aware grouping (LAG) method. Instead of detecting pairwise interacting variables, we directly identify a nonseparable subcomponent. To this end, we propose to use two convergence features: 1) variable convergence time and 2) accumulative path, to describe variables’ fitness landscapes; then, variables are clustered according to these two features. Numerical experiments show that LAG can more effectively identify interactive decision variables in the presence of multiplicative noise than the DG and some of its variants. Up to 500 dimensions, the performance of CC CMA-ES with landscape-aware grouping (CC-CMAES-LAG) is competitive compared with existing CC algorithms and uncertainty-handling CMA-ES (UH-CMA-ES).},
  archive      = {J_TEVC},
  author       = {Yapei Wu and Xingguang Peng and Handing Wang and Yaochu Jin and Demin Xu},
  doi          = {10.1109/TEVC.2022.3180224},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {686-700},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Cooperative coevolutionary CMA-ES with landscape-aware grouping in noisy environments},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed and expensive evolutionary constrained
optimization with on-demand evaluation. <em>TEVC</em>, <em>27</em>(3),
671–685. (<a href="https://doi.org/10.1109/TEVC.2022.3177936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expensive optimization problems (EOPs) are common in industry and surrogate-assisted evolutionary algorithms (SAEAs) have been developed for solving them. However, many EOPs have not only expensive objective but also expensive constraints, which are evaluated through distributed ways. We define this kind of EOPs as distributed expensive constrained optimization problems (DECOPs). The distributed characteristic of DECOPs leads to the asynchronous evaluation of both objective and constraints. Though some researchers have studied the asynchronous evaluation of objectives, the asynchronous evaluation of constraints has not gained much attention. Therefore, this article gives a formal formulation of DECOPs and proposes a distributed evolutionary constrained optimization algorithm with on-demand evaluation (DEAOE). DEAOE can adaptively evolve different constraints in an asynchronous way through the on-demand evaluation strategy. The on-demand evaluation works from two aspects to improve the population convergence and diversity. From the aspect of individual selection, a joint sample selection strategy is adopted to determine which candidates are promising. From the aspect of constraint selection, an infeasible-first evaluation strategy is devised to judge which constraints need to be further evolved. Extensive experiments and analyses on benchmark functions and engineering problems demonstrate that DEAOE has better performance and higher efficiency compared to centralized state-of-the-art SAEAs.},
  archive      = {J_TEVC},
  author       = {Feng-Feng Wei and Wei-Neng Chen and Qing Li and Sang-Woon Jeon and Jun Zhang},
  doi          = {10.1109/TEVC.2022.3177936},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {671-685},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Distributed and expensive evolutionary constrained optimization with on-demand evaluation},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust optimization over time by estimating robustness of
promising regions. <em>TEVC</em>, <em>27</em>(3), 657–670. (<a
href="https://doi.org/10.1109/TEVC.2022.3180590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world optimization problems are dynamic. The field of robust optimization over time (ROOT) deals with dynamic optimization problems in which frequent changes of the deployed solution are undesirable. This can be due to the high cost of switching the deployed solutions, the limitation of the needed resources to deploy such new solutions, and/or the system being intolerant toward frequent changes of the deployed solution. In the considered ROOT problems in this article, the main goal is to find solutions that maximize the average number of environments where they remain acceptable. In the state-of-the-art methods developed to tackle these problems, the decision makers/metrics used to select solutions for deployment mostly make simplifying assumptions about the problem instances. Besides, the current methods all use the population control components, which have been originally designed for tracking the global optimum over time without taking any robustness considerations into account. In this article, a multipopulation ROOT method is proposed with two novel components: 1) a robustness estimation component that estimates robustness of the promising regions and 2) a dual-mode computational resource allocation component to manage subpopulations by taking several factors, including robustness, into account. Our experimental results demonstrate the superiority of the proposed method over other state-of-the-art approaches.},
  archive      = {J_TEVC},
  author       = {Danial Yazdani and Donya Yazdani and Jürgen Branke and Mohammad Nabi Omidvar and Amir Hossein Gandomi and Xin Yao},
  doi          = {10.1109/TEVC.2022.3180590},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {657-670},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Robust optimization over time by estimating robustness of promising regions},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic auxiliary task-based evolutionary multitasking for
constrained multiobjective optimization. <em>TEVC</em>, <em>27</em>(3),
642–656. (<a href="https://doi.org/10.1109/TEVC.2022.3175065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving constrained multiobjective optimization problems (CMOPs), the utilization of infeasible solutions significantly affects algorithm’s performance because they not only maintain diversity but also provide promising search directions. In light of this situation, this article proposes a new multitasking-constrained multiobjective optimization (MTCMO) framework, in which a dynamic auxiliary task is created to assist in solving a complex CMOP (the main task) via the knowledge transfer. Moreover, the constraint boundary of the auxiliary task reduces dynamically, so that it keeps a high relatedness with the main task to continuously provide supplementary evolutionary directions. Furthermore, an improved $\epsilon $ method is designed for the auxiliary task to utilize diverse high-quality infeasible solutions for breaking through infeasible obstacles in the early stage and approaching the feasible boundary from infeasible regions in the later stage. Besides, a new test function with decision space constraints is designed, where one parameter can be adjusted to control the overlap degree between the constrained Pareto front and the unconstrained Pareto front. This function and the other two modified existing functions are used to analyze the characteristics of MTCMO. Finally, compared with 11 state-of-the-art peer methods, the superior or competitive performance of MTCMO is demonstrated on 54 benchmark functions and two real-world applications.},
  archive      = {J_TEVC},
  author       = {Kangjia Qiao and Kunjie Yu and Boyang Qu and Jing Liang and Hui Song and Caitong Yue and Hongyu Lin and Kay Chen Tan},
  doi          = {10.1109/TEVC.2022.3175065},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {642-656},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Dynamic auxiliary task-based evolutionary multitasking for constrained multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable artificial intelligence by genetic programming:
A survey. <em>TEVC</em>, <em>27</em>(3), 621–641. (<a
href="https://doi.org/10.1109/TEVC.2022.3225509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable artificial intelligence (XAI) has received great interest in the recent decade, due to its importance in critical application domains, such as self-driving cars, law, and healthcare. Genetic programming (GP) is a powerful evolutionary algorithm for machine learning. Compared with other standard machine learning models such as neural networks, the models evolved by GP tend to be more interpretable due to their model structure with symbolic components. However, interpretability has not been explicitly considered in GP until recently, following the surge in the popularity of XAI. This article provides a comprehensive review of the studies on GP that can potentially improve the model interpretability, both explicitly and implicitly, as a byproduct. We group the existing studies related to explainable artificial intelligence by GP into two categories. The first category considers the intrinsic interpretability, aiming to directly evolve more interpretable (and effective) models by GP. The second category focuses on post-hoc interpretability, which uses GP to explain other black-box machine learning models, or explain the models evolved by GP by simpler models such as linear models. This comprehensive survey demonstrates the strong potential of GP for improving the interpretability of machine learning models and balancing the complex tradeoff between model accuracy and interpretability.},
  archive      = {J_TEVC},
  author       = {Yi Mei and Qi Chen and Andrew Lensen and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2022.3225509},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {621-641},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Explainable artificial intelligence by genetic programming: A survey},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A learning-based memetic algorithm for energy-efficient
flexible job-shop scheduling with type-2 fuzzy processing time.
<em>TEVC</em>, <em>27</em>(3), 610–620. (<a
href="https://doi.org/10.1109/TEVC.2022.3175832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green flexible job-shop scheduling problem (FJSP) aims to improve profit and reduce energy consumption for modern manufacturing. Meanwhile, FJSP with type-2 fuzzy processing time is proposed to predict the uncertainty in timing constraint for better simulating the practical production. This study addresses the multiobjective energy-efficient FJSP with type-2 processing time (ET2FJSP), where the minimization of makespan and total energy consumption are considered simultaneously. The previous studies do not propose the model verification and energy-saving strategy. Moreover, the best parameters required by an algorithm in different stage are different. Therefore, we propose a mixed-integer linear programming model and design a learning-based reference vector memetic algorithm (LRVMA). Its main features are: 1) four problem-specific initial rules that are presented for initialization to generate diverse solutions; 2) four problem-specific local search methods that are incorporated to enhance the exploitation; 3) an effective solution selection method depending on the Tchebycheff decomposition strategy that is utilized to balance the convergence and diversity; 4) a reinforcement learning-based parameter selection strategy that is proposed to improve the diversity of nondominated solutions; and 5) an energy-saving strategy that is designed to reduce energy consumption. To verify the effectiveness of LRVMA, it is compared against other related algorithms. The results demonstrate that LRVMA outperforms the compared algorithms for solving ET2FJSP.},
  archive      = {J_TEVC},
  author       = {Rui Li and Wenyin Gong and Chao Lu and Ling Wang},
  doi          = {10.1109/TEVC.2022.3175832},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {610-620},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A learning-based memetic algorithm for energy-efficient flexible job-shop scheduling with type-2 fuzzy processing time},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Surrogate sample-assisted particle swarm optimization for
feature selection on high-dimensional data. <em>TEVC</em>,
<em>27</em>(3), 595–609. (<a
href="https://doi.org/10.1109/TEVC.2022.3175226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of the number of features and the sample size, existing feature selection (FS) methods based on evolutionary optimization still face challenges such as the “curse of dimensionality” and the high computational cost. In view of this, dividing or clustering the sample and feature spaces at the same time, this article proposes a hybrid FS algorithm using surrogate sample-assisted particle swarm optimization (SS-PSO). First, a nonrepetitive uniform sampling strategy is employed to divide the whole sample set into several small-size sample subsets. Regarding each sample subset as a surrogate unit, next, a collaborative feature clustering mechanism is proposed to divide the feature space, with the purpose of reducing both the computational cost of clustering feature and the search space of PSO. Following that, an ensemble surrogate-assisted integer PSO is proposed. To ensure the prediction accuracy of ensemble surrogate when evaluating particles, an ensemble surrogate construction and management strategy is designed. Since the whole sample set is replaced by a small number of surrogate units, SS-PSO significantly reduces the cost of evaluating particles in PSO. Finally, the proposed algorithm is applied to some typical datasets, and compared with six typical evolutionary FS algorithms, as well as its several variant algorithms. The experimental results show that SS-PSO can obtain good feature subsets at the smallest computational cost on most of datasets. All verify that SS-PSO is a highly competitive method for high-dimensional FS.},
  archive      = {J_TEVC},
  author       = {Xianfang Song and Yong Zhang and Dunwei Gong and Hui Liu and Wanqiu Zhang},
  doi          = {10.1109/TEVC.2022.3175226},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {595-609},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Surrogate sample-assisted particle swarm optimization for feature selection on high-dimensional data},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A stochastic simulation optimization-based range gate
pull-off jamming method. <em>TEVC</em>, <em>27</em>(3), 580–594. (<a
href="https://doi.org/10.1109/TEVC.2022.3175517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Range gate pull-off (RGPO) jamming is an electronic countermeasure widely used to fool radar tracking systems. Nevertheless, the research on its strategy optimization has only been tepid. The optimization model, appropriate performance metrics, as well as efficient algorithms are required to further the research in this field. The algebraic description for the objective function of the optimization of the RGPO jamming strategy is difficult to obtain, and the jamming results are not deterministic under the influence of the input noise. To address these issues, this article models the generation of the RGPO jamming strategy as a stochastic simulation optimization (SSO) problem, and proposes an optimization algorithm of the RGPO jamming strategy with the help of SSO technologies. We propose the committee-based active learning (CAL) assisted optimal computing budget allocation-based particle swarm optimization (CALPSO-OCBA) to alleviate the competition between solution space search and candidate solution performance evaluation by embedding CAL into PSO-OCBA. To improve the feasibility of the proposed algorithm, a scoring scheme that does not rely on the internal knowledge of the radar tracking system (i.e., the tracking model, tracking method, and tracking parameters) is designed. In addition, we use four most widely used tracking problems as the benchmarks for testing the proposed optimization algorithm of the RGPO jamming strategy. Experimental results demonstrate that the proposed algorithm is highly competitive in solving the optimization problem of the RGPO jamming strategy.},
  archive      = {J_TEVC},
  author       = {Yuanhang Wang and Tianxian Zhang and Lingjiang Kong and Zhijie Ma},
  doi          = {10.1109/TEVC.2022.3175517},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {580-594},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A stochastic simulation optimization-based range gate pull-off jamming method},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strengthening gradient descent by sequential motion
optimization for deep neural networks. <em>TEVC</em>, <em>27</em>(3),
565–579. (<a href="https://doi.org/10.1109/TEVC.2022.3171052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we explore the advantages of heuristic mechanisms and devise a new optimization framework named sequential motion optimization (SMO) to strengthen gradient-based methods. The key idea of SMO is inspired from a movement mechanism in a recent metaheuristic method called balancing composite motion optimization (BCMO). Specifically, SMO establishes a sequential motion chain of two gradient-guided individuals, including a leader and a follower to enhance the effectiveness of parameter updates in each iteration. A surrogate gradient model with low computation cost is theoretically established to estimate the gradient of the follower by that of the leader through chain rule during the training process. Experimental results in terms of training quality on both fully connected multilayer perceptrons (MLPs) and convolutional neural networks (CNNs) with respect to three popular benchmark datasets, including MNIST, Fashion-MNIST, and CIFAR-10 demonstrate the superior performance of the proposed framework in comparison with the vanilla stochastic gradient descent (SGD) implemented via backpropagation (BP) algorithm. Although this study only introduces the vanilla gradient descent (GD) as a main gradient-guided factor in SMO for deep neural network (DNN) training application, it is great potential to combine with other gradient-based variants to improve its effectiveness and solve other large-scale optimization problems in practice.},
  archive      = {J_TEVC},
  author       = {Thang Le-Duc and Quoc-Hung Nguyen and Jaehong Lee and H. Nguyen-Xuan},
  doi          = {10.1109/TEVC.2022.3171052},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {565-579},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Strengthening gradient descent by sequential motion optimization for deep neural networks},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benchmarking optimization algorithms for auto-tuning GPU
kernels. <em>TEVC</em>, <em>27</em>(3), 550–564. (<a
href="https://doi.org/10.1109/TEVC.2022.3210654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed phenomenal growth in the application, and capabilities of graphical processing units (GPUs) due to their high parallel computation power at relatively low cost. However, writing a computationally efficient GPU program (kernel) is challenging and, generally, only certain specific kernel configurations lead to significant increases in performance. Auto-tuning is the process of automatically optimizing software for highly efficient execution on a target hardware platform. Auto-tuning is particularly useful for GPU programming, as a single kernel requires retuning after code changes, for different input data, and for different architectures. However, the discrete and nonconvex nature of the search space creates a challenging optimization problem. In this work, we investigate which algorithm produces the fastest kernels if the time-budget for the tuning task is varied. We conduct a survey by performing experiments on 26 different kernel spaces, from nine different GPUs, for 16 different evolutionary black-box optimization algorithms. We then analyze these results and introduce a novel metric based on the PageRank centrality concept as a tool for gaining insight into the difficulty of the optimization problem. We demonstrate that our metric correlates strongly with the observed tuning performance.},
  archive      = {J_TEVC},
  author       = {Richard Arnoud Schoonhoven and Ben van Werkhoven and Kees Joost Batenburg},
  doi          = {10.1109/TEVC.2022.3210654},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {550-564},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Benchmarking optimization algorithms for auto-tuning GPU kernels},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A genetic algorithm (GA) and swarm-based binary decision
diagram (BDD) reordering optimizer reinforced with recent operators.
<em>TEVC</em>, <em>27</em>(3), 535–549. (<a
href="https://doi.org/10.1109/TEVC.2022.3170212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of binary decision diagrams (BDDs) has proliferated in numerous fields. When a system criterion is formulated in form of a Boolean function, its BDD is constructed. Each node in the BDD is further mapped into another form to be exploited in the system analysis. However, the cost of the resultant mapping form is directly related to the BDD size which can be effectively reduced through applying proper variable reordering followed by applying reduction rules that preserve the fidelity of the BDD in correctly representing the input Boolean function. Although several algorithms have been proposed in the literature to find the optimal order of variables in the BDD, the scalability of such algorithms is a serious barrier when it comes to complex systems with exponential explosion in the possible number of orders in the search space. Furthermore, solely exploring the search space in BDD reordering is not sufficient since better permutations might be obtained with slight tuning of the candidate solutions. Thus, a sufficient degree of equilibrium between exploration and exploitation should be preserved during the evolution of the reordering algorithm. In this article, we propose a BDD optimizer driven by either genetic algorithm (GA) or swarm engines. The proposed GA-based BDD reordering optimizer iteratively processes an essentially large population with a randomized mixing of low destructive crossover/mutation operators. The proposed swarm-based optimizer, on the other hand, maps a vector of real numbers into a permutation to further construct its companion BDD. The generation of the next vector is guided by recent parameter and parameter-less swarm algorithms that are armed with effective mechanisms to simultaneously conduct exploration and exploitation. Experimental results show that our proposed optimizer effectively reduces the resultant BDD size for input Boolean functions with almost linear computational complexity. Furthermore, it has been found that exploiting recent swarm optimizers with spiral movement in BDD reordering problem can outperform GA for large scale Boolean functions. Finally, as a real-world application, our proposed algorithm is applied to reversible logic synthesis to show the achieved reduction in the quantum cost (QC) associated with BDD-based synthesis.},
  archive      = {J_TEVC},
  author       = {Ahmed Awad and Amjad Hawash and Baker Abdalhaq},
  doi          = {10.1109/TEVC.2022.3170212},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {535-549},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A genetic algorithm (GA) and swarm-based binary decision diagram (BDD) reordering optimizer reinforced with recent operators},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An iterative two-stage multifidelity optimization algorithm
for computationally expensive problems. <em>TEVC</em>, <em>27</em>(3),
520–534. (<a href="https://doi.org/10.1109/TEVC.2022.3170970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engineering design optimization often involves use of numerical simulations to assess the performance of candidate designs. The simulations for computing high-fidelity (HF) performance estimates, such as finite element analysis or computational fluid dynamics, are typically computationally expensive. In some cases, it may also be possible to run an alternate or cheaper version of the simulation (through, e.g., use of a coarse mesh) to yield a low-fidelity (LF) performance estimate. Multifidelity optimization refers to the class of methods that aim to manage LF and HF evaluations efficiently to optimize computationally expensive problems within a limited computing budget. Among the prominent existing multifidelity approaches, some of them depend on a sufficiently dense a priori sampling; while others use unidirectional information exchange from LF to HF; both of which lead to a possibility of spending evaluation budget on unpromising search regions. This article proposes an improved multifidelity approach using an iterative, two-stage scheme (MFITS). It uses the collective information from the previously evaluated designs to determine a sampling neighborhood for LF evaluations. These samples are, in turn, used for building a co-kriging surrogate model that is then searched globally to identify a good candidate for HF evaluation. By restricting the LF sampling neighborhood, the computational budget can be used more efficiently, as the search is focused on regions that have historically produced good quality solutions. Numerical experiments and benchmarking are conducted on two suites of test problems and two practical design optimization problems to demonstrate the efficacy of MFITS.},
  archive      = {J_TEVC},
  author       = {Angus Kenny and Tapabrata Ray and Hemant Kumar Singh},
  doi          = {10.1109/TEVC.2022.3170970},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {520-534},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An iterative two-stage multifidelity optimization algorithm for computationally expensive problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimizing expected deviation in upper level outcomes due to
lower level decision making in hierarchical multiobjective problems.
<em>TEVC</em>, <em>27</em>(3), 505–519. (<a
href="https://doi.org/10.1109/TEVC.2022.3172302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many societal and industrial problem-solving tasks involving search, optimization, design, and management are conveniently decomposed into hierarchical subproblems. While this process allows a systematic procedure to have a multistakeholder solution, the independent decision-making process for the lower level problem causes a deviation in the expected outcome of the upper level problem. In this article, we provide a new and computationally efficient evolutionary approach allowing upper level decision makers to analyze the vagaries of lower level decision making when choosing a preferred solution with the minimum deviation from their expectations. This concept is novel and pragmatic. We demonstrate the concept through a search for optimistic–pessimistic tradeoff solutions found by an evolutionary multiobjective optimization approach first on two difficult test problems, then on a watershed management problem and a telecommunication management problem. The approach is generic and can be applied to similar hierarchical management problems to achieve minimum deviation with a more predictive and reliable outcome. The proposed solution procedure is found to choose an optimistic solution that has approximately 31\%–65\% reduced deviation compared to another optimistic solution chosen at random in the test problems and approximately 85\%–95\% reduced deviation in the two practical problems, making the method of this study applicable to practical hierarchical problems.},
  archive      = {J_TEVC},
  author       = {Kalyanmoy Deb and Zhichao Lu and Ian Kropp and J. Sebastian Hernandez-Suarez and Rayan Hussein and Steven Miller and A. Pouyan Nejadhashemi},
  doi          = {10.1109/TEVC.2022.3172302},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {505-519},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Minimizing expected deviation in upper level outcomes due to lower level decision making in hierarchical multiobjective problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using an estimation of distribution algorithm to achieve
multitasking semantic web service composition. <em>TEVC</em>,
<em>27</em>(3), 490–504. (<a
href="https://doi.org/10.1109/TEVC.2022.3170899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web service composition composes existing Web services to accommodate users’ requests for required functionalities with the best possible quality of services (QoS). Due to the computational complexity of this problem, evolutionary computation (EC) techniques have been employed to efficiently find composite services with near-optimal functional quality (i.e., quality of semantic matchmaking, QoSM for short) or nonfunctional quality (i.e., QoS) for each composition request individually. With a rapid increase in composition requests from a growing number of users, solving one composition request at a time can hardly meet the efficiency target anymore. Driven by the idea that the solutions obtained from solving one request can be highly useful for tackling other related requests, multitasking service composition approaches have been proposed to efficiently deal with multiple composition requests concurrently. However, existing attempts have not been effective in learning and sharing knowledge among solutions for multiple requests. In this article, we model the problem of collectively handling multiple service composition requests as a new multitasking service composition problem and propose a new permutation-based multifactorial evolutionary algorithm based on an estimation of distribution algorithm (EDA), named PMFEA-EDA, to effectively and efficiently solve this problem. In particular, we introduce a novel method for effective knowledge sharing across different service composition requests. For that, we develop a new sampling mechanism to increase the chance of identifying high-quality service compositions in both the single-tasking and multitasking contexts. Our experiment shows that our proposed approach, PMFEA-EDA, takes much less time than existing approaches that process each service request separately, and also outperforms them in terms of both QoSM and QoS.},
  archive      = {J_TEVC},
  author       = {Chen Wang and Hui Ma and Gang Chen and Sven Hartmann},
  doi          = {10.1109/TEVC.2022.3170899},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {490-504},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Using an estimation of distribution algorithm to achieve multitasking semantic web service composition},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient adaptive differential grouping algorithm for
large-scale black-box optimization. <em>TEVC</em>, <em>27</em>(3),
475–489. (<a href="https://doi.org/10.1109/TEVC.2022.3170793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decomposition plays a significant role in cooperative coevolution (CC), which shows great potential in large-scale black-box optimization (LSBO). However, current learning-based decomposition algorithms require many fitness evaluations (FEs) to detect variable interdependencies and encounter the difficulty of threshold setting. To address these issues, this study proposes an efficient adaptive differential grouping (EADG) algorithm. Instead of homogeneously tackling different types of LSBO instances, EADG first identifies the instance type by detecting the interdependencies of a few pairs of variable subsets. Only if the instance is partially separable dose EADG further engages with it by converting its decomposition process into a search process in a binary tree. This facilitates the systematic reutilization of evaluated solutions so that half the interdependencies can be directly deduced without extra FEs. To promote the decomposition accuracy, EADG specially designs a normalized interdependency indicator that can adaptively generate a decomposition threshold according to its ordinal distribution. Theoretical analysis and experimental results show that EADG outperforms current popular decomposition algorithms. Further tests indicate that it can help CC achieve highly competitive optimization performance.},
  archive      = {J_TEVC},
  author       = {An Chen and Zhigang Ren and Wenhua Guo and Yongsheng Liang and Zuren Feng},
  doi          = {10.1109/TEVC.2022.3170793},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {475-489},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An efficient adaptive differential grouping algorithm for large-scale black-box optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Genetic programming for image classification: A new program
representation with flexible feature reuse. <em>TEVC</em>,
<em>27</em>(3), 460–474. (<a
href="https://doi.org/10.1109/TEVC.2022.3169490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting effective features from images is crucial for image classification, but it is challenging due to high variations across images. Genetic programming (GP) has become a promising machine-learning approach to feature learning in image classification. The representation of existing GP-based image classification methods is usually the tree-based structure. These methods typically learn useful image features according to the output of the GP program’s root node. However, they are not flexible enough in feature learning since the features produced by internal nodes of the GP program have seldom been directly used. In this article, we propose a new image classification approach using GP with a new program structure, which can flexibly reuse features generated from different nodes, including internal nodes of the GP program. The new method can automatically learn various informative image features based on the new function set and terminal set for effective and efficient image classification. Furthermore, instead of relying on a predefined classification algorithm, the proposed approach can automatically select a suitable classification algorithm based on the learned features and conduct classification simultaneously in a single evolved GP program for an image classification task. The experimental results on 12 benchmark datasets of varying difficulty suggest that the new approach achieves better performance than many state-of-the-art methods. Further analysis demonstrates the effectiveness and efficiency of the flexible feature reuse in the proposed approach. The analysis of evolved GP programs/solutions shows their potentially high interpretability.},
  archive      = {J_TEVC},
  author       = {Qinglan Fan and Ying Bi and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2022.3169490},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {460-474},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Genetic programming for image classification: A new program representation with flexible feature reuse},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fuzzy decision variables framework for large-scale
multiobjective optimization. <em>TEVC</em>, <em>27</em>(3), 445–459. (<a
href="https://doi.org/10.1109/TEVC.2021.3118593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale multiobjective optimization, too many decision variables hinder the convergence search of evolutionary algorithms. Reducing the search range of the decision space will significantly alleviate this puzzle. With this in mind, this article proposes a fuzzy decision variables framework for large-scale multiobjective optimization. The framework divides the entire evolutionary process into two main stages: 1) fuzzy evolution and 2) precise evolution. In fuzzy evolution, we blur the decision variables of the original solution to reduce the search range of the evolutionary algorithm in the decision space so that the evolutionary population can quickly converge. The degree of fuzzification gradually decreases with the evolutionary process. Once the population approximately converges, the framework will turn to precise evolution. In precise evolution, the actual decision variables of the solution are directly optimized to increase the diversity of the population so as to be closer to the true Pareto optimal front. Finally, this article embeds some representative algorithms into the proposed framework and verifies the framework’s effectiveness through comparative experiments on various large-scale multiobjective problems with 500 to 5000 decision variables. The experimental results show that in large-scale multiobjective optimization, the framework proposed in this article can significantly improve the performance and computational efficiency of multiobjective optimization algorithms.},
  archive      = {J_TEVC},
  author       = {Xu Yang and Juan Zou and Shengxiang Yang and Jinhua Zheng and Yuan Liu},
  doi          = {10.1109/TEVC.2021.3118593},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {445-459},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A fuzzy decision variables framework for large-scale multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A greedy cooperative co-evolutionary algorithm with
problem-specific knowledge for multiobjective flowshop group scheduling
problems. <em>TEVC</em>, <em>27</em>(3), 430–444. (<a
href="https://doi.org/10.1109/TEVC.2021.3115795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flowshop sequence-dependent group scheduling problem (FSDGSP) with the production efficiency measures has been extensively studied due to its wide industrial applications. However, energy efficiency indicators are often ignored in the literature. This article considers the FSDGSP to minimize makespan, total flow time, and total energy consumption, simultaneously. After the problem-specific knowledge is extracted, a mixed-integer linear programming model and a critical path-based accelerated evaluation method are proposed. Since the FSDGSP includes multiple coupled subproblems, a greedy cooperative co-evolutionary algorithm (GCCEA) is designed to explore the solution space in depth. Meanwhile, a random mutation operator and a greedy energy-saving strategy are employed to adjust the processing speeds of machines to obtain a potential nondominated solution. A large number of experimental results show that the proposed algorithm significantly outperforms the existing classic multiobjective optimization algorithms, which is due to the usage of problem-related knowledge.},
  archive      = {J_TEVC},
  author       = {Xuan He and Quan-Ke Pan and Liang Gao and Ling Wang and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1109/TEVC.2021.3115795},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {430-444},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A greedy cooperative co-evolutionary algorithm with problem-specific knowledge for multiobjective flowshop group scheduling problems},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solution of large-scale many-objective optimization problems
based on dimension reduction and solving knowledge-guided evolutionary
algorithm. <em>TEVC</em>, <em>27</em>(3), 416–429. (<a
href="https://doi.org/10.1109/TEVC.2021.3110780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are lots of many-objective optimization problems (MaOPs) in real-world applications, which often have many decision variables. Although a variety of methods have been proposed to solve MaOPs, with the increasing number of decision variables or objective functions, the performance of these algorithms deteriorates appreciably. In view of this, this article proposes a method to solve large-scale MaOPs (LSMaOPs) based on dimension reduction and a solving knowledge-guided evolutionary algorithm (KGEA). First, a dimension reduction method of objective functions is proposed. By clustering and aggregating the objective functions based on their correlation, the dimension of the original LSMaOP is effectively reduced. In addition, the correlations between the reduced objective functions are relatively low, so they can better represent different preferences. Then, we propose a solving KGEA to solve the transformed LSMaOP. In order to get a better set of initial solutions, a population initialization method by mirror partitioning the decision space is given, in which we dynamically modify the sampling probability according to the performance of solutions contained in each subdomain. At the same time, the algorithm will continuously supplement new excellent individuals using the solving knowledge obtained in the evolution of the population. To examine the performance of the proposed method, we carried out a number of comparative experiments. The experimental results demonstrated that the proposed algorithm can effectively tackle LSMaOPs.},
  archive      = {J_TEVC},
  author       = {Xiangjuan Yao and Qian Zhao and Dunwei Gong and Song Zhu},
  doi          = {10.1109/TEVC.2021.3110780},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {416-429},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Solution of large-scale many-objective optimization problems based on dimension reduction and solving knowledge-guided evolutionary algorithm},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary large-scale multiobjective optimization:
Benchmarks and algorithms. <em>TEVC</em>, <em>27</em>(3), 401–415. (<a
href="https://doi.org/10.1109/TEVC.2021.3099487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary large-scale multiobjective optimization (ELMO) has received increasing attention in recent years. This study has compared various existing optimizers for ELMO on different benchmarks, revealing that both benchmarks and algorithms for ELMO still need significant improvement. Thus, a new test suite and a new optimizer framework are proposed to further promote the research of ELMO. More realistic features are considered in the new benchmarks, such as mixed formulation of objective functions, mixed linkages in variables, and imbalanced contributions of variables to the objectives, which are challenging to the existing optimizers. To better tackle these benchmarks, a variable group-based learning strategy is embedded into the new optimizer framework for ELMO, which significantly improves the quality of reproduction in large-scale search space. The experimental results validate that the designed benchmarks can comprehensively evaluate the performance of existing optimizers for ELMO and the proposed optimizer shows distinct advantages in tackling these benchmarks.},
  archive      = {J_TEVC},
  author       = {Songbai Liu and Qiuzhen Lin and Ka-Chun Wong and Qing Li and Kay Chen Tan},
  doi          = {10.1109/TEVC.2021.3099487},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {401-415},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary large-scale multiobjective optimization: Benchmarks and algorithms},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guest editorial special issue on large-scale evolutionary
multiobjective optimization and its practical applications.
<em>TEVC</em>, <em>27</em>(3), 398–400. (<a
href="https://doi.org/10.1109/TEVC.2023.3273012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex optimization problems with hundreds or even thousands of decision variables and dozens of conflicting objectives are not uncommon in the real world. In the past five years, increased research efforts have been dedicated to large-scale multiobjective optimization problems (LSMOPs) by using a variety of search strategies, including variable grouping, variable analysis, problem transformation, dimensionality reduction, and novel recombination operators. Despite the success of these efforts in solving some general LSMOPs, there still remains a big gap between the LSMOPs that have been addressed and those encountered in real life, such as sparse, highly constrained, dynamic, and expensive LMOPs, as well as very large-scale and many-objective optimization problems that are widely seen and of paramount importance for solving scientific and engineering problems. Due to the significant practical importance of large-scale multiobjective optimization, there is a high demand for computationally efficient and effective evolutionary algorithms for solving LSMOPs.},
  archive      = {J_TEVC},
  author       = {Xingyi Zhang and Ran Cheng and Yaochu Jin and Bernhard Sendhoff},
  doi          = {10.1109/TEVC.2023.3273012},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {3},
  pages        = {398-400},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Guest editorial special issue on large-scale evolutionary multiobjective optimization and its practical applications},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Promoting transfer of robot neuro-motion-controllers by
many-objective topology and weight evolution. <em>TEVC</em>,
<em>27</em>(2), 385–395. (<a
href="https://doi.org/10.1109/TEVC.2022.3172294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of robot motion controllers to quickly adapt to new environments is expected to extend the applications of mobile robots. Using the concept of transfer optimization, this study investigates the capabilities of neuro-motion-controllers, which were obtained by simultaneously solving several source problems, to adapt to target problems. In particular, the adaptation comparison is carried out between specialized controllers, which are optimal for a single source motion problem, and nonspecialized controllers that can solve several source motion problems. The compared types of controllers were simultaneously obtained by a many-objective evolution search that is tailored for the optimization of the topology and weights of neural networks. Based on the examined problems, it appears that nonspecialized solutions, which are “good enough” in all the source motion problems, show significantly better transfer capabilities as compared with solutions that were optimized for a single source motion problem. The proposed approach opens up new opportunities to develop controllers that have good enough performances in various environments while also exhibiting efficient adaptation capabilities to changes in the environments.},
  archive      = {J_TEVC},
  author       = {Adham Salih and Amiram Moshaiov},
  doi          = {10.1109/TEVC.2022.3172294},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {385-395},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Promoting transfer of robot neuro-motion-controllers by many-objective topology and weight evolution},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive learning: An alternative surrogate for offline
data-driven evolutionary computation. <em>TEVC</em>, <em>27</em>(2),
370–384. (<a href="https://doi.org/10.1109/TEVC.2022.3170638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline data-driven evolutionary algorithms (DDEAs), which learn problem models from historical data and then perform optimization, have attracted significant attention in the data-driven age. Most existing studies build surrogate models based on regression methods to predict the fitness of each solution, which depends heavily on the quality and quantity of offline data. Considering the evolution trait of evolutionary algorithms (EAs), the absolute fitness of each individual is not essential, instead, the relative strengths of individuals are adequate. This article explores an alternative way to realize DDEAs by establishing a contrastive learning model that performs binary classification to determine the pros and cons between individuals. The task of binary classification is relatively simpler than regression, and meanwhile the training data is inherently augmented to the square of the origin. The proposed contrastive learning model is implemented based on a siamese neural network to measure the differences between solutions. Further, we use the predicted pairwise relationship between individuals to construct a directed graph and propose a topological sort algorithm on the graph to obtain the ranking of the population. During the topological sort, a regression model based on local principle is used to resolve some conflicting issues. Integrating the above components, an offline DDEA named contrastive learning-based DDEA (CL-DDEA) is put forward. Experiments and comparisons with state-of-the-arts validate the powerfulness of CL-DDEA, especially on high-dimensional problems.},
  archive      = {J_TEVC},
  author       = {Hao-Gan Huang and Yue-Jiao Gong},
  doi          = {10.1109/TEVC.2022.3170638},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {370-384},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Contrastive learning: An alternative surrogate for offline data-driven evolutionary computation},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bilevel gene-based multiobjective memetic algorithm for
passive localization system deployment optimization. <em>TEVC</em>,
<em>27</em>(2), 355–369. (<a
href="https://doi.org/10.1109/TEVC.2022.3168427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The passive localization system (PLS) is fundamental to many wireless applications. The deployment of the monitoring stations plays a key role in the performance of the PLSes. However, the workflow of the emerging cutting-edge PLSes is becoming more flexible in the complicated environment, which makes it hard to optimize the deployment. To fulfill the requirement of the real-world applications, we propose a multiobjective PLS deployment optimization model, including a surrogate geometric dilution of precision (S-GDOP) model and a system coverage indicator to meet the demand for the detection performance of the known and unknown targets. The proposed S-GDOP is separable and open to various performance-related factors in this article. Motivated by the various cooperation mechanisms and the empirical deployment patterns, we propose a bilevel gene-based multiobjective memetic algorithm within the decomposition framework to solve this problem. By maintaining an adaptive multicomponent gene population (MCGP) and a local pivot (LP)-based local search, the population evolves on two precise and consecutive gene levels, which effectively utilizes the problem and evolution-related heuristic information. The proposed algorithm outperforms another four popular algorithms in 83.3\% bilateral comparisons and obtains more implicit deployment patterns, clearer deployment structures, and better converged Pareto fronts.},
  archive      = {J_TEVC},
  author       = {Zhao Wang and Maoguo Gong and Peng Li and Fei Xie and Mingyang Zhang},
  doi          = {10.1109/TEVC.2022.3168427},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {355-369},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A bilevel gene-based multiobjective memetic algorithm for passive localization system deployment optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Offline and online objective reduction via gaussian mixture
model clustering. <em>TEVC</em>, <em>27</em>(2), 341–354. (<a
href="https://doi.org/10.1109/TEVC.2022.3168836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective reduction has been regarded as a basic issue in many-objective optimization. Existing objective reduction methods identify one set of essential objectives using an approximate nondominated front. However, if the Pareto front (PF) of a many-objective optimization problem (MaOP) is irregular, one single set of essential objectives may not be efficient for objective reduction. This article proposes to produce several different sets of essential objectives in objective reduction. More specifically, we use the Gaussian mixture model clustering to classify the obtained nondominated front into different subsets and perform objective reduction on each subset. Both an offline objective reduction method and an online objective reduction method are developed. The experimental results indicate that our proposed methods work well for MaOPs with degenerate or nondegenerate PFs.},
  archive      = {J_TEVC},
  author       = {Genghui Li and Zhenkun Wang and Qingfu Zhang and Jianyong Sun},
  doi          = {10.1109/TEVC.2022.3168836},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {341-354},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Offline and online objective reduction via gaussian mixture model clustering},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Objective space-based population generation to accelerate
evolutionary algorithms for large-scale many-objective optimization.
<em>TEVC</em>, <em>27</em>(2), 326–340. (<a
href="https://doi.org/10.1109/TEVC.2022.3166815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation and updating of solutions, e.g., crossover and mutation, of many existing evolutionary algorithms directly operate on decision variables. The operators are very time consuming for large-scale and many-objective optimization problems. Different from them, this work proposes an objective space-based population generation method to obtain new individuals in the objective space and then map them to decision variable space and synthesize new solutions. It introduces three new objective vector generation methods and uses a linear mapping method to tightly connect objective space and decision one to jointly determine new-generation solutions. A loop can be formed directly between two spaces, which can generate new solutions faster and use more feedback information in the objective space. In order to demonstrate the performance of the proposed algorithm, this work performs a series of empirical experiments involving both large-scale decision variables and many objectives. Compared with the state-of-the-art traditional and large-scale algorithms, the proposed method exceeds or at least reaches its peers’ best level in overall performance while achieving great saving in execution time.},
  archive      = {J_TEVC},
  author       = {Qi Deng and Qi Kang and Liang Zhang and MengChu Zhou and Jing An},
  doi          = {10.1109/TEVC.2022.3166815},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {326-340},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Objective space-based population generation to accelerate evolutionary algorithms for large-scale many-objective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge transfer genetic programming with auxiliary
population for solving uncertain capacitated arc routing problem.
<em>TEVC</em>, <em>27</em>(2), 311–325. (<a
href="https://doi.org/10.1109/TEVC.2022.3169289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertain capacitated arc routing problem (UCARP) is an NP-hard combinatorial optimization problem with a wide range of applications in logistics domains. Genetic programming (GP) hyper-heuristic has been successfully applied to evolve routing policies to effectively handle the uncertain environment in this problem. The real world usually encounters different but related instances due to events, such as season change and vehicle breakdowns, and it is desirable to transfer knowledge gained from solving one instance to help solve another related one. However, the solutions found by the GP process can lack diversity, and the existing methods use the transferred knowledge mainly during initialization. Thus, they cannot sufficiently handle the change from the source to the target instance. To address this issue, we develop a novel knowledge transfer GP with an auxiliary population. In addition to the main population for the target instance, we initialize an auxiliary population using the transferred knowledge and evolve it alongside the main population. We develop a novel scheme to carefully exchange the knowledge between the two populations, and a surrogate model to evaluate the auxiliary population efficiently. The experimental results confirm that the proposed method performed significantly better than the state-of-the-art GP approaches for a wide range of uncertain arc routing instances, in terms of both final performance and convergence speed.},
  archive      = {J_TEVC},
  author       = {Mazhar Ansari Ardeh and Yi Mei and Mengjie Zhang and Xin Yao},
  doi          = {10.1109/TEVC.2022.3169289},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {311-325},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knowledge transfer genetic programming with auxiliary population for solving uncertain capacitated arc routing problem},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differential evolution-based feature selection: A
niching-based multiobjective approach. <em>TEVC</em>, <em>27</em>(2),
296–310. (<a href="https://doi.org/10.1109/TEVC.2022.3168052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is to reduce both the dimensionality of data and the classification error rate (i.e., increase the classification accuracy) of a learning algorithm. The two objectives are often conflicting, thus a multiobjective feature selection method can obtain a set of nondominated feature subsets. Each solution in the set has a different size and a corresponding classification error rate. However, most existing feature selection algorithms have ignored that, for a given size, there can be different feature subsets with very similar or the same accuracy. This article introduces a niching-based multiobjective feature selection method that simultaneously minimizes the number of selected features and the classification error rate. The proposed method conceives to identify: 1) a set of feature subsets with good convergence and distribution and 2) multiple feature subsets choosing the same number of features with almost the same lowest classification error rate. The contributions of this article are threefold. First, a niching and global interaction mutation operator is proposed that can produce promising feature subsets. Second, a newly developed environmental selection mechanism allows equal informative feature subsets to be stored by relaxing the Pareto-dominance relationship. Finally, the proposed subset repairing mechanism can generate better feature subsets and further remove the redundant features. The proposed method is compared against seven multiobjective feature selection algorithms on 19 datasets, including both binary and multiclass classification tasks. The results show that the proposed method can evolve a rich and diverse set of nondominated solutions for different feature selection tasks, and their availability helps in understanding the relationships between features.},
  archive      = {J_TEVC},
  author       = {Peng Wang and Bing Xue and Jing Liang and Mengjie Zhang},
  doi          = {10.1109/TEVC.2022.3168052},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {296-310},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Differential evolution-based feature selection: A niching-based multiobjective approach},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the evolutionary synthesis of fault-resilient digital
circuits. <em>TEVC</em>, <em>27</em>(2), 281–295. (<a
href="https://doi.org/10.1109/TEVC.2022.3169641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the event of an upset, fault-resilient circuits maintain correct functionality allowing the system to remain fully operational or at least operate with a graceful degradation. Every circuit has a certain level of inherent resilience to faults. Often times, this inherent resilience to faults is insufficient for the given application. This is because conventional synthesis tools generally only focus on optimizing a circuit with respect to area, power, or timing budgets. There is a wide range of applications where faulty circuit behavior can lead to fatal results. Fault injection analyses are reported and show that even a single fault can be critical to the desired circuit operation. To which end, this article presents synthesis of fault-resilient (SYFR) circuits, an evolutionary method for automated synthesis of increased fault-resilience digital circuits suitable for fine-grained use. Test results for synthesis of up to 60 input circuits with SYFR are reported. SYFR can be repeatedly applied to a circuit to obtain various design tradeoffs between fault resilience and implementation costs. SYFR can also be flexibly applied to build circuits, which are selectively fault resilient, i.e., their tolerance to faults is workload aware. In addition, a novel population seeding mechanism to reduce the design space is introduced and experimentally validated. In summary, this article demonstrates that SYFR can be considered a competitive synthesis methodology for constructing fault-resilient circuits.},
  archive      = {J_TEVC},
  author       = {Umar Afzaal and Abdus Sami Hassan and Muhammad Usman and Jeong-A Lee},
  doi          = {10.1109/TEVC.2022.3169641},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {281-295},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {On the evolutionary synthesis of fault-resilient digital circuits},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A variable granularity search-based multiobjective feature
selection algorithm for high-dimensional data classification.
<em>TEVC</em>, <em>27</em>(2), 266–280. (<a
href="https://doi.org/10.1109/TEVC.2022.3160458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) have shown their competitiveness in solving the problem of feature selection (FS). However, in most of the existing EA-based FS methods, one bit in the individual only represents one feature, which means with the number of features increasing, the search space of these methods increases exponentially and makes them not suitable for the data classification with high dimensions. To tackle the issue, in this article, a variable granularity search-based multiobjective EA, termed as VGS-MOEA, is proposed for high-dimensional FS, where one bit in the individual representation denotes a group of features and results in the search space reducing greatly. To be specific, at the beginning, the search granularity of VGS-MOEA is coarse (a bit denotes a great number of features), which helps the proposed algorithm detect the potentially good feature subsets quickly. As the evolution continues, the search granularity is refined gradually, where a bit denotes a smaller number of features until it only represents one feature. With this decomposition of granularity, a more refined search is performed and leads to the VGS-MOEA obtaining feature subsets with higher quality. Experimental results on 12 high-dimensional data sets with different characteristics have shown that in comparison with the state of the arts, the proposed VGS-MOEA has demonstrated its superiority in terms of the classification accuracy, the number of selected features, and the running time.},
  archive      = {J_TEVC},
  author       = {Fan Cheng and Junjie Cui and Qijun Wang and Lei Zhang},
  doi          = {10.1109/TEVC.2022.3160458},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {266-280},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A variable granularity search-based multiobjective feature selection algorithm for high-dimensional data classification},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving the single-row facility layout problem by k-medoids
memetic permutation group. <em>TEVC</em>, <em>27</em>(2), 251–265. (<a
href="https://doi.org/10.1109/TEVC.2022.3165987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single-row facility layout problem (SRFLP) is concerned with arranging facilities along a straight line so as to minimize the sum of the products of the flow costs and distances among all facility pairs. SRFLP has rich practical applications and is however NP-hard. In this article, we first investigate a dedicated symmetry-breaking approach based on the permutation group theory for reducing the solution space of SRFLP. Relevant symmetry properties are identified through the alternating group of the original solution space or the corresponding coordinate rotation space. Then, a memetic algorithm is proposed to explore promising search regions regarding the reduced solution space. The memetic algorithm employs a problem-specific crossover operator guided by ${k}$ -medoids clustering technique to produce meaningful offspring solutions. The algorithm additionally uses a simulated annealing procedure to intensively exploit a given search region and a distance-and-quality-based population management strategy to ensure a reasonable diversity of the population. Experimental results on commonly used benchmark instances and newly introduced large-scale instances with sizes up to 2000 facilities show that the proposed algorithm competes favorably with state-of-the-art SRFLP algorithms. It attains all but one previous best known upper bounds (BKS) and discovers new upper bounds for 33 instances out of the 93 popular benchmark instances.},
  archive      = {J_TEVC},
  author       = {Lixin Tang and Zuocheng Li and Jin-Kao Hao},
  doi          = {10.1109/TEVC.2022.3165987},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {251-265},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Solving the single-row facility layout problem by K-medoids memetic permutation group},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multiobjective multitask optimization algorithm using
transfer rank. <em>TEVC</em>, <em>27</em>(2), 237–250. (<a
href="https://doi.org/10.1109/TEVC.2022.3147568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective multitask optimization (MMO) attempts to solve several problems simultaneously. This is commonly done by identifying useful knowledge to transfer between tasks, thereby producing optimal solutions more quickly. In this study, an MMO algorithm using transfer rank and a KNN model is proposed to achieve this goal. The definition of transfer rank is first introduced for quantifying the priority of transfer solutions, to improve the probability of a positive result. The solution with the higher rank was assumed to be the most suitable for transfer, as solutions were sorted in descending order based on transfer rank. Priority was given to previous and positive-transfer solutions and those with the same transfer rank were distinguished using a KNN model classifier. The effectiveness of the proposed algorithm was verified by studying benchmark MMO problems. The experimental results showed the proposed algorithm was more effective than other conventional MMO techniques.},
  archive      = {J_TEVC},
  author       = {Hongyan Chen and Hai-Lin Liu and Fangqing Gu and Kay Chen Tan},
  doi          = {10.1109/TEVC.2022.3147568},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {237-250},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A multiobjective multitask optimization algorithm using transfer rank},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A genetic algorithm approach to automate architecture design
for acoustic scene classification. <em>TEVC</em>, <em>27</em>(2),
222–236. (<a href="https://doi.org/10.1109/TEVC.2022.3185543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been widely used with remarkable success in the acoustic scene classification (ASC) task. However, the performance of these CNNs highly relies on their architectures, requiring a lot of effort and expertise to design CNNs suitable for the investigated problem. In this work, we propose an efficient genetic algorithm (GA) that aims to find optimized CNN architectures for the ASC task. The proposed algorithm uses frequency-dimension splitting of the input spectrograms in order to explore the architecture search space in sub-CNN models in addition to classical single-path CNNs. Specifically, this algorithm aims to find the best number of sub-CNNs in addition to their architectures to better capture the distinct features of the input spectrograms. The proposed GA is specifically designed for sound classification to suit the ASC task than many other GAs that optimize conventional single-path CNN architectures. Experimental results on three benchmark datasets demonstrate the effectiveness of the proposed method. Specifically, the proposed algorithm has achieved around 17.8\%, 16\%, and 17.2\%, relative improvement in accuracy with respect to the baseline systems on the development datasets of DCASE2018-Task1A, DCASE2019-Task1A, and DCASE2020-Task1A, respectively.},
  archive      = {J_TEVC},
  author       = {Noha W. Hasan and Ali S. Saudi and Mahmoud I. Khalil and Hazem M. Abbas},
  doi          = {10.1109/TEVC.2022.3185543},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {222-236},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A genetic algorithm approach to automate architecture design for acoustic scene classification},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on evolutionary constrained multiobjective
optimization. <em>TEVC</em>, <em>27</em>(2), 201–221. (<a
href="https://doi.org/10.1109/TEVC.2022.3155533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling constrained multiobjective optimization problems (CMOPs) is extremely challenging, since multiple conflicting objectives subject to various constraints require to be simultaneously optimized. To deal with CMOPs, numerous constrained multiobjective evolutionary algorithms (CMOEAs) have been proposed in recent years, and they have achieved promising performance. However, there has been few literature on the systematic review of the related studies currently. This article provides a comprehensive survey for evolutionary constrained multiobjective optimization. We first review a large number of CMOEAs through categorization and analyze their advantages and drawbacks in each category. Then, we summarize the benchmark test problems and investigate the performance of different constraint handling techniques (CHTs) and different algorithms, followed by some emerging and representative applications of CMOEAs. Finally, we discuss some new challenges and point out some directions of the future research in the field of evolutionary constrained multiobjective optimization.},
  archive      = {J_TEVC},
  author       = {Jing Liang and Xuanxuan Ban and Kunjie Yu and Boyang Qu and Kangjia Qiao and Caitong Yue and Ke Chen and Kay Chen Tan},
  doi          = {10.1109/TEVC.2022.3155533},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {2},
  pages        = {201-221},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey on evolutionary constrained multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Orthogonal transfer for multitask optimization.
<em>TEVC</em>, <em>27</em>(1), 185–200. (<a
href="https://doi.org/10.1109/TEVC.2022.3160196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge transfer (KT) plays a key role in multitask optimization. However, most of the existing KT methods still face two challenges. First, the tasks may commonly have different dimensionalities (DDs), making the KT between heterogeneous search spaces very difficult. Second, the tasks may have different degrees of similarity in different dimensions, making that treating all dimensions with equal importance may be harmful to the KT process. To address these two challenges, this article proposes a novel orthogonal transfer (OT) method that is enabled by a cross-task mapping (CTM) strategy, which can achieve high-quality KT among heterogeneous tasks. For the first challenge, the CTM strategy maps the global best individual of one task from its original search space to the search space of the target task via an optimization process, which can handle the difference in task dimensionality. For the second challenge, the OT method is performed on the CTM-obtained individual and a random individual of the target task to find the best combination of different dimensions in these two individuals rather than treating all the dimensions equally, so as to achieve high-quality KT. To verify the effectiveness of the proposed OT method and the resulted OT-based multitask optimization (OTMTO) algorithm, this article not only uses the existing multitask optimization benchmark but also proposes a new benchmark test suite named multitask optimization problems (MTOPs) with DDs. Comprehensive experimental results on the existing and the proposed benchmarks show that the proposed OT method and the OTMTO algorithm are very advantageous in providing high-quality KT and in handling the heterogeneity of search space in MTOPs compared to the existing competitive evolutionary multitask optimization (EMTO) algorithms.},
  archive      = {J_TEVC},
  author       = {Sheng-Hao Wu and Zhi-Hui Zhan and Kay Chen Tan and Jun Zhang},
  doi          = {10.1109/TEVC.2022.3160196},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {185-200},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Orthogonal transfer for multitask optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast multipoint expected improvement for parallel
expensive optimization. <em>TEVC</em>, <em>27</em>(1), 170–184. (<a
href="https://doi.org/10.1109/TEVC.2022.3168060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multipoint expected improvement (EI) criterion is a well-defined parallel infill criterion for expensive optimization. However, the exact calculation of the classical multipoint EI involves evaluating a significant amount of multivariate normal cumulative distribution functions, which makes the inner optimization of this infill criterion very time consuming when the number of infill samples is large. To tackle this problem, we propose a novel fast multipoint EI criterion in this work. The proposed infill criterion is calculated using only univariate normal cumulative distributions; thus, it is easier to implement and cheaper to compute than the classical multipoint EI criterion. It is shown that the computational time of the proposed fast multipoint EI is several orders lower than the classical multipoint EI on the benchmark problems. In addition, we propose to use cooperative coevolutionary algorithms (CCEAs) to solve the inner optimization problem of the proposed fast multipoint EI by decomposing the optimization problem into multiple subproblems with each subproblem corresponding to one infill sample and solving these subproblems cooperatively. Numerical experiments show that using CCEAs can improve the performance of the proposed algorithm significantly compared with using standard evolutionary algorithms. This work provides a fast and efficient approach for parallel expensive optimization.},
  archive      = {J_TEVC},
  author       = {Dawei Zhan and Yun Meng and Huanlai Xing},
  doi          = {10.1109/TEVC.2022.3168060},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {170-184},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A fast multipoint expected improvement for parallel expensive optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiobjective multitask optimization-neighborhood as a
bridge for knowledge transfer. <em>TEVC</em>, <em>27</em>(1), 155–169.
(<a href="https://doi.org/10.1109/TEVC.2022.3154416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implicit parallelism of a population in evolutionary algorithms (EAs) provides an ideal platform for dealing with multiple tasks simultaneously. However, little effort has been made to explore what information among different tasks can be used as valuable knowledge to help the optimization of different tasks. This article proposes a multiobjective multitask optimization (MO-MTO) EA based on decomposition with dual neighborhoods (MTEA/D-DN), in which the neighborhood is used as a bridge to achieve knowledge transfer among different tasks. In MTEA/D-DN, each subproblem not only maintains a neighborhood (internal neighborhood) within its own task based on the Euclidean distance between weight vectors but also keeps a neighborhood (external neighborhood) with the subproblems of other tasks via gray relation analysis in order to mine valuable information and communicate among tasks. The experimental studies show that our proposed algorithm outperforms five other state-of-the-art algorithms on a set of benchmark test instances and a real-world problem in steel plant.},
  archive      = {J_TEVC},
  author       = {Xianpeng Wang and Zhiming Dong and Lixin Tang and Qingfu Zhang},
  doi          = {10.1109/TEVC.2022.3154416},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {155-169},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective multitask optimization-neighborhood as a bridge for knowledge transfer},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary optimization of COVID-19 vaccine distribution
with evolutionary demands. <em>TEVC</em>, <em>27</em>(1), 141–154. (<a
href="https://doi.org/10.1109/TEVC.2022.3164260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vaccination uptake has become the key factor that will determine our success in containing the coronavirus pneumonia (COVID-19) pandemic. Efficient distribution of vaccines to inoculation spots is crucial to curtailing the spread of the novel COVID-19 pandemic. Normally, in a big city, a huge number of vaccines need to be transported from central depot(s) through a set of satellites to widely scattered inoculation spots by special-purpose vehicles every day. Such a large two-echelon vehicle routing problem is computationally difficult. Moreover, the demands for vaccines evolve with the epidemic spread over time, and the actual demands are hard to determine early and exactly, which not only increases the problem difficulty but also prolongs the distribution time. Based on our practical experience of COVID-19 vaccine distribution in China, we present a hybrid machine learning and evolutionary computation method, which first uses a fuzzy deep learning model to forecast the demands for vaccines for each next day, such that we can predistribute the forecasted number of vaccines to the satellites in advance; after obtaining the actual demands, it uses an evolutionary algorithm (EA) to route vehicles to distribute vaccines from the satellites/depots to the inoculation spots on each day. The EA saves historical problem instances and their high-quality solutions in a knowledge base, so as to capture inherent relationship between evolving problem inputs to solutions; when solving a new problem instance on each day, the EA utilizes historical solutions that perform well on the similar instances to improve initial solution quality and, hence, accelerate convergence. Computational results on real-world instances of vaccine distribution demonstrate that the proposed method can produce solutions with significantly shorter distribution time compared to state-of-the-arts and, hence, contribute to accelerating the achievement of herd immunity.},
  archive      = {J_TEVC},
  author       = {Yu-Jun Zheng and Xin Chen and Qin Song and Jun Yang and Ling Wang},
  doi          = {10.1109/TEVC.2022.3164260},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {141-154},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary optimization of COVID-19 vaccine distribution with evolutionary demands},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Batched data-driven evolutionary multiobjective optimization
based on manifold interpolation. <em>TEVC</em>, <em>27</em>(1), 126–140.
(<a href="https://doi.org/10.1109/TEVC.2022.3162993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective optimization problems are ubiquitous in real-world science, engineering, and design optimization problems. It is not uncommon that the objective functions are as a black box, the evaluation of which usually involve time-consuming and/or costly physical experiments. Data-driven evolutionary optimization can be used to search for a set of nondominated tradeoff solutions, where the expensive objective functions are approximated as a surrogate model. In this article, we propose a framework for implementing batched data-driven evolutionary multiobjective optimization (EMO). It is so general that any off-the-shelf EMO algorithms can be applied in a plug-in manner. There are two unique components: 1) based on the Karush–Kuhn–Tucker conditions, a manifold interpolation approach that explores more diversified solutions with a convergence guarantee along the manifold of the approximated Pareto-optimal set and 2) a batch recommendation approach that reduces the computational time of the data-driven evolutionary optimization process by evaluating multiple samples at a time in parallel. Comparing against seven state-of-the-art surrogate-assisted evolutionary algorithms, experiments on 168 benchmark test problem instances with various properties and a real-world application on hyper-parameter optimization fully demonstrate the effectiveness and superiority of our proposed framework, which is featured with a faster convergence and a stronger resilience to various Pareto-optimal front shapes.},
  archive      = {J_TEVC},
  author       = {Ke Li and Renzhi Chen},
  doi          = {10.1109/TEVC.2022.3162993},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {126-140},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Batched data-driven evolutionary multiobjective optimization based on manifold interpolation},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A distributed model predictive control-based method for
multidifferent-target search in unknown environments. <em>TEVC</em>,
<em>27</em>(1), 111–125. (<a
href="https://doi.org/10.1109/TEVC.2022.3161942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a framework for multidifferent-target search in unknown environments based on swarm intelligence. In this framework, the idea of distributed model predictive control is introduced in the target search method. The use of a hierarchical prediction strategy further improves the robot’s path prediction ability in unknown environments. Compared with swarm intelligence methods—adaptive robotic particle swarm optimization (A-RPSO), improved group explosion strategy (IGES), and other existing works, this strategy significantly improves the multidifferent-target search functionality and the task success rate in unknown complex obstacle environments. Moreover, two effective efforts are then introduced to reduce computational complexity and speed up online decision making. One is to select cooperative individuals based on the line of sight, and the other is to reduce both the frequency of decision making and the amount of data transmitted. A comparison between obstacle-free map experiments and obstacle map experiments confirms the effectiveness of the ideas and methods presented in this article.},
  archive      = {J_TEVC},
  author       = {Lei Zhao and Rui Li and Jianda Han and Jianlei Zhang},
  doi          = {10.1109/TEVC.2022.3161942},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {111-125},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A distributed model predictive control-based method for multidifferent-target search in unknown environments},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchy ranking method for multimodal multiobjective
optimization with local pareto fronts. <em>TEVC</em>, <em>27</em>(1),
98–110. (<a href="https://doi.org/10.1109/TEVC.2022.3155757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multiobjective problems (MMOPs) commonly arise in real-world situations where distant solutions in decision space share a very similar objective value. Traditional multimodal multiobjective evolutionary algorithms (MMEAs) prefer to pursue multiple Pareto solutions that have the same objective values. However, a more practical situation in engineering problems is that one solution is slightly worse than another in terms of objective values, while the solutions are far away in the decision space. In other words, such problems have global and local Pareto fronts (PFs). In this study, we proposed several benchmark problems with several local PFs. Then, we proposed an evolutionary algorithm with a hierarchy ranking method (HREA) to find both the global and the local PFs based on the decision maker’s preference. Regarding HREA, we proposed a local convergence quality evaluation method to better maintain diversity in the decision space. Moreover, a hierarchy ranking method was introduced to update the convergence archive. The experimental results show that HREA is competitive compared with other state-of-the-art MMEAs for solving the chosen benchmark problems.},
  archive      = {J_TEVC},
  author       = {Wenhua Li and Xingyi Yao and Tao Zhang and Rui Wang and Ling Wang},
  doi          = {10.1109/TEVC.2022.3155757},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {98-110},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Hierarchy ranking method for multimodal multiobjective optimization with local pareto fronts},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comprehensive survey on program synthesis with
evolutionary algorithms. <em>TEVC</em>, <em>27</em>(1), 82–97. (<a
href="https://doi.org/10.1109/TEVC.2022.3162324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic generation of computer programs is one of the main applications with practical relevance in the field of evolutionary computation. With program synthesis techniques not only software developers could be supported in their everyday work but even users without any programming knowledge could be empowered to automate repetitive tasks and implement their own new functionality. In recent years, many novel program synthesis approaches based on evolutionary algorithms have been proposed and evaluated on common benchmark problems. Therefore, we identify and discuss in this survey the relevant evolutionary program synthesis approaches in the literature and provide an in-depth analysis of their performance. The most influential approaches we identify are stack-based, grammar-guided, as well as linear genetic programming (GP). For the stack-based approaches, we identify 37 in-scope papers, and for the grammar-guided and linear GP approaches, we identify 12 and 5 papers, respectively. Furthermore, we find that these approaches perform well on benchmark problems if there is a simple mapping from the given input to the correct output. On problems where this mapping is complex, e.g., if the problem consists of several subproblems or requires iteration/recursion for a correct solution, results tend to be worse. Consequently, for future work, we encourage researchers not only to use a program’s output for assessing the quality of a solution but also the way toward a solution (e.g., correctly solved subproblems).},
  archive      = {J_TEVC},
  author       = {Dominik Sobania and Dirk Schweim and Franz Rothlauf},
  doi          = {10.1109/TEVC.2022.3162324},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {82-97},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A comprehensive survey on program synthesis with evolutionary algorithms},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to accelerate evolutionary search for large-scale
multiobjective optimization. <em>TEVC</em>, <em>27</em>(1), 67–81. (<a
href="https://doi.org/10.1109/TEVC.2022.3155593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing evolutionary search strategies are not so efficient when directly handling the decision space of large-scale multiobjective optimization problems (LMOPs). To enhance the efficiency of tackling LMOPs, this article proposes an accelerated evolutionary search (AES) strategy. Its main idea is to learn a gradient-descent-like direction vector (GDV) for each solution via the specially trained feedforward neural network, which may be the learnt possibly fastest convergent direction to reproduce new solutions efficiently. To be specific, a multilayer perceptron (MLP) with only one hidden layer is constructed, in which the number of neurons in the input and output layers is equal to the dimension of the decision space. Then, to get appropriate training data for the model, the current population is divided into two subsets based on the nondominated sorting, and each poor solution in one subset with worse convergence will be paired to an elitist solution in another subset with the minimum angle to it, which is considered most likely to guide it with rapid convergence. Next, this MLP is updated via backpropagation with gradient descent by using the above elaborately prepared dataset. Finally, an accelerated large-scale multiobjective evolutionary algorithm (ALMOEA) is designed by using AES as a reproduction operator. Experimental studies validate the effectiveness of the proposed AES when handling the search space of LMOPs with dimensionality ranging from 1000 to 10000. When compared with six state-of-the-art evolutionary algorithms, the experimental results also show the better efficiency and performance of the proposed optimizer in solving various LMOPs.},
  archive      = {J_TEVC},
  author       = {Songbai Liu and Jun Li and Qiuzhen Lin and Ye Tian and Kay Chen Tan},
  doi          = {10.1109/TEVC.2022.3155593},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {67-81},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning to accelerate evolutionary search for large-scale multiobjective optimization},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary computation in action: Hyperdimensional deep
embedding spaces of gigapixel pathology images. <em>TEVC</em>,
<em>27</em>(1), 52–66. (<a
href="https://doi.org/10.1109/TEVC.2022.3178299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main obstacles of adopting digital pathology is the challenge of efficient processing of hyperdimensional digitized biopsy samples, called whole slide images (WSIs). Exploiting deep learning and introducing compact WSI representations are urgently needed to accelerate image analysis and facilitate the visualization and interpretability of pathology results in a postpandemic world. In this article, we introduce a new evolutionary approach for WSI representation based on large-scale multiobjective optimization (LSMOP) of deep embeddings. We start with patch-based sampling to feed KimiaNet, a histopathology-specialized deep network, and to extract a multitude of feature vectors. Coarse multiobjective feature selection uses the reduced search space strategy guided by the classification accuracy and the number of features. In the second stage, the frequent features histogram (FFH), a novel WSI representation, is constructed by multiple runs of coarse LSMOP. Fine evolutionary feature selection is then applied to find a compact (short-length) feature vector based on the FFH and contributes to a more robust deep-learning approach to digital pathology supported by the stochastic power of evolutionary algorithms. We validate the proposed schemes using The Cancer Genome Atlas (TCGA) images in terms of WSI representation, classification accuracy, and feature quality. Furthermore, a novel decision space for multicriteria decision making in the LSMOP field is introduced. Finally, a patch-level visualization approach is proposed to increase the interpretability of deep features. The proposed evolutionary algorithm finds a very compact feature vector to represent a WSI (almost 14000 times smaller than the original feature vectors) with 8\% higher accuracy compared to the codes provided by the state-of-the-art methods},
  archive      = {J_TEVC},
  author       = {Azam Asilian Bidgoli and Shahryar Rahnamayan and Taher Dehkharghanian and Abtin Riasatian and Hamid R. Tizhoosh},
  doi          = {10.1109/TEVC.2022.3178299},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {52-66},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary computation in action: Hyperdimensional deep embedding spaces of gigapixel pathology images},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accurate multiobjective low-rank and sparse model for
hyperspectral image denoising method. <em>TEVC</em>, <em>27</em>(1),
37–51. (<a href="https://doi.org/10.1109/TEVC.2021.3078478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the unavoidable influence of sparse and Gaussian noise during the process of data acquisition, the quality of hyperspectral images (HSIs) is degraded and their applications are greatly limited. It is therefore necessary to restore clean HSIs. In the traditional methods, low-rank and sparse matrix decomposition methods are usually applied to restore the pure data matrix from the observed data matrix. However, due to the fact that the optimization of the ${l}_{0}$ -norm for the sparse modeling is a nonconvex and NP-hard problem, convex relaxation and regularization parameters are usually introduced. However, convex relaxation often leads to inaccurate sparse modeling results, and the sensitive regularization parameters can lead to unstable results. Thus, in this article, to address these issues, an accurate multiobjective low-rank and sparse denoising framework is proposed for HSIs to achieve accurate modeling. The ${l}_{0}$ -norm is directly modeled as the sparse noise and is optimized by an evolutionary algorithm, and the denoising problem is converted into a multiobjective optimization problem through simultaneously optimizing the low-rank term, the sparse term, and the data fidelity term, without sensitive regularization parameters. However, since the low-rank clean image and sparse noise of the HSI are encoded into a solution, the length of the solution is too long to be optimized. In this article, a subfitness strategy is constructed to achieve effective optimization by comparing the objective function values corresponding to each band for each solution. The experiments undertaken with simulated images in 11 noise cases and four real noisy images confirm the effectiveness of the proposed method.},
  archive      = {J_TEVC},
  author       = {Yuting Wan and Ailong Ma and Wei He and Yanfei Zhong},
  doi          = {10.1109/TEVC.2021.3078478},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {37-51},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Accurate multiobjective low-rank and sparse model for hyperspectral image denoising method},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PRE-NAS: Evolutionary neural architecture search with
predictor. <em>TEVC</em>, <em>27</em>(1), 26–36. (<a
href="https://doi.org/10.1109/TEVC.2022.3227562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) aims to automate architecture engineering in neural networks. This often requires a high computational overhead to evaluate a number of candidate networks from the set of all possible networks in the search space. Prediction of the performance of a network can alleviate this high computational overhead by mitigating the need for evaluating every candidate network. Developing such a predictor typically requires a large number of evaluated architectures which may be difficult to obtain. We address this challenge by proposing a novel evolutionary-based NAS strategy, predictor-assisted evolutionary NAS (PRE-NAS) which can perform well even with an extremely small number of evaluated architectures. PRE-NAS leverages new evolutionary search strategies and integrates high-fidelity weight inheritance over generations. Unlike one-shot strategies, which may suffer from bias in the evaluation due to weight sharing, offspring candidates in PRE-NAS are topologically homogeneous. This circumvents bias and leads to more accurate predictions. Extensive experiments on the NAS-Bench-201 and DARTS search spaces show that PRE-NAS can outperform state-of-the-art NAS methods. With only a single GPU searching for 0.6 days, a competitive architecture can be found by PRE-NAS which achieves 2.40\% and 24\% test error rates on CIFAR-10 and ImageNet, respectively.},
  archive      = {J_TEVC},
  author       = {Yameng Peng and Andy Song and Vic Ciesielski and Haytham M. Fayek and Xiaojun Chang},
  doi          = {10.1109/TEVC.2022.3227562},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {26-36},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {PRE-NAS: Evolutionary neural architecture search with predictor},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on evolutionary computation for computer vision and
image analysis: Past, present, and future trends. <em>TEVC</em>,
<em>27</em>(1), 5–25. (<a
href="https://doi.org/10.1109/TEVC.2022.3220747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision (CV) is a big and important field in artificial intelligence covering a wide range of applications. Image analysis is a major task in CV aiming to extract, analyze and understand the visual content of images. However, image-related tasks are very challenging due to many factors, e.g., high variations across images, high dimensionality, domain expertise requirement, and image distortions. Evolutionary computation (EC) approaches have been widely used for image analysis with significant achievement. However, there is no comprehensive survey of existing EC approaches to image analysis. To fill this gap, this article provides a comprehensive survey covering all essential EC approaches to important image analysis tasks, including edge detection, image segmentation, image feature analysis, image classification, object detection, and others. This survey aims to provide a better understanding of evolutionary CV (ECV) by discussing the contributions of different approaches and exploring how and why EC is used for CV and image analysis. The applications, challenges, issues, and trends associated to this research field are also discussed and summarized to provide further guidelines and opportunities for future research.},
  archive      = {J_TEVC},
  author       = {Ying Bi and Bing Xue and Pablo Mesejo and Stefano Cagnoni and Mengjie Zhang},
  doi          = {10.1109/TEVC.2022.3220747},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {5-25},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey on evolutionary computation for computer vision and image analysis: Past, present, and future trends},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guest editorial special issue on evolutionary computer
vision. <em>TEVC</em>, <em>27</em>(1), 2–4. (<a
href="https://doi.org/10.1109/TEVC.2023.3235641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary Computer Vision (ECV) is at the intersection of two major research fields of artificial intelligence: 1) computer vision (CV) and 2) evolutionary computation (EC). This special issue brings an overview of state-of-the-art contributions to the latest research and development in the discipline. CV includes methods for acquiring, processing, analyzing, and understanding images. The aim is to design computational models of human and animal perception. ECV is an interdisciplinary research area where analytical methods combined with powerful stochastic optimization and metaheuristic approaches produced human-competitive results. From an engineering standpoint, ECV aims to design software and hardware solutions useful for solving challenging CV problems. From a scientific viewpoint, the goal is to enhance our current understanding of visual processing in nature and replicate this within a seeing machine. ECV is a well-established research discipline as evolutionary algorithms are more efficient than classical optimization approaches for the discontinuous, nondifferentiable, multimodal, and noisy search, optimization, and learning problems arising in many CV tasks. EC has also demonstrated its ability as a robust approach to cope with the fundamental steps of image processing, image analysis, and image understanding included in the CV pipeline (e.g., restoration, segmentation, registration, classification, reconstruction, or tracking).},
  archive      = {J_TEVC},
  author       = {Gustavo Olague and Mario Köppen and Oscar Cordón},
  doi          = {10.1109/TEVC.2023.3235641},
  journal      = {IEEE Transactions on Evolutionary Computation},
  number       = {1},
  pages        = {2-4},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Guest editorial special issue on evolutionary computer vision},
  volume       = {27},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
