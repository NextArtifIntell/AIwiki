<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MP_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mp---172">MP - 172</h2>
<ul>
<li><details>
<summary>
(2023). Recognizing even-cycle and even-cut matroids. <em>MP</em>,
<em>202</em>(1), 515–542. (<a
href="https://doi.org/10.1007/s10107-023-01944-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even-cycle matroids are elementary lifts of graphic matroids and even-cut matroids are elementary lifts of cographic matroids. We present a polynomial algorithm to check if a binary matroid is an even-cycle matroid and we present a polynomial algorithm to check if a binary matroid is an even-cut matroid. These two algorithms rely on a polynomial algorithm (to be described in a pair of follow-up papers) to check if a binary matroid is pinch-graphic.},
  archive      = {J_MP},
  author       = {Guenin, Bertrand and Heo, Cheolwon},
  doi          = {10.1007/s10107-023-01944-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {515-542},
  shortjournal = {Math. Program.},
  title        = {Recognizing even-cycle and even-cut matroids},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). First- and second-order optimality conditions for
second-order cone and semidefinite programming under a constant rank
condition. <em>MP</em>, <em>202</em>(1), 473–513. (<a
href="https://doi.org/10.1007/s10107-023-01942-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The well known constant rank constraint qualification [Math. Program. Study 21:110–126, 1984] introduced by Janin for nonlinear programming has been recently extended to a conic context by exploiting the eigenvector structure of the problem. In this paper we propose a more general and geometric approach for defining a new extension of this condition to the conic context. The main advantage of our approach is that we are able to recast the strong second-order properties of the constant rank condition in a conic context. In particular, we obtain a second-order necessary optimality condition that is stronger than the classical one obtained under Robinson’s constraint qualification, in the sense that it holds for every Lagrange multiplier, even though our condition is independent of Robinson’s condition.},
  archive      = {J_MP},
  author       = {Andreani, Roberto and Haeser, Gabriel and Mito, Leonardo M. and Ramírez, Héctor and Silveira, Thiago P.},
  doi          = {10.1007/s10107-023-01942-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {473-513},
  shortjournal = {Math. Program.},
  title        = {First- and second-order optimality conditions for second-order cone and semidefinite programming under a constant rank condition},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A trust region method for noisy unconstrained optimization.
<em>MP</em>, <em>202</em>(1), 445–472. (<a
href="https://doi.org/10.1007/s10107-023-01941-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical trust region methods were designed to solve problems in which function and gradient information are exact. This paper considers the case when there are errors (or noise) in the above computations and proposes a simple modification of the trust region method to cope with these errors. The new algorithm only requires information about the size/standard deviation of the errors in the function evaluations and incurs no additional computational expense. It is shown that, when applied to a smooth (but not necessarily convex) objective function, the iterates of the algorithm visit a neighborhood of stationarity infinitely often, assuming errors in the function and gradient evaluations are bounded. It is also shown that, after visiting the above neighborhood for the first time, the iterates cannot stray too far from it, as measured by the objective value. Numerical results illustrate how the classical trust region algorithm may fail in the presence of noise, and how the proposed algorithm ensures steady progress towards stationarity in these cases.},
  archive      = {J_MP},
  author       = {Sun, Shigeng and Nocedal, Jorge},
  doi          = {10.1007/s10107-023-01941-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {445-472},
  shortjournal = {Math. Program.},
  title        = {A trust region method for noisy unconstrained optimization},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of the optimization landscape of linear quadratic
gaussian (LQG) control. <em>MP</em>, <em>202</em>(1), 399–444. (<a
href="https://doi.org/10.1007/s10107-023-01938-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper revisits the classical Linear Quadratic Gaussian (LQG) control from a modern optimization perspective. We analyze two aspects of the optimization landscape of the LQG problem: (1) Connectivity of the set of stabilizing controllers $$\mathcal {C}_n$$ ; and (2) Structure of stationary points. It is known that similarity transformations do not change the input-output behavior of a dynamic controller or LQG cost. This inherent symmetry by similarity transformations makes the landscape of LQG very rich. We show that (1) The set of stabilizing controllers $$\mathcal {C}_n$$ has at most two path-connected components and they are diffeomorphic under a mapping defined by a similarity transformation; (2) There might exist many strictly suboptimal stationary points of the LQG cost function over $$\mathcal {C}_n$$ that are not controllable and not observable; (3) All controllable and observable stationary points are globally optimal and they are identical up to a similarity transformation. These results shed some light on the performance analysis of direct policy gradient methods for solving the LQG problem.},
  archive      = {J_MP},
  author       = {Tang, Yujie and Zheng, Yang and Li, Na},
  doi          = {10.1007/s10107-023-01938-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {399-444},
  shortjournal = {Math. Program.},
  title        = {Analysis of the optimization landscape of linear quadratic gaussian (LQG) control},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Publisher correction to: Lyapunov stability of the
subgradient method with constant step size. <em>MP</em>,
<em>202</em>(1), 397–398. (<a
href="https://doi.org/10.1007/s10107-023-01948-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Josz, Cédric and Lai, Lexiao},
  doi          = {10.1007/s10107-023-01948-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {397-398},
  shortjournal = {Math. Program.},
  title        = {Publisher correction to: Lyapunov stability of the subgradient method with constant step size},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Lyapunov stability of the subgradient method with constant
step size. <em>MP</em>, <em>202</em>(1), 387–396. (<a
href="https://doi.org/10.1007/s10107-023-01936-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the subgradient method with constant step size for minimizing locally Lipschitz semi-algebraic functions. In order to analyze the behavior of its iterates in the vicinity of a local minimum, we introduce a notion of discrete Lyapunov stability and propose necessary and sufficient conditions for stability.},
  archive      = {J_MP},
  author       = {Josz, Cédric and Lai, Lexiao},
  doi          = {10.1007/s10107-023-01936-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {387-396},
  shortjournal = {Math. Program.},
  title        = {Lyapunov stability of the subgradient method with constant step size},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction: Global convergence of the gradient method for
functions definable in o-minimal structures. <em>MP</em>,
<em>202</em>(1), 385. (<a
href="https://doi.org/10.1007/s10107-023-01972-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Josz, Cédric},
  doi          = {10.1007/s10107-023-01972-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {385},
  shortjournal = {Math. Program.},
  title        = {Correction: Global convergence of the gradient method for functions definable in o-minimal structures},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Global convergence of the gradient method for functions
definable in o-minimal structures. <em>MP</em>, <em>202</em>(1),
355–383. (<a href="https://doi.org/10.1007/s10107-023-01937-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the gradient method with variable step size for minimizing functions that are definable in o-minimal structures on the real field and differentiable with locally Lipschitz gradients. We prove that global convergence holds if continuous gradient trajectories are bounded, with the minimum gradient norm vanishing at the rate o(1/k) if the step sizes are greater than a positive constant. If additionally the gradient is continuously differentiable, all saddle points are strict, and the step sizes are constant, then convergence to a local minimum holds almost surely over any bounded set of initial points.},
  archive      = {J_MP},
  author       = {Josz, Cédric},
  doi          = {10.1007/s10107-023-01937-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {355-383},
  shortjournal = {Math. Program.},
  title        = {Global convergence of the gradient method for functions definable in o-minimal structures},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Inequality constrained stochastic nonlinear optimization
via active-set sequential quadratic programming. <em>MP</em>,
<em>202</em>(1), 279–353. (<a
href="https://doi.org/10.1007/s10107-023-01935-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study nonlinear optimization problems with a stochastic objective and deterministic equality and inequality constraints, which emerge in numerous applications including finance, manufacturing, power systems and, recently, deep neural networks. We propose an active-set stochastic sequential quadratic programming (StoSQP) algorithm that utilizes a differentiable exact augmented Lagrangian as the merit function. The algorithm adaptively selects the penalty parameters of the augmented Lagrangian, and performs a stochastic line search to decide the stepsize. The global convergence is established: for any initialization, the KKT residuals converge to zero almost surely. Our algorithm and analysis further develop the prior work of Na et al. (Math Program, 2022. https://doi.org/10.1007/s10107-022-01846-z ). Specifically, we allow nonlinear inequality constraints without requiring the strict complementary condition; refine some of designs in Na et al. (2022) such as the feasibility error condition and the monotonically increasing sample size; strengthen the global convergence guarantee; and improve the sample complexity on the objective Hessian. We demonstrate the performance of the designed algorithm on a subset of nonlinear problems collected in CUTEst test set and on constrained logistic regression problems.},
  archive      = {J_MP},
  author       = {Na, Sen and Anitescu, Mihai and Kolar, Mladen},
  doi          = {10.1007/s10107-023-01935-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {279-353},
  shortjournal = {Math. Program.},
  title        = {Inequality constrained stochastic nonlinear optimization via active-set sequential quadratic programming},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discrete potential mean field games: Duality and numerical
resolution. <em>MP</em>, <em>202</em>(1), 241–278. (<a
href="https://doi.org/10.1007/s10107-023-01934-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and investigate a general class of discrete time and finite state space mean field game (MFG) problems with potential structure. Our model incorporates interactions through a congestion term and a price variable. It also allows hard constraints on the distribution of the agents. We analyze the connection between the MFG problem and two optimal control problems in duality. We present two families of numerical methods and detail their implementation: (i) primal-dual proximal methods (and their extension with nonlinear proximity operators), (ii) the alternating direction method of multipliers (ADMM) and a variant called ADM-G. We give some convergence results. Numerical results are provided for two examples with hard constraints.},
  archive      = {J_MP},
  author       = {Bonnans, J. Frédéric and Lavigne, Pierre and Pfeiffer, Laurent},
  doi          = {10.1007/s10107-023-01934-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {241-278},
  shortjournal = {Math. Program.},
  title        = {Discrete potential mean field games: Duality and numerical resolution},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A gradient sampling algorithm for stratified maps with
applications to topological data analysis. <em>MP</em>, <em>202</em>(1),
199–239. (<a href="https://doi.org/10.1007/s10107-023-01931-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel gradient descent algorithm refining the well-known Gradient Sampling algorithm on the class of stratifiably smooth objective functions, which are defined as locally Lipschitz functions that are smooth on some regular pieces—called the strata—of the ambient Euclidean space. On this class of functions, our algorithm achieves a sub-linear convergence rate. We then apply our method to objective functions based on the (extended) persistent homology map computed over lower-star filters, which is a central tool of Topological Data Analysis. For this, we propose an efficient exploration of the corresponding stratification by using the Cayley graph of the permutation group. Finally, we provide benchmarks and novel topological optimization problems that demonstrate the utility and applicability of our framework.},
  archive      = {J_MP},
  author       = {Leygonie, Jacob and Carrière, Mathieu and Lacombe, Théo and Oudot, Steve},
  doi          = {10.1007/s10107-023-01931-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {199-239},
  shortjournal = {Math. Program.},
  title        = {A gradient sampling algorithm for stratified maps with applications to topological data analysis},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel reformulation for the single-sink fixed-charge
transportation problem. <em>MP</em>, <em>202</em>(1), 169–198. (<a
href="https://doi.org/10.1007/s10107-023-01930-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single-sink fixed-charge transportation problem is known to have many applications in the area of manufacturing and transportation as well as being an important subproblem of the fixed-charge transportation problem. However, even the best algorithms from the literature do not fully leverage the structure of this problem, to the point of being surpassed by modern general-purpose mixed-integer programming solvers for large instances. We introduce a novel reformulation of the problem and study its theoretical properties. This reformulation leads to a range of new upper and lower bounds, dominance relations, linear relaxations, and filtering procedures. The resulting algorithm includes a heuristic phase and an exact phase, the main step of which is to solve a very small number of knapsack subproblems. Computational experiments are presented for existing and new types of instances. These tests indicate that the new algorithm systematically reduces the resolution time of the state-of-the-art exact methods by several orders of magnitude.},
  archive      = {J_MP},
  author       = {Legault, Robin and Côté, Jean-François and Gendron, Bernard},
  doi          = {10.1007/s10107-023-01930-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {169-198},
  shortjournal = {Math. Program.},
  title        = {A novel reformulation for the single-sink fixed-charge transportation problem},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data perturbations in stochastic generalized equations:
Statistical robustness in static and sample average approximated models.
<em>MP</em>, <em>202</em>(1), 135–168. (<a
href="https://doi.org/10.1007/s10107-023-01925-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sample average approximation which is also known as Monte Carlo method has been widely used for solving stochastic programming and equilibrium problems. In a data-driven environment, samples are often drawn from empirical data and hence may be potentially contaminated. Consequently it is legitimate to ask whether statistical estimators obtained from solving the sample average approximated problems are statistically robust, that is, the difference between the laws of the statistical estimators based on contaminated data and real data is controllable under some metrics. In Guo and Xu (Math Program 190:679–720, 2021), we address the issue for the estimators of the optimal values of a wide range of stochastic programming problems. In this paper, we complement the research by investigating the optimal solution estimators and we do so by considering stochastic generalized equations (SGE) as a unified framework. Specifically, we look into the impact of a single data perturbation on the solutions of the SGE using the notion of influence function in robust statistics. Since the SGE may have multiple solutions, we use the proto-derivative of a set-valued mapping to introduce the notion of generalized influence function (GIF) and derive sufficient conditions under which the GIF is well defined, bounded and uniformly bounded. We then move on to quantitative statistical analysis of the SGE when all of sample data are potentially contaminated and demonstrate under moderate conditions quantitative statistical robustness of the solutions obtained from solving sample average approximated SGE.},
  archive      = {J_MP},
  author       = {Guo, Shaoyan and Xu, Huifu},
  doi          = {10.1007/s10107-023-01925-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {135-168},
  shortjournal = {Math. Program.},
  title        = {Data perturbations in stochastic generalized equations: Statistical robustness in static and sample average approximated models},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). <span
class="math display"><strong>2</strong> <strong>×</strong> <strong>2</strong></span>
-convexifications for convex quadratic optimization with indicator
variables. <em>MP</em>, <em>202</em>(1), 95–134. (<a
href="https://doi.org/10.1007/s10107-023-01924-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the convex quadratic optimization problem with indicator variables. For the $${2\times 2}$$ case, we describe the convex hull of the epigraph in the original space of variables, and also give a conic quadratic extended formulation. Then, using the convex hull description for the $${2\times 2}$$ case as a building block, we derive an extended SDP relaxation for the general case. This new formulation is stronger than other SDP relaxations proposed in the literature for the problem, including the optimal perspective relaxation and the optimal rank-one relaxation. Computational experiments indicate that the proposed formulations are quite effective in reducing the integrality gap of the optimization problems.},
  archive      = {J_MP},
  author       = {Han, Shaoning and Gómez, Andrés and Atamtürk, Alper},
  doi          = {10.1007/s10107-023-01924-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {95-134},
  shortjournal = {Math. Program.},
  title        = {$$\mathbf {2\times 2}$$ -convexifications for convex quadratic optimization with indicator variables},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Publisher correction to: A new perspective on low-rank
optimization. <em>MP</em>, <em>202</em>(1), 93–94. (<a
href="https://doi.org/10.1007/s10107-023-01947-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Bertsimas, Dimitris and Cory-Wright, Ryan and Pauphilet, Jean},
  doi          = {10.1007/s10107-023-01947-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {93-94},
  shortjournal = {Math. Program.},
  title        = {Publisher correction to: A new perspective on low-rank optimization},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A new perspective on low-rank optimization. <em>MP</em>,
<em>202</em>(1), 47–92. (<a
href="https://doi.org/10.1007/s10107-023-01933-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key question in many low-rank problems throughout optimization, machine learning, and statistics is to characterize the convex hulls of simple low-rank sets and judiciously apply these convex hulls to obtain strong yet computationally tractable relaxations. We invoke the matrix perspective function—the matrix analog of the perspective function—to characterize explicitly the convex hull of epigraphs of simple matrix convex functions under low-rank constraints. Further, we combine the matrix perspective function with orthogonal projection matrices—the matrix analog of binary variables which capture the row-space of a matrix—to develop a matrix perspective reformulation technique that reliably obtains strong relaxations for a variety of low-rank problems, including reduced rank regression, non-negative matrix factorization, and factor analysis. Moreover, we establish that these relaxations can be modeled via semidefinite constraints and thus optimized over tractably. The proposed approach parallels and generalizes the perspective reformulation technique in mixed-integer optimization and leads to new relaxations for a broad class of problems.},
  archive      = {J_MP},
  author       = {Bertsimas, Dimitris and Cory-Wright, Ryan and Pauphilet, Jean},
  doi          = {10.1007/s10107-023-01933-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {47-92},
  shortjournal = {Math. Program.},
  title        = {A new perspective on low-rank optimization},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient joint object matching via linear programming.
<em>MP</em>, <em>202</em>(1), 1–46. (<a
href="https://doi.org/10.1007/s10107-023-01932-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint object matching, also known as multi-image matching, namely, the problem of finding consistent partial maps among all pairs of objects within a collection, is a crucial task in many areas of computer vision. This problem subsumes bipartite graph matching and graph partitioning as special cases and is NP-hard, in general. We develop scalable linear programming (LP) relaxations with theoretical performance guarantees for joint object matching. We start by proposing a new characterization of consistent partial maps; this in turn enables us to formulate joint object matching as an integer linear programming (ILP) problem. To construct strong LP relaxations, we study the facial structure of the convex hull of the feasible region of this ILP, which we refer to as the joint matching polytope. We present an exponential family of facet-defining inequalities that can be separated in strongly polynomial time, hence obtaining a partial characterization of the joint matching polytope that is both tight and cheap to compute. To analyze the theoretical performance of the proposed LP relaxations, we focus on permutation group synchronization, an important special case of joint object matching. We show that under the random corruption model for the input maps, a simple LP relaxation, that is, an LP containing only a very small fraction of the proposed facet-defining inequalities, recovers the ground truth with high probability if the corruption level is below 40\%. Finally, via a preliminary computational study on synthetic data, we show that the proposed LP relaxations outperform a popular SDP relaxation both in terms of recovery and tightness.},
  archive      = {J_MP},
  author       = {De Rosa, Antonio and Khajavirad, Aida},
  doi          = {10.1007/s10107-023-01932-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-46},
  shortjournal = {Math. Program.},
  title        = {Efficient joint object matching via linear programming},
  volume       = {202},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smooth over-parameterized solvers for non-smooth structured
optimization. <em>MP</em>, <em>201</em>(1), 897–952. (<a
href="https://doi.org/10.1007/s10107-022-01923-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-smooth optimization is a core ingredient of many imaging or machine learning pipelines. Non-smoothness encodes structural constraints on the solutions, such as sparsity, group sparsity, low-rank and sharp edges. It is also the basis for the definition of robust loss functions and scale-free functionals such as square-root Lasso. Standard approaches to deal with non-smoothness leverage either proximal splitting or coordinate descent. These approaches are effective but usually require parameter tuning, preconditioning or some sort of support pruning. In this work, we advocate and study a different route, which operates a non-convex but smooth over-parameterization of the underlying non-smooth optimization problems. This generalizes quadratic variational forms that are at the heart of the popular Iterative Reweighted Least Squares. Our main theoretical contribution connects gradient descent on this reformulation to a mirror descent flow with a varying Hessian metric. This analysis is crucial to derive convergence bounds that are dimension-free. This explains the efficiency of the method when using small grid sizes in imaging. Our main algorithmic contribution is to apply the Variable Projection method which defines a new formulation by explicitly minimizing over part of the variables. This leads to a better conditioning of the minimized functional and improves the convergence of simple but very efficient gradient-based methods, for instance quasi-Newton solvers. We exemplify the use of this new solver for the resolution of regularized regression problems for inverse problems and supervised learning, including total variation prior and non-convex regularizers.},
  archive      = {J_MP},
  author       = {Poon, Clarice and Peyré, Gabriel},
  doi          = {10.1007/s10107-022-01923-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {897-952},
  shortjournal = {Math. Program.},
  title        = {Smooth over-parameterized solvers for non-smooth structured optimization},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constrained composite optimization and augmented lagrangian
methods. <em>MP</em>, <em>201</em>(1), 863–896. (<a
href="https://doi.org/10.1007/s10107-022-01922-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate finite-dimensional constrained structured optimization problems, featuring composite objective functions and set-membership constraints. Offering an expressive yet simple language, this problem class provides a modeling framework for a variety of applications. We study stationarity and regularity concepts, and propose a flexible augmented Lagrangian scheme. We provide a theoretical characterization of the algorithm and its asymptotic properties, deriving convergence results for fully nonconvex problems. It is demonstrated how the inner subproblems can be solved by off-the-shelf proximal methods, notwithstanding the possibility to adopt any solvers, insofar as they return approximate stationary points. Finally, we describe our matrix-free implementation of the proposed algorithm and test it numerically. Illustrative examples show the versatility of constrained composite programs as a modeling tool and expose difficulties arising in this vast problem class.},
  archive      = {J_MP},
  author       = {De Marchi, Alberto and Jia, Xiaoxi and Kanzow, Christian and Mehlitz, Patrick},
  doi          = {10.1007/s10107-022-01922-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {863-896},
  shortjournal = {Math. Program.},
  title        = {Constrained composite optimization and augmented lagrangian methods},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strong valid inequalities for a class of concave submodular
minimization problems under cardinality constraints. <em>MP</em>,
<em>201</em>(1), 803–861. (<a
href="https://doi.org/10.1007/s10107-022-01921-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the polyhedral convex hull structure of a mixed-integer set which arises in a class of cardinality-constrained concave submodular minimization problems. This class of problems has an objective function in the form of $$f(a^\top x)$$ , where f is a univariate concave function, a is a non-negative vector, and x is a binary vector of appropriate dimension. Such minimization problems frequently appear in applications that involve risk-aversion or economies of scale. We propose three classes of strong valid linear inequalities for this convex hull and specify their facet conditions when a has two distinct values. We show how to use these inequalities to obtain valid inequalities for general a that contains multiple values. We further provide a complete linear convex hull description for this mixed-integer set when a contains two distinct values and the cardinality constraint upper bound is two. Our computational experiments on the mean-risk optimization problem demonstrate the effectiveness of the proposed inequalities in a branch-and-cut framework.},
  archive      = {J_MP},
  author       = {Yu, Qimeng and Küçükyavuz, Simge},
  doi          = {10.1007/s10107-022-01921-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {803-861},
  shortjournal = {Math. Program.},
  title        = {Strong valid inequalities for a class of concave submodular minimization problems under cardinality constraints},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Softmax policy gradient methods can take exponential time to
converge. <em>MP</em>, <em>201</em>(1), 707–802. (<a
href="https://doi.org/10.1007/s10107-022-01920-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The softmax policy gradient (PG) method, which performs gradient ascent under softmax policy parameterization, is arguably one of the de facto implementations of policy optimization in modern reinforcement learning. For $$\gamma $$ -discounted infinite-horizon tabular Markov decision processes (MDPs), remarkable progress has recently been achieved towards establishing global convergence of softmax PG methods in finding a near-optimal policy. However, prior results fall short of delineating clear dependencies of convergence rates on salient parameters such as the cardinality of the state space $${\mathcal {S}}$$ and the effective horizon $$\frac{1}{1-\gamma }$$ , both of which could be excessively large. In this paper, we deliver a pessimistic message regarding the iteration complexity of softmax PG methods, despite assuming access to exact gradient computation. Specifically, we demonstrate that the softmax PG method with stepsize $$\eta $$ can take $$\begin{aligned} \frac{1}{\eta } |{\mathcal {S}}|^{2^{\Omega \big (\frac{1}{1-\gamma }\big )}} ~\text {iterations} \end{aligned}$$ to converge, even in the presence of a benign policy initialization and an initial state distribution amenable to exploration (so that the distribution mismatch coefficient is not exceedingly large). This is accomplished by characterizing the algorithmic dynamics over a carefully-constructed MDP containing only three actions. Our exponential lower bound hints at the necessity of carefully adjusting update rules or enforcing proper regularization in accelerating PG methods.},
  archive      = {J_MP},
  author       = {Li, Gen and Wei, Yuting and Chi, Yuejie and Chen, Yuxin},
  doi          = {10.1007/s10107-022-01920-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {707-802},
  shortjournal = {Math. Program.},
  title        = {Softmax policy gradient methods can take exponential time to converge},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified single-loop alternating gradient projection
algorithm for nonconvex–concave and convex–nonconcave minimax problems.
<em>MP</em>, <em>201</em>(1), 635–706. (<a
href="https://doi.org/10.1007/s10107-022-01919-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much recent research effort has been directed to the development of efficient algorithms for solving minimax problems with theoretical convergence guarantees due to the relevance of these problems to a few emergent applications. In this paper, we propose a unified single-loop alternating gradient projection (AGP) algorithm for solving smooth nonconvex-(strongly) concave and (strongly) convex–nonconcave minimax problems. AGP employs simple gradient projection steps for updating the primal and dual variables alternatively at each iteration. We show that it can find an $$\varepsilon $$ -stationary point of the objective function in $${\mathcal {O}}\left( \varepsilon ^{-2} \right) $$ (resp. $${\mathcal {O}}\left( \varepsilon ^{-4} \right) $$ ) iterations under nonconvex-strongly concave (resp. nonconvex–concave) setting. Moreover, its gradient complexity to obtain an $$\varepsilon $$ -stationary point of the objective function is bounded by $${\mathcal {O}}\left( \varepsilon ^{-2} \right) $$ (resp., $${\mathcal {O}}\left( \varepsilon ^{-4} \right) $$ ) under the strongly convex–nonconcave (resp., convex–nonconcave) setting. To the best of our knowledge, this is the first time that a simple and unified single-loop algorithm is developed for solving both nonconvex-(strongly) concave and (strongly) convex–nonconcave minimax problems. Moreover, the complexity results for solving the latter (strongly) convex–nonconcave minimax problems have never been obtained before in the literature. Numerical results show the efficiency of the proposed AGP algorithm. Furthermore, we extend the AGP algorithm by presenting a block alternating proximal gradient (BAPG) algorithm for solving more general multi-block nonsmooth nonconvex-(strongly) concave and (strongly) convex–nonconcave minimax problems. We can similarly establish the gradient complexity of the proposed algorithm under these four different settings.},
  archive      = {J_MP},
  author       = {Xu, Zi and Zhang, Huiling and Xu, Yang and Lan, Guanghui},
  doi          = {10.1007/s10107-022-01919-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {635-706},
  shortjournal = {Math. Program.},
  title        = {A unified single-loop alternating gradient projection algorithm for nonconvex–concave and convex–nonconcave minimax problems},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerating inexact successive quadratic approximation for
regularized optimization through manifold identification. <em>MP</em>,
<em>201</em>(1), 599–633. (<a
href="https://doi.org/10.1007/s10107-022-01916-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For regularized optimization that minimizes the sum of a smooth term and a regularizer that promotes structured solutions, inexact proximal-Newton-type methods, or successive quadratic approximation (SQA) methods, are widely used for their superlinear convergence in terms of iterations. However, unlike the counter parts in smooth optimization, they suffer from lengthy running time in solving regularized subproblems because even approximate solutions cannot be computed easily, so their empirical time cost is not as impressive. In this work, we first show that for partly smooth regularizers, although general inexact solutions cannot identify the active manifold that makes the objective function smooth, approximate solutions generated by commonly-used subproblem solvers will identify this manifold, even with arbitrarily low solution precision. We then utilize this property to propose an improved SQA method, ISQA $$^{+}$$ , that switches to efficient smooth optimization methods after this manifold is identified. We show that for a wide class of degenerate solutions, ISQA $$^{+}$$ possesses superlinear convergence not only in iterations, but also in running time because the cost per iteration is bounded. In particular, our superlinear convergence result holds on problems satisfying a sharpness condition that is more general than that in existing literature. We also prove iterate convergence under a sharpness condition for inexact SQA, which is novel for this family of methods that could easily violate the classical relative-error condition frequently used in proving convergence under similar conditions. Experiments on real-world problems support that ISQA $$^{+}$$ improves running time over some modern solvers for regularized optimization.},
  archive      = {J_MP},
  author       = {Lee, Ching-pei},
  doi          = {10.1007/s10107-022-01916-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {599-633},
  shortjournal = {Math. Program.},
  title        = {Accelerating inexact successive quadratic approximation for regularized optimization through manifold identification},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A proximal trust-region method for nonsmooth optimization
with inexact function and gradient evaluations. <em>MP</em>,
<em>201</em>(1), 559–598. (<a
href="https://doi.org/10.1007/s10107-022-01915-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many applications require minimizing the sum of smooth and nonsmooth functions. For example, basis pursuit denoising problems in data science require minimizing a measure of data misfit plus an $$\ell ^1$$ -regularizer. Similar problems arise in the optimal control of partial differential equations (PDEs) when sparsity of the control is desired. We develop a novel trust-region method to minimize the sum of a smooth nonconvex function and a nonsmooth convex function. Our method is unique in that it permits and systematically controls the use of inexact objective function and derivative evaluations. When using a quadratic Taylor model for the trust-region subproblem, our algorithm is an inexact, matrix-free proximal Newton-type method that permits indefinite Hessians. We prove global convergence of our method in Hilbert space and demonstrate its efficacy on three examples from data science and PDE-constrained optimization.},
  archive      = {J_MP},
  author       = {Baraldi, Robert J. and Kouri, Drew P.},
  doi          = {10.1007/s10107-022-01915-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {559-598},
  shortjournal = {Math. Program.},
  title        = {A proximal trust-region method for nonsmooth optimization with inexact function and gradient evaluations},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Methodology and first-order algorithms for solving nonsmooth
and non-strongly convex bilevel optimization problems. <em>MP</em>,
<em>201</em>(1), 521–558. (<a
href="https://doi.org/10.1007/s10107-022-01914-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simple bilevel problems are optimization problems in which we want to find an optimal solution to an inner problem that minimizes an outer objective function. Such problems appear in many machine learning and signal processing applications as a way to eliminate undesirable solutions. In our work, we suggest a new approach that is designed for bilevel problems with simple outer functions, such as the $$l_1$$ norm, which are not required to be either smooth or strongly convex. In our new ITerative Approximation and Level-set EXpansion (ITALEX) approach, we alternate between expanding the level-set of the outer function and approximately optimizing the inner problem over this level-set. We show that optimizing the inner function through first-order methods such as proximal gradient and generalized conditional gradient results in a feasibility convergence rate of O(1/k), which up to now was a rate only achieved by bilevel algorithms for smooth and strongly convex outer functions. Moreover, we prove an $$O(1/\sqrt{k})$$ rate of convergence for the outer function, contrary to existing methods, which only provide asymptotic guarantees. We demonstrate this performance through numerical experiments.},
  archive      = {J_MP},
  author       = {Doron, Lior and Shtern, Shimrit},
  doi          = {10.1007/s10107-022-01914-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {521-558},
  shortjournal = {Math. Program.},
  title        = {Methodology and first-order algorithms for solving nonsmooth and non-strongly convex bilevel optimization problems},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hessian averaging in stochastic newton methods achieves
superlinear convergence. <em>MP</em>, <em>201</em>(1), 473–520. (<a
href="https://doi.org/10.1007/s10107-022-01913-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider minimizing a smooth and strongly convex objective function using a stochastic Newton method. At each iteration, the algorithm is given an oracle access to a stochastic estimate of the Hessian matrix. The oracle model includes popular algorithms such as Subsampled Newton and Newton Sketch, which can efficiently construct stochastic Hessian estimates for many tasks, e.g., training machine learning models. Despite using second-order information, these existing methods do not exhibit superlinear convergence, unless the stochastic noise is gradually reduced to zero during the iteration, which would lead to a computational blow-up in the per-iteration cost. We propose to address this limitation with Hessian averaging: instead of using the most recent Hessian estimate, our algorithm maintains an average of all the past estimates. This reduces the stochastic noise while avoiding the computational blow-up. We show that this scheme exhibits local Q-superlinear convergence with a non-asymptotic rate of $$(\varUpsilon \sqrt{\log (t)/t}\,)^{t}$$ , where $$\varUpsilon $$ is proportional to the level of stochastic noise in the Hessian oracle. A potential drawback of this (uniform averaging) approach is that the averaged estimates contain Hessian information from the global phase of the method, i.e., before the iterates converge to a local neighborhood. This leads to a distortion that may substantially delay the superlinear convergence until long after the local neighborhood is reached. To address this drawback, we study a number of weighted averaging schemes that assign larger weights to recent Hessians, so that the superlinear convergence arises sooner, albeit with a slightly slower rate. Remarkably, we show that there exists a universal weighted averaging scheme that transitions to local convergence at an optimal stage, and still exhibits a superlinear convergence rate nearly (up to a logarithmic factor) matching that of uniform Hessian averaging.},
  archive      = {J_MP},
  author       = {Na, Sen and Dereziński, Michał and Mahoney, Michael W.},
  doi          = {10.1007/s10107-022-01913-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {473-520},
  shortjournal = {Math. Program.},
  title        = {Hessian averaging in stochastic newton methods achieves superlinear convergence},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An inexact projected gradient method with rounding and
lifting by nonlinear programming for solving rank-one semidefinite
relaxation of polynomial optimization. <em>MP</em>, <em>201</em>(1),
409–472. (<a href="https://doi.org/10.1007/s10107-022-01912-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider solving high-order and tight semidefinite programming (SDP) relaxations of nonconvex polynomial optimization problems (POPs) that often admit degenerate rank-one optimal solutions. Instead of solving the SDP alone, we propose a new algorithmic framework that blends local search using the nonconvex POP into global descent using the convex SDP. In particular, we first design a globally convergent inexact projected gradient method (iPGM) for solving the SDP that serves as the backbone of our framework. We then accelerate iPGM by taking long, but safeguarded, rank-one steps generated by fast nonlinear programming algorithms. We prove that the new framework is still globally convergent for solving the SDP. To solve the iPGM subproblem of projecting a given point onto the feasible set of the SDP, we design a two-phase algorithm with phase one using a symmetric Gauss–Seidel based accelerated proximal gradient method (sGS-APG) to generate a good initial point, and phase two using a modified limited-memory BFGS (L-BFGS) method to obtain an accurate solution. We analyze the convergence for both phases and establish a novel global convergence result for the modified L-BFGS that does not require the objective function to be twice continuously differentiable. We conduct numerical experiments for solving second-order SDP relaxations arising from a diverse set of POPs. Our framework demonstrates state-of-the-art efficiency, scalability, and robustness in solving degenerate SDPs to high accuracy, even in the presence of millions of equality constraints.},
  archive      = {J_MP},
  author       = {Yang, Heng and Liang, Ling and Carlone, Luca and Toh, Kim-Chuan},
  doi          = {10.1007/s10107-022-01912-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {409-472},
  shortjournal = {Math. Program.},
  title        = {An inexact projected gradient method with rounding and lifting by nonlinear programming for solving rank-one semidefinite relaxation of polynomial optimization},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The landscape of the proximal point method for
nonconvex–nonconcave minimax optimization. <em>MP</em>, <em>201</em>(1),
373–407. (<a href="https://doi.org/10.1007/s10107-022-01910-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimax optimization has become a central tool in machine learning with applications in robust optimization, reinforcement learning, GANs, etc. These applications are often nonconvex–nonconcave, but the existing theory is unable to identify and deal with the fundamental difficulties this poses. In this paper, we study the classic proximal point method (PPM) applied to nonconvex–nonconcave minimax problems. We find that a classic generalization of the Moreau envelope by Attouch and Wets provides key insights. Critically, we show this envelope not only smooths the objective but can convexify and concavify it based on the level of interaction present between the minimizing and maximizing variables. From this, we identify three distinct regions of nonconvex–nonconcave problems. When interaction is sufficiently strong, we derive global linear convergence guarantees. Conversely when the interaction is fairly weak, we derive local linear convergence guarantees with a proper initialization. Between these two settings, we show that PPM may diverge or converge to a limit cycle.},
  archive      = {J_MP},
  author       = {Grimmer, Benjamin and Lu, Haihao and Worah, Pratik and Mirrokni, Vahab},
  doi          = {10.1007/s10107-022-01910-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {373-407},
  shortjournal = {Math. Program.},
  title        = {The landscape of the proximal point method for nonconvex–nonconcave minimax optimization},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consistent approximations in composite optimization.
<em>MP</em>, <em>201</em>(1), 339–372. (<a
href="https://doi.org/10.1007/s10107-022-01909-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximations of optimization problems arise in computational procedures and sensitivity analysis. The resulting effect on solutions can be significant, with even small approximations of components of a problem translating into large errors in the solutions. We specify conditions under which approximations are well behaved in the sense of minimizers, stationary points, and level-sets and this leads to a framework of consistent approximations. The framework is developed for a broad class of composite problems, which are neither convex nor smooth. We demonstrate the framework using examples from stochastic optimization, neural-network based machine learning, distributionally robust optimization, penalty and augmented Lagrangian methods, interior-point methods, homotopy methods, smoothing methods, extended nonlinear programming, difference-of-convex programming, and multi-objective optimization. An enhanced proximal method illustrates the algorithmic possibilities. A quantitative analysis supplements the development by furnishing rates of convergence.},
  archive      = {J_MP},
  author       = {Royset, Johannes O.},
  doi          = {10.1007/s10107-022-01909-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {339-372},
  shortjournal = {Math. Program.},
  title        = {Consistent approximations in composite optimization},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supermodularity and valid inequalities for quadratic
optimization with indicators. <em>MP</em>, <em>201</em>(1), 295–338. (<a
href="https://doi.org/10.1007/s10107-022-01908-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the minimization of a rank-one quadratic with indicators and show that the underlying set function obtained by projecting out the continuous variables is supermodular. Although supermodular minimization is, in general, difficult, the specific set function for the rank-one quadratic can be minimized in linear time. We show that the convex hull of the epigraph of the quadratic can be obtained from inequalities for the underlying supermodular set function by lifting them into nonlinear inequalities in the original space of variables. Explicit forms of the convex-hull description are given, both in the original space of variables and in an extended formulation via conic quadratic-representable inequalities, along with a polynomial separation algorithm. Computational experiments indicate that the lifted supermodular inequalities in conic quadratic form are quite effective in reducing the integrality gap for quadratic optimization with indicators.},
  archive      = {J_MP},
  author       = {Atamtürk, Alper and Gómez, Andrés},
  doi          = {10.1007/s10107-022-01908-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {295-338},
  shortjournal = {Math. Program.},
  title        = {Supermodularity and valid inequalities for quadratic optimization with indicators},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An approximation algorithm for indefinite mixed integer
quadratic programming. <em>MP</em>, <em>201</em>(1), 263–293. (<a
href="https://doi.org/10.1007/s10107-022-01907-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we give an algorithm that finds an $$\epsilon $$ -approximate solution to a mixed integer quadratic programming (MIQP) problem. The algorithm runs in polynomial time if the rank of the quadratic function and the number of integer variables are fixed. The running time of the algorithm is expected unless P = NP. In order to design this algorithm we introduce the novel concepts of spherical form MIQP and of aligned vectors, and we provide a number of results of independent interest. In particular, we give a strongly polynomial algorithm to find a symmetric decomposition of a matrix, and show a related result on simultaneous diagonalization of matrices.},
  archive      = {J_MP},
  author       = {Pia, Alberto Del},
  doi          = {10.1007/s10107-022-01907-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {263-293},
  shortjournal = {Math. Program.},
  title        = {An approximation algorithm for indefinite mixed integer quadratic programming},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resolvent splitting for sums of monotone operators with
minimal lifting. <em>MP</em>, <em>201</em>(1), 231–262. (<a
href="https://doi.org/10.1007/s10107-022-01906-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study fixed point algorithms for finding a zero in the sum of $$n\ge 2$$ maximally monotone operators by using their resolvents. More precisely, we consider the class of such algorithms where each resolvent is evaluated only once per iteration. For any algorithm from this class, we show that the underlying fixed point operator is necessarily defined on a d-fold Cartesian product space with $$d\ge n-1$$ . Further, we show that this bound is unimprovable by providing a family of examples for which $$d=n-1$$ is attained. This family includes the Douglas–Rachford algorithm as the special case when $$n=2$$ . Applications of the new family of algorithms in distributed decentralised optimisation and multi-block extensions of the alternation direction method of multipliers (ADMM) are discussed.},
  archive      = {J_MP},
  author       = {Malitsky, Yura and Tam, Matthew K.},
  doi          = {10.1007/s10107-022-01906-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {231-262},
  shortjournal = {Math. Program.},
  title        = {Resolvent splitting for sums of monotone operators with minimal lifting},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Principled analyses and design of first-order methods with
inexact proximal operators. <em>MP</em>, <em>201</em>(1), 185–230. (<a
href="https://doi.org/10.1007/s10107-022-01903-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proximal operations are among the most common primitives appearing in both practical and theoretical (or high-level) optimization methods. This basic operation typically consists in solving an intermediary (hopefully simpler) optimization problem. In this work, we survey notions of inaccuracies that can be used when solving those intermediary optimization problems. Then, we show that worst-case guarantees for algorithms relying on such inexact proximal operations can be systematically obtained through a generic procedure based on semidefinite programming. This methodology is primarily based on the approach introduced by Drori and Teboulle (Math Program 145(1–2):451–482, 2014) and on convex interpolation results, and allows producing non-improvable worst-case analyses. In other words, for a given algorithm, the methodology generates both worst-case certificates (i.e., proofs) and problem instances on which they are achieved. Relying on this methodology, we study numerical worst-case performances of a few basic methods relying on inexact proximal operations including accelerated variants, and design a variant with optimized worst-case behavior. We further illustrate how to extend the approach to support strongly convex objectives by studying a simple relatively inexact proximal minimization method.},
  archive      = {J_MP},
  author       = {Barré, Mathieu and Taylor, Adrien B. and Bach, Francis},
  doi          = {10.1007/s10107-022-01903-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {185-230},
  shortjournal = {Math. Program.},
  title        = {Principled analyses and design of first-order methods with inexact proximal operators},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Faster first-order primal-dual methods for linear
programming using restarts and sharpness. <em>MP</em>, <em>201</em>(1),
133–184. (<a href="https://doi.org/10.1007/s10107-022-01901-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First-order primal-dual methods are appealing for their low memory overhead, fast iterations, and effective parallelization. However, they are often slow at finding high accuracy solutions, which creates a barrier to their use in traditional linear programming (LP) applications. This paper exploits the sharpness of primal-dual formulations of LP instances to achieve linear convergence using restarts in a general setting that applies to alternating direction method of multipliers (ADMM), primal-dual hybrid gradient method (PDHG) and extragradient method (EGM). In the special case of PDHG, without restarts we show an iteration count lower bound of $$\Omega (\kappa ^2 \log (1/\epsilon ))$$ , while with restarts we show an iteration count upper bound of $$O(\kappa \log (1/\epsilon ))$$ , where $$\kappa $$ is a condition number and $$\epsilon $$ is the desired accuracy. Moreover, the upper bound is optimal for a wide class of primal-dual methods, and applies to the strictly more general class of sharp primal-dual problems. We develop an adaptive restart scheme and verify that restarts significantly improve the ability of PDHG, EGM, and ADMM to find high accuracy solutions to LP problems.},
  archive      = {J_MP},
  author       = {Applegate, David and Hinder, Oliver and Lu, Haihao and Lubin, Miles},
  doi          = {10.1007/s10107-022-01901-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {133-184},
  shortjournal = {Math. Program.},
  title        = {Faster first-order primal-dual methods for linear programming using restarts and sharpness},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trace ratio optimization with an application to multi-view
learning. <em>MP</em>, <em>201</em>(1), 97–131. (<a
href="https://doi.org/10.1007/s10107-022-01900-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A trace ratio optimization problem over the Stiefel manifold is investigated from the perspectives of both theory and numerical computations. Necessary conditions in the form of nonlinear eigenvalue problem with eigenvector dependency (NEPv) are established and a numerical method based on the self-consistent field (SCF) iteration with a postprocessing step is designed to solve the NEPv and the method is proved to be always convergent. As an application to multi-view subspace learning, a new framework and its instantiated concrete models are proposed and demonstrated on real world data sets. Numerical results show that the efficiency of the proposed numerical methods and effectiveness of the new orthogonal multi-view subspace learning models.},
  archive      = {J_MP},
  author       = {Wang, Li and Zhang, Lei-Hong and Li, Ren-Cang},
  doi          = {10.1007/s10107-022-01900-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {97-131},
  shortjournal = {Math. Program.},
  title        = {Trace ratio optimization with an application to multi-view learning},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An elementary approach to tight worst case complexity
analysis of gradient based methods. <em>MP</em>, <em>201</em>(1), 63–96.
(<a href="https://doi.org/10.1007/s10107-022-01899-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a novel analysis that allows to achieve tight complexity bounds of gradient-based methods for convex optimization. We start by identifying some of the pitfalls rooted in the classical complexity analysis of the gradient descent method, and show how they can be remedied. Our methodology hinges on elementary and direct arguments in the spirit of the classical analysis. It allows us to establish some new (and reproduce known) tight complexity results for several fundamental algorithms including, gradient descent, proximal point and proximal gradient methods which previously could be proven only through computer-assisted convergence proof arguments.},
  archive      = {J_MP},
  author       = {Teboulle, Marc and Vaisbourd, Yakov},
  doi          = {10.1007/s10107-022-01899-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {63-96},
  shortjournal = {Math. Program.},
  title        = {An elementary approach to tight worst case complexity analysis of gradient based methods},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A semismooth newton based augmented lagrangian method for
nonsmooth optimization on matrix manifolds. <em>MP</em>,
<em>201</em>(1), 1–61. (<a
href="https://doi.org/10.1007/s10107-022-01898-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to studying an augmented Lagrangian method for solving a class of manifold optimization problems, which have nonsmooth objective functions and nonlinear constraints. Under the constant positive linear dependence condition on manifolds, we show that the proposed method converges to a stationary point of the nonsmooth manifold optimization problem. Moreover, we propose a globalized semismooth Newton method to solve the augmented Lagrangian subproblem on manifolds efficiently. The local superlinear convergence of the manifold semismooth Newton method is also established under some suitable conditions. We also prove that the semismoothness on submanifolds can be inherited from that in the ambient manifold. Finally, numerical experiments on compressed modes and (constrained) sparse principal component analysis illustrate the advantages of the proposed method.},
  archive      = {J_MP},
  author       = {Zhou, Yuhao and Bao, Chenglong and Ding, Chao and Zhu, Jun},
  doi          = {10.1007/s10107-022-01898-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-61},
  shortjournal = {Math. Program.},
  title        = {A semismooth newton based augmented lagrangian method for nonsmooth optimization on matrix manifolds},
  volume       = {201},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust convex optimization: A new perspective that unifies
and extends. <em>MP</em>, <em>200</em>(2), 877–918. (<a
href="https://doi.org/10.1007/s10107-022-01881-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust convex constraints are difficult to handle, since finding the worst-case scenario is equivalent to maximizing a convex function. In this paper, we propose a new approach to deal with such constraints that unifies most approaches known in the literature and extends them in a significant way. The extension is either obtaining better solutions than the ones proposed in the literature, or obtaining solutions for classes of problems unaddressed by previous approaches. Our solution is based on an extension of the Reformulation-Linearization-Technique, and can be applied to general convex inequalities and general convex uncertainty sets. It generates a sequence of conservative approximations which can be used to obtain both upper- and lower- bounds for the optimal objective value. We illustrate the numerical benefit of our approach on a robust control and robust geometric optimization example.},
  archive      = {J_MP},
  author       = {Bertsimas, Dimitris and Hertog, Dick den and Pauphilet, Jean and Zhen, Jianzhe},
  doi          = {10.1007/s10107-022-01881-w},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {877-918},
  shortjournal = {Math. Program.},
  title        = {Robust convex optimization: A new perspective that unifies and extends},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simple and fast algorithm for binary integer and online
linear programming. <em>MP</em>, <em>200</em>(2), 831–875. (<a
href="https://doi.org/10.1007/s10107-022-01880-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a simple and fast online algorithm for solving a class of binary integer linear programs (LPs) arisen in general resource allocation problem. The algorithm requires only one single pass through the input data and is free of matrix inversion. It can be viewed as both an approximate algorithm for solving binary integer LPs and a fast algorithm for solving online LP problems. The algorithm is inspired by an equivalent form of the dual problem of the relaxed LP and it essentially performs (one-pass) projected stochastic subgradient descent in the dual space. We analyze the algorithm in two different models, stochastic input and random permutation, with minimal technical assumptions on the input data. The algorithm achieves $$O\left( m \sqrt{n}\right) $$ expected regret under the stochastic input model and $$O\left( (m+\log n)\sqrt{n}\right) $$ expected regret under the random permutation model, and it achieves $$O(m \sqrt{n})$$ expected constraint violation under both models, where n is the number of decision variables and m is the number of constraints. The algorithm enjoys the same performance guarantee when generalized to a multi-dimensional LP setting which covers a wider range of applications. In addition, we employ the notion of the permutational Rademacher complexity and derive regret bounds for two earlier online LP algorithms for comparison. Both algorithms improve the regret bound by a factor of $$\sqrt{m}$$ by paying more computational cost. Furthermore, we demonstrate how to convert the possibly infeasible solution to a feasible one through a randomized procedure. Numerical experiments illustrate the general applicability and effectiveness of the algorithms.},
  archive      = {J_MP},
  author       = {Li, Xiaocheng and Sun, Chunlin and Ye, Yinyu},
  doi          = {10.1007/s10107-022-01880-x},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {831-875},
  shortjournal = {Math. Program.},
  title        = {Simple and fast algorithm for binary integer and online linear programming},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Global optimization using random embeddings. <em>MP</em>,
<em>200</em>(2), 781–829. (<a
href="https://doi.org/10.1007/s10107-022-01871-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a random-subspace algorithmic framework for global optimization of Lipschitz-continuous objectives, and analyse its convergence using novel tools from conic integral geometry. X-REGO randomly projects, in a sequential or simultaneous manner, the high-dimensional original problem into low-dimensional subproblems that can then be solved with any global, or even local, optimization solver. We estimate the probability that the randomly-embedded subproblem shares (approximately) the same global optimum as the original problem. This success probability is then used to show almost sure convergence of X-REGO to an approximate global solution of the original problem, under weak assumptions on the problem (having a strictly feasible global solution) and on the solver (guaranteed to find an approximate global solution of the reduced problem with sufficiently high probability). In the particular case of unconstrained objectives with low effective dimension, we propose an X-REGO variant that explores random subspaces of increasing dimension until finding the effective dimension of the problem, leading to X-REGO globally converging after a finite number of embeddings, proportional to the effective dimension. We show numerically that this variant efficiently finds both the effective dimension and an approximate global minimizer of the original problem.},
  archive      = {J_MP},
  author       = {Cartis, Coralia and Massart, Estelle and Otemissov, Adilet},
  doi          = {10.1007/s10107-022-01871-y},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {781-829},
  shortjournal = {Math. Program.},
  title        = {Global optimization using random embeddings},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complexity of optimizing over the integers. <em>MP</em>,
<em>200</em>(2), 739–780. (<a
href="https://doi.org/10.1007/s10107-022-01862-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the first part of this paper, we present a unified framework for analyzing the algorithmic complexity of any optimization problem, whether it be continuous or discrete in nature. This helps to formalize notions like “input”, “size” and “complexity” in the context of general mathematical optimization, avoiding context dependent definitions which is one of the sources of difference in the treatment of complexity within continuous and discrete optimization. In the second part of the paper, we employ the language developed in the first part to study information theoretic and algorithmic complexity of mixed-integer convex optimization, which contains as a special case continuous convex optimization on the one hand and pure integer optimization on the other. We strive for the maximum possible generality in our exposition. We hope that this paper contains material that both continuous optimizers and discrete optimizers find new and interesting, even though almost all of the material presented is common knowledge in one or the other community. We see the main merit of this paper as bringing together all of this information under one unifying umbrella with the hope that this will act as yet another catalyst for more interaction across the continuous-discrete divide. In fact, our motivation behind Part I of the paper is to provide a common language for both communities.},
  archive      = {J_MP},
  author       = {Basu, Amitabh},
  doi          = {10.1007/s10107-022-01862-z},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {739-780},
  shortjournal = {Math. Program.},
  title        = {Complexity of optimizing over the integers},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graphical designs and gale duality. <em>MP</em>,
<em>200</em>(2), 703–737. (<a
href="https://doi.org/10.1007/s10107-022-01861-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graphical design is a subset of graph vertices such that the weighted averages of certain graph eigenvectors over the design agree with their global averages. We use Gale duality to show that positively weighted graphical designs in regular graphs are in bijection with the faces of a generalized eigenpolytope of the graph. This connection can be used to organize, compute and optimize designs. We illustrate the power of this tool on three families of Cayley graphs – cocktail party graphs, cycles, and graphs of hypercubes – by computing or bounding the smallest designs that average all but the last eigenspace in frequency order.},
  archive      = {J_MP},
  author       = {Babecki, Catherine and Thomas, Rekha R.},
  doi          = {10.1007/s10107-022-01861-0},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {703-737},
  shortjournal = {Math. Program.},
  title        = {Graphical designs and gale duality},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph-based decomposition method for convex quadratic
optimization with indicators. <em>MP</em>, <em>200</em>(2), 669–701. (<a
href="https://doi.org/10.1007/s10107-022-01845-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider convex quadratic optimization problems with indicator variables when the matrix Q defining the quadratic term in the objective is sparse. We use a graphical representation of the support of Q, and show that if this graph is a path, then we can solve the associated problem in polynomial time. This enables us to construct a compact extended formulation for the closure of the convex hull of the epigraph of the mixed-integer convex problem. Furthermore, motivated by inference problems with graphical models, we propose a novel decomposition method for a class of general (sparse) strictly diagonally dominant Q, which leverages the efficient algorithm for the path case. Our computational experiments demonstrate the effectiveness of the proposed method compared to state-of-the-art mixed-integer optimization solvers.},
  archive      = {J_MP},
  author       = {Liu, Peijing and Fattahi, Salar and Gómez, Andrés and Küçükyavuz, Simge},
  doi          = {10.1007/s10107-022-01845-0},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {669-701},
  shortjournal = {Math. Program.},
  title        = {A graph-based decomposition method for convex quadratic optimization with indicators},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The augmented lagrangian method can approximately solve
convex optimization with least constraint violation. <em>MP</em>,
<em>200</em>(2), 633–667. (<a
href="https://doi.org/10.1007/s10107-022-01843-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many important practical optimization problems whose feasible regions are not known to be nonempty or not, and optimizers of the objective function with the least constraint violation prefer to be found. A natural way for dealing with these problems is to extend the nonlinear optimization problem as the one optimizing the objective function over the set of points with the least constraint violation. This leads to the study of the shifted problem. This paper focuses on the constrained convex optimization problem. The sufficient condition for the closedness of the set of feasible shifts is presented and the continuity properties of the optimal value function and the solution mapping for the shifted problem are studied. Properties of the conjugate dual of the shifted problem are discussed through the relations between the dual function and the optimal value function. The solvability of the dual of the optimization problem with the least constraint violation is investigated. It is shown that, if the least violated shift is in the domain of the subdifferential of the optimal value function, then this dual problem has an unbounded solution set. Under this condition, the optimality conditions for the problem with the least constraint violation are established in term of the augmented Lagrangian. It is shown that the augmented Lagrangian method has the properties that the sequence of shifts converges to the least violated shift and the sequence of multipliers is unbounded. Moreover, it is proved that the augmented Lagrangian method is able to find an approximate solution to the problem with the least constraint violation and it has linear rate of convergence under an error bound condition. The augmented Lagrangian method is applied to an illustrative convex second-order cone constrained optimization problem with least constraint violation and numerical results verify our theoretical results.},
  archive      = {J_MP},
  author       = {Dai, Yu-Hong and Zhang, Liwei},
  doi          = {10.1007/s10107-022-01843-2},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {633-667},
  shortjournal = {Math. Program.},
  title        = {The augmented lagrangian method can approximately solve convex optimization with least constraint violation},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue: International symposium on mathematical
programming 2022. <em>MP</em>, <em>200</em>(2), 629–631. (<a
href="https://doi.org/10.1007/s10107-023-01990-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Davis, Damek Shea and Günlük, Oktay and Kaibel, Volker and Nannicini, Giacomo and Yuan, Xa-Xiang},
  doi          = {10.1007/s10107-023-01990-0},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {629-631},
  shortjournal = {Math. Program.},
  title        = {Special issue: International symposium on mathematical programming 2022},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving orthogonal group synchronization via convex and
low-rank optimization: Tightness and landscape analysis. <em>MP</em>,
<em>200</em>(1), 589–628. (<a
href="https://doi.org/10.1007/s10107-022-01896-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group synchronization aims to recover the group elements from their noisy pairwise measurements. It has found many applications in community detection, clock synchronization, and joint alignment problem. This paper focuses on the orthogonal group synchronization which is often used in cryo-EM and computer vision. However, it is generally NP-hard to retrieve the group elements by finding the least squares estimator. In this work, we first study the semidefinite programming (SDP) relaxation of the orthogonal group synchronization and its tightness, i.e., the SDP estimator is exactly equal to the least squares estimator. Moreover, we investigate the performance of the Burer-Monteiro factorization in solving the SDP relaxation by analyzing its corresponding optimization landscape. We provide deterministic sufficient conditions which guarantee: (i) the tightness of SDP relaxation; (ii) optimization landscape arising from the Burer-Monteiro approach is benign, i.e., the global optimum is exactly the least squares estimator and no other spurious local optima exist. Our result provides a solid theoretical justification of why the Burer-Monteiro approach is remarkably efficient and effective in solving the large-scale SDPs arising from orthogonal group synchronization. We perform numerical experiments to complement our theoretical analysis, which gives insights into future research directions.},
  archive      = {J_MP},
  author       = {Ling, Shuyang},
  doi          = {10.1007/s10107-022-01896-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {589-628},
  shortjournal = {Math. Program.},
  title        = {Solving orthogonal group synchronization via convex and low-rank optimization: Tightness and landscape analysis},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Branch-and-bound solves random binary IPs in poly(n)-time.
<em>MP</em>, <em>200</em>(1), 569–587. (<a
href="https://doi.org/10.1007/s10107-022-01895-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Branch-and-bound is the workhorse of all state-of-the-art mixed integer linear programming (MILP) solvers. These implementations of branch-and-bound typically use variable branching, that is, the child nodes are obtained via disjunctions of the form $$x_j \le \lfloor \bar{x}_j \rfloor \vee x_j \ge \lceil \bar{x}_j \rceil $$ , where $$\bar{x}$$ is an optimal solution to the LP corresponding to the parent node. Even though modern MILP solvers are able to solve very large-scale instances efficiently, relatively little attention has been given to understanding why the underlying branch-and-bound algorithm performs so well. In this paper, our goal is to theoretically analyze the performance of the standard variable branching based branch-and-bound algorithm. In order to avoid the exponential worst-case lower bounds, we follow the common idea of considering random instances. More precisely, we consider random integer programs where the entries of the coefficient matrix and the objective function are randomly sampled. Our main result is that with good probability branch-and-bound with variable branching explores only a polynomial number of nodes to solve these instances, for a fixed number of constraints. To the best of our knowledge this is the first known such result for a standard version of branch-and-bound. We believe that this result provides an indication as to why branch-and-bound with variable branching works so well in practice.},
  archive      = {J_MP},
  author       = {Dey, Santanu S. and Dubey, Yatharth and Molinaro, Marco},
  doi          = {10.1007/s10107-022-01895-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {569-587},
  shortjournal = {Math. Program.},
  title        = {Branch-and-bound solves random binary IPs in poly(n)-time},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A limiting analysis on regularization of singular SDP and
its implication to infeasible interior-point algorithms. <em>MP</em>,
<em>200</em>(1), 531–568. (<a
href="https://doi.org/10.1007/s10107-022-01891-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider primal-dual pairs of semidefinite programs and assume that they are singular, i.e., both primal and dual are either weakly feasible or weakly infeasible. Under such circumstances, strong duality may break down and the primal and dual might have a nonzero duality gap. Nevertheless, there are arbitrary small perturbations to the problem data which would make them strongly feasible thus zeroing the duality gap. In this paper, we conduct an asymptotic analysis of the optimal value as the perturbation for regularization is driven to zero. Specifically, we fix two positive definite matrices, $$I_p$$ and $$I_d$$ , say, (typically the identity matrices), and regularize the primal and dual problems by shifting their associated affine space by $$\eta I_p$$ and $$\varepsilon I_d$$ , respectively, to recover interior feasibility of both problems, where $$\varepsilon $$ and $$\eta $$ are positive numbers. Then we analyze the behavior of the optimal value of the regularized problem when the perturbation is reduced to zero keeping the ratio between $$\eta $$ and $$\varepsilon $$ constant. A key feature of our analysis is that no further assumptions such as compactness or constraint qualifications are ever made. It will be shown that the optimal value of the perturbed problem converges to a value between the primal and dual optimal values of the original problems. Furthermore, the limiting optimal value changes “monotonically” from the primal optimal value to the dual optimal value as a function of $$\theta $$ , if we parametrize $$(\varepsilon , \eta )$$ as $$(\varepsilon , \eta )=t(\cos \theta , \sin \theta )$$ and let $$t\rightarrow 0$$ . Finally, the analysis leads us to the relatively surprising consequence that some representative infeasible interior-point algorithms for SDP generate sequences converging to a number between the primal and dual optimal values, even in the presence of a nonzero duality gap. Though this result is more of theoretical interest at this point, it might be of some value in the development of infeasible interior-point algorithms that can handle singular problems.},
  archive      = {J_MP},
  author       = {Tsuchiya, Takashi and Lourenço, Bruno F. and Muramatsu, Masakazu and Okuno, Takayuki},
  doi          = {10.1007/s10107-022-01891-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {531-568},
  shortjournal = {Math. Program.},
  title        = {A limiting analysis on regularization of singular SDP and its implication to infeasible interior-point algorithms},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Facial reduction for symmetry reduced semidefinite and
doubly nonnegative programs. <em>MP</em>, <em>200</em>(1), 475–529. (<a
href="https://doi.org/10.1007/s10107-022-01890-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider both facial reduction, FR, and symmetry reduction, SR, techniques for semidefinite programming, SDP. We show that the two together fit surprisingly well in an alternating direction method of multipliers, ADMM, approach. In fact, this approach allows for simply adding on nonnegativity constraints, and solving the doubly nonnegative, DNN , relaxation of many classes of hard combinatorial problems. We also show that the singularity degree remains the same after SR, and that the DNN relaxations considered here have singularity degree one, that is reduced to zero after FR. The combination of FR and SR leads to a significant improvement in both numerical stability and running time for both the ADMM and interior point approaches. We test our method on various DNN relaxations of hard combinatorial problems including quadratic assignment problems with sizes of more than $$n=500$$ . This translates to a semidefinite constraint of order 250, 000 and $$625\times 10^8$$ nonnegative constrained variables, before applying the reduction techniques.},
  archive      = {J_MP},
  author       = {Hu, Hao and Sotirov, Renata and Wolkowicz, Henry},
  doi          = {10.1007/s10107-022-01890-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {475-529},
  shortjournal = {Math. Program.},
  title        = {Facial reduction for symmetry reduced semidefinite and doubly nonnegative programs},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-asymptotic superlinear convergence of standard
quasi-newton methods. <em>MP</em>, <em>200</em>(1), 425–473. (<a
href="https://doi.org/10.1007/s10107-022-01887-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study and prove the non-asymptotic superlinear convergence rate of the Broyden class of quasi-Newton algorithms which includes the Davidon–Fletcher–Powell (DFP) method and the Broyden–Fletcher–Goldfarb–Shanno (BFGS) method. The asymptotic superlinear convergence rate of these quasi-Newton methods has been extensively studied in the literature, but their explicit finite–time local convergence rate is not fully investigated. In this paper, we provide a finite–time (non-asymptotic) convergence analysis for Broyden quasi-Newton algorithms under the assumptions that the objective function is strongly convex, its gradient is Lipschitz continuous, and its Hessian is Lipschitz continuous at the optimal solution. We show that in a local neighborhood of the optimal solution, the iterates generated by both DFP and BFGS converge to the optimal solution at a superlinear rate of $$(1/k)^{k/2}$$ , where k is the number of iterations. We also prove a similar local superlinear convergence result holds for the case that the objective function is self-concordant. Numerical experiments on several datasets confirm our explicit convergence rate bounds. Our theoretical guarantee is one of the first results that provide a non-asymptotic superlinear convergence rate for quasi-Newton methods.},
  archive      = {J_MP},
  author       = {Jin, Qiujiang and Mokhtari, Aryan},
  doi          = {10.1007/s10107-022-01887-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {425-473},
  shortjournal = {Math. Program.},
  title        = {Non-asymptotic superlinear convergence of standard quasi-newton methods},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). K-median: Exact recovery in the extended stochastic ball
model. <em>MP</em>, <em>200</em>(1), 357–423. (<a
href="https://doi.org/10.1007/s10107-022-01886-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study exact recovery conditions for the linear programming relaxation of the k-median problem in the stochastic ball model (SBM). In Awasthi et al. (Relax, no need to round: integrality of clustering formulations. arXiv:1408.4045, 2015; in: Proceedings of the 2015 conference on innovations in theoretical computer science, pp 191–200, 2015), the authors give a tight result for the k-median LP in the SBM, saying that exact recovery can be achieved as long as the balls are pairwise disjoint. We give a counterexample to their result, thereby showing that the k-median LP is not tight in low dimension. Instead, we give a near optimal result showing that the k-median LP in the SBM is tight in high dimension. We also show that, if the probability measure satisfies some concentration assumptions, then the k-median LP in the SBM is tight in every dimension. Furthermore, we propose a new model of data called extended stochastic ball model (ESBM), which significantly generalizes the well-known SBM. We then show that exact recovery can still be achieved in the ESBM.},
  archive      = {J_MP},
  author       = {Del Pia, Alberto and Ma, Mingchen},
  doi          = {10.1007/s10107-022-01886-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {357-423},
  shortjournal = {Math. Program.},
  title        = {K-median: Exact recovery in the extended stochastic ball model},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The smoothed number of pareto-optimal solutions in
bicriteria integer optimization. <em>MP</em>, <em>200</em>(1), 319–355.
(<a href="https://doi.org/10.1007/s10107-022-01885-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-established heuristic approach for solving bicriteria optimization problems is to enumerate the set of Pareto-optimal solutions. The heuristics following this principle are often successful in practice. Their running time, however, depends on the number of enumerated solutions, which is exponential in the worst case. We study bicriteria integer optimization problems in the model of smoothed analysis, in which inputs are subject to a small amount of random noise, and we prove an almost tight polynomial bound on the expected number of Pareto-optimal solutions. Our results give rise to tight polynomial bounds for the expected running time of the Nemhauser-Ullmann algorithm for the knapsack problem and they improve known results on the running times of heuristics for the bounded knapsack problem and the bicriteria shortest path problem.},
  archive      = {J_MP},
  author       = {Beier, René and Röglin, Heiko and Rösner, Clemens and Vöcking, Berthold},
  doi          = {10.1007/s10107-022-01885-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {319-355},
  shortjournal = {Math. Program.},
  title        = {The smoothed number of pareto-optimal solutions in bicriteria integer optimization},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributionally robust stochastic variational inequalities.
<em>MP</em>, <em>200</em>(1), 279–317. (<a
href="https://doi.org/10.1007/s10107-022-01889-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a formulation of the distributionally robust variational inequality (DRVI) to deal with uncertainties of distributions of the involved random variables in variational inequalities. Examples of the DRVI are provided, including the optimality conditions for distributionally robust optimization and distributionally robust games (DRG). The existence of solutions and monotonicity of the DRVI are discussed. Moreover, we propose a sample average approximation (SAA) approach to the DRVI and study its convergence properties. Numerical examples of DRG are presented to illustrate solutions of the DRVI and convergence properties of the SAA approach.},
  archive      = {J_MP},
  author       = {Sun, Hailin and Shapiro, Alexander and Chen, Xiaojun},
  doi          = {10.1007/s10107-022-01889-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {279-317},
  shortjournal = {Math. Program.},
  title        = {Distributionally robust stochastic variational inequalities},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Error bounds, facial residual functions and applications to
the exponential cone. <em>MP</em>, <em>200</em>(1), 229–278. (<a
href="https://doi.org/10.1007/s10107-022-01883-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct a general framework for deriving error bounds for conic feasibility problems. In particular, our approach allows one to work with cones that fail to be amenable or even to have computable projections, two previously challenging barriers. For the purpose, we first show how error bounds may be constructed using objects called one-step facial residual functions. Then, we develop several tools to compute these facial residual functions even in the absence of closed form expressions for the projections onto the cones. We demonstrate the use and power of our results by computing tight error bounds for the exponential cone feasibility problem. Interestingly, we discover a natural example for which the tightest error bound is related to the Boltzmann–Shannon entropy. We were also able to produce an example of sets for which a Hölderian error bound holds but the supremum of the set of admissible exponents is not itself an admissible exponent.},
  archive      = {J_MP},
  author       = {Lindstrom, Scott B. and Lourenço, Bruno F. and Pong, Ting Kei},
  doi          = {10.1007/s10107-022-01883-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {229-278},
  shortjournal = {Math. Program.},
  title        = {Error bounds, facial residual functions and applications to the exponential cone},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-multiplicity n-fold IP via configuration LP.
<em>MP</em>, <em>200</em>(1), 199–227. (<a
href="https://doi.org/10.1007/s10107-022-01882-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {N-fold integer programs (IPs) form an important class of block-structured IPs for which increasingly fast algorithms have recently been developed and successfully applied. We study high-multiplicity N-fold IPs, which encode IPs succinctly by presenting a description of each block type and a vector of block multiplicities. Our goal is to design algorithms which solve N-fold IPs in time polynomial in the size of the succinct encoding, which may be significantly smaller than the size of the explicit (non-succinct) instance. We present the first fixed-parameter algorithm for high-multiplicity N-fold IPs, which even works for convex objectives. Our key contribution is a novel proximity theorem which relates fractional and integer optima of the Configuration LP, a fundamental notion by Gilmore and Gomory [Oper. Res., 1961] which we generalize. Our algorithm for N-fold IP is faster than previous algorithms whenever the number of blocks is much larger than the number of block types, such as in N-fold IP models for various scheduling problems.},
  archive      = {J_MP},
  author       = {Knop, Dušan and Koutecký, Martin and Levin, Asaf and Mnich, Matthias and Onn, Shmuel},
  doi          = {10.1007/s10107-022-01882-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {199-227},
  shortjournal = {Math. Program.},
  title        = {High-multiplicity N-fold IP via configuration LP},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast augmented lagrangian method in the convex regime with
convergence guarantees for the iterates. <em>MP</em>, <em>200</em>(1),
147–197. (<a href="https://doi.org/10.1007/s10107-022-01879-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to minimize a continuously differentiable convex function with Lipschitz continuous gradient under linear equality constraints. The proposed inertial algorithm results from the discretization of the second-order primal-dual dynamical system with asymptotically vanishing damping term addressed by Boţ and Nguyen (J. Differential Equations 303:369–406, 2021), and it is formulated in terms of the Augmented Lagrangian associated with the minimization problem. The general setting we consider for the inertial parameters covers the three classical rules by Nesterov, Chambolle–Dossal and Attouch–Cabot used in the literature to formulate fast gradient methods. For these rules, we obtain in the convex regime convergence rates of order $${\mathcal {O}}\left( 1/k^{2} \right) $$ for the primal-dual gap, the feasibility measure, and the objective function value. In addition, we prove that the generated sequence of primal-dual iterates converges to a primal-dual solution in a general setting that covers the two latter rules. This is the first result which provides the convergence of the sequence of iterates generated by a fast algorithm for linearly constrained convex optimization problems without additional assumptions such as strong convexity. We also emphasize that all convergence results of this paper are compatible with the ones obtained in Boţ and Nguyen (J. Differential Equations 303:369–406, 2021) in the continuous setting.},
  archive      = {J_MP},
  author       = {Boţ, Radu Ioan and Csetnek, Ernö Robert and Nguyen, Dang-Khoa},
  doi          = {10.1007/s10107-022-01879-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {147-197},
  shortjournal = {Math. Program.},
  title        = {Fast augmented lagrangian method in the convex regime with convergence guarantees for the iterates},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Homogenization for polynomial optimization with unbounded
sets. <em>MP</em>, <em>200</em>(1), 105–145. (<a
href="https://doi.org/10.1007/s10107-022-01878-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers polynomial optimization with unbounded sets. We give a homogenization formulation and propose a hierarchy of Moment-SOS relaxations to solve it. Under the assumptions that the feasible set is closed at infinity and the ideal of homogenized equality constraining polynomials is real radical, we show that this hierarchy of Moment-SOS relaxations has finite convergence, if some optimality conditions (i.e., the linear independence constraint qualification, strict complementarity and second order sufficient conditions) hold at every minimizer, including the one at infinity. Moreover, we prove extended versions of Putinar-Vasilescu type Positivstellensatz for polynomials that are nonnegative on unbounded sets. The classical Moment-SOS hierarchy with denominators is also studied. In particular, we give a positive answer to a conjecture of Mai, Lasserre and Magron in their recent work.},
  archive      = {J_MP},
  author       = {Huang, Lei and Nie, Jiawang and Yuan, Ya-Xiang},
  doi          = {10.1007/s10107-022-01878-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {105-145},
  shortjournal = {Math. Program.},
  title        = {Homogenization for polynomial optimization with unbounded sets},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the effective putinar’s positivstellensatz and moment
approximation. <em>MP</em>, <em>200</em>(1), 71–103. (<a
href="https://doi.org/10.1007/s10107-022-01877-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyse the representation of positive polynomials in terms of Sums of Squares. We provide a quantitative version of Putinar’s Positivstellensatz over a compact basic semialgebraic set S, with a new polynomial bound on the degree of the positivity certificates. This bound involves a Łojasiewicz exponent associated to the description of S. We show that if the gradients of the active constraints are linearly independent on S (Constraint Qualification condition), this Łojasiewicz exponent is equal to 1. We deduce the first general polynomial bound on the convergence rate of the optima in Lasserre’s Sum-of-Squares hierarchy to the global optimum of a polynomial function on S, and the first general bound on the Hausdorff distance between the cone of truncated (probability) measures supported on S and the cone of truncated pseudo-moment sequences, which are positive on the quadratic module of S.},
  archive      = {J_MP},
  author       = {Baldi, Lorenzo and Mourrain, Bernard},
  doi          = {10.1007/s10107-022-01877-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {71-103},
  shortjournal = {Math. Program.},
  title        = {On the effective putinar’s positivstellensatz and moment approximation},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Newton acceleration on manifolds identified by proximal
gradient methods. <em>MP</em>, <em>200</em>(1), 37–70. (<a
href="https://doi.org/10.1007/s10107-022-01873-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proximal methods are known to identify the underlying substructure of nonsmooth optimization problems. Even more, in many interesting situations, the output of a proximity operator comes with its structure at no additional cost, and convergence is improved once it matches the structure of a minimizer. However, it is impossible in general to know whether the current structure is final or not; such highly valuable information has to be exploited adaptively. To do so, we place ourselves in the case where a proximal gradient method can identify manifolds of differentiability of the nonsmooth objective. Leveraging this manifold identification, we show that Riemannian Newton-like methods can be intertwined with the proximal gradient steps to drastically boost the convergence. We prove the superlinear convergence of the algorithm when solving some nondegenerated nonsmooth nonconvex optimization problems. We provide numerical illustrations on optimization problems regularized by $$\ell _1$$ -norm or trace-norm.},
  archive      = {J_MP},
  author       = {Bareilles, Gilles and Iutzeler, Franck and Malick, Jérôme},
  doi          = {10.1007/s10107-022-01873-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {37-70},
  shortjournal = {Math. Program.},
  title        = {Newton acceleration on manifolds identified by proximal gradient methods},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The role of optimization in some recent advances in
data-driven decision-making. <em>MP</em>, <em>200</em>(1), 1–35. (<a
href="https://doi.org/10.1007/s10107-022-01874-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven decision-making has garnered growing interest as a result of the increasing availability of data in recent years. With that growth many opportunities and challenges have sprung up in the areas of predictive and prescriptive analytics. Often, optimization can play an important role in tackling these issues. In this paper, we review some recent advances that highlight the difference that optimization can make in data-driven decision-making. We discuss some of our contributions that aim to advance both predictive and prescriptive models. First, we describe how we can optimally estimate clustered models that result in improved predictions. Next, we consider how we can optimize over objective functions that arise from tree ensemble models in order to obtain better prescriptions. Finally, we discuss how we can learn optimal solutions directly from the data allowing for prescriptions without the need for predictions. For all these new methods, we stress the need for good performance but also the scalability to large heterogeneous datasets.},
  archive      = {J_MP},
  author       = {Baardman, Lennart and Cristian, Rares and Perakis, Georgia and Singhvi, Divya and Skali Lami, Omar and Thayaparan, Leann},
  doi          = {10.1007/s10107-022-01874-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-35},
  shortjournal = {Math. Program.},
  title        = {The role of optimization in some recent advances in data-driven decision-making},
  volume       = {200},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sum of squares generalizations for conic sets. <em>MP</em>,
<em>199</em>(1), 1417–1429. (<a
href="https://doi.org/10.1007/s10107-022-01831-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polynomial nonnegativity constraints can often be handled using the sum of squares condition. This can be efficiently enforced using semidefinite programming formulations, or as more recently proposed by Papp and Yildiz (Papp D in SIAM J O 29: 822–851, 2019), using the sum of squares cone directly in an interior point algorithm. Beyond nonnegativity, more complicated polynomial constraints (in particular, generalizations of the positive semidefinite, second order and $$\ell _1$$ -norm cones) can also be modeled through structured sum of squares programs. We take a different approach and propose using more specialized cones instead. This can result in lower dimensional formulations, more efficient oracles for interior point methods, or self-concordant barriers with smaller parameters.},
  archive      = {J_MP},
  author       = {Kapelevich, Lea and Coey, Chris and Vielma, Juan Pablo},
  doi          = {10.1007/s10107-022-01831-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1417-1429},
  shortjournal = {Math. Program.},
  title        = {Sum of squares generalizations for conic sets},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An augmented lagrangian method for optimization problems
with structured geometric constraints. <em>MP</em>, <em>199</em>(1),
1365–1415. (<a
href="https://doi.org/10.1007/s10107-022-01870-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the theoretical and numerical investigation of an augmented Lagrangian method for the solution of optimization problems with geometric constraints. Specifically, we study situations where parts of the constraints are nonconvex and possibly complicated, but allow for a fast computation of projections onto this nonconvex set. Typical problem classes which satisfy this requirement are optimization problems with disjunctive constraints (like complementarity or cardinality constraints) as well as optimization problems over sets of matrices which have to satisfy additional rank constraints. The key idea behind our method is to keep these complicated constraints explicitly in the constraints and to penalize only the remaining constraints by an augmented Lagrangian function. The resulting subproblems are then solved with the aid of a problem-tailored nonmonotone projected gradient method. The corresponding convergence theory allows for an inexact solution of these subproblems. Nevertheless, the overall algorithm computes so-called Mordukhovich-stationary points of the original problem under a mild asymptotic regularity condition, which is generally weaker than most of the respective available problem-tailored constraint qualifications. Extensive numerical experiments addressing complementarity- and cardinality-constrained optimization problems as well as a semidefinite reformulation of MAXCUT problems visualize the power of our approach.},
  archive      = {J_MP},
  author       = {Jia, Xiaoxi and Kanzow, Christian and Mehlitz, Patrick and Wachsmuth, Gerd},
  doi          = {10.1007/s10107-022-01870-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1365-1415},
  shortjournal = {Math. Program.},
  title        = {An augmented lagrangian method for optimization problems with structured geometric constraints},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linear convergence of an alternating polar decomposition
method for low rank orthogonal tensor approximations. <em>MP</em>,
<em>199</em>(1), 1305–1364. (<a
href="https://doi.org/10.1007/s10107-022-01867-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low rank orthogonal tensor approximation (LROTA) is an important problem in tensor computations and their applications. A classical and widely used algorithm is the alternating polar decomposition method (APD). In this paper, an improved version iAPD of the classical APD is proposed. For the first time, all of the following four fundamental properties are established for iAPD: (i) the algorithm converges globally and the whole sequence converges to a KKT point without any assumption; (ii) it exhibits an overall sublinear convergence with an explicit rate which is sharper than the usual O(1/k) for first order methods in optimization; (iii) more importantly, it converges R-linearly for a generic tensor without any assumption; (iv) for almost all LROTA problems, iAPD reduces to APD after finitely many iterations if it converges to a local minimizer.},
  archive      = {J_MP},
  author       = {Hu, Shenglong and Ye, Ke},
  doi          = {10.1007/s10107-022-01867-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1305-1364},
  shortjournal = {Math. Program.},
  title        = {Linear convergence of an alternating polar decomposition method for low rank orthogonal tensor approximations},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards explicit superlinear convergence rate for SR1.
<em>MP</em>, <em>199</em>(1), 1273–1303. (<a
href="https://doi.org/10.1007/s10107-022-01865-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the convergence rate of the famous Symmetric Rank-1 (SR1) algorithm, which has wide applications in different scenarios. Although it has been extensively investigated, SR1 still lacks a non-asymptotic superlinear rate compared with other quasi-Newton methods such as DFP and BFGS. In this paper, we address the aforementioned issue to obtain the first explicit non-asymptotic rates of superlinear convergence for the vanilla SR1 methods with a correction strategy that is used to achieve numerical stability. Specifically, the vanilla SR1 with the correction strategy achieves the rate of the form $$\left( \frac{2n\ln (4\varkappa )}{k}\right) ^{k/2}$$ for general smooth strongly-convex functions where k is the iteration counter, $$\varkappa $$ is the condition number of the objective function, and n is the dimensionality of the problem. Furthermore, the vanilla SR1 algorithm enjoys a little faster convergence rate and can find the optima of the quadratic objective function at most n steps.},
  archive      = {J_MP},
  author       = {Ye, Haishan and Lin, Dachao and Chang, Xiangyu and Zhang, Zhihua},
  doi          = {10.1007/s10107-022-01865-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1273-1303},
  shortjournal = {Math. Program.},
  title        = {Towards explicit superlinear convergence rate for SR1},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tangencies and polynomial optimization. <em>MP</em>,
<em>199</em>(1), 1239–1272. (<a
href="https://doi.org/10.1007/s10107-022-01869-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a polynomial function $$f :{\mathbb {R}}^n \rightarrow {\mathbb {R}}$$ and an unbounded closed semi-algebraic set $$S \subset {\mathbb {R}}^n,$$ we show that the conditions listed below are characterized exactly in terms of the so-called tangency variety of the restriction of f on S: Besides, we also provide some stability criteria for boundedness and coercivity of f on S.},
  archive      = {J_MP},
  author       = {Phạm, Tiến-Sơn},
  doi          = {10.1007/s10107-022-01869-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1239-1272},
  shortjournal = {Math. Program.},
  title        = {Tangencies and polynomial optimization},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exact computation of an error bound for the balanced linear
complementarity problem with unique solution. <em>MP</em>,
<em>199</em>(1), 1221–1238. (<a
href="https://doi.org/10.1007/s10107-022-01860-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the balanced form of the standard linear complementarity problem with unique solution and provides a more precise expression of an upper error bound discovered by Chen and Xiang and published in 2006. This expression has at least two advantages. It makes possible the exact computation of the error bound factor and it provides a satisfactory upper estimate of that factor in terms of the data bitlength when the data is formed of rational numbers. Along the way, we show that, when any rowwise convex combination of two square matrices is nonsingular, the $$\ell _\infty $$ norm of the inverse of these rowwise convex combinations is maximized by an extreme diagonal matrix.},
  archive      = {J_MP},
  author       = {Dussault, Jean-Pierre and Gilbert, Jean Charles},
  doi          = {10.1007/s10107-022-01860-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1221-1238},
  shortjournal = {Math. Program.},
  title        = {Exact computation of an error bound for the balanced linear complementarity problem with unique solution},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zeroth-order optimization with orthogonal random directions.
<em>MP</em>, <em>199</em>(1), 1179–1219. (<a
href="https://doi.org/10.1007/s10107-022-01866-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and analyze a randomized zeroth-order optimization method based on approximating the exact gradient by finite differences computed in a set of orthogonal random directions that changes with each iteration. A number of previously proposed methods are recovered as special cases including spherical smoothing, coordinate descent, as well as discretized gradient descent. Our main contribution is proving convergence guarantees as well as convergence rates under different parameter choices and assumptions. In particular, we consider convex objectives, but also possibly non-convex objectives satisfying the Polyak-Łojasiewicz (PL) condition. Theoretical results are complemented and illustrated by numerical experiments.},
  archive      = {J_MP},
  author       = {Kozak, David and Molinari, Cesare and Rosasco, Lorenzo and Tenorio, Luis and Villa, Silvia},
  doi          = {10.1007/s10107-022-01866-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1179-1219},
  shortjournal = {Math. Program.},
  title        = {Zeroth-order optimization with orthogonal random directions},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Polynomial-time algorithms for multimarginal optimal
transport problems with structure. <em>MP</em>, <em>199</em>(1),
1107–1178. (<a
href="https://doi.org/10.1007/s10107-022-01868-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimarginal Optimal Transport (MOT) has attracted significant interest due to applications in machine learning, statistics, and the sciences. However, in most applications, the success of MOT is severely limited by a lack of efficient algorithms. Indeed, MOT in general requires exponential time in the number of marginals k and their support sizes n. This paper develops a general theory about what “structure” makes MOT solvable in $$\mathrm {poly}(n,k)$$ time. We develop a unified algorithmic framework for solving MOT in $$\mathrm {poly}(n,k)$$ time by characterizing the structure that different algorithms require in terms of simple variants of the dual feasibility oracle. This framework has several benefits. First, it enables us to show that the Sinkhorn algorithm, which is currently the most popular MOT algorithm, requires strictly more structure than other algorithms do to solve MOT in $$\mathrm {poly}(n,k)$$ time. Second, our framework makes it much simpler to develop $$\mathrm {poly}(n,k)$$ time algorithms for a given MOT problem. In particular, it is necessary and sufficient to (approximately) solve the dual feasibility oracle—which is much more amenable to standard algorithmic techniques. We illustrate this ease-of-use by developing $$\mathrm {poly}(n,k)$$ -time algorithms for three general classes of MOT cost structures: (1) graphical structure; (2) set-optimization structure; and (3) low-rank plus sparse structure. For structure (1), we recover the known result that Sinkhorn has $$\mathrm {poly}(n,k)$$ runtime; moreover, we provide the first $$\mathrm {poly}(n,k)$$ time algorithms for computing solutions that are exact and sparse. For structures (2)-(3), we give the first $$\mathrm {poly}(n,k)$$ time algorithms, even for approximate computation. Together, these three structures encompass many—if not most—current applications of MOT.},
  archive      = {J_MP},
  author       = {Altschuler, Jason M. and Boix-Adserà, Enric},
  doi          = {10.1007/s10107-022-01868-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1107-1178},
  shortjournal = {Math. Program.},
  title        = {Polynomial-time algorithms for multimarginal optimal transport problems with structure},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-discrete optimal transport: Hardness, regularization
and numerical solution. <em>MP</em>, <em>199</em>(1), 1033–1106. (<a
href="https://doi.org/10.1007/s10107-022-01856-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-discrete optimal transport problems, which evaluate the Wasserstein distance between a discrete and a generic (possibly non-discrete) probability measure, are believed to be computationally hard. Even though such problems are ubiquitous in statistics, machine learning and computer vision, however, this perception has not yet received a theoretical justification. To fill this gap, we prove that computing the Wasserstein distance between a discrete probability measure supported on two points and the Lebesgue measure on the standard hypercube is already $$\#$$ P-hard. This insight prompts us to seek approximate solutions for semi-discrete optimal transport problems. We thus perturb the underlying transportation cost with an additive disturbance governed by an ambiguous probability distribution, and we introduce a distributionally robust dual optimal transport problem whose objective function is smoothed with the most adverse disturbance distributions from within a given ambiguity set. We further show that smoothing the dual objective function is equivalent to regularizing the primal objective function, and we identify several ambiguity sets that give rise to several known and new regularization schemes. As a byproduct, we discover an intimate relation between semi-discrete optimal transport problems and discrete choice models traditionally studied in psychology and economics. To solve the regularized optimal transport problems efficiently, we use a stochastic gradient descent algorithm with imprecise stochastic gradient oracles. A new convergence analysis reveals that this algorithm improves the best known convergence guarantee for semi-discrete optimal transport problems with entropic regularizers.},
  archive      = {J_MP},
  author       = {Taşkesen, Bahar and Shafieezadeh-Abadeh, Soroosh and Kuhn, Daniel},
  doi          = {10.1007/s10107-022-01856-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1033-1106},
  shortjournal = {Math. Program.},
  title        = {Semi-discrete optimal transport: Hardness, regularization and numerical solution},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Node connectivity augmentation via iterative randomized
rounding. <em>MP</em>, <em>199</em>(1), 995–1031. (<a
href="https://doi.org/10.1007/s10107-022-01854-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many network design problems deal with the design of low-cost networks that are resilient to the failure of their elements (such as nodes or links). One such problem is Connectivity Augmentation, with the goal of cheaply increasing the (edge- or node-)connectivity of a given network from a value k to $$k+1$$ . The problem is NP-hard for $$k \ge 1$$ , and the most studied setting focuses on the case of edge-connectivity with $$k=1$$ . In this work, we give a 1.892-approximation algorithm for the NP-hard problem of augmenting the node-connectivity of any given graph from 1 to 2, which improves upon the state-of-the-art approximation previously developed in the literature. The starting point of our work is a known reduction from Connectivity Augmentation to some specific instances of the Node-Steiner Tree problem, and our result is obtained by developing a new and simple analysis of the iterative randomized rounding technique when applied to such Steiner Tree instances. Our results also imply a 1.892-approximation algorithm for the problem of augmenting the edge-connectivity of a given graph from any value k to $$k+1$$ . While this does not beat the best approximation factor known for this problem, a key point of our work is that the analysis of our approximation factor is less involved when compared to previous results in the literature. In addition, our work gives new insights on the iterative randomized rounding method, that might be of independent interest.},
  archive      = {J_MP},
  author       = {Angelidakis, Haris and Hyatt-Denesik, Dylan and Sanità, Laura},
  doi          = {10.1007/s10107-022-01854-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {995-1031},
  shortjournal = {Math. Program.},
  title        = {Node connectivity augmentation via iterative randomized rounding},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A convergence analysis of the price of anarchy in atomic
congestion games. <em>MP</em>, <em>199</em>(1), 937–993. (<a
href="https://doi.org/10.1007/s10107-022-01853-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the convergence of the price of anarchy (PoA) of Nash equilibria in atomic congestion games with growing total demand T. When the cost functions are polynomials of the same degree, we obtain explicit rates for a rapid convergence of the PoAs of pure and mixed Nash equilibria to 1 in terms of 1/T and $$d_{max}/T$$ , where $$d_{max}$$ is the maximum demand controlled by an individual. Similar convergence results carry over to the random inefficiency of the random flow induced by an arbitrary mixed Nash equilibrium. For arbitrary polynomial cost functions, we derive a related convergence rate for the PoA of pure Nash equilibria (if they exist) when the demands fulfill certain regularity conditions and $$d_{max}$$ is bounded as $$T\rightarrow \infty .$$ In this general case, also the PoA of mixed Nash equilibria converges to 1 as $$T\rightarrow \infty $$ when $$d_{max}$$ is bounded. Our results constitute the first convergence analysis for the PoA in atomic congestion games and show that selfish behavior is well justified when the total demand is large.},
  archive      = {J_MP},
  author       = {Wu, Zijun and Möhring, Rolf H. and Ren, Chunying and Xu, Dachuan},
  doi          = {10.1007/s10107-022-01853-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {937-993},
  shortjournal = {Math. Program.},
  title        = {A convergence analysis of the price of anarchy in atomic congestion games},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An exponential lower bound for zadeh’s pivot rule.
<em>MP</em>, <em>199</em>(1), 865–936. (<a
href="https://doi.org/10.1007/s10107-022-01848-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The question whether the Simplex Algorithm admits an efficient pivot rule remains one of the most important open questions in discrete optimization. While many natural, deterministic pivot rules are known to yield exponential running times, the random-facet rule was shown to have a subexponential running time. For a long time, Zadeh’s rule remained the most prominent candidate for the first deterministic pivot rule with subexponential running time. We present a lower bound construction that shows that Zadeh’s rule is in fact exponential in the worst case. Our construction is based on a close relation to the Strategy Improvement Algorithm for Parity Games and the Policy Iteration Algorithm for Markov Decision Processes, and we also obtain exponential lower bounds for Zadeh’s rule in these contexts.},
  archive      = {J_MP},
  author       = {Disser, Yann and Friedmann, Oliver and Hopp, Alexander V.},
  doi          = {10.1007/s10107-022-01848-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {865-936},
  shortjournal = {Math. Program.},
  title        = {An exponential lower bound for zadeh’s pivot rule},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding stationary points on bounded-rank matrices: A
geometric hurdle and a smooth remedy. <em>MP</em>, <em>199</em>(1),
831–864. (<a href="https://doi.org/10.1007/s10107-022-01851-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of provably finding a stationary point of a smooth function to be minimized on the variety of bounded-rank matrices. This turns out to be unexpectedly delicate. We trace the difficulty back to a geometric obstacle: On a nonsmooth set, there may be sequences of points along which standard measures of stationarity tend to zero, but whose limit points are not stationary. We name such events apocalypses, as they can cause optimization algorithms to converge to non-stationary points. We illustrate this explicitly for an existing optimization algorithm on bounded-rank matrices. To provably find stationary points, we modify a trust-region method on a standard smooth parameterization of the variety. The method relies on the known fact that second-order stationary points on the parameter space map to stationary points on the variety. Our geometric observations and proposed algorithm generalize beyond bounded-rank matrices. We give a geometric characterization of apocalypses on general constraint sets, which implies that Clarke-regular sets do not admit apocalypses. Such sets include smooth manifolds, manifolds with boundaries, and convex sets. Our trust-region method supports parameterization by any complete Riemannian manifold.},
  archive      = {J_MP},
  author       = {Levin, Eitan and Kileel, Joe and Boumal, Nicolas},
  doi          = {10.1007/s10107-022-01851-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {831-864},
  shortjournal = {Math. Program.},
  title        = {Finding stationary points on bounded-rank matrices: A geometric hurdle and a smooth remedy},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unifying mirror descent and dual averaging. <em>MP</em>,
<em>199</em>(1), 793–830. (<a
href="https://doi.org/10.1007/s10107-022-01850-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and analyze a new family of first-order optimization algorithms which generalizes and unifies both mirror descent and dual averaging. Within the framework of this family, we define new algorithms for constrained optimization that combines the advantages of mirror descent and dual averaging. Our preliminary simulation study shows that these new algorithms significantly outperform available methods in some situations.},
  archive      = {J_MP},
  author       = {Juditsky, Anatoli and Kwon, Joon and Moulines, Éric},
  doi          = {10.1007/s10107-022-01850-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {793-830},
  shortjournal = {Math. Program.},
  title        = {Unifying mirror descent and dual averaging},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An adaptive stochastic sequential quadratic programming
with differentiable exact augmented lagrangians. <em>MP</em>,
<em>199</em>(1), 721–791. (<a
href="https://doi.org/10.1007/s10107-022-01846-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider solving nonlinear optimization problems with a stochastic objective and deterministic equality constraints. We assume for the objective that its evaluation, gradient, and Hessian are inaccessible, while one can compute their stochastic estimates by, for example, subsampling. We propose a stochastic algorithm based on sequential quadratic programming (SQP) that uses a differentiable exact augmented Lagrangian as the merit function. To motivate our algorithm design, we first revisit and simplify an old SQP method Lucidi (J. Optim. Theory Appl. 67(2): 227–245, 1990) developed for solving deterministic problems, which serves as the skeleton of our stochastic algorithm. Based on the simplified deterministic algorithm, we then propose a non-adaptive SQP for dealing with stochastic objective, where the gradient and Hessian are replaced by stochastic estimates but the stepsizes are deterministic and prespecified. Finally, we incorporate a recent stochastic line search procedure Paquette and Scheinberg (SIAM J. Optim. 30(1): 349–376 2020) into the non-adaptive stochastic SQP to adaptively select the random stepsizes, which leads to an adaptive stochastic SQP. The global “almost sure” convergence for both non-adaptive and adaptive SQP methods is established. Numerical experiments on nonlinear problems in CUTEst test set demonstrate the superiority of the adaptive algorithm.},
  archive      = {J_MP},
  author       = {Na, Sen and Anitescu, Mihai and Kolar, Mladen},
  doi          = {10.1007/s10107-022-01846-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {721-791},
  shortjournal = {Math. Program.},
  title        = {An adaptive stochastic sequential quadratic programming with differentiable exact augmented lagrangians},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disjunctive cuts in mixed-integer conic optimization.
<em>MP</em>, <em>199</em>(1), 671–719. (<a
href="https://doi.org/10.1007/s10107-022-01844-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies disjunctive cutting planes in Mixed-Integer Conic Programming. Building on conic duality, we formulate a cut-generating conic program for separating disjunctive cuts, and investigate the impact of the normalization condition on its resolution. In particular, we show that a careful selection of normalization guarantees its solvability and conic strong duality. Then, we highlight the shortcomings of separating conic-infeasible points in an outer-approximation context, and propose conic extensions to the classical lifting and monoidal strengthening procedures. Finally, we assess the computational behavior of various normalization conditions in terms of gap closed, computing time and cut sparsity. In the process, we show that our approach is competitive with the internal lift-and-project cuts of a state-of-the-art solver.},
  archive      = {J_MP},
  author       = {Lodi, Andrea and Tanneau, Mathieu and Vielma, Juan-Pablo},
  doi          = {10.1007/s10107-022-01844-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {671-719},
  shortjournal = {Math. Program.},
  title        = {Disjunctive cuts in mixed-integer conic optimization},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New valid inequalities and formulations for the static joint
chance-constrained lot-sizing problem. <em>MP</em>, <em>199</em>(1),
639–669. (<a href="https://doi.org/10.1007/s10107-022-01847-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the static joint chance-constrained lot-sizing problem, in which production decisions over a planning horizon are made before knowing random future demands, and the inventory variables are then determined by the demand realizations. The joint chance constraint imposes a service level requirement that the probability that all demands are met on time be above a threshold. We model uncertain outcomes with a finite set of scenarios and begin by applying existing results about chance-constrained programming to obtain an initial extended mixed-integer programming formulation. We further strengthen this formulation with a new class of valid inequalities that generalizes the classical ( $$\ell ,S$$ ) inequalities for the deterministic uncapacitated lot-sizing problem. In addition, we prove an optimality condition of the solutions under a modified Wagner-Whitin condition, and based on this derive a new extended mixed-integer programming formulation. This formulation is further extended to the case with constant capacities. We conduct a thorough computational study demonstrating the effectiveness of the new valid inequalities and extended formulation.},
  archive      = {J_MP},
  author       = {Zhang, Zeyang and Gao, Chuanhou and Luedtke, James},
  doi          = {10.1007/s10107-022-01847-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {639-669},
  shortjournal = {Math. Program.},
  title        = {New valid inequalities and formulations for the static joint chance-constrained lot-sizing problem},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probability maximization via minkowski functionals: Convex
representations and tractable resolution. <em>MP</em>, <em>199</em>(1),
595–637. (<a href="https://doi.org/10.1007/s10107-022-01859-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the maximizing of the probability $${\mathbb {P}}\left{ \, \zeta \, \mid \, \zeta \, \in \, {\mathbf {K}}({\mathbf {x}}) \, \right} $$ over a closed and convex set $${\mathcal {X}}$$ , a special case of the chance-constrained optimization problem. Suppose $${\mathbf {K}}({\mathbf {x}}) \, \triangleq \, \left{ \, \zeta \, \in \, {\mathcal {K}}\, \mid \, c({\mathbf {x}},\zeta ) \, \ge \, 0 \right} $$ , and $$\zeta $$ is uniformly distributed on a convex and compact set $${\mathcal {K}}$$ and $$c({\mathbf {x}},\zeta )$$ is defined as either $$c({\mathbf {x}},\zeta )\, \triangleq \, 1-\left| \zeta ^T{\mathbf {x}}\right| ^m$$ where $$m\ge 0$$ (Setting A) or $$c({\mathbf {x}},\zeta ) \, \triangleq \, T{\mathbf {x}}\, - \, \zeta $$ (Setting B). We show that in either setting, by leveraging recent findings in the context of non-Gaussian integrals of positively homogenous functions, $${\mathbb {P}}\left{ \,\zeta \, \mid \, \zeta \, \in \, {\mathbf {K}}({\mathbf {x}}) \, \right} $$ can be expressed as the expectation of a suitably defined continuous function $$F(\bullet ,\xi )$$ with respect to an appropriately defined Gaussian density (or its variant), i.e. $${\mathbb {E}}_{{{\tilde{p}}}} \left[ \, F({\mathbf {x}},\xi )\, \right] $$ . Aided by a recent observation in convex analysis, we then develop a convex representation of the original problem requiring the minimization of $$g\left( {\mathbb {E}}\left[ \, F(\bullet ,\xi )\, \right] \right) $$ over $${\mathcal {X}}$$ , where g is an appropriately defined smooth convex function. Traditional stochastic approximation schemes cannot contend with the minimization of $$g\left( {\mathbb {E}}\left[ F(\bullet ,\xi )\right] \right) $$ over $$\mathcal X$$ , since conditionally unbiased sampled gradients are unavailable. We then develop a regularized variance-reduced stochastic approximation (r-VRSA) scheme that obviates the need for such unbiasedness by combining iterative regularization with variance-reduction. Notably, (r-VRSA) is characterized by almost-sure convergence guarantees, a convergence rate of $$\mathcal {O}(1/k^{1/2-a})$$ in expected sub-optimality where $$a &gt; 0$$ , and a sample complexity of $$\mathcal {O}(1/\epsilon ^{6+\delta })$$ where $$\delta &gt; 0$$ . To the best of our knowledge, this may be the first such scheme for probability maximization problems with convergence and rate guarantees. Preliminary numerics on a portfolio selection problem (Setting A) and a set-covering problem (Setting B) suggest that the scheme competes well with naive mini-batch SA schemes as well as integer programming approximation methods.},
  archive      = {J_MP},
  author       = {Bardakci, I. E. and Jalilzadeh, A. and Lagoa, C. and Shanbhag, U. V.},
  doi          = {10.1007/s10107-022-01859-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {595-637},
  shortjournal = {Math. Program.},
  title        = {Probability maximization via minkowski functionals: Convex representations and tractable resolution},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimal gradient method for smooth strongly convex
minimization. <em>MP</em>, <em>199</em>(1), 557–594. (<a
href="https://doi.org/10.1007/s10107-022-01839-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an optimal gradient method for smooth strongly convex optimization. The method is optimal in the sense that its worst-case bound on the distance to an optimal point exactly matches the lower bound on the oracle complexity for the class of problems, meaning that no black-box first-order method can have a better worst-case guarantee without further assumptions on the class of problems at hand. In addition, we provide a constructive recipe for obtaining the algorithmic parameters of the method and illustrate that it can be used for deriving methods for other optimality criteria as well.},
  archive      = {J_MP},
  author       = {Taylor, Adrien and Drori, Yoel},
  doi          = {10.1007/s10107-022-01839-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {557-594},
  shortjournal = {Math. Program.},
  title        = {An optimal gradient method for smooth strongly convex minimization},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Riemannian optimization via frank-wolfe methods.
<em>MP</em>, <em>199</em>(1), 525–556. (<a
href="https://doi.org/10.1007/s10107-022-01840-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study projection-free methods for constrained Riemannian optimization. In particular, we propose a Riemannian Frank-Wolfe (RFW) method that handles constraints directly, in contrast to prior methods that rely on (potentially costly) projections. We analyze non-asymptotic convergence rates of RFW to an optimum for geodesically convex problems, and to a critical point for nonconvex objectives. We also present a practical setting under which RFW can attain a linear convergence rate. As a concrete example, we specialize RFW to the manifold of positive definite matrices and apply it to two tasks: (i) computing the matrix geometric mean (Riemannian centroid); and (ii) computing the Bures-Wasserstein barycenter. Both tasks involve geodesically convex interval constraints, for which we show that the Riemannian “linear” oracle required by RFW admits a closed form solution; this result may be of independent interest. We complement our theoretical results with an empirical comparison of RFW against state-of-the-art Riemannian optimization methods, and observe that RFW performs competitively on the task of computing Riemannian centroids.},
  archive      = {J_MP},
  author       = {Weber, Melanie and Sra, Suvrit},
  doi          = {10.1007/s10107-022-01840-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {525-556},
  shortjournal = {Math. Program.},
  title        = {Riemannian optimization via frank-wolfe methods},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable subspace methods for derivative-free nonlinear
least-squares optimization. <em>MP</em>, <em>199</em>(1), 461–524. (<a
href="https://doi.org/10.1007/s10107-022-01836-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a general framework for large-scale model-based derivative-free optimization based on iterative minimization within random subspaces. We present a probabilistic worst-case complexity analysis for our method, where in particular we prove high-probability bounds on the number of iterations before a given optimality is achieved. This framework is specialized to nonlinear least-squares problems, with a model-based framework based on the Gauss–Newton method. This method achieves scalability by constructing local linear interpolation models to approximate the Jacobian, and computes new steps at each iteration in a subspace with user-determined dimension. We then describe a practical implementation of this framework, which we call DFBGN. We outline efficient techniques for selecting the interpolation points and search subspace, yielding an implementation that has a low per-iteration linear algebra cost (linear in the problem dimension) while also achieving fast objective decrease as measured by evaluations. Extensive numerical results demonstrate that DFBGN has improved scalability, yielding strong performance on large-scale nonlinear least-squares problems.},
  archive      = {J_MP},
  author       = {Cartis, Coralia and Roberts, Lindon},
  doi          = {10.1007/s10107-022-01836-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {461-524},
  shortjournal = {Math. Program.},
  title        = {Scalable subspace methods for derivative-free nonlinear least-squares optimization},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving sparse principal component analysis with global
support. <em>MP</em>, <em>199</em>(1), 421–459. (<a
href="https://doi.org/10.1007/s10107-022-01857-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse principal component analysis with global support (SPCAgs), is the problem of finding the top-r leading principal components such that all these principal components are linear combinations of a common subset of at most k variables. SPCAgs is a popular dimension reduction tool in statistics that enhances interpretability compared to regular principal component analysis (PCA). Methods for solving SPCAgs in the literature are either greedy heuristics (in the special case of $$r = 1$$ ) with guarantees under restrictive statistical models or algorithms with stationary point convergence for some regularized reformulation of SPCAgs. Crucially, none of the existing computational methods can efficiently guarantee the quality of the solutions obtained by comparing them against dual bounds. In this work, we first propose a convex relaxation based on operator norms that provably approximates the feasible region of SPCAgs within a $$c_1 + c_2 \sqrt{\log r} = O(\sqrt{\log r})$$ factor for some constants $$c_1, c_2$$ . To prove this result, we use a novel random sparsification procedure that uses the Pietsch-Grothendieck factorization theorem and may be of independent interest. We also propose a simpler relaxation that is second-order cone representable and gives a $$(2\sqrt{r})$$ -approximation for the feasible region. Using these relaxations, we then propose a convex integer program that provides a dual bound for the optimal value of SPCAgs. Moreover, it also has worst-case guarantees: it is within a multiplicative/additive factor of the original optimal value, and the multiplicative factor is $$O(\log r)$$ or O(r) depending on the relaxation used. Finally, we conduct computational experiments that show that our convex integer program provides, within a reasonable time, good upper bounds that are typically significantly better than the natural baselines.},
  archive      = {J_MP},
  author       = {Dey, Santanu S. and Molinaro, Marco and Wang, Guanyi},
  doi          = {10.1007/s10107-022-01857-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {421-459},
  shortjournal = {Math. Program.},
  title        = {Solving sparse principal component analysis with global support},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Convergence of augmented lagrangian methods in extensions
beyond nonlinear programming. <em>MP</em>, <em>199</em>(1), 375–420. (<a
href="https://doi.org/10.1007/s10107-022-01832-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The augmented Lagrangian method (ALM) is extended to a broader-than-ever setting of generalized nonlinear programming in convex and nonconvex optimization that is capable of handling many common manifestations of nonsmoothness. With the help of a recently developed sufficient condition for local optimality, it is shown to be derivable from the proximal point algorithm through a kind of local duality corresponding to an optimal solution and accompanying multiplier vector that furnish a local saddle point of the augmented Lagrangian. This approach leads to surprising insights into stepsize choices and new results on linear convergence that draw on recent advances in convergence properties of the proximal point algorithm. Local linear convergence is shown to be assured for a class of model functions that covers more territory than before.},
  archive      = {J_MP},
  author       = {Rockafellar, R. Tyrrell},
  doi          = {10.1007/s10107-022-01832-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {375-420},
  shortjournal = {Math. Program.},
  title        = {Convergence of augmented lagrangian methods in extensions beyond nonlinear programming},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal error bounds for non-expansive fixed-point
iterations in normed spaces. <em>MP</em>, <em>199</em>(1), 343–374. (<a
href="https://doi.org/10.1007/s10107-022-01830-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates optimal error bounds and convergence rates for general Mann iterations for computing fixed-points of non-expansive maps. We look for iterations that achieve the smallest fixed-point residual after n steps, by minimizing a worst-case bound $$\Vert x^n-Tx^n\Vert \le R_n$$ derived from a nested family of optimal transport problems. We prove that this bound is tight so that minimizing $$R_n$$ yields optimal iterations. Inspired from numerical results we identify iterations that attain the rate $$R_n=O(1/n)$$ , which we also show to be the best possible. In particular, we prove that the classical Halpern iteration achieves this optimal rate for several alternative stepsizes, and we determine analytically the optimal stepsizes that attain the smallest worst-case residuals at every step n, with a tight bound $$R_n\approx \frac{4}{n+4}$$ . We also determine the optimal Halpern stepsizes for affine non-expansive maps, for which we get exactly $$R_n=\frac{1}{n+1}$$ . Finally, we show that the best rate for the classical Krasnosel’skiĭ–Mann iteration is $$\varOmega (1/\sqrt{n})$$ , and present numerical evidence suggesting that even extended variants cannot reach a faster rate.},
  archive      = {J_MP},
  author       = {Contreras, Juan Pablo and Cominetti, Roberto},
  doi          = {10.1007/s10107-022-01830-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {343-374},
  shortjournal = {Math. Program.},
  title        = {Optimal error bounds for non-expansive fixed-point iterations in normed spaces},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Subgradient ellipsoid method for nonsmooth convex problems.
<em>MP</em>, <em>199</em>(1), 305–341. (<a
href="https://doi.org/10.1007/s10107-022-01833-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new ellipsoid-type algorithm for solving nonsmooth problems with convex structure. Examples of such problems include nonsmooth convex minimization problems, convex-concave saddle-point problems and variational inequalities with monotone operator. Our algorithm can be seen as a combination of the standard Subgradient and Ellipsoid methods. However, in contrast to the latter one, the proposed method has a reasonable convergence rate even when the dimensionality of the problem is sufficiently large. For generating accuracy certificates in our algorithm, we propose an efficient technique, which ameliorates the previously known recipes (Nemirovski in Math Oper Res 35(1):52–78, 2010).},
  archive      = {J_MP},
  author       = {Rodomanov, Anton and Nesterov, Yurii},
  doi          = {10.1007/s10107-022-01833-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {305-341},
  shortjournal = {Math. Program.},
  title        = {Subgradient ellipsoid method for nonsmooth convex problems},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Primal-dual path following method for nonlinear
semi-infinite programs with semi-definite constraints. <em>MP</em>,
<em>199</em>(1), 251–303. (<a
href="https://doi.org/10.1007/s10107-022-01827-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a primal-dual path following method for nonlinear semi-infinite semi-definite programs with infinitely many convex inequality constraints, called SISDP for short. A straightforward approach to the SISDP is to use classical methods for semi-infinite programs such as discretization and exchange methods and solve a sequence of (nonlinear) semi-definite programs (SDPs). However, it is often too demanding to find exact solutions of SDPs. In contrast, our approach does not rely on solving SDPs accurately but approximately following a path leading to a solution, which is formed on the intersection of the semi-infinite feasible region and the interior of the semi-definite feasible region. Specifically, we first present a prototype path-following method and show its global weak* convergence to a Karush-Kuhn-Tucker point of the SISDP under some mild assumptions. Next, to achieve fast local convergence, we integrate a two-step sequential quadratic programming method equipped with the Monteiro-Zhang scaling technique into the prototype method. We prove two-step superlinear convergence of the resulting algorithm using Alizadeh-Hareberly-Overton-like, Nesterov-Todd, and Helmberg-Rendle-Vanderbei-Wolkowicz/Kojima-Shindoh-Hara/Monteiro scaling directions. Finally, we conduct some numerical experiments to demonstrate the efficiency of the proposed method through comparison with a discretization method that solves SDPs obtained by finite relaxation of the SISDP.},
  archive      = {J_MP},
  author       = {Okuno, Takayuki and Fukushima, Masao},
  doi          = {10.1007/s10107-022-01827-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {251-303},
  shortjournal = {Math. Program.},
  title        = {Primal-dual path following method for nonlinear semi-infinite programs with semi-definite constraints},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vertex downgrading to minimize connectivity. <em>MP</em>,
<em>199</em>(1), 215–249. (<a
href="https://doi.org/10.1007/s10107-022-01824-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of interdicting a directed graph by deleting nodes with the goal of minimizing the local edge connectivity of the remaining graph from a given source to a sink. We introduce and study a general downgrading variant of the interdiction problem where the capacity of an arc is a function of the subset of its endpoints that are downgraded, and the goal is to minimize the downgraded capacity of a minimum source-sink cut subject to a node downgrading budget. This models the case when both ends of an arc must be downgraded to remove it, for example. For this generalization, we provide a bicriteria (4, 2)-approximation that downgrades nodes with total weight at most 4 times the budget and provides a solution where the downgraded connectivity from the source to the sink is at most 2 times that in an optimal solution. We accomplish this with an LP relaxation and rounding using a ball-growing algorithm based on the LP values. Furthermore, we show that other bicriteria approximations exist where one can worsen the approximation factor for one of the costs in order to improve the other. We further generalize the downgrading problem to one where each vertex can be downgraded to one of k levels, and the arc capacities are functions of the pairs of levels to which its ends are downgraded. We generalize our LP rounding to get a (4k, 4k)-approximation for this case. Trade-offs between the two approximation ratios similar to the two-level case also exist for the generalized problem. By transferring node values to edge values, we also derive new bicriteria approximation results for the vertex interdiction versions of the multiway cut problem in digraphs and multicut problems in undirected graphs.},
  archive      = {J_MP},
  author       = {Aissi, Hassene and Chen, Da Qi and Ravi, R.},
  doi          = {10.1007/s10107-022-01824-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {215-249},
  shortjournal = {Math. Program.},
  title        = {Vertex downgrading to minimize connectivity},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lower bounds for non-convex stochastic optimization.
<em>MP</em>, <em>199</em>(1), 165–214. (<a
href="https://doi.org/10.1007/s10107-022-01822-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We lower bound the complexity of finding $$\epsilon $$ -stationary points (with gradient norm at most $$\epsilon $$ ) using stochastic first-order methods. In a well-studied model where algorithms access smooth, potentially non-convex functions through queries to an unbiased stochastic gradient oracle with bounded variance, we prove that (in the worst case) any algorithm requires at least $$\epsilon ^{-4}$$ queries to find an $$\epsilon $$ -stationary point. The lower bound is tight, and establishes that stochastic gradient descent is minimax optimal in this model. In a more restrictive model where the noisy gradient estimates satisfy a mean-squared smoothness property, we prove a lower bound of $$\epsilon ^{-3}$$ queries, establishing the optimality of recently proposed variance reduction techniques.},
  archive      = {J_MP},
  author       = {Arjevani, Yossi and Carmon, Yair and Duchi, John C. and Foster, Dylan J. and Srebro, Nathan and Woodworth, Blake},
  doi          = {10.1007/s10107-022-01822-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {165-214},
  shortjournal = {Math. Program.},
  title        = {Lower bounds for non-convex stochastic optimization},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of the frank–wolfe method for convex composite
optimization involving a logarithmically-homogeneous barrier.
<em>MP</em>, <em>199</em>(1), 123–163. (<a
href="https://doi.org/10.1007/s10107-022-01820-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present and analyze a new generalized Frank–Wolfe method for the composite optimization problem $$(P): {\min }_{x\in {\mathbb {R}}^n} \; f(\mathsf {A} x) + h(x)$$ , where f is a $$\theta $$ -logarithmically-homogeneous self-concordant barrier, $$\mathsf {A}$$ is a linear operator and the function h has a bounded domain but is possibly non-smooth. We show that our generalized Frank–Wolfe method requires $$O((\delta _0 + \theta + R_h)\ln (\delta _0) + (\theta + R_h)^2/\varepsilon )$$ iterations to produce an $$\varepsilon $$ -approximate solution, where $$\delta _0$$ denotes the initial optimality gap and $$R_h$$ is the variation of h on its domain. This result establishes certain intrinsic connections between $$\theta $$ -logarithmically homogeneous barriers and the Frank–Wolfe method. When specialized to the D-optimal design problem, we essentially recover the complexity obtained by Khachiyan (Math Oper Res 21 (2): 307–320, 1996) using the Frank–Wolfe method with exact line-search. We also study the (Fenchel) dual problem of (P), and we show that our new method is equivalent to an adaptive-step-size mirror descent method applied to the dual problem. This enables us to provide iteration complexity bounds for the mirror descent method despite the fact that the dual objective function is non-Lipschitz and has unbounded domain. In addition, we present computational experiments that point to the potential usefulness of our generalized Frank–Wolfe method on Poisson image de-blurring problems with TV regularization, and on simulated PET problem instances.},
  archive      = {J_MP},
  author       = {Zhao, Renbo and Freund, Robert M.},
  doi          = {10.1007/s10107-022-01820-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {123-163},
  shortjournal = {Math. Program.},
  title        = {Analysis of the Frank–Wolfe method for convex composite optimization involving a logarithmically-homogeneous barrier},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linear convergence of frank–wolfe for rank-one matrix
recovery without strong convexity. <em>MP</em>, <em>199</em>(1), 87–121.
(<a href="https://doi.org/10.1007/s10107-022-01821-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider convex optimization problems which are widely used as convex relaxations for low-rank matrix recovery problems. In particular, in several important problems, such as phase retrieval and robust PCA, the underlying assumption in many cases is that the optimal solution is rank-one. In this paper we consider a simple and natural sufficient condition on the objective so that the optimal solution to these relaxations is indeed unique and rank-one. Mainly, we show that under this condition, the standard Frank–Wolfe method with line-search (i.e., without any tuning of parameters whatsoever), which only requires a single rank-one SVD computation per iteration, finds an $$\epsilon $$ -approximated solution in only $$O(\log {1/\epsilon })$$ iterations (as opposed to the previous best known bound of $$O(1/\epsilon )$$ ), despite the fact that the objective is not strongly convex. We consider several variants of the basic method with improved complexities, as well as an extension motivated by robust PCA, and finally, an extension to nonsmooth problems.},
  archive      = {J_MP},
  author       = {Garber, Dan},
  doi          = {10.1007/s10107-022-01821-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {87-121},
  shortjournal = {Math. Program.},
  title        = {Linear convergence of Frank–Wolfe for rank-one matrix recovery without strong convexity},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Sample average approximation with heavier tails II:
Localization in stochastic convex optimization and persistence results
for the lasso. <em>MP</em>, <em>199</em>(1), 49–86. (<a
href="https://doi.org/10.1007/s10107-023-01940-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Localization” has proven to be a valuable tool in the Statistical Learning literature as it allows sharp risk bounds in terms of the problem geometry. Localized bounds seem to be much less exploited in the stochastic optimization literature. In addition, there is an obvious interest in both communities in obtaining risk bounds that require weak moment assumptions or “heavier-tails”. In this work we use a localization toolbox to derive risk bounds in two specific applications. The first is in portfolio risk minimization with conditional value-at-risk constraints. We consider a setting where, among all assets with high returns, there is a portion of dimension g, unknown to the investor, that has significant less risk than the other remaining portion. Our rates for the SAA problem show that “risk inflation”, caused by a multiplicative factor, affects the statistical rate only via a term proportional to g. As the “normalized risk” increases, the contribution in the rate from the extrinsic dimension diminishes while the dependence on g is kept fixed. Localization is a key tool to show this property. As a second application of our localization toolbox, we obtain sharp oracle inequalities for least-squares estimators with a Lasso-type constraint under weak moment assumptions. One main consequence of these inequalities is to obtain persistence, as posed by Greenshtein and Ritov, with covariates having heavier tails. This gives improvements in prior work of Bartlett, Mendelson and Neeman.},
  archive      = {J_MP},
  author       = {Oliveira, Roberto I. and Thompson, Philip},
  doi          = {10.1007/s10107-023-01940-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {49-86},
  shortjournal = {Math. Program.},
  title        = {Sample average approximation with heavier tails II: Localization in stochastic convex optimization and persistence results for the lasso},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Sample average approximation with heavier tails i:
Non-asymptotic bounds with weak assumptions and stochastic constraints.
<em>MP</em>, <em>199</em>(1), 1–48. (<a
href="https://doi.org/10.1007/s10107-022-01810-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive new and improved non-asymptotic deviation inequalities for the sample average approximation (SAA) of an optimization problem. Our results give strong error probability bounds that are “sub-Gaussian” even when the randomness of the problem is fairly heavy tailed. Additionally, we obtain good (often optimal) dependence on the sample size and geometrical parameters of the problem. Finally, we allow for random constraints on the SAA and unbounded feasible sets, which also do not seem to have been considered before in the non-asymptotic literature. Our proofs combine different ideas of potential independent interest: an adaptation of Talagrand’s “generic chaining” bound for sub-Gaussian processes; “localization” ideas from the Statistical Learning literature; and the use of standard conditions in Optimization (metric regularity, Slater-type conditions) to control fluctuations of the feasible set.},
  archive      = {J_MP},
  author       = {Oliveira, Roberto I. and Thompson, Philip},
  doi          = {10.1007/s10107-022-01810-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-48},
  shortjournal = {Math. Program.},
  title        = {Sample average approximation with heavier tails i: Non-asymptotic bounds with weak assumptions and stochastic constraints},
  volume       = {199},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Difference of convex algorithms for bilevel programs with
applications in hyperparameter selection. <em>MP</em>, <em>198</em>(2),
1583–1616. (<a
href="https://doi.org/10.1007/s10107-022-01888-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present difference of convex algorithms for solving bilevel programs in which the upper level objective functions are difference of convex functions, and the lower level programs are fully convex. This nontrivial class of bilevel programs provides a powerful modelling framework for dealing with applications arising from hyperparameter selection in machine learning. Thanks to the full convexity of the lower level program, the value function of the lower level program turns out to be convex and hence the bilevel program can be reformulated as a difference of convex bilevel program. We propose two algorithms for solving the reformulated difference of convex program and show their convergence to stationary points under very mild assumptions. Finally we conduct numerical experiments to a bilevel model of support vector machine classification.},
  archive      = {J_MP},
  author       = {Ye, Jane J. and Yuan, Xiaoming and Zeng, Shangzhi and Zhang, Jin},
  doi          = {10.1007/s10107-022-01888-3},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1583-1616},
  shortjournal = {Math. Program.},
  title        = {Difference of convex algorithms for bilevel programs with applications in hyperparameter selection},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An online convex optimization-based framework for convex
bilevel optimization. <em>MP</em>, <em>198</em>(2), 1519–1582. (<a
href="https://doi.org/10.1007/s10107-022-01894-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new framework for solving the convex bilevel optimization problem, where one optimizes a convex objective over the optimal solutions of another convex optimization problem. As a key step of our framework, we form an online convex optimization (OCO) problem in which the objective function remains fixed while the domain changes over time. We note that the structure of our OCO problem is different from the classical OCO problem that has been intensively studied in the literature. We first develop two OCO algorithms that work under different assumptions and provide their theoretical convergence rates. Our first algorithm works under minimal convexity assumptions, while our second algorithm is equipped to exploit structural information on the objective function, including smoothness, lack of first-order smoothness, and strong convexity. We then carefully translate our OCO results into their counterparts for solving the convex bilevel problem. In the context of convex bilevel optimization, our results lead to rates of convergence in terms of both inner and outer objective functions simultaneously, and in particular without assuming strong convexity in the outer objective function. Specifically, after T iterations, our first algorithm achieves $$O(T^{-1/3})$$ error bound in both levels, and this is further improved to $$O(T^{-1/2})$$ by our second algorithm. We illustrate the numerical efficacy of our algorithms on standard linear inverse problems and a large-scale text classification problem.},
  archive      = {J_MP},
  author       = {Shen, Lingqing and Ho-Nguyen, Nam and Kılınç-Karzan, Fatma},
  doi          = {10.1007/s10107-022-01894-5},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1519-1582},
  shortjournal = {Math. Program.},
  title        = {An online convex optimization-based framework for convex bilevel optimization},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convex generalized nash equilibrium problems and polynomial
optimization. <em>MP</em>, <em>198</em>(2), 1485–1518. (<a
href="https://doi.org/10.1007/s10107-021-01739-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies convex generalized Nash equilibrium problems that are given by polynomials. We use rational and parametric expressions for Lagrange multipliers to formulate efficient polynomial optimization for computing generalized Nash equilibria (GNEs). The Moment-SOS hierarchy of semidefinite relaxations are used to solve the polynomial optimization. Under some general assumptions, we prove the method can find a GNE if there exists one, or detect nonexistence of GNEs. Numerical experiments are presented to show the efficiency of the method.},
  archive      = {J_MP},
  author       = {Nie, Jiawang and Tang, Xindong},
  doi          = {10.1007/s10107-021-01739-7},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1485-1518},
  shortjournal = {Math. Program.},
  title        = {Convex generalized nash equilibrium problems and polynomial optimization},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pure characteristics demand models and distributionally
robust mathematical programs with stochastic complementarity
constraints. <em>MP</em>, <em>198</em>(2), 1449–1484. (<a
href="https://doi.org/10.1007/s10107-021-01720-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formulate pure characteristics demand models under uncertainties of probability distributions as distributionally robust mathematical programs with stochastic complementarity constraints (DRMP-SCC). For any fixed first-stage variable and a random realization, the second-stage problem of DRMP-SCC is a monotone linear complementarity problem (LCP). To deal with ambiguity of probability distributions of the involved random variables in the stochastic LCP, we use the distributionally robust approach. Moreover, we propose an approximation problem with regularization and discretization to solve DRMP-SCC, which is a two-stage nonconvex-nonconcave minimax optimization problem. We prove the convergence of the approximation problem to DRMP-SCC regarding the optimal solution sets, optimal values and stationary points as the regularization parameter goes to zero and the sample size goes to infinity. Finally, preliminary numerical results for investigating distributional robustness of pure characteristics demand models are reported to illustrate the effectiveness and efficiency of our approaches.},
  archive      = {J_MP},
  author       = {Jiang, Jie and Chen, Xiaojun},
  doi          = {10.1007/s10107-021-01720-4},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1449-1484},
  shortjournal = {Math. Program.},
  title        = {Pure characteristics demand models and distributionally robust mathematical programs with stochastic complementarity constraints},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial classification via distributional robustness
with wasserstein ambiguity. <em>MP</em>, <em>198</em>(2), 1411–1447. (<a
href="https://doi.org/10.1007/s10107-022-01796-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a model for adversarial classification based on distributionally robust chance constraints. We show that under Wasserstein ambiguity, the model aims to minimize the conditional value-at-risk of the distance to misclassification, and we explore links to adversarial classification models proposed earlier and to maximum-margin classifiers. We also provide a reformulation of the distributionally robust model for linear classification, and show it is equivalent to minimizing a regularized ramp loss objective. Numerical experiments show that, despite the nonconvexity of this formulation, standard descent methods appear to converge to the global minimizer for this problem. Inspired by this observation, we show that, for a certain class of distributions, the only stationary point of the regularized ramp loss minimization problem is the global minimizer.},
  archive      = {J_MP},
  author       = {Ho-Nguyen, Nam and Wright, Stephen J.},
  doi          = {10.1007/s10107-022-01796-6},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1411-1447},
  shortjournal = {Math. Program.},
  title        = {Adversarial classification via distributional robustness with wasserstein ambiguity},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A primal nonsmooth reformulation for bilevel optimization
problems. <em>MP</em>, <em>198</em>(2), 1381–1409. (<a
href="https://doi.org/10.1007/s10107-021-01764-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solution of bilevel optimization problems with possibly nondifferentiable upper objective functions and with smooth and convex lower-level problems is discussed. A new approximate one-level reformulation for the original problem is introduced. An algorithm based on this reformulation is developed that is proven to converge to a solution of the bilevel problem. Each iteration of the algorithm depends on the solution of a nonsmooth optimization problem and its implementation leverages recent advances on nonsmooth optimization algorithms, which are fundamental to obtain a practical method. Experimental work is performed in order to demonstrate some characteristics of the algorithm in practice.},
  archive      = {J_MP},
  author       = {Helou, Elias S. and Santos, Sandra A. and Simões, Lucas E. A.},
  doi          = {10.1007/s10107-021-01764-6},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1381-1409},
  shortjournal = {Math. Program.},
  title        = {A primal nonsmooth reformulation for bilevel optimization problems},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linear-step solvability of some folded concave and
singly-parametric sparse optimization problems. <em>MP</em>,
<em>198</em>(2), 1339–1380. (<a
href="https://doi.org/10.1007/s10107-021-01766-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies several versions of the sparse optimization problem in statistical estimation defined by a pairwise separation objective. The sparsity (i.e., $$\ell _0$$ ) function is approximated by a folded concave function; the pairwise separation gives rise to an objective of the Z-type. After presenting several realistic estimation problems to illustrate the Z-structure, we introduce a linear-step inner-outer loop algorithm for computing a directional stationary solution of the nonconvex nondifferentiable folded concave sparsity problem. When specialized to a quadratic loss function with a Z-matrix and a piecewise quadratic folded concave sparsity function, the overall complexity of the algorithm is a low-order polynomial in the number of variables of the problem; thus the algorithm is strongly polynomial in this quadratic case. We also consider the parametric version of the problem that has a weighted $$\ell _1$$ -regularizer and a quadratic loss function with a (hidden) Z-matrix. We present a linear-step algorithm in two cases depending on whether the variables have prescribed signs or with unknown signs. In both cases, a parametric algorithm is presented and its strong polynomiality is established under suitable conditions on the weights. Such a parametric algorithm can be combined with an interval search scheme for choosing the parameter to optimize a secondary objective function in a bilevel setting. The analysis makes use of a least-element property of a Z-function, and, for the case of a quadratic loss function, the strongly polynomial solvability of a linear complementarity problem with a hidden Z-matrix. The origin of the latter class of matrices can be traced to an inspirational paper of Olvi Mangasarian to whom we dedicate our present work.},
  archive      = {J_MP},
  author       = {Gómez, Andrés and He, Ziyu and Pang, Jong-Shi},
  doi          = {10.1007/s10107-021-01766-4},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1339-1380},
  shortjournal = {Math. Program.},
  title        = {Linear-step solvability of some folded concave and singly-parametric sparse optimization problems},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk-neutral PDE-constrained generalized nash equilibrium
problems. <em>MP</em>, <em>198</em>(2), 1287–1337. (<a
href="https://doi.org/10.1007/s10107-022-01800-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of risk-neutral generalized Nash equilibrium problems is introduced in which the feasible strategy set of each player is subject to a common linear elliptic partial differential equation with random inputs. In addition, each player’s actions are taken from a bounded, closed, and convex set on the individual strategies and a bound constraint on the common state variable. Existence of Nash equilibria and first-order optimality conditions are derived by exploiting higher integrability and regularity of the random field state variables and a specially tailored constraint qualification for GNEPs with the assumed structure. A relaxation scheme based on the Moreau-Yosida approximation of the bound constraint is proposed, which ultimately leads to numerical algorithms for the individual player problems as well as the GNEP as a whole. The relaxation scheme is related to probability constraints and the viability of the proposed numerical algorithms are demonstrated via several examples.},
  archive      = {J_MP},
  author       = {Gahururu, Deborah B. and Hintermüller, Michael and Surowiec, Thomas M.},
  doi          = {10.1007/s10107-022-01800-z},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1287-1337},
  shortjournal = {Math. Program.},
  title        = {Risk-neutral PDE-constrained generalized nash equilibrium problems},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the computation of equilibria in monotone and potential
stochastic hierarchical games. <em>MP</em>, <em>198</em>(2), 1227–1285.
(<a href="https://doi.org/10.1007/s10107-022-01897-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of noncooperative hierarchical $${\textbf{N}}$$ -player games where the ith player solves a parametrized stochastic mathematical program with equilibrium constraints (MPEC) with the caveat that the implicit form of the ith player’s in MPEC is convex in player strategy, given rival decisions. Few, if any, general purpose schemes exist for computing equilibria, motivating the development of computational schemes in two regimes: (a) Monotone regimes. When player-specific implicit problems are convex, then the necessary and sufficient equilibrium conditions are given by a stochastic inclusion. Under a monotonicity assumption on the operator, we develop a variance-reduced stochastic proximal-point scheme that achieves deterministic rates of convergence in terms of solving proximal-point problems in monotone/strongly monotone regimes with optimal or near-optimal sample-complexity guarantees. Finally, the generated sequences are shown to converge to an equilibrium in an almost-sure sense in both monotone and strongly monotone regimes; (b) Potentiality. When the implicit form of the game admits a potential function, we develop an asynchronous relaxed inexact smoothed proximal best-response framework, requiring the efficient computation of an approximate solution of an MPEC with a strongly convex implicit objective. To this end, we consider an $$\eta $$ -smoothed counterpart of this game where each player’s problem is smoothed via randomized smoothing. In fact, a Nash equilibrium of the smoothed counterpart is an $$\eta $$ -approximate Nash equilibrium of the original game. Our proposed scheme produces a sequence and a relaxed variant that converges almost surely to an $$\eta $$ -approximate Nash equilibrium. This scheme is reliant on resolving the proximal problem, a stochastic MPEC whose implicit form has a strongly convex objective, with increasing accuracy in finite-time. The smoothing framework allows for developing a variance-reduced zeroth-order scheme for such problems that admits a fast rate of convergence. Numerical studies on a class of multi-leader multi-follower games suggest that variance-reduced proximal schemes provide significantly better accuracy with far lower run-times. The relaxed best-response scheme scales well with problem size and generally displays more stability than its unrelaxed counterpart.},
  archive      = {J_MP},
  author       = {Cui, Shisheng and Shanbhag, Uday V.},
  doi          = {10.1007/s10107-022-01897-2},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1227-1285},
  shortjournal = {Math. Program.},
  title        = {On the computation of equilibria in monotone and potential stochastic hierarchical games},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complexity guarantees for an implicit smoothing-enabled
method for stochastic MPECs. <em>MP</em>, <em>198</em>(2), 1153–1225.
(<a href="https://doi.org/10.1007/s10107-022-01893-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical programs with equilibrium constraints (MPECs) represent a class of hierarchical programs that allow for modeling problems in engineering, economics, finance, and statistics. While stochastic generalizations have been assuming increasing relevance, there is a pronounced absence of efficient first/zeroth-order schemes with non-asymptotic rate guarantees for resolving even deterministic variants of such problems. We consider a subclass of stochastic MPECs (SMPECs) where the parametrized lower-level equilibrium problem is given by a deterministic/stochastic variational inequality problem whose mapping is strongly monotone, uniformly in upper-level decisions. Under suitable assumptions, this paves the way for resolving the implicit problem with a Lipschitz continuous objective via a gradient-free zeroth-order method by leveraging a locally randomized spherical smoothing framework. Efficient algorithms for resolving the implicit problem allow for leveraging any convexity property possessed by the implicit problem, which in turn facilitates the computation of approximate global minimizers. In this setting, we present schemes for single-stage and two-stage stochastic MPECs when the upper-level problem is either convex or nonconvex in an implicit sense. (I). Single-stage SMPECs. In single-stage SMPECs, in convex regimes, our proposed inexact schemes are characterized by a complexity in upper-level projections, upper-level samples, and lower-level projections of $${\mathcal {O}}(\tfrac{1}{\epsilon ^2})$$ , $${\mathcal {O}}(\tfrac{1}{\epsilon ^2})$$ , and $${\mathcal {O}}(\tfrac{1}{\epsilon ^2}\ln (\tfrac{1}{\epsilon }))$$ , respectively. Analogous bounds for the nonconvex regime are $${\mathcal {O}}(\tfrac{1}{\epsilon })$$ , $${\mathcal {O}}(\tfrac{1}{\epsilon ^2})$$ , and $${\mathcal {O}}(\tfrac{1}{\epsilon ^3})$$ , respectively. (II). Two-stage SMPECs. In two-stage SMPECs, in convex regimes, our proposed inexact schemes have a complexity in upper-level projections, upper-level samples, and lower-level projections of $${\mathcal {O}}(\tfrac{1}{\epsilon ^2})$$ , $${\mathcal {O}}(\tfrac{1}{\epsilon ^2})$$ , and $${\mathcal {O}}(\tfrac{1}{\epsilon ^2}\ln (\tfrac{1}{\epsilon }))$$ while the corresponding bounds in the nonconvex regime are $${\mathcal {O}}(\tfrac{1}{\epsilon })$$ , $${\mathcal {O}}(\tfrac{1}{\epsilon ^2})$$ , and $${\mathcal {O}}(\tfrac{1}{\epsilon ^2}\ln (\tfrac{1}{\epsilon }))$$ , respectively. In addition, we derive statements for accelerated schemes in settings where the exact solution of the lower-level problem is available. Preliminary numerics suggest that the schemes scale with problem size, are relatively robust to modification of algorithm parameters, show distinct benefits in obtaining near-global minimizers for convex implicit problems in contrast with competing solvers, and provide solutions of similar accuracy in a fraction of the time taken by sample-average approximation (SAA).},
  archive      = {J_MP},
  author       = {Cui, Shisheng and Shanbhag, Uday V. and Yousefian, Farzad},
  doi          = {10.1007/s10107-022-01893-6},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1153-1225},
  shortjournal = {Math. Program.},
  title        = {Complexity guarantees for an implicit smoothing-enabled method for stochastic MPECs},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A pessimistic bilevel stochastic problem for elastic shape
optimization. <em>MP</em>, <em>198</em>(2), 1125–1151. (<a
href="https://doi.org/10.1007/s10107-021-01736-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider pessimistic bilevel stochastic programs in which the follower maximizes over a fixed compact convex set a strictly convex quadratic function, whose Hessian depends on the leader’s decision. This results in a random upper level outcome which is evaluated by a convex risk measure. Under assumptions including real analyticity of the lower-level goal function, we prove the existence of optimal solutions. We discuss an alternate model, where the leader hedges against optimal lower-level solutions, and show that solvability can be guaranteed under weaker conditions in both, a deterministic and a stochastic setting. The approach is applied to a mechanical shape optimization problem in which the leader decides on an optimal material distribution to minimize a tracking-type cost functional, whereas the follower chooses forces from an admissible set to maximize a compliance objective. The material distribution is considered to be stochastically perturbed in the actual construction phase. Computational results illustrate the bilevel optimization concept and demonstrate the interplay of follower and leader in shape design and testing.},
  archive      = {J_MP},
  author       = {Burtscheidt, Johanna and Claus, Matthias and Conti, Sergio and Rumpf, Martin and Sassen, Josua and Schultz, Rüdiger},
  doi          = {10.1007/s10107-021-01736-w},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1125-1151},
  shortjournal = {Math. Program.},
  title        = {A pessimistic bilevel stochastic problem for elastic shape optimization},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue: Hierarchical optimization. <em>MP</em>,
<em>198</em>(2), 1121–1123. (<a
href="https://doi.org/10.1007/s10107-022-01911-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Bennett, Kristin P. and Ferris, Michael C. and Pang, Jong-Shi and Solodov, Mikhail V. and Wright, Stephen J.},
  doi          = {10.1007/s10107-022-01911-7},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1121-1123},
  shortjournal = {Math. Program.},
  title        = {Special issue: Hierarchical optimization},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On implicit function theorem for locally lipschitz
equations. <em>MP</em>, <em>198</em>(1), 1107–1120. (<a
href="https://doi.org/10.1007/s10107-021-01750-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equations defined by locally Lipschitz continuous mappings with a parameter are considered. Implicit function theorems for this equation are obtained. The regularity condition is formulated in the terms of the Clarke Jacobian. Implicit functions estimates are derived. It is shown that the considered regularity assumptions are weaker than most of the known ones. The obtained implicit function theorems are applied to derive conditions for upper semicontinuity of the optimal value function for parameterized optimization problems},
  archive      = {J_MP},
  author       = {Arutyunov, Aram V. and Zhukovskiy, Sergey E.},
  doi          = {10.1007/s10107-021-01750-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1107-1120},
  shortjournal = {Math. Program.},
  title        = {On implicit function theorem for locally lipschitz equations},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Policy mirror descent for reinforcement learning: Linear
convergence, new sampling complexity, and generalized problem classes.
<em>MP</em>, <em>198</em>(1), 1059–1106. (<a
href="https://doi.org/10.1007/s10107-022-01816-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present new policy mirror descent (PMD) methods for solving reinforcement learning (RL) problems with either strongly convex or general convex regularizers. By exploring the structural properties of these overall highly nonconvex problems we show that the PMD methods exhibit fast linear rate of convergence to the global optimality. We develop stochastic counterparts of these methods, and establish an $${{\mathcal {O}}}(1/\epsilon )$$ (resp., $${{\mathcal {O}}}(1/\epsilon ^2)$$ ) sampling complexity for solving these RL problems with strongly (resp., general) convex regularizers using different sampling schemes, where $$\epsilon $$ denote the target accuracy. We further show that the complexity for computing the gradients of these regularizers, if necessary, can be bounded by $${{\mathcal {O}}}{(\log _\gamma \epsilon ) [(1-\gamma )L/\mu ]^{1/2}\log (1/\epsilon )}$$ (resp., $${{\mathcal {O}}} {(\log _\gamma \epsilon ) (L/\epsilon )^{1/2}}$$ ) for problems with strongly (resp., general) convex regularizers. Here $$\gamma $$ denotes the discounting factor. To the best of our knowledge, these complexity bounds, along with our algorithmic developments, appear to be new in both optimization and RL literature. The introduction of these convex regularizers also greatly enhances the flexibility and thus expands the applicability of RL models.},
  archive      = {J_MP},
  author       = {Lan, Guanghui},
  doi          = {10.1007/s10107-022-01816-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1059-1106},
  shortjournal = {Math. Program.},
  title        = {Policy mirror descent for reinforcement learning: Linear convergence, new sampling complexity, and generalized problem classes},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Bound-constrained global optimization of functions with low
effective dimensionality using multiple random embeddings. <em>MP</em>,
<em>198</em>(1), 997–1058. (<a
href="https://doi.org/10.1007/s10107-022-01812-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the bound-constrained global optimization of functions with low effective dimensionality, that are constant along an (unknown) linear subspace and only vary over the effective (complement) subspace. We aim to implicitly explore the intrinsic low dimensionality of the constrained landscape using feasible random embeddings, in order to understand and improve the scalability of algorithms for the global optimization of these special-structure problems. A reduced subproblem formulation is investigated that solves the original problem over a random low-dimensional subspace subject to affine constraints, so as to preserve feasibility with respect to the given domain. Under reasonable assumptions, we show that the probability that the reduced problem is successful in solving the original, full-dimensional problem is positive. Furthermore, in the case when the objective’s effective subspace is aligned with the coordinate axes, we provide an asymptotic bound on this success probability that captures its polynomial dependence on the effective and, surprisingly, ambient dimensions. We then propose X-REGO, a generic algorithmic framework that uses multiple random embeddings, solving the above reduced problem repeatedly, approximately and possibly, adaptively. Using the success probability of the reduced subproblems, we prove that X-REGO converges globally, with probability one, and linearly in the number of embeddings, to an $$\epsilon $$ -neighbourhood of a constrained global minimizer. Our numerical experiments on special structure functions illustrate our theoretical findings and the improved scalability of X-REGO variants when coupled with state-of-the-art global—and even local—optimization solvers for the subproblems.},
  archive      = {J_MP},
  author       = {Cartis, Coralia and Massart, Estelle and Otemissov, Adilet},
  doi          = {10.1007/s10107-022-01812-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {997-1058},
  shortjournal = {Math. Program.},
  title        = {Bound-constrained global optimization of functions with low effective dimensionality using multiple random embeddings},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence of the forward-backward algorithm: Beyond the
worst-case with the help of geometry. <em>MP</em>, <em>198</em>(1),
937–996. (<a href="https://doi.org/10.1007/s10107-022-01809-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a comprehensive study of the convergence of the forward-backward algorithm under suitable geometric conditions, such as conditioning or Łojasiewicz properties. These geometrical notions are usually local by nature, and may fail to describe the fine geometry of objective functions relevant in inverse problems and signal processing, that have a nice behaviour on manifolds, or sets open with respect to a weak topology. Motivated by this observation, we revisit those geometric notions over arbitrary sets. In turn, this allows us to present several new results as well as collect in a unified view a variety of results scattered in the literature. Our contributions include the analysis of infinite dimensional convex minimization problems, showing the first Łojasiewicz inequality for a quadratic function associated to a compact operator, and the derivation of new linear rates for problems arising from inverse problems with low-complexity priors. Our approach allows to establish unexpected connections between geometry and a priori conditions in inverse problems, such as source conditions, or restricted isometry properties.},
  archive      = {J_MP},
  author       = {Garrigos, Guillaume and Rosasco, Lorenzo and Villa, Silvia},
  doi          = {10.1007/s10107-022-01809-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {937-996},
  shortjournal = {Math. Program.},
  title        = {Convergence of the forward-backward algorithm: Beyond the worst-case with the help of geometry},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A globally convergent proximal newton-type method in
nonsmooth convex optimization. <em>MP</em>, <em>198</em>(1), 899–936.
(<a href="https://doi.org/10.1007/s10107-022-01797-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes and justifies a new algorithm of the proximal Newton type to solve a broad class of nonsmooth composite convex optimization problems without strong convexity assumptions. Based on advanced notions and techniques of variational analysis, we establish implementable results on the global convergence of the proposed algorithm as well as its local convergence with superlinear and quadratic rates. For certain structured problems, the obtained local convergence conditions do not require the local Lipschitz continuity of the corresponding Hessian mappings that is a crucial assumption used in the literature to ensure a superlinear convergence of other algorithms of the proximal Newton type. The conducted numerical experiments of solving the $$l_1$$ regularized logistic regression model illustrate the possibility of applying the proposed algorithm to deal with practically important problems.},
  archive      = {J_MP},
  author       = {Mordukhovich, Boris S. and Yuan, Xiaoming and Zeng, Shangzhi and Zhang, Jin},
  doi          = {10.1007/s10107-022-01797-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {899-936},
  shortjournal = {Math. Program.},
  title        = {A globally convergent proximal newton-type method in nonsmooth convex optimization},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An exact penalty approach for optimization with nonnegative
orthogonality constraints. <em>MP</em>, <em>198</em>(1), 855–897. (<a
href="https://doi.org/10.1007/s10107-022-01794-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization with nonnegative orthogonality constraints has wide applications in machine learning and data sciences. It is NP-hard due to some combinatorial properties of the constraints. We first propose an equivalent optimization formulation with nonnegative and multiple spherical constraints and an additional single nonlinear constraint. Various constraint qualifications, the first- and second-order optimality conditions of the equivalent formulation are discussed. By establishing a local error bound of the feasible set, we design a class of (smooth) exact penalty models via keeping the nonnegative and multiple spherical constraints. The penalty models are exact if the penalty parameter is sufficiently large but finite. A practical penalty algorithm with postprocessing is then developed to approximately solve a series of subproblems with nonnegative and multiple spherical constraints. We study the asymptotic convergence and establish that any limit point is a weakly stationary point of the original problem and becomes a stationary point under some additional mild conditions. Extensive numerical results on the problem of computing the orthogonal projection onto nonnegative orthogonality constraints, the orthogonal nonnegative matrix factorization problems and the K-indicators model show the effectiveness of our proposed approach.},
  archive      = {J_MP},
  author       = {Jiang, Bo and Meng, Xiang and Wen, Zaiwen and Chen, Xiaojun},
  doi          = {10.1007/s10107-022-01794-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {855-897},
  shortjournal = {Math. Program.},
  title        = {An exact penalty approach for optimization with nonnegative orthogonality constraints},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A duality based 2-approximation algorithm for maximum
agreement forest. <em>MP</em>, <em>198</em>(1), 811–853. (<a
href="https://doi.org/10.1007/s10107-022-01790-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give a 2-approximation algorithm for the Maximum Agreement Forest problem on two rooted binary trees. This NP-hard problem has been studied extensively in the past two decades, since it can be used to compute the rooted Subtree Prune-and-Regraft (rSPR) distance between two phylogenetic trees. Our algorithm is combinatorial and its running time is quadratic in the input size. To prove the approximation guarantee, we construct a feasible dual solution for a novel exponential-size linear programming formulation. In addition, we show this linear program has a smaller integrality gap than previously known formulations, and we give an equivalent compact formulation, showing that it can be solved in polynomial time.},
  archive      = {J_MP},
  author       = {Olver, Neil and Schalekamp, Frans and van der Ster, Suzanne and Stougie, Leen and van Zuylen, Anke},
  doi          = {10.1007/s10107-022-01790-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {811-853},
  shortjournal = {Math. Program.},
  title        = {A duality based 2-approximation algorithm for maximum agreement forest},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complexity of branch-and-bound and cutting planes in
mixed-integer optimization. <em>MP</em>, <em>198</em>(1), 787–810. (<a
href="https://doi.org/10.1007/s10107-022-01789-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the theoretical complexity of branch-and-bound (BB) and cutting plane (CP) algorithms for mixed-integer optimization. In particular, we study the relative efficiency of BB and CP, when both are based on the same family of disjunctions. We extend a result of Dash (International Conference on Integer Programming and Combinatorial Optimization (IPCO), pp. 145–160, 2002) to the nonlinear setting which shows that for convex 0/1 problems, CP does at least as well as BB, with variable disjunctions. We sharpen this by giving instances of the stable set problem where we can provably establish that CP does exponentially better than BB. We further show that if one moves away from 0/1 sets, this advantage of CP over BB disappears; there are examples where BB finishes in O(1) time, but CP takes infinitely long to prove optimality, and exponentially long to get to arbitrarily close to the optimal value (for variable disjunctions). We next show that if the dimension is considered a fixed constant, then the situation reverses and BB does at least as well as CP (up to a polynomial blow up factor), for quite general families of disjunctions. This is also complemented by examples where this gap is exponential (in the size of the input data).},
  archive      = {J_MP},
  author       = {Basu, Amitabh and Conforti, Michele and Di Summa, Marco and Jiang, Hongyi},
  doi          = {10.1007/s10107-022-01789-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {787-810},
  shortjournal = {Math. Program.},
  title        = {Complexity of branch-and-bound and cutting planes in mixed-integer optimization},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On approximations of the PSD cone by a polynomial number of
smaller-sized PSD cones. <em>MP</em>, <em>198</em>(1), 733–785. (<a
href="https://doi.org/10.1007/s10107-022-01795-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of approximating the cone of positive semidefinite (PSD) matrices with a cone that can be described by smaller-sized PSD constraints. Specifically, we ask the question: “how closely can we approximate the set of unit-trace $$n \times n$$ PSD matrices, denoted by D, using at most N number of $$k \times k$$ PSD constraints?” In this paper, we prove lower bounds on N to achieve a good approximation of D by considering two constructions of an approximating set. First, we consider the unit-trace $$n \times n$$ symmetric matrices that are PSD when restricted to a fixed set of k-dimensional subspaces in $${\mathbb {R}}^n$$ . We prove that if this set is a good approximation of D, then the number of subspaces must be at least exponentially large in n for any $$k = o(n)$$ . Second, we show that any set S that approximates D within a constant approximation ratio must have superpolynomial $${\varvec{S}}_+^k$$ -extension complexity. To be more precise, if S is a constant factor approximation of D, then S must have $${\varvec{S}}_+^k$$ -extension complexity at least $$\exp ( C \cdot \min { \sqrt{n}, n/k })$$ where C is some absolute constant. In addition, we show that any set S such that $$D \subseteq S$$ and the Gaussian width of S is at most a constant times larger than the Gaussian width of D must have $${\varvec{S}}_+^k$$ -extension complexity at least $$\exp ( C \cdot \min { n^{1/3}, \sqrt{n/k} })$$ . These results imply that the cone of $$n \times n$$ PSD matrices cannot be approximated by a polynomial number of $$k \times k$$ PSD constraints for any $$k = o(n / \log ^2 n)$$ . These results generalize the recent work of Fawzi (Math Oper Res 46(4):1479–1489, 2021) on the hardness of polyhedral approximations of $${\varvec{S}}_+^n$$ , which corresponds to the special case with $$k=1$$ .},
  archive      = {J_MP},
  author       = {Song, Dogyoon and Parrilo, Pablo A.},
  doi          = {10.1007/s10107-022-01795-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {733-785},
  shortjournal = {Math. Program.},
  title        = {On approximations of the PSD cone by a polynomial number of smaller-sized PSD cones},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constrained stochastic blackbox optimization using a
progressive barrier and probabilistic estimates. <em>MP</em>,
<em>198</em>(1), 675–732. (<a
href="https://doi.org/10.1007/s10107-022-01787-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces the StoMADS-PB algorithm for constrained stochastic blackbox optimization, which is an extension of the mesh adaptive direct-search (MADS) method originally developed for deterministic blackbox optimization under general constraints. The values of the objective and constraint functions are provided by a noisy blackbox, i.e., they can only be computed with random noise whose distribution is unknown. As in MADS, constraint violations are aggregated into a single constraint violation function. Since all function values are numerically unavailable, StoMADS-PB uses estimates and introduces probabilistic bounds for the violation. Such estimates and bounds obtained from stochastic observations are required to be accurate and reliable with high, but fixed, probabilities. The proposed method, which allows intermediate infeasible solutions, accepts new points using sufficient decrease conditions and imposing a threshold on the probabilistic bounds. Using Clarke nonsmooth calculus and martingale theory, Clarke stationarity convergence results for the objective and the violation function are derived with probability one.},
  archive      = {J_MP},
  author       = {Dzahini, Kwassi Joseph and Kokkolaras, Michael and Le Digabel, Sébastien},
  doi          = {10.1007/s10107-022-01787-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {675-732},
  shortjournal = {Math. Program.},
  title        = {Constrained stochastic blackbox optimization using a progressive barrier and probabilistic estimates},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chance-constrained set covering with wasserstein ambiguity.
<em>MP</em>, <em>198</em>(1), 621–674. (<a
href="https://doi.org/10.1007/s10107-022-01788-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a generalized distributionally robust chance-constrained set covering problem (DRC) with a Wasserstein ambiguity set, where both decisions and uncertainty are binary-valued. We establish the NP-hardness of DRC and recast it as a two-stage stochastic program, which facilitates decomposition algorithms. Furthermore, we derive two families of valid inequalities. The first family targets the hypograph of a “shifted” submodular function, which is associated with each scenario of the two-stage reformulation. We show that the valid inequalities give a complete description of the convex hull of the hypograph. The second family mixes inequalities across multiple scenarios and gains further strength via lifting. Our numerical experiments demonstrate the out-of-sample performance of the DRC model and the effectiveness of our proposed reformulation and valid inequalities.},
  archive      = {J_MP},
  author       = {Shen, Haoming and Jiang, Ruiwei},
  doi          = {10.1007/s10107-022-01788-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {621-674},
  shortjournal = {Math. Program.},
  title        = {Chance-constrained set covering with wasserstein ambiguity},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards improving christofides algorithm on fundamental
classes by gluing convex combinations of tours. <em>MP</em>,
<em>198</em>(1), 595–620. (<a
href="https://doi.org/10.1007/s10107-022-01784-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new approach for gluing tours over certain tight, 3-edge cuts. Gluing over 3-edge cuts has been used in algorithms for finding Hamilton cycles in special graph classes and in proving bounds for 2-edge-connected subgraph problem, but not much was known in this direction for gluing connected multigraphs. We apply this approach to the traveling salesman problem (TSP) in the case when the objective function of the subtour elimination relaxation is minimized by a $$\theta $$ -cyclic point: $$x_e \in {0,\theta , 1-\theta , 1}$$ , where the support graph is subcubic and each vertex is incident to at least one edge with x-value 1. Such points are sufficient to resolve TSP in general. For these points, we construct a convex combination of tours in which we can reduce the usage of edges with x-value 1 from the $$\frac{3}{2}$$ of Christofides algorithm to $$\frac{3}{2}-\frac{\theta }{10}$$ while keeping the usage of edges with fractional x-value the same as Christofides algorithm. A direct consequence of this result is for the Uniform Cover Problem for TSP: In the case when the objective function of the subtour elimination relaxation is minimized by a $$\frac{2}{3}$$ -uniform point: $$x_e \in {0, \frac{2}{3}}$$ , we give a $$\frac{17}{12}$$ -approximation algorithm for TSP. For such points, this lands us halfway between the approximation ratios $$\frac{3}{2}$$ of Christofides algorithm and $$\frac{4}{3}$$ implied by the famous “four-thirds conjecture”.},
  archive      = {J_MP},
  author       = {Haddadan, Arash and Newman, Alantha},
  doi          = {10.1007/s10107-022-01784-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {595-620},
  shortjournal = {Math. Program.},
  title        = {Towards improving christofides algorithm on fundamental classes by gluing convex combinations of tours},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the optimality of pseudo-polynomial algorithms for
integer programming. <em>MP</em>, <em>198</em>(1), 561–593. (<a
href="https://doi.org/10.1007/s10107-022-01783-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the classic Integer Programming Feasibility (IPF) problem, the objective is to decide whether, for a given $$m \times n$$ matrix A and an m-vector $$b=(b_1,\dots , b_m)$$ , there is a non-negative integer n-vector x such that $$Ax=b$$ . Solving (IPF) is an important step in numerous algorithms and it is important to obtain an understanding of the precise complexity of this problem as a function of natural parameters of the input. The classic pseudo-polynomial time algorithm of Papadimitriou [J. ACM 1981] for instances of (IPF) with a constant number of constraints was only recently improved upon by Eisenbrand and Weismantel [SODA 2018] and Jansen and Rohwedder [ITCS 2019]. Jansen and Rohwedder designed an algorithm for (IPF) with running time $${\mathcal {O}}(m \varDelta )^m$$ $$\log (\varDelta ) \log (\varDelta +\Vert b\Vert _{\infty })+{\mathcal {O}}(mn)$$ . Here, $$\varDelta $$ is an upper bound on the absolute values of the entries of A. We continue this line of work and show that under the Exponential Time Hypothesis (ETH), the algorithm of Jansen and Rohwedder is nearly optimal, by proving a lower bound of $$n^{o(\frac{m}{\log m})} \cdot \Vert b\Vert _{\infty }^{o(m)}$$ . We also prove that assuming ETH, (IPF) cannot be solved in time $$f(m)\cdot (n \cdot \Vert b\Vert _{\infty })^{o(\frac{m}{\log m})}$$ for any computable function f. This motivates us to pick up the line of research initiated by Cunningham and Geelen [IPCO 2007] who studied the complexity of solving (IPF) with non-negative matrices in which the number of constraints may be unbounded, but the branch-width of the column-matroid corresponding to the constraint matrix is a constant. We prove a lower bound on the complexity of solving (IPF) for such instances and obtain optimal results with respect to a closely related parameter, path-width. Specifically, we prove matching upper and lower bounds for (IPF) when the path-width of the corresponding column-matroid is a constant .},
  archive      = {J_MP},
  author       = {Fomin, Fedor V. and Panolan, Fahad and Ramanujan, M. S. and Saurabh, Saket},
  doi          = {10.1007/s10107-022-01783-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {561-593},
  shortjournal = {Math. Program.},
  title        = {On the optimality of pseudo-polynomial algorithms for integer programming},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Lower bounds on the size of general branch-and-bound trees.
<em>MP</em>, <em>198</em>(1), 539–559. (<a
href="https://doi.org/10.1007/s10107-022-01781-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A general branch-and-bound tree is a branch-and-bound tree which is allowed to use general disjunctions of the form $$\pi ^{\top } x \le \pi _0 \,\vee \, \pi ^{\top }x \ge \pi _0 + 1$$ , where $$\pi $$ is an integer vector and $$\pi _0$$ is an integer scalar, to create child nodes. We construct a packing instance, a set covering instance, and a Traveling Salesman Problem instance, such that any general branch-and-bound tree that solves these instances must be of exponential size. We also verify that an exponential lower bound on the size of general branch-and-bound trees persists even when we add Gaussian noise to the coefficients of the cross-polytope, thus showing that a polynomial-size “smoothed analysis” upper bound is not possible. The results in this paper can be viewed as the branch-and-bound analog of the seminal paper by Chvátal et al. (Linear Algebra Appl 114:455–499, 1989), who proved lower bounds for the Chvátal–Gomory rank.},
  archive      = {J_MP},
  author       = {Dey, Santanu S. and Dubey, Yatharth and Molinaro, Marco},
  doi          = {10.1007/s10107-022-01781-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {539-559},
  shortjournal = {Math. Program.},
  title        = {Lower bounds on the size of general branch-and-bound trees},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Achieving consistency with cutting planes. <em>MP</em>,
<em>198</em>(1), 507–537. (<a
href="https://doi.org/10.1007/s10107-022-01778-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary role of cutting planes is to separate fractional solutions of the linear programming relaxation, which results in tighter bounds for pruning the search tree and reducing its size. Bounding, however, has an indirect impact on the size of the search tree. Cutting planes can also reduce backtracking by excluding inconsistent partial assignments that occur in the course of branching, which directly reduces the tree size. A partial assignment is inconsistent with a constraint set when it cannot be extended to a full feasible assignment. The constraint programming community has studied consistency extensively and used it as an effective tool for the reduction of backtracking. We extend this approach to integer programming by defining concepts of consistency that are useful in a branch-and-bound context. We present a theoretical framework for studying these concepts, their connection with the convex hull and their power to exclude infeasible partial assignments. We introduce a new class of cutting planes that target achieving consistency rather than improving dual bounds. Computational experiments on both synthetic and benchmark instances show that the new class of cutting planes can significantly outperform classical cutting planes, such as disjunctive cuts, by reducing the size of the search tree and the solution time. More broadly, we suggest that consistency concepts offer a new perspective on integer programming that can lead to a better understanding of what makes cutting planes work when used in branch-and-bound search.},
  archive      = {J_MP},
  author       = {Davarnia, Danial and Rajabalizadeh, Atefeh and Hooker, John},
  doi          = {10.1007/s10107-022-01778-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {507-537},
  shortjournal = {Math. Program.},
  title        = {Achieving consistency with cutting planes},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sublinear circuits and the constrained signomial
nonnegativity problem. <em>MP</em>, <em>198</em>(1), 471–505. (<a
href="https://doi.org/10.1007/s10107-022-01776-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional Sums-of-AM/GM-Exponentials (conditional SAGE) is a decomposition method to prove nonnegativity of a signomial or polynomial over some subset X of real space. In this article, we undertake the first structural analysis of conditional SAGE signomials for convex sets X. We introduce the X-circuits of a finite subset $${\mathcal {A}}\subset {\mathbb {R}}^n$$ , which generalize the simplicial circuits of the affine-linear matroid induced by $${\mathcal {A}}$$ to a constrained setting. The X-circuits serve as the main tool in our analysis and exhibit particularly rich combinatorial properties for polyhedral X, in which case the set of X-circuits is comprised of one-dimensional cones of suitable polyhedral fans. The framework of X-circuits transparently reveals when an X-nonnegative conditional AM/GM-exponential can in fact be further decomposed as a sum of simpler X-nonnegative signomials. We develop a duality theory for X-circuits with connections to geometry of sets that are convex according to the geometric mean. This theory provides an optimal power cone reconstruction of conditional SAGE signomials when X is polyhedral. In conjunction with a notion of reduced X-circuits, the duality theory facilitates a characterization of the extreme rays of conditional SAGE cones. Since signomials under logarithmic variable substitutions give polynomials, our results also have implications for nonnegative polynomials and polynomial optimization.},
  archive      = {J_MP},
  author       = {Murray, Riley and Naumann, Helen and Theobald, Thorsten},
  doi          = {10.1007/s10107-022-01776-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {471-505},
  shortjournal = {Math. Program.},
  title        = {Sublinear circuits and the constrained signomial nonnegativity problem},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Perturbed fenchel duality and first-order methods.
<em>MP</em>, <em>198</em>(1), 443–469. (<a
href="https://doi.org/10.1007/s10107-022-01779-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the iterates generated by a generic first-order meta-algorithm satisfy a canonical perturbed Fenchel duality inequality. The latter in turn readily yields a unified derivation of the best known convergence rates for various popular first-order algorithms including the conditional gradient method as well as the main kinds of Bregman proximal methods: subgradient, gradient, fast gradient, and universal gradient methods.},
  archive      = {J_MP},
  author       = {Gutman, David H. and Peña, Javier F.},
  doi          = {10.1007/s10107-022-01779-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {443-469},
  shortjournal = {Math. Program.},
  title        = {Perturbed fenchel duality and first-order methods},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Terracini convexity. <em>MP</em>, <em>198</em>(1), 399–441.
(<a href="https://doi.org/10.1007/s10107-022-01774-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a generalization of the notion of neighborliness to non-polyhedral convex cones. Although a definition of neighborliness is available in the non-polyhedral case in the literature, it is fairly restrictive as it requires all the low-dimensional faces to be polyhedral. Our approach is more flexible and includes, for example, the cone of positive-semidefinite matrices as a special case (this cone is not neighborly in general). We term our generalization Terracini convexity due to its conceptual similarity with the conclusion of Terracini’s lemma from algebraic geometry. Polyhedral cones are Terracini convex if and only if they are neighborly. More broadly, we derive many families of non-polyhedral Terracini convex cones based on neighborly cones, linear images of cones of positive-semidefinite matrices, and derivative relaxations of Terracini convex hyperbolicity cones. As a demonstration of the utility of our framework in the non-polyhedral case, we give a characterization based on Terracini convexity of the tightness of semidefinite relaxations for certain inverse problems.},
  archive      = {J_MP},
  author       = {Saunderson, James and Chandrasekaran, Venkat},
  doi          = {10.1007/s10107-022-01774-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {399-441},
  shortjournal = {Math. Program.},
  title        = {Terracini convexity},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Near-linear convergence of the random osborne algorithm for
matrix balancing. <em>MP</em>, <em>198</em>(1), 363–397. (<a
href="https://doi.org/10.1007/s10107-022-01825-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit Matrix Balancing, a pre-conditioning task used ubiquitously for computing eigenvalues and matrix exponentials. Since 1960, Osborne’s algorithm has been the practitioners’ algorithm of choice, and is now implemented in most numerical software packages. However, the theoretical properties of Osborne’s algorithm are not well understood. Here, we show that a simple random variant of Osborne’s algorithm converges in near-linear time in the input sparsity. Specifically, it balances $$K \in {\mathbb {R}}_{\ge 0}^{n \times n}$$ after $$O(m \varepsilon ^{-2} \log \kappa )$$ arithmetic operations in expectation and with high probability, where m is the number of nonzeros in K, $$\varepsilon $$ is the $$\ell _1$$ accuracy, and $$\kappa = \sum _{ij} K_{ij} / ( \min _{ij : K_{ij} \ne 0} K_{ij})$$ measures the conditioning of K. Previous work had established near-linear runtimes either only for $$\ell _2$$ accuracy (a weaker criterion which is less relevant for applications), or through an entirely different algorithm based on (currently) impractical Laplacian solvers. We further show that if the graph with adjacency matrix K is moderately connected—e.g., if K has at least one positive row/column pair—then Osborne’s algorithm initially converges exponentially fast, yielding an improved runtime $$O(m \varepsilon ^{-1} \log \kappa )$$ . We also address numerical precision issues by showing that these runtime bounds still hold when using $$O(\log (n\kappa /\varepsilon ))$$ -bit numbers. Our results are established through an intuitive potential argument that leverages a convex optimization perspective of Osborne’s algorithm, and relates the per-iteration progress to the current imbalance as measured in Hellinger distance. Unlike previous analyses, we critically exploit log-convexity of the potential. Notably, our analysis extends to other variants of Osborne’s algorithm: along the way, we also establish significantly improved runtime bounds for cyclic, greedy, and parallelized variants of Osborne’s algorithm.},
  archive      = {J_MP},
  author       = {Altschuler, Jason M. and Parrilo, Pablo A.},
  doi          = {10.1007/s10107-022-01825-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {363-397},
  shortjournal = {Math. Program.},
  title        = {Near-linear convergence of the random osborne algorithm for matrix balancing},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonlinear acceleration of momentum and primal-dual
algorithms. <em>MP</em>, <em>198</em>(1), 325–362. (<a
href="https://doi.org/10.1007/s10107-022-01775-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe convergence acceleration schemes for multistep optimization algorithms where the underlying fixed-point operator is not symmetric. In particular, our analysis handles algorithms with momentum terms such as Nesterov’s accelerated method or primal-dual methods. The acceleration technique combines previous iterates through a weighted sum, whose coefficients are computed via a simple linear system. We analyze performance in both online and offline modes, and we study in particular a variant of Nesterov’s method that uses nonlinear acceleration at each iteration. We use Crouzeix’s conjecture to show that acceleration performance is controlled by the solution of a Chebyshev problem on the numerical range of a non-symmetric operator modeling the behavior of iterates near the optimum. Numerical experiments are detailed on logistic regression problems.},
  archive      = {J_MP},
  author       = {Bollapragada, Raghu and Scieur, Damien and d’Aspremont, Alexandre},
  doi          = {10.1007/s10107-022-01775-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {325-362},
  shortjournal = {Math. Program.},
  title        = {Nonlinear acceleration of momentum and primal-dual algorithms},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized self-concordant analysis of frank–wolfe
algorithms. <em>MP</em>, <em>198</em>(1), 255–323. (<a
href="https://doi.org/10.1007/s10107-022-01771-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Projection-free optimization via different variants of the Frank–Wolfe method has become one of the cornerstones of large scale optimization for machine learning and computational statistics. Numerous applications within these fields involve the minimization of functions with self-concordance like properties. Such generalized self-concordant functions do not necessarily feature a Lipschitz continuous gradient, nor are they strongly convex, making them a challenging class of functions for first-order methods. Indeed, in a number of applications, such as inverse covariance estimation or distance-weighted discrimination problems in binary classification, the loss is given by a generalized self-concordant function having potentially unbounded curvature. For such problems projection-free minimization methods have no theoretical convergence guarantee. This paper closes this apparent gap in the literature by developing provably convergent Frank–Wolfe algorithms with standard $$\mathcal {O}(1/k)$$ convergence rate guarantees. Based on these new insights, we show how these sublinearly convergent methods can be accelerated to yield linearly convergent projection-free methods, by either relying on the availability of a local liner minimization oracle, or a suitable modification of the away-step Frank–Wolfe method.},
  archive      = {J_MP},
  author       = {Dvurechensky, Pavel and Safin, Kamil and Shtern, Shimrit and Staudigl, Mathias},
  doi          = {10.1007/s10107-022-01771-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {255-323},
  shortjournal = {Math. Program.},
  title        = {Generalized self-concordant analysis of Frank–Wolfe algorithms},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convergence rates of the heavy-ball method under the
łojasiewicz property. <em>MP</em>, <em>198</em>(1), 195–254. (<a
href="https://doi.org/10.1007/s10107-022-01770-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a joint study of the behavior of solutions of the Heavy Ball ODE and Heavy Ball type algorithms is given. Since the pioneering work of Polyak (USSR Comput Math Math Phys 4(5):1–17, 1964), it is well known that such a scheme is very efficient for $$C^2$$ strongly convex functions with Lipschitz gradient. But much less is known when only growth conditions are considered. Depending on the geometry of the function to minimize, convergence rates for convex functions, with some additional regularity such as quasi-strong convexity, or strong convexity, were recently obtained in Aujol et al. (Convergence rates of the Heavy-Ball method for quasi-strongly convex optimization, 2020). Convergence results with much weaker assumptions are given in the present paper: namely, linear convergence rates when assuming a growth condition (which amounts to a Łojasiewicz property in the convex case). This analysis is firstly performed in continuous time for the ODE, and then transposed for discrete optimization schemes. In particular, a variant of the Heavy Ball algorithm is proposed, which converges geometrically whatever the parameters choice, and which has the best state of the art convergence rate for first order methods to minimize composite non smooth convex functions satisfying a Łojasiewicz property.},
  archive      = {J_MP},
  author       = {Aujol, J.-F. and Dossal, Ch. and Rondepierre, A.},
  doi          = {10.1007/s10107-022-01770-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {195-254},
  shortjournal = {Math. Program.},
  title        = {Convergence rates of the heavy-ball method under the Łojasiewicz property},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Augmented lagrangians and hidden convexity in sufficient
conditions for local optimality. <em>MP</em>, <em>198</em>(1), 159–194.
(<a href="https://doi.org/10.1007/s10107-022-01768-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Second-order sufficient conditions for local optimality have long been central to designing solution algorithms and justifying claims about their convergence. Here a far-reaching extension of such conditions, called variational sufficiency, is explored in territory beyond just classical nonlinear programming. Variational sufficiency is already known to support multiplier methods that are able, even without convexity, to achieve problem decomposition, but further insight has been needed into how it coordinates with other sufficient conditions. In the framework of this paper, it is shown to characterize local optimality in terms of having a convex–concave-type local saddle point of an augmented Lagrangian function. A stronger version of variational sufficiency is tied in turn to local strong convexity in the primal argument of that function and a property of augmented tilt stability that offers crucial aid to Lagrange multiplier methods at a fundamental level of analysis. Moreover, that strong version is translated here through second-order variational analysis into statements that can readily be compared to existing sufficient conditions in nonlinear programming, second-order cone programming, and other problem formulations which can incorporate nonsmooth objectives and regularization terms.},
  archive      = {J_MP},
  author       = {Rockafellar, R. Tyrrell},
  doi          = {10.1007/s10107-022-01768-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {159-194},
  shortjournal = {Math. Program.},
  title        = {Augmented lagrangians and hidden convexity in sufficient conditions for local optimality},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse PCA on fixed-rank matrices. <em>MP</em>,
<em>198</em>(1), 139–157. (<a
href="https://doi.org/10.1007/s10107-022-01769-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse PCA is the optimization problem obtained from PCA by adding a sparsity constraint on the principal components. Sparse PCA is NP-hard and hard to approximate even in the single-component case. In this paper we settle the computational complexity of sparse PCA with respect to the rank of the covariance matrix. We show that, if the rank of the covariance matrix is a fixed value, then there is an algorithm that solves sparse PCA to global optimality, whose running time is polynomial in the number of features. We also prove a similar result for the version of sparse PCA which requires the principal components to have disjoint supports.},
  archive      = {J_MP},
  author       = {Del Pia, Alberto},
  doi          = {10.1007/s10107-022-01769-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {139-157},
  shortjournal = {Math. Program.},
  title        = {Sparse PCA on fixed-rank matrices},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Affine-invariant contracting-point methods for convex
optimization. <em>MP</em>, <em>198</em>(1), 115–137. (<a
href="https://doi.org/10.1007/s10107-021-01761-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop new affine-invariant algorithms for solving composite convex minimization problems with bounded domain. We present a general framework of Contracting-Point methods, which solve at each iteration an auxiliary subproblem restricting the smooth part of the objective function onto contraction of the initial domain. This framework provides us with a systematic way for developing optimization methods of different order, endowed with the global complexity bounds. We show that using an appropriate affine-invariant smoothness condition, it is possible to implement one iteration of the Contracting-Point method by one step of the pure tensor method of degree $$p \ge 1$$ . The resulting global rate of convergence in functional residual is then $${\mathcal {O}}(1 / k^p)$$ , where k is the iteration counter. It is important that all constants in our bounds are affine-invariant. For $$p = 1$$ , our scheme recovers well-known Frank–Wolfe algorithm, providing it with a new interpretation by a general perspective of tensor methods. Finally, within our framework, we present efficient implementation and total complexity analysis of the inexact second-order scheme $$(p = 2)$$ , called Contracting Newton method. It can be seen as a proper implementation of the trust-region idea. Preliminary numerical results confirm its good practical performance both in the number of iterations, and in computational time.},
  archive      = {J_MP},
  author       = {Doikov, Nikita and Nesterov, Yurii},
  doi          = {10.1007/s10107-021-01761-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {115-137},
  shortjournal = {Math. Program.},
  title        = {Affine-invariant contracting-point methods for convex optimization},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Error bounds and a condition number for the absolute value
equations. <em>MP</em>, <em>198</em>(1), 85–113. (<a
href="https://doi.org/10.1007/s10107-021-01756-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their relation to the linear complementarity problem, absolute value equations have been intensively studied recently. In this paper, we present error bound conditions for absolute value equations. Along with the error bounds, we introduce a condition number. We consider general scaled matrix p-norms, as well as particular p-norms. We discuss basic properties of the condition number, including its computational complexity. We present various bounds on the condition number, and we give exact formulae for special classes of matrices. Moreover, we consider matrices that appear based on the transformation from the linear complementarity problem. Finally, we apply the error bound to convergence analysis of two methods for solving absolute value equations.},
  archive      = {J_MP},
  author       = {Zamani, Moslem and Hladík, Milan},
  doi          = {10.1007/s10107-021-01756-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {85-113},
  shortjournal = {Math. Program.},
  title        = {Error bounds and a condition number for the absolute value equations},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximation algorithms for the generalized incremental
knapsack problem. <em>MP</em>, <em>198</em>(1), 27–83. (<a
href="https://doi.org/10.1007/s10107-021-01755-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study a discrete multi-period extension of the classical knapsack problem, dubbed generalized incremental knapsack. In this setting, we are given a set of n items, each associated with a non-negative weight, and T time periods with non-decreasing capacities $$W_1 \le \dots \le W_T$$ . When item i is inserted at time t, we gain a profit of $$p_{it}$$ ; however, this item remains in the knapsack for all subsequent periods. The goal is to decide if and when to insert each item, subject to the time-dependent capacity constraints, with the objective of maximizing our total profit. Interestingly, this setting subsumes as special cases a number of recently-studied incremental knapsack problems, all known to be strongly NP-hard. Our first contribution comes in the form of a polynomial-time $$(\frac{1}{2}-\epsilon )$$ -approximation for the generalized incremental knapsack problem. This result is based on a reformulation as a single-machine sequencing problem, which is addressed by blending dynamic programming techniques and the classical Shmoys–Tardos algorithm for the generalized assignment problem. Combined with further enumeration-based self-reinforcing ideas and new structural properties of nearly-optimal solutions, we turn our algorithm into a quasi-polynomial time approximation scheme (QPTAS). Hence, under widely believed complexity assumptions, this finding rules out the possibility that generalized incremental knapsack is APX-hard.},
  archive      = {J_MP},
  author       = {Faenza, Yuri and Segev, Danny and Zhang, Lingyi},
  doi          = {10.1007/s10107-021-01755-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {27-83},
  shortjournal = {Math. Program.},
  title        = {Approximation algorithms for the generalized incremental knapsack problem},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Arboricity games: The core and the nucleolus. <em>MP</em>,
<em>198</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s10107-021-01752-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The arboricity of a graph is the minimum number of forests required to cover all its edges. In this paper, we examine arboricity from a game-theoretic perspective and investigate cost-sharing in the minimum forest cover problem. We introduce the arboricity game as a cooperative cost game defined on a graph. The players are edges, and the cost of each coalition is the arboricity of the subgraph induced by the coalition. We study properties of the core and propose an efficient algorithm for computing the nucleolus when the core is not empty. In order to compute the nucleolus in the core, we introduce the prime partition which is built on the densest subgraph lattice. The prime partition decomposes the edge set of a graph into a partially ordered set defined from minimal densest minors and their invariant precedence relation. Moreover, edges from the same partition always have the same value in a core allocation. Consequently, when the core is not empty, the prime partition significantly reduces the number of variables and constraints required in the linear programs of Maschler’s scheme and allows us to compute the nucleolus in polynomial time. Besides, the prime partition provides a graph decomposition analogous to the celebrated core decomposition and the density-friendly decomposition, which may be of independent interest.},
  archive      = {J_MP},
  author       = {Xiao, Han and Fang, Qizhi},
  doi          = {10.1007/s10107-021-01752-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Math. Program.},
  title        = {Arboricity games: The core and the nucleolus},
  volume       = {198},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linear regression with partially mismatched data: Local
search with theoretical guarantees. <em>MP</em>, <em>197</em>(2),
1265–1303. (<a
href="https://doi.org/10.1007/s10107-022-01863-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear regression is a fundamental modeling tool in statistics and related fields. In this paper, we study an important variant of linear regression in which the predictor-response pairs are partially mismatched. We use an optimization formulation to simultaneously learn the underlying regression coefficients and the permutation corresponding to the mismatches. The combinatorial structure of the problem leads to computational challenges. We propose and study a simple greedy local search algorithm for this optimization problem that enjoys strong theoretical guarantees and appealing computational performance. We prove that under a suitable scaling of the number of mismatched pairs compared to the number of samples and features, and certain assumptions on problem data; our local search algorithm converges to a nearly-optimal solution at a linear rate. In particular, in the noiseless case, our algorithm converges to the global optimal solution with a linear convergence rate. Based on this result, we prove an upper bound for the estimation error of the parameter. We also propose an approximate local search step that allows us to scale our approach to much larger instances. We conduct numerical experiments to gather further insights into our theoretical results, and show promising performance gains compared to existing approaches.},
  archive      = {J_MP},
  author       = {Mazumder, Rahul and Wang, Haoyue},
  doi          = {10.1007/s10107-022-01863-y},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1265-1303},
  shortjournal = {Math. Program.},
  title        = {Linear regression with partially mismatched data: Local search with theoretical guarantees},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the integrality gap of binary integer programs with
gaussian data. <em>MP</em>, <em>197</em>(2), 1221–1263. (<a
href="https://doi.org/10.1007/s10107-022-01828-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a binary integer program (IP) $$\max c^{\mathsf {T}}x, Ax \le b, x \in {0,1}^n$$ , where $$A \in {\mathbb {R}}^{m \times n}$$ and $$c \in {\mathbb {R}}^n$$ have independent Gaussian entries and the right-hand side $$b \in {\mathbb {R}}^m$$ satisfies that its negative coordinates have $$\ell _2$$ norm at most n/10, we prove that the gap between the value of the linear programming relaxation and the IP is upper bounded by $${\text {poly}}(m)(\log n)^2 / n$$ with probability at least $$1-2/n^7-2^{-{\text {poly}}(m)}$$ . Our results give a Gaussian analogue of the classical integrality gap result of Dyer and Frieze (Math OR, 1989) in the case of random packing IPs. In constrast to the packing case, our integrality gap depends only polynomially on m instead of exponentially. Building upon recent breakthrough work of Dey, Dubey and Molinaro (SODA, 2021), we show that the integrality gap implies that branch-and-bound requires $$n^{{\text {poly}}(m)}$$ time on random Gaussian IPs with good probability, which is polynomial when the number of constraints m is fixed. We derive this result via a novel meta-theorem, which relates the size of branch-and-bound trees and the integrality gap for random logconcave IPs.},
  archive      = {J_MP},
  author       = {Borst, Sander and Dadush, Daniel and Huiberts, Sophie and Tiwari, Samarth},
  doi          = {10.1007/s10107-022-01828-1},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1221-1263},
  shortjournal = {Math. Program.},
  title        = {On the integrality gap of binary integer programs with gaussian data},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proximity bounds for random integer programs. <em>MP</em>,
<em>197</em>(2), 1201–1219. (<a
href="https://doi.org/10.1007/s10107-022-01786-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study proximity bounds within a natural model of random integer programs of the type $$\max \;\varvec{c}^{\top }\varvec{x}:\varvec{A}\varvec{x}=\varvec{b},\,\varvec{x}\in {\mathbb {Z}}_{\ge 0}$$ , where $$\varvec{A}\in {\mathbb {Z}}^{m\times n}$$ is of rank m, $$\varvec{b}\in {\mathbb {Z}}^{m}$$ and $$\varvec{c}\in {\mathbb {Z}}^{n}$$ . In particular, we seek bounds for proximity in terms of the parameter $$\Delta (\varvec{A})$$ , which is the square root of the determinant of the Gram matrix $$\varvec{A}\varvec{A}^{\top }$$ of $$\varvec{A}$$ . We prove that, up to constants depending on n and m, the proximity is “generally” bounded by $$\Delta (\varvec{A})^{1/(n-m)}$$ , which is significantly better than the best deterministic bounds which are, again up to dimension constants, linear in $$\Delta (\varvec{A})$$ .},
  archive      = {J_MP},
  author       = {Celaya, Marcel and Henk, Martin},
  doi          = {10.1007/s10107-022-01786-8},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1201-1219},
  shortjournal = {Math. Program.},
  title        = {Proximity bounds for random integer programs},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computational aspects of relaxation complexity:
Possibilities and limitations. <em>MP</em>, <em>197</em>(2), 1173–1200.
(<a href="https://doi.org/10.1007/s10107-021-01754-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relaxation complexity $${{\,\mathrm{rc}\,}}(X)$$ of the set of integer points X contained in a polyhedron is the smallest number of facets of any polyhedron P such that the integer points in P coincide with X. It is a useful tool to investigate the existence of compact linear descriptions of X. In this article, we derive tight and computable upper bounds on $${{\,\mathrm{rc}\,}}_\mathbb {Q}(X)$$ , a variant of $${{\,\mathrm{rc}\,}}(X)$$ in which the polyhedra P are required to be rational, and we show that $${{\,\mathrm{rc}\,}}(X)$$ can be computed in polynomial time if X is 2-dimensional. Further, we investigate computable lower bounds on $${{\,\mathrm{rc}\,}}(X)$$ with the particular focus on the existence of a finite set $$Y \subseteq \mathbb {Z}^d$$ such that separating X and $$Y \setminus X$$ allows us to deduce $${{\,\mathrm{rc}\,}}(X) \ge k$$ . In particular, we show for some choices of X that no such finite set Y exists to certify the value of $${{\,\mathrm{rc}\,}}(X)$$ , providing a negative answer to a question by Weltge (2015). We also obtain an explicit formula for $${{\,\mathrm{rc}\,}}(X)$$ for specific classes of sets X and present the first practically applicable approach to compute $${{\,\mathrm{rc}\,}}(X)$$ for sets X that admit a finite certificate.},
  archive      = {J_MP},
  author       = {Averkov, Gennadiy and Hojny, Christopher and Schymura, Matthias},
  doi          = {10.1007/s10107-021-01754-8},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1173-1200},
  shortjournal = {Math. Program.},
  title        = {Computational aspects of relaxation complexity: Possibilities and limitations},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The double exponential runtime is tight for 2-stage
stochastic ILPs. <em>MP</em>, <em>197</em>(2), 1145–1172. (<a
href="https://doi.org/10.1007/s10107-022-01837-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider fundamental algorithmic number theoretic problems and their relation to a class of block structured Integer Linear Programs (ILPs) called 2-stage stochastic. A 2-stage stochastic ILP is an integer program of the form $$\min {c^T x \mid {\mathcal {A}} x = b, \ell \le x \le u, x \in {\mathbb {Z}}^{r + ns} }$$ where the constraint matrix $${\mathcal {A}} \in {\mathbb {Z}}^{nt \times r +ns}$$ consists of n matrices $$A_i \in {\mathbb {Z}}^{t \times r}$$ on the vertical line and n matrices $$B_i \in {\mathbb {Z}}^{t \times s}$$ on the diagonal line aside. We show a stronger hardness result for a number theoretic problem called Quadratic Congruences where the objective is to compute a number $$z \le \gamma $$ satisfying $$z^2 \equiv \alpha \bmod \beta $$ for given $$\alpha , \beta , \gamma \in {\mathbb {Z}}$$ . This problem was proven to be NP-hard already in 1978 by Manders and Adleman. However, this hardness only applies for instances where the prime factorization of $$\beta $$ admits large multiplicities of each prime number. We circumvent this necessity proving that the problem remains NP-hard, even if each prime number only occurs constantly often. Using this new hardness result for the $$\textsc {Quadratic Congruences}$$ problem, we prove a lower bound of $$2^{2^{\delta (s+t)}} |I|^{O(1)}$$ for some $$\delta &gt; 0$$ for the running time of any algorithm solving 2-stage stochastic ILPs assuming the Exponential Time Hypothesis (ETH). Here, |I| is the encoding length of the instance. This result even holds if r, $$||b||_{\infty }$$ , $$||c||_{\infty }, ||\ell ||_{\infty }$$ and the largest absolute value $$\varDelta $$ in the constraint matrix $${\mathcal {A}}$$ are constant. This shows that the state-of-the-art algorithms are nearly tight. Further, it proves the suspicion that these ILPs are indeed harder to solve than the closely related $$n$$ -fold ILPs where the constraint matrix is the transpose of $${\mathcal {A}}$$ .},
  archive      = {J_MP},
  author       = {Jansen, Klaus and Klein, Kim-Manuel and Lassota, Alexandra},
  doi          = {10.1007/s10107-022-01837-0},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1145-1172},
  shortjournal = {Math. Program.},
  title        = {The double exponential runtime is tight for 2-stage stochastic ILPs},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed parameter approximation scheme for min-max k-cut.
<em>MP</em>, <em>197</em>(2), 1093–1144. (<a
href="https://doi.org/10.1007/s10107-022-01842-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the graph k-partitioning problem under the min-max objective, termed as Minmax $$k$$ -cut. The input here is a graph $$G=(V,E)$$ with non-negative integral edge weights $$w:E\rightarrow {\mathbb {Z}}_+$$ and an integer $$k\ge 2$$ and the goal is to partition the vertices into k non-empty parts $$V_1, \ldots , V_k$$ so as to minimize $$\max _{i=1}^k w(\delta (V_i))$$ . Although minimizing the sum objective $$\sum _{i=1}^k w(\delta (V_i))$$ , termed as Minsum $$k$$ -cut, has been studied extensively in the literature, very little is known about minimizing the max objective. We initiate the study of Minmax $$k$$ -cut by showing that it is NP-hard and W[1]-hard when parameterized by k, and design a parameterized approximation scheme when parameterized by k. The main ingredient of our parameterized approximation scheme is an exact algorithm for Minmax $$k$$ -cut that runs in time $$(\lambda k)^{{\mathsf {O}}(k^2)}n^{{\mathsf {O}}(1)}+{\mathsf {O}}(m)$$ , where $$\lambda $$ is value of the optimum, n is the number of vertices, and m is the number of edges. Our algorithmic technique builds on the technique of Lokshtanov, Saurabh, and Surianarayanan (FOCS, 2020) who showed a similar result for Minsum $$k$$ -cut. Our algorithmic techniques are more general and can be used to obtain parameterized approximation schemes for minimizing $$\ell _p$$ -norm measures of k-partitioning for every $$p\ge 1$$ .},
  archive      = {J_MP},
  author       = {Chandrasekaran, Karthekeyan and Wang, Weihang},
  doi          = {10.1007/s10107-022-01842-3},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1093-1144},
  shortjournal = {Math. Program.},
  title        = {Fixed parameter approximation scheme for min-max k-cut},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A tight approximation algorithm for the cluster vertex
deletion problem. <em>MP</em>, <em>197</em>(2), 1069–1091. (<a
href="https://doi.org/10.1007/s10107-021-01744-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give the first 2-approximation algorithm for the cluster vertex deletion problem. This approximation factor is tight, since approximating the problem within any constant factor smaller than 2 is UGC-hard. Our algorithm combines previous approaches, based on the local ratio technique and the management of twins, with a novel construction of a “good” cost function on the vertices at distance at most 2 from any vertex of the input graph. As an additional contribution, we also study cluster vertex deletion from the polyhedral perspective, where we prove almost matching upper and lower bounds on how well linear programming relaxations can approximate the problem.},
  archive      = {J_MP},
  author       = {Aprile, Manuel and Drescher, Matthew and Fiorini, Samuel and Huynh, Tony},
  doi          = {10.1007/s10107-021-01744-w},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1069-1091},
  shortjournal = {Math. Program.},
  title        = {A tight approximation algorithm for the cluster vertex deletion problem},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximum weight disjoint paths in outerplanar graphs via
single-tree cut approximators. <em>MP</em>, <em>197</em>(2), 1049–1067.
(<a href="https://doi.org/10.1007/s10107-022-01780-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 1997 there has been a steady stream of advances for the maximum disjoint paths problem. Achieving tractable results has usually required focusing on relaxations such as: (i) to allow some bounded edge congestion in solutions, (ii) to only consider the unit weight (cardinality) setting, (iii) to only require fractional routability of the selected demands (the all-or-nothing flow setting). For the general form (no congestion, general weights, integral routing) of edge-disjoint paths (edp) even the case of unit capacity trees which are stars generalizes the maximum matching problem for which Edmonds provided an exact algorithm. For general capacitated trees, Garg, Vazirani, Yannakakis showed the problem is APX-Hard and Chekuri, Mydlarz, Shepherd provided a 4-approximation. This is essentially the only setting where a constant approximation is known for the general form of edp. We extend their result by giving a constant-factor approximation algorithm for general-form edp in outerplanar graphs. A key component for the algorithm is to find a single-tree O(1) cut approximator for outerplanar graphs. Previously O(1) cut approximators were only known via distributions on trees and these were based implicitly on the results of Gupta, Newman, Rabinovich and Sinclair for distance tree embeddings combined with results of Anderson and Feige.},
  archive      = {J_MP},
  author       = {Naves, Guyslain and Shepherd, F. Bruce and Xia, Henry},
  doi          = {10.1007/s10107-022-01780-0},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1049-1067},
  shortjournal = {Math. Program.},
  title        = {Maximum weight disjoint paths in outerplanar graphs via single-tree cut approximators},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Speed-robust scheduling: Sand, bricks, and rocks.
<em>MP</em>, <em>197</em>(2), 1009–1048. (<a
href="https://doi.org/10.1007/s10107-022-01829-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The speed-robust scheduling problem is a two-stage problem where, given m machines, jobs must be grouped into at most m bags while the processing speeds of the machines are unknown. After the speeds are revealed, the grouped jobs must be assigned to the machines without being separated. To evaluate the performance of algorithms, we determine upper bounds on the worst-case ratio of the algorithm’s makespan and the optimal makespan given full information. We refer to this ratio as the robustness factor. We give an algorithm with a robustness factor $$2-\frac{1}{m}$$ for the most general setting and improve this to 1.8 for equal-size jobs. For the special case of infinitesimal jobs, we give an algorithm with an optimal robustness factor equal to $$\frac{e}{e-1}\approx 1.58$$ . The particular machine environment in which all machines have either speed 0 or 1 was studied before by Stein and Zhong (ACM Trans Algorithms 16(1):1-20, 2020. https://doi.org/10.1145/3340320 ). For this setting, we provide an algorithm for scheduling infinitesimal jobs with an optimal robustness factor of $$\frac{1+\sqrt{2}}{2}\approx 1.207$$ . It lays the foundation for an algorithm matching the lower bound of $$\frac{4}{3}$$ for equal-size jobs.},
  archive      = {J_MP},
  author       = {Eberle, Franziska and Hoeksma, Ruben and Megow, Nicole and Nölke, Lukas and Schewior, Kevin and Simon, Bertrand},
  doi          = {10.1007/s10107-022-01829-0},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {1009-1048},
  shortjournal = {Math. Program.},
  title        = {Speed-robust scheduling: Sand, bricks, and rocks},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust k-center with two types of radii. <em>MP</em>,
<em>197</em>(2), 991–1007. (<a
href="https://doi.org/10.1007/s10107-022-01799-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the non-uniform k-center problem, the objective is to cover points in a metric space with specified number of balls of different radii. Chakrabarty, Goyal, and Krishnaswamy [ICALP 2016, Trans. on Algs. 2020] (CGK, henceforth) give a constant factor approximation when there are two types of radii. In this paper, we give a constant factor approximation for the two radii case in the presence of outliers. To achieve this, we need to bypass the technical barrier of bad integrality gaps in the CGK approach. We do so using “the ellipsoid method inside the ellipsoid method”: use an outer layer of the ellipsoid method to reduce to stylized instances and use an inner layer of the ellipsoid method to solve these specialized instances. This idea is of independent interest and could be applicable to other problems.},
  archive      = {J_MP},
  author       = {Chakrabarty, Deeparnab and Negahbani, Maryam},
  doi          = {10.1007/s10107-022-01799-3},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {991-1007},
  shortjournal = {Math. Program.},
  title        = {Robust k-center with two types of radii},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-streaming algorithms for submodular matroid
intersection. <em>MP</em>, <em>197</em>(2), 967–990. (<a
href="https://doi.org/10.1007/s10107-022-01858-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the basic greedy algorithm gives a semi-streaming algorithm with an approximation guarantee of 2 for the unweighted matching problem, it was only recently that Paz and Schwartzman obtained an analogous result for weighted instances. Their approach is based on the versatile local ratio technique and also applies to generalizations such as weighted hypergraph matchings. However, the framework for the analysis fails for the related problem of weighted matroid intersection and as a result the approximation guarantee for weighted instances did not match the factor 2 achieved by the greedy algorithm for unweighted instances.Our main result closes this gap by developing a semi-streaming algorithm with an approximation guarantee of $$2+\varepsilon $$ for weighted matroid intersection, improving upon the previous best guarantee of $$4+\varepsilon $$ . Our techniques also allow us to generalize recent results by Levin and Wajc on submodular maximization subject to matching constraints to that of matroid-intersection constraints. While our algorithm is an adaptation of the local ratio technique used in previous works, the analysis deviates significantly and relies on structural properties of matroid intersection, called kernels. Finally, we also conjecture that our algorithm gives a $$(k+\varepsilon )$$ approximation for the intersection of k matroids but prove that new tools are needed in the analysis as the structural properties we use fail for $$k\ge 3$$ .},
  archive      = {J_MP},
  author       = {Garg, Paritosh and Jordan, Linus and Svensson, Ola},
  doi          = {10.1007/s10107-022-01858-9},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {967-990},
  shortjournal = {Math. Program.},
  title        = {Semi-streaming algorithms for submodular matroid intersection},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implications, conflicts, and reductions for steiner trees.
<em>MP</em>, <em>197</em>(2), 903–966. (<a
href="https://doi.org/10.1007/s10107-021-01757-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Steiner tree problem in graphs (SPG) is one of the most studied problems in combinatorial optimization. In the past 10 years, there have been significant advances concerning approximation and complexity of the SPG. However, the state of the art in (practical) exact solution of the SPG has remained largely unchallenged for almost 20 years. While the DIMACS Challenge 2014 and the PACE Challenge 2018 brought renewed interest into Steiner tree problems, even the best new SPG solvers cannot match the state of the art on the vast majority of benchmark instances. The following article seeks to advance exact SPG solution once again. The article is based on a combination of three concepts: Implications, conflicts, and reductions. As a result, various new SPG techniques are conceived. Notably, several of the resulting techniques are (provably) stronger than well-known methods from the literature that are used in exact SPG algorithms. Finally, by integrating the new methods into a branch-and-cut framework, we obtain an exact SPG solver that is not only competitive with, but even outperforms the current state of the art on an extensive collection of benchmark sets. Furthermore, we can solve several instances for the first time to optimality.},
  archive      = {J_MP},
  author       = {Rehfeldt, Daniel and Koch, Thorsten},
  doi          = {10.1007/s10107-021-01757-5},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {903-966},
  shortjournal = {Math. Program.},
  title        = {Implications, conflicts, and reductions for steiner trees},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new integer programming formulation of the graphical
traveling salesman problem. <em>MP</em>, <em>197</em>(2), 877–902. (<a
href="https://doi.org/10.1007/s10107-022-01849-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Traveling Salesman Problem (TSP), a salesman wants to visit a set of cities and return home. There is a cost $$c_{ij}$$ of traveling from city i to city j, which is the same in either direction for the Symmetric TSP. The objective is to visit each city exactly once, minimizing total travel costs. In the Graphical TSP, a city may be visited more than once, which may be necessary on a sparse graph. We present a new integer programming formulation for the Graphical TSP requiring only two classes of polynomial-sized constraints while addressing an open question proposed by Denis Naddef. We generalize one of these classes, and present promising preliminary computational results.},
  archive      = {J_MP},
  author       = {Carr, Robert and Ravi, R. and Simonetti, Neil},
  doi          = {10.1007/s10107-022-01849-w},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {877-902},
  shortjournal = {Math. Program.},
  title        = {A new integer programming formulation of the graphical traveling salesman problem},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-cover inequalities for totally-ordered multiple
knapsack sets: Theory and computation. <em>MP</em>, <em>197</em>(2),
847–875. (<a href="https://doi.org/10.1007/s10107-022-01817-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a method to generate cutting-planes from multiple covers of knapsack constraints. The covers may come from different knapsack inequalities if the weights in the inequalities form a totally-ordered set. Thus, we introduce and study the structure of a totally-ordered multiple knapsack set. The valid multi-cover inequalities we derive for its convex hull have a number of interesting properties. First, they generalize the well-known (1, k)-configuration inequalities. Second, they are not aggregation cuts. Third, they cannot be generated as rank-1 Chvátal-Gomory cuts from the inequality system consisting of the knapsack constraints and all their minimal cover inequalities. We also provide conditions under which the inequalities are facets for the convex hull of the totally-ordered knapsack set, as well as conditions for those inequalities to fully characterize its convex hull. We give an integer program to solve the separation and provide numerical experiments that showcase the strength of these new inequalities},
  archive      = {J_MP},
  author       = {Del Pia, Alberto and Linderoth, Jeff and Zhu, Haoran},
  doi          = {10.1007/s10107-022-01817-4},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {847-875},
  shortjournal = {Math. Program.},
  title        = {Multi-cover inequalities for totally-ordered multiple knapsack sets: Theory and computation},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exact solution of network flow models with strong
relaxations. <em>MP</em>, <em>197</em>(2), 813–846. (<a
href="https://doi.org/10.1007/s10107-022-01785-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the solution of Mixed Integer Linear Programming (MILP) models with strong relaxations that are derived from Dantzig–Wolfe decompositions and allow a pseudo-polynomial pricing algorithm. We exploit their network-flow characterization and provide a framework based on column generation, reduced-cost variable-fixing, and a highly asymmetric branching scheme that allows us to take advantage of the potential of the current MILP solvers. We apply our framework to a variety of cutting and packing problems from the literature. The efficiency of the framework is proved by extensive computational experiments, in which a significant number of open instances could be solved to proven optimality for the first time.},
  archive      = {J_MP},
  author       = {de Lima, Vinícius Loti and Iori, Manuel and Miyazawa, Flávio Keidi},
  doi          = {10.1007/s10107-022-01785-9},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {813-846},
  shortjournal = {Math. Program.},
  title        = {Exact solution of network flow models with strong relaxations},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A computational status update for exact rational mixed
integer programming. <em>MP</em>, <em>197</em>(2), 793–812. (<a
href="https://doi.org/10.1007/s10107-021-01749-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The last milestone achievement for the roundoff-error-free solution of general mixed integer programs over the rational numbers was a hybrid-precision branch-and-bound algorithm published by Cook, Koch, Steffy, and Wolter in 2013. We describe a substantial revision and extension of this framework that integrates symbolic presolving, features an exact repair step for solutions from primal heuristics, employs a faster rational LP solver based on LP iterative refinement, and is able to produce independently verifiable certificates of optimality. We study the significantly improved performance and give insights into the computational behavior of the new algorithmic components. On the MIPLIB 2017 benchmark set, we observe an average speedup of 10.7x over the original framework and 2.9 times as many instances solved within a time limit of two hours.},
  archive      = {J_MP},
  author       = {Eifler, Leon and Gleixner, Ambros},
  doi          = {10.1007/s10107-021-01749-5},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {793-812},
  shortjournal = {Math. Program.},
  title        = {A computational status update for exact rational mixed integer programming},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A finite time combinatorial algorithm for instantaneous
dynamic equilibrium flows. <em>MP</em>, <em>197</em>(2), 761–792. (<a
href="https://doi.org/10.1007/s10107-022-01772-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instantaneous dynamic equilibrium (IDE) is a standard game-theoretic concept in dynamic traffic assignment in which individual flow particles myopically select en route currently shortest paths towards their destination. We analyze IDE within the Vickrey bottleneck model, where current travel times along a path consist of the physical travel times plus the sum of waiting times in all the queues along a path. Although IDE have been studied for decades, several fundamental questions regarding equilibrium computation and complexity are not well understood. In particular, all existence results and computational methods are based on fixed-point theorems and numerical discretization schemes and no exact finite time algorithm for equilibrium computation is known to date. As our main result we show that a natural extension algorithm needs only finitely many phases to converge leading to the first finite time combinatorial algorithm computing an IDE. We complement this result by several hardness results showing that computing IDE with natural properties is NP-hard.},
  archive      = {J_MP},
  author       = {Graf, Lukas and Harks, Tobias},
  doi          = {10.1007/s10107-022-01772-0},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {761-792},
  shortjournal = {Math. Program.},
  title        = {A finite time combinatorial algorithm for instantaneous dynamic equilibrium flows},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Affinely representable lattices, stable matchings, and
choice functions. <em>MP</em>, <em>197</em>(2), 721–760. (<a
href="https://doi.org/10.1007/s10107-022-01838-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Birkhoff’s representation theorem (Birkhoff, Duke Math J 3(3):443–454, 1937) defines a bijection between elements of a distributive lattice and the family of upper sets of an associated poset. Although not used explicitly, this result is at the backbone of the combinatorial algorithm by Irving et al. (J ACM 34(3):532-543, 1987) for maximizing a linear function over the set of stable matchings in Gale and Shapley’s stable marriage model (Gale and Shapley, Am Math Monthly 69(1):9–15 1962). In this paper, we introduce a property of distributive lattices, which we term as affine representability, and show its role in efficiently solving linear optimization problems over the elements of a distributive lattice, as well as describing the convex hull of the characteristic vectors of the lattice elements. We apply this concept to the stable matching model with path-independent quota-filling choice functions, thus giving efficient algorithms and a compact polyhedral description for this model. To the best of our knowledge, this model generalizes all those for which similar results were known, and our paper is the first that proposes efficient algorithms for stable matchings with choice functions, beyond classical extensions of the Deferred Acceptance algorithm.},
  archive      = {J_MP},
  author       = {Faenza, Yuri and Zhang, Xuan},
  doi          = {10.1007/s10107-022-01838-z},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {721-760},
  shortjournal = {Math. Program.},
  title        = {Affinely representable lattices, stable matchings, and choice functions},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the geometry of symmetry breaking inequalities.
<em>MP</em>, <em>197</em>(2), 693–719. (<a
href="https://doi.org/10.1007/s10107-022-01819-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breaking symmetries is a popular way of speeding up the branch-and-bound method for symmetric integer programs. We study fundamental domains, which are minimal and closed symmetry breaking polyhedra. Our long-term goal is to understand the relationship between the complexity of such polyhedra and their symmetry breaking capability. Borrowing ideas from geometric group theory, we provide structural properties that relate the action of the group with the geometry of the facets of fundamental domains. Inspired by these insights, we provide a new generalized construction for fundamental domains, which we call generalized Dirichlet domain. Our construction is recursive and exploits the coset decomposition of the subgroups that fix given vectors in $${\mathbb {R}}^n$$ . We use this construction to analyze a recently introduced set of symmetry breaking inequalities by Salvagnin (Symmetry Breaking Inequalities from the Schreier-Sims table. In: International Conference on the Integration of Constraint Programming, Artificial Intelligence, and Operations Research, pp. 521–529, 2018) and Liberti and Ostrowski (J Global Opt 60:183–194, 2014), called Schreier-Sims inequalities. In particular, this shows that every permutation group admits a fundamental domain with less than n facets. We also show that this bound is tight. Finally, we prove that the fundamental domain defined by the Schreier-Sims inequalities can contain an exponential number of isomorphic binary vectors for a given permutation group G. This provides evidence of the lack of symmetry breaking effectiveness of this fundamental domain. Conversely, a suitably constructed GDD for this G has linearly many inequalities and contains unique representatives for isomorphic binary vectors.},
  archive      = {J_MP},
  author       = {Verschae, José and Villagra, Matías and von Niederhäusern, Léonard},
  doi          = {10.1007/s10107-022-01819-2},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {693-719},
  shortjournal = {Math. Program.},
  title        = {On the geometry of symmetry breaking inequalities},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complexity, exactness, and rationality in polynomial
optimization. <em>MP</em>, <em>197</em>(2), 661–692. (<a
href="https://doi.org/10.1007/s10107-022-01818-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on rational solutions or nearly-feasible rational solutions that serve as certificates of feasibility for polynomial optimization problems. We show that, under some separability conditions, certain cubic polynomially constrained sets admit rational solutions. However, we show in other cases that it is NP Hard to detect if rational solutions exist or if they exist of any reasonable size. We extend this idea to various settings including near feasible, but super optimal solutions and detecting rational rays on which a cubic function is unbounded. Lastly, we show that in fixed dimension, the feasibility problem over a set defined by polynomial inequalities is in NP by providing a simple certificate to verify feasibility. We conclude with several related examples of irrationality and encoding size issues in QCQPs and SOCPs.},
  archive      = {J_MP},
  author       = {Bienstock, Daniel and Pia, Alberto Del and Hildebrand, Robert},
  doi          = {10.1007/s10107-022-01818-3},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {661-692},
  shortjournal = {Math. Program.},
  title        = {Complexity, exactness, and rationality in polynomial optimization},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sum-of-squares hierarchies for binary polynomial
optimization. <em>MP</em>, <em>197</em>(2), 621–660. (<a
href="https://doi.org/10.1007/s10107-021-01745-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the sum-of-squares hierarchy of approximations for the problem of minimizing a polynomial f over the boolean hypercube $${{\mathbb {B}}^{n}={0,1}^n}$$ . This hierarchy provides for each integer $$r \in {\mathbb {N}}$$ a lower bound $$\smash {f_{({r})}}$$ on the minimum $$f_{\min }$$ of f, given by the largest scalar $$\lambda $$ for which the polynomial $$f - \lambda $$ is a sum-of-squares on $${\mathbb {B}}^{n}$$ with degree at most 2r. We analyze the quality of these bounds by estimating the worst-case error $$f_{\min }- \smash {f_{({r})}}$$ in terms of the least roots of the Krawtchouk polynomials. As a consequence, for fixed $$t \in [0, 1/2]$$ , we can show that this worst-case error in the regime $$r \approx t \cdot n$$ is of the order $$1/2 - \sqrt{t(1-t)}$$ as n tends to $$\infty $$ . Our proof combines classical Fourier analysis on $${\mathbb {B}}^{n}$$ with the polynomial kernel technique and existing results on the extremal roots of Krawtchouk polynomials. This link to roots of orthogonal polynomials relies on a connection between the hierarchy of lower bounds $$\smash {f_{({r})}}$$ and another hierarchy of upper bounds $$\smash {f^{({r})}}$$ , for which we are also able to establish the same error analysis. Our analysis extends to the minimization of a polynomial over the q-ary cube $$\mathbb ({\mathbb {Z}}/ q{\mathbb {Z}})^{n}$$ . Furthermore, our results apply to the setting of matrix-valued polynomials.},
  archive      = {J_MP},
  author       = {Slot, Lucas and Laurent, Monique},
  doi          = {10.1007/s10107-021-01745-9},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {621-660},
  shortjournal = {Math. Program.},
  title        = {Sum-of-squares hierarchies for binary polynomial optimization},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifting convex inequalities for bipartite bilinear programs.
<em>MP</em>, <em>197</em>(2), 587–619. (<a
href="https://doi.org/10.1007/s10107-021-01759-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to derive new classes of valid convex inequalities for quadratically constrained quadratic programs (QCQPs) through the technique of lifting. Our first main result shows that, for sets described by one bipartite bilinear constraint together with bounds, it is always possible to sequentially lift a seed inequality that is valid for a restriction obtained by fixing variables to their bounds, when the lifting is accomplished using affine functions of the fixed variables. In this setting, sequential lifting involves solving a non-convex nonlinear optimization problem each time a variable is lifted, just as in Mixed Integer Linear Programming. To reduce the computational burden associated with this procedure, we develop a framework based on subadditive approximations of lifting functions that permits sequence-independent lifting of seed inequalities for separable bipartite bilinear sets. In particular, this framework permits the derivation of closed-form valid inequalities. We then study a separable bipartite bilinear set where the coefficients form a minimal cover with respect to the right-hand-side. For this set, we introduce a bilinear cover inequality, which is second-order cone representable. We argue that this bilinear cover inequality is strong by showing that it yields a constant-factor approximation of the convex hull of the original set. We study its lifting function and construct a two-slope subadditive upper bound. Using this subadditive approximation, we lift fixed variable pairs in closed-form, thus deriving a lifted bilinear cover inequality that is valid for general separable bipartite bilinear sets with box constraints.},
  archive      = {J_MP},
  author       = {Gu, Xiaoyi and Dey, Santanu S. and Richard, Jean-Philippe P.},
  doi          = {10.1007/s10107-021-01759-3},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {587-619},
  shortjournal = {Math. Program.},
  title        = {Lifting convex inequalities for bipartite bilinear programs},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the implementation and strengthening of intersection cuts
for QCQPs. <em>MP</em>, <em>197</em>(2), 549–586. (<a
href="https://doi.org/10.1007/s10107-022-01808-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of strong linear inequalities for QCQPs has been recently tackled by a number of authors using the intersection cut paradigm—a highly studied tool in integer programming whose flexibility has triggered these renewed efforts in non-linear settings. In this work, we consider intersection cuts using the recently proposed construction of maximal quadratic-free sets. Using these sets, we derive closed-form formulas to compute intersection cuts which allow for quick cut-computations by simply plugging-in parameters associated to an arbitrary quadratic inequality being violated by a vertex of an LP relaxation. Additionally, we implement a cut-strengthening procedure that dates back to Glover and evaluate these techniques with extensive computational experiments.},
  archive      = {J_MP},
  author       = {Chmiela, Antonia and Muñoz, Gonzalo and Serrano, Felipe},
  doi          = {10.1007/s10107-022-01808-5},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {549-586},
  shortjournal = {Math. Program.},
  title        = {On the implementation and strengthening of intersection cuts for QCQPs},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximating the discrete time-cost tradeoff problem with
bounded depth. <em>MP</em>, <em>197</em>(2), 529–547. (<a
href="https://doi.org/10.1007/s10107-022-01777-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the deadline version of the discrete time-cost tradeoff problem for the special case of bounded depth. Such instances occur for example in VLSI design. The depth of an instance is the number of jobs in a longest chain and is denoted by d. We prove new upper and lower bounds on the approximability. First we observe that the problem can be regarded as a special case of finding a minimum-weight vertex cover in a d-partite hypergraph. Next, we study the natural LP relaxation, which can be solved in polynomial time for fixed d and—for time-cost tradeoff instances—up to an arbitrarily small error in general. Improving on prior work of Lovász and of Aharoni, Holzman and Krivelevich, we describe a deterministic algorithm with approximation ratio slightly less than $$\frac{d}{2}$$ for minimum-weight vertex cover in d-partite hypergraphs for fixed d and given d-partition. This is tight and yields also a $$\frac{d}{2}$$ -approximation algorithm for general time-cost tradeoff instances, even if d is not fixed. We also study the inapproximability and show that no better approximation ratio than $$\frac{d+2}{4}$$ is possible, assuming the Unique Games Conjecture and $$\text {P}\ne \text {NP}$$ . This strengthens a result of Svensson [21], who showed that under the same assumptions no constant-factor approximation algorithm exists for general time-cost tradeoff instances (of unbounded depth). Previously, only APX-hardness was known for bounded depth.},
  archive      = {J_MP},
  author       = {Daboul, Siad and Held, Stephan and Vygen, Jens},
  doi          = {10.1007/s10107-022-01777-9},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {529-547},
  shortjournal = {Math. Program.},
  title        = {Approximating the discrete time-cost tradeoff problem with bounded depth},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online k-taxi via double coverage and time-reverse
primal-dual. <em>MP</em>, <em>197</em>(2), 499–527. (<a
href="https://doi.org/10.1007/s10107-022-01815-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the online k-taxi problem, a generalization of the k-server problem, in which k servers are located in a metric space. A sequence of requests is revealed one by one, where each request is a pair of two points, representing the start and destination of a travel request by a passenger. The goal is to serve all requests while minimizing the distance traveled without carrying a passenger. We show that the classic Double Coverage algorithm has competitive ratio $$2^k-1$$ on HSTs, matching a recent lower bound for deterministic algorithms. For bounded depth HSTs, the competitive ratio turns out to be much better and we obtain tight bounds. When the depth is $$d\ll k$$ , these bounds are approximately $$k^d/d!$$ . By standard embedding results, we obtain a randomized algorithm for arbitrary n-point metrics with (polynomial) competitive ratio $$O(k^c\Delta ^{1/c}\log _{\Delta } n)$$ , where $$\Delta $$ is the aspect ratio and $$c\ge 1$$ is an arbitrary positive integer constant. The previous known bound was $$O(2^k\log n)$$ . For general (weighted) tree metrics, we prove the competitive ratio of Double Coverage to be $$\Theta (k^d)$$ for any fixed depth d, and in contrast to HSTs it is not bounded by $$2^k-1$$ . We obtain our results by a dual fitting analysis where the dual solution is constructed step-by-step backwards in time. Unlike the forward-time approach typical of online primal-dual analyses, this allows us to combine information from both the past and the future when assigning dual variables. We believe this method can also be useful for other problems. Using this technique, we also provide a dual fitting proof of the k-competitiveness of Double Coverage for the k-server problem on trees.},
  archive      = {J_MP},
  author       = {Buchbinder, Niv and Coester, Christian and Naor, Joseph},
  doi          = {10.1007/s10107-022-01815-6},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {499-527},
  shortjournal = {Math. Program.},
  title        = {Online k-taxi via double coverage and time-reverse primal-dual},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving the approximation ratio for capacitated vehicle
routing. <em>MP</em>, <em>197</em>(2), 451–497. (<a
href="https://doi.org/10.1007/s10107-022-01841-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise a new approximation algorithm for capacitated vehicle routing. Our algorithm yields a better approximation ratio for general capacitated vehicle routing as well as for the unit-demand case and the splittable variant. Our results hold in arbitrary metric spaces. This is the first improvement upon the classical tour partitioning algorithm by Haimovich and Rinnooy Kan (Math Oper Res 10:527–542, 1985) and Altinkemer and Gavish (Oper Res Lett 6:149–158, 1987).},
  archive      = {J_MP},
  author       = {Blauth, Jannis and Traub, Vera and Vygen, Jens},
  doi          = {10.1007/s10107-022-01841-4},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {451-497},
  shortjournal = {Math. Program.},
  title        = {Improving the approximation ratio for capacitated vehicle routing},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue: Integer programming and combinatorial
optimization (IPCO) 2021. <em>MP</em>, <em>197</em>(2), 449–450. (<a
href="https://doi.org/10.1007/s10107-022-01892-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Dey, Santanu and Singh, Mohit and Williamson, David P.},
  doi          = {10.1007/s10107-022-01892-7},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {449-450},
  shortjournal = {Math. Program.},
  title        = {Special issue: Integer programming and combinatorial optimization (IPCO) 2021},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reformulation-linearization technique for optimization
over simplices. <em>MP</em>, <em>197</em>(1), 427–447. (<a
href="https://doi.org/10.1007/s10107-021-01726-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study non-convex optimization problems over simplices. We show that for a large class of objective functions, the convex approximation obtained from the Reformulation-Linearization Technique (RLT) admits optimal solutions that exhibit a sparsity pattern. This characteristic of the optimal solutions allows us to conclude that (i) a linear matrix inequality constraint, which is often added to tighten the relaxation, is vacuously satisfied and can thus be omitted, and (ii) the number of decision variables in the RLT relaxation can be reduced from $${\mathcal {O}} (n^2)$$ to $${\mathcal {O}} (n)$$ . Taken together, both observations allow us to reduce computation times by up to several orders of magnitude. Our results can be specialized to indefinite quadratic optimization problems over simplices and extended to non-convex optimization problems over the Cartesian product of two simplices as well as specific classes of polyhedral and non-convex feasible regions. Our numerical experiments illustrate the promising performance of the proposed framework.},
  archive      = {J_MP},
  author       = {Selvi, Aras and den Hertog, Dick and Wiesemann, Wolfram},
  doi          = {10.1007/s10107-021-01726-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {427-447},
  shortjournal = {Math. Program.},
  title        = {A reformulation-linearization technique for optimization over simplices},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-halfspace closure. <em>MP</em>, <em>197</em>(1),
411–426. (<a href="https://doi.org/10.1007/s10107-022-01802-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define a new cutting plane closure for pure integer programs called the two-halfspace closure. It is a natural generalization of the well-known Chvátal-Gomory closure. We prove that the two-halfspace closure is polyhedral. We also study the corresponding two-halfspace rank of any valid inequality and show that it is at most the split rank of the inequality. Moreover, while the split rank can be strictly larger than the two-halfspace rank, the split rank is at most twice the two-halfspace rank. A key step of our analysis shows that the split closure of a rational polyhedron can be obtained by considering the split closures of all k-dimensional (rational) projections of the polyhedron, for any fixed $$k \ge 2$$ . This result may be of independent interest.},
  archive      = {J_MP},
  author       = {Basu, Amitabh and Jiang, Hongyi},
  doi          = {10.1007/s10107-022-01802-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {411-426},
  shortjournal = {Math. Program.},
  title        = {Two-halfspace closure},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variance reduction for root-finding problems. <em>MP</em>,
<em>197</em>(1), 375–410. (<a
href="https://doi.org/10.1007/s10107-021-01758-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimizing finite sums of smooth and strongly convex functions is an important task in machine learning. Recent work has developed stochastic gradient methods that optimize these sums with less computation than methods that do not exploit the finite sum structure. This speedup results from using efficiently constructed stochastic gradient estimators, which have variance that diminishes as the algorithm progresses. In this work, we ask whether the benefits of variance reduction extend to fixed point and root-finding problems involving sums of nonlinear operators. Our main result shows that variance reduction offers a similar speedup when applied to a broad class of root-finding problems. We illustrate the result on three tasks involving sums of n nonlinear operators: averaged fixed point, monotone inclusions, and nonsmooth common minimizer problems. In certain “poorly conditioned regimes,” the proposed method offers an n-fold speedup over standard methods.},
  archive      = {J_MP},
  author       = {Davis, Damek},
  doi          = {10.1007/s10107-021-01758-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {375-410},
  shortjournal = {Math. Program.},
  title        = {Variance reduction for root-finding problems},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the robustness of potential-based flow networks.
<em>MP</em>, <em>197</em>(1), 337–374. (<a
href="https://doi.org/10.1007/s10107-021-01760-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Potential-based flows provide a simple yet realistic mathematical model of transport in many real-world infrastructure networks such as, e.g., gas or water networks, where the flow along each edge depends on the difference of the potentials at its end nodes. We call a network topology robust if the maximal node potential needed to satisfy a set of demands never increases when demands are decreased. This notion of robustness is motivated by infrastructure networks where users first make reservations for certain demands that may be larger than the actual flows sent later on. In these networks, node potentials correspond to physical quantities such as pressures or hydraulic heads and must be guaranteed to lie within a fixed range, even if the actual amounts are smaller than the previously reserved demands. Our main results are a precise characterization of robust network topologies for the case of point-to-point demands via forbidden node-labeled graph minors, as well as an efficient algorithm for testing robustness.},
  archive      = {J_MP},
  author       = {Klimm, Max and Pfetsch, Marc E. and Raber, Rico and Skutella, Martin},
  doi          = {10.1007/s10107-021-01760-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {337-374},
  shortjournal = {Math. Program.},
  title        = {On the robustness of potential-based flow networks},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Box-total dual integrality and edge-connectivity.
<em>MP</em>, <em>197</em>(1), 307–336. (<a
href="https://doi.org/10.1007/s10107-021-01743-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph $$G=(V,E)$$ and an integer $$k\ge 1$$ , the graph $$H=(V,F)$$ , where F is a family of elements (with repetitions allowed) of E, is a k-edge-connected spanning subgraph of G if H cannot be disconnected by deleting any $$k-1$$ elements of F. The convex hull of incidence vectors of the k-edge-connected subgraphs of a graph G forms the k-edge-connected subgraph polyhedron of G. We prove that this polyhedron is box-totally dual integral if and only if G is series–parallel. In this case, we also provide an integer box-totally dual integral system describing this polyhedron.},
  archive      = {J_MP},
  author       = {Barbato, Michele and Grappe, Roland and Lacroix, Mathieu and Lancini, Emiliano},
  doi          = {10.1007/s10107-021-01743-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {307-336},
  shortjournal = {Math. Program.},
  title        = {Box-total dual integrality and edge-connectivity},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strengthened SDP relaxation for an extended trust region
subproblem with an application to optimal power flow. <em>MP</em>,
<em>197</em>(1), 281–306. (<a
href="https://doi.org/10.1007/s10107-021-01737-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an extended trust region subproblem minimizing a nonconvex function over the hollow ball $$r \le \Vert x\Vert \le R$$ intersected with a full-dimensional second order cone (SOC) constraint of the form $$\Vert x - c\Vert \le b^T x - a$$ . In particular, we present a class of valid cuts that improve existing semidefinite programming (SDP) relaxations and are separable in polynomial time. We connect our cuts to the literature on the optimal power flow (OPF) problem by demonstrating that previously derived cuts capturing a convex hull important for OPF are actually just special cases of our cuts. In addition, we apply our methodology to derive a new class of closed-form, locally valid, SOC cuts for nonconvex quadratic programs over the mixed polyhedral-conic set $${x \ge 0 : \Vert x \Vert \le 1 }$$ . Finally, we show computationally on randomly generated instances that our cuts are effective in further closing the gap of the strongest SDP relaxations in the literature, especially in low dimensions.},
  archive      = {J_MP},
  author       = {Eltved, Anders and Burer, Samuel},
  doi          = {10.1007/s10107-021-01737-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {281-306},
  shortjournal = {Math. Program.},
  title        = {Strengthened SDP relaxation for an extended trust region subproblem with an application to optimal power flow},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic first-order methods for convex and nonconvex
functional constrained optimization. <em>MP</em>, <em>197</em>(1),
215–279. (<a href="https://doi.org/10.1007/s10107-021-01742-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional constrained optimization is becoming more and more important in machine learning and operations research. Such problems have potential applications in risk-averse machine learning, semisupervised learning and robust optimization among others. In this paper, we first present a novel Constraint Extrapolation (ConEx) method for solving convex functional constrained problems, which utilizes linear approximations of the constraint functions to define the extrapolation (or acceleration) step. We show that this method is a unified algorithm that achieves the best-known rate of convergence for solving different functional constrained convex composite problems, including convex or strongly convex, and smooth or nonsmooth problems with stochastic objective and/or stochastic constraints. Many of these rates of convergence were in fact obtained for the first time in the literature. In addition, ConEx is a single-loop algorithm that does not involve any penalty subproblems. Contrary to existing primal-dual methods, it does not require the projection of Lagrangian multipliers into a (possibly unknown) bounded set. Second, for nonconvex functional constrained problems, we introduce a new proximal point method which transforms the initial nonconvex problem into a sequence of convex problems by adding quadratic terms to both the objective and constraints. Under certain MFCQ-type assumption, we establish the convergence and rate of convergence of this method to KKT points when the convex subproblems are solved exactly or inexactly. For large-scale and stochastic problems, we present a more practical proximal point method in which the approximate solutions of the subproblems are computed by the aforementioned ConEx method. Under a strong feasibility assumption, we establish the total iteration complexity of ConEx required by this inexact proximal point method for a variety of problem settings, including nonconvex smooth or nonsmooth problems with stochastic objective and/or stochastic constraints. To the best of our knowledge, most of these convergence and complexity results of the proximal point method for nonconvex problems also seem to be new in the literature.},
  archive      = {J_MP},
  author       = {Boob, Digvijay and Deng, Qi and Lan, Guanghui},
  doi          = {10.1007/s10107-021-01742-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {215-279},
  shortjournal = {Math. Program.},
  title        = {Stochastic first-order methods for convex and nonconvex functional constrained optimization},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting the approximate carathéodory problem via the
frank-wolfe algorithm. <em>MP</em>, <em>197</em>(1), 191–214. (<a
href="https://doi.org/10.1007/s10107-021-01735-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The approximate Carathéodory theorem states that given a compact convex set $${\mathcal {C}}\subset {\mathbb {R}}^n$$ and $$p\in [2,+\infty [$$ , each point $$x^*\in {\mathcal {C}}$$ can be approximated to $$\epsilon $$ -accuracy in the $$\ell _p$$ -norm as the convex combination of $${\mathcal {O}}(pD_p^2/\epsilon ^2)$$ vertices of $${\mathcal {C}}$$ , where $$D_p$$ is the diameter of $${\mathcal {C}}$$ in the $$\ell _p$$ -norm. A solution satisfying these properties can be built using probabilistic arguments or by applying mirror descent to the dual problem. We revisit the approximate Carathéodory problem by solving the primal problem via the Frank-Wolfe algorithm, providing a simplified analysis and leading to an efficient practical method. Furthermore, improved cardinality bounds are derived naturally using existing convergence rates of the Frank-Wolfe algorithm in different scenarios, when $$x^*$$ is in the interior of $${\mathcal {C}}$$ , when $$x^*$$ is the convex combination of a subset of vertices with small diameter, or when $${\mathcal {C}}$$ is uniformly convex. We also propose cardinality bounds when $$p\in [1,2[\cup {+\infty }$$ via a nonsmooth variant of the algorithm. Lastly, we address the problem of finding sparse approximate projections onto $${\mathcal {C}}$$ in the $$\ell _p$$ -norm, $$p\in [1,+\infty ]$$ .},
  archive      = {J_MP},
  author       = {Combettes, Cyrille W. and Pokutta, Sebastian},
  doi          = {10.1007/s10107-021-01735-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {191-214},
  shortjournal = {Math. Program.},
  title        = {Revisiting the approximate carathéodory problem via the frank-wolfe algorithm},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binary optimal control by trust-region steepest descent.
<em>MP</em>, <em>197</em>(1), 147–190. (<a
href="https://doi.org/10.1007/s10107-021-01733-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a trust-region steepest descent method for dynamic optimal control problems with binary-valued integrable control functions. Our method interprets the control function as an indicator function of a measurable set and makes set-valued adjustments derived from the sublevel sets of a topological gradient function. By combining this type of update with a trust-region framework, we are able to show by theoretical argument that our method achieves asymptotic stationarity despite possible discretization errors and truncation errors during step determination. To demonstrate the practical applicability of our method, we solve two optimal control problems constrained by ordinary and partial differential equations, respectively, and one topological optimization problem.},
  archive      = {J_MP},
  author       = {Hahn, Mirko and Leyffer, Sven and Sager, Sebastian},
  doi          = {10.1007/s10107-021-01733-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {147-190},
  shortjournal = {Math. Program.},
  title        = {Binary optimal control by trust-region steepest descent},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterizing the universal rigidity of generic
tensegrities. <em>MP</em>, <em>197</em>(1), 109–145. (<a
href="https://doi.org/10.1007/s10107-021-01730-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tensegrity is a structure made from cables, struts, and stiff bars. A d-dimensional tensegrity is universally rigid if it is rigid in any dimension $$d&#39;$$ with $$d&#39;\ge d$$ . The celebrated super stability condition due to Connelly gives a sufficient condition for a tensegrity to be universally rigid. Gortler and Thurston showed that super stability characterizes universal rigidity when the point configuration is generic and every member is a stiff bar. We extend this result in two directions. We first show that a generic universally rigid tensegrity is super stable. We then extend it to tensegrities with point group symmetry, and show that this characterization still holds as long as a tensegrity is generic modulo symmetry. Our strategy is based on the block-diagonalization technique for symmetric semidefinite programming problems, and our proof relies on the theory of real irreducible representations of finite groups.},
  archive      = {J_MP},
  author       = {Oba, Ryoshun and Tanigawa, Shin-ichi},
  doi          = {10.1007/s10107-021-01730-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {109-145},
  shortjournal = {Math. Program.},
  title        = {Characterizing the universal rigidity of generic tensegrities},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sum-of-squares chordal decomposition of polynomial matrix
inequalities. <em>MP</em>, <em>197</em>(1), 71–108. (<a
href="https://doi.org/10.1007/s10107-021-01728-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove decomposition theorems for sparse positive (semi)definite polynomial matrices that can be viewed as sparsity-exploiting versions of the Hilbert–Artin, Reznick, Putinar, and Putinar–Vasilescu Positivstellensätze. First, we establish that a polynomial matrix P(x) with chordal sparsity is positive semidefinite for all $$x\in \mathbb {R}^n$$ if and only if there exists a sum-of-squares (SOS) polynomial $$\sigma (x)$$ such that $$\sigma P$$ is a sum of sparse SOS matrices. Second, we show that setting $$\sigma (x)=(x_1^2 + \cdots + x_n^2)^\nu $$ for some integer $$\nu $$ suffices if P is homogeneous and positive definite globally. Third, we prove that if P is positive definite on a compact semialgebraic set $$\mathcal {K}={x:g_1(x)\ge 0,\ldots ,g_m(x)\ge 0}$$ satisfying the Archimedean condition, then $$P(x) = S_0(x) + g_1(x)S_1(x) + \cdots + g_m(x)S_m(x)$$ for matrices $$S_i(x)$$ that are sums of sparse SOS matrices. Finally, if $$\mathcal {K}$$ is not compact or does not satisfy the Archimedean condition, we obtain a similar decomposition for $$(x_1^2 + \cdots + x_n^2)^\nu P(x)$$ with some integer $$\nu \ge 0$$ when P and $$g_1,\ldots ,g_m$$ are homogeneous of even degree. Using these results, we find sparse SOS representation theorems for polynomials that are quadratic and correlatively sparse in a subset of variables, and we construct new convergent hierarchies of sparsity-exploiting SOS reformulations for convex optimization problems with large and sparse polynomial matrix inequalities. Numerical examples demonstrate that these hierarchies can have a significantly lower computational complexity than traditional ones.},
  archive      = {J_MP},
  author       = {Zheng, Yang and Fantuzzi, Giovanni},
  doi          = {10.1007/s10107-021-01728-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {71-108},
  shortjournal = {Math. Program.},
  title        = {Sum-of-squares chordal decomposition of polynomial matrix inequalities},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multicriteria cuts and size-constrained k-cuts in
hypergraphs. <em>MP</em>, <em>197</em>(1), 27–69. (<a
href="https://doi.org/10.1007/s10107-021-01732-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address counting and optimization variants of multicriteria global min-cut and size-constrained min-k-cut in hypergraphs. All of our results build on the random contraction approach of Karger (Proceedings of the 4th annual ACM-SIAM symposium on discrete algorithms, SODA, pp 21–30, 1993). Our techniques illustrate the versatility of the random contraction approach to address counting and algorithmic problems concerning multiobjective min-cuts and size-constrained k-cuts in hypergraphs.},
  archive      = {J_MP},
  author       = {Beideman, Calvin and Chandrasekaran, Karthekeyan and Xu, Chao},
  doi          = {10.1007/s10107-021-01732-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {27-69},
  shortjournal = {Math. Program.},
  title        = {Multicriteria cuts and size-constrained k-cuts in hypergraphs},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inexact accelerated high-order proximal-point methods.
<em>MP</em>, <em>197</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s10107-021-01727-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new framework of bi-level unconstrained minimization for development of accelerated methods in Convex Programming. These methods use approximations of the high-order proximal points, which are solutions of some auxiliary parametric optimization problems. For computing these points, we can use different methods, and, in particular, the lower-order schemes. This opens a possibility for the latter methods to overpass traditional limits of the Complexity Theory. As an example, we obtain a new second-order method with the convergence rate $$O\left( k^{-4}\right) $$ , where k is the iteration counter. This rate is better than the maximal possible rate of convergence for this type of methods, as applied to functions with Lipschitz continuous Hessian. We also present new methods with the exact auxiliary search procedure, which have the rate of convergence $$O\left( k^{-(3p+1)/ 2}\right) $$ , where $$p \ge 1$$ is the order of the proximal operator. The auxiliary problem at each iteration of these schemes is convex.},
  archive      = {J_MP},
  author       = {Nesterov, Yurii},
  doi          = {10.1007/s10107-021-01727-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Math. Program.},
  title        = {Inexact accelerated high-order proximal-point methods},
  volume       = {197},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
