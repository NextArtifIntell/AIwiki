<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="si---12">SI - 12</h2>
<ul>
<li><details>
<summary>
(2023). Elitist artificial bee colony with dynamic population size
for multimodal optimization problems. <em>SI</em>, <em>17</em>(4),
305–334. (<a href="https://doi.org/10.1007/s11721-023-00228-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world problems can be formulated as a multimodal optimization problem (MMOP), and metaheuristic algorithms used in solving MMOP have to find multiple optimal points simultaneously. The key requirement for dealing with such problems is to balance exploration capability in global space and exploitation in multiple optimal spaces. Artificial bee colony (ABC), a metaheuristic algorithm, is designed to find only a single global optimum and cannot solve the MMOP. In this paper, we propose an ABC variant named “Elitist ABC with Dynamic Population Size” to cope with multimodal optimization problems. It has a dynamic population size strategy and uses a search equation selection strategy powered by elite members. The dynamic population size strategy enhances the exploration capability of the algorithm. The search equation selection strategy determines the appropriate search behavior for a particular problem instance at runtime. Thus, exploitation and exploration behaviors can be adjusted adaptively. In addition, candidate optimum peaks, that are overlooked in the original ABC algorithm, are memorized with elite population members. The proposed algorithm has been tested on multimodal optimization problems presented at CEC 2013. The algorithm has been compared with ten state-of-the-art multimodal optimization algorithms and the top 25 algorithms participating in the CEC competition on multimodal function optimization between 2013 and 2020. Experimental results have shown that the proposed algorithm is superior to many new algorithms and can compete with top-level algorithms.},
  archive      = {J_SI},
  author       = {Aydın, Doğan and Özcan, Yunus and Sulaiman, Muhammad and Yavuz, Gürcan and Halim, Zahid},
  doi          = {10.1007/s11721-023-00228-1},
  journal      = {Swarm Intelligence},
  number       = {4},
  pages        = {305-334},
  shortjournal = {Swarm Intell.},
  title        = {Elitist artificial bee colony with dynamic population size for multimodal optimization problems},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Consensus decision-making in artificial swarms via
entropy-based local negotiation and preference updating. <em>SI</em>,
<em>17</em>(4), 283–303. (<a
href="https://doi.org/10.1007/s11721-023-00226-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an entropy-based consensus algorithm for a swarm of artificial agents with limited sensing, communication, and processing capabilities. Each agent is modeled as a probabilistic finite state machine with a preference for a finite number of options defined as a probability distribution. The most preferred option, called exhibited decision, determines the agent’s state. The state transition is governed by internally updating this preference based on the states of neighboring agents and their entropy-based levels of certainty. Swarm agents continuously update their preferences by exchanging the exhibited decisions and the certainty values among the locally connected neighbors, leading to consensus towards an agreed-upon decision. The presented method is evaluated for its scalability over the swarm size and the number of options and its reliability under different conditions. Adopting classical best-of-N target selection scenarios, the algorithm is compared with three existing methods, the majority rule, frequency-based method, and k-unanimity method. The evaluation results show that the entropy-based method is reliable and efficient in these consensus problems.},
  archive      = {J_SI},
  author       = {Zheng, Chuanqi and Lee, Kiju},
  doi          = {10.1007/s11721-023-00226-3},
  journal      = {Swarm Intelligence},
  number       = {4},
  pages        = {283-303},
  shortjournal = {Swarm Intell.},
  title        = {Consensus decision-making in artificial swarms via entropy-based local negotiation and preference updating},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effect of swarm density on collective tracking performance.
<em>SI</em>, <em>17</em>(3), 253–281. (<a
href="https://doi.org/10.1007/s11721-023-00225-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How does the size of a swarm affect its collective action? Despite being arguably a key parameter, no systematic and satisfactory guiding principles exist to select the number of units required for a given task and environment. Even when limited by practical considerations, system designers should endeavor to identify what a reasonable swarm size should be. Here, we show that this fundamental question is closely linked to that of selecting an appropriate swarm density. Our analysis of the influence of density on the collective performance of a target tracking task reveals different ‘phases’ corresponding to markedly distinct group dynamics. We identify a ‘transition’ phase, in which a complex emergent collective response arises. Interestingly, the collective dynamics within this transition phase exhibit a clear trade-off between exploratory actions and exploitative ones. We show that at any density, the exploration–exploitation balance can be adjusted to maximize the system’s performance through various means, such as by changing the level of connectivity between agents. While the density is the primary factor to be considered, it should not be the sole one to be accounted for when sizing the system. Due to the inherent finite-size effects present in physical systems, we establish that the number of constituents primarily affects system-level properties such as exploitation in the transition phase. These results illustrate that instead of learning and optimizing a swarm’s behavior for a specific set of task parameters, further work should instead concentrate on learning to be adaptive, thereby endowing the swarm with the highly desirable feature of being able to operate effectively over a wide range of circumstances.},
  archive      = {J_SI},
  author       = {Kwa, Hian Lee and Philippot, Julien and Bouffanais, Roland},
  doi          = {10.1007/s11721-023-00225-4},
  journal      = {Swarm Intelligence},
  number       = {3},
  pages        = {253-281},
  shortjournal = {Swarm Intell.},
  title        = {Effect of swarm density on collective tracking performance},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent bandit with agent-dependent expected rewards.
<em>SI</em>, <em>17</em>(3), 219–251. (<a
href="https://doi.org/10.1007/s11721-023-00224-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies on the exploration policies for stochastic multi-agent bandit (MAB) problems demonstrate that integrating the experience of other group members accelerates the learning of optimal actions. However, the basic assumption of the classical MAB problem that the expected rewards are agent-independent is invalid in many real-world problems. The group members have different expected rewards for the possible actions, perhaps due to the different initial states or local environments. To solve the MAB problem with agent-dependent expected rewards, we develop a decentralized exploration policy in which agents apply confidence-weighting to integrate the experience of other group members and to estimate the expected rewards. Theoretical analysis demonstrates that the acceleration of learning still works in the agent-dependent case, and numerical simulation results verify that the proposed exploration policy outperforms the state-of-the-art method.},
  archive      = {J_SI},
  author       = {Jiang, Fan and Cheng, Hui},
  doi          = {10.1007/s11721-023-00224-5},
  journal      = {Swarm Intelligence},
  number       = {3},
  pages        = {219-251},
  shortjournal = {Swarm Intell.},
  title        = {Multi-agent bandit with agent-dependent expected rewards},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Out-of-the-box parameter control for evolutionary and
swarm-based algorithms with distributed reinforcement learning.
<em>SI</em>, <em>17</em>(3), 173–217. (<a
href="https://doi.org/10.1007/s11721-022-00222-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter control methods for metaheuristics with reinforcement learning put forward so far usually present the following shortcomings: (1) Their training processes are usually highly time-consuming and they are not able to benefit from parallel or distributed platforms; (2) they are usually sensitive to their hyperparameters, which means that the quality of the final results is heavily dependent on their values; (3) and limited benchmarks have been used to assess their generality. This paper addresses these issues by proposing a methodology for training out-of-the-box parameter control policies for mono-objective non-niching evolutionary and swarm-based algorithms using distributed reinforcement learning with population-based training. The proposed methodology is suitable to be used in any mono-objective optimization problem and for any mono-objective and non-niching Evolutionary and swarm-based algorithm. The results in this paper achieved through extensive experiments show that the proposed method satisfactorily improves all the aforementioned issues, overcoming constant, random and human-designed policies in several different scenarios.},
  archive      = {J_SI},
  author       = {de Lacerda, Marcelo Gomes Pereira and de Lima Neto, Fernando Buarque and Ludermir, Teresa Bernarda and Kuchen, Herbert},
  doi          = {10.1007/s11721-022-00222-z},
  journal      = {Swarm Intelligence},
  number       = {3},
  pages        = {173-217},
  shortjournal = {Swarm Intell.},
  title        = {Out-of-the-box parameter control for evolutionary and swarm-based algorithms with distributed reinforcement learning},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Three-dimensional relative localization and synchronized
movement with wireless ranging. <em>SI</em>, <em>17</em>(1), 147–172.
(<a href="https://doi.org/10.1007/s11721-022-00221-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relative localization is a key capability for autonomous robot swarms, and it is a substantial challenge, especially for small flying robots, as they are extremely restricted in terms of sensors and processing while other robots may be located anywhere around them in three-dimensional space. In this article, we generalize wireless ranging-based relative localization to three dimensions. In particular, we show that robots can localize others in three dimensions by ranging to each other and only exchanging body velocities and yaw rates. We perform a nonlinear observability analysis, investigating the observability of relative locations for different cases. Furthermore, we show both in simulation and with real-world experiments that the proposed method can be used for successfully achieving various swarm behaviours. In order to demonstrate the method’s generality, we demonstrate it both on tiny quadrotors and lightweight flapping wing robots.},
  archive      = {J_SI},
  author       = {Pfeiffer, Sven and Munaro, Veronica and Li, Shushuai and Rizzo, Alessandro and de Croon, Guido C. H. E.},
  doi          = {10.1007/s11721-022-00221-0},
  journal      = {Swarm Intelligence},
  number       = {1},
  pages        = {147-172},
  shortjournal = {Swarm Intell.},
  title        = {Three-dimensional relative localization and synchronized movement with wireless ranging},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collective gradient perception with a flying robot swarm.
<em>SI</em>, <em>17</em>(1), 117–146. (<a
href="https://doi.org/10.1007/s11721-022-00220-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of collective and emergent sensing with a flying robot swarm in which social interactions among individuals lead to following the gradient of a scalar field in the environment without the need of any gradient sensing capability. We proposed two methods—desired distance modulation and speed modulation—with and without alignment control. In the former, individuals modulate their desired distance to their neighbors and in the latter, they modulate their speed depending on the social interactions with their neighbors and measurements from the environment. Methods are systematically tested using two metrics with different scalar field models, swarm sizes and swarm densities. Experiments are conducted using: (1) a kinematic simulator, (2) a physics-based simulator, and (3) real nano-drone swarm. Results show that using the proposed methods, a swarm—composed of individuals lacking gradient sensing ability—is able to follow the gradient in a scalar field successfully. Results show that when individuals modulate their desired distances, alignment control is not needed but it still increases the performance. However, when individuals modulate their speed, alignment control is needed for collective motion. Real nano-drone experiments reveal that the proposed methods are applicable in real-life scenarios.},
  archive      = {J_SI},
  author       = {Karagüzel, Tugay Alperen and Turgut, Ali Emre and Eiben, A. E. and Ferrante, Eliseo},
  doi          = {10.1007/s11721-022-00220-1},
  journal      = {Swarm Intelligence},
  number       = {1},
  pages        = {117-146},
  shortjournal = {Swarm Intell.},
  title        = {Collective gradient perception with a flying robot swarm},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wildfire detection in large-scale environments using
force-based control for swarms of UAVs. <em>SI</em>, <em>17</em>(1),
89–115. (<a href="https://doi.org/10.1007/s11721-022-00218-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wildfires affect countries worldwide as global warming increases the probability of their appearance. Monitoring vast areas of forests can be challenging due to the lack of resources and information. Additionally, early detection of wildfires can be beneficial for their mitigation. To this end, we explore in simulation the use of swarms of uncrewed aerial vehicles (UAVs) with long autonomy that can cover large areas the size of California to detect early stage wildfires. Four decentralised control algorithms are tested: (1) random walking, (2) dispersion, (3) pheromone avoidance and (4) dynamic space partition. The first three adaptations are known from literature, whereas the last one is newly developed. The algorithms are tested with swarms of different sizes to test the spatial coverage of the system in 24 h of simulation time. Best results are achieved using a version of the dynamic space partition algorithm (DSP) which can detect 82\% of the fires using only 20 UAVs. When the swarm consists of 40 or more aircraft 100\% coverage can also be achieved. Further tests of DSP show robustness when agents fail and when new fires are generated in the area.},
  archive      = {J_SI},
  author       = {Tzoumas, Georgios and Pitonakova, Lenka and Salinas, Lucio and Scales, Charles and Richardson, Thomas and Hauert, Sabine},
  doi          = {10.1007/s11721-022-00218-9},
  journal      = {Swarm Intelligence},
  number       = {1},
  pages        = {89-115},
  shortjournal = {Swarm Intell.},
  title        = {Wildfire detection in large-scale environments using force-based control for swarms of UAVs},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drone flocking optimization using NSGA-II and principal
component analysis. <em>SI</em>, <em>17</em>(1), 63–87. (<a
href="https://doi.org/10.1007/s11721-022-00216-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individual agents in natural systems like flocks of birds or schools of fish display a remarkable ability to coordinate and communicate in local groups and execute a variety of tasks efficiently. Emulating such natural systems into drone swarms to solve problems in defense, agriculture, industrial automation, and humanitarian relief is an emerging technology. However, flocking of aerial robots while maintaining multiple objectives, like collision avoidance, high speed etc., is still a challenge. This paper proposes optimized flocking of drones in a confined environment with multiple conflicting objectives. The considered objectives are collision avoidance (with each other and the wall), speed, correlation, and communication (connected and disconnected agents). Principal Component Analysis (PCA) is applied for dimensionality reduction and understanding of the collective dynamics of the swarm. The control model is characterized by 12 parameters which are then optimized using a multi-objective solver (NSGA-II). The obtained results are reported and compared with that of the CMA-ES algorithm. The study is particularly useful as the proposed optimizer outputs a Pareto Front representing different types of swarms that can be applied to different scenarios in the real world.},
  archive      = {J_SI},
  author       = {Bansal, Jagdish Chand and Sethi, Nikhil and Anicho, Ogbonnaya and Nagar, Atulya},
  doi          = {10.1007/s11721-022-00216-x},
  journal      = {Swarm Intelligence},
  number       = {1},
  pages        = {63-87},
  shortjournal = {Swarm Intell.},
  title        = {Drone flocking optimization using NSGA-II and principal component analysis},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A field-based computing approach to sensing-driven
clustering in robot swarms. <em>SI</em>, <em>17</em>(1), 27–62. (<a
href="https://doi.org/10.1007/s11721-022-00215-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm intelligence leverages collective behaviours emerging from interaction and activity of several “simple” agents to solve problems in various environments. One problem of interest in large swarms featuring a variety of sub-goals is swarm clustering, where the individuals of a swarm are assigned or choose to belong to zero or more groups, also called clusters. In this work, we address the sensing-based swarm clustering problem, where clusters are defined based on both the values sensed from the environment and the spatial distribution of the values and the agents. Moreover, we address it in a setting characterised by decentralisation of computation and interaction, and dynamicity of values and mobility of agents. For the solution, we propose to use the field-based computing paradigm, where computation and interaction are expressed in terms of a functional manipulation of fields, distributed and evolving data structures mapping each individual of the system to values over time. We devise a solution to sensing-based swarm clustering leveraging multiple concurrent field computations with limited domain and evaluate the approach experimentally by means of simulations, showing that the programmed swarms form clusters that well reflect the underlying environmental phenomena dynamics.},
  archive      = {J_SI},
  author       = {Aguzzi, Gianluca and Audrito, Giorgio and Casadei, Roberto and Damiani, Ferruccio and Torta, Gianluca and Viroli, Mirko},
  doi          = {10.1007/s11721-022-00215-y},
  journal      = {Swarm Intelligence},
  number       = {1},
  pages        = {27-62},
  shortjournal = {Swarm Intell.},
  title        = {A field-based computing approach to sensing-driven clustering in robot swarms},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Noise-resistant and scalable collective preference learning
via ranked voting in swarm robotics. <em>SI</em>, <em>17</em>(1), 5–26.
(<a href="https://doi.org/10.1007/s11721-022-00214-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm robotics studies how to use large groups of cooperating robots to perform designated tasks. Given the need for scalability, individual members of the swarm usually have only limited sensory capabilities, which can be unreliable in noisy situations. One way to address this shortcoming is via collective decision-making, and utilizing peer-to-peer local interactions to enhance the behavioral performances of the whole swarm of intelligent agents. In this paper, we address a collective preference learning scenario, where agents seek to rank a series of given sites according to a preference order. We have proposed and tested a novel ranked voting-based strategy to perform the designated task. We use two variants of a belief fusion-based strategy as benchmarks. We compare the considered algorithms in terms of accuracy and precision of decisions as well as the convergence time. We have tested the considered algorithms in various noise levels, evidence rates, and swarm sizes. We have concluded that the proposed ranked voting approach is significantly cheaper and more accurate, at the cost of less precision and longer convergence time. It is especially advantageous compared to the benchmark when facing high noise or large swarm size.},
  archive      = {J_SI},
  author       = {Shan, Qihao and Mostaghim, Sanaz},
  doi          = {10.1007/s11721-022-00214-z},
  journal      = {Swarm Intelligence},
  number       = {1},
  pages        = {5-26},
  shortjournal = {Swarm Intell.},
  title        = {Noise-resistant and scalable collective preference learning via ranked voting in swarm robotics},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-disciplinary approaches for designing intelligent
swarms of drones. <em>SI</em>, <em>17</em>(1), 1–4. (<a
href="https://doi.org/10.1007/s11721-023-00223-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SI},
  author       = {de Croon, G. C. H. E. and Hönig, W. and Theraulaz, G. and Vásárhelyi, G.},
  doi          = {10.1007/s11721-023-00223-6},
  journal      = {Swarm Intelligence},
  number       = {1},
  pages        = {1-4},
  shortjournal = {Swarm Intell.},
  title        = {Cross-disciplinary approaches for designing intelligent swarms of drones},
  volume       = {17},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
