<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>BCYB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="bcyb---30">BCYB - 30</h2>
<ul>
<li><details>
<summary>
(2023). Multistability in neural systems with random
cross-connections. <em>BCYB</em>, <em>117</em>(6), 485–506. (<a
href="https://doi.org/10.1007/s00422-023-00981-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural circuits with multiple discrete attractor states could support a variety of cognitive tasks according to both empirical data and model simulations. We assess the conditions for such multistability in neural systems using a firing rate model framework, in which clusters of similarly responsive neurons are represented as single units, which interact with each other through independent random connections. We explore the range of conditions in which multistability arises via recurrent input from other units while individual units, typically with some degree of self-excitation, lack sufficient self-excitation to become bistable on their own. We find many cases of multistability—defined as the system possessing more than one stable fixed point—in which stable states arise via a network effect, allowing subsets of units to maintain each others&#39; activity because their net input to each other when active is sufficiently positive. In terms of the strength of within-unit self-excitation and standard deviation of random cross-connections, the region of multistability depends on the response function of units. Indeed, multistability can arise with zero self-excitation, purely through zero-mean random cross-connections, if the response function rises supralinearly at low inputs from a value near zero at zero input. We simulate and analyze finite systems, showing that the probability of multistability can peak at intermediate system size, and connect with other literature analyzing similar systems in the infinite-size limit. We find regions of multistability with a bimodal distribution for the number of active units in a stable state. Finally, we find evidence for a log-normal distribution of sizes of attractor basins, which produces Zipf’s Law when enumerating the proportion of trials within which random initial conditions lead to a particular stable state of the system.},
  archive      = {J_BCYB},
  author       = {Breffle, Jordan and Mokashe, Subhadra and Qiu, Siwei and Miller, Paul},
  doi          = {10.1007/s00422-023-00981-w},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {6},
  pages        = {485-506},
  shortjournal = {Biol. Cybern.},
  title        = {Multistability in neural systems with random cross-connections},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy optimisation predicts the capacity of ion buffering
in the brain. <em>BCYB</em>, <em>117</em>(6), 467–484. (<a
href="https://doi.org/10.1007/s00422-023-00980-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurons store energy in the ionic concentration gradients they build across their cell membrane. The amount of energy stored, and hence the work the ions can do by mixing, can be enhanced by the presence of ion buffers in extra- and intracellular space. Buffers act as sources and sinks of ions, however, and unless the buffering capacities for different ion species obey certain relationships, a complete mixing of the ions may be impeded by the physical conditions of charge neutrality and isotonicity. From these conditions, buffering capacities were calculated that enabled each ion species to mix completely. In all valid buffer distributions, the $$\hbox {Ca}^{2+}$$ ions were buffered most, with a capacity exceeding that of $$\hbox {Na}^+$$ and $$\hbox {K}^+$$ buffering by at least an order of magnitude. The similar magnitude of the (oppositely directed) $$\hbox {Na}^+$$ and $$\hbox {K}^+$$ gradients made extracellular space behave as a $$\hbox {Na}^+$$ – $$\hbox {K}^+$$ exchanger. Anions such as $$\hbox {Cl}^-$$ were buffered least. The great capacity of the extra- and intracellular $$\hbox {Ca}^{2+}$$ buffers caused a large influx of $$\hbox {Ca}^{2+}$$ ions as is typically observed during energy deprivation. These results explain many characteristics of the physiological buffer distributions but raise the question how the brain controls the capacity of its ion buffers. It is suggested that neurons and glial cells, by their great sensitivity to gradients of charge and osmolarity, respectively, sense deviations from electro-neutral and isotonic mixing, and use these signals to tune the chemical composition, and buffering capacity, of the extra- and intracellular matrices.},
  archive      = {J_BCYB},
  author       = {Maex, Reinoud},
  doi          = {10.1007/s00422-023-00980-x},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {6},
  pages        = {467-484},
  shortjournal = {Biol. Cybern.},
  title        = {Energy optimisation predicts the capacity of ion buffering in the brain},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Face detection based on a human attention guided multi-scale
model. <em>BCYB</em>, <em>117</em>(6), 453–466. (<a
href="https://doi.org/10.1007/s00422-023-00978-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiscale models are among the cutting-edge technologies used for face detection and recognition. An example is Deformable part-based models (DPMs), which encode a face as a multiplicity of local areas (parts) at different resolution scales and their hierarchical and spatial relationship. Although these models have proven successful and incredibly efficient in practical applications, the mutual position and spatial resolution of the parts involved are arbitrarily defined by a human specialist and the final choice of the optimal scales and parts is based on heuristics. This work seeks to understand whether a multi-scale model can take inspiration from human fixations to select specific areas and spatial scales. In more detail, it shows that a multi-scale pyramid representation can be adopted to extract interesting points, and that human attention can be used to select the points at the scales that lead to the best face detection performance. Human fixations can therefore provide a valid methodological basis on which to build a multiscale model, by selecting the spatial scales and areas of interest that are most relevant to humans.},
  archive      = {J_BCYB},
  author       = {Cadoni, Marinella and Lagorio, Andrea and Grosso, Enrico},
  doi          = {10.1007/s00422-023-00978-5},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {6},
  pages        = {453-466},
  shortjournal = {Biol. Cybern.},
  title        = {Face detection based on a human attention guided multi-scale model},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Single-compartment model of a pyramidal neuron, fitted to
recordings with current and conductance injection. <em>BCYB</em>,
<em>117</em>(6), 433–451. (<a
href="https://doi.org/10.1007/s00422-023-00976-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For single neuron models, reproducing characteristics of neuronal activity such as the firing rate, amplitude of spikes, and threshold potentials as functions of both synaptic current and conductance is a challenging task. In the present work, we measure these characteristics of regular spiking cortical neurons using the dynamic patch-clamp technique, compare the data with predictions from the standard Hodgkin-Huxley and Izhikevich models, and propose a relatively simple five-dimensional dynamical system model, based on threshold criteria. The model contains a single sodium channel with slow inactivation, fast activation and moderate deactivation, as well as, two fast repolarizing and slow shunting potassium channels. The model quantitatively reproduces characteristics of steady-state activity that are typical for a cortical pyramidal neuron, namely firing rate not exceeding 30 Hz; critical values of the stimulating current and conductance which induce the depolarization block not exceeding 80 mV and 3, respectively (both values are scaled by the resting input conductance); extremum of hyperpolarization close to the midpoint between spikes. The analysis of the model reveals that the spiking regime appears through a saddle-node-on-invariant-circle bifurcation, and the depolarization block is reached through a saddle-node bifurcation of cycles. The model can be used for realistic network simulations, and it can also be implemented within the so-called mean-field, refractory density framework.},
  archive      = {J_BCYB},
  author       = {Chizhov, Anton V. and Amakhin, Dmitry V. and Sagtekin, A. Erdem and Desroches, Mathieu},
  doi          = {10.1007/s00422-023-00976-7},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {6},
  pages        = {433-451},
  shortjournal = {Biol. Cybern.},
  title        = {Single-compartment model of a pyramidal neuron, fitted to recordings with current and conductance injection},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Divisive normalization processors in the early visual system
of the drosophila brain. <em>BCYB</em>, <em>117</em>(6), 411–431. (<a
href="https://doi.org/10.1007/s00422-023-00972-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Divisive normalization is a model of canonical computation of brain circuits. We demonstrate that two cascaded divisive normalization processors (DNPs), carrying out intensity/contrast gain control and elementary motion detection, respectively, can model the robust motion detection realized by the early visual system of the fruit fly. We first introduce a model of elementary motion detection and rewrite its underlying phase-based motion detection algorithm as a feedforward divisive normalization processor. We then cascade the DNP modeling the photoreceptor/amacrine cell layer with the motion detection DNP. We extensively evaluate the DNP for motion detection in dynamic environments where light intensity varies by orders of magnitude. The results are compared to other bio-inspired motion detectors as well as state-of-the-art optic flow algorithms under natural conditions. Our results demonstrate the potential of DNPs as canonical building blocks modeling the analog processing of early visual systems. The model highlights analog processing for accurately detecting visual motion, in both vertebrates and invertebrates. The results presented here shed new light on employing DNP-based algorithms in computer vision.},
  archive      = {J_BCYB},
  author       = {Lazar, Aurel A. and Zhou, Yiyin},
  doi          = {10.1007/s00422-023-00972-x},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {6},
  pages        = {411-431},
  shortjournal = {Biol. Cybern.},
  title        = {Divisive normalization processors in the early visual system of the drosophila brain},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Four attributes of intelligence, a thousand questions.
<em>BCYB</em>, <em>117</em>(6), 407–409. (<a
href="https://doi.org/10.1007/s00422-023-00979-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jeff Hawkins is one of those rare individuals who speaks the languages of both AI and neuroscience. In his recent book, &quot;A Thousand Brains: A New Theory of Intelligence&quot;, Hawkins proposes that current learning algorithms lack four attributes which will be necessary for true machine intelligence. Here we demonstrate that a minimal learning system which satisfies all four points can be constructed using only simple, classical machine learning techniques. We illustrate that such a system falls short of biological intelligence in some important ways. We suggest that Hawkins’ list is a useful model, but the “recipe” for true intelligence—if there is one—may not be so easily defined.},
  archive      = {J_BCYB},
  author       = {Bardal, Matthieu and Chalmers, Eric},
  doi          = {10.1007/s00422-023-00979-4},
  journal      = {Biological Cybernetics},
  month        = {12},
  number       = {6},
  pages        = {407-409},
  shortjournal = {Biol. Cybern.},
  title        = {Four attributes of intelligence, a thousand questions},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stakes of neuromorphic foveation: A promising future for
embedded event cameras. <em>BCYB</em>, <em>117</em>(4), 389–406. (<a
href="https://doi.org/10.1007/s00422-023-00974-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foveation can be defined as the organic action of directing the gaze towards a visual region of interest to acquire relevant information selectively. With the recent advent of event cameras, we believe that taking advantage of this visual neuroscience mechanism would greatly improve the efficiency of event data processing. Indeed, applying foveation to event data would allow to comprehend the visual scene while significantly reducing the amount of raw data to handle. In this respect, we demonstrate the stakes of neuromorphic foveation theoretically and empirically across several computer vision tasks, namely semantic segmentation and classification. We show that foveated event data have a significantly better trade-off between quantity and quality of the information conveyed than high- or low-resolution event data. Furthermore, this compromise extends even over fragmented datasets. Our code is publicly available online at: https://github.com/amygruel/FoveationStakes_DVS .},
  archive      = {J_BCYB},
  author       = {Gruel, Amélie and Hareb, Dalia and Grimaldi, Antoine and Martinet, Jean and Perrinet, Laurent and Linares-Barranco, Bernabé and Serrano-Gotarredona, Teresa},
  doi          = {10.1007/s00422-023-00974-9},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {389-406},
  shortjournal = {Biol. Cybern.},
  title        = {Stakes of neuromorphic foveation: A promising future for embedded event cameras},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning heterogeneous delays in a layer of spiking neurons
for fast motion detection. <em>BCYB</em>, <em>117</em>(4), 373–387. (<a
href="https://doi.org/10.1007/s00422-023-00975-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precise timing of spikes emitted by neurons plays a crucial role in shaping the response of efferent biological neurons. This temporal dimension of neural activity holds significant importance in understanding information processing in neurobiology, especially for the performance of neuromorphic hardware, such as event-based cameras. Nonetheless, many artificial neural models disregard this critical temporal dimension of neural activity. In this study, we present a model designed to efficiently detect temporal spiking motifs using a layer of spiking neurons equipped with heterogeneous synaptic delays. Our model capitalizes on the diverse synaptic delays present on the dendritic tree, enabling specific arrangements of temporally precise synaptic inputs to synchronize upon reaching the basal dendritic tree. We formalize this process as a time-invariant logistic regression, which can be trained using labeled data. To demonstrate its practical efficacy, we apply the model to naturalistic videos transformed into event streams, simulating the output of the biological retina or event-based cameras. To evaluate the robustness of the model in detecting visual motion, we conduct experiments by selectively pruning weights and demonstrate that the model remains efficient even under significantly reduced workloads. In conclusion, by providing a comprehensive, event-driven computational building block, the incorporation of heterogeneous delays has the potential to greatly improve the performance of future spiking neural network algorithms, particularly in the context of neuromorphic chips.},
  archive      = {J_BCYB},
  author       = {Grimaldi, Antoine and Perrinet, Laurent U.},
  doi          = {10.1007/s00422-023-00975-8},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {373-387},
  shortjournal = {Biol. Cybern.},
  title        = {Learning heterogeneous delays in a layer of spiking neurons for fast motion detection},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward metacognition: Subject-aware contrastive deep fusion
representation learning for EEG analysis. <em>BCYB</em>,
<em>117</em>(4), 363–372. (<a
href="https://doi.org/10.1007/s00422-023-00967-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a subject-aware contrastive learning deep fusion neural network framework for effectively classifying subjects’ confidence levels in the perception of visual stimuli. The framework, called WaveFusion, is composed of lightweight convolutional neural networks for per-lead time–frequency analysis and an attention network for integrating the lightweight modalities for final prediction. To facilitate the training of WaveFusion, we incorporate a subject-aware contrastive learning approach by taking advantage of the heterogeneity within a multi-subject electroencephalogram dataset to boost representation learning and classification accuracy. The WaveFusion framework demonstrates high accuracy in classifying confidence levels by achieving a classification accuracy of 95.7% while also identifying influential brain regions.},
  archive      = {J_BCYB},
  author       = {Briden, Michael and Norouzi, Narges},
  doi          = {10.1007/s00422-023-00967-8},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {363-372},
  shortjournal = {Biol. Cybern.},
  title        = {Toward metacognition: Subject-aware contrastive deep fusion representation learning for EEG analysis},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bio-inspired, task-free continual learning through activity
regularization. <em>BCYB</em>, <em>117</em>(4), 345–361. (<a
href="https://doi.org/10.1007/s00422-023-00973-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to sequentially learn multiple tasks without forgetting is a key skill of biological brains, whereas it represents a major challenge to the field of deep learning. To avoid catastrophic forgetting, various continual learning (CL) approaches have been devised. However, these usually require discrete task boundaries. This requirement seems biologically implausible and often limits the application of CL methods in the real world where tasks are not always well defined. Here, we take inspiration from neuroscience, where sparse, non-overlapping neuronal representations have been suggested to prevent catastrophic forgetting. As in the brain, we argue that these sparse representations should be chosen on the basis of feed forward (stimulus-specific) as well as top-down (context-specific) information. To implement such selective sparsity, we use a bio-plausible form of hierarchical credit assignment known as Deep Feedback Control (DFC) and combine it with a winner-take-all sparsity mechanism. In addition to sparsity, we introduce lateral recurrent connections within each layer to further protect previously learned representations. We evaluate the new sparse-recurrent version of DFC on the split-MNIST computer vision benchmark and show that only the combination of sparsity and intra-layer recurrent connections improves CL performance with respect to standard backpropagation. Our method achieves similar performance to well-known CL methods, such as Elastic Weight Consolidation and Synaptic Intelligence, without requiring information about task boundaries. Overall, we showcase the idea of adopting computational principles from the brain to derive new, task-free learning algorithms for CL.},
  archive      = {J_BCYB},
  author       = {Lässig, Francesco and Aceituno, Pau Vilimelis and Sorbaro, Martino and Grewe, Benjamin F.},
  doi          = {10.1007/s00422-023-00973-w},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {345-361},
  shortjournal = {Biol. Cybern.},
  title        = {Bio-inspired, task-free continual learning through activity regularization},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extreme image transformations affect humans and machines
differently. <em>BCYB</em>, <em>117</em>(4), 331–343. (<a
href="https://doi.org/10.1007/s00422-023-00968-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some recent artificial neural networks (ANNs) claim to model aspects of primate neural and human performance data. Their success in object recognition is, however, dependent on exploiting low-level features for solving visual tasks in a way that humans do not. As a result, out-of-distribution or adversarial input is often challenging for ANNs. Humans instead learn abstract patterns and are mostly unaffected by many extreme image distortions. We introduce a set of novel image transforms inspired by neurophysiological findings and evaluate humans and ANNs on an object recognition task. We show that machines perform better than humans for certain transforms and struggle to perform at par with humans on others that are easy for humans. We quantify the differences in accuracy for humans and machines and find a ranking of difficulty for our transforms for human data. We also suggest how certain characteristics of human visual processing can be adapted to improve the performance of ANNs for our difficult-for-machines transforms.},
  archive      = {J_BCYB},
  author       = {Malik, Girik and Crowder, Dakarai and Mingolla, Ennio},
  doi          = {10.1007/s00422-023-00968-7},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {331-343},
  shortjournal = {Biol. Cybern.},
  title        = {Extreme image transformations affect humans and machines differently},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Canonical circuit computations for computer vision.
<em>BCYB</em>, <em>117</em>(4), 299–329. (<a
href="https://doi.org/10.1007/s00422-023-00966-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced computer vision mechanisms have been inspired by neuroscientific findings. However, with the focus on improving benchmark achievements, technical solutions have been shaped by application and engineering constraints. This includes the training of neural networks which led to the development of feature detectors optimally suited to the application domain. However, the limitations of such approaches motivate the need to identify computational principles, or motifs, in biological vision that can enable further foundational advances in machine vision. We propose to utilize structural and functional principles of neural systems that have been largely overlooked. They potentially provide new inspirations for computer vision mechanisms and models. Recurrent feedforward, lateral, and feedback interactions characterize general principles underlying processing in mammals. We derive a formal specification of core computational motifs that utilize these principles. These are combined to define model mechanisms for visual shape and motion processing. We demonstrate how such a framework can be adopted to run on neuromorphic brain-inspired hardware platforms and can be extended to automatically adapt to environment statistics. We argue that the identified principles and their formalization inspires sophisticated computational mechanisms with improved explanatory scope. These and other elaborated, biologically inspired models can be employed to design computer vision solutions for different tasks and they can be used to advance neural network architectures of learning.},
  archive      = {J_BCYB},
  author       = {Schmid, Daniel and Jarvers, Christian and Neumann, Heiko},
  doi          = {10.1007/s00422-023-00966-9},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {299-329},
  shortjournal = {Biol. Cybern.},
  title        = {Canonical circuit computations for computer vision},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). What can computer vision learn from visual neuroscience?
Introduction to the special issue. <em>BCYB</em>, <em>117</em>(4),
297–298. (<a href="https://doi.org/10.1007/s00422-023-00977-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BCYB},
  author       = {Chen, Kexin and Kashyap, Hirak J. and Krichmar, Jeffrey L. and Li, Xiumin},
  doi          = {10.1007/s00422-023-00977-6},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {297-298},
  shortjournal = {Biol. Cybern.},
  title        = {What can computer vision learn from visual neuroscience? introduction to the special issue},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fundamental inequality governing the rate coding response
of sensory neurons. <em>BCYB</em>, <em>117</em>(4), 285–295. (<a
href="https://doi.org/10.1007/s00422-023-00971-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental inequality governing the spike activity of peripheral neurons is derived and tested against auditory data. This inequality states that the steady-state firing rate must lie between the arithmetic and geometric means of the spontaneous and peak activities during adaptation. Implications towards the development of auditory mechanistic models are explored.},
  archive      = {J_BCYB},
  author       = {Wong, Willy},
  doi          = {10.1007/s00422-023-00971-y},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {285-295},
  shortjournal = {Biol. Cybern.},
  title        = {A fundamental inequality governing the rate coding response of sensory neurons},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The bcm rule allows a spinal cord model to learn rhythmic
movements. <em>BCYB</em>, <em>117</em>(4), 275–284. (<a
href="https://doi.org/10.1007/s00422-023-00970-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, it is accepted that animal locomotion is controlled by a central pattern generator in the spinal cord. Experiments and models show that rhythm generating neurons and genetically determined network properties could sustain oscillatory output activity suitable for locomotion. However, current central pattern generator models do not explain how a spinal cord circuitry, which has the same basic genetic plan across species, can adapt to control the different biomechanical properties and locomotion patterns existing in these species. Here we demonstrate that rhythmic and alternating movements in pendulum models can be learned by a monolayer spinal cord circuitry model using the Bienenstock–Cooper–Munro learning rule, which has been previously proposed to explain learning in the visual cortex. These results provide an alternative theory to central pattern generator models, because rhythm generating neurons and genetically defined connectivity are not required in our model. Though our results are not in contradiction to current models, as existing neural mechanism and structures, not used in our model, can be expected to facilitate the kind of learning demonstrated here. Therefore, our model could be used to augment existing models.},
  archive      = {J_BCYB},
  author       = {Kohler, Matthias and Röhrbein, Florian and Knoll, Alois and Albu-Schäffer, Alin and Jörntell, Henrik},
  doi          = {10.1007/s00422-023-00970-z},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {275-284},
  shortjournal = {Biol. Cybern.},
  title        = {The bcm rule allows a spinal cord model to learn rhythmic movements},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Periodic solutions in next generation neural field models.
<em>BCYB</em>, <em>117</em>(4), 259–274. (<a
href="https://doi.org/10.1007/s00422-023-00969-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a next generation neural field model which describes the dynamics of a network of theta neurons on a ring. For some parameters the network supports stable time-periodic solutions. Using the fact that the dynamics at each spatial location are described by a complex-valued Riccati equation we derive a self-consistency equation that such periodic solutions must satisfy. We determine the stability of these solutions, and present numerical results to illustrate the usefulness of this technique. The generality of this approach is demonstrated through its application to several other systems involving delays, two-population architecture and networks of Winfree oscillators.},
  archive      = {J_BCYB},
  author       = {Laing, Carlo R. and Omel’chenko, Oleh E.},
  doi          = {10.1007/s00422-023-00969-6},
  journal      = {Biological Cybernetics},
  month        = {10},
  number       = {4},
  pages        = {259-274},
  shortjournal = {Biol. Cybern.},
  title        = {Periodic solutions in next generation neural field models},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How aggressive interactions with biomimetic agents optimize
reproductive performances in mass-reared males of the mediterranean
fruit fly. <em>BCYB</em>, <em>117</em>(3), 249–258. (<a
href="https://doi.org/10.1007/s00422-023-00965-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mass-rearing procedures of insect species, often used in biological control and Sterile Insect Technique, can reduce the insects competitiveness in foraging, dispersal, and mating. The evocation of certain behaviours responsible to induce specific neuroendocrine products may restore or improve the competitiveness of mass-reared individuals. Herein, we used a mass-reared strain of Ceratitis capitata as model organism. C. capitata is a polyphagous pest exhibiting territorial displays that are closely related to its reproductive performance. We tested if the behaviour of C. capitata males could be altered by hybrid aggressive interactions with a conspecific-mimicking robotic fly, leading to more competitive individuals in subsequent mating events. Aggressive interactions with the robotic fly had a notable effect on subsequent courtship and mating sequences of males that performed longer courtship displays compared to naïve individuals. Furthermore, previous interactions with the robotic fly produced a higher mating success of males. Reproductive performances of C. capitata males may be improved by specific octopaminergic neurones activated during previous aggressive interactions with the robotic fly. This study adds fundamental knowledge on the potential role of specific neuro-behavioural processes in the ecology of tephritid species and paves the way to innovative biotechnological control methods based on robotics and bionics.},
  archive      = {J_BCYB},
  author       = {Romano, Donato and Benelli, Giovanni and Stefanini, Cesare},
  doi          = {10.1007/s00422-023-00965-w},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {249-258},
  shortjournal = {Biol. Cybern.},
  title        = {How aggressive interactions with biomimetic agents optimize reproductive performances in mass-reared males of the mediterranean fruit fly},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixed <span class="math display"><em>μ</em></span>
-synthesis tracking control and disturbance rejection in a robotic digit
of an impaired human hand for anthropomorphic coordination.
<em>BCYB</em>, <em>117</em>(3), 221–247. (<a
href="https://doi.org/10.1007/s00422-023-00964-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a partially impaired anthropomorphic hand, maintaining the movement coordination of the robotic digits with the central nervous system (CNS) and natural digits is crucial for robust performance. A challenge in the control perspective of movement coordination of a human hand is finding methods robust to the disturbances in a well-posed control problem of a biomechanical model. We use visco-elastic dynamics in the human palm frame of reference to explore the biomechanics of movement coordination to solve this control problem. Our biomechanical model incorporates the time delay due to actuation force, parametric uncertainty, exogenous disturbances, and sensory noise to constitute a 21-degree of freedom model. A mixed $$\mu $$ -synthesis controller, considering the real parametric uncertainty, represents the CNS in the control paradigm. We consider the robotic finger’s flexion movement when perturbed from the initial equilibrium. The controller provides feedback force at the joints to regulate the robotic finger movement. The index finger follows a reference trajectory of the joint angular position profile and stabilizes at a flexion angle of 1 rad/s at a time of 1 s. The main control objective is to keep the angular displacement of the finger joint constant when a disturbance force acts. We simulate the modeling scheme in MATLAB/ Simulink. The results demonstrate that our controller scheme is robust against the worst-case disturbance and achieves the desired performance value. Developing a biologically inspired neurophysiological controller with robust performance has many applications, including assistive rehabilitation devices, hand movement disorder diagnosis, and robotic manipulators.},
  archive      = {J_BCYB},
  author       = {Iqbal, Maryam and Imtiaz, Junaid and Mughal, Asif Mahmood},
  doi          = {10.1007/s00422-023-00964-x},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {221-247},
  shortjournal = {Biol. Cybern.},
  title        = {Mixed $$\mu $$ -synthesis tracking control and disturbance rejection in a robotic digit of an impaired human hand for anthropomorphic coordination},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-organizing maps on “what-where” codes towards fully
unsupervised classification. <em>BCYB</em>, <em>117</em>(3), 211–220.
(<a href="https://doi.org/10.1007/s00422-023-00963-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interest in unsupervised learning architectures has been rising. Besides being biologically unnatural, it is costly to depend on large labeled data sets to get a well-performing classification system. Therefore, both the deep learning community and the more biologically-inspired models community have focused on proposing unsupervised techniques that can produce adequate hidden representations which can then be fed to a simpler supervised classifier. Despite great success with this approach, an ultimate dependence on a supervised model remains, which forces the number of classes to be known beforehand, and makes the system depend on labels to extract concepts. To overcome this limitation, recent work has been proposed that shows how a self-organizing map (SOM) can be used as a completely unsupervised classifier. However, to achieve success it required deep learning techniques to generate high quality embeddings. The purpose of this work is to show that we can use our previously proposed What-Where encoder in tandem with the SOM to get an end-to-end unsupervised system that is Hebbian. Such system, requires no labels to train nor does it require knowledge of which classes exist beforehand. It can be trained online and adapt to new classes that may emerge. As in the original work, we use the MNIST data set to run an experimental analysis and verify that the system achieves similar accuracies to the best ones reported thus far. Furthermore, we extend the analysis to the more difficult Fashion-MNIST problem and conclude that the system still performs.},
  archive      = {J_BCYB},
  author       = {Sa-Couto, Luis and Wichert, Andreas},
  doi          = {10.1007/s00422-023-00963-y},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {211-220},
  shortjournal = {Biol. Cybern.},
  title        = {Self-organizing maps on “what-where” codes towards fully unsupervised classification},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Validating models of sensory conflict and perception for
motion sickness prediction. <em>BCYB</em>, <em>117</em>(3), 185–209. (<a
href="https://doi.org/10.1007/s00422-023-00959-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human motion perception system has long been linked to motion sickness through state estimation conflict terms. However, to date, the extent to which available perception models are able to predict motion sickness, or which of the employed perceptual mechanisms are of most relevance to sickness prediction, has not been studied. In this study, the subjective vertical model, the multi-sensory observer model and the probabilistic particle filter model were all validated for their ability to predict motion perception and sickness, across a large set of motion paradigms of varying complexity from literature. It was found that even though the models provided a good match for the perception paradigms studied, they could not be made to capture the full range of motion sickness observations. The resolution of the gravito-inertial ambiguity has been identified to require further attention, as key model parameters selected to match perception data did not optimally match motion sickness data. Two additional mechanisms that may enable better future predictive models of sickness have, however, been identified. Firstly, active estimation of the magnitude of gravity appears to be instrumental for predicting motion sickness induced by vertical accelerations. Secondly, the model analysis showed that the influence of the semicircular canals on the somatogravic effect may explain the differences in the dynamics observed for motion sickness induced by vertical and horizontal plane accelerations.},
  archive      = {J_BCYB},
  author       = {Irmak, Tugrul and Pool, Daan M. and de Winkel, Ksander N. and Happee, Riender},
  doi          = {10.1007/s00422-023-00959-8},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {185-209},
  shortjournal = {Biol. Cybern.},
  title        = {Validating models of sensory conflict and perception for motion sickness prediction},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-dimensional models of single neurons: A review.
<em>BCYB</em>, <em>117</em>(3), 163–183. (<a
href="https://doi.org/10.1007/s00422-023-00960-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical Hodgkin–Huxley (HH) point-neuron model of action potential generation is four-dimensional. It consists of four ordinary differential equations describing the dynamics of the membrane potential and three gating variables associated to a transient sodium and a delayed-rectifier potassium ionic currents. Conductance-based models of HH type are higher-dimensional extensions of the classical HH model. They include a number of supplementary state variables associated with other ionic current types, and are able to describe additional phenomena such as subthreshold oscillations, mixed-mode oscillations (subthreshold oscillations interspersed with spikes), clustering and bursting. In this manuscript we discuss biophysically plausible and phenomenological reduced models that preserve the biophysical and/or dynamic description of models of HH type and the ability to produce complex phenomena, but the number of effective dimensions (state variables) is lower. We describe several representative models. We also describe systematic and heuristic methods of deriving reduced models from models of HH type.},
  archive      = {J_BCYB},
  author       = {Chialva, Ulises and González Boscá, Vicente and Rotstein, Horacio G.},
  doi          = {10.1007/s00422-023-00960-1},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {3},
  pages        = {163-183},
  shortjournal = {Biol. Cybern.},
  title        = {Low-dimensional models of single neurons: A review},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structure and dynamics that specialize neurons for
high-frequency coincidence detection in the barn owl nucleus laminaris.
<em>BCYB</em>, <em>117</em>(1), 143–162. (<a
href="https://doi.org/10.1007/s00422-023-00962-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A principal cue for sound source localization is the difference in arrival times of sounds at an animal’s two ears (interaural time difference, ITD). Neurons that process ITDs are specialized to compare the timing of inputs with submillisecond precision. In the barn owl, ITD processing begins in the nucleus laminaris (NL) region of the auditory brain stem. Remarkably, NL neurons are sensitive to ITDs in high-frequency sounds (kilohertz-range). This contrasts with ITD-based sound localization in analogous regions in mammals where ITD sensitivity is typically restricted to lower-frequency sounds. Guided by previous experiments and modeling studies of tone-evoked responses of NL neurons, we propose NL neurons achieve high-frequency ITD sensitivity if they respond selectively to the small-amplitude, high-frequency oscillations in their inputs, and remain relatively non-responsive to mean input level. We use a biophysically based model to study the effects of soma–axon coupling on dynamics and function in NL neurons. First, we show that electrical separation of the soma from the axon region in the neuron enhances high-frequency ITD sensitivity. This soma–axon coupling configuration promotes linear subthreshold dynamics and rapid spike initiation, making the model more responsive to input oscillations, rather than mean input level. Second, we provide new evidence for the essential role of phasic dynamics for high-frequency neural coincidence detection. Transforming our model to the phasic firing mode further tunes the model to respond selectively to the oscillating inputs that carry ITD information. Similar structural and dynamical mechanisms specialize mammalian auditory brain stem neurons for ITD sensitivity, and thus, our work identifies common principles of ITD processing and neural coincidence detection across species and for sounds at widely different frequencies.},
  archive      = {J_BCYB},
  author       = {Drucker, Ben and Goldwyn, Joshua H.},
  doi          = {10.1007/s00422-023-00962-z},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {1},
  pages        = {143-162},
  shortjournal = {Biol. Cybern.},
  title        = {Structure and dynamics that specialize neurons for high-frequency coincidence detection in the barn owl nucleus laminaris},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approaching object acceleration differentially affects the
predictions of neuronal collision avoidance models. <em>BCYB</em>,
<em>117</em>(1), 129–142. (<a
href="https://doi.org/10.1007/s00422-023-00961-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The processing of visual information for collision avoidance has been investigated at the biophysical level in several model systems. In grasshoppers, the (so-called) $$\eta $$ model captures reasonably well the visual processing performed by an identified neuron called the lobular giant movement detector as it tracks approaching objects. Similar phenomenological models have been used to describe either the firing rate or the membrane potential of neurons responsible for visually guided collision avoidance in other animals. Specifically, in goldfish, the $$\kappa $$ model has been proposed to describe the Mauthner cell, an identified neuron involved in startle escape responses. In the vinegar fly, a third model was developed for the giant fiber neuron, which triggers last resort escapes immediately before an impending collision. One key property of these models is their prediction that peak neuronal responses occur at a fixed delay after the simulated approaching object reaches a threshold angular size on the retina. This prediction is valid for simulated objects approaching at a constant speed. We tested whether it remains valid when approaching objects accelerate. After characterizing and comparing the models’ responses to accelerating and constant speed stimuli, we find that the prediction holds true for the $$\kappa $$ and the giant fiber model, but not for the $$\eta $$ model. These results suggest that acceleration in the approach trajectory of an object may help distinguish and further constrain the neuronal computations required for collision avoidance in grasshoppers, fish and vinegar flies.},
  archive      = {J_BCYB},
  author       = {Gabbiani, Fabrizio and Preuss, Thomas and Dewell, Richard B.},
  doi          = {10.1007/s00422-023-00961-0},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {1},
  pages        = {129-142},
  shortjournal = {Biol. Cybern.},
  title        = {Approaching object acceleration differentially affects the predictions of neuronal collision avoidance models},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Controlling stick balancing on a linear track: Delayed state
feedback or delay-compensating predictor feedback? <em>BCYB</em>,
<em>117</em>(1), 113–127. (<a
href="https://doi.org/10.1007/s00422-023-00957-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A planar stick balancing task was investigated using stabilometry parameters (SP); a concept initially developed to assess the stability of human postural sway. Two subject groups were investigated: 6 subjects (MD) with many days of balancing a 90 cm stick on a linear track and 25 subjects (OD) with only one day of balancing experience. The underlying mechanical model is a pendulum-cart system. Two control force models were investigated by means of numerical simulations: (1) delayed state feedback (DSF); and (2) delay-compensating predictor feedback (PF). Both models require an internal model and are subject to certainty thresholds with delayed switching. Measured and simulated time histories were compared quantitatively using a cost function in terms of some essential SPs for all subjects. Minimization of the cost function showed that the control strategy of both OD and MD subjects can better be described by DSF. The control mechanism for the MD subjects was superior in two aspects: (1) they devoted less energy to controlling the cart’s position; and (2) their perception threshold for the stick’s angular velocity was found to be smaller. Findings support the concept that when sufficient sensory information is readily available, a delay-compensating PF strategy is not necessary.},
  archive      = {J_BCYB},
  author       = {Nagy, Dalma J. and Milton, John G. and Insperger, Tamas},
  doi          = {10.1007/s00422-023-00957-w},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {1},
  pages        = {113-127},
  shortjournal = {Biol. Cybern.},
  title        = {Controlling stick balancing on a linear track: Delayed state feedback or delay-compensating predictor feedback?},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient multi-scale representation of visual objects using
a biologically plausible spike-latency code and winner-take-all
inhibition. <em>BCYB</em>, <em>117</em>(1), 95–111. (<a
href="https://doi.org/10.1007/s00422-023-00956-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have surpassed human performance in key visual challenges such as object recognition, but require a large amount of energy, computation, and memory. In contrast, spiking neural networks (SNNs) have the potential to improve both the efficiency and biological plausibility of object recognition systems. Here we present a SNN model that uses spike-latency coding and winner-take-all inhibition (WTA-I) to efficiently represent visual stimuli using multi-scale parallel processing. Mimicking neuronal response properties in early visual cortex, images were preprocessed with three different spatial frequency (SF) channels, before they were fed to a layer of spiking neurons whose synaptic weights were updated using spike-timing-dependent-plasticity. We investigate how the quality of the represented objects changes under different SF bands and WTA-I schemes. We demonstrate that a network of 200 spiking neurons tuned to three SFs can efficiently represent objects with as little as 15 spikes per neuron. Studying how core object recognition may be implemented using biologically plausible learning rules in SNNs may not only further our understanding of the brain, but also lead to novel and efficient artificial vision systems.},
  archive      = {J_BCYB},
  author       = {Sanchez-Garcia, Melani and Chauhan, Tushar and Cottereau, Benoit R. and Beyeler, Michael},
  doi          = {10.1007/s00422-023-00956-x},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {1},
  pages        = {95-111},
  shortjournal = {Biol. Cybern.},
  title        = {Efficient multi-scale representation of visual objects using a biologically plausible spike-latency code and winner-take-all inhibition},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamical systems model of development of the action
differentiation in early infancy: A requisite of physical agency.
<em>BCYB</em>, <em>117</em>(1), 81–93. (<a
href="https://doi.org/10.1007/s00422-023-00955-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Young infants are sensitive to whether their body movements cause subsequent events or not during the interaction with the environment. This ability has been revealed by empirical studies on the reinforcement of limb movements when a string is attached between an infant limb and a mobile toy suspended overhead. A previous study reproduced the experimental observation by modeling both the infant’s limb and a mobile toy as a system of coupled oscillators. The authors then argued that emergence of agency could be explained by a phase transition in the dynamical system: from a weakly coupled state to a state where the both movements of the limb and the toy are highly coordinated. However, what remains unexplained is the following experimental observation: When the limb is connected to the mobile toy by a string, the infant increases the average velocity of the arm’s movement. On the other hand, when the toy is controlled externally, the average arm’s velocity is greatly reduced. Since young infants produce exuberant spontaneous movements even with no external stimuli, the inhibition of motor action to suppress the formation of spurious action-perception coupling should be also a crucial sign for the emergence of agency. Thus, we present a dynamical system model for the development of action differentiation, to move or not to move, in the mobile task. In addition to the pair of limb and mobile oscillators for providing positive feedback for reinforcement in the previous model, bifurcation dynamics are incorporated to enhance or inhibit self-movements in response to detecting contingencies between the limb and mobile movements. The results from computer simulations reproduce experimental observations on the developmental emergence of action differentiation between 2 and 3 months of age in the form of a bifurcation diagram. We infer that the emergence of physical agency entails young infants’ ability not only to enhance a specific action-perception coupling, but also to decouple it and create a new mode of action-perception coupling based on the internal state dynamics with contingency detection between self-generated actions and environmental events.},
  archive      = {J_BCYB},
  author       = {Fujihira, Ryo and Taga, Gentaro},
  doi          = {10.1007/s00422-023-00955-y},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {1},
  pages        = {81-93},
  shortjournal = {Biol. Cybern.},
  title        = {Dynamical systems model of development of the action differentiation in early infancy: A requisite of physical agency},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bistability at the onset of neuronal oscillations.
<em>BCYB</em>, <em>117</em>(1), 61–79. (<a
href="https://doi.org/10.1007/s00422-022-00954-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Hodgkin–Huxley (HH) model and squid axon (bathed in reduced Ca2+) fire repetitively for steady current injection. Moreover, for a current-range just suprathreshold, repetitive firing coexists with a stable steady state. Neuronal excitability, as such, shows bistability and hysteresis providing the opportunity for the system to perform as switchable between firing and non-firing states with transient input and providing the backbone as a dynamical mechanism for bursting oscillations. Some conditions for bistability can be derived by intricate analysis (bifurcation theory) and characterized by simulation, but conditions for emergence and robustness of such bistability do not typically follow from intuition. Here, we demonstrate with a semi-quantitative two-variable, V–w, reduction of the HH model features that promote/reduce bistability. Visualization of flow and trajectories in the V–w phase plane provides an intuitive grasp for bistability. The geometry of action potential recovery involves a late phase during which the dynamic negative feedback of $${I}_{\rm Na}$$ inactivation and $${I}_{\rm K}$$ activation over/undershoot, respectively, their resting values, thereby leading to hyperexcitabilty and an intrinsically generated opportunity to by-pass the spiral-like stable rest state and initiate the next spike upstroke. We illustrate control of bistability and dependence of the degree of hysteresis on recovery timescales and gating properties. Our dynamical dissection reveals the strongly attracting depolarized phase of the spike, enabling approximations like the resetting feature of adapting integrate-and-fire models. We extend our insights and show that the Morris–Lecar model can also exhibit robust bistability.},
  archive      = {J_BCYB},
  author       = {Lu, Yiqing and Xin, Xiu and Rinzel, John},
  doi          = {10.1007/s00422-022-00954-5},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {1},
  pages        = {61-79},
  shortjournal = {Biol. Cybern.},
  title        = {Bistability at the onset of neuronal oscillations},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A time-causal and time-recursive scale-covariant scale-space
representation of temporal signals and past time. <em>BCYB</em>,
<em>117</em>(1), 21–59. (<a
href="https://doi.org/10.1007/s00422-022-00953-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an overview of a theory for performing temporal smoothing on temporal signals in such a way that: (i) temporally smoothed signals at coarser temporal scales are guaranteed to constitute simplifications of corresponding temporally smoothed signals at any finer temporal scale (including the original signal) and (ii) the temporal smoothing process is both time-causal and time-recursive, in the sense that it does not require access to future information and can be performed with no other temporal memory buffer of the past than the resulting smoothed temporal scale-space representations themselves. For specific subsets of parameter settings for the classes of linear and shift-invariant temporal smoothing operators that obey this property, it is shown how temporal scale covariance can be additionally obtained, guaranteeing that if the temporal input signal is rescaled by a uniform temporal scaling factor, then also the resulting temporal scale-space representations of the rescaled temporal signal will constitute mere rescalings of the temporal scale-space representations of the original input signal, complemented by a shift along the temporal scale dimension. The resulting time-causal limit kernel that obeys this property constitutes a canonical temporal kernel for processing temporal signals in real-time scenarios when the regular Gaussian kernel cannot be used, because of its non-causal access to information from the future, and we cannot additionally require the temporal smoothing process to comprise a complementary memory of the past beyond the information contained in the temporal smoothing process itself, which in this way also serves as a multi-scale temporal memory of the past. We describe how the time-causal limit kernel relates to previously used temporal models, such as Koenderink’s scale-time kernels and the ex-Gaussian kernel. We do also give an overview of how the time-causal limit kernel can be used for modelling the temporal processing in models for spatio-temporal and spectro-temporal receptive fields, and how it more generally has a high potential for modelling neural temporal response functions in a purely time-causal and time-recursive way, that can also handle phenomena at multiple temporal scales in a theoretically well-founded manner. We detail how this theory can be efficiently implemented for discrete data, in terms of a set of recursive filters coupled in cascade. Hence, the theory is generally applicable for both: (i) modelling continuous temporal phenomena over multiple temporal scales and (ii) digital processing of measured temporal signals in real time. We conclude by stating implications of the theory for modelling temporal phenomena in biological, perceptual, neural and memory processes by mathematical models, as well as implications regarding the philosophy of time and perceptual agents. Specifically, we propose that for A-type theories of time, as well as for perceptual agents, the notion of a non-infinitesimal inner temporal scale of the temporal receptive fields has to be included in representations of the present, where the inherent nonzero temporal delay of such time-causal receptive fields implies a need for incorporating predictions from the actual time-delayed present in the layers of a perceptual hierarchy, to make it possible for a representation of the perceptual present to constitute a representation of the environment with timing properties closer to the actual present.},
  archive      = {J_BCYB},
  author       = {Lindeberg, Tony},
  doi          = {10.1007/s00422-022-00953-6},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {1},
  pages        = {21-59},
  shortjournal = {Biol. Cybern.},
  title        = {A time-causal and time-recursive scale-covariant scale-space representation of temporal signals and past time},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparison between an exact and a heuristic neural mass
model with second-order synapses. <em>BCYB</em>, <em>117</em>(1), 5–19.
(<a href="https://doi.org/10.1007/s00422-022-00952-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural mass models (NMMs) are designed to reproduce the collective dynamics of neuronal populations. A common framework for NMMs assumes heuristically that the output firing rate of a neural population can be described by a static nonlinear transfer function (NMM1). However, a recent exact mean-field theory for quadratic integrate-and-fire (QIF) neurons challenges this view by showing that the mean firing rate is not a static function of the neuronal state but follows two coupled nonlinear differential equations (NMM2). Here we analyze and compare these two descriptions in the presence of second-order synaptic dynamics. First, we derive the mathematical equivalence between the two models in the infinitely slow synapse limit, i.e., we show that NMM1 is an approximation of NMM2 in this regime. Next, we evaluate the applicability of this limit in the context of realistic physiological parameter values by analyzing the dynamics of models with inhibitory or excitatory synapses. We show that NMM1 fails to reproduce important dynamical features of the exact model, such as the self-sustained oscillations of an inhibitory interneuron QIF network. Furthermore, in the exact model but not in the limit one, stimulation of a pyramidal cell population induces resonant oscillatory activity whose peak frequency and amplitude increase with the self-coupling gain and the external excitatory input. This may play a role in the enhanced response of densely connected networks to weak uniform inputs, such as the electric fields produced by noninvasive brain stimulation.},
  archive      = {J_BCYB},
  author       = {Clusella, Pau and Köksal-Ersöz, Elif and Garcia-Ojalvo, Jordi and Ruffini, Giulio},
  doi          = {10.1007/s00422-022-00952-7},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {1},
  pages        = {5-19},
  shortjournal = {Biol. Cybern.},
  title        = {Comparison between an exact and a heuristic neural mass model with second-order synapses},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial board of biological cybernetics: Advances in
computational neuroscience. <em>BCYB</em>, <em>117</em>(1), 1–3. (<a
href="https://doi.org/10.1007/s00422-023-00958-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BCYB},
  doi          = {10.1007/s00422-023-00958-9},
  journal      = {Biological Cybernetics},
  month        = {4},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Biol. Cybern.},
  title        = {Editorial board of biological cybernetics: Advances in computational neuroscience},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
