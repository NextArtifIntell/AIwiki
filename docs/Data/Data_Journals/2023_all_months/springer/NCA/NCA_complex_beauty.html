<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NCA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nca---1484">NCA - 1484</h2>
<ul>
<li><details>
<summary>
(2023). Investigation of the aerodynamic optimization design of
fluid machinery based on machine learning. <em>NCA</em>,
<em>35</em>(36), 25307–25317. (<a
href="https://doi.org/10.1007/s00521-023-08591-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluid machinery plays an important role in national pillar industries such as national defense, military, aerospace, heavy industry, energy and power and is also the main industrial energy source. At present, many problems remain in the design of fluid machinery and systems. From the point of view of system optimization design, the utilization rate of fluid mechanics is low, which is mainly due to the mismatch between the system and the network. Based on this, relevant scholars have proposed changing high-pressure fluid machinery hydraulic systems into medium-pressure or low-pressure impeller systems and using hydraulic coupling to regulate the flow of mechanical pumps and fluid machinery to further achieve fluid machinery purposes. However, with the high efficiency, high precision and scalability of fluid machinery, a traditional single core processor has been unable to meet the high precision requirements. Therefore, how to develop software suitable for high-performance computing according to different actual conditions is an important problem. In recent years, with the development of machine learning technology, various algorithms have emerged and been widely used in fluid mechanics. These include the naive Bayesian classifier algorithm, K-means clustering algorithm, K-means clustering machine learning algorithm and support vector machine learning algorithm. Machine learning algorithms based on deep learning have a strong inductive learning ability. They can find the potential flow field information through a large number of experiments and numerical simulations. Through machine learning, a mathematical hydrodynamics gas optimization model is established. The research results show that on this basis, the overall pressure of the hydrodynamic gas optimization model established using a machine learning method was 10.1\% higher than that of the control group. This showed that the hydrodynamic gas optimization model established using a machine learning method had better aerodynamic characteristics, providing a reference for future related work.},
  archive      = {J_NCA},
  author       = {Fang, Ganlin and Yang, Ruifeng and Shen, Hang and Wang, Huaishan and Han, Zhipeng and Li, Guoliang},
  doi          = {10.1007/s00521-023-08591-0},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25307-25317},
  shortjournal = {Neural Comput. Appl.},
  title        = {Investigation of the aerodynamic optimization design of fluid machinery based on machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Localization algorithm for anisotropic wireless sensor
networks based on the adaptive chaotic slime mold algorithm.
<em>NCA</em>, <em>35</em>(36), 25291–25306. (<a
href="https://doi.org/10.1007/s00521-023-09026-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the poor localization accuracy of anisotropic localization algorithms, an adaptive chaotic slime mold algorithm called TSMA is proposed to optimize node localization in wireless sensor networks (WSNs). The adaptive chaos mechanism is first applied to the slime mold algorithm (SMA) to initialize the population using the tent map of the chaotic map with the goal of increasing the diversity of the population. Then, global and local search capabilities can be combined by setting an adaptive chaotic oscillation factor during the iterative algorithm optimization. A new localization algorithm combining PDM and TSMA is proposed in the anisotropic localization environment of WSNs. The localization performance of PDM–TSMA is further improved due to the use of anchor node screening and a feasible domain-limiting strategy. According to the simulation results, the proposed algorithm improves the localization performance by 28\% and 46\% on average in three different environments.},
  archive      = {J_NCA},
  author       = {Peng, Duo and Gao, Yuwei},
  doi          = {10.1007/s00521-023-09026-6},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25291-25306},
  shortjournal = {Neural Comput. Appl.},
  title        = {Localization algorithm for anisotropic wireless sensor networks based on the adaptive chaotic slime mold algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new multi-sensor fire detection method based on LSTM
networks with environmental information fusion. <em>NCA</em>,
<em>35</em>(36), 25275–25289. (<a
href="https://doi.org/10.1007/s00521-023-08709-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-sensor fire detection has been widely used, which allows monitoring multiple environmental indicators. However, most multi-sensor detection methods detect fires only by comparing the measurements of environmental indicators at each detection time with the preset thresholds. It is prone to fire false alarms due to neglecting the time series characteristics of environmental information. To improve the robustness and accuracy of fire detection, this paper proposes a new multi-sensor fire detection method based on long short-term memory (LSTM) networks, named EIF-LSTM. EIF-LSTM integrates environmental information fusion, which is divided into two steps. First, EIF-LSTM extracts the time series characteristics of the monitoring environment by processing multi-sensor time series readings, including environmental indicator variation information and environmental level information. Second, the normalized multi-sensor time series readings, environmental indicator variation information and environmental level information are fused together for fire prediction. The LSTM network realizes the extraction of environmental time series characteristics due to its ability to learn long-term dependencies. The addition of two kinds of time series information increases the detection dimension and enhances the fusion effect. Experimental results on a real-world fire dataset show that EIF-LSTM is capable of achieving state-of-the-art detection performance.},
  archive      = {J_NCA},
  author       = {Liu, Pingshan and Xiang, Pingchuan and Lu, Dianjie},
  doi          = {10.1007/s00521-023-08709-4},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25275-25289},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new multi-sensor fire detection method based on LSTM networks with environmental information fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). X-ray PCB defect automatic diagnosis algorithm based on deep
learning and artificial intelligence. <em>NCA</em>, <em>35</em>(36),
25263–25273. (<a
href="https://doi.org/10.1007/s00521-023-08499-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a main electronic material, X-ray circuits are widely used in various electronic devices, and their quality has an important impact on the overall quality of electronic products. In the process of mass production of circuit boards, due to the large number of layers, tight lines and some harmful external factors, circuit board quality may be problematic. Detecting circuit board defects are important for improving the reliability of electronic products. This paper introduces deep learning and artificial intelligence technology to conduct research on the automatic detection of X-ray circuit board defects. The study used a defect detection system to study X-ray circuit boards as a detection object and obtained the structure, lighting system and composition of the detection system. The working principle of the detection system is explained, and the image is preprocessed. Testing the processing performance of the PCB defect detection system, when the number of pixels is 6526, 7028, 7530 and 8032, the time consumption ratios between the proposed detection system and image processing on a traditional PC are 35.17\%, 35.4\%, 35\% and 35.28\%, respectively. The experimental results make a certain contribution to the future artificial intelligence X-ray PCB defect automatic diagnosis algorithm.},
  archive      = {J_NCA},
  author       = {Liu, Yaojun and Wang, Ping and Liu, Jingjing and Liu, Chuanyang},
  doi          = {10.1007/s00521-023-08499-9},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25263-25273},
  shortjournal = {Neural Comput. Appl.},
  title        = {X-ray PCB defect automatic diagnosis algorithm based on deep learning and artificial intelligence},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logistic regression prediction models and key influencing
factors analysis of diabetes based on algorithm design. <em>NCA</em>,
<em>35</em>(36), 25249–25261. (<a
href="https://doi.org/10.1007/s00521-023-08447-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the key influencing factors and prediction accuracy of diabetes. Nine test indexes were mainly considered: low density lipoprotein, triglyceride, total cholesterol, white blood cell, temperature, blood pressure, heart rate, blood sugar, and age. By designing data experiment method and logistic regression prediction algorithm based on fivefold cross validation, it is used to analyze odds ratio, full subset screening regression, cross validation, root mean square error and confusion matrix on 96 original data samples with 76 diabetes patients and 20 non-diabetes patients. Based on statistical test and innovation, two modeling ideas based on the combination of clinical experience and statistical test are proposed. Logistic regression model I with 2 parameter variables and Logistic regression model II with 5 parameter variables are, respectively, established to predict and compare the accuracy of five groups of different cross validation test sets. The prediction accuracy of the former is 93.7895\%, and that of the latter is 91.7895\%. This study found that age and blood sugar are the key influencing factors of diabetes. However, total cholesterol, temperature and white blood cell have little effect on diabetes. The research method has high application value and can provide scientific solutions for medical institutions to predict, analyze and early diagnose diabetes.},
  archive      = {J_NCA},
  author       = {Li, Zhijian and Pang, Sulin and Qu, Hongying and Lian, Wanmin},
  doi          = {10.1007/s00521-023-08447-7},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25249-25261},
  shortjournal = {Neural Comput. Appl.},
  title        = {Logistic regression prediction models and key influencing factors analysis of diabetes based on algorithm design},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph-based collaborative filtering algorithm combining
implicit user preference and explicit time-related feedback.
<em>NCA</em>, <em>35</em>(36), 25235–25247. (<a
href="https://doi.org/10.1007/s00521-023-08694-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering is one of the most extensively utilized recommendation algorithms in the e-commerce industry. It typically relies either on implicit or explicit feedback. The existing collaborative approaches fail to capture changes in user preferences while integrating implicit and explicit data. To model the user&#39;s current preference, we propose a novel graph-based CWALK algorithm that combines time-related item correlation explicitly and the user&#39;s preference for an item implicitly. In the first stage, we cluster users based on their rating behavior, and in the second stage, we combine implicit and explicit feedback to construct a matrix for each user group. A random-walk-with-restart is employed on the matrix to generate a recommendation for each user. Extensive evaluation using the real-world MovieLens dataset shows that the proposed method improves the accuracy of recommendations.},
  archive      = {J_NCA},
  author       = {Suganeshwari, G. and Syed Ibrahim Peer Mohamed, Syed Ibrahim and Sugumaran, Vijayan},
  doi          = {10.1007/s00521-023-08694-8},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25235-25247},
  shortjournal = {Neural Comput. Appl.},
  title        = {A graph-based collaborative filtering algorithm combining implicit user preference and explicit time-related feedback},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance analysis of the asymmetric dual-queue periodic
query threshold service polling system. <em>NCA</em>, <em>35</em>(36),
25223–25234. (<a
href="https://doi.org/10.1007/s00521-023-08463-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on establishing a mathematical model of the system provided system parameters, using the discrete-time Markov chain and a function set by a nonnegative integer random variable as probabilistic methods, the discrete time variable, two-queue different-gated polling system is fully analyzed, the low- and higher-order properties and cycle period of the system are deduced, and the average queue pair length and average waiting delay for message packets are calculated accurately. The simulation experiments agree well with the theoretical calculations. The analysis further deepens the understanding of the asymmetric threshold polling system, lays the foundation for research on the asymmetric threshold polling system, and has positive significance for a better and more flexible control periodic query polling work system.},
  archive      = {J_NCA},
  author       = {Cheng, Man and He, Jinghong and Wang, Xinchun},
  doi          = {10.1007/s00521-023-08463-7},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25223-25234},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance analysis of the asymmetric dual-queue periodic query threshold service polling system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structural optimization design of machine tools based on
parallel artificial neural networks and genetic algorithms.
<em>NCA</em>, <em>35</em>(36), 25201–25221. (<a
href="https://doi.org/10.1007/s00521-023-08371-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses a dynamic modeling and design methodology for machine tools based on parallel artificial neural networks and genetic algorithms. Firstly, subjected to geometrical and static stiffness constraints, a machine tool optimization problem is proposed by minimizing the weighted functions of lower-order natural frequencies and frequency responses. Then, the dynamic analysis of the holistic machine tool is systematically investigated based on the proposed improved reduced dynamic model, leading to the formulation of the mathematical expression for multi-objective optimization. Utilizing genetic algorithms, the proposed optimization problem is solved after the functions between performance and design variables are approximated by employing feedforward backpropagation neural networks. Finally, an optimization example and experiments are implemented on a box-in-box type precision horizontal machine tool prototype. The designed machine tool offers expected dynamic behaviors over the task workspace. Experimental results demonstrate that the derived model is accurate and effective for the prediction of lower-order dynamics, as well as the effectiveness of the design methodology used in its development.},
  archive      = {J_NCA},
  author       = {Ma, Yiwei and Tian, Yanling and Liu, Xianping},
  doi          = {10.1007/s00521-023-08371-w},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25201-25221},
  shortjournal = {Neural Comput. Appl.},
  title        = {Structural optimization design of machine tools based on parallel artificial neural networks and genetic algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Financial model construction of a cross-border e-commerce
platform based on machine learning. <em>NCA</em>, <em>35</em>(36),
25189–25199. (<a
href="https://doi.org/10.1007/s00521-023-08456-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of informatization, traditional industries have been seriously impacted by cross-border e-commerce (CBEC), and the financial management mode no longer meets the needs of CBEC users. As cross-border electronic trading platforms face enormous financial data challenges, they need financial supervision and effective network risk protection. Artificial intelligence (AI) can effectively improve the financial accounting ability and resource integration of platforms. However, at present, the underdeveloped financial management system of CBEC platforms and problems, such as the running records of platform funds have seriously hindered the development of the financial standardization of platforms because the financial management system affects managers’ statistical analysis of financial data. Therefore, this paper analyzes the financial risks, the management problems and the causes of these problems of CBEC platforms and then uses AI to study the financial operation of CBEC platforms. Subsequently, this paper uses a machine learning (ML) algorithm to analyze the financial data clustering center and the security factor of the financial model. Finally, this paper proposes some corresponding strategies for financial model optimization and construction that can improve the information security and capital management of CBEC finance and promote the long-term development of CBEC platforms. The experimental results show that the classifier value and the safety factor of the financial model of CBEC platforms gradually increase under the ML algorithm. The mean value of the classifier value is approximately 1.14, and the mean value of the safety factor is approximately 1.37. Overall, the initial value of the classifier value of the platform financial model is 0.85, which increases to 1.41 on the seventh day, while the whole process increases by 0.56. The initial value of the safety factor of the platform financial model is 1.10, which increases to 1.64 on the seventh day, while the whole process increases by 0.54. The transaction information security and financial accounting accuracy of the CBEC platform financial model is better than that of the original financial model. The transaction information security is 10.4\% higher than that of the original financial model, and the financial accounting accuracy is 10\% higher than that of the original financial model. In other words, both AI and ML can promote the financial accounting standards and long-term development of CBEC platforms.},
  archive      = {J_NCA},
  author       = {Zhou, Kan},
  doi          = {10.1007/s00521-023-08456-6},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25189-25199},
  shortjournal = {Neural Comput. Appl.},
  title        = {Financial model construction of a cross-border e-commerce platform based on machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous multi-task smoking behavior recognition model
combined with attention. <em>NCA</em>, <em>35</em>(36), 25175–25187. (<a
href="https://doi.org/10.1007/s00521-023-08616-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional behavior recognition model has the disadvantage that it can’t get the internal relationship between similar behaviors, such as smoking, pen, chin and the clamped objects, which limits the actual landing of such fine and complex behaviors as smoking recognition. To solve these problems, this paper puts forward the heterogeneous algorithm HMMA-NET (Heterogeneous multi-task smoking behavior recognition model combined with Attention), which consists of two modules: behavior prior and local detection, aiming at establishing the relationship between behavior and behavior objects. CNN combined with channel attention mechanism is used in both behavior prior module and local detection module. The former uses sign language semantic features to complete the primary prior of behavior according to the obtained behavior affinity vector field, while the latter designs network optimization such as fast Edgebox to obtain candidate areas, so as to transfer component information and achieve the goal of fast fine-grained detection. Finally, the two modules use SaaS mode to complete association recognition. Experiment shows that the algorithm can recognize complex actions effectively, and its accuracy is still equal to or even better than that of a single model, in which the accuracy of detecting smoking behavior scenes is 96.10\%, and the false detection rate is 3.6\%. The algorithm has been commercialized and applied to the actual monitoring of petrochemical scenes. The running results show that the algorithm can maintain good real-time performance and generalization ability.},
  archive      = {J_NCA},
  author       = {Qiu, Xiaotian and Kang, Xinchen and Zhang, Yang and Yao, Dengfeng and Li, Wanmin and Li, Li},
  doi          = {10.1007/s00521-023-08616-8},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25175-25187},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heterogeneous multi-task smoking behavior recognition model combined with attention},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic model averaging-based procurement optimization of
prefabricated components. <em>NCA</em>, <em>35</em>(36), 25157–25173.
(<a href="https://doi.org/10.1007/s00521-023-08715-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the promotion of construction industrialization, the prefabricated construction market is becoming increasingly competitive. The raw material cost of prefabricated components accounts for a large proportion of the total cost of prefabricated construction project. Effective planning of raw material procurement strategy for prefabricated components can significantly optimize the cost of materials and prefabricated construction project. Considering the impact of material price fluctuation and demand change on the procurement strategy of raw materials for prefabricated components, this study proposes a procurement model of raw materials for prefabricated components, which considers the changing demand and price fluctuation under multiple time series. Firstly, the price of raw materials for prefabricated components is predicted based on dynamic model averaging and dynamic model selection, and then, price is embedded into the procurement and inventory replenishment model. Finally, the raw material procurement strategy with the objective of minimizing procurement cost is generated through genetic algorithm. An application example is presented to demonstrate the capabilities of the procurement strategy model with respect to accuracy of price prediction and optimizing material procurement decisions.},
  archive      = {J_NCA},
  author       = {Du, Juan and Li, Xiufang and Sugumaran, Vijayan and Hu, Yuqing and Xue, Yan},
  doi          = {10.1007/s00521-023-08715-6},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25157-25173},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic model averaging-based procurement optimization of prefabricated components},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enterprise innovation evaluation method based on swarm
optimization algorithm and artificial neural network. <em>NCA</em>,
<em>35</em>(36), 25143–25156. (<a
href="https://doi.org/10.1007/s00521-023-08317-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Promoting the development of enterprises is a common task of all countries in the world, and the government has always taken promoting enterprise development as a long-term strategy. With the development for market, as an integral part of the social market economy, enterprises have made great contributions to the rapid of national economy. The enterprises are increasing, but the market competition is becoming increasingly fierce, and the weaknesses of enterprises such as limited scale, lax management and difficult financing are constantly highlighted. The appearance of these problems makes enterprises encounter many bottleneck problems in the process of development. Innovation, as the inexhaustible power of enterprise development, plays a significant role in enterprise growth, it is the key to solving the bottleneck problem of enterprise development. If an enterprise wants to achieve considerable development, it must innovate and enhance its competitiveness through innovation. In this context, how to evaluate enterprise innovation has become an important work. This work proposes an IPSO-ATT-MSCNN network via PSO from swarm optimization algorithm and artificial neural network to evaluate enterprise innovation. First, this work designs a multi-scale convolutional neural network (ATT-MSNN) via attention mechanism. This method uses multi-scale convolution to extract features of different scales, which improves the richness of features. This adds attention mechanisms to enhance useful features and reduce the impact of unwanted features such as noise. Second, in view of the performance degradation caused by the random initialization, this paper uses improved PSO algorithm to optimize the initial parameters. Third, this work proposes a series of strategies for promoting enterprise innovation. Finally, this work carried out a comprehensive and systematic experiment for the designed method, and the experiment verified the superiority of this method.},
  archive      = {J_NCA},
  author       = {Zhang, Qiansha and Zeng, Xiaoxia and Lo, Wei and Fan, Binbin},
  doi          = {10.1007/s00521-023-08317-2},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25143-25156},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enterprise innovation evaluation method based on swarm optimization algorithm and artificial neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ontology construction and mapping of multi-source
heterogeneous data based on hybrid neural network and autoencoder.
<em>NCA</em>, <em>35</em>(36), 25131–25141. (<a
href="https://doi.org/10.1007/s00521-023-08373-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In big data era, multi-source heterogeneous data become the biggest obstacle to data sharing due to its high dimension and inconsistent structure. Using text classification to solve the ontology construction and mapping problem of multi-source heterogeneous data can not only reduce manual operation, but also improve the accuracy and efficiency. This paper proposes an ontology construction and mapping scheme based on hybrid neural network and autoencoder. Firstly, the proposed text classification method uses the multi-core convolutional neural network to capture local features and uses the improved Bidirectional Long Short-Term Memory network to compensate for the shortcomings of the convolutional neural network that cannot obtain context-related information. Secondly, a similarity matching method is used for ontology mapping, which integrate autoencoder to improve anti-interference ability. We have carried out several sets of experiments to test the validity of the proposed ontology construction and mapping scheme.},
  archive      = {J_NCA},
  author       = {Zhao, Wenbin and Fu, Zijian and Fan, Tongrang and Wang, Jiaqi},
  doi          = {10.1007/s00521-023-08373-8},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25131-25141},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ontology construction and mapping of multi-source heterogeneous data based on hybrid neural network and autoencoder},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Identification of mild cognitive impairment by machine
learning algorithm. <em>NCA</em>, <em>35</em>(36), 25121–25130. (<a
href="https://doi.org/10.1007/s00521-023-08489-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the aging of the population, China has a large population base. The number of people suffering from mild cognitive impairment has gradually increased and gradually turned to senile dementia. The probability of mild cognitive impairment in China is about 5–7\%, and about 15 million people are ill. To better distinguish mild cognitive impairment from Alzheimer’s, this paper adopted the machine learning (ML) method to model. The evaluation table was established by considering the reaction time, education, background, memory, and other aspects of the patient. Machine learning has been applied in the fields of the Internet, finance, medicine, automation, biological science, etc. Through the machine learning support vector machine (SVM) and linear regression, the classification accuracy was compared. The results showed that the classification accuracy of SVM was 87.92\% under the ML algorithm. It also showed that ML was more conducive to classification and recognition, which has played an important role in the identification of mild cognitive impairment in the current aging population.},
  archive      = {J_NCA},
  author       = {Li, Haozhen},
  doi          = {10.1007/s00521-023-08489-x},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25121-25130},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification of mild cognitive impairment by machine learning algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoGCN: Co-occurring item-aware GCN for recommendation.
<em>NCA</em>, <em>35</em>(36), 25107–25120. (<a
href="https://doi.org/10.1007/s00521-023-08703-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolution networks (GCNs) play an increasingly vital role in recommender systems, due to their remarkable relation modeling and representation capabilities. Concretely, they can capture high-order semantic correlations within sparse bipartite interaction graphs, thereby enhancing user–item collaborative encodings. Despite the exciting prospects, the existing GCN-based models mainly focus on user–item interactions and seldom consider effectiveness of the side item co-occurrence information on user behavior guidance, resulting in limited performance improvement. Therefore, we propose a novel side item co-occurrence information-aware GCN model. Specifically, we first decouple the original heterogeneous relation graph into corresponding user–item and item–item subgraphs for user–item interaction and item co-occurrence relation modeling. Thereafter, we conduct adaptive iterative aggregation on these subgraphs for user intention understanding and co-occurring item correlation perception. Finally, we present two semantic fusion strategies for sufficient user–item semantic collaborative learning, thereby boosting the overall recommendation performance. Extensive comparison experiments are conducted on three benchmark datasets to justify the superiority of our model.},
  archive      = {J_NCA},
  author       = {Zhao, Xinxiao and Liu, Fan and Liu, Hao and Xu, Mingzhu and Tang, Haoyu and Li, Xueqing and Hu, Yupeng},
  doi          = {10.1007/s00521-023-08703-w},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25107-25120},
  shortjournal = {Neural Comput. Appl.},
  title        = {CoGCN: Co-occurring item-aware GCN for recommendation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reducing environment exposure to COVID-19 by IoT sensing and
computing with deep learning. <em>NCA</em>, <em>35</em>(36),
25097–25106. (<a
href="https://doi.org/10.1007/s00521-023-08712-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has caused significant harm globally, prompting us to prioritize prevention measures. Effective hand-washing is one of the most critical and straightforward measures that can help prevent the spread of this virus. Medical staff’s hands are considered a major source of hospital infection. Effective hand-washing can prevent up to 30\% of diarrhea-related illnesses, which is crucial in preventing nosocomial infections (Tartari et al. in Clin Microbiol Infect 23(9):596–598, 2017). This paper proposes an electronic-based real-time hand-washing identification framework called Alpha Hand Washing (ALPHA HW). The system uses camera-based identification, edge computing, and deep learning to automatically identify correct hand-washing behaviors, thereby facilitating effective hand-washing (Bertasius et al. in: Computer vision and pattern recognition, 2015). We achieved an accuracy of 78.0\% mAP and a speed of 52 FPS in detecting scenes using specific monitoring datasets in hospitals by constructing the complex recognition system into a grid computing problem. Leveraging edge computing, our system achieves real-time identification with low memory consumption and high-efficiency computation. Alpha HW presents scientific and financial values in epidemic prevention and control that can facilitate popularization to reduce virus spread (Bewley et al. in 2016 IEEE international conference on image processing, 2016).},
  archive      = {J_NCA},
  author       = {Ma, Chendong and Song, Jun and Xu, Yibo and Fan, Hongwei and Liu, Xiaoran and Wu, Xing and Luo, Yang and Sun, Tuo and Xie, Jiemin},
  doi          = {10.1007/s00521-023-08712-9},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25097-25106},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reducing environment exposure to COVID-19 by IoT sensing and computing with deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploration of a network security situational awareness
model based on multisource data fusion. <em>NCA</em>, <em>35</em>(36),
25083–25095. (<a
href="https://doi.org/10.1007/s00521-023-08500-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous expansion of the network scale, network technology is also constantly developing. However, with the continuous deterioration of the security environment, the problem of network safety is improving. The traditional single security method has greatly improved the network’s stability, but due to the lack of effective cooperation, it becomes increasingly difficult to understand the state changes of the entire network at all times. In such a large environment, research on network security situational awareness can obtain theoretical value and has certain application prospects. The current understanding of cybersecurity situational awareness is not deep enough. Most cases are built in a single-source environment and cannot accurately reflect the perception of attack phases and sequences. To solve this problem, a new model of network safety situation awareness based on multisource data fusion was proposed. The model can effectively perceive the attack stages and sequences and provide an early warning, which is of great importance to improve the network security situation awareness and maintain the network security environment. On the basis of extracting the degree of dissimilarity, in this paper, the fusion-based method is used to generate the attack trajectory, thus forming the multisource data fusion and reconstruction algorithm and finally forming the network security situational awareness model. Compared with the single-source data fusion and reconstruction algorithm, this method has better performance. The final result shows that when the original number of alarms was 1237, after multisource data fusion, the number of alarms was reduced to 124. Moreover, on the basis of multisource data fusion, the detection rate of the number of alarms reached 86.67\%, which was 26.67\% higher than that of single-source data fusion; the false alarm rate was 5.63\%, which was 1.19\% lower than that of single-source data fusion. In addition, when using the trajectory reconstruction method to reconstruct the trajectory, the accuracy of the multisource data fusion algorithm was also 1.18\% higher than that of the single source, and the completeness also increased by 2.53\% compared with the single source. Therefore, the proposed algorithm has higher efficiency, and it is helpful to establish and study the network safety situation consciousness model.},
  archive      = {J_NCA},
  author       = {Li, Xingguo and Zhong, Yu},
  doi          = {10.1007/s00521-023-08500-5},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25083-25095},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploration of a network security situational awareness model based on multisource data fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling the gaze point distribution to assist eye-based
target selection in head-mounted displays. <em>NCA</em>,
<em>35</em>(36), 25069–25081. (<a
href="https://doi.org/10.1007/s00521-023-08705-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its natural and fast characteristics, eye tracking, as a novel input modality, has been widely used in head-mounted displays for interaction. However, because of the inadvertent jitter of eyes and limitations of eye tracking devices, the eye-based selection often performs poorly in accuracy and stability compared with other input modalities, especially for small targets. To address this issue, we built a likelihood model by modeling the gaze point distribution and then combined it with Bayesian rules to infer the intended target from the perspective of probability as an alternative to the traditional selection criteria based on boundary judgment. Our investigation shows that using our model improves the selection performance significantly over the conventional ray-casting selection method and using the existing optimal likelihood model, especially in the selection of small targets.},
  archive      = {J_NCA},
  author       = {Lei, Ting and Chen, Jing and Chen, Jixiang and Liu, Bo},
  doi          = {10.1007/s00521-023-08705-8},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25069-25081},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modeling the gaze point distribution to assist eye-based target selection in head-mounted displays},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic response prediction of underwater explosive vessel
based on LOO-XGBoost model. <em>NCA</em>, <em>35</em>(36), 25057–25067.
(<a href="https://doi.org/10.1007/s00521-023-08613-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the characteristics of the dynamic response real test data of underwater explosive vessels with few feature dimensions, unclear feature relationships and small effective data amount, to improve the prediction precision of the dynamic response of the container, a dynamic response prediction model based on the LOO-XGBoost algorithm is proposed. The model uses a CART tree as the base learner, inputs the preprocessed data, and trains the target model layer by building multiple weak learners. Compared with the prediction models based on LOO-SVR, 10FLOD-XGBoost and BPNN, the simulation performance is better, the prediction accuracy is higher, and it has the significant advantage of avoiding the standardization of data features and not caring about whether the features are inter-dependent. It provides certain feasibility for the statistical prediction of the small sample capacity of similar projects.},
  archive      = {J_NCA},
  author       = {Li, Linna and Gu, Jun and Huang, Xiaowu and Zhong, Dongwang},
  doi          = {10.1007/s00521-023-08613-x},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25057-25067},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic response prediction of underwater explosive vessel based on LOO-XGBoost model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cognitive spectrum sensing algorithm based on an RBF neural
network and machine learning. <em>NCA</em>, <em>35</em>(36),
25045–25055. (<a
href="https://doi.org/10.1007/s00521-023-08488-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After 70 years of intricate development, machine learning, represented by deep learning, is based on the multilevel structure of the human brain and the layer-by-layer analysis and processing mechanism of neuron connection and interaction information. The powerful parallel information processing ability of self-adaptation and self-learning has allowed for breakthroughs in many fields, among which the most representative is image recognition. Therefore, this paper proposed optimizing the RBF algorithm with machine learning (ML) to improve the recognition rate of spectrum sensing. The results showed that the average detection success rates of the RBF algorithm were 93.62\%, 95.07\%, 96.91\%, 98.78\% and 99.37\% when the SNRs were − 8 dB, − 4 dB, 0 dB, 4 dB and 8 dB, respectively, and the other conditions were kept the same. The average detection success rates of the SVM/RBF algorithm were 97.65\%, 99.63\%, 99.76\%, 99.91\% and 99.88\%, respectively. The average detection success rate of the SVM/RBF algorithm was significantly higher than that of the RBF algorithm. This indicates that analyzing the RBF neural network algorithm through ML can improve the success rate of spectrum sensing, which highlights a new direction for the application of ML and neural networks.},
  archive      = {J_NCA},
  author       = {Yang, Shi and Tong, Chaoran},
  doi          = {10.1007/s00521-023-08488-y},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25045-25055},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cognitive spectrum sensing algorithm based on an RBF neural network and machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven full waveform inversion for ultrasonic bone
quantitative imaging. <em>NCA</em>, <em>35</em>(36), 25027–25043. (<a
href="https://doi.org/10.1007/s00521-023-08464-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Full waveform inversion (FWI) has potential for quantitative ultrasound bone imaging, which can provide detailed estimation of bone internal structure. The existing ultrasound FWI methods suffer from cycle skipping and local minima and high computational costs, which limits their clinical application potential. In recent years, data-driven method for solving the problem of inversion has become a very novel approach, but we haven&#39;t seen it in the application of ultrasonic bone imaging studies. Herein, we develop an improved dual-encoder-based Unet with high-frequency feature enhancement (DEFE-Unet) for ultrasonic bone quantitative imaging to obtain more detailed information by inserting high-frequency feature extractors related to bone microstructure into the network. This method can obtain more detailed and fine results than FWI and avoid the extremely high computational cost of FWI dual-parameter modeling. We designed two types of bone model datasets based on Micro_CT images to train and test the proposed network architecture. Experimental results show that the DEFE-Unet algorithm proposed in this paper obtains competitive results with less computational cost compared to the FWI algorithm. Compared with other baseline machine learning architectures, such as Unet and attention-Unet, the proposed algorithm achieves significant performance improvement with a small computational cost increment. The results show that the DEFE-Unet has better potential in clinical detection of bone disease.},
  archive      = {J_NCA},
  author       = {Suo, Meng and Zhang, Dong and Yang, Haiqi and Yang, Yan},
  doi          = {10.1007/s00521-023-08464-6},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25027-25043},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-driven full waveform inversion for ultrasonic bone quantitative imaging},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent recognition of audio scene based on hybrid
attention and parallel deep feature processing under genetic
evolutionary computing. <em>NCA</em>, <em>35</em>(36), 25013–25026. (<a
href="https://doi.org/10.1007/s00521-023-08351-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent recognition of audio scene aims to analyze the environment information of audio signal with computer, which has important research significance. The audio scene recognition methods extract features from the input acoustic feature representation and use the acoustic features to classify the scene type. The common feature extraction method of audio signal is Mel frequency cepstrum coefficient. Although this method can capture the most recognizable part of audio data, it can only analyze the short-term characteristics of the signal. This is often not enough to completely describe the structural characteristics of the entire audio data. With the development of computer technology and high-performance processors, audio scene recognition via deep learning solves modeling high-dimensional and multi-classification complex relationships. In this work, we propose an audio scene recognition network that combines deep learning and genetic algorithm called IGA-HA-CNN-BiGRU. First, this work combines CNN and BiGRU networks to build a parallel depth feature extraction network. Parallel neural network has strong learning ability of spatial and temporal features and can effectively extract audio feature parameters. Second, this work combines time-domain attention with channel-domain attention to design a hybrid attention mechanism. This can process features to enhance the discriminability of audio features. Thirdly, in view of the defect of initialization of deep neural network, this work uses improved genetic algorithm to optimize it to improve the model performance. Finally, this work has carried out various experiments on the proposed method, and the experimental data can prove the reliability of the method.},
  archive      = {J_NCA},
  author       = {Li, Danyang and Jia, Chunlei},
  doi          = {10.1007/s00521-023-08351-0},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25013-25026},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent recognition of audio scene based on hybrid attention and parallel deep feature processing under genetic evolutionary computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ECBTNet: English-foreign chinese intelligent translation via
multi-subspace attention and hyperbolic tangent LSTM. <em>NCA</em>,
<em>35</em>(36), 25001–25011. (<a
href="https://doi.org/10.1007/s00521-023-08624-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The translation and sharing of languages around the world has become a necessary precondition for the movement of people. Teaching Chinese as a foreign language (TCFL) undertakes international function of spreading national culture. How to translate Chinese as a foreign language into English has become an important task. Machine translation has moved beyond the realm of theory to practical use as a result of advancements in computing. Deep learning is a prominent and relatively young subfield of machine learning that has shown promising results in a variety of fields. This paper aims to develop a TCFL-oriented English-Chinese neural machine translation model. First, this paper proposes a hyperbolic tangent long short-term memory network (HTLSTM). This will integrate future information and historical information to extract more sufficient contextual semantic information. Secondly, this paper proposes a multi-subspace attention mechanism. This integrates multiple attention calculation functions in the multi-subspace attention mechanism (MSATT). Thirdly, this paper combines HTLSTM with MSATT to construct an English-Chinese bilingual neural translation model called ECBTNet. The multi-subspace attention maps hidden state of hyperbolic tangent long-term short-term memory network to multiple subspaces. This then uses multiple attention calculation functions in the multi-attention mechanism when calculating the attention score. By applying different attention calculation functions in different subspaces to extract omni-directional context information features, accurate attention calculation results can be obtained. Finally, a systematic experiment is carried out, and the experimental data verify the feasibility of applying ECBTNet to the field of English-Chinese translation in TCFL.},
  archive      = {J_NCA},
  author       = {Yang, Jing},
  doi          = {10.1007/s00521-023-08624-8},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {25001-25011},
  shortjournal = {Neural Comput. Appl.},
  title        = {ECBTNet: English-foreign chinese intelligent translation via multi-subspace attention and hyperbolic tangent LSTM},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparative analysis of urban underground public space and
user walking paths based on the social network model. <em>NCA</em>,
<em>35</em>(36), 24981–24999. (<a
href="https://doi.org/10.1007/s00521-023-08589-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation status of the underground public space pedestrian system is of varying quality, but decision-makers and operators have no way of knowing its current operation status and how to retrofit it. In this paper, the social network model is adopted to compare and analyze the characteristic parameters of urban underground public space networks and users’ pedestrian routes in 13 cases in the main urban area of Chongqing to judge the suitability of the two networks. The results show a mismatch between the existing urban underground public spaces and users’ walking paths, with most users choosing to move within a fixed range and preferring to stop at nodes with larger areas, while there is an obvious waste of resources in the rest of the nodes. The overall connectivity and aggregation are generally low although the number of nodes in transit between the two networks matches. In addition, with different types of space compared, the cross-block urban underground public space network is more suitable for users’ pedestrian routes, followed by the square and street types, and the compound type is ranked last.},
  archive      = {J_NCA},
  author       = {Jia, Xinming and Yan, Bo and Fang, Ling and Wang, Jinyao and Pang, Simai and Liu, Yang and Xu, Minyao},
  doi          = {10.1007/s00521-023-08589-8},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {24981-24999},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparative analysis of urban underground public space and user walking paths based on the social network model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Research on sheep face recognition algorithm based on
improved AlexNet model. <em>NCA</em>, <em>35</em>(36), 24971–24979. (<a
href="https://doi.org/10.1007/s00521-023-08413-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To better solve the problems of the intensive and large-scale sheep farm, such as difficult basic data collection and individual performance discrimination, this paper proposes a sheep face recognition algorithm based on the improved AlexNet Model. Based on AlexNet Model, the receptive field size is increased, the local response normalization is canceled, the FC1 layer is replaced with the Senet module of attention mechanism, and the Relu activation function is replaced with the mish function. We apply it to sheep face recognition. At Gansu Zhongtian sheep farm, sheep face data were collected, and a sheep face dataset was constructed. Through the test, the recognition accuracy is about 98.37\%, and the recognition accuracy of the sheep face verification set tracked and collected after 100 days is about 96.58\%, which proves that the improved AlexNet network model can quickly and accurately identify sheep individuals. Therefore, the model provides a new idea for the research of sheep face recognition and has specific application and popularization value.},
  archive      = {J_NCA},
  author       = {Zhang, Cheng and Zhang, Hao and Tian, Fang and Zhou, Yong and Zhao, Shuhong and Du, Xiaoyong},
  doi          = {10.1007/s00521-023-08413-3},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {24971-24979},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on sheep face recognition algorithm based on improved AlexNet model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploration of english speech translation recognition based
on the LSTM RNN algorithm. <em>NCA</em>, <em>35</em>(36), 24961–24970.
(<a href="https://doi.org/10.1007/s00521-023-08462-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s information society, the demand for intelligence is increasing daily. English speech translation recognition technology based on the LSTM (long short-term memory) recurrent neural network (RNN) algorithm is an important manifestations of computer intelligence. In recent years, many scholars have conducted research on speech translation recognition technology, including template matching and statistical pattern recognition. Each of these methods has its drawbacks. This paper discusses English speech recognition techniques by utilizing the basic RNN principles. Moreover, its application and construction in practice, which can provide some useful reference for future researchers, are analysed. LSTM RNN is an intelligent system that is different from traditional pattern recognition methods. The greatest difference is that it simulates the information processing of the human brain and realizes the intelligent information processing in a distributed manner. It has a variety of automatic recognition and extraction functions, such as storage, association, and retrieval, especially for speech translation and recognition problems with high perception ability. This new neural network recognition system has a strong scientific nature and can store sound information in a decentralized manner, similar to the human brain. The LSTM RNN has been widely used in the speech recognition field due to its excellent performance in extraction and classification. The study found that the recognition accuracy of the original RNN was generally maintained between 48 and 54\%, and the data loss rate was relatively high. The accuracy rate of speech recognition based on LSTM RNN was as high as 94\%, and the information storage efficiency was high, which greatly avoided repetitive processes. The voice data processing speed can be completed in 4.5 s at the fastest, which plays an important role in terms of mass satisfaction and social development needs.},
  archive      = {J_NCA},
  author       = {Yuan, Qiwei and Dai, Yu and Li, Guangming},
  doi          = {10.1007/s00521-023-08462-8},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {24961-24970},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploration of english speech translation recognition based on the LSTM RNN algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on evolutionary computation-based methods and
applications for data processing. <em>NCA</em>, <em>35</em>(36),
24959–24960. (<a
href="https://doi.org/10.1007/s00521-023-09104-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Liu, Weidong and Sreedevi, A. G.},
  doi          = {10.1007/s00521-023-09104-9},
  journal      = {Neural Computing and Applications},
  number       = {36},
  pages        = {24959-24960},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on evolutionary computation-based methods and applications for data processing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interval type-2 fuzzy linguistic summarization using
restriction levels. <em>NCA</em>, <em>35</em>(35), 24947–24957. (<a
href="https://doi.org/10.1007/s00521-023-09002-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using restriction levels and interval type-2 fuzzy sets into linguistic summarization evaluation is a novel strategy presented in this paper. The uncertainty and ambiguity in the linguistic summaries are handled by the suggested method by using interval type 2 fuzzy sets. While it complies with the requirements that evaluation methods should meet, the suggested method additionally makes use of restriction levels to offer a more reliable evaluation framework. On the basis of real-world data, the proposed method’s efficacy is shown. The findings demonstrate that the suggested approach can offer a thorough and precise evaluation of the linguistic summary techniques. The suggested method can assist practitioners and researchers in evaluating linguistic summaries results in a simple yet consistent fashion.},
  archive      = {J_NCA},
  author       = {Aydogan, Sena},
  doi          = {10.1007/s00521-023-09002-0},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24947-24957},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interval type-2 fuzzy linguistic summarization using restriction levels},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parametric estimation scheme for aircraft fuel consumption
using machine learning. <em>NCA</em>, <em>35</em>(35), 24925–24946. (<a
href="https://doi.org/10.1007/s00521-023-08981-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most efficient technique that is used for aircraft engine tuning is through mounting the engine on the engine test bench (ETB) to analyze, tune and monitor its variables through the ETB run. It is practically very difficult to unmount the engine from the aircraft and mount it on the ETB for analyzing and estimating a single variable such as fuel consumption or oil temperature as the unmounting process requires huge manpower and machinery. This problem can be resolved if the fuel consumption of an air vehicle is estimated without unmounting the engine from the aircraft through applying data analytics and machine learning models. Therefore, in this paper, the fuel consumption of an aircraft is analyzed and estimated through advanced data science techniques. The dataset went through data analyzing and preprocessing techniques before applying multiple machine learning models such as multiple linear regression (MLR), support vector regression, decision tree regression and deep learning algorithm RNN/LSTM. The performance of algorithms has been evaluated using model evaluation methods such as mean absolute error (MAE), root mean square error (RMSE) and coefficient of determination. The models are evaluated in taxi, cruise and approach flight phases where the LSTM performs excellent among all other algorithms with RMSE 15.1\%, 10.5\% and 0.9\%, respectively.},
  archive      = {J_NCA},
  author       = {Wahid, Mirza Anas and Bukhari, Syed Hashim Raza and Maqsood, Muazzam and Aadil, Farhan and Khan, Muhammad Ismail and Awan, Saeed Ehsan},
  doi          = {10.1007/s00521-023-08981-4},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24925-24946},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parametric estimation scheme for aircraft fuel consumption using machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Honey formation optimization with single component for
numerical function optimization: HFO-1. <em>NCA</em>, <em>35</em>(35),
24897–24923. (<a
href="https://doi.org/10.1007/s00521-023-08984-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Honey formation optimization (HFO) is originally proposed for design problems where the definitions of the objective functions are known priori or under design. HFO extends the Artificial Bee Colony (ABC) algorithm with the concept of multiple components in a source and the worker bees tending to collect components currently needed. However, the necessity of component design for a particular problem makes the HFO not applicable to optimize an arbitrary objective function. In this paper, HFO with single component (HFO-1) is proposed in order to remove this hardship of HFO for numerical function optimizations. Unlike the HFO, which only models the honey formation inside the bee, the HFO-1 further model the honey production process in the hive where sources are turned into honey-forms inside the bee and mature in time through various types of mixing processes using enzymes until the whole mixture becomes mature in the hive. During mixing process, the $$Pbest$$ (population best) is used as primal catalyzer that metamorphoses other forms towards itself. When the current mixture is mature, a new mixture is started from a new site and saturated with the $$Gbest$$ (global best) to fasten the maturity of the new mixture towards $$Gbest$$ . HFO-1 is original in that it extends the formation phase of HFO with novel local search and importantly introduces 3 new phases, mixing, maturation, and saturation, specific to honey production. In this article, 6 algorithms (Whale Optimization, Differential Search, Particle Swarm Optimization, Improved Grey Wolf, Moth-Flame Optimization, HFO-1) are comparatively studied on the basis of 60 popular benchmark functions, containing CEC2019 functions. The results show that HFO-1 is superior to others according to mean absolute error, mean variance and Wilcoxon Rank-Sum Test analysis.},
  archive      = {J_NCA},
  author       = {Yetgin, Zeki and Ercan, Uğur},
  doi          = {10.1007/s00521-023-08984-1},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24897-24923},
  shortjournal = {Neural Comput. Appl.},
  title        = {Honey formation optimization with single component for numerical function optimization: HFO-1},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). QuanCro: A novel framework for quantification of corn crops’
consistency under natural field conditions. <em>NCA</em>,
<em>35</em>(35), 24877–24896. (<a
href="https://doi.org/10.1007/s00521-023-08961-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop population and inter-plant spacing in corn farms can provide useful insight into plant phenotypic analysis and informed establishment decisions, improving crop productivity. Traditionally, farmers have relied on manual inspection to assess crop consistency, such as counting plant stands and manually estimating plant spacing. This assessment is carried out in small predefined areas, leading to insufficient crop consistency analysis on the entire field. Moreover, alternative computer vision techniques computing only one or two key parameters also prove insufficient for accurate crop consistency assessment. This research presents a framework called QuanCro that utilizes red–green–blue images from field machinery to analyze crop parameters such as plant stands counting, plant emergence rate, and plant spacing. It utilizes the state-of-the-art object detection network—You Only Look Once version 7 (YOLOv7), to locate and count corn plants combined with our proposed semantic segmentation model, Small Pyramid-UNet (SP-UNet) architecture, to determine leaf area index. This architecture is designed to be memory efficient and computationally less expensive than similar networks, such as HRNet_Mscale (72.1M) and SegNet (34.65M), as it has approximately 21M parameters. The SP-UNet is further integrated with the Zhang–Suen thinning technique and progressive probabilistic Hough transform for crop row detection and plant spacing information. QuanCro accurately estimates crop densities and identifies inconsistent crop areas. The method is tested using 8000 images and shows a mean average precision of 0.976 for identifying plant stands. The SP-UNet achieves intersection over union scores of 0.973, 0.924, and 0.926 for crops, rows, and backgrounds, respectively.},
  archive      = {J_NCA},
  author       = {Islam, Fatimah and Ullah, Muhib and Bais, Abdul},
  doi          = {10.1007/s00521-023-08961-8},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24877-24896},
  shortjournal = {Neural Comput. Appl.},
  title        = {QuanCro: A novel framework for quantification of corn crops’ consistency under natural field conditions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning and multi-station classification of
volcano-seismic events of the nevados del chillán volcanic complex
(chile). <em>NCA</em>, <em>35</em>(35), 24859–24876. (<a
href="https://doi.org/10.1007/s00521-023-08994-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a methodology for developing a volcano-seismic event classification system using a multi-station deep learning approach to support monitoring the Nevados del Chillán Volcanic Complex, which has been active since 2017. A convolutional network of multiple inputs processes the information from an event recorded up to five seismic stations. Each record is represented by its normalized spectrogram; thus, the network may receive from one to five spectrograms as input. The design includes entering additional information into the network, like the stations configuration and the event duration, information not provided by the spectrograms. Finally, this work includes the design and implementation of a relational database to access the continuous traces of events, showing different subsets of data quickly and efficiently. The results show that the classification of an event recorded up to five stations is substantially more effective than a single-station strategy. However, incorporating additional information of the signal does not significantly improve the classification performance.},
  archive      = {J_NCA},
  author       = {Ferreira, Alejandro and Curilem, Millaray and Gomez, Walter and Rios, Ricardo},
  doi          = {10.1007/s00521-023-08994-z},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24859-24876},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning and multi-station classification of volcano-seismic events of the nevados del chillán volcanic complex (Chile)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A smart IoT-based irrigation system design using AI and
prediction model. <em>NCA</em>, <em>35</em>(35), 24843–24857. (<a
href="https://doi.org/10.1007/s00521-023-08987-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing intelligent irrigation and adjusting the irrigation system is essential in today’s agricultural system to control the amount of water required for the plant. This study focuses on data obtained from sensors measuring (soil temperature and humidity, temperature and humidity of ambient and light) and image processing of plant leaves. To analyze the data, two models were implemented including a regression model in SPSS software and another model by genetic programming in MATLAB 2018 software. The optimal model was a combined model of sensors and images in genetic programming with higher R2 and lower standard error of 0.88 and 0.03, respectively. This model was superior to the regression model which had an R2 and standard error of 0.86 and 0.21, respectively, so this optimal model was selected to adjust the microcontroller for the intelligent irrigation system. The following year by replanting the crop, the intelligent irrigation system was presented as the superior system with 11\% water saving compared to the previous year (irrigation by the user). Also, no changes were observed in the yield and color indicators of the plant at the level of 5\%, which indicates the superiority of the intelligent irrigation system and its high accuracy of this system.},
  archive      = {J_NCA},
  author       = {Behzadipour, Faeze and Ghasemi Nezhad Raeini, Mahmod and Abdanan Mehdizadeh, Saman and Taki, Morteza and Khalil Moghadam, Bijan and Zare Bavani, Mohammad Reza and Lloret, Jaime},
  doi          = {10.1007/s00521-023-08987-y},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24843-24857},
  shortjournal = {Neural Comput. Appl.},
  title        = {A smart IoT-based irrigation system design using AI and prediction model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Photovoltaic system fault detection techniques: A review.
<em>NCA</em>, <em>35</em>(35), 24829–24842. (<a
href="https://doi.org/10.1007/s00521-023-09041-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar energy has received great interest in recent years, for electric power generation. Furthermore, photovoltaic (PV) systems have been widely spread over the world because of the technological advances in this field. However, these PV systems need accurate monitoring and periodic follow-up in order to achieve and optimize their performance. The PV systems are influenced by various types of faults, ranging from temporary to permanent failures. A PV system failure poses a significant challenge in determining the type and location of faults to quickly and cost-effectively maintain the required performance of the system without disturbing its normal operation. Therefore, a suitable fault detection system should be enabled to minimize the damage caused by the faulty PV module and protect the PV system from various losses. In this work, different classifications of PV faults and fault detection techniques are presented. Specifically, thermography methods and their benefits in classifying and localizing different types of faults are addressed. In addition, an overview of recent techniques using different artificial intelligence tools with thermography methods is also presented.},
  archive      = {J_NCA},
  author       = {El-Banby, Ghada M. and Moawad, Nada M. and Abouzalm, Belal A. and Abouzaid, Wessam F. and Ramadan, E. A.},
  doi          = {10.1007/s00521-023-09041-7},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24829-24842},
  shortjournal = {Neural Comput. Appl.},
  title        = {Photovoltaic system fault detection techniques: A review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based collaborative filtering recommender
systems: A comprehensive and systematic review. <em>NCA</em>,
<em>35</em>(35), 24783–24827. (<a
href="https://doi.org/10.1007/s00521-023-08958-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the volume of online information is growing and it is difficult to find the required information. Effective strategies such as recommender systems are required to overcome information overload. Collaborative filtering is a widely used type of recommender system in e-commerce environments and can simply provide suggestions for users. Recently, deep learning approaches were applied in collaborative filtering to tackle some drawbacks. This systematic review aims to provide a comprehensive review of recent research efforts on deep learning-based collaborative filtering recommender systems. We explain the research methodology and paper selection process and the search query. 102 papers are selected out of 719 papers that were published between 2019 and May 2023. Furthermore, the approaches in the selected papers are classified into two main categories: memory-based and model-based techniques. The main ideas, advantages, disadvantages, used tools, type of neural network, applications, and evaluation parameters of each selected paper are also discussed in detail. It was found that CNN (Convolutional Neural Network), AE (Autoencoder), DNN (Deep neural network), and Hybrid networks are the four mostly used neural networks in recommender systems. Also, Python, MATLAB, and Java are the most frequently used tools in the reviewed papers. Regarding the applications of the recommender systems in the reviewed papers, movies, products, and music recommendation are three most frequent applications. We point out the open issues and future research directions. Some key challenges such as cold start, data sparsity, scalability, and accuracy are still open to be addressed.},
  archive      = {J_NCA},
  author       = {Torkashvand, Atena and Jameii, Seyed Mahdi and Reza, Akram},
  doi          = {10.1007/s00521-023-08958-3},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24783-24827},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based collaborative filtering recommender systems: A comprehensive and systematic review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual dimensionality reduction on instance-level and
feature-level for multi-label data. <em>NCA</em>, <em>35</em>(35),
24773–24782. (<a
href="https://doi.org/10.1007/s00521-022-08117-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The training data in multi-label learning are often high dimensional and contains a quantity of noise and redundant information, resulting in high memory overhead and low classification performance during the learning process. Therefore, dimensionality reduction for multi-label data has become an important research topic. Existing dimensionality reduction methods for multi-label data focus on either the instance-level or the feature-level; few studies have achieved both. This paper proposes a novel two-stage method to reduce dimensionality for both instances and features on multi-label data. In the dimensionality reduction stage of instances, the original training data are converted into single-label data utilizing binary relevance. The learning vector quantization technique is employed to perform prototype selection on the transformed data and generate new instance-level low-dimensional multi-label data on the ground of the nearest neighbor information of the selected prototypes. Next, a filter-based feature selection method is proposed to choose discriminative features for each class label in the feature reduction phase. The number of retained features is determined according to the preset proportion parameters to achieve the feature-level dimensionality reduction. Experimental results on seven benchmarks verify the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Li, Haikun and Fang, Min and Wang, Peng},
  doi          = {10.1007/s00521-022-08117-0},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24773-24782},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual dimensionality reduction on instance-level and feature-level for multi-label data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic generation of labanotation based on human pose
estimation in folk dance videos. <em>NCA</em>, <em>35</em>(35),
24755–24771. (<a
href="https://doi.org/10.1007/s00521-023-08206-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Labanotation generation methods have some drawbacks due to low efficiency and incapability to recognize existing videos, which can also be affected by the quality of hardware equipment. To address the issues in existing methods, we propose a new Labanotation generation method for folk dance videos based on pose estimation. Specifically, our method first extracts the key frame images from the fork dance video using temporal differences. Afterward, the 2D joint points of a dancer can be detected from key frame images by using multi-scale fusion of high-resolution net (HRNet), then maps the 2D–3D joint point sequence of the dancer using a pose projection generative adversarial network (pose projection GAN) to predict the coordinates of the 3D joint point position. Finally, the corresponding Labanotation can be generated by analyzing the estimate posture. Experimental results show that the method can achieve the conversion of dance movements in folk dance videos into digital Labanotation, and the automatic generation is much more efficient than manual recording. This method can quickly record endangered folk dances and contribute to the preservation and transmission of movement-based intangible cultural heritage.},
  archive      = {J_NCA},
  author       = {Cai, Xingquan and Wang, Tong and Lu, Rui and Jia, Sichen and Sun, Haiyan},
  doi          = {10.1007/s00521-023-08206-8},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24755-24771},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic generation of labanotation based on human pose estimation in folk dance videos},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DDCM: A decentralized density clustering and its results
gathering approach. <em>NCA</em>, <em>35</em>(35), 24743–24754. (<a
href="https://doi.org/10.1007/s00521-023-08392-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of distributed clustering is an important method of solving large-scale data mining problems. There are still some problems associated with distributed clustering, such as a performance bottleneck on the master node and network congestion caused by global broadcasting. This paper proposes a decentralized clustering method based on density clustering and the content-addressable network technique. It can form a cluster with excellent scalability and load balancing capabilities based on several surrounding nodes. In addition, a method is presented for optimizing the way clustering results are gathered in different application scenarios. Based on our extensive experiments, the proposed approach performs three times better than benchmark algorithms in terms of efficiency and has a stable expanding ratio of about 0.6 for large-scale data sets.},
  archive      = {J_NCA},
  author       = {Zou, Lida},
  doi          = {10.1007/s00521-023-08392-5},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24743-24754},
  shortjournal = {Neural Comput. Appl.},
  title        = {DDCM: A decentralized density clustering and its results gathering approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-source feature extraction network for salient object
detection. <em>NCA</em>, <em>35</em>(35), 24727–24742. (<a
href="https://doi.org/10.1007/s00521-022-08172-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) must capture the multi-level features from both global and local view. Furthermore, interiors and boundaries of salient objects must be processed simultaneously in order to generate a clear salient map with sharp boundaries. In addition, the object-part relationship should be taken into consideration to segment the salient object as a whole. To address above issues, we propose a novel multi-source feature extraction network (MFEN), which is capable of integrating salient features, boundary features and global feature, simultaneously. First of all, the multi-source global and local module (MGLM) is introduced to integrate multi-source features, composing of a series of hybrid dilation convolution modules with different dilated rate. Furthermore, the boundary detection module is introduced to predict the boundary map and boundary features, helping for locating the salient object and sharpen edge. In addition, the adjacent features from MGLM are fused progressively to generate the final salient map by feature fusion modules. Experimental results on five datasets demonstrate that our proposed MFEN outperforms recent 18 SOD methods. More importantly, the ablation study shows that the MGLM is an effective feature fusion module for multi-level and multi-source feature.},
  archive      = {J_NCA},
  author       = {Xu, Kun and Guo, Jichang},
  doi          = {10.1007/s00521-022-08172-7},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24727-24742},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-source feature extraction network for salient object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal sentiment system and method based on CRNN-SVM.
<em>NCA</em>, <em>35</em>(35), 24713–24725. (<a
href="https://doi.org/10.1007/s00521-023-08366-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional sentiment analysis focuses on text-level sentiment mining, transforming sentiment mining into classification or regression problems, resulting in a sentiment analysis low accuracy rate. Sentiment analysis refers to the use of natural language processing, text analysis, and computational linguistics to systematically identify, extract, quantify, and study sentimental states. Therefore, more scholars have begun to focus on speech recognition and facial expression recognition research, and extracting and analysing people’s sentiment tendencies can improve sentiment recognition accuracy. Traditional single-modal sentiment analysis can no longer meet people’s needs. Therefore, this paper proposes a multimodal sentiment analysis method based on the multimodal sentiment analysis method that can obtain more sentimental information sources and help people make better decisions. The experimental results in this paper show that the highest recognition rates of CNN-SVM, RNN-SVM, and CRNN-SVM were 76.8\%, 71.2\%, and 93.5\%, respectively. It can be seen that CRNN-SVM has the highest sentiment tendency recognition rate in deep learning, so it is suitable to apply CRNN-SVM to sentiment tendency analysis system design in this paper. The average accuracy rate of the system designed in this paper was 91\%, and the stability was also very strong, which shows that the system designed in this paper is meaningful. The main contribution of this paper is based on the limitations of single-mode emotion analysis. It proposes a multimode emotion analysis method and introduces a convolutional neural network to help people obtain more emotional information sources to meet their needs.},
  archive      = {J_NCA},
  author       = {Zhao, Yuxia and Mamat, Mahpirat and Aysa, Alimjan and Ubul, Kurban},
  doi          = {10.1007/s00521-023-08366-7},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24713-24725},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal sentiment system and method based on CRNN-SVM},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization for image stereo-matching using deep
reinforcement learning in rule constraints and parallax estimation.
<em>NCA</em>, <em>35</em>(35), 24701–24711. (<a
href="https://doi.org/10.1007/s00521-023-08227-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereo-matching is a hot topic in the field of visual image research, to address the low image-matching accuracy of traditional algorithms. In this paper, an optimization for image stereo-matching algorithm using deep reinforcement learning (DRL) is proposed in rule constraints and parallax estimation. First, the image edge pixel constraint rules are established, and the image sample blocks are adjusted. Second, the image parallax estimation is performed by computing geometric constraint and pixel parallax probability in rule constraints, and a DRL structure is designed. Finally, the DRL analysis is performed iteratively by the convolutional neural networks feature extraction, agent training decision, and reward value accumulation, and stereo-matching images are output. Experiments show that the image structural similarity of the proposed algorithm is high, and the correct matching rate is more than 95\%. The images have good interpretability, and the stereo-matching effect is good.},
  archive      = {J_NCA},
  author       = {Ren, Jie and Guan, Fuyu and Li, Xueyan and Cao, Jie and Li, Xiaofeng},
  doi          = {10.1007/s00521-023-08227-3},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24701-24711},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization for image stereo-matching using deep reinforcement learning in rule constraints and parallax estimation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method of network public opinion prediction based on the
model of grey forecasting and hybrid fuzzy neural network. <em>NCA</em>,
<em>35</em>(35), 24681–24700. (<a
href="https://doi.org/10.1007/s00521-023-08205-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unexpected events occur frequently, and network public opinion prediction is one of the important research directions. Aiming at the problem that the current network public opinion prediction models mostly take improving the accuracy of the model as a breakthrough point, and lack the problem of exploring the law of public opinion communication, the study analyzes the current micro blog emergency propagation, focusing on introducing the implicit law of emotion vector, user browsing, and emergencies. At the same time, it studies the influencing factors causing the fluctuation of micro blog transmission of emergencies and selects the grey prediction model. The defects of the model are analyzed, and it has the constant increment problem and the lack of ability to deal with interference factors, and metabolic grey prediction model is used for the prediction of micro blog emergencies. At the same time, the concept of an incremental coefficient is introduced and the hybrid fuzzy neural network is adopted, the emotional knowledge is the key factor affecting the increment of grey prediction model. Use fuzzy neural network to analyze the micro blog emotional data generation, and obtain a mixed public opinion prediction model based on fuzzy neural network and grey prediction model. In the experimental process, the performance of the optimized prediction model is compared with that of the original prediction model, and a large number of data analyses prove that the optimized prediction model is effective. The experimental results show that the optimized prediction model has higher prediction accuracy.},
  archive      = {J_NCA},
  author       = {Chen, Xuegang and Duan, Sheng and Li, Shanglin and Liu, Dong and Fan, Hongbin},
  doi          = {10.1007/s00521-023-08205-9},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24681-24700},
  shortjournal = {Neural Comput. Appl.},
  title        = {A method of network public opinion prediction based on the model of grey forecasting and hybrid fuzzy neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel interest evolution network based on transformer and
a gated residual for CTR prediction in display advertising.
<em>NCA</em>, <em>35</em>(35), 24665–24680. (<a
href="https://doi.org/10.1007/s00521-023-08349-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently extracting user interest from user behavior sequences is the key to improving the click-through rate, and learning sophisticated feature interaction information is also critical in maximizing CTR. However, in terms of interest extraction, the problem of sequence dependence in most existing methods renders low training efficiency. Meanwhile, when exploring high-order feature interactions, the existing method fails to exploit information from all layers of the model. In this study, we propose an interest evolution network (TGRIEN) based on transformer and a gated residual. First, a transformer network supervised by an auxiliary loss function is proposed to extract users’ interests from behavioral sequences in parallel to enhance the training efficiency. Second, a minimal gated unit with an attention forget gate is constructed to detect interests related to target ads and capture the evolution of users’ interests. A gating mechanism is also employed in the residual module to construct a skip gated residual network, which can realize more abundant and effective feature interaction information in several ways. We evaluate the performance of TGRIEN on two real-world datasets. Experimental results demonstrate that our model significantly outperforms state-of-the-art baselines in terms of both prediction and training efficiency.},
  archive      = {J_NCA},
  author       = {Qin, Chaoyong and Xie, Jialin and Jiang, Qiuxian and Chen, Xin},
  doi          = {10.1007/s00521-023-08349-8},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24665-24680},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel interest evolution network based on transformer and a gated residual for CTR prediction in display advertising},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Five-dimensional evaluation system and perceptron
intelligent computing performance measurement methods based on medical
heterogeneous equipment health data. <em>NCA</em>, <em>35</em>(35),
24651–24664. (<a
href="https://doi.org/10.1007/s00521-023-08316-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article mainly focuses on the preprocessing method of medical heterogeneous equipment health data sources and the performance measurement of single-layer perceptron network intelligent computing. It structures a data quality evaluation system of medical heterogeneous equipment with five different dimensions: patient personal information, medical basic data, medical testing data, medical treatment data and medical device data. An innovative preprocessing algorithm of data sources is proposed to study the missing data, the error data, the repetition data and the validity data. By constructing a single-layer perceptron network, accuracy, misjudgment rate, precision, recall, true positive rate and false positive rate in intelligent computing are studied, and the corresponding mathematical calculation formulas are established. In the application research, this article collected 157 original data from a medical institution. The algorithm is applied and the models are tested. The research solved the problems of intelligent computing performance measurement of heterogeneous devices based on single-layer perceptron network.},
  archive      = {J_NCA},
  author       = {Qu, Hongying and Lian, Wanmin and Pang, Sulin and Wu, Zhiyong and You, Ge and Wang, Jiaqi},
  doi          = {10.1007/s00521-023-08316-3},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24651-24664},
  shortjournal = {Neural Comput. Appl.},
  title        = {Five-dimensional evaluation system and perceptron intelligent computing performance measurement methods based on medical heterogeneous equipment health data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MapReduce-based distributed tensor clustering algorithm.
<em>NCA</em>, <em>35</em>(35), 24633–24649. (<a
href="https://doi.org/10.1007/s00521-023-08415-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster analysis is one of the most fundamental methods in data mining, and it has been widely used in economics, social sciences and computer science. However, with the rapid development of Internet technology, the volume of data required for various web applications has grown rapidly, making the traditional clustering analysis methods face technical challenges. How to obtain useful information in a large amount of data quickly and efficiently is an urgent problem in many industrial fields. With the continuous development of cloud computing technology, large amounts of data can be performed quickly and efficiently. Hadoop is an open source distributed cloud computing platform with HDFS (Digital File System) and MapReduce as its core. HDFS provides massive data storage, while MapReduce uses the MapReduce programming model to achieve parallel processing. Compared with the traditional parallel programming model, it contains basic functions such as data partitioning, task scheduling, and parallel processing, making it possible for users to develop distributed applications on their own without understanding the basics of distributed basics, thus facilitating the design of parallel programs. K-means algorithm is a typical clustering analysis method, which is widely used in industry, but the number of iterations will increase significantly due to the growth of data volume, thus reducing the efficiency of computation. In order to better apply to the cluster analysis of large-scale data, this paper firstly implements a parallelization algorithm based on MapReduce on Hadoop platform using the basic idea of MapReduce and improves the K-means algorithm for the problems of blindness and easy to fall into local optimum when selecting randomly in clusters.},
  archive      = {J_NCA},
  author       = {Zhang, Hongjun and Li, Peng and Meng, Fanshuo and Fan, Weibei and Xue, Zhuangzhuang},
  doi          = {10.1007/s00521-023-08415-1},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24633-24649},
  shortjournal = {Neural Comput. Appl.},
  title        = {MapReduce-based distributed tensor clustering algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiment recognition and analysis method of official
document text based on BERT–SVM model. <em>NCA</em>, <em>35</em>(35),
24621–24632. (<a
href="https://doi.org/10.1007/s00521-023-08226-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment recognition analysis is an important method for studying social textual information. It has an important position in social text analysis and research. However, at present, the efficiency of official document text sentiment recognition is low, and manual judgment methods are often used, so the subjective consciousness is strong. This article aims to study the sentiment official document text recognition and analysis method based on the neural network BERT model. It extracts the sentiment information contained in the internet text information through the BERT–SVM model algorithm under deep learning and then mines the user&#39;s sentiment. Sentiment analysis is carried out on the sentences in the article, considering the influencing factors of individuals, society, and even the country, putting the method in the position of analyzing the different sentiments represented by a sentence or each word. This article first describes the related technologies of text sentiment recognition, such as feedforward neural networks, convolutional neural networks, and recurrent neural networks. By sentiment training using LSTM-RNN and LSTM-RNN-word2vec models, experiments show that the average accuracy of sentiment classification is 95.12\%, the K nearest neighbors result is 90.87\% and the Bayesian classifier is 86.84\%. By comparison, the BERT–SVM model improves the accuracy of text sentiment classification.},
  archive      = {J_NCA},
  author       = {Hao, Shule and Zhang, Peng and Liu, Sen and Wang, Yuhang},
  doi          = {10.1007/s00521-023-08226-4},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24621-24632},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sentiment recognition and analysis method of official document text based on BERT–SVM model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A modified adaptive sparrow search algorithm based on
chaotic reverse learning and spiral search for global optimization.
<em>NCA</em>, <em>35</em>(35), 24603–24620. (<a
href="https://doi.org/10.1007/s00521-023-08207-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A population-based metaheuristic algorithm that takes its cues from the foraging strategy of sparrows is called the sparrow search algorithm (SSA). While SSA is competitive when compared to other algorithms, it nevertheless has a propensity to carry out imbalanced exploitation and exploration and find the local optimum. Therefore, the modified adaptive sparrow search algorithm (MASSA), an SSA modification, is created to address these problems. To increase population variety, the MASSA uses a chaotic reverse learning technique. Second, to balance the exploitation and exploration capacities, a dynamic adaptive weight is added. In the end, an adaptive spiral search technique improves algorithm performance. Among 23 classical test functions, of which 13 are multidimensional and the other 10 are fixed dimensional, the best chaotic operator is found. It is proven that MASSA is superior. Simulation studies demonstrate that the MASSA described in this study is superior to previous algorithms in terms of stability, convergence speed, and convergence accuracy. Finally, a sample robot path planning problem is resolved using MASSA, and the experimental outcomes confirmed the viability and usefulness of MASSA.},
  archive      = {J_NCA},
  author       = {Geng, Junqi and Sun, Xianming and Wang, Haihua and Bu, Xianghai and Liu, Daohuan and Li, Fei and Zhao, Zengwu},
  doi          = {10.1007/s00521-023-08207-7},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24603-24620},
  shortjournal = {Neural Comput. Appl.},
  title        = {A modified adaptive sparrow search algorithm based on chaotic reverse learning and spiral search for global optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The evaluation of an active soft waist exoskeleton for
repetitive lifting task. <em>NCA</em>, <em>35</em>(35), 24595–24602. (<a
href="https://doi.org/10.1007/s00521-023-08348-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study is to determine how a lightweight active soft waist exoskeleton (ASWE) reduces the oxygen consumption and activity of lower back muscles of the wearer performing the repetitive lifting tasks. The heavy and frequent manual lifting operations are usually associated with an increased risk of injury in the industry. An ASWE is designed to assist workers&#39; spine for lifting weights. The structural composition and operation principle were described for the ASWE. Twelve men were recruited in the experiments as the test subjects. Oxygen consumption and electromyography of the thoracic erector spinae (TES) at the T9 level and lumbar erector spinae (LES) at the L3 level were recorded during 90 lifts in 15 min. Subjects&#39; discomfort and effectiveness evaluation were collected after lifting trials. The average value of oxygen consumption was decreased from form 15.9 ml/kg/min (Without-ASWE condition) to 13.7 ml/kg/min (With-ASWE condition). The increase in electromyography root mean square amplitude from the start until the end of the lifting trial was significantly lower when the ASWE was in use for the TES (162.79 vs. 82.08\%) and the LES (122.48 vs. 83.87\%). The use of the ASWE showed less oxygen consumption and back muscle contraction compared to the nonuse, which might reduce metabolic consumption or slow down the muscle fatigue level of the wearer&#39;s back across the lifting trial. Therefore, wearing the ASWE can reduce the discomfort of body parts, lumbar regions that exercise for a long time.},
  archive      = {J_NCA},
  author       = {Yang, Liang and Qu, Chenxi and Yin, Peng and Lv, Jiliang and Qu, Shengguan},
  doi          = {10.1007/s00521-023-08348-9},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24595-24602},
  shortjournal = {Neural Comput. Appl.},
  title        = {The evaluation of an active soft waist exoskeleton for repetitive lifting task},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early warning control model and simulation study of
engineering safety risk based on a convolutional neural network.
<em>NCA</em>, <em>35</em>(35), 24587–24594. (<a
href="https://doi.org/10.1007/s00521-022-08170-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the coexistence of fuzziness and randomness of risk factors in engineering early warning, this paper proposes a risk early warning model based on a convolutional neural network, which identifies and analyzes the risk points in engineering through engineering site pictures and provides early warning for engineering risk points in time. The risk warning model fully characterizes the fuzziness and randomness of risk, and the warning results are more objective and in line with the actual situation, which provides a more feasible engineering risk warning method. The experiments prove that the method can accurately warn of project risks, and the warning readiness rate reaches 91.3\%.},
  archive      = {J_NCA},
  author       = {Liu, Qixin and Chen, Ziwei},
  doi          = {10.1007/s00521-022-08170-9},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24587-24594},
  shortjournal = {Neural Comput. Appl.},
  title        = {Early warning control model and simulation study of engineering safety risk based on a convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-domain dynamic access control based on “blockchain +
artificial intelligence.” <em>NCA</em>, <em>35</em>(35), 24575–24585.
(<a href="https://doi.org/10.1007/s00521-023-08360-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access control is widely recognised by the public, and people’s demand for secure access control (AC) has gradually increased. Artificial intelligence technology has been widely used in cross-domain dynamic AC, driving the development of AC. To make public AC stable and secure, this text used a regional chain and AI technology to study domain dynamic AC. The text first discusses the necessity of cross-domain AC research, then introduces several common AC models, and finally explains the application of blockchain and AI in AC. Based on this, this text describes the design of a cross-domain dynamic AC model based on “blockchain + AI” and finally reviews simulation experiments conducted to compare the performance of several ACs. The cross-domain dynamic AC model based on “blockchain + AI” proposed in this text is superior to other AC models in terms of confidentiality, integrity, availability, efficiency and legitimate use. Its legal usage is 25.3\% higher than that of the identity-based access control (IBAC) model. The test results described in this text show that the use of regional chain and AI technology can greatly improve the effect of AC, thus providing an impetus for the development of AC.},
  archive      = {J_NCA},
  author       = {Wang, Fengling and Hu, Zhenlong and Wang, Han and Chen, Xingji and Feng, Weigong},
  doi          = {10.1007/s00521-023-08360-z},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24575-24585},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-domain dynamic access control based on “blockchain + artificial intelligence”},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computer-aided digital media art creation based on
artificial intelligence. <em>NCA</em>, <em>35</em>(35), 24565–24574. (<a
href="https://doi.org/10.1007/s00521-023-08584-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by information technology, artificial intelligence (AI) has gradually become an important symbol of modern society. In digital media art creation, AI has unique advantages and can help artists create better works. The purpose of this research was to study digital media art creation based on AI’s computer-aided technology. This study analysed the possibility of combining digital media art with AI and the positive effects of combining it with digital media art creation are discussed. A support vector machine (SVM) algorithm based on AI is proposed, and computer-aided digital media art creation based on AI was analysed experimentally. The experimental results of this study showed that artistic works created based on AI computer-aided technology had a digital dynamic score of 80 to 90, a digital sound effect score of 82 to 92, a digital stunt score of 85 to 95, a digital texture score of 83 to 96, and a digital colour score of 86 to 93. These scores were higher than those of works of art created based on traditional technology, indicating that AI-based computer-aided technology can be well applied to the creation of digital media art.},
  archive      = {J_NCA},
  author       = {Zhao, Bozuo and Zhan, Danping and Zhang, Canlin and Su, Meng},
  doi          = {10.1007/s00521-023-08584-z},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24565-24574},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computer-aided digital media art creation based on artificial intelligence},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on neural computing and applications in cyber
intelligence: ATCI 2022. <em>NCA</em>, <em>35</em>(35), 24563–24564. (<a
href="https://doi.org/10.1007/s00521-023-09101-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yan, Yuwei and Abawajy, Jemal},
  doi          = {10.1007/s00521-023-09101-y},
  journal      = {Neural Computing and Applications},
  number       = {35},
  pages        = {24563-24564},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on neural computing and applications in cyber intelligence: ATCI 2022},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RETRACTED ARTICLE: Data mining technology of computer
testing system for intelligent machining. <em>NCA</em>, <em>35</em>(34),
24561. (<a href="https://doi.org/10.1007/s00521-020-05369-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Lu, Jun and Zhang, Liang},
  doi          = {10.1007/s00521-020-05369-6},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24561},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Data mining technology of computer testing system for intelligent machining},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The flip-flop neuron: A memory efficient alternative for
solving challenging sequence processing and decision-making problems.
<em>NCA</em>, <em>35</em>(34), 24543–24559. (<a
href="https://doi.org/10.1007/s00521-023-08552-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential decision-making tasks that require information integration over extended durations of time are challenging for several reasons, including the problem of vanishing gradients, long training times and significant memory requirements. To this end, we propose a neuron model fashioned after the JK flip-flops in digital systems. A flip-flop is a sequential device that can store state information of the previous history. We incorporate the JK flip-flop neuron into several deep network architectures and apply the networks to difficult sequence processing problems. The proposed architectures include flip-flop neural networks (FFNNs), bidirectional flip-flop neural networks (BiFFNNs), convolutional flip-flop neural networks (ConvFFNNs), and bidirectional convolutional flip-flop neural networks (BiConvFFNNs). Learning rules of proposed architectures have also been derived. We have considered the most popular benchmark sequential tasks like signal generation, sentiment analysis, handwriting generation, text generation, video frame prediction, lung volume prediction, and action recognition to evaluate the proposed networks. Finally, we compare the results of our networks with the results from analogous networks with Long Short-Term Memory (LSTM) neurons on the same sequential tasks. Our results show that the JK flip-flop networks outperform the LSTM networks significantly or marginally on all the tasks, with only half of the trainable parameters.},
  archive      = {J_NCA},
  author       = {Kumari, Sweta and Chandrasekaran, Vigneswaran and Chakravarthy, V. Srinivasa},
  doi          = {10.1007/s00521-023-08552-7},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24543-24559},
  shortjournal = {Neural Comput. Appl.},
  title        = {The flip-flop neuron: A memory efficient alternative for solving challenging sequence processing and decision-making problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Architectural richness in deep reservoir computing.
<em>NCA</em>, <em>35</em>(34), 24525–24542. (<a
href="https://doi.org/10.1007/s00521-021-06760-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir computing (RC) is a popular class of recurrent neural networks (RNNs) with untrained dynamics. Recently, advancements on deep RC architectures have shown a great impact in time-series applications, showing a convenient trade-off between predictive performance and required training complexity. In this paper, we go more in depth into the analysis of untrained RNNs by studying the quality of recurrent dynamics developed by the layers of deep RC neural networks. We do so by assessing the richness of the neural representations in the different levels of the architecture, using measures originating from the fields of dynamical systems, numerical analysis and information theory. Our experiments, on both synthetic and real-world datasets, show that depth—as an architectural factor of RNNs design—has a natural effect on the quality of RNN dynamics (even without learning of the internal connections). The interplay between depth and the values of RC scaling hyper-parameters, especially the scaling of inter-layer connections, is crucial to design rich untrained recurrent neural systems.},
  archive      = {J_NCA},
  author       = {Gallicchio, Claudio and Micheli, Alessio},
  doi          = {10.1007/s00521-021-06760-7},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24525-24542},
  shortjournal = {Neural Comput. Appl.},
  title        = {Architectural richness in deep reservoir computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel keyframe extraction method for video classification
using deep neural networks. <em>NCA</em>, <em>35</em>(34), 24513–24524.
(<a href="https://doi.org/10.1007/s00521-021-06322-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining convolutional neural networks (CNNs) and recurrent neural networks (RNNs) produces a powerful architecture for video classification problems as spatial–temporal information can be processed simultaneously and effectively. Using transfer learning, this paper presents a comparative study to investigate how temporal information can be utilized to improve the performance of video classification when CNNs and RNNs are combined in various architectures. To enhance the performance of the identified architecture for effective combination of CNN and RNN, a novel action template-based keyframe extraction method is proposed by identifying the informative region of each frame and selecting keyframes based on the similarity between those regions. Extensive experiments on KTH and UCF-101 datasets with ConvLSTM-based video classifiers have been conducted. Experimental results are evaluated using one-way analysis of variance, which reveals the effectiveness of the proposed keyframe extraction method in the sense that it can significantly improve video classification accuracy.},
  archive      = {J_NCA},
  author       = {Savran Kızıltepe, Rukiye and Gan, John Q. and Escobar, Juan José},
  doi          = {10.1007/s00521-021-06322-x},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24513-24524},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel keyframe extraction method for video classification using deep neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DAC-HPP: Deep attributed clustering with high-order
proximity preserve. <em>NCA</em>, <em>35</em>(34), 24493–24511. (<a
href="https://doi.org/10.1007/s00521-023-09052-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed graph clustering, the task of grouping nodes into communities using both graph structure and node attributes, is a fundamental problem in graph analysis. Recent approaches have utilized deep learning for node embedding followed by conventional clustering methods. However, these methods often suffer from the limitations of relying on the original network structure, which may be inadequate for clustering due to sparsity and noise, and using separate approaches that yield suboptimal embeddings for clustering. To address these limitations, we propose a novel method called Deep Attributed Clustering with High-order Proximity Preserve (DAC-HPP) for attributed graph clustering. DAC-HPP leverages an end-to-end deep clustering framework that integrates high-order proximities and fosters structural cohesiveness and attribute homogeneity. We introduce a modified Random Walk with Restart that captures k-order structural and attribute information, enabling the modelling of interactions between network structure and high-order proximities. A consensus matrix representation is constructed by combining diverse proximity measures, and a deep joint clustering approach is employed to leverage the complementary strengths of embedding and clustering. In summary, DAC-HPP offers a unique solution for attributed graph clustering by incorporating high-order proximities and employing an end-to-end deep clustering framework. Extensive experiments demonstrate its effectiveness, showcasing its superiority over existing methods. Evaluation on synthetic and real networks demonstrates that DAC-HPP outperforms seven state-of-the-art approaches, confirming its potential for advancing attributed graph clustering research.},
  archive      = {J_NCA},
  author       = {Berahmand, Kamal and Li, Yuefeng and Xu, Yue},
  doi          = {10.1007/s00521-023-09052-4},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24493-24511},
  shortjournal = {Neural Comput. Appl.},
  title        = {DAC-HPP: Deep attributed clustering with high-order proximity preserve},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SAMLink: A mobility signature augmentation model for
trajectory-user linking. <em>NCA</em>, <em>35</em>(34), 24473–24491. (<a
href="https://doi.org/10.1007/s00521-023-09049-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory-user linking (TUL) aims to link trajectories to users who generate them, based on the historical trajectories of a set of users (e.g., social media users or drivers). It is a fundamental task for many downstream applications of trajectory data. However, there is a lack of a general method to solve the TUL problem for different types of trajectory data. Existing studies usually focus on specific trajectory data, such as check-in data. Unlike subjectively self-selected check-in data, objectively recorded trajectory data is more prevalent and voluminous in real life. To address the issue, we propose a mobility signature augmentation model named SAMLink to solve the TUL problem for different types of trajectory data. It contains three components: feature embedding, mobility signature learning, and linking. Specifically, there are three modules in the key component of mobility signature learning, i.e., local mobility signature learning, attention-based signature augmentation, and adaptive fusion. The first module encodes the input trajectory to learn the local mobility signature, while the second module generates a global mobility signature from the historical trajectories using an attention mechanism. Furthermore, the last module adaptively fuses local and global mobility signatures to yield better identification results. We evaluate our proposed model on three real-world trajectory datasets, i.e., the check-in dataset, the TCD dataset, and the ERI taxi dataset. Our results demonstrate the effectiveness and generalization of our proposed model for solving the TUL problem across different types of trajectory data.},
  archive      = {J_NCA},
  author       = {Chen, Chao-Xiong and Zhang, Wanyi and Yu, Bo and Chen, Chao},
  doi          = {10.1007/s00521-023-09049-z},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24473-24491},
  shortjournal = {Neural Comput. Appl.},
  title        = {SAMLink: A mobility signature augmentation model for trajectory-user linking},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptively weighted loss-enabled lightweight
teacher–student model for real-time railroad inspection on edge devices.
<em>NCA</em>, <em>35</em>(34), 24455–24472. (<a
href="https://doi.org/10.1007/s00521-023-09038-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railroad inspections to identify missing track components are crucial to railroad operational safety. This paper presents a new lightweight computer vision model on edge devices for accurate, real-time rail track inspection. It modifies the teacher–student guidance mechanism in NanoDet ( https://github.com/RangiLyu/nanodet ) by introducing a new adaptively weighted loss (AWL) to the training process. The AWL evaluates the teacher and student model qualities, determines the weight of the student loss, and then balances their loss contributions on-the-fly, gearing the training process toward proper knowledge distillation and guidance. Compared to SOTA models, our AWL-NanoDet features a tiny model size of less than 10 MB and a computation cost of 1.52 G FLOPs and achieves an processing time of less than 14 ms per frame when tested on Nvidia’s AGX Orin. Relative to native NanoDet, it also notably improves the model’s performance by nearly 10\%, enabling highly accurate, real-time detection of track components.},
  archive      = {J_NCA},
  author       = {Guo, Jiawei and Zhang, Sen and Qian, Yu and Wang, Yi},
  doi          = {10.1007/s00521-023-09038-2},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24455-24472},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptively weighted loss-enabled lightweight teacher–student model for real-time railroad inspection on edge devices},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modal fusion learning through biosignal, audio, and
visual content for detection of mental stress. <em>NCA</em>,
<em>35</em>(34), 24435–24454. (<a
href="https://doi.org/10.1007/s00521-023-09036-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental stress is a significant risk factor for several maladies and can negatively impact a person’s quality of life, including their work and personal relationships. Traditional methods of detecting mental stress through interviews and questionnaires may not capture individuals’ instantaneous emotional responses. In this study, the method of experience sampling was used to analyze the participants’ immediate affective responses, which provides a more comprehensive and dynamic understanding of the participants’ experiences. WorkStress3D dataset was compiled using information gathered from 20 participants for three distinct modalities. During an average of one week, 175 h of data containing physiological signals such as BVP, EDA, and body temperature, as well as facial expressions and auditory data, were collected from a single subject. We present a novel fusion model that uses double-early fusion approaches to combine data from multiple modalities. The model’s F1 score of 0.94 with a loss of 0.18 is very encouraging, showing that it can accurately identify and classify varying degrees of stress. Furthermore, we investigate the utilization of transfer learning techniques to improve the efficacy of our stress detection system. Despite our efforts, we were unable to attain better results than the fusion model. Transfer learning resulted in an accuracy of 0.93 and a loss of 0.17, illustrating the difficulty of adapting pre-trained models to the task of stress analysis. The results we obtained emphasize the significance of multi-modal fusion in stress detection and the importance of selecting the most suitable model architecture for the given task. The proposed fusion model demonstrates its potential for achieving an accurate and robust classification of stress. This research contributes to the field of stress analysis and contributes to the development of effective models for stress detection.},
  archive      = {J_NCA},
  author       = {Dogan, Gulin and Akbulut, Fatma Patlar},
  doi          = {10.1007/s00521-023-09036-4},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24435-24454},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-modal fusion learning through biosignal, audio, and visual content for detection of mental stress},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geometric-driven structure recovery from a single
omnidirectional image based on planar depth map learning. <em>NCA</em>,
<em>35</em>(34), 24407–24433. (<a
href="https://doi.org/10.1007/s00521-023-09025-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene structure recovery is a crucial process for assisting scene reconstruction and understanding by extracting vital scene structure information and has been widely used in smart city, VR/AR and intelligent robot navigation. Omnidirectional image with a 180° or 360° field of view (FoV) provides greater visual information, making them a significant research topic in computer vision and computational photography. However, indoor omnidirectional scene structure recovery faces challenges like severe occlusion of critical local regions caused by cluttered objects and large nonlinear distortion. To address these limitations, we propose a geometric-driven indoor structure recovery method based on planar depth map learning, aiming to mitigate the interference caused by occlusions in critical local regions. Our approach involves designing an OmniPDMNet, a planar depth map learning network for omnidirectional image, which uses upsampling and a feature-based objective loss function to accurately estimate high-precision planar depth map. Furthermore, we leverage prior knowledge from the omnidirectional depth map and introduce it into the structure recovery network (OmniSRNet) to extract global structural features and enhance the overall quality of structure recovery. We also introduce a distortion-aware module for feature extraction from omnidirectional image, allowing adaptability to omnidirectional geometric distortion and enhancing the performance of both OmniPDMNet and OmniSRNet. Finally, we conduct extensive experiments on omnidirectional dataset focusing on planar depth and structure recovery demonstrate that our proposed method achieves state-of-the-art performance.},
  archive      = {J_NCA},
  author       = {Meng, Ming and Xiao, Likai and Zhou, Zhong},
  doi          = {10.1007/s00521-023-09025-7},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24407-24433},
  shortjournal = {Neural Comput. Appl.},
  title        = {Geometric-driven structure recovery from a single omnidirectional image based on planar depth map learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple frequency–spatial network for RGBT tracking in the
presence of motion blur. <em>NCA</em>, <em>35</em>(34), 24389–24406. (<a
href="https://doi.org/10.1007/s00521-023-09024-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT tracking combines visible and thermal infrared images to achieve tracking and faces challenges due to motion blur caused by camera and target movement. In this study, we observe that the tracking in motion blur is significantly affected by both frequency and spatial aspects. And blurred targets exhibit sharp texture details that are represented as high-frequency information. But existing trackers capture low-frequency components while ignoring high-frequency information. To enhance the representation of sharp information in blurred scenes, we introduce multi-frequency and multi-spatial information in network, called FSBNet. First, we construct a modality-specific unsymmetrical architecture and integrate an adaptive soft threshold mechanism into a DCT-based multi-frequency channel attention adapter (DFDA). DFDA adaptively integrates rich multi-frequency information. Second, we propose a masked frequency-based translation adapter (MFTA) to refine drifting failure boxes caused by camera motion. Moreover, we find that small targets get more affected by motion blur compared to larger targets, and we mitigate this issue by designing a cross-scale mutual conversion adapter (CFCA) between the frequency and spatial domains. Extensive experiments on GTOT, RGBT234 and LasHeR benchmarks demonstrate the promising performance of our method in the presence of motion blur.},
  archive      = {J_NCA},
  author       = {Fan, Shenghua and Chen, Xi and He, Chu and Yu, Lei and Mao, Zhongjie and Zheng, Yujin},
  doi          = {10.1007/s00521-023-09024-8},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24389-24406},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multiple frequency–spatial network for RGBT tracking in the presence of motion blur},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sim-GAIL: A generative adversarial imitation learning
approach of student modelling for intelligent tutoring systems.
<em>NCA</em>, <em>35</em>(34), 24369–24388. (<a
href="https://doi.org/10.1007/s00521-023-08989-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous application of artificial intelligence (AI) technologies in online education has led to significant progress, especially in the field of Intelligent Tutoring Systems (ITS), online courses and learning management systems (LMS). An important research direction of the field is to provide students with customised learning trajectories via student modelling. Previous studies have shown that customisation of learning trajectories could effectively improve students’ learning experiences and outcomes. However, training an ITS that can customise students’ learning trajectories suffers from cold-start, time-consumption, human labour-intensity, and cost problems. One feasible approach is to simulate real students’ behaviour trajectories through algorithms, to generate data that could be used to train the ITS. Nonetheless, implementing high-accuracy student modelling methods that effectively address these issues remains an ongoing challenge. Traditional simulation methods, in particular, encounter difficulties in ensuring the quality and diversity of the generated data, thereby limiting their capacity to provide intelligent tutoring systems (ITS) with high-fidelity and diverse training data. We thus propose Sim-GAIL, a novel student modelling method based on generative adversarial imitation learning (GAIL). To the best of our knowledge, it is the first method using GAIL to address the challenge of lacking training data, resulting from the issues mentioned above. We analyse and compare the performance of Sim-GAIL with two traditional Reinforcement Learning-based and Imitation Learning-based methods using action distribution evaluation, cumulative reward evaluation, and offline-policy evaluation. The experiments demonstrate that our method outperforms traditional ones on most metrics. Moreover, we apply our method to a domain plagued by the cold-start problem, knowledge tracing (KT), and the results show that our novel method could effectively improve the KT model’s prediction accuracy in a cold-start scenario.},
  archive      = {J_NCA},
  author       = {Li, Zhaoxing and Shi, Lei and Wang, Jindi and Cristea, Alexandra I. and Zhou, Yunzhan},
  doi          = {10.1007/s00521-023-08989-w},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24369-24388},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sim-GAIL: A generative adversarial imitation learning approach of student modelling for intelligent tutoring systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improvement of a pressure rise test rig for cooling capacity
inference of hermetic compressors based on ANNs. <em>NCA</em>,
<em>35</em>(34), 24357–24367. (<a
href="https://doi.org/10.1007/s00521-023-09034-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent publications have proposed the use of tools based on artificial neural networks to infer the cooling capacity of refrigeration compressors from the results of pressure rise tests, which are quick tests used for production quality assurance. However, the typical rigs used in such tests were not designed to evaluate compressor performance, so the uncertainty in the inferred cooling capacity is high. This paper proposes an improved test rig aiming a better correlation of its results with cooling capacity. A committee of multilayer perceptron artificial neural networks was used to make the cooling capacity inferences from the results obtained in the improved test rig. A method that combines bootstrap techniques with Monte Carlo simulations was used to assure the reliability of the results. The average absolute difference observed between the results of the proposed method and the results of traditional tests done in laboratory was 0.35\%, with standard deviation of 0.47\%. In addition, the average uncertainty of the inferences was 4.3\% for the test samples, which is close to the uncertainty of 3.0\% observed in traditional tests, both for a coverage probability of 95\%. The time required to carry out the proposed test is about 1 min, thus enabling an increase in the sampling of tested compressors with respect to the traditional method used in industry.},
  archive      = {J_NCA},
  author       = {Barros, Vinicius T. and Machado, João P. Z. and Pacheco, Antonio L. S. and Flesch, Rodolfo C. C.},
  doi          = {10.1007/s00521-023-09034-6},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24357-24367},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improvement of a pressure rise test rig for cooling capacity inference of hermetic compressors based on ANNs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep encoder–decoder-based shared learning for
multi-criteria recommendation systems. <em>NCA</em>, <em>35</em>(34),
24347–24356. (<a
href="https://doi.org/10.1007/s00521-023-09007-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recommendation system (RS) can help overcome information overload issues by offering personalized predictions for users. Typically, RS considers the overall ratings of users on items to generate recommendations for them. However, users may consider several aspects when evaluating items. Hence, a multi-criteria RS considers n-aspects of items to generate more accurate recommendations than a single-criteria RS. This research paper proposes two deep encoder–decoder models based on shared learning for a multi-criteria RS, multi-modal deep encoder–decoder-based shared learning (MMEDSL) and multi-criteria deep encoder–decoder-based shared learning (MCEDSL). MMEDSL employs the shared learning technique by concentrating on the multi-modality concept in deep learning, while MCEDSL focuses on the training process to apply the shared learning technique. The shared learning captures useful shared information during the learning process since the multi-criteria may have hidden inter-relationships. A set of experiments were conducted to compare the proposed models with recent baseline approaches. The Yahoo! Movies multi-criteria dataset was utilized. The results demonstrate that the proposed models outperform other algorithms. In addition, the results show that integrating the shared learning technique with the RS produces precise recommendation predictions.},
  archive      = {J_NCA},
  author       = {Fraihat, Salam and Abu Tahon, Bushra and Alhijawi, Bushra and Awajan, Arafat},
  doi          = {10.1007/s00521-023-09007-9},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24347-24356},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep encoder–decoder-based shared learning for multi-criteria recommendation systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling reproductive fitness of predator, hippodamia
variegata (coleoptera: Coccinellidae) using support vector machine (SVM)
on three nitrogen treatments. <em>NCA</em>, <em>35</em>(34),
24333–24346. (<a
href="https://doi.org/10.1007/s00521-023-09020-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein and carbohydrate content in the diet of the predator Hippodamia variegata Goeze (variegated ladybug) directly influences reproduction fitness by affecting foraging efficiency. The effect of three varied qualities of Aphis gossypii Glover (cotton aphid) prey on daily H. variegata feeding and daily egg production (DEP) were estimated using the support vector machine (SVM). The SVM can predict predator reproductive behavior as a function of the relationship between foraging and prey nutritional composition. We used the total number and weight of aphids consumed, volume of protein, lipid, carbohydrate, and glycogen, and total energy received by the ladybug after feeding on one prey item as input variables. Aphid quality varied as nitrogen (N) fertilization levels were 110, 160, and 210 ppm on the Cucumis sativus L. (cucumber) host plants. The model estimated female beetles consumed more aphids and nutrients on C. sativus plants with N levels of 160 ppm compared to lower (110 ppm) N levels and had higher reproductive transformation efficiencies. Transformation rates of aphid feeding to egg production in females exposed to the 160 ppm treatment were 65\% greater, had lower nutrient and energy requirements, and achieved a 29.4\% higher DEP than those exposed to high (210 ppm) N levels. The SVM predicted nutrient compositions of A. gossypii exposed to 160 ppm N were balanced such that H. variegata exhibited greater reproduction efficiency than the other N treatments for first 30 d from the start of reproduction.},
  archive      = {J_NCA},
  author       = {Hosseini, Afsane and Hosseini, Mojtaba and Rohani, Abbas and Lawson, Shaneka},
  doi          = {10.1007/s00521-023-09020-y},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24333-24346},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modeling reproductive fitness of predator, hippodamia variegata (Coleoptera: Coccinellidae) using support vector machine (SVM) on three nitrogen treatments},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of solidification crack formation in laser beam
welding videos of sheet metal using neural networks. <em>NCA</em>,
<em>35</em>(34), 24315–24332. (<a
href="https://doi.org/10.1007/s00521-023-09004-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser beam welding has become widely applied in many industrial fields in recent years. Solidification cracks remain one of the most common welding faults that can prevent a safe welded joint. In civil engineering, convolutional neural networks (CNNs) have been successfully used to detect cracks in roads and buildings by analysing images of the constructed objects. These cracks are found in static objects, whereas the generation of a welding crack is a dynamic process. Detecting the formation of cracks as early as possible is greatly important to ensure high welding quality. In this study, two end-to-end models based on long short-term memory and three-dimensional convolutional networks (3D-CNN) are proposed for automatic crack formation detection. To achieve maximum accuracy with minimal computational complexity, we progressively modify the model to find the optimal structure. The controlled tensile weldability test is conducted to generate long videos used for training and testing. The performance of the proposed models is compared with the classical neural network ResNet-18, which has been proven to be a good transfer learning model for crack detection. The results show that our models can detect the start time of crack formation earlier, while ResNet-18 only detects cracks during the propagation stage.},
  archive      = {J_NCA},
  author       = {Huo, Wenjie and Bakir, Nasim and Gumenyuk, Andrey and Rethmeier, Michael and Wolter, Katinka},
  doi          = {10.1007/s00521-023-09004-y},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24315-24332},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of solidification crack formation in laser beam welding videos of sheet metal using neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A many-objective evolutionary algorithm based on novel
fitness estimation and grouping layering. <em>NCA</em>, <em>35</em>(34),
24283–24314. (<a
href="https://doi.org/10.1007/s00521-023-08950-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective optimization problems pose a great challenge for traditional Pareto-based multi-objective evolutionary algorithms (MOEAs), due to the loss of selection pressure (pressure that drives the population evolution) and the difficulty of diversity maintenance. To relieve the above challenge, this paper proposes a many-objective evolutionary algorithm based on novel fitness estimation and grouping layering (called MaOEA-FEGL). The novel fitness estimation mechanism can increase selection pressure and maintain diversity simultaneously by integrating the designed cos function-based convergence measure and adaptive mapping angle distance-based diversity measure. Meanwhile, a grouping layering strategy is proposed for further enhancing convergence and diversity, which divides individuals into different groups. Then, the individuals in each group are stratified into different layers by the R2 indicator. Based on the above mechanism and strategy, a two-round environmental selection strategy is designed to select elite individuals for the next generation. In addition, a variable classification-based initialization technique is designed to generate a high-quality initialization population and further provide a good start for the subsequent population evolution. Experimental studies on two well-known benchmark suites and two real-world engineering applications with objective numbers varying from 3 to 20 demonstrate that our algorithm is highly competitive compared with some state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Zhang, Wei and Liu, Jianchang and Liu, Junhua and Liu, Yuanchao and Wang, Honghai},
  doi          = {10.1007/s00521-023-08950-x},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24283-24314},
  shortjournal = {Neural Comput. Appl.},
  title        = {A many-objective evolutionary algorithm based on novel fitness estimation and grouping layering},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gish: A novel activation function for image classification.
<em>NCA</em>, <em>35</em>(34), 24259–24281. (<a
href="https://doi.org/10.1007/s00521-023-09035-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Convolutional Neural Networks (CNNs), the selection and use of appropriate activation functions is of critical importance. It has been seen that the Rectified Linear Unit (ReLU) is widely used in many CNN models. Looking at the recent studies, it has been seen that some non-monotonic activation functions are gradually moving towards becoming the new standard to improve the performance of CNN models. It has been observed that some non-monotonic activation functions such as Swish, Mish, Logish and Smish are used to obtain successful results in various deep learning models. However, only a few of them have been widely used in most of the studies. Inspired by them, in this study, a new activation function named Gish, whose mathematical model can be represented by $$y=x\cdot ln(2-{e}^{{-e}^{x}})$$ , which can overcome other activation functions with its good properties, is proposed. The variable $$x$$ is used to contribute to a strong regulation effect of negative output. The logarithm operation is done to reduce the numerical range of the expression $$(2-{e}^{{-e}^{x}})$$ . To present our contributions in this work, various experiments were conducted on different network models and datasets to evaluate the performance of Gish. With the experimental results, 98.7\% success was achieved with the EfficientNetB4 model in the MNIST dataset, 86.5\% with the EfficientNetB5 model in the CIFAR-10 dataset and 90.8\% with the EfficientNetB6 model in the SVHN dataset. The obtained performances were shown to be higher than Swish, Mish, Logish and Smish. These results confirm the effectiveness and performance of Gish.},
  archive      = {J_NCA},
  author       = {Kaytan, Mustafa and Aydilek, İbrahim Berkan and Yeroğlu, Celaleddin},
  doi          = {10.1007/s00521-023-09035-5},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24259-24281},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gish: A novel activation function for image classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constraint trajectory planning for redundant space robot.
<em>NCA</em>, <em>35</em>(34), 24243–24258. (<a
href="https://doi.org/10.1007/s00521-023-08972-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel hybrid heuristic algorithm, particle swarm optimization, and whale optimization algorithm (PSO–WOA), to solve a multi-objective optimization problem relating to point-to-point trajectory planning of space robots. First of all, the kinematics of the space robot is introduced, and the motion of each revolute joint of the manipulator is parameterized by Bézier curve. Then, contradictory objective functions are proposed, and the trajectory planning problem is transformed into a multi-objective optimization problem. The pose of the end-effector at the end of motion is set as the primary objective. The base disturbance, execution time, and manipulability of the end-effector are also taken into account. Furthermore, self-collision avoidance during the motion is also considered. The trajectory planning problem finally comes down to finding an optimal parameter of the Bézier curve for each joint. We propose a novel hybrid PSO–WOA, which is supposed to take advantages of the best of both methods: the exploration feature of the WOA and exploitation feature of the PSO. In order to enhance the performance of the PSO–WOA, the good point set and lévy flight stochastic steps are employed for the initialization and updating process, respectively. The proposed method is applied to generate an optimal trajectory for a redundant free-floating space robot. The simulation results demonstrate the effectiveness of the PSO–WOA.},
  archive      = {J_NCA},
  author       = {Li, Run and Liu, Ming and Teutsch, Johannes and Wollherr, Dirk},
  doi          = {10.1007/s00521-023-08972-5},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24243-24258},
  shortjournal = {Neural Comput. Appl.},
  title        = {Constraint trajectory planning for redundant space robot},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring unsupervised pre-training for echo state networks.
<em>NCA</em>, <em>35</em>(34), 24225–24242. (<a
href="https://doi.org/10.1007/s00521-023-08988-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo State Networks (ESNs) are a special type of Recurrent Neural Networks (RNNs), in which the input and recurrent connections are traditionally generated randomly, and only the output weights are trained. However, recent publications have addressed the problem that a purely random initialization may not be ideal. Instead, a completely deterministic or data-driven initialized ESN structure was proposed. In this work, an unsupervised training methodology for the hidden components of an ESN is proposed. Motivated by traditional Hidden Markov Models (HMMs), which have been widely used for speech recognition for decades, we present an unsupervised pre-training method for the recurrent weights and bias weights of ESNs. This approach allows for using unlabeled data during the training procedure and shows superior results for continuous spoken phoneme recognition, as well as for a large variety of time-series classification datasets.},
  archive      = {J_NCA},
  author       = {Steiner, Peter and Jalalvand, Azarakhsh and Birkholz, Peter},
  doi          = {10.1007/s00521-023-08988-x},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24225-24242},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring unsupervised pre-training for echo state networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multivariate long-time series traffic passenger flow
prediction using causal convolutional sparse self-attention
MTS-informer. <em>NCA</em>, <em>35</em>(34), 24207–24223. (<a
href="https://doi.org/10.1007/s00521-023-09003-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important part of the operation preparation process of the intelligent transportation system, the passenger flow distribution law and forecast can guide the urban rail transit to formulate a reasonable operation scheduling plan. Due to the complexity, multi-variables, and instability of traffic passenger flow data, accurate passenger flow prediction takes a lot of work. Based on a convolutional neural network, a causal convolution self-attention traffic passenger flow prediction model MTS-Informer framework is proposed. This method follows the changing law of auxiliary variables, adopts the stabilization method to reduce the instability of the original sequence, and uses the causal convolution feature to improve the ability of the model’s self-attention mechanism to extract local information from the input sequence. The weakening effect of the self-attention mechanism ensures that it can learn similarly to the differential features in the original sequence data. In addition, the stationarity detection of the original sequence data is added. The experimental results show that the fitting degree of the sample data is significantly improved, and the standard error decreases between 10 and 40\%, which verifies the effectiveness of the proposed modeling technique. It has higher prediction accuracy and operating efficiency and can provide a basis for urban traffic passenger flow prediction.},
  archive      = {J_NCA},
  author       = {Liu, Miaonan and Wang, Wei and Hu, Xianhui and Fu, Yunlai and Xu, Fujin and Miao, Xinying},
  doi          = {10.1007/s00521-023-09003-z},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24207-24223},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multivariate long-time series traffic passenger flow prediction using causal convolutional sparse self-attention MTS-informer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MOPRD: A multidisciplinary open peer review dataset.
<em>NCA</em>, <em>35</em>(34), 24191–24206. (<a
href="https://doi.org/10.1007/s00521-023-08891-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open peer review is a growing trend in academic publications. Public access to peer review data can benefit both the academic and publishing communities. It also serves as a great support to studies on review comment generation and further to the realization of automated scholarly paper review. However, most of the existing peer review datasets do not provide data that cover the whole peer review process. Apart from this, their data are not diversified enough as the data are mainly collected from the field of computer science. These two drawbacks of the currently available peer review datasets need to be addressed to unlock more opportunities for related studies. In response, we construct MOPRD, a multidisciplinary open peer review dataset. This dataset consists of paper metadata, multiple version manuscripts, review comments, meta-reviews, author’s rebuttal letters, and editorial decisions. Moreover, we propose a modular guided review comment generation method based on MOPRD. Experiments show that our method delivers better performance as indicated by both automatic metrics and human evaluation. We also explore other potential applications of MOPRD, including meta-review generation, editorial decision prediction, author rebuttal generation, and scientometric analysis. MOPRD is a strong endorsement for further studies in peer review-related research and other applications.},
  archive      = {J_NCA},
  author       = {Lin, Jialiang and Song, Jiaxin and Zhou, Zhangping and Chen, Yidong and Shi, Xiaodong},
  doi          = {10.1007/s00521-023-08891-5},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24191-24206},
  shortjournal = {Neural Comput. Appl.},
  title        = {MOPRD: A multidisciplinary open peer review dataset},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance analysis of neural network-based unified
physical layer for indoor hybrid LiFi–WiFi flying networks.
<em>NCA</em>, <em>35</em>(34), 24179–24189. (<a
href="https://doi.org/10.1007/s00521-023-09017-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent developments in unmanned aerial vehicles (UAVs) and indoor hybrid LiFi–WiFi networks (HLWNs) present a significant opportunity for creating low-cost, power-efficient, reliable, flexible, and ad-hoc HLWN-enabled indoor flying networks (IFNs). However, to efficiently operate and practically realize indoor HLWN, a unified physical layer (UniPHY) is indispensable for joint communication (control and data transfer) and sensing (e.g., localization). A UniPHY structure reduces costs and increases overall flexibility for HLWN-based IFNs. While conventional block-based wireless transceivers independently designed for LiFi and WiFi offer mediocre performance for a composite UniPHY waveform, a machine learning-based end-to-end learning framework for UniPHY can improve overall error performance and reduce the complexity of UAV transceiver hardware. Therefore, this paper proposes a novel generic end-to-end learning framework for a UniPHY system that can efficiently enable HLWN. The performance of the proposed learning framework based on deep neural networks (DNNs) and convolutional neural networks (CNNs) is investigated. Additionally, we assess the computational complexity of the proposed DNN and CNN learning frameworks. The results demonstrate that the performance of DNNs and CNNs varies depending on the considered channel model. Specifically, the analysis reveals that CNNs outperform traditional DNNs in WiFi (Rayleigh fading-based) channels. In contrast, traditional DNNs perform better than CNNs in LiFi (additive white Gaussian noise (AWGN)-based) channels.},
  archive      = {J_NCA},
  author       = {Anwar, Dil Nashin and Ahmad, Rizwana and Bany Salameh, Haythem and Elgala, Hany and Ayyash, Moussa},
  doi          = {10.1007/s00521-023-09017-7},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24179-24189},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance analysis of neural network-based unified physical layer for indoor hybrid LiFi–WiFi flying networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computationally efficient recognition of unconstrained
handwritten urdu script using BERT with vision transformers.
<em>NCA</em>, <em>35</em>(34), 24161–24177. (<a
href="https://doi.org/10.1007/s00521-023-08976-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The handwritten Urdu text recognition is a challenging area in pattern recognition and has gained much importance after the rapid emergence of several camera-based applications on portable devices, which facilitate the daily processing of plenty of images. The various challenges encountered in handwritten Urdu recognition are writer-dependent variations amongst different Urdu writers, irregular positioning of diacritics associated with a character, context sensitivity of characters, and cursive nature of Urdu script. These challenges also make it difficult to formulate a large generalized handwritten Urdu dataset. The state-of-the-art approaches proposed for the recognition of handwritten Urdu text mostly focus on implicit approaches. These approaches are error prone and do not yield significant recognition rates. The holistic approach of handwritten Urdu recognition has been least explored to date and the existing holistic approaches are complex and time consuming as they mostly rely on convolutional/recurrent neural networks or statistical methods. Hence, in this research, a novel and efficient vision transformer-based methodology using BERT architecture has been proposed to the recognition of handwritten Urdu text. The proposed approach uses convolution feature maps as word embedding in the transformer that makes full use of the powerful attention mechanism of the vision transformer to focus on a particular connected component (ligature) in handwritten Urdu text. To cover the entire Urdu corpus, we have pre-trained several benchmark handwritten Urdu datasets such as UNHD and NUST-UHWR and tested unconstrained handwritten Urdu text. In comparison with the state-of-the-art techniques, the experimental evaluation of the proposed approach reports the better results of the various performance parameters such as Ligature Error Rate (LER), precision, sensitivity, specificity, f1-score, and accuracy. The great success of the proposed approach lies in (i) the significant reduction of training time needed to train a large handwritten Urdu dataset, (ii) minimum computational complexity as there is no overhead of diacritic separation and re-association as used in most of the state-of-the-art techniques, and (iii) the proposed approach registers a new state-of-the-art LER of up to 3\% only on unconstrained handwritten Urdu text.},
  archive      = {J_NCA},
  author       = {Ganai, Aejaz Farooq and Khursheed, Farida},
  doi          = {10.1007/s00521-023-08976-1},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24161-24177},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computationally efficient recognition of unconstrained handwritten urdu script using BERT with vision transformers},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DAerosol-NTM: Applying deep learning and neural turing
machine in aerosol prediction. <em>NCA</em>, <em>35</em>(34),
24123–24159. (<a
href="https://doi.org/10.1007/s00521-023-08868-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pollution caused by aerosol (particulate matter) has a detrimental impact on urban environments, particularly in terms of socio-economic factors and public health. Aerosol particles, ranging in size from 1 nm to 100 µm, can easily penetrate organic tissues, carrying toxic gaseous compounds and minerals such as carbon monoxide, ozone, nitrogen dioxide, and sulfur dioxide. Recent advancements in neural network technology, combined with deep learning techniques, have made it possible to predict surges in aerosol pollution. In this study, we introduce DAerosol-NTM, a deep learning framework that utilizes the latest developments in neural Turing machines (NTMs) to access external memory. When compared with four baseline studies that employ multilayer perceptron (MLP), deep neural networks (DNNs), long short-term memory (LSTM), and deep LSTM (DLSTM), DAerosol-NTM significantly improves prediction accuracy by 8–31\% and precision by 46–91\% and reduces the root mean square error (RMSE) by 24–85\%. Additionally, DAerosol-NTM incorporates up to 20 years of particulate matter data in its external storage, making it the first model capable of predicting aerosol pollution surges. By analyzing the data from the previous 96 h, the optimal time interval before and after the aerosol event (TIBAAE) enables the prediction of aerosol events within the following 24 h.},
  archive      = {J_NCA},
  author       = {Asaei-Moamam, Zahra-Sadat and Safi-Esfahani, Faramraz and Mirjalili, Seyedali and Mohammadpour, Reza and Nadimi-Shahraki, Mohamad-Hosein},
  doi          = {10.1007/s00521-023-08868-4},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24123-24159},
  shortjournal = {Neural Comput. Appl.},
  title        = {DAerosol-NTM: Applying deep learning and neural turing machine in aerosol prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnosis of breast cancer molecular subtypes using machine
learning models on unimodal and multimodal datasets. <em>NCA</em>,
<em>35</em>(34), 24109–24121. (<a
href="https://doi.org/10.1007/s00521-023-09005-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is a significant global health concern, with millions of cases and deaths each year. Accurate diagnosis is critical for timely treatment and medication. Machine learning techniques have shown promising results in detecting breast cancer. Previous studies have primarily used single-modality data for breast cancer diagnosis. Hence, this work aims to mobilize the benefits of multimodal data over unimodality samples. This study proposes a custom deep learning-based model pipeline that works over this multimodal data. This work has been separated into three phases. Phase 1 and Phase 2 under the unimodal category examine gene expression data and histopathological images separately. The Cancer Genome Atlas makes these datasets available. In Phase 3, the proposed pipeline operates on both data types’ samples for each patient in the multimodal category. This study investigates how data pre-processing (cleaning, transformation, reduction) and cascaded filtering affect model performance. Precision, recall, f1-score, and accuracy assessed the models, whereas L2 regularization, exponentially weighted moving average, and transfer learning minimized over-fitting. A custom deep neural network and support vector machine obtained 86\% accuracy in Phase 1, whereas the VGG16 model reached 80.21\% accuracy in Phase 2. In Phase 3, the curated multimodal dataset was applied to a custom deep learning pipeline (VGG16 backbone with hyper-tuned machine learning models as head classifiers) to achieve 94\% accuracy, demonstrating the importance of multimodal data over unimodal in breast cancer subtype classification. These findings highlight the importance of multimodal data for breast cancer diagnosis and subtype prediction.},
  archive      = {J_NCA},
  author       = {Rani, Samta and Ahmad, Tanvir and Masood, Sarfaraz and Saxena, Chandni},
  doi          = {10.1007/s00521-023-09005-x},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24109-24121},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diagnosis of breast cancer molecular subtypes using machine learning models on unimodal and multimodal datasets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). POC-net: Pelican optimization-based convolutional neural
network for recognizing large pose variation from video. <em>NCA</em>,
<em>35</em>(34), 24091–24107. (<a
href="https://doi.org/10.1007/s00521-023-08953-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, face recognition using video surveillance systems becomes one of the active research topics in security domains. Security plays a significant role in everyday life for secure and sustainable developments of smart cities. The conventional techniques provide efficient recognition results only when the faces are captured with complete face images. However, they suffer to handle large pose variation images extracted from video sequences. Therefore, to deal with this issue, this paper specially designed a multidimensional face recognition model to recognize faces under multiple pose variations and angles. Three face video databases, namely facesurv database, IARPA Janus benchmark database and McGill database, are utilized for experimental evaluation. The videos of these three databases are converted into number of image frames through background subtraction process. From the image frames, the large pose variation images with different angles are identified and selected to process further. The video recorded under dynamic environment conditions diminishes recognition performance, so the image frames are processed through several preprocessing pipelines. The preprocessed images are then fed into the proposed optimal mask region-based convolutional neural network with modified short-term memory (OMRCNN-MBiLSTM) model, which learns the facial patterns present in the images more efficiently. The feature vectors learned by the proposed classifier are matched with the input face database to determine the identity of the person. With the ability to handle multiview and large pose variations, the proposed model accurately recognizes faces. The simulation result manifests the superiority of proposed model over other existing methods.},
  archive      = {J_NCA},
  author       = {Jayabharathi, P. and Suresh, A.},
  doi          = {10.1007/s00521-023-08953-8},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24091-24107},
  shortjournal = {Neural Comput. Appl.},
  title        = {POC-net: Pelican optimization-based convolutional neural network for recognizing large pose variation from video},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Q-learning whale optimization algorithm for test suite
generation with constraints support. <em>NCA</em>, <em>35</em>(34),
24069–24090. (<a
href="https://doi.org/10.1007/s00521-023-09000-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new variant of a metaheuristic algorithm based on the whale optimization algorithm (WOA), the Q-learning algorithm and the Exponential Monte Carlo Acceptance Probability called (QWOA-EMC). Unlike WOA, QWOA-EMC permits just-in-time adaptive selection of its operators (i.e., between shrinking mechanism, spiral shape mechanism, and random generation) based on their historical performances as well as exploits the Monte Carlo Acceptance probability to further strengthen its exploration capabilities by allowing a poor performing operator to be reselected with probability in the early part of the iteration. Experimental results for constraints combinatorial test generation demonstrate that the proposed QWOA-EMC outperforms WOA and performs competitively against other metaheuristic algorithms.},
  archive      = {J_NCA},
  author       = {Hassan, Ali Abdullah and Abdullah, Salwani and Zamli, Kamal Z. and Razali, Rozilawati},
  doi          = {10.1007/s00521-023-09000-2},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24069-24090},
  shortjournal = {Neural Comput. Appl.},
  title        = {Q-learning whale optimization algorithm for test suite generation with constraints support},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The use of generative adversarial networks in medical image
augmentation. <em>NCA</em>, <em>35</em>(34), 24055–24068. (<a
href="https://doi.org/10.1007/s00521-023-09100-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) have been widely applied in various domains, including medical image analysis. GANs have been utilized in classification and segmentation tasks, aiding in the detection and diagnosis of diseases and disorders. However, medical image datasets often suffer from insufficiency and imbalanced class distributions. To overcome these limitations, researchers have employed GANs to generate augmented medical images, effectively expanding datasets and balancing class distributions. This review follows the PRISMA guidelines and systematically collects peer-reviewed articles on the development of GAN-based augmentation models. Automated searches were conducted on electronic databases such as IEEE, Scopus, Science Direct, and PubMed, along with forward and backward snowballing. Out of numerous articles, 52 relevant ones published between 2018 and February 2022 were identified. The gathered information was synthesized to determine common GAN architectures, medical image modalities, body organs of interest, augmentation tasks, and evaluation metrics employed to assess model performance. Results indicated that cGAN and DCGAN were the most popular GAN architectures in the reviewed studies. Medical image modalities such as MRI, CT, X-ray, and ultrasound, along with body organs like the brain, chest, breast, and lung, were frequently used. Furthermore, the developed models were evaluated, and potential challenges and future directions for GAN-based medical image augmentation were discussed. This review presents a comprehensive overview of the current state-of-the-art in GAN-based medical image augmentation and emphasizes the potential advantages and challenges associated with GAN utilization in this domain.},
  archive      = {J_NCA},
  author       = {Makhlouf, Ahmed and Maayah, Marina and Abughanam, Nada and Catal, Cagatay},
  doi          = {10.1007/s00521-023-09100-z},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24055-24068},
  shortjournal = {Neural Comput. Appl.},
  title        = {The use of generative adversarial networks in medical image augmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel deep transfer learning framework with adversarial
domain adaptation: Application to financial time-series forecasting.
<em>NCA</em>, <em>35</em>(34), 24037–24054. (<a
href="https://doi.org/10.1007/s00521-023-09047-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial market prediction is generally regarded as one of the most challenging tasks in data mining. Recent deep learning models have achieved success in improving the accuracy of financial time-series forecasting (TSF), but as implicit complex information, and there have few available labeled data, the generalization capability of current benchmarks is poor in this field. To alleviate the restriction of overfitting caused by insufficient clean data, a novel deep transfer learning framework incorporating adversarial domain adaptation is proposed for financial TSF task, dubbed as ADA-FTSF for short, in improving reliable, accurate and competitive deep forecasting models. Concretely, we implement a typical adversarial domain adaptation architecture to transfer feature knowledge and reduce the distribution discrepancy between financial datasets. To reduce the shape difference during the pre-train process, a smoothed formulation of dynamic time warping (DTW) is also introduced tactfully in adversarial training phase to measure the shape loss. Notably, the confident selection of source domain from potential source datasets will make significant impact on forecasting performance. In our study, appropriate source dataset is selected using temporal causal discovery method via transfer entropy derived from copula entropy. The feasibility and effectiveness of the proposed framework are validated by the empirical experiments, ablation study, Diebold–Mariano test and parameter sensitivity analysis conducting on different financial datasets of three domains (financial indexes, energy futures and agricultural futures).},
  archive      = {J_NCA},
  author       = {Zhang, Dabin and Lin, Ruibin and Wei, Tingting and Ling, Liwen and Huang, Junjie},
  doi          = {10.1007/s00521-023-09047-1},
  journal      = {Neural Computing and Applications},
  number       = {34},
  pages        = {24037-24054},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel deep transfer learning framework with adversarial domain adaptation: Application to financial time-series forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An integrated fuzzy neural supervision and attention-based
graph neural network for improving network clustering. <em>NCA</em>,
<em>35</em>(33), 24015–24035. (<a
href="https://doi.org/10.1007/s00521-023-08974-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, graph neural network (GNN) and auto-encoding (AE) have been widely utilized in multiple data mining problems. These architectures have demonstrated powers in data high-dimensional embedding for improving the performance of various task-driven learning tasks, like as clustering. However, most of recent GNN-based cluster techniques still suffered several limitations. These limitations are related to the capability of simultaneously preserving the low-levelled latent feature and global structural representations of the given network/graph. These view-varied graph representations can help to improve the performance of multi-scaled clustering task. Moreover, the achieved multi-viewed structural node embeddings which are learnt by GNN-based architectures might also involve with problems. These problems are related to feature noise and data uncertainty. These feature noise/uncertainties are occurred within representation learning process. These limitations can directly lead to the downgrade in the accuracy performance for clustering tasks. To overcome existing limitations, within this paper, we proposed a novel fuzzy-driven noise-reduced attention-based graph auto-encoding mechanism for network clustering, called as: FAGC. In general, our proposed FAGC model is as an attention-driven multi-layered graph-based AE architecture which is integrated with a custom de-noising fuzzy neural network. In our proposed FAGC model, we integrate the fuzzy neural network with GNN to eliminate problems which are related to the feature uncertainty and noise occurrence during the graph representation learning process. Later, the better quality as well as rich-structural network representations which are generated from our FAGC model are utilized to achieve state-of-the-art performances for the network clustering problem. The extensive experiments within benchmark networked datasets and comparative studies demonstrated the effectiveness and outperformance of our proposed FAGC model in comparing with state-of-the-art graph embedding techniques.},
  archive      = {J_NCA},
  author       = {Vo, Tham},
  doi          = {10.1007/s00521-023-08974-3},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {24015-24035},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated fuzzy neural supervision and attention-based graph neural network for improving network clustering},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A gradient boosting-based mortality prediction model for
COVID-19 patients. <em>NCA</em>, <em>35</em>(33), 23997–24013. (<a
href="https://doi.org/10.1007/s00521-023-08997-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has been a global public health concern since March 11, 2020. Healthcare systems struggled to meet patients’ growing needs for diagnosis, treatment, and care. As healthcare industries struggled to cope with the overwhelming demands, advanced intelligence and computing technologies have become essential. Artificial intelligence techniques have become essential for identifying and triaging patients, predicting disease severity, and detecting outcomes. The aim of the paper is to propose a gradient boosting-based model to predict the mortality of COVID-19 patients and to improve the prediction accuracy by incorporating resampling strategies. A real COVID-19 data that includes patients’ travel, health, geographical, and demographic information is obtained from a public repository. The dataset used in the study has the class imbalance problem, and several approaches are applied to solve the problem. In this study, a gradient boosting-based model for predicting the mortality of COVID-19 patients is proposed. This approach incorporates resampling strategies, such as synthetic minority oversampling technique (SMOTE), random under-sampling, and clustering-based under-sampling, to address the imbalanced class distribution problem in the dataset. Then, gradient boosting machines (GBM) such as extreme gradient boosting (XGBoost), light gradient boosting machine (LightGBM), and categorical boosting (CatBoost) are analyzed in terms of accuracy and computational time. Random search method is used to find the optimal hyper-parameters for the algorithms. A stacking-based hybrid model that combines the XGBoost, LightGBM, and CatBoost algorithms was used for comparison in the experiments. In the experiments, the factors that can influence the mortality of COVID-19 patients are investigated. And, it is found that the age of the patient, whether the patient belonged to Wuhan, the difference between when they first noticed symptoms and when they visited the hospital (in days) affect the mortality. By utilizing over/under-sampling approaches, we ameliorated the concern of class imbalance. XGBoost, LightGBM, and CatBoost are effectively analyzed in terms of various performance metrics to determine the suitable GBM for the proposed system. The experimental results revealed that the stacking-based hybrid model performs well with the balanced dataset provided by SMOTE. CatBoost produces superior results for a balanced dataset with random under-sampling and clustering-based under-sampling. The main focus of the study is to propose a gradient boosting-based model for predicting the mortality of COVID-19 patients. This study also emphasizes the importance of addressing the imbalanced class distribution problem in the dataset and incorporates resampling strategies to improve the prediction accuracy. Our promising result confirms the success of the proposed system in predicting mortality of COVID-19 disease.},
  archive      = {J_NCA},
  author       = {Keser, Sinem Bozkurt and Keskin, Kemal},
  doi          = {10.1007/s00521-023-08997-w},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23997-24013},
  shortjournal = {Neural Comput. Appl.},
  title        = {A gradient boosting-based mortality prediction model for COVID-19 patients},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning-based robust optimal tracking control
for disturbed nonlinear systems. <em>NCA</em>, <em>35</em>(33),
23987–23996. (<a
href="https://doi.org/10.1007/s00521-023-08993-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concludes a robust optimal tracking control law for a class of nonlinear systems. A characteristic of this paper is that the designed controller can guarantee both robustness and optimality under nonlinearity and mismatched disturbances. Optimal controllers for nonlinear systems are difficult to obtain, hence a reinforcement learning method is adopted with two neural networks (NNs) approximating the cost function and optimal controller, respectively. We designed weight update laws for critic NN and actor NN based on gradient descent and stability, respectively. In addition, matched and mismatched disturbances are estimated by fixed-time disturbance observers and an artful transformation based on backstepping method is employed to convert the system into a filtered error nonlinear system. Through a rigorous analysis using the Lyapunov method, we demonstrate states and estimation errors remain uniformly ultimately bounded. Finally, the effectiveness of the proposed method is verified through two illustrative examples.},
  archive      = {J_NCA},
  author       = {Fan, Zhong-Xin and Tang, Lintao and Li, Shihua and Liu, Rongjie},
  doi          = {10.1007/s00521-023-08993-0},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23987-23996},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement learning-based robust optimal tracking control for disturbed nonlinear systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SCAU-net: 3D self-calibrated attention u-net for brain tumor
segmentation. <em>NCA</em>, <em>35</em>(33), 23973–23985. (<a
href="https://doi.org/10.1007/s00521-023-08872-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, U-Net architecture with its strong adaptability has become prevalent in the field of MRI brain tumor segmentation. Meanwhile, researchers have demonstrated that introducing attention mechanisms, especially self-attention, into U-Net can effectively improve the performance of segmentation models. However, the self-attention has disadvantages of heavy computational burden, quadratic complexity as well as ignoring the potential correlations between different samples. Besides, current attention segmentation models seldom focus on adaptively computing the receptive field of tumor images that may capture discriminant information effectively. To address these issues, we propose a novel 3D U-Net related brain tumor segmentation model dubbed as self-calibrated attention U-Net (SCAU-Net) in this work, which simultaneously introduces two lightweight modules, i.e., external attention module and self-calibrated convolution module, into a single U-Net. More specifically, SCAU-Net embeds the external attention into the skip connection to better utilize encoding features for semantic up-sampling, and it leverages several 3D self-calibrated convolution modules to replace the original convolution layers, which adaptively computes the receptive field of tumor images for effective segmentation. SCAU-Net achieves segmentation results on the BraTS 2020 validation dataset with the dice similarity coefficient of 0.905, 0.821 and 0.781 and the 95\% Hausdorff distance (HD95) of 4.0, 9.7 and 29.3 on the whole tumor, tumor core and enhancing tumor, respectively. Similarly, competitive results are obtained on BraTS 2018 and BraTS 2019 validation datasets. Experimental results demonstrate that SCAU-Net outperforms its baseline and achieves outstanding performance compared to various representative brain tumor models.},
  archive      = {J_NCA},
  author       = {Liu, Dongwei and Sheng, Ning and Han, Yutong and Hou, Yaqing and Liu, Bin and Zhang, Jianxin and Zhang, Qiang},
  doi          = {10.1007/s00521-023-08872-8},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23973-23985},
  shortjournal = {Neural Comput. Appl.},
  title        = {SCAU-net: 3D self-calibrated attention U-net for brain tumor segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated detecting and severity grading of diabetic
retinopathy using transfer learning and attention mechanism.
<em>NCA</em>, <em>35</em>(33), 23959–23971. (<a
href="https://doi.org/10.1007/s00521-023-09001-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a common retinal complication led by diabetes over the years, considered a cause of vision loss. Its timely identification is crucial to prevent blindness, requiring expert humans to analyze digital color fundus images. Hence, it is a time-consuming and expensive process. In this study, we propose a model named Attention-DenseNet for detecting and severity grading of DR. We apply a pre-trained convolutional neural network to extract features and get a hierarchical representation of color fundus images. What is essential for the correct diagnosis of DR is to recognize all the retinal lesions and discriminative regions. However, convolutional neural networks may overlook some tiny lesions of color fundus images. So, we use an attention model to solve this issue, which helps the model focus more on distinctive areas than others. We use APTOS 2019 dataset and fivefold cross-validation to assess the model&#39;s performance. The method achieves an overall accuracy of 98.44\%, an area under receiver operating characteristic curve of 99.55\%, and quadratic weighted kappa of 96.88\% for the detection task, and an overall accuracy of 83.69\%, an area under receiver operating characteristic curve of 97\%, and quadratic weighted kappa of 89.26\% for grading task. Our experimental results indicate that the model is superior to recent studies and can be suitable for DR classification in real life, especially for DR detection.},
  archive      = {J_NCA},
  author       = {Dinpajhouh, Maryam and Seyyedsalehi, Seyyed Ali},
  doi          = {10.1007/s00521-023-09001-1},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23959-23971},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated detecting and severity grading of diabetic retinopathy using transfer learning and attention mechanism},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accuracy improvement in ag: A-si memristive synaptic
device-based neural network through adadelta learning method on
handwritten-digit recognition. <em>NCA</em>, <em>35</em>(33),
23943–23958. (<a
href="https://doi.org/10.1007/s00521-023-08995-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional computing architecture (Von Neumann) that requires data transfer between the off-chip memory and processor consumes a large amount of energy when running machine learning (ML) models. Memristive synaptic devices are employed to eliminate this inevitable inefficiency in energy while solving cognitive tasks. However, the performances of energy-efficient neuromorphic systems, which are expected to provide promising results, need to be enhanced in terms of accuracy and test error rates for classification applications. Improving accuracy in such ML models depends on the optimal learning parameter changes from a device to algorithm-level optimisation. To do this, this paper considers the Adadelta, an adaptive learning rate technique, to achieve accurate results by reducing the losses and compares the accuracy, test error rates, and energy consumption of stochastic gradient descent (SGD), Adagrad and Adadelta optimisation methods integrated into the Ag:a-Si synaptic device neural network model. The experimental results demonstrated that Adadelta enhanced the accuracy of the hardware-based neural network model by up to 4.32\% when compared to the Adagrad method. The Adadelta method achieved the best accuracy rate of 94\%, while DGD and SGD provided an accuracy rate of 68.11 and 75.37\%, respectively. These results show that it is vital to select a proper optimisation method to enhance performance, particularly the accuracy and test error rates of the neuro-inspired nano-synaptic device-based neural network models.},
  archive      = {J_NCA},
  author       = {Yilmaz, Yildiran},
  doi          = {10.1007/s00521-023-08995-y},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23943-23958},
  shortjournal = {Neural Comput. Appl.},
  title        = {Accuracy improvement in ag: A-si memristive synaptic device-based neural network through adadelta learning method on handwritten-digit recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utilizing social media and machine learning for personality
and emotion recognition using PERS. <em>NCA</em>, <em>35</em>(33),
23927–23941. (<a
href="https://doi.org/10.1007/s00521-023-08962-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personality reflects how people can behave in different situations and affects their decisions. Analyzing personality is useful in many fields, for example in the prediction of performance in a job. Emotion recognition is another important research topic due to the wide spread of social media. People express their feeling in form of Facebook posts, tweeter real reactions, and shares. Understanding both personality and emotions from the written text is much easier when it comes to humans. However, this task is impossible with the huge amount of data spread all other social media. The use of machine learning algorithms for personality and emotion recognition from text data is a new research field. In this paper, we propose an enhanced recognition system for personality recognition and emotion recognition. The proposed enhanced recognition system is composed of four main modules, namely data acquisition module, data preprocessing module, personality recognition module, and emotion recognition module. Several machine learning algorithms are used for the multiclass classification process. Gray wolf optimization (GWO) algorithm is used for hyperparameter optimization, while group GWO (GGWO) algorithm is used for feature selection. The proposed model could achieve an accuracy of 99.99\% using the random forest algorithm for personality detection and 88.06\% using a decision tree for emotion recognition, which outperforms other state-of-the-art studies. We can profit from social media despite some of its drawbacks by understanding people&#39;s emotions through their tweets, posts, etc. For instance, before someone commits suicide, we can tell what their intentions are. Most suicide committers, according to recent studies, leave suicide notes on their social media accounts, and these letters need to be taken seriously.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and El-Gendy, Eman M. and Saafan, Mahmoud M. and Gamel, Samah A.},
  doi          = {10.1007/s00521-023-08962-7},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23927-23941},
  shortjournal = {Neural Comput. Appl.},
  title        = {Utilizing social media and machine learning for personality and emotion recognition using PERS},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review of age and gender detection methods based on
handwriting analysis. <em>NCA</em>, <em>35</em>(33), 23909–23925. (<a
href="https://doi.org/10.1007/s00521-023-08996-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwriting recognition and analysis has been an active area of research in the last two decades. Handwriting analysis is being studied in various fields of science, such as graphology, neurology, psychology, and computer science. Furthermore, automated handwriting analysis has several applications, including forensic, security, medical, and disease prediction. This paper presents the most recent handwriting analysis techniques and advancements available in the literature for age and gender classification/detection. Different steps, including feature extraction and classification, frequently used in the literature for age and gender detection, are discussed, and the presented works are classified according to the applied feature extraction and classification methods. The online and offline benchmark databases are also reviewed. We used a text mining technique to perform a quantitative content analysis of the presented research and better understand the co-occurrence network diagrams of age and gender classification/detection. This study is a valuable resource that provides new research directions to students and researchers interested in this field for further research and investigation.},
  archive      = {J_NCA},
  author       = {Alaei, Fahimeh and Alaei, Alireza},
  doi          = {10.1007/s00521-023-08996-x},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23909-23925},
  shortjournal = {Neural Comput. Appl.},
  title        = {Review of age and gender detection methods based on handwriting analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HTwitt: A hadoop-based platform for analysis and
visualization of streaming twitter data. <em>NCA</em>, <em>35</em>(33),
23893–23908. (<a
href="https://doi.org/10.1007/s00521-021-06046-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twitter produces a massive amount of data due to its popularity that is one of the reasons underlying big data problems. One of those problems is the classification of tweets due to use of sophisticated and complex language, which makes the current tools insufficient. We present our framework HTwitt, built on top of the Hadoop ecosystem, which consists of a MapReduce algorithm and a set of machine learning techniques embedded within a big data analytics platform to efficiently address the following problems: (1) traditional data processing techniques are inadequate to handle big data; (2) data preprocessing needs substantial manual effort; (3) domain knowledge is required before the classification; (4) semantic explanation is ignored. In this work, these challenges are overcome by using different algorithms combined with a Naïve Bayes classifier to ensure reliability and highly precise recommendations in virtualization and cloud environments. These features make HTwitt different from others in terms of having an effective and practical design for text classification in big data analytics. The main contribution of the paper is to propose a framework for building landslide early warning systems by pinpointing useful tweets and visualizing them along with the processed information. We demonstrate the results of the experiments which quantify the levels of overfitting in the training stage of the model using different sizes of real-world datasets in machine learning phases. Our results demonstrate that the proposed system provides high-quality results with a score of nearly 95\% and meets the requirement of a Hadoop-based classification system.},
  archive      = {J_NCA},
  author       = {Demirbaga, Umit},
  doi          = {10.1007/s00521-021-06046-y},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23893-23908},
  shortjournal = {Neural Comput. Appl.},
  title        = {HTwitt: A hadoop-based platform for analysis and visualization of streaming twitter data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid weighted fuzzy approach for brain tumor
segmentation using MR images. <em>NCA</em>, <em>35</em>(33),
23877–23891. (<a
href="https://doi.org/10.1007/s00521-021-06010-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human brain tumor detection and classification are time-consuming however vital tasks for any medical expert. Assistance via computer aided diagnosis is commonly used to enhance diagnosis capabilities attaining maximum detection accuracy. Despite significant research, brain tumor segmentation is still an open challenge due to variability in image modality, contrast, tumor type, and other factors. Many great works ranging from manual, semiautomatic, or fully automatic tumor segmentation with magnetic resonance (MR) brain images are available, however, still creating a space for developing efficient and accurate approaches in this domain. This manuscript proposes a hybrid weighted fuzzy k-means (WFKM) brain tumor segmentation algorithm using MR images to retrieve more meaningful clusters. It is based on fuzzification of weights which works on spatial context with illumination penalize membership approach which helps in settling issues with pixel’s multiple memberships as well as exponential increase in number of iterations. The segmented image is further utilized for successful tumor type identification as benign or malignant by means of SVM. Experimentation performed on MR images using Digital Imaging and Communications in Medicine (DICOM) dataset shows that fusion of proposed WFKM and SVM outperforms many existing approaches. Further, performance evaluation parameters show that the proposal produces better overall accuracy. Results on variety of images further prove applicability of the proposal in detecting ranges and shapes of brain tumor. The proposed approach excels qualitatively as well as quantitatively reporting an average accuracy of 97\% on DICOM dataset with total number of images varying from 100 to 1000.},
  archive      = {J_NCA},
  author       = {Chahal, Prabhjot Kaur and Pandey, Shreelekha},
  doi          = {10.1007/s00521-021-06010-w},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23877-23891},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid weighted fuzzy approach for brain tumor segmentation using MR images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Triage of potential COVID-19 patients from chest x-ray
images using hierarchical convolutional networks. <em>NCA</em>,
<em>35</em>(33), 23861–23876. (<a
href="https://doi.org/10.1007/s00521-020-05641-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current COVID-19 pandemic has motivated the researchers to use artificial intelligence techniques for a potential alternative to reverse transcription-polymerase chain reaction due to the limited scale of testing. The chest X-ray (CXR) is one of the alternatives to achieve fast diagnosis, but the unavailability of large-scale annotated data makes the clinical implementation of machine learning-based COVID detection difficult. Another issue is the usage of ImageNet pre-trained networks which does not extract reliable feature representations from medical images. In this paper, we propose the use of hierarchical convolutional network (HCN) architecture to naturally augment the data along with diversified features. The HCN uses the first convolution layer from COVIDNet followed by the convolutional layers from well-known pre-trained networks to extract the features. The use of the convolution layer from COVIDNet ensures the extraction of representations relevant to the CXR modality. We also propose the use of ECOC for encoding multiclass problems to binary classification for improving the recognition performance. Experimental results show that HCN architecture is capable of achieving better results in comparison with the existing studies. The proposed method can accurately triage potential COVID-19 patients through CXR images for sharing the testing load and increasing the testing capacity.},
  archive      = {J_NCA},
  author       = {Dev, Kapal and Khowaja, Sunder Ali and Bist, Ankur Singh and Saini, Vaibhav and Bhatia, Surbhi},
  doi          = {10.1007/s00521-020-05641-9},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23861-23876},
  shortjournal = {Neural Comput. Appl.},
  title        = {Triage of potential COVID-19 patients from chest X-ray images using hierarchical convolutional networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic traffic forecasting and fuzzy-based optimized
admission control in federated 5G-open RAN networks. <em>NCA</em>,
<em>35</em>(33), 23841–23859. (<a
href="https://doi.org/10.1007/s00521-021-06206-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing connectivity to high-density traffic demand is one of the key promises of future wireless networks. The open radio access network (O-RAN) is one of the critical drivers ensuring such connectivity in heterogeneous networks. Despite intense interest from researchers in this domain, key challenges remain to ensure efficient network resource allocation and utilization. This paper proposes a dynamic traffic forecasting scheme to predict future traffic demand in federated O-RAN. Utilizing information on user demand and network capacity, we propose a fully reconfigurable admission control framework via fuzzy-logic optimization. We also perform detailed analysis on several parameters (user satisfaction level, utilization gain, and fairness) over benchmarks from various papers. The results show that the proposed forecasting and fuzzy-logic-based admission control framework significantly enhances fairness and provides guaranteed quality of experience without sacrificing resource utilization. Moreover, we have proven that the proposed framework can accommodate a large number of devices connected simultaneously in the federated O-RAN.},
  archive      = {J_NCA},
  author       = {Perveen, Abida and Abozariba, Raouf and Patwary, Mohammad and Aneiba, Adel},
  doi          = {10.1007/s00521-021-06206-0},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23841-23859},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic traffic forecasting and fuzzy-based optimized admission control in federated 5G-open RAN networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). N-semble-based method for identifying parkinson’s disease
genes. <em>NCA</em>, <em>35</em>(33), 23829–23839. (<a
href="https://doi.org/10.1007/s00521-021-05974-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) genes identification plays an important role in improving the diagnosis and treatment of the disease. A number of machine learning methods have been proposed to identify disease-related genes, but only few of these methods are adopted for PD. This work puts forth a novel neural network-based ensemble (n-semble) method to identify Parkinson’s disease genes. The artificial neural network is trained in a unique way to ensemble the multiple model predictions. The proposed n-semble method is composed of four parts: (1) protein sequences are used to construct feature vectors using physicochemical properties of amino acid; (2) dimensionality reduction is achieved using the t-Distributed Stochastic Neighbor Embedding (t-SNE) method, (3) the Jaccard method is applied to find likely negative samples from unknown (candidate) genes, and (4) gene prediction is performed with n-semble method. The proposed n-semble method has been compared with Smalter’s, ProDiGe, PUDI and EPU methods using various evaluation metrics. It has been concluded that the proposed n-semble method outperforms the existing gene identification methods over the other methods and achieves significantly higher precision, recall and F Score of 88.9\%, 90.9\% and 89.8\%, respectively. The obtained results confirm the effectiveness and validity of the proposed framework.},
  archive      = {J_NCA},
  author       = {Arora, Priya and Mishra, Ashutosh and Malhi, Avleen},
  doi          = {10.1007/s00521-021-05974-z},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23829-23839},
  shortjournal = {Neural Comput. Appl.},
  title        = {N-semble-based method for identifying parkinson’s disease genes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid NN-based green cognitive radio sensor networks for
next-generation IoT. <em>NCA</em>, <em>35</em>(33), 23819–23827. (<a
href="https://doi.org/10.1007/s00521-021-05700-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In any cognitive radio sensor networks (CRSNs), the secondary users (SUs) and primary users (PUs) share the opportunity to use the authorized frequency band. Here, the SU nodes can only transmit in the temporarily idle spectrum when it is not in use by any PU nodes. The proper estimation and detection of primary nodes are important for the energy-efficient spectrum access. The work basically presents a state of the art in implementing Bayesian-based convolutional neural network (CNN) for addressing the issue of energy constraints in next-generation Internet of things (Nx-IoT) using CRSN. Initially, we use blind source separation to extract the energy features and cyclic spectrum features of the signal and carry on the asymptotic autocorrelation calculation to the extracted signal. Finally, we construct the corresponding training set for CNN training and establish a suitable spectrum sensing model for Nx-IoT. Theoretical analysis and simulation results validate a suitable B-CNN spectrum sensing model along with energy-efficient cooperative communication between the SU nodes.},
  archive      = {J_NCA},
  author       = {Mukherjee, Amrit and Li, Manman and Goswami, Pratik and Yang, Lixia and Garg, Sahil and Piran, Md. Jalil},
  doi          = {10.1007/s00521-021-05700-9},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23819-23827},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid NN-based green cognitive radio sensor networks for next-generation IoT},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep reinforcement learning-based algorithm for
reliability-aware multi-domain service deployment in smart ecosystems.
<em>NCA</em>, <em>35</em>(33), 23795–23817. (<a
href="https://doi.org/10.1007/s00521-020-05372-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transition towards full network virtualization will see services for smart ecosystems including smart metering, healthcare and transportation among others, being deployed as Service Function Chains (SFCs) comprised of an ordered set of virtual network functions. However, since such services are usually deployed in remote cloud networks, the SFCs may transcend multiple domains belonging to different Infrastructure Providers (InPs), possibly with differing policies regarding billing and Quality-of-service (QoS) guarantees. Therefore, efficiently allocating the exhaustible network resources to the different SFCs while meeting the stringent requirements of the services such as delay and QoS among others, remains a complex challenge, especially under limited information disclosure by the InPs. In this work, we formulate the SFC deployment problem across multiple domains focusing on delay constraints, and propose a framework for SFC orchestration which adheres to the privacy requirements of the InPs. Then, we propose a reinforcement learning (RL)-based algorithm for partitioning the SFC request across the different InPs while considering service reliability across the participating InPs. Such RL-based algorithms have the intelligence to infer undisclosed InP information from historical data obtained from past experiences. Simulation results, considering both online and offline scenarios, reveal that the proposed algorithm results in up to 10\% improvement in terms of acceptance ratio and provisioning cost compared to the benchmark algorithms, with up to more than 90\% saving in execution time for large networks. In addition, the paper proposes an enhancement to a state-of-the-art algorithm which results in up to 5\% improvement in terms of provisioning cost.},
  archive      = {J_NCA},
  author       = {Kibalya, Godfrey and Serrat, Joan and Gorricho, Juan-Luis and Okello, Dorothy and Zhang, Peiying},
  doi          = {10.1007/s00521-020-05372-x},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23795-23817},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep reinforcement learning-based algorithm for reliability-aware multi-domain service deployment in smart ecosystems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven management for fuzzy sewage treatment processes
using hybrid neural computing. <em>NCA</em>, <em>35</em>(33),
23781–23794. (<a
href="https://doi.org/10.1007/s00521-020-05655-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing public attention on sustainable development and green ecosystems, the efficient management of fuzzy sewage treatment processes (FSTPs) has been a major concern in academia. Characterized by strong abstraction and analysis abilities, data mining technologies provide a novel perspective to solve this problem. In recent years, data-driven management for FSTP has been widely investigated, resulting in a number of typical approaches. However, almost all existing technical approaches consider FSTP a unidirectional, sequential process, ignoring the bidirectional temporality caused by backflow operations. Therefore, we propose a data-driven management mechanism for FSTP based on hybrid neural computing (IM-HNC for short). This mechanism attempts to capture the bidirectional time-series features of FSTP with the aid of a bidirectional long short-term memory model, and further introduces a convolutional neural network to construct feature spaces with a stronger expression capability. Empirically, we implement a series of experiments on three datasets under different parameter settings to test the efficiency and robustness of the proposed IM-HNC. The experimental results manifest that the IM-HNC has an average performance improvement of approximately 5\% compared to the baselines.},
  archive      = {J_NCA},
  author       = {Zeng, Wenru and Guo, Zhiwei and Shen, Yu and Bashir, Ali Kashif and Yu, Keping and Al-Otaibi, Yasser D. and Gao, Xu},
  doi          = {10.1007/s00521-020-05655-3},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23781-23794},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-driven management for fuzzy sewage treatment processes using hybrid neural computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting users’ behavior using mouse movement information:
An information foraging theory perspective. <em>NCA</em>,
<em>35</em>(33), 23767–23780. (<a
href="https://doi.org/10.1007/s00521-020-05306-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of users’ behavior is essential for keeping useful information on the web. Previous studies have used mouse cursor information in web usability evaluation and designing user-oriented search interfaces. However, we know fairly to a small extent pertaining to user behavior, specifically clicking and navigating behavior, for prolonged search session illustrating sophisticated search norms. In this study, we perform extensive analysis on a mouse movement activities dataset to capture every users’ movement pattern using the effects of information foraging theory (IFT). The mouse cursor movement information dataset includes the timing and positioning information of mouse cursors collected from several users in different sessions. The tasks vary in two dimensions: (1) to determine the interactive elements (i.e., information episodes) of user interaction with the site; (2) adopt these findings to predict users’ behavior by exploiting the LSTM model. Our model is developed to find the main patterns of the user’s movement on the site and simulate the behavior of users’ mouse movement on any website. We validate our approach on a mouse movement dataset with a rich collection of time and position information of mouse pointers in which searchers and websites are annotated by web foragers and information patches, respectively. Our evaluation shows that the proposed IFT-based effects provide an LSTM model a more accurate interpretative exposition of all the patterns in the movement of the users’ mouse cursors across the screen.},
  archive      = {J_NCA},
  author       = {Jaiswal, Amit Kumar and Tiwari, Prayag and Hossain, M. Shamim},
  doi          = {10.1007/s00521-020-05306-7},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23767-23780},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting users’ behavior using mouse movement information: An information foraging theory perspective},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards design and implementation of industry 4.0 for food
manufacturing. <em>NCA</em>, <em>35</em>(33), 23753–23765. (<a
href="https://doi.org/10.1007/s00521-021-05726-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s factories are considered as smart ecosystems with humans, machines and devices interacting with each other for efficient manufacturing of products. Industry 4.0 is a suite of enabler technologies for such smart ecosystems that allow transformation of industrial processes. When implemented, Industry 4.0 technologies have a huge impact on efficiency, productivity and profitability of businesses. The adoption and implementation of Industry 4.0, however, require to overcome a number of practical challenges, in most cases, due to the lack of modernisation and automation in place with traditional manufacturers. This paper presents a first of its kind case study for moving a traditional food manufacturer, still using the machinery more than one hundred years old, a common occurrence for small- and medium-sized businesses, to adopt the Industry 4.0 technologies. The paper reports the challenges we have encountered during the transformation process and in the development stage. The paper also presents a smart production control system that we have developed by utilising AI, machine learning, Internet of things, big data analytics, cyber-physical systems and cloud computing technologies. The system provides novel data collection, information extraction and intelligent monitoring services, enabling improved efficiency and consistency as well as reduced operational cost. The platform has been developed in real-world settings offered by an Innovate UK-funded project and has been integrated into the company’s existing production facilities. In this way, the company has not been required to replace old machinery outright, but rather adapted the existing machinery to an entirely new way of operating. The proposed approach and the lessons outlined can benefit similar food manufacturing industries and other SME industries.},
  archive      = {J_NCA},
  author       = {Konur, Savas and Lan, Yang and Thakker, Dhavalkumar and Morkyani, Geev and Polovina, Nereida and Sharp, James},
  doi          = {10.1007/s00521-021-05726-z},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23753-23765},
  shortjournal = {Neural Comput. Appl.},
  title        = {Towards design and implementation of industry 4.0 for food manufacturing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart aging monitoring and early dementia recognition
(SAMEDR): Uncovering the hidden wellness parameter for preventive
well-being monitoring to categorize cognitive impairment and dementia in
community-dwelling elderly subjects through AI. <em>NCA</em>,
<em>35</em>(33), 23739–23751. (<a
href="https://doi.org/10.1007/s00521-021-06139-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning weakening because of dementia degrades the performance in activities of daily living (ADL). Present research work distinguishes care needs, dangers and monitors the effect of dementia on an individual. This research contrasts in ADL design execution between dementia-affected people and other healthy elderly with heterogeneous sensors. More than 300,000 sensors associated activation data were collected from the dementia patients and healthy controls with wellness sensors networks. Generated ADLs were envisioned and understood through the activity maps, diversity and other wellness parameters to categorize wellness healthy, and dementia affected the elderly. Diversity was significant between diseased and healthy subjects. Heterogeneous unobtrusive sensor data evaluate behavioral patterns associated with ADL, helpful to reveal the impact of cognitive degradation, to measure ADL variation throughout dementia. The primary focus of activity recognition in the current research is to transfer dementia subject occupied homes models to generalized age-matched healthy subject data models to utilize new services, label classified datasets and produce limited datasets due to less training. Current research proposes a novel Smart Aging Monitoring and Early Dementia Recognition system that provides the exchange of data models between dementia subject occupied homes (DSOH) to healthy subject occupied homes (HSOH) in a move to resolve the deficiency of training data. At that point, the key attributes are mapped onto each other utilizing a sensor data fusion that assures to retain the diversities between various HSOH &amp; DSOH by diminishing the divergence between them. Moreover, additional tests have been conducted to quantify the excellence of the offered framework: primary, in contradiction of the precision of feature mapping techniques; next, computing the merit of categorizing data at DSOH; and, the last, the aptitude of the projected structure to function thriving due to noise data. The outcomes show encouraging pointers and highlight the boundaries of the projected approach.},
  archive      = {J_NCA},
  author       = {Ghayvat, Hemant and Gope, Prosanta},
  doi          = {10.1007/s00521-021-06139-8},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23739-23751},
  shortjournal = {Neural Comput. Appl.},
  title        = {Smart aging monitoring and early dementia recognition (SAMEDR): Uncovering the hidden wellness parameter for preventive well-being monitoring to categorize cognitive impairment and dementia in community-dwelling elderly subjects through AI},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning-based approach for fault diagnosis of
current-carrying ring in catenary system. <em>NCA</em>, <em>35</em>(33),
23725–23737. (<a
href="https://doi.org/10.1007/s00521-021-06280-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Industrial Internet of Things, the deep learning-based methods are used to help solve various problems. The current-carrying ring as one of important components on the catenary system which is always small in the catenary image has the potential risk to be a defect to impact the train operation. To improve the detection performance for the faulted current-carrying ring, a fault diagnosis method for the current-carrying ring based on an improved CenterNet model is proposed. Through analyzing of the characteristics of the catenary images and the detection network, the catenary image is preprocessed firstly by a simple enhancement method, which is proposed based on the Retinex theory for improving the quality of the image and suppressing noise in some degree. The embedded attention modules denoted as spatial weight block and channel weight block are adopted to enhance the local and global features, respectively. The shallow characteristics are fused into the deep semantic features with adaptive learning weights to make the features abundant. The weighted loss is presented to improve the performance of the detection for the faulted current-carrying ring. The experimental results show that the proposed method has improved fault diagnosis accuracy for the current-carrying rings which presents higher precision and recall values compared with the other detection networks in the experiments. It could provide useful assistance for improving efficiency and stability of the railway transportation.},
  archive      = {J_NCA},
  author       = {Chen, Yuwen and Song, Bin and Zeng, Yuan and Du, Xiaojiang and Guizani, Mohsen},
  doi          = {10.1007/s00521-021-06280-4},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23725-23737},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning-based approach for fault diagnosis of current-carrying ring in catenary system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid bio-inspired algorithm and convolutional neural
network for automatic lung tumor detection. <em>NCA</em>,
<em>35</em>(33), 23711–23724. (<a
href="https://doi.org/10.1007/s00521-020-05362-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we have proposed a hybrid bio-inspired algorithm which takes the merits of whale optimization algorithm (WOA) and adaptive particle swarm optimization (APSO). The proposed algorithm is referred as the hybrid WOA_APSO algorithm. We utilize a convolutional neural network (CNN) for classification purposes. Extensive experiments are performed to evaluate the performance of the proposed model. Here, pre-processing and segmentation are performed on 120 lung CT images for obtaining the segmented tumored and non-tumored region nodule. The statistical, texture, geometrical and structural features are extracted from the processed image using different techniques. The optimized feature selection plays a crucial role in determining the accuracy of the classification algorithm. The novel variant of whale optimization algorithm and adaptive particle swarm optimization, hybrid bio-inspired WOA_APSO, is proposed for selecting optimized features. The feature selection grouping is applied by embedding linear discriminant analysis which helps in determining the reduced dimensions of subsets. Twofold performance comparisons are done. First, we compare the performance against the different classification techniques such as support vector machine, artificial neural network (ANN) and CNN. Second, the computational cost of the hybrid WOA_APSO is compared with the standard WOA and APSO algorithms. The experimental result reveals that the proposed algorithm is capable of automatic lung tumor detection and it outperforms the other state-of-the-art methods on standard quality measures such as accuracy (97.18\%), sensitivity (97\%) and specificity (98.66\%). The results reported in this paper are encouraging; hence, these results will motivate other researchers to explore more in this direction.},
  archive      = {J_NCA},
  author       = {Vijh, Surbhi and Gaurav, Prashant and Pandey, Hari Mohan},
  doi          = {10.1007/s00521-020-05362-z},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23711-23724},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid bio-inspired algorithm and convolutional neural network for automatic lung tumor detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neuro-fuzzy analytics in athlete development (NueroFATH): A
machine learning approach. <em>NCA</em>, <em>35</em>(33), 23697–23710.
(<a href="https://doi.org/10.1007/s00521-021-05704-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Athletes represent the apex of physical capacity filling in a social picture of performance and build. In light of the fundamental contrasts in athletic capacities required for different games, each game demands an alternate body type standard. Because of the decent variety of these body types, each can have an altogether different body standard. Nowadays, a large number of athletes participate in assessments and a large number of human hours are spent on playing out these assessments every year. These assessments are performed to check the physical strength of athletes and evaluate them for different games. This paper presents a machine learning approach to the physical assessment of athletes known as NueroFATH. The proposed NueroFATH approach relies on neuro-fuzzy analytics that involves the deployment of neural networks and fuzzy c-means techniques to predict the athletes for the potential of winning medals. This can be achieved using athletes’ physical assessment parameters. The goal of this study is not only to identify the athletes based on which group they fall into (gold/silver/bronze), but also to understand which physical characteristic is important to identify them and categorize them in a medal group. It was determined that features, namely height, body mass, body mass index, 40 m and vertical jump are the most important for achieving 98.40\% accuracy for athletes to classify them in the gold category when they are in the bronze category. Unsupervised learning showed that features, namely body mass, body mass index, vertical jump, med ball, 40 m, peak oxygen content, peak height velocity have the highest variability. We can achieve upto 97.06\% accuracy when features, i.e., body mass, body mass index, vertical jump, med ball, 40 m, peak oxygen content, peak height velocity were used.},
  archive      = {J_NCA},
  author       = {Rathore, Heena and Mohamed, Amr and Guizani, Mohsen and Rathore, Shailendra},
  doi          = {10.1007/s00521-021-05704-5},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23697-23710},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neuro-fuzzy analytics in athlete development (NueroFATH): A machine learning approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel solution for finding postpartum haemorrhage using
fuzzy neural techniques. <em>NCA</em>, <em>35</em>(33), 23683–23696. (<a
href="https://doi.org/10.1007/s00521-020-05683-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Postpartum haemorrhage (PPH) is the loss of blood above 500 ml during vaginal or caesarean deliveries. It is difficult to find a PPH in an earlier stage, so pregnant women are exposed to excess blood loss that makes them suffer and die. Antenatal practices help in identifying risk factors, and modern technology is used to overcome the risk. Still, the morbidity rate and the mortality arise due to the unpredicted and unexpected cause. PPH is still a significant cause of maternal morbidity and mortality worldwide. The novelty of this research work is to alert medical practitioner about excessive bleeding of pregnant women during childbirth. We are proposing an automation system using wearable devices to prevent pregnant women from the PPH. These devices measure parameters like temperature, pulse rate, blood pressure, and sweat rate of pregnant women. Fuzzy neural technique-based rules are used for each parameter to predict the risk in developing PPH and to evaluate the performance of proposed system for reducing mortality and morbidity rates. Our findings of experiment are carried on metrics of HPPH (high-level postpartum haemorrhage), NPPH (normal-level postpartum haemorrhage), and MPPH (medium-level postpartum haemorrhage) for 15 patients. Fuzzy output value of 1 indicates patient state with NPPH, 0 indicates patient state with HPPH, and values in between 0 and 1 indicate MPPH. Based on the sensitivity of the predicted values, medical attention is taken from doctors or nurses in nearby locations using Internet of Things infrastructure.},
  archive      = {J_NCA},
  author       = {Kumar, V. D. Ambeth and Sharmila, S. and Kumar, Abhishek and Bashir, A. K. and Rashid, Mamoon and Gupta, Sachin Kumar and Alnumay, Waleed S.},
  doi          = {10.1007/s00521-020-05683-z},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23683-23696},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel solution for finding postpartum haemorrhage using fuzzy neural techniques},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review on COVID-19 forecasting models. <em>NCA</em>,
<em>35</em>(33), 23671–23681. (<a
href="https://doi.org/10.1007/s00521-020-05626-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel coronavirus (COVID-19) has spread to more than 200 countries worldwide, leading to more than 36 million confirmed cases as of October 10, 2020. As such, several machine learning models that can forecast the outbreak globally have been released. This work presents a review and brief analysis of the most important machine learning forecasting models against COVID-19. The work presented in this study possesses two parts. In the first section, a detailed scientometric analysis presents an influential tool for bibliometric analyses, which were performed on COVID-19 data from the Scopus and Web of Science databases. For the above-mentioned analysis, keywords and subject areas are addressed, while the classification of machine learning forecasting models, criteria evaluation, and comparison of solution approaches are discussed in the second section of the work. The conclusion and discussion are provided as the final sections of this study.},
  archive      = {J_NCA},
  author       = {Rahimi, Iman and Chen, Fang and Gandomi, Amir H.},
  doi          = {10.1007/s00521-020-05626-8},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23671-23681},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review on COVID-19 forecasting models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neuro-fuzzy analytics for intelligent big data
processing in smart ecosystems. <em>NCA</em>, <em>35</em>(33),
23667–23669. (<a
href="https://doi.org/10.1007/s00521-023-09102-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Aujla, Gagangeet Singh and Jindal, Anish and Rawat, Danda B. and Jiang, Chunxiao},
  doi          = {10.1007/s00521-023-09102-x},
  journal      = {Neural Computing and Applications},
  number       = {33},
  pages        = {23667-23669},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep neuro-fuzzy analytics for intelligent big data processing in smart ecosystems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Projective lag quasi-synchronization of coupled systems with
mixed delays and parameter mismatch: A unified theory. <em>NCA</em>,
<em>35</em>(32), 23649–23665. (<a
href="https://doi.org/10.1007/s00521-023-08980-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the projective lag quasi-synchronization by feedback control of a coupled dynamical system with delays and parameter mismatches on arbitrary time domains. Being formulated on time scales, our results are valid simultaneously for continuous- and discrete-time models as well as for any non-standard time domain. Furthermore, the controller design respects the structure of the equations so that we can characterize the stabilization by a limited controller action. Our proofs rely on the unified matrix-measure theory and the generalized Halanay inequality on time scales. We validate our theoretical results with several simulation examples on various time domains.},
  archive      = {J_NCA},
  author       = {Kumar, Vipin and Heiland, Jan and Benner, Peter},
  doi          = {10.1007/s00521-023-08980-5},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23649-23665},
  shortjournal = {Neural Comput. Appl.},
  title        = {Projective lag quasi-synchronization of coupled systems with mixed delays and parameter mismatch: A unified theory},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Diegraph: Dual-branch information exchange graph
convolutional network for deformable medical image registration.
<em>NCA</em>, <em>35</em>(32), 23631–23647. (<a
href="https://doi.org/10.1007/s00521-023-08979-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformable medical image registration (DMIR) is a crucial task in medical image analysis. Current learning-based approaches concatenate two images into two channels, then use convolution or transformer-based networks to extract features for modeling spatial correspondence. However, this approach mixes the features of the two images before searching for correspondence, making the spatial modeling process challenging. To solve this problem, this paper proposes a purely convolutional framework, DIEGraph, for DMIR. The proposed method first extracts features separately from the moving and fixed images using a dual-branch network. Then, it splits the features into patches and constructs a graph by connecting the nearest neighbors of these patches. Based on the graph representation, the proposed method uses an information exchange graph convolutional network module to exchange dual-branch information and model correspondence. Additionally, a dilated residual fusion module is deployed for feature fusion. We conducted a qualitative and quantitative evaluation on two 3D datasets. The proposed method achieved higher Dice scores than Transmorph by 0.9 $$\%$$ and 3.8 $$\%$$ on the two datasets, respectively, while maintaining a comparable voxel folding percentage. Ablation studies also verify the effectiveness of the components in the proposed model.},
  archive      = {J_NCA},
  author       = {Wang, Longji and Yan, Zhiyue and Cao, Wenming and Ji, Jianhua},
  doi          = {10.1007/s00521-023-08979-y},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23631-23647},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diegraph: Dual-branch information exchange graph convolutional network for deformable medical image registration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast walsh–hadamard transform and deep learning approach for
diagnosing psychiatric diseases from electroencephalography (EEG)
signals. <em>NCA</em>, <em>35</em>(32), 23617–23630. (<a
href="https://doi.org/10.1007/s00521-023-08971-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Psychiatric diseases are very common worldwide, including schizophrenia (SZ) and Alzheimer&#39;s disease (AD). Early diagnosis is very important for medical intervention. Proper diagnosis of these diseases requires long-term observations and extensive testing to recognize their clinical features. These observations and tests may be subjective, expensive, incomplete, or inaccurate. EEG is a strong candidate for the diagnosis of diseases with the advantages of being noninvasive, based on findings, less costly and getting results in a short time. In this paper, we proposed an EEG-based solution for the diagnosis of psychiatric diseases using a fast Walsh–Hadamard transform (FWHT) and deep learning approach. Two different publicly available datasets were combined. SZ, AD and healthy controls (HC) were automatically multi-classified in experiment 1 and SZ and AD groups were classified in experiment 2. Features were extracted using the FWHT. The performances of support vector machine, decision tree, k-nearest neighbour, and bidirectional long-short-term memory (BLSTM) algorithms were compared for each experiment using the extracted features. In the experiments, the BLSTM algorithm displayed the best performance. The BLSTM algorithm demonstrated promising results with 91.05\% overall accuracy, 0.86 kappa statistics in experiment 1, and with 98.38\% overall accuracy, 0.96 kappa statistics in experiment 2. The results of the experiment provided evidence that people with different psychiatric diseases have different EEG signals. Moreover, it is a rare attempt that SZ, AD and HC groups can be classified automatically and effectively from EEG signals using deep learning model and accuracy was higher than related literature studies.},
  archive      = {J_NCA},
  author       = {Göker, Hanife and Tosun, Mustafa},
  doi          = {10.1007/s00521-023-08971-6},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23617-23630},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fast Walsh–Hadamard transform and deep learning approach for diagnosing psychiatric diseases from electroencephalography (EEG) signals},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized gradient emphasis learning for off-policy
evaluation and control with function approximation. <em>NCA</em>,
<em>35</em>(32), 23599–23616. (<a
href="https://doi.org/10.1007/s00521-023-08965-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emphatic temporal-difference (ETD) learning (Sutton et al. 2016) is a pioneering off-policy reinforcement learning method involving the use of the followon trace. The recently proposed gradient emphasis learning (GEM, Zhang et al. 2020) algorithm is used to fix the problems of unbounded variance and large emphasis approximation error introduced by the followon trace from the perspective of stochastic approximation. In this paper, we rethink GEM and introduce a novel generalized GEM( $$\beta$$ ) algorithm to learn the true emphasis. The key to the construction of the generalized GEM( $$\beta$$ ) algorithm is introducing a tunable hyperparameter $$\beta$$ that is not necessarily the same as the discount factor $$\gamma$$ to the GEM operator. We then apply the emphasis estimated by the proposed GEM( $$\beta$$ ) algorithm to the value estimation gradient and the policy gradient, respectively, yielding the corresponding ETD variant for off-policy evaluation (OPE) and actor-critic algorithm for off-policy control. Finally, we empirically demonstrate the advantages of the proposed algorithms on the diagnostic linear OPE benchmark as well as classic control tasks with neural network function approximators.},
  archive      = {J_NCA},
  author       = {Cao, Jiaqing and Liu, Quan and Wu, Lan and Fu, Qiming and Zhong, Shan},
  doi          = {10.1007/s00521-023-08965-4},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23599-23616},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generalized gradient emphasis learning for off-policy evaluation and control with function approximation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPDGAN: A generative adversarial network based on SPD
manifold learning for automatic image colorization. <em>NCA</em>,
<em>35</em>(32), 23581–23597. (<a
href="https://doi.org/10.1007/s00521-023-08999-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the automatic colorization problem, which converts a grayscale image to a colorized one. Recent deep learning approaches can colorize automatically grayscale images. However, when it comes to different scenes which contain distinct color styles, it is difficult to accurately capture the color characteristics. In this work, we propose a fully automatic colorization approach based on Symmetric Positive Definite (SPD) Manifold Learning with a generative adversarial network (SPDGAN) that improves the quality of the colorization results. Our SPDGAN model establishes an adversarial game between two discriminators and a generator. The latter is based on ResNet architecture with few alterations. Its goal is to generate fake colorized images without losing color information across layers through residual connections. Then, we employ two discriminators from different domains. The first one is devoted to the image pixel domain, while the second one is to the Riemann manifold domain which helps to avoid color misalignment. Extensive experiments are conducted on the Places365 and COCO-stuff databases to test the effect of each component of our SPDGAN. In addition, quantitative and qualitative comparisons with state-of-the-art methods demonstrate the effectiveness of our model by achieving more realistic colorized images with less artifacts visually, and good results of PSNR, SSIM, and FID values.},
  archive      = {J_NCA},
  author       = {Mourchid, Youssef and Donias, Marc and Berthoumieu, Yannick and Najim, Mohamed},
  doi          = {10.1007/s00521-023-08999-8},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23581-23597},
  shortjournal = {Neural Comput. Appl.},
  title        = {SPDGAN: A generative adversarial network based on SPD manifold learning for automatic image colorization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IoT-based intelligent waste management system. <em>NCA</em>,
<em>35</em>(32), 23551–23579. (<a
href="https://doi.org/10.1007/s00521-023-08970-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the population density in cities has increased at a higher pace, so waste generation is on the rise in most societies due to population growth. Given this concern, it would be highly important to manage waste generation. Intelligent city planning is necessary to improve the quality of city life and make cities more livable. This paper presents an intelligent waste management system (IWMS) in smart cities based on Internet of Things components like sensors, detectors, and actuators. IWMS contains three main phases. The first phase of the system is to adapt the low energy adaptive clustering hierarchy approach as an optimization process to better balance the energy consumption of smart waste bins (SBs), thus leading to extending the life of the smart waste network. The second phase is handling the missing values which are retrieved from SBs using an improved version of the k-nearest neighbor algorithm based on artificial hummingbird optimization (AHA), while the third phase presents an optimal energy-efficient route process for the routing of waste trucks that improves fuel efficiency and reduces the time to get an appropriate SB. According to the experimental results, the proposed system has achieved energy savings of 34\% for the smart waste bin network. Moreover, compared to other systems, it has a lower mean error rate when generating missing values, and the results related to convergence and running time validate its superiority compared with other metaheuristic algorithms.},
  archive      = {J_NCA},
  author       = {Ahmed, Mohammed M. and Hassanien, Ehab and Hassanien, Aboul Ella},
  doi          = {10.1007/s00521-023-08970-7},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23551-23579},
  shortjournal = {Neural Comput. Appl.},
  title        = {IoT-based intelligent waste management system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight micro-motion gesture recognition based on MIMO
millimeter wave radar using bidirectional-GRU network. <em>NCA</em>,
<em>35</em>(32), 23537–23550. (<a
href="https://doi.org/10.1007/s00521-023-08978-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-contact gesture recognition is a novel form of human–computer interaction. It has broad prospects in many applications, such as Augmented Reality/Virtual Reality, smart homes and intelligent medical systems. Therefore, it has become a research hotspot in recent years. This paper investigates a lightweight micro-motion gesture recognition method based on Multiple Input and Multiple Output millimeter wave radar. We employ TI’s MMWCAS radar, comprising four cascaded AWR1243 radar boards, to collect gesture data. During the data pre-processing stage, we extract the Range-time Map, Doppler-time Map, Azimuth-time Map and Elevation-time Map of the dynamic gestures to characterize the dynamic motion features. These maps are then simplified into a one-dimensional vector to reduce data volume. We propose an 8HBi-GRU model, which combines the Bidirectional Gate Recurrent Unit (Bi-GRU) with a multi-head self-attention mechanism, to identify twelve types of micro-motion gestures using feature vectors. The model achieves an accuracy of 98.24 $$\%$$ , with precision and recall rates exceeding 0.97 and 0.98, respectively, for ten of the gesture types. Experimental results demonstrate that the proposed 8HBi-GRU model achieves lightweight gesture recognition rapidly and requires minimal storage space compared to image-based deep learning methods.},
  archive      = {J_NCA},
  author       = {Zhao, Yaqin and Song, Yuqing and Wu, Longwen and Liu, Puqiu and Lv, Ruchen and Ullah, Hikmat},
  doi          = {10.1007/s00521-023-08978-z},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23537-23550},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lightweight micro-motion gesture recognition based on MIMO millimeter wave radar using bidirectional-GRU network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph encoder–decoder network for unsupervised anomaly
detection. <em>NCA</em>, <em>35</em>(32), 23521–23535. (<a
href="https://doi.org/10.1007/s00521-023-08964-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key component of many graph neural networks (GNNs) is the pooling operation, which seeks to reduce the size of a graph while preserving important structural information. However, most existing graph pooling strategies rely on an assignment matrix obtained by employing a GNN layer, which is characterized by trainable parameters, often leading to significant computational complexity and a lack of interpretability in the pooling process. In this paper, we propose an unsupervised graph encoder–decoder model to detect abnormal nodes from graphs by learning an anomaly scoring function to rank nodes based on their degree of abnormality. In the encoding stage, we design a novel pooling mechanism, named LCPool, which leverages locality-constrained linear coding for feature encoding to find a cluster assignment matrix by solving a least-square optimization problem with a locality regularization term. By enforcing locality constraints during the coding process, LCPool is designed to be free from learnable parameters, capable of efficiently handling large graphs, and can effectively generate a coarser graph representation while retaining the most significant structural characteristics of the graph. In the decoding stage, we propose an unpooling operation, called LCUnpool, to reconstruct both the structure and nodal features of the original graph. We conduct empirical evaluations of our method on six benchmark datasets using several evaluation metrics, and the results demonstrate its superiority over state-of-the-art anomaly detection approaches.},
  archive      = {J_NCA},
  author       = {Mesgaran, Mahsa and Hamza, A. Ben},
  doi          = {10.1007/s00521-023-08964-5},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23521-23535},
  shortjournal = {Neural Comput. Appl.},
  title        = {A graph encoder–decoder network for unsupervised anomaly detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Investigation of ensemble methods in terms of statistics:
TIMMS 2019 example. <em>NCA</em>, <em>35</em>(32), 23507–23520. (<a
href="https://doi.org/10.1007/s00521-023-08969-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, it is aimed to determine the factors affecting the mathematics achievements of eighth-grade students through trends in international mathematics and science study 2019 and compare the classification performances according to sample sizes and the number of independent variables of Bagging and Adaboost methods. Firstly, the most important factors affecting mathematics skills were obtained by using feature selection methods. Then, the performances of the methods were examined according to the sample size and the number of variables. As a result of the analysis carried out, no obvious difference was found between the performances of the methods according to the number of independent variables. On the other hand, the performances of methods of this study varied according to sample sizes, and it was seen that Bagging method showed better classification performance than Adaboost method in all sample sizes, and the performance of both methods approached each other when a sample of 3000 units was used.},
  archive      = {J_NCA},
  author       = {Bezek Güre, Özlem},
  doi          = {10.1007/s00521-023-08969-0},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23507-23520},
  shortjournal = {Neural Comput. Appl.},
  title        = {Investigation of ensemble methods in terms of statistics: TIMMS 2019 example},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FATE: A three-stage method for arithmetical exercise
correction. <em>NCA</em>, <em>35</em>(32), 23491–23506. (<a
href="https://doi.org/10.1007/s00521-023-08890-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the number of primary students rapidly rises, the highly repetitive task of correcting arithmetical exercises consumes much time for teachers and hinders them from concentrating more on the growth of students. To reduce the workload of teachers, arithmetical exercise correction (AEC) is proposed to automatically detect, recognize and correct various arithmetical exercises in the workbook. However, two crucial issues need to be addressed since the research in this field is still immature, i.e., accurate detection of the arithmetic exercise with various structures and the effective recognition of long-size exercise. In this paper, we propose a three-stage method dubbed as FATE, to correct arithmetical exercises in an end-to-end manner. Specifically, we apply the anchor-free model with a feature pyramid network and constraint of center-ness to avoid the redundant bounding boxes. On the other hand, we employ a transformer-based framework with contrastive learning to extract global symbol information and generate corresponding sequences. Finally, we design a series of rule-based templates to correct the generated sequence based on the unique features of each type of arithmetical exercises, respectively. Extensive experiments demonstrate that our method yields the detection average precision of 96.8\%, the recognition accuracy of 92.3\% and the $$\mathrm {F_{1}}$$ score of 91.2\% in spotting experiment on the public dataset, which outperforms the state-of-the-art method.},
  archive      = {J_NCA},
  author       = {Zhu, Qipeng and Luo, Zhuoyan and Zhu, Shipeng and Jing, Qi and Xu, Zihang and Xue, Hui},
  doi          = {10.1007/s00521-023-08890-6},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23491-23506},
  shortjournal = {Neural Comput. Appl.},
  title        = {FATE: A three-stage method for arithmetical exercise correction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An ATC instruction processing-based trajectory prediction
algorithm designing. <em>NCA</em>, <em>35</em>(32), 23477–23490. (<a
href="https://doi.org/10.1007/s00521-021-05713-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The radiotelephony communication is a voice communication mode between air traffic service unit and aircraft currently. The control instruction is a kind of unstructured data, so that the automatic systems cannot use understand its semantic. If control instruction is regarded as a sort of special “natural language,” methods such as syntax analysis and sematic analysis can be adopted to generate the structured instruction. The correct recognition of the language must be important for the control instruction. However, the control instruction in Chinese is different from the general use of Chinese language in form, resulting in prepositions becoming important for semantic analysis. This paper proposes a deep neural network-based Chinese language control construction algorithm for the trajectory prediction. In particular, analysis of sematic characteristics of control instruction is realized by using cognitive linguistics theory and construction grammar theory. The control instruction is then designed by the semantic ontology. Based on the deep neural networks by considering the word sequence of instruction as the inputs. The test results have demonstrated the effectiveness of the proposed algorithm with a developed entity extracting model. (The results are quantified using the BiLSTM-LAN-CRF in detail.)},
  archive      = {J_NCA},
  author       = {Wang, Xuan and Mao, Yi and Wu, Xiaoyong and Xu, Qucheng and Jiang, Weiyu and Yin, Suwan},
  doi          = {10.1007/s00521-021-05713-4},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23477-23490},
  shortjournal = {Neural Comput. Appl.},
  title        = {An ATC instruction processing-based trajectory prediction algorithm designing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Grid cell modeling with mapping representation of
self-motion for path integration. <em>NCA</em>, <em>35</em>(32),
23465–23476. (<a
href="https://doi.org/10.1007/s00521-021-06039-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The representation of grid cells in the medial entorhinal cortex region is crucial for path integration. In this paper, we proposed a grid cell modeling mechanism by mapping the agent’s self-motion in Euclidean space to the neuronal activity of grid cells. Our representational model can achieve multi-scale hexagonal patterns of grid cells from recurrent neural network (RNN) and enables path integration for 1D, 2D and 3D spaces. Different from the existing works which need to learn weights of RNN to get the vector representation of grid cells, our method can obtain weights by direct matrix operations. Moreover, compared with the classical models based on continuous attractor network, our model avoids the connection matrix’s symmetry limitation and spatial representation redundancy problems. In this paper, we also discuss the connection pattern between grid cells and place cells to demonstrate grid cells’ functioning as a metric for coding space.},
  archive      = {J_NCA},
  author       = {Wang, Jiru and Yan, Rui and Tang, Huajin},
  doi          = {10.1007/s00521-021-06039-x},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23465-23476},
  shortjournal = {Neural Comput. Appl.},
  title        = {Grid cell modeling with mapping representation of self-motion for path integration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing learning capabilities of movement primitives under
distributed probabilistic framework for flexible assembly tasks.
<em>NCA</em>, <em>35</em>(32), 23453–23464. (<a
href="https://doi.org/10.1007/s00521-021-06543-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel probabilistic distributed framework based on movement primitives for flexible robot assembly. Since the modern advanced industrial cell usually deals with various scenarios that are not fixed via-point trajectories but highly reconfigurable tasks, the industrial robots used in these applications must be capable of adapting and learning new in-demand skills without programming experts. Therefore, we propose a probabilistic framework that could accommodate various learning abilities trained with different movement-primitive datasets, separately. Derived from the Bayesian Committee Machine, this framework could infer new adapting trajectories with weighted contributions of each training dataset. To verify the feasibility of our proposed imitation learning framework, the simulation comparison with the state-of-the-art movement learning framework task-parametrised GMM is conducted. Several key aspects, such as generalisation capability, learning accuracy and computation expense, are discussed and compared. Moreover, two real-world experiments, i.e. riveting picking and nutplate picking, are further tested with the YuMi collaborative robot to verify the application feasibility in industrial assembly manufacturing.},
  archive      = {J_NCA},
  author       = {Wang, Likun and Jia, Shuya and Wang, Guoyan and Turner, Alison and Ratchev, Svetan},
  doi          = {10.1007/s00521-021-06543-0},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23453-23464},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing learning capabilities of movement primitives under distributed probabilistic framework for flexible assembly tasks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Human–robot skill transmission for mobile robot via
learning by demonstration. <em>NCA</em>, <em>35</em>(32), 23441–23451.
(<a href="https://doi.org/10.1007/s00521-021-06449-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a skill transmission technique for the mobile robot via learning by demonstration. When the material is transported to the designated location, the robot can show the human-like capabilities: autonomous tracking target. In this case, a skill transmission framework is designed, which the Kinect sensor is utilized to distinguish human activity recognition to create a planned path. Moreover, the dynamic movement primitive method is implemented to represent the teaching data, and the Gaussian mixture regression is utilized to encode the learning trajectory. Furthermore, in order to realize the accurate position control of trajectory tracking, a model predictive tracking control is investigated, where the recurrent neural network is used to eliminate the uncertain interaction. Finally, some experimental tasks using the mobile robot (BIT-6NAZA) are carried out to demonstrate the effectiveness of the developed techniques in real-world scenarios.},
  archive      = {J_NCA},
  author       = {Li, Jiehao and Wang, Junzheng and Wang, Shoukun and Yang, Chenguang},
  doi          = {10.1007/s00521-021-06449-x},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23441-23451},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human–robot skill transmission for mobile robot via learning by demonstration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving reinforcement learning with human assistance: An
argument for human subject studies with HIPPO gym. <em>NCA</em>,
<em>35</em>(32), 23429–23439. (<a
href="https://doi.org/10.1007/s00521-021-06375-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is a popular machine learning paradigm for game playing, robotics control, and other sequential decision tasks. However, RL agents often have long learning times with high data requirements because they begin by acting randomly. In order to better learn in complex tasks, we argue that an external teacher can often significantly help the RL agent learn. OpenAI Gym is a common framework for RL research, including a large number of standard environments and agents, making RL research significantly more accessible. This article introduces our new open-source RL framework, the Human Input Parsing Platform for Openai Gym (HIPPO Gym), and the design decisions that went into its creation. The goal of this platform is to facilitate human-RL research, making human-in-the-loop RL more accessible, including learning from demonstrations, learning from feedback, or curriculum learning. In addition, all experiments can be conducted over the internet without any additional software needed on the client’s computer, making experiments at scale significantly easier.},
  archive      = {J_NCA},
  author       = {Taylor, Matthew E. and Nissen, Nicholas and Wang, Yuan and Navidi, Neda},
  doi          = {10.1007/s00521-021-06375-y},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23429-23439},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving reinforcement learning with human assistance: An argument for human subject studies with HIPPO gym},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Persistent rule-based interactive reinforcement learning.
<em>NCA</em>, <em>35</em>(32), 23411–23428. (<a
href="https://doi.org/10.1007/s00521-021-06466-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive reinforcement learning has allowed speeding up the learning process in autonomous agents by including a human trainer providing extra information to the agent in real-time. Current interactive reinforcement learning research has been limited to real-time interactions that offer relevant user advice to the current state only. Additionally, the information provided by each interaction is not retained and instead discarded by the agent after a single-use. In this work, we propose a persistent rule-based interactive reinforcement learning approach, i.e., a method for retaining and reusing provided knowledge, allowing trainers to give general advice relevant to more than just the current state. Our experimental results show persistent advice substantially improves the performance of the agent while reducing the number of interactions required for the trainer. Moreover, rule-based advice shows similar performance impact as state-based advice, but with a substantially reduced interaction count.},
  archive      = {J_NCA},
  author       = {Bignold, Adam and Cruz, Francisco and Dazeley, Richard and Vamplew, Peter and Foale, Cameron},
  doi          = {10.1007/s00521-021-06466-w},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23411-23428},
  shortjournal = {Neural Comput. Appl.},
  title        = {Persistent rule-based interactive reinforcement learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selective eye-gaze augmentation to enhance imitation
learning in atari games. <em>NCA</em>, <em>35</em>(32), 23401–23410. (<a
href="https://doi.org/10.1007/s00521-021-06367-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the selective use of eye-gaze information in learning human actions in Atari games. Extensive evidence suggests that our eye movements convey a wealth of information about the direction of our attention and mental states and encode the information necessary to complete a task. Based on this evidence, we hypothesize that selective use of eye-gaze, as a clue for attention direction, will enhance the learning from demonstration. For this purpose, we propose a selective eye-gaze augmentation (SEA) network that learns when to use the eye-gaze information. The proposed network architecture consists of three sub-networks: gaze prediction, gating, and action prediction network. Using the prior 4 game frames, a gaze map is predicted by the gaze prediction network, which is used for augmenting the input frame. The gating network will determine whether the predicted gaze map should be used in learning and is fed to the final network to predict the action at the current frame. To validate this approach, we use publicly available Atari Human Eye-Tracking And Demonstration (Atari-HEAD) dataset consists of 20 Atari games with 28 million human demonstrations and 328 million eye-gazes (over game frames) collected from four subjects. We demonstrate the efficacy of selective eye-gaze augmentation compared to the state-of-the-art Attention Guided Imitation Learning (AGIL) and Behavior Cloning (BC). The results indicate that the selective augmentation approach (the SEA network) performs significantly better than the AGIL and BC. Moreover, to demonstrate the significance of selective use of gaze through the gating network, we compare our approach with the random selection of the gaze. Even in this case, the SEA network performs significantly better, validating the advantage of selectively using the gaze in demonstration learning.},
  archive      = {J_NCA},
  author       = {Thammineni, Chaitanya and Manjunatha, Hemanth and Esfahani, Ehsan T.},
  doi          = {10.1007/s00521-021-06367-y},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23401-23410},
  shortjournal = {Neural Comput. Appl.},
  title        = {Selective eye-gaze augmentation to enhance imitation learning in atari games},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active learning with sampling by joint global-local
uncertainty for salient object detection. <em>NCA</em>, <em>35</em>(32),
23387–23399. (<a
href="https://doi.org/10.1007/s00521-021-06395-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The training of the SOD model relies on abundant annotated data, which needs laborious and expensive manual labeling. The generated pseudo-labels for reducing the annotation of the salient object will inevitably introduce noise, which will degrade the performance of the model and cannot fully represent the ground truth of manual labeling. To address this issue, we propose a novel active sampling strategy for salient object detection. The method is made up of two parts: a prediction module and an active learning module. The prediction module predicts the saliency of the image and provides the saliency prediction map for the active learning module. Then, the active learning module measures the global uncertainty and local uncertainty of the prediction map, aiming to select the most informative samples for the model. The selected samples are manually annotated and added to the training set to retrain the prediction model. Experimental results on DUTS dataset indicate that the amount of data can be reduced by 48.3\% with competitive performance compared with the state-of-the-art SOD model.},
  archive      = {J_NCA},
  author       = {Li, Longfei and Fu, Haidong and Xu, Xin},
  doi          = {10.1007/s00521-021-06395-8},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23387-23399},
  shortjournal = {Neural Comput. Appl.},
  title        = {Active learning with sampling by joint global-local uncertainty for salient object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint regularization and low-rank fusion for atmospheric
turbulence removal. <em>NCA</em>, <em>35</em>(32), 23369–23385. (<a
href="https://doi.org/10.1007/s00521-021-06336-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atmospheric turbulence removal remains a challenging task, because it is very difficult to mitigate geometric distortion and remove spatially and temporally variant blur. This paper presents a novel strategy for atmospheric turbulence removal by characterizing local smoothness, nonlocal similarity and low-rank property of natural images. The main contributions are three folds. First, a joint regularization model is made which combines nonlocal total variation regularization and steering kernel regression total variation regularization in order that reference image enhancement and image registration are jointly implemented on geometric distortion reduction. Secondly, a fast split Bregman iteration algorithm is designed to address the joint variation optimization problem. Finally, a weighted nuclear norm is introduced to constrain the low-rank optimization problem to reduce blur variation and generate a fusion image. Extensive experimental results show that our method can effectively mitigate geometric deformation as well as blur variations and that it outperforms several other state-of-the-art turbulence removal methods.},
  archive      = {J_NCA},
  author       = {Qu, Yanyun and Yang, Wenjin and Xie, Yuan and Wu, Weiwei and Wu, Yang and Wang, Hanzi},
  doi          = {10.1007/s00521-021-06336-5},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23369-23385},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint regularization and low-rank fusion for atmospheric turbulence removal},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards human distance estimation using a thermal sensor
array. <em>NCA</em>, <em>35</em>(32), 23357–23367. (<a
href="https://doi.org/10.1007/s00521-021-06193-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human distance estimation is essential in many vital applications, specifically, in human localisation-based systems, such as independent living for older adults applications, and making places safe through preventing the transmission of contagious diseases through social distancing alert systems. Previous approaches to estimate the distance between a reference sensing device and human subject relied on visual or high-resolution thermal cameras. However, regular visual cameras have serious concerns about people’s privacy in indoor environments, and high-resolution thermal cameras are costly. This paper proposes a novel approach to estimate the distance for indoor human-centred applications using a low-resolution thermal sensor array. The proposed system presents a discrete and adaptive sensor placement continuous distance estimators using classification techniques and artificial neural network, respectively. It also proposes a real-time distance-based field of view classification through a novel image-based feature. Besides, the paper proposes a transfer application to the proposed continuous distance estimator to measure human height. The proposed approach is evaluated in different indoor environments, sensor placements with different participants. This paper shows a median overall error of $$\pm 0.2$$ m in continuous-based estimation and $$96.8\%$$ achieved-accuracy in discrete distance estimation.},
  archive      = {J_NCA},
  author       = {Naser, Abdallah and Lotfi, Ahmad and Zhong, Joni},
  doi          = {10.1007/s00521-021-06193-2},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23357-23367},
  shortjournal = {Neural Comput. Appl.},
  title        = {Towards human distance estimation using a thermal sensor array},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning framework for realistic robot motion
generation. <em>NCA</em>, <em>35</em>(32), 23343–23356. (<a
href="https://doi.org/10.1007/s00521-021-06192-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robots are being developed to play the role of personal assistants. With the development of artificial intelligence technology, humanoid robots are expected to perform many human tasks, such as housework, human care, and even medical treatment. However, robots cannot currently move flexibly like humans, which affects their fine motor skill performance. This is primarily because traditional robot control methods use manipulators that are difficult to articulate well. To solve this problem, we propose a nonlinear realistic robot motion generation method based on deep learning. Our method benefits from decomposing human motions into basic motions and realistic motions using the multivariate empirical mode decomposition and learning the biomechanical relationships between them by using an autoencoder generation network. The experimental results show that realistic motion features can be learned by the generation network and motion realism can be increased by adding the learned motions to the robots.},
  archive      = {J_NCA},
  author       = {Dong, Ran and Chang, Qiong and Ikuno, Soichiro},
  doi          = {10.1007/s00521-021-06192-3},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23343-23356},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning framework for realistic robot motion generation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iterative learning-based path control for robot-assisted
upper-limb rehabilitation. <em>NCA</em>, <em>35</em>(32), 23329–23341.
(<a href="https://doi.org/10.1007/s00521-021-06037-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robot-assisted rehabilitation, the performance of robotic assistance is dependent on the human user’s dynamics, which are subject to uncertainties. In order to enhance the rehabilitation performance and in particular to provide a constant level of assistance, we separate the task space into two subspaces where a combined scheme of adaptive impedance control and trajectory learning is developed. Human movement speed can vary from person to person and it cannot be predefined for the robot. Therefore, in the direction of human movement, an iterative trajectory learning approach is developed to update the robot reference according to human movement and to achieve the desired interaction force between the robot and the human user. In the direction normal to the task trajectory, human’s unintentional force may deteriorate the trajectory tracking performance. Therefore, an impedance adaptation method is utilized to compensate for unknown human force and prevent the human user drifting away from the updated robot reference trajectory. The proposed scheme was tested in experiments that emulated three upper-limb rehabilitation modes: zero interaction force, assistive and resistive. Experimental results showed that the desired assistance level could be achieved, despite uncertain human dynamics.},
  archive      = {J_NCA},
  author       = {Maqsood, Kamran and Luo, Jing and Yang, Chenguang and Ren, Qingyuan and Li, Yanan},
  doi          = {10.1007/s00521-021-06037-z},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23329-23341},
  shortjournal = {Neural Comput. Appl.},
  title        = {Iterative learning-based path control for robot-assisted upper-limb rehabilitation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based facial emotion recognition for
human–computer interaction applications. <em>NCA</em>, <em>35</em>(32),
23311–23328. (<a
href="https://doi.org/10.1007/s00521-021-06012-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most significant fields in the man–machine interface is emotion recognition using facial expressions. Some of the challenges in the emotion recognition area are facial accessories, non-uniform illuminations, pose variations, etc. Emotion detection using conventional approaches having the drawback of mutual optimization of feature extraction and classification. To overcome this problem, researchers are showing more attention toward deep learning techniques. Nowadays, deep-learning approaches are playing a major role in classification tasks. This paper deals with emotion recognition by using transfer learning approaches. In this work pre-trained networks of Resnet50, vgg19, Inception V3, and Mobile Net are used. The fully connected layers of the pre-trained ConvNets are eliminated, and we add our fully connected layers that are suitable for the number of instructions in our task. Finally, the newly added layers are only trainable to update the weights. The experiment was conducted by using the CK + database and achieved an average accuracy of 96\% for emotion detection problems.},
  archive      = {J_NCA},
  author       = {Chowdary, M. Kalpana and Nguyen, Tu N. and Hemanth, D. Jude},
  doi          = {10.1007/s00521-021-06012-8},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23311-23328},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based facial emotion recognition for human–computer interaction applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-tuned support vector regression model for stock
predictions. <em>NCA</em>, <em>35</em>(32), 23295–23309. (<a
href="https://doi.org/10.1007/s00521-021-05842-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new machine learning (ML) technique is proposed that uses the fine-tuned version of support vector regression for stock forecasting of time series data. Grid search technique is applied over training dataset to select the best kernel function and to optimize its parameters. The optimized parameters are validated through validation dataset. Thus, the tuning of this parameters to their optimized value not only increases model’s overall accuracy but also requires less time and memory. Further, this also minimizes the model from being data overfitted. The proposed method is used to analysis different performance parameters of stock market like up-to-daily and up-to-monthly return, cumulative monthly return, its volatility nature and the risk associated with it. Eight different large-sized datasets are chosen from different domain, and stock is predicted for each case by using the proposed method. A comparison is carried out among the proposed method and some similar methods of same interest in terms of computed root mean square error and the mean absolute percentage error. The comparison reveals the proposed method to be more accurate in predicting the stocks for the chosen datasets. Further, the proposed method requires much less time than its counterpart methods.},
  archive      = {J_NCA},
  author       = {Dash, Ranjan Kumar and Nguyen, Tu N. and Cengiz, Korhan and Sharma, Aditi},
  doi          = {10.1007/s00521-021-05842-w},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23295-23309},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fine-tuned support vector regression model for stock predictions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Composite dynamic movement primitives based on neural
networks for human–robot skill transfer. <em>NCA</em>, <em>35</em>(32),
23283–23293. (<a
href="https://doi.org/10.1007/s00521-021-05747-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, composite dynamic movement primitives (DMPs) based on radial basis function neural networks (RBFNNs) are investigated for robots’ skill learning from human demonstrations. The composite DMPs could encode the position and orientation manipulation skills simultaneously for human-to-robot skills transfer. As the robot manipulator is expected to perform tasks in unstructured and uncertain environments, it requires the manipulator to own the adaptive ability to adjust its behaviours to new situations and environments. Since the DMPs can adapt to uncertainties and perturbation, and spatial and temporal scaling, it has been successfully employed for various tasks, such as trajectory planning and obstacle avoidance. However, the existing skill model mainly focuses on position or orientation modelling separately; it is a common constraint in terms of position and orientation simultaneously in practice. Besides, the generalisation of the skill learning model based on DMPs is still hard to deal with dynamic tasks, e.g., reaching a moving target and obstacle avoidance. In this paper, we proposed a composite DMPs-based framework representing position and orientation simultaneously for robot skill acquisition and the neural networks technique is used to train the skill model. The effectiveness of the proposed approach is validated by simulation and experiments.},
  archive      = {J_NCA},
  author       = {Si, Weiyong and Wang, Ning and Yang, Chenguang},
  doi          = {10.1007/s00521-021-05747-8},
  journal      = {Neural Computing and Applications},
  number       = {32},
  pages        = {23283-23293},
  shortjournal = {Neural Comput. Appl.},
  title        = {Composite dynamic movement primitives based on neural networks for human–robot skill transfer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Observer-based adaptive backstepping control for mimo
nonlinear systems with unknown hysteresis: A nonlinear gain feedback
approach. <em>NCA</em>, <em>35</em>(31), 23265–23281. (<a
href="https://doi.org/10.1007/s00521-023-08896-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an adaptive neural network (NN) control problem is studied for nonstrict-feedback multi-input multi-output (MIMO) nonlinear systems with unmeasurable states and unknown hysteresis. Firstly, to estimate the unmeasurable states, a NN state observer is constructed. Additionally, the unknown nonlinear terms are online approximated by using radial basis function-neural networks (RBF-NNs). And then, the complexity problem is addressed by using the dynamic surface control (DSC), which is easy to overcome the problem of repeated differentiations for virtual control signals. Furthermore, a nonlinear gain feedback function is introduced into the backstepping design procedure to improve the dynamic performance of the closed-loop system. Meanwhile, to satisfy the practical engineering application, a prescribed performance control (PPC) technique is implemented to guarantee the tracking error can converge to a preassigned area. By using the proposed control scheme, all closed-loop signals are semi-global uniformly ultimately bounded (SGUUB). At last, the preponderance and usefulness of the proposed controller are indicated by simulation results.},
  archive      = {J_NCA},
  author       = {Liu, Xiang and Shi, Yiqi and Wu, Nailong and Yan, Huaicheng and Wang, Yueying},
  doi          = {10.1007/s00521-023-08896-0},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23265-23281},
  shortjournal = {Neural Comput. Appl.},
  title        = {Observer-based adaptive backstepping control for mimo nonlinear systems with unknown hysteresis: A nonlinear gain feedback approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MECPformer: Multi-estimations complementary patch with
CNN-transformers for weakly supervised semantic segmentation.
<em>NCA</em>, <em>35</em>(31), 23249–23264. (<a
href="https://doi.org/10.1007/s00521-023-08816-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The initial seed based on the convolutional neural network (CNN) for weakly supervised semantic segmentation always highlights the most discriminative regions but fails to identify the global target information. Methods based on transformers have been proposed successively benefiting from the advantage of capturing long-range feature representations. However, we observe a flaw regardless of the gifts based on the transformer. Given a class, the initial seeds generated based on the transformer may invade regions belonging to other classes. Inspired by the mentioned issues, we devise a simple yet effective method with multi-estimations complementary patch (MECP) strategy and adaptive conflict module (ACM), dubbed MECPformer. Given an image, we manipulate it with the MECP strategy at different epochs, and the network mines and deeply fuses the semantic information at different levels. In addition, ACM adaptively removes conflicting pixels and exploits the network self-training capability to mine potential target information. Without bells and whistles, our MECPformer has reached new state-of-the-art $$72.0\%$$ mIoU on the PASCAL VOC 2012 and $$42.4\%$$ on MS COCO 2014 dataset. The code is available at https://github.com/ChunmengLiu1/MECPformer .},
  archive      = {J_NCA},
  author       = {Liu, Chunmeng and Li, Guangyao and Shen, Yao and Wang, Ruiqi},
  doi          = {10.1007/s00521-023-08816-2},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23249-23264},
  shortjournal = {Neural Comput. Appl.},
  title        = {MECPformer: Multi-estimations complementary patch with CNN-transformers for weakly supervised semantic segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A study on the placement of photovoltaic units in the north
and south of vietnam for energy loss reduction by using a proposed slime
mould algorithm. <em>NCA</em>, <em>35</em>(31), 23225–23247. (<a
href="https://doi.org/10.1007/s00521-023-08982-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the impact of rated power and the total capacity of all photovoltaic units on the energy loss reduction of radial distribution networks is investigated. An IEEE 69-node system is supposed to be a radial distribution network in the North and South of Vietnam to take the real mean solar radiations of 1 year from the global solar map for simulation. Five study cases are implemented corresponding to the difference of rated power of five installed photovoltaic units, including optimal size and four fixed sizes of 250, 500, 750 and 1000 kW. The proposed modified slime mould algorithm (MSMA) and three other algorithms including the original Coot optimization algorithm (COA), original Transient search optimization algorithm (TSOA) and original slime mould algorithm (SMA) are used to find optimal solutions of the five study cases. As a result, MSMA is the best method for reaching smaller 1-year energy loss and finding a higher number of more effective solutions than others. In addition, the study also suggests the placement of photovoltaic units should use optimal rated power for each unit and optimal total capacity for all units rather than using the same rated power for each unit and a predetermined total capacity for all units.},
  archive      = {J_NCA},
  author       = {Kien, Le Chi and Nguyen, Thuan Thanh and Phan, Tan Minh and Nguyen, Thang Trung},
  doi          = {10.1007/s00521-023-08982-3},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23225-23247},
  shortjournal = {Neural Comput. Appl.},
  title        = {A study on the placement of photovoltaic units in the north and south of vietnam for energy loss reduction by using a proposed slime mould algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Vision transformer with multiple granularities for person
re-identification. <em>NCA</em>, <em>35</em>(31), 23213–23223. (<a
href="https://doi.org/10.1007/s00521-023-08913-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting discriminative features using vision transformer is a popular research direction for person re-identification. However, feature extraction of existing vision transformer is relatively simple. To solve this problem, we design a vision transformer with multiple granularities for person re-identification. We propose three stages of multi-granularity feature extraction, including stage1 (shuffle), stage2 (split and concat) and stage3 (refine and enhance), which help the model to extract local and global fine features in strips. The highlight block is added in stage3 to enhance features by mathematical variation, which will highlight and strengthen the core features that are beneficial to classification. In addition, the loss function is optimized by introducing Circle Loss on top of ID Loss and Triplet Loss, and using the weighted sum of the three as the final loss function. Finally, we evaluated the performance of our method on three standard benchmark datasets: Market-1501, DukeMTMC-reID and MSMT17, and experimental results show that our method is superior to the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Chen, Bingcai and Zhang, Fansheng and Yang, Xin and Ning, Qian and Leung, Victor C. M.},
  doi          = {10.1007/s00521-023-08913-2},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23213-23223},
  shortjournal = {Neural Comput. Appl.},
  title        = {Vision transformer with multiple granularities for person re-identification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnosis of breast cancer based on hybrid features
extraction in dynamic contrast enhanced magnetic resonance imaging.
<em>NCA</em>, <em>35</em>(31), 23199–23212. (<a
href="https://doi.org/10.1007/s00521-023-08909-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer develops in breast cells. It is the most common type of cancer in women and the second most lethal disease after lung cancer. The presence of breast masses is an important symptom for detecting breast cancer in its early stages. This study proposes a hybrid features extraction method to improve the automatic detection of breast cancer by combining three feature extraction methods: Kinetic Features, convolutional neural network deep learning features, and the newly proposed Quantum Chebyshev polynomials model. The long short-term memory model is used as a classifier in this study to detect breast cancer automatically, which could reduce human errors in the diagnosis process. The experimental results using a large publicly available dataset achieved a detection accuracy of 99.50\% for hybrid features in post-contrast 2, potentially reducing human errors in the diagnosis process.},
  archive      = {J_NCA},
  author       = {Hasan, Ali M. and Aljobouri, Hadeel K. and Al-Waely, Noor K. N. and Ibrahim, Rabha W. and Jalab, Hamid A. and Meziane, Farid},
  doi          = {10.1007/s00521-023-08909-y},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23199-23212},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diagnosis of breast cancer based on hybrid features extraction in dynamic contrast enhanced magnetic resonance imaging},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A discrete heuristic algorithm with swarm and evolutionary
features for data replication problem in distributed systems.
<em>NCA</em>, <em>35</em>(31), 23177–23197. (<a
href="https://doi.org/10.1007/s00521-023-08853-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Availability and accessibility of data objects in a reasonable time is a main issue in distributed systems like cloud computing services. As a result, the reduction of data-related operation times in distributed systems such as data read/write has become a major challenge in the development of these systems. In this regard, replicating the data objects on different servers is one commonly used technique. In general, replica placement plays an essential role in the efficiency of distributed systems and can be implemented statically or dynamically. Estimation of the minimum number of data replicas and the optimal placement of the replicas is an NP-complete optimization problem. Hence, different heuristic algorithms have been proposed for optimal replica placement in distributed systems. Reducing data processing costs as well as the number of replicas, and increasing the reliability of the replica placement algorithms are the main goals of this research. This paper presents a discrete and swarm-evolutionary method using a combination of shuffle-frog leaping and genetic algorithms to data-replica placement problems in distributed systems. The experiments on the standard dataset show that the proposed method reduces data access time by up to 30\% with about 14 replicas; whereas the generated replicas by the GA and ACO are, respectively, 24 and 30. The average reduction in data access time by GA and ACO 21\% and 18\% which shows less efficiency than the SFLA–GA algorithm. Regarding the results, the SFLA–GA converges on the optimal solution before the 10th iteration, which shows the higher performance of the proposed method. Furthermore, the standard deviation among the results obtained by the proposed method on several runs is about 0.029, which is lower than other algorithms. Additionally, the proposed method has a higher success rate than other algorithms in the replica placement problem.},
  archive      = {J_NCA},
  author       = {Arasteh, Bahman and Allahviranloo, Tofigh and Funes, Peri and Torkamanian-Afshar, Mahsa and Khari, Manju and Catak, Muammer},
  doi          = {10.1007/s00521-023-08853-x},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23177-23197},
  shortjournal = {Neural Comput. Appl.},
  title        = {A discrete heuristic algorithm with swarm and evolutionary features for data replication problem in distributed systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid deep learning cost evaluation using CNN with ANN for
the plastic injection industry. <em>NCA</em>, <em>35</em>(31),
23153–23175. (<a
href="https://doi.org/10.1007/s00521-023-08947-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The plastic injection moulding industry has been growing and expanding rapidly. Cost evaluation is important to business operations and numerous aspects influence part pricing. However, the intricacy of production data often includes distinctive factors that result in inaccurate and a long waiting time. Therefore, the objective of this research is to propose a cost evaluation approach that combines a 3-dimension convolutional neural network (3D-CNN) with an artificial neural network (ANN) to improve the accuracy of complex geometry from a dense voxel of convolutional neural network (CNN) that can disentangle the difficulty of primary cost evaluation. The methodology consists of 3D-voxelization adopted to 3-dimension convolutional neural network (3D-CNN) and the feature extraction of complex geometry to feature parameters using the learning ability of artificial neural network (ANN) to achieve better accuracy. Then, bulk price analysis is developed for multi-price in-depth for multi-volumes. These results can predict cost evaluation at about 98.65\% accuracy for parts costs, 95.17\% accuracy for mould costs, and 96.83\% of multi-price for multi-volume. The contribution of this research is based upon a new hybrid deep learning using 3-dimension convolutional neural network (3D-CNN) with artificial neural network (ANN) that is practical and accurate in performing cost evaluation multi-prices for multi-volumes for decision-making in the plastic injection industry.},
  archive      = {J_NCA},
  author       = {Kengpol, Athakorn and Tabkosai, Pornthip},
  doi          = {10.1007/s00521-023-08947-6},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23153-23175},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid deep learning cost evaluation using CNN with ANN for the plastic injection industry},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The pickup and delivery hybrid-operations of AGV
conflict-free scheduling problem with time constraint among multi-FMCs.
<em>NCA</em>, <em>35</em>(31), 23125–23151. (<a
href="https://doi.org/10.1007/s00521-023-08897-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since much emphasis has been put on the eco-friendly manufacturing process in industries, and the complex changes in market demands, this paper focuses on a green scheduling problem of automated guided vehicles (AGVs) in a flexible manufacturing system (FMS). The studied FMS consists of multi-FMCs (flexible manufacturing cells) which have many material handling needs with time constraints. Distinguished from other AGV scheduling problems in FMS, this paper concentrates on the pickup and delivery operations or even bi-handling requirements of AGVs for FMCs, ignoring the inner production process within them. To solve this problem, a bi-objective mathematical model is built trying to minimize the total tardiness and energy consumption of AGVs simultaneously. Some properties of the problem and a no-collision algorithm are developed for the potential conflicts among AGVs. Due to the NP-hard nature of the proposed problem, a hyper-heuristic (HH) algorithm based on a double deep Q network (DDQN) is introduced, which benefits from the structures of double decision networks and multi-operator. To improve the performance of the proposed algorithm, the experience pool is used to increase the convergence speed and the crowding distance, and the non-dominated sorting strategies are presented to decide the acceptance of the new generation. Besides, in the DDQN, the states and rewards of agents are designed based on the characteristics of the scheduling problem. Finally, many experiments have been conducted and the computational results reveal that the proposed DDQN-HH algorithm outperforms the other two compared algorithms in both the convergence speed and quality of solutions.},
  archive      = {J_NCA},
  author       = {Zhou, Binghai and Lei, Yuanrui},
  doi          = {10.1007/s00521-023-08897-z},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23125-23151},
  shortjournal = {Neural Comput. Appl.},
  title        = {The pickup and delivery hybrid-operations of AGV conflict-free scheduling problem with time constraint among multi-FMCs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning: Systematic review, models, challenges, and
research directions. <em>NCA</em>, <em>35</em>(31), 23103–23124. (<a
href="https://doi.org/10.1007/s00521-023-08957-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current development in deep learning is witnessing an exponential transition into automation applications. This automation transition can provide a promising framework for higher performance and lower complexity. This ongoing transition undergoes several rapid changes, resulting in the processing of the data by several studies, while it may lead to time-consuming and costly models. Thus, to address these challenges, several studies have been conducted to investigate deep learning techniques; however, they mostly focused on specific learning approaches, such as supervised deep learning. In addition, these studies did not comprehensively investigate other deep learning techniques, such as deep unsupervised and deep reinforcement learning techniques. Moreover, the majority of these studies neglect to discuss some main methodologies in deep learning, such as transfer learning, federated learning, and online learning. Therefore, motivated by the limitations of the existing studies, this study summarizes the deep learning techniques into supervised, unsupervised, reinforcement, and hybrid learning-based models. In addition to address each category, a brief description of these categories and their models is provided. Some of the critical topics in deep learning, namely, transfer, federated, and online learning models, are explored and discussed in detail. Finally, challenges and future directions are outlined to provide wider outlooks for future researchers.},
  archive      = {J_NCA},
  author       = {Talaei Khoei, Tala and Ould Slimane, Hadjar and Kaabouch, Naima},
  doi          = {10.1007/s00521-023-08957-4},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23103-23124},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning: Systematic review, models, challenges, and research directions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drone cybersecurity issues, solutions, trend insights and
future perspectives: A survey. <em>NCA</em>, <em>35</em>(31),
23063–23101. (<a
href="https://doi.org/10.1007/s00521-023-08857-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presented an exhaustive survey on the security and privacy issues of drones. These security concerns were thoroughly dissected, particularly the aspect of cybersecurity, which was classified into nine levels. These levels include emerging issues, communication-based attacks, sensors, hardware, hardware-based attacks, software attacks, and physical attacks on the drone itself. Furthermore, we discussed the other non-cybersecurity challenges of drones, such as terrorism, mid-air collisions, illegal surveillance, smuggling, electronic snooping, and reconnaissance, alongside proffering possible solutions. Many of the discovered aspects of drone cybersecurity issues were then quantitatively analyzed using a multi-criteria decision-making problem-solving technique. The questionnaire responses from the general public, experts, and stakeholders in the aviation industry were analyzed. The findings revealed variations in cyber-attack techniques such as distributed denial-of-service (DDoS), denial-of-service (DoS), hacking, jamming, spoofing, electronic snooping, eavesdropping, advanced persistent threat (APT), reconnaissance, hijacking, man-in-the-middle attack, and so on. However, the majority of the participants in the survey, which constitute 70\%, were unaware of the existing drone cybersecurity challenges. The remaining 30\% were aware of the current drone security issues. Meanwhile, both parties are looking for an immediate solution that will fully provide an atmosphere of prospects in the drone industry. Following that, we presented our experience with drone security and privacy, as well as potential future research directions. This paper is unique in that it discusses the various types of drone cyber-attacks and non-cyber-attack scenarios that threaten the socio-economic system, aviation industry, national security, as well as public security and privacy concerns. It also offers solutions to the cyber-attack and non-cyber-attack cases that have been investigated. As a result, the findings of this study could be used to create, develop, and implement more secure cloud systems to safeguard drones from cyber and non-cyber-attacks.},
  archive      = {J_NCA},
  author       = {Omolara, Abiodun Esther and Alawida, Moatsum and Abiodun, Oludare Isaac},
  doi          = {10.1007/s00521-023-08857-7},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23063-23101},
  shortjournal = {Neural Comput. Appl.},
  title        = {Drone cybersecurity issues, solutions, trend insights and future perspectives: A survey},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning based multipurpose medical image
watermarking. <em>NCA</em>, <em>35</em>(31), 23041–23062. (<a
href="https://doi.org/10.1007/s00521-023-08457-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital data security has become an exigent area of research due to a huge amount of data availability at present time. Some of the fields like medical imaging and medical data sharing over communication platforms require high security against counterfeit access, manipulation and other processing operations. It is essential because the changed/manipulated data may lead to erroneous judgment by medical experts and can negatively influence the human’s heath. This work offers a blind and robust medical image watermarking framework using deep neural network to provide effective security solutions for medical images. During watermarking, the region of interest (ROI) data of the original image is preserved by employing the LZW (Lampel-Ziv-Welch) compression algorithm. Subsequently the robust watermark is inserted into the original image using IWT (integer wavelet transform) based embedding approach. Next, the SHA-256 algorithm-based hash keys are generated for ROI and RONI (region of non-interest) regions. The fragile watermark is then prepared by ROI recovery data and the hash keys. Further, the LSB replacement-based insertion mechanism is utilized to embed the fragile watermark into RONI embedding region of robust watermarked image. A deep neural network-based framework is used to perform robust watermark extraction for efficient results with less computational time. Simulation results verify that the scheme has significant imperceptibility, efficient robust watermark extraction, correct authentication and completely reversible nature for ROI recovery. The relative investigation with existing schemes confirms the dominance of the proposed work over already existing work.},
  archive      = {J_NCA},
  author       = {Sinhal, Rishi and Ansari, Irshad Ahmad},
  doi          = {10.1007/s00521-023-08457-5},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23041-23062},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning based multipurpose medical image watermarking},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Threat object-based anomaly detection in x-ray images using
GAN-based ensembles. <em>NCA</em>, <em>35</em>(31), 23025–23040. (<a
href="https://doi.org/10.1007/s00521-022-08029-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of detecting dangerous or prohibited objects in luggage is a very important step during the implementation of Security setup at Airports, Banks, Government buildings, etc. At present, the most common techniques for detecting such dangerous objects are by using intelligent data analysis algorithms such as deep learning techniques on X-ray imaging or employing a human workforce for inferring the presence of these threat objects in the obtained X-ray images. One of the major challenges while using deep-learning methods to detect such objects is the lack of high-quality threat image data containing the “dangerous” objects (objects of interest) versus the non-threat image data in practical scenarios. So, to tackle this data scarcity problem, anomaly detection techniques using normal data samples have shown great promise. Also, among the available Deep Learning Strategies for anomaly detection for computer vision applications, generative adversarial networks have achieved state-of-the-art results. Considering these insights, we adopted a newly proposed architecture known as Skip-GANomaly and devised a modified version of it by using a UNet++ style generator which performed better than Skip-GANomaly, getting an AUC of 94.94\% on Compass-XP, a public X-ray dataset. Finally, for targeting better latent space exploration, we combine these two architectures into an Ensemble, which gives another boost to the performance, getting an AUC of 96.8\% on the same Compass-XP, a public X-ray dataset. To further validate the effectiveness of ensemble-based architecture, its performance was tested on patch-based training data on a subset of randomly chosen images of another huge public X-ray dataset named as SIXray, and obtained an AUC of 75.3\% on this reduced dataset. To demonstrate the prowess of the discriminator and to bring some explainability to the working of our ensemble, we have used Uniform Manifold Approximation and Projection to plot the latent-space vectors for the dangerous and non-dangerous objects of the test-set; this analysis indicates that the Ensemble learns better features for separating the anomalous class from non-anomalous with respect to the individual architectures. Thus, our proposed architecture provides state-of-the-art results for threat object detection. Most importantly, our models are able to detect threat objects without ever being trained on images containing threat objects.},
  archive      = {J_NCA},
  author       = {Kolte, Shreyas and Bhowmik, Neelanjan and Dhiraj},
  doi          = {10.1007/s00521-022-08029-z},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23025-23040},
  shortjournal = {Neural Comput. Appl.},
  title        = {Threat object-based anomaly detection in X-ray images using GAN-based ensembles},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IoT inspired smart environment for personal healthcare in
gym. <em>NCA</em>, <em>35</em>(31), 23007–23023. (<a
href="https://doi.org/10.1007/s00521-022-07488-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has the ability to collect health-related data from surroundings. As a result, the Cloud Centric IoT (CCIoT) Technology is used in this paper to measure a trainee’s health-related traits during fitness time in a gym. The proposed system can forecast a trainee’s probabilistic sensitivity to health status during workouts. Back-propagation based Artificial Neural Network (ANN) methodology is used as a prediction model for this purpose, and it is divided into 3 phases: Observation, Learning, and Prediction. In addition, the trainee’s health status is depicted in real-time using a colour scheme strategy that depicts the probabilistic vulnerability. The presented framework was tested by a 6 day trial in which five individuals were supervised at various gymnasiums. For assessing the general efficacy of the proposed framework, the outcomes are compared to various state-of-the-art approaches in terms of prediction efficiency, temporal prediction, and stability.},
  archive      = {J_NCA},
  author       = {Ahanger, Tariq Ahamed},
  doi          = {10.1007/s00521-022-07488-8},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {23007-23023},
  shortjournal = {Neural Comput. Appl.},
  title        = {IoT inspired smart environment for personal healthcare in gym},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognition of multi-cognitive tasks from EEG signals using
EMD methods. <em>NCA</em>, <em>35</em>(31), 22989–23006. (<a
href="https://doi.org/10.1007/s00521-022-07425-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental task classification (MTC), based on the electroencephalography (EEG) signals is a demanding brain–computer interface (BCI). It is independent of all types of muscular activity. MTC-based BCI systems are capable to identify cognitive activity of human. The success of BCI system depends upon the efficient feature representation from raw EEG signals for classification of mental activities. This paper mainly presents on a novel feature representation (formation of most informative features) of the EEG signal for the both, binary as well as multi MTC, using a combination of some statistical, uncertainty and memory- based coefficient. In this work, the feature formation is carried out in the two stages. In the first stage, the signal is split into different oscillatory functions with the help of three well-known empirical mode decomposition (EMD) algorithms, and a new set of eight parameters (features) are calculated from the oscillatory function in the second stage of feature vector construction. Support vector machine (SVM) is used to classify the feature vectors obtained corresponding to the different mental tasks. This study consists the problem formulation of two variants of MTC; two-class and multi-class MTC. The suggested scheme outperforms the existing work for the both types of mental tasks classification.},
  archive      = {J_NCA},
  author       = {Gupta, Akshansh and Kumar, Dhirendra and Verma, Hanuman and Tanveer, M. and Javier, Andreu Perez and Lin, Chin-Teng and Prasad, Mukesh},
  doi          = {10.1007/s00521-022-07425-9},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22989-23006},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recognition of multi-cognitive tasks from EEG signals using EMD methods},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Examining the effect of intellectual devices for healthiness
using flower bee algorithm. <em>NCA</em>, <em>35</em>(31), 22971–22987.
(<a href="https://doi.org/10.1007/s00521-022-07172-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern days, for the perseverance of monitoring the vigor of a specific individual, the Wireless Body Sensor Networks have been emerging as an auspicious platform. The foremost challenge such as energy, path loss, and transmission distance that is prevalent from early days has been addressed in this article. The focal notion specified in this exploration is to discover the sensor locations on a human body that is much suitable for interconnecting the information about the intact body thus satisfying all the objectives. The focal difference between the proposed technique and the existing methods is that the projected methodology enacts multiple objectives as an alternative of distinct impartial. Further, the problem of finding the locations of sensors has been executed on an online monitoring system using MATLAB platform where the consequences are found to be improved practically for about 65\% when compared with existing literature.},
  archive      = {J_NCA},
  author       = {Teekaraman, Yuvaraja and Manoharan, Hariprasath and Kuppusamy, Ramya},
  doi          = {10.1007/s00521-022-07172-x},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22971-22987},
  shortjournal = {Neural Comput. Appl.},
  title        = {Examining the effect of intellectual devices for healthiness using flower bee algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence-assisted blockchain-based framework
for smart and secure EMR management. <em>NCA</em>, <em>35</em>(31),
22959–22969. (<a
href="https://doi.org/10.1007/s00521-022-07087-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare professionals, patients, and other stakeholders have been storing medical prescriptions and other relevant reports electronically. These reports contain the personal information of the patients, which is sensitive data. Therefore, there exists a need to store these records in a decentralized model (using IPFS and Ethereum decentralized application) to provide data and identity protection. Many patients recurrently visit doctors and undergo treatments while receiving different prescriptions and reports. In case of an emergency, the doctors and attendants may need and benefit from the patients’ medical history. However, they are unable to go through medical history and a wide range of previous reports and prescriptions due to time constraints. In this paper, we propose an AI-assisted blockchain-based framework in which the stored medical records (handwritten prescriptions, printed prescriptions, and printed reports) are stored and processed using various AI techniques like optical character recognition (OCR) to form a single patient medical history report. The report concisely presents only the crucial information for convenience and perusal and is stored securely over a decentralized blockchain network for later use.},
  archive      = {J_NCA},
  author       = {Chamola, Vinay and Goyal, Adit and Sharma, Pranab and Hassija, Vikas and Binh, Huynh Thi Thanh and Saxena, Vikas},
  doi          = {10.1007/s00521-022-07087-7},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22959-22969},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial intelligence-assisted blockchain-based framework for smart and secure EMR management},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conquering insufficient/imbalanced data learning for the
internet of medical things. <em>NCA</em>, <em>35</em>(31), 22949–22958.
(<a href="https://doi.org/10.1007/s00521-022-06897-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a data augmentation technique that solves insufficient/imbalanced data problems during crowdsensing by the Internet of Medical Things (IoMT) or wireless sensor networks (WSNs), owing to diversified locations and heterogeneous conditions. This may cause problems because the samples in various categories may vary in quantities, which create skew distributions. Besides, pattern analysis of insufficient observed samples also generates biased models. In view of such, this work proposes synthetic minority oversampling generative adversarial networks (SMOGANs) for processing imbalanced data, where insufficient samples in quantities can be automatically expanded, so that different classes contain equal numbers of samples, subsequently avoiding biased modeling. The SMOGAN consists of two modules, where the first one is the synthetic minority oversampling technique (SMOTE), and the second involves a GAN. The former is used to initialize the proposed system, in which insufficient/imbalanced data samples are roughly augmented in quantities. Subsequently, the GAN enriches feature diversities of those pseudoreal samples formerly augmented by the SMOTE. Experiments on open datasets were carried out for evaluation. To assess the capability of data augmentation, only 4.00\% of the real data were reserved as minority classes and then sent into different data augmentation methods for comparison. Analytical results showed that the proposed SMOGANs outperformed the baselines. Accuracy was increased compared with the baselines. Such results showed that the proposed SMOGAN could improve data collection problems of insufficient/imbalanced datasets by enhancing data quantities and qualities.},
  archive      = {J_NCA},
  author       = {Lan, Zi-Ching and Huang, Guan-Yu and Li, Yun-Pei and Rho, Seungmin and Vimal, S. and Chen, Bo-Wei},
  doi          = {10.1007/s00521-022-06897-z},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22949-22958},
  shortjournal = {Neural Comput. Appl.},
  title        = {Conquering insufficient/imbalanced data learning for the internet of medical things},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Real-time emotional health detection using fine-tuned
transfer networks with multimodal fusion. <em>NCA</em>, <em>35</em>(31),
22935–22948. (<a
href="https://doi.org/10.1007/s00521-022-06913-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing and regulating human emotion or a wave of riding emotions are a vital life skill as it can play an important role in how a person thinks, behaves and acts. Accurate real-time emotion detection can revolutionize the human–computer interaction industry and has the potential to provide a proactive approach to mental health care. Several untapped sources of data, including social media data (psycholinguistic markers), multimodal data (audio and video signals) combined with the sensor-based psychophysiological and brain signals, help to comprehend the affective states and emotional experiences. In this work, we propose a model that utilizes three modalities, i.e., visual (facial expression and body gestures), audio (speech) and text (spoken content), to classify emotion into discrete categories based on Ekman’s model with an additional category for ‘neutral’ state. Transfer learning has been used with multistage fine-tuning for each modality instead of training on a single dataset to make the model generalizable. The use of multiple modalities allows integration of heterogeneous data from different sources effectively. The results of the three modalities are combined at the decision-level using weighted fusion technique. The proposed EmoHD model compares favorably to the state-of-the-art technique on two benchmark datasets MELD and IEMOCAP.},
  archive      = {J_NCA},
  author       = {Sharma, Aditi and Sharma, Kapil and Kumar, Akshi},
  doi          = {10.1007/s00521-022-06913-2},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22935-22948},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time emotional health detection using fine-tuned transfer networks with multimodal fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hint: Harnessing the wisdom of crowds for handling
multi-phase tasks. <em>NCA</em>, <em>35</em>(31), 22911–22933. (<a
href="https://doi.org/10.1007/s00521-021-06825-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resourcefulness of crowdsourcing can be used to handle a wide range of complex macro-tasks, such as travel planning, translation, and software development. Multi-phase tasks are a type of macro-task that consists of several subtasks distributed across multiple sequential phases. Due to the recent work’s disregard for the task’s sequential correlation, it is difficult for them to handle multi-stage tasks effectively. This work bridges this gap. We call this novel approach Hint, which incorporates task design, pre hoc worker coordination, and post hoc crowd work coordination. Starting with the task interface design, Hint makes workers aware of the relationship between phases in order to improve their processing abilities. Second, pre hoc coordination of workers is to organize the workers to do the tasks to lower the monetary costs required to meet a specific quality standard. Third, post hoc coordination of crowd work is through a decision tree-based coordination strategy. Extensive tests are carried out on real-world datasets to validate the desirable qualities of the suggested mechanism.},
  archive      = {J_NCA},
  author       = {Fang, Yili and Chen, Pengpeng and han, Tao},
  doi          = {10.1007/s00521-021-06825-7},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22911-22933},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hint: Harnessing the wisdom of crowds for handling multi-phase tasks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Challenges for ocular disease identification in the era of
artificial intelligence. <em>NCA</em>, <em>35</em>(31), 22887–22909. (<a
href="https://doi.org/10.1007/s00521-021-06770-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal image analysis is an integral and fundamental step towards the identification and classification of ocular diseases like glaucoma, diabetic retinopathy, macular edema, and cardiovascular diseases through computer-aided diagnosis systems. Various abnormalities are observed through retinal image modalities like fundus, fluorescein angiography, and optical coherence tomography by ophthalmologists, and computer science professionals. Retinal image analysis has gained a lot of importance in recent years due to advances in computational, storage, and image acquisition technologies. Better computational capabilities lead to a rise in the implementation of deep learning-based methods for ocular disease detection. Although deep learning promises better performance in this field, some issues like lack of well-labeled datasets, unavailability of large enough datasets, class imbalance, and model generalizability are yet to be addressed. Also, the real-time implementation of detection methods on new devices or existing hardware is an untouched area. This article highlights the development of retinal image analysis and related issues due to the introduction of AI-based methods. The methods are analyzed in terms of standard performance metrics on various publicly and privately available datasets.},
  archive      = {J_NCA},
  author       = {Gour, Neha and Tanveer, M. and Khanna, Pritee},
  doi          = {10.1007/s00521-021-06770-5},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22887-22909},
  shortjournal = {Neural Comput. Appl.},
  title        = {Challenges for ocular disease identification in the era of artificial intelligence},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A CNN-based modular classification scheme for motor imagery
using a novel EEG sampling protocol suitable for IoT healthcare systems.
<em>NCA</em>, <em>35</em>(31), 22865–22886. (<a
href="https://doi.org/10.1007/s00521-021-06716-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of brain-computer interfaces (BCI) for real-time has become a paramount technology. Implementation of real-time BCI systems requires of methodologies that achieve high performance on classification over general brain signals of different subjects. Therefore, this work presents two simple and efficient methodologies to classify two and four motor imageries. The methodology to classify two motor imageries (MC-TM) includes an analysis of feature extraction methods based on spatial patterns and time–frequency transforms; and a convolutional neural network that preserves the information of the magnitude in the frequency bands of the sensorimotor rhythms (CNN-PIM). Besides, the methodology to classify four motor imageries (MC-FM) includes a modular classification scheme that instances 6 CNN-PIM; a new algorithm that uses the output of the softmax of each CNN-PIM to enhance the performance of the MC-FM methodology; an electroencephalogram sampling protocol that includes a specific procedure for 4 MIs classes; and a new dataset with the brain signals of 15 subjects. The MC-TM methodology achieved an accuracy of 94.44 ± 02.18\% evaluated in BCI Competition IV dataset 2a (BCI-IV-2a), and accuracy of 97.67 ± 02.06\% when evaluated in the EEGdataset. Meanwhile, the MC-FM achieved accuracies of 91.37 ± 3.29\% and 86.48 ± 4.74\% when evaluated in BCI-IV-2a and in the proposed dataset, respectively. These results situate our methodologies in a competitive position in comparison with the state-of-the-art methods. Moreover, the approximate processing time that the MC-FM methodology takes to classify EEG signals is 270 ms. Thus, it is suitable to be implemented in a real-time BCI system.},
  archive      = {J_NCA},
  author       = {Chacon-Murguia, Mario I. and Rivas-Posada, Eduardo},
  doi          = {10.1007/s00521-021-06716-x},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22865-22886},
  shortjournal = {Neural Comput. Appl.},
  title        = {A CNN-based modular classification scheme for motor imagery using a novel EEG sampling protocol suitable for IoT healthcare systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new unsupervised pseudo-siamese network with two filling
strategies for image denoising and quality enhancement. <em>NCA</em>,
<em>35</em>(31), 22855–22863. (<a
href="https://doi.org/10.1007/s00521-021-06699-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital image noise may be introduced during acquisition, transmission, or processing and affects readability and image processing effectiveness. The accuracy of established image processing techniques, such as segmentation, recognition, and edge detection, is adversely impacted by noise. There exists an extensive body of work which focuses on circumventing such issues through digital image enhancement and noise reduction, but this work is limited by a number of constraints including the application of non-adaptive parameters, potential loss of edge detail information, and (with supervised approaches) a requirement for clean, labeled, training data. This paper, developed on the principle of Noise2Void, presents a new unsupervised learning approach incorporating a pseudo-siamese network. Our method enables image denoising without the need for clean images or paired noise images, instead requiring only noise images. Two independent branches of the network utilize different filling strategies, namely zero filling and adjacent pixel filling. Then, the network employs a loss function to improve the similarity of the results in the two branches. We also modify the Efficient Channel Attention module to extract more diverse features and improve performance on the basis of global average pooling. Experimental results show that compared with traditional methods, the pseudo-siamese network has a greater improvement on the ADNI dataset in terms of quantitative and qualitative evaluation. Our method therefore has practical utility in cases where clean images are difficult to obtain.},
  archive      = {J_NCA},
  author       = {Huang, Chenxi and Hong, Dan and Yang, Chenhui and Cai, Chunting and Tao, Siyi and Clawson, Kathy and Peng, Yonghong},
  doi          = {10.1007/s00521-021-06699-9},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22855-22863},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new unsupervised pseudo-siamese network with two filling strategies for image denoising and quality enhancement},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced lung image segmentation using deep learning.
<em>NCA</em>, <em>35</em>(31), 22839–22853. (<a
href="https://doi.org/10.1007/s00521-021-06719-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in technology, assistive medical systems are emerging with rapid growth and helping healthcare professionals. The proactive diagnosis of diseases with artificial intelligence (AI) and its aligned technologies has been an exciting research area in the last decade. Doctors usually detect tuberculosis (TB) by checking the lungs’ X-rays. Classification using deep learning algorithms is successfully able to achieve accuracy almost similar to a doctor in detecting TB. It is found that the probability of detecting TB increases if classification algorithms are implemented on segmented lungs instead of the whole X-ray. The paper’s novelty lies in detailed analysis and discussion of U-Net +  + results and implementation of U-Net +  + in lung segmentation using X-ray. A thorough comparison of U-Net +  + with three other benchmark segmentation architectures and segmentation in diagnosing TB or other pulmonary lung diseases is also made in this paper. To the best of our knowledge, no prior research tried to implement U-Net +  + for lung segmentation. Most of the papers did not even use segmentation before classification, which causes data leakage. Very few used segmentations before classification, but they only used U-Net, which U-Net +  + can easily replace because accuracy and mean_iou of U-Net +  + are greater than U-Net accuracy and mean_iou , discussed in results, which can minimize data leakage. The authors achieved more than 98\% lung segmentation accuracy and mean_iou 0.95 using U-Net +  + , and the efficacy of such comparative analysis is validated.},
  archive      = {J_NCA},
  author       = {Gite, Shilpa and Mishra, Abhinav and Kotecha, Ketan},
  doi          = {10.1007/s00521-021-06719-8},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22839-22853},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced lung image segmentation using deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Hybrid feature fusion for classification optimization of
short ECG segment in IoT based intelligent healthcare system.
<em>NCA</em>, <em>35</em>(31), 22823–22837. (<a
href="https://doi.org/10.1007/s00521-021-06693-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With more than 50 million people worldwide at risk of heart disease, early diagnosis of cardiovascular disease is essential. The classification of electrocardiogram (ECG) recordings can diagnose Atrial Fibrillation (AF) and other types of arrhythmia. Short ECG segments recorded from wearable devices in an IoT-based system can further provide continuous abnormality detection. The performance of ECG classification is usually high in normal segments, but much lower in the target classes, i.e., AF and other arrhythmias, which could result from class imbalance and limited feature representation. Deep learning methods have been employed as feature extractors in previous studies. Among them, convolutional neural networks (CNN) can generate rich features in different scales. But CNN may omit precise temporal information such as the duration between R-waves in two QRS waves (RR interval) irregularity, which is insensitive to noise segments. Thus, aiming at improving the classification performance of AF and other classes in short ECG segments, we propose a hybrid feature fusion method integrating the above-mentioned features. The fused features are trained and tested in a support vector machine classifier. The F1-score results show that our method outperforms not only the same CNN method without feature fusion in all the four classes, which average F1-score reached 84.3\% and classification time per single sample of 0.005 s, but also several state-of-the-art methods, especially in the target classes, which validates the effectiveness of the proposed method. We then further discuss the impact of length on the performance of the proposed method, providing insights into future applications.},
  archive      = {J_NCA},
  author       = {Zhang, Xianbin and Jiang, Mingzhe and Wu, Wanqing and de Albuquerque, Victor Hugo C.},
  doi          = {10.1007/s00521-021-06693-1},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22823-22837},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid feature fusion for classification optimization of short ECG segment in IoT based intelligent healthcare system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A simulated measurement for COVID-19 pandemic using the
effective reproductive number on an empirical portion of population:
Epidemiological models. <em>NCA</em>, <em>35</em>(31), 22813–22821. (<a
href="https://doi.org/10.1007/s00521-021-06579-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 as a global pandemic has had an unprecedented impact on the entire world. Projecting the future spread of the virus in relation to its characteristics for a specific suite of countries against a temporal trend can provide public health guidance to governments and organizations. Therefore, this paper presented an epidemiological comparison of the traditional SEIR model with an extended and modified version of the same model by splitting the infected compartment into asymptomatic mild and symptomatic severe. We then exposed our derived layered model into two distinct case studies with variations in mitigation strategies and non-pharmaceutical interventions (NPIs) as a matter of benchmarking and comparison. We focused on exploring the United Arab Emirates (a small yet urban centre (where clear sequential stages NPIs were implemented). Further, we concentrated on extending the models by utilizing the effective reproductive number (Rt) estimated against time, a more realistic than the static R0, to assess the potential impact of NPIs within each case study. Compared to the traditional SEIR model, the results supported the modified model as being more sensitive in terms of peaks of simulated cases and flattening determinations.},
  archive      = {J_NCA},
  author       = {Alsinglawi, Belal and Mubin, Omar and Alnajjar, Fady and Kheirallah, Khalid and Elkhodr, Mahmoud and Al Zobbi, Mohammed and Novoa, Mauricio and Arsalan, Mudassar and Poly, Tahmina Nasrin and Gochoo, Munkhjargal and Khan, Gulfaraz and Dev, Kapal},
  doi          = {10.1007/s00521-021-06579-2},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22813-22821},
  shortjournal = {Neural Comput. Appl.},
  title        = {A simulated measurement for COVID-19 pandemic using the effective reproductive number on an empirical portion of population: Epidemiological models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection and classification of alzheimer’s disease from
cognitive impairment with resting-state fMRI. <em>NCA</em>,
<em>35</em>(31), 22797–22812. (<a
href="https://doi.org/10.1007/s00521-021-06436-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection and classification of Alzheimer’s disease (AD) are a demanding field of research in medicine throws light on innovative approach in detecting and classifying AD from cognitive impairment with resting-state functional magnetic resonance imaging (rsfMRI). The goal of this research is chiefly aimed to diagnose mild cognitive impairment (MCI) patients who essentially need support for medical intervention. A new concept is presented in classifying AD and MCI from rsfMRI using Alzheimer&#39;s Disease Neuroimaging Initiative (ADNI) dataset. The images are preprocessed using some advanced technique to eliminate noise and parameter variations, and the preprocessed images are used for extracting the raw features. The rsfMRI is applied for feature selection processes in order to reduce feature dimensions using principal component analysis (PCA). The proposed kernel-based PCA-support vector regression (SVR) includes t-distributed stochastic neighbor embedding (tSNE) and polynomial kernel-based tSNE that are separately handled by significantly merging correlated local and class features. The kernel PCA method analysis the new features explicitly based on nonlinear mapping function in the data points of high-dimensional search. The kernel PCA method is suitable to analysis the new feature and feature importance in AD classification. The proposed kernel SVR method has the advantage of effectively analyzing the high-dimensional data to provide linear relationship and suitable to apply in MCI and AD data. The PCA method is applied for feature reduction process due to its capacity to select the relevant features and effectively analyzing the individual features. The proposed kernel-SVR method has the advantage of selecting the relevant features and avoid overfitting problem in the classifier. The SVR uses reduced features that are obtained from different reduction methods for classification of AD and MCI, a polynomial kernel based. The results showed that the proposed kernel-based PCA-SVR showed better average accuracy values 98.53\% for kernel PCA when compared the existing models hippocampal visual features of 79.15\% and deep neural network of 80.21\%},
  archive      = {J_NCA},
  author       = {Buvaneswari, PR. and Gayathri, R.},
  doi          = {10.1007/s00521-021-06436-2},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22797-22812},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection and classification of alzheimer’s disease from cognitive impairment with resting-state fMRI},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Realistic medical image super-resolution with pyramidal
feature multi-distillation networks for intelligent healthcare systems.
<em>NCA</em>, <em>35</em>(31), 22781–22796. (<a
href="https://doi.org/10.1007/s00521-021-06287-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two key requirements for medical lesion image super-resolution reconstruction in intelligent healthcare systems: clarity and reality. Because only clear and real super-resolution medical images can effectively help doctors observe the lesions of the disease. The existing super-resolution methods based on pixel space optimization often lack high-frequency details which result in blurred detail features and unclear visual perception. Also, the super-resolution methods based on feature space optimization usually have artifacts or structural deformation in the generated image. This paper proposes a novel pyramidal feature multi-distillation network for super-resolution reconstruction of medical images in intelligent healthcare systems. Firstly, we design a multi-distillation block that combines pyramidal convolution and shallow residual block. Secondly, we construct a two-branch super-resolution network to optimize the visual perception quality of the super-resolution branch by fusing the information of the gradient map branch. Finally, we combine contextual loss and L1 loss in the gradient map branch to optimize the quality of visual perception and design the information entropy contrast-aware channel attention to give different weights to the feature map. Besides, we use an arbitrary scale upsampler to achieve super-resolution reconstruction at any scale factor. The experimental results show that the proposed super-resolution reconstruction method achieves superior performance compared to other methods in this work.},
  archive      = {J_NCA},
  author       = {Ren, Sheng and Guo, Kehua and Ma, Jianguang and Zhu, Feihong and Hu, Bin and Zhou, Haoming},
  doi          = {10.1007/s00521-021-06287-x},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22781-22796},
  shortjournal = {Neural Comput. Appl.},
  title        = {Realistic medical image super-resolution with pyramidal feature multi-distillation networks for intelligent healthcare systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent-based smart power management for remote health
monitoring. <em>NCA</em>, <em>35</em>(31), 22771–22780. (<a
href="https://doi.org/10.1007/s00521-021-06040-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Internet of things (IoT) paradigm, wireless sensor networks (WSNs) contribute hugely by connecting all the devices for smart application purposes. The smart applications include smart healthcare system, as a key phenomenon of new era of medical service. Smart healthcare system consists of different techniques and approaches, and remote health monitoring is one of those important techniques of healthcare system, which helps doctors to monitor health of remotely located patients with different health statistics provided by sensors. This whole process should be fast, prompt in response and energy efficient which is tough with limited battery power of sensors. The article proposes a novel method for efficient utilization of power in WSNs, using artificial neural network-based technique self-organizing map (SOM) for clustering and distributed artificial intelligence (DAI) for power distribution in the nodes. The hybrid approach of SOM and multi-agent-based DAI results in better performance compared to other existing methods. The performance of the proposed method is validated with mathematical analysis and simulation results, which justifies the significance of the work for IoT environment.},
  archive      = {J_NCA},
  author       = {Goswami, Pratik and Mukherjee, Amrit and Sarkar, Bishal and Yang, Lixia},
  doi          = {10.1007/s00521-021-06040-4},
  journal      = {Neural Computing and Applications},
  number       = {31},
  pages        = {22771-22780},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-agent-based smart power management for remote health monitoring},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep feature fusion network using residual channel
shuffled attention for cassava leaf disease detection. <em>NCA</em>,
<em>35</em>(30), 22755–22770. (<a
href="https://doi.org/10.1007/s00521-023-08943-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cassava is a significant source of carbohydrates for tropical populations. However, diseases caused by agents such as bacteria, viruses, fungi, and phytoplasmas cause considerable economic damage to these crops. Existing methods for cassava disease detection require farmers to seek the assistance of agricultural experts for visual inspection and diagnosis, which is challenging and laborious. Most studies have employed pre-trained convolutional neural networks to detect diseases in cassava leaves. Also, it is essential to design customized deep neural networks specific to the target domain for precise classification. This research proposes a novel deep fusion of two networks, residual channel shuffled attention network and Efficientnet. The first network, RCSANet, was presented to capture contextual information using depthwise separable convolution effectively. It also integrates significant inter-spatial and inter-channel information using the triplet attention module and employs shuffled group convolution to capture features from distinct filter groups. As a result of incorporating the above architectural enhancements, the proposed feature fusion network exhibited better performance than the existing studies. The proposed network was trained on the Kaggle cassava leaf disease dataset with 21,367 samples and yielded a classification accuracy of 93.25\%.},
  archive      = {J_NCA},
  author       = {Karthik, R. and Menaka, R. and Siddharth, M. V. and Hussain, Sameeha and Murugan, Bala and Won, Daehan},
  doi          = {10.1007/s00521-023-08943-w},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22755-22770},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep feature fusion network using residual channel shuffled attention for cassava leaf disease detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-component graph collaborative filtering using
auxiliary information for TV program recommendation. <em>NCA</em>,
<em>35</em>(30), 22737–22754. (<a
href="https://doi.org/10.1007/s00521-023-08940-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems for TV programs play an important role in alleviating the information overload problem. Existing TV program recommendation methods either do not aggregate neighborhood information well to capture collaborative signals from interaction data, or fail to make good use of auxiliary information, because they ignore the heterogeneity of different entities and relationships. In this paper, we propose a multi-component graph collaborative filtering recommendation based on auxiliary information, which learns representations of user and program through heterogeneous data modeling and information propagation on graphs. We extract homogeneous subgraphs from the heterogeneous graph based on multiple symmetric meta-paths, learn the components of the node representation by performing graph convolution on the homogeneous subgraphs, and finally combine the components to obtain the complete user representation and program representation. Experiments on real-world datasets show that our approach can effectively improve the performance of TV program recommendations compared to the existing baselines.},
  archive      = {J_NCA},
  author       = {Yao, Zebin and Ji, Meiqi and Xing, Tongtong and Fu, Ruiling and Li, Sitong and Yin, Fulian},
  doi          = {10.1007/s00521-023-08940-z},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22737-22754},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-component graph collaborative filtering using auxiliary information for TV program recommendation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Normalized deep learning algorithms based information
aggregation functions to classify motor imagery EEG signal.
<em>NCA</em>, <em>35</em>(30), 22725–22736. (<a
href="https://doi.org/10.1007/s00521-023-08944-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the discipline of Brain-Computer-Interface (BCI) has attracted attention to exploiting Electroencephalograph (EEG) mental activities such as Motor Imagery (MI). Neurons in the human brain are activated during these MI tasks and generate an electrical potential of small magnitude reached to the scalp as a signal. Classification of MI data is a primary problem in BCI systems. Classification accuracy of these biomedical signals emerges as a significant task in the scientific community. This work proposes two main ideas: a new preprocessing technique based on four EEG frequency bands and a new stacking method for three deep-learning architectures used to decode three classes of MI signals. The preprocessing stage was introduced using Fast Fourier Transform to perform frequency analysis and data aggregation functions to enhance the data view. Performance was evaluated using well-defined metrics: accuracy, precision, recall, and f1-score for multiple batch sizes, optimizers, and epochs. Experimental results were evaluated using a publicly available dataset (BCI Competition IV dataset 2a) and local data collected from four subjects using the EMOTIV EPOC headset. The highest f1-scores achieved with the R-CNN model were 94\% and 84\% using the aforementioned datasets. Our proposed models also outperform many related models studied in the literature.},
  archive      = {J_NCA},
  author       = {Al-Hamadani, Ammar A. and Mohammed, Mamoun J. and Tariq, Suphian M.},
  doi          = {10.1007/s00521-023-08944-9},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22725-22736},
  shortjournal = {Neural Comput. Appl.},
  title        = {Normalized deep learning algorithms based information aggregation functions to classify motor imagery EEG signal},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning with ExtendeD exponential linear unit (DELU).
<em>NCA</em>, <em>35</em>(30), 22705–22724. (<a
href="https://doi.org/10.1007/s00521-023-08932-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activation functions are crucial parts of artificial neural networks. From the first perceptron created artificially up to today, many functions are proposed. Some of them are currently in common use, such as Rectified Linear Unit (ReLU) and Exponential Linear Unit (ELU) and other ReLU variants. In this article we propose a novel activation function, called ExtendeD Exponential Linear Unit (DELU). After its introduction and presenting its basic properties, by making various simulations with different datasets and architectures, we show that it may perform better than other activation functions in certain cases. While also inheriting most of the good properties of ReLU and ELU, DELU offers an increase of success in comparison with them by slowing the alignment of neurons in early stages of training process. In experiments, DELU performed better than other activation functions in general, for Fashion MNIST, CIFAR-10 and CIFAR-100 classification tasks with different sized Residual Neural Networks (ResNet). Specifically, DELU managed to reduce the error rate by sufficiently high confidence levels in CIFAR datasets in comparison with ReLU and ELU networks. In addition, DELU is compared in an image segmentation example as well. Also, compatibility of DELU is tested with different initializations, and statistical methods are employed to verify these success rates by using Z-score analysis, which may be considered as a different view of success assessment in neural networks.},
  archive      = {J_NCA},
  author       = {Çatalbaş, Burak and Morgül, Ömer},
  doi          = {10.1007/s00521-023-08932-z},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22705-22724},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning with ExtendeD exponential linear unit (DELU)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-mmlg: A novel framework of extracting multiple main
melodies from MIDI files. <em>NCA</em>, <em>35</em>(30), 22687–22704.
(<a href="https://doi.org/10.1007/s00521-023-08924-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an essential part of music, main melody is the cornerstone of music information retrieval. In the MIR’s sub-field of main melody extraction, the mainstream methods assume that the main melody is unique. However, the assumption cannot be established, especially for music with multiple main melodies such as symphony or music with many harmonies. Hence, the conventional methods ignore some main melodies in the music. To solve this problem, we propose a deep learning-based Multiple Main Melodies Generator (Multi-MMLG) framework that can automatically predict potential main melodies from a MIDI file. This framework consists of two stages: (1) main melody classification using a proposed MIDIXLNet model and (2) conditional prediction using a modified MuseBERT model. Experiment results suggest that the proposed MIDIXLNet model increases the accuracy of main melody classification from 89.62 to 97.37\%. In addition, this model requires fewer parameters (71.8 million) than the previous state-of-art approaches. We also conduct ablation experiments on the Multi-MMLG framework. In the best-case scenario, predicting meaningful multiple main melodies for the music are achieved.},
  archive      = {J_NCA},
  author       = {Zhao, Jing and Taniar, David and Adhinugraha, Kiki and Baskaran, Vishnu Monn and Wong, KokSheik},
  doi          = {10.1007/s00521-023-08924-z},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22687-22704},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-mmlg: A novel framework of extracting multiple main melodies from MIDI files},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ANWOA: An adaptive nonlinear whale optimization algorithm
for high-dimensional optimization problems. <em>NCA</em>,
<em>35</em>(30), 22671–22686. (<a
href="https://doi.org/10.1007/s00521-023-08917-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most competitive nature-inspired metaheuristic optimization algorithms is the whale optimization algorithm (WOA). This algorithm is proven awesome in solving complex and constrained multi-objective problems. It is also popularly used as a feature selection algorithm while solving non-deterministic polynomial-time hardness (NP-hard) problems. Many enhancements have been introduced in the literature for the WOA resulting in better optimization algorithms. Differently from these research efforts, this paper presents a novel version of the WOA called ANWOA. ANWOA considers producing two types of discrete chaotic maps that have suitable period states, and the highest sensitivity to initial conditions, randomness, and stability which in turn leads to optimal initial population selection and thus global optimality. The presented ANWOA uses two nonlinear parameters instead of the two linear ones which permeate both the exploration and exploitation phases of WOA, leading to accelerated convergence, better accuracy, and influential improvement in the spiral updating position. Additionally, a dynamic inertia weight coefficient is utilized to attain a suitable balance between the exploration and exploitation phases meanwhile improving the convergence speed. Furthermore, ANWOA uses circle map values that influence each random factor in the WOA and consequently ensuring not trapped in local optima with a promoted global optimum search. The empirical analysis is conducted in thirty-three benchmark functions, and the results show that the introduced novel algorithm is the most competitive one.},
  archive      = {J_NCA},
  author       = {Elmogy, Ahmed and Miqrish, Haitham and Elawady, Wael and El-Ghaish, Hany},
  doi          = {10.1007/s00521-023-08917-y},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22671-22686},
  shortjournal = {Neural Comput. Appl.},
  title        = {ANWOA: An adaptive nonlinear whale optimization algorithm for high-dimensional optimization problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SP2LSTM: A patch learning-based electrical load forecasting
for container terminal. <em>NCA</em>, <em>35</em>(30), 22651–22669. (<a
href="https://doi.org/10.1007/s00521-023-08878-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term electricity load forecasting plays a crucial role in modern container terminal. In this work, we design a short-term forecasting approach aimed at port load under the framework of patch learning. Firstly, singular spectrum analysis is applied to obtain denoised and noise features, respectively; then, a patch learning model based on the long short-term memory network is employed to address such a time-series forecasting problem. LSTM network and BiLSTM are considered as the global models to process denoised and noisy data, respectively, and convolutional neural network is selected as the patch model. Furthermore, an endpoint detection strategy is designed for adaptively identifying the positions of patches. The performance of the proposed model is tested and verified on a real Chinese container terminal load dataset. Experimental results show that the proposed approach, compared with state-of-the-art load forecasting models, has the greatest performance with respect to seven evaluation criteria.},
  archive      = {J_NCA},
  author       = {Cao, Jingjing and Chen, Yujia and Cao, Xiaohua and Wang, Qiang and Wang, Bo and Du, Jiepeng and Wen, Zhipeng},
  doi          = {10.1007/s00521-023-08878-2},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22651-22669},
  shortjournal = {Neural Comput. Appl.},
  title        = {SP2LSTM: A patch learning-based electrical load forecasting for container terminal},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mifanet: Multi-scale information fusion attention network
for determining hatching eggs activity via detecting PPG signals.
<em>NCA</em>, <em>35</em>(30), 22637–22649. (<a
href="https://doi.org/10.1007/s00521-023-08798-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to accurately detect dead embryos when developing vaccines. Detection of photoplethysmography signals can help determine hatching egg activity via convolutional neural networks, which is considered the most reliable and promising method in the industry. The existing detection methods face some challenges because the convolution operations have difficulty capturing global representations from PPG signals. In this study, we propose a composite network structure, termed MifaNet, to take advantage of self-attention mechanisms for enhanced convolution operations. MifaNet captures long-distance feature dependencies and local feature details through independent branches. A feature fusion module is used to fuse concurrent features and output the detection results. Extensive experiments were conducted on our dataset, and the results confirm that MifaNet outperforms state-of-the-art techniques.},
  archive      = {J_NCA},
  author       = {Guo, Quan and Geng, Lei and Xiao, Zhitao and Zhang, Fang and Liu, Yanbei},
  doi          = {10.1007/s00521-023-08798-1},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22637-22649},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mifanet: Multi-scale information fusion attention network for determining hatching eggs activity via detecting PPG signals},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-region building counting in satellite imagery using
counting consistency. <em>NCA</em>, <em>35</em>(30), 22621–22636. (<a
href="https://doi.org/10.1007/s00521-023-08923-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the number of buildings in any geographical region is a vital component of urban analysis, disaster management, and public policy decision. Deep learning methods for building localization and counting in satellite imagery, can serve as a viable and cheap alternative. However, these algorithms suffer performance degradation when applied to the regions on which they have not been trained. Current large datasets mostly cover the developed regions and collecting such datasets for every region is a costly, time-consuming, and difficult endeavor. In this paper, we propose an unsupervised domain adaptation method for counting buildings where we use a labeled source domain (developed regions) and adapt the trained model on an unlabeled target domain (developing regions). We initially align distribution maps across domains by aligning the output space distribution through adversarial loss. We then exploit counting consistency constraints, within-image count consistency, and across-image count consistency, to decrease the domain shift. Within-image consistency enforces that the building count in the whole image should be greater than or equal to the count in any of its sub-image. Across-image consistency constraint enforces that if an image contains considerably more buildings than the other image, then their sub-images shall also have the same order. These two constraints encourage the behavior to be consistent across and within the images, regardless of the scale. To evaluate the performance of our proposed approach, we collected and annotated a large-scale dataset consisting of challenging South Asian regions having higher building densities and irregular structures as compared to existing datasets. We perform extensive experiments to verify the efficacy of our approach and report improvements of approximately 7–20\% over the competitive baseline methods. The dataset and code are available here: https://github.com/intelligentMachines-ITU/domain-Adaptive-Building-Counting .},
  archive      = {J_NCA},
  author       = {Zakria, Muaaz and Rawal, Hamza and Sultani, Waqas and Ali, Mohsen},
  doi          = {10.1007/s00521-023-08923-0},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22621-22636},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-region building counting in satellite imagery using counting consistency},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time synchronization of complex-valued memristive
competitive neural networks based on two novel fixed-time stability
theorems. <em>NCA</em>, <em>35</em>(30), 22605–22620. (<a
href="https://doi.org/10.1007/s00521-023-08874-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fixed-time synchronization (FTS) of complex-valued memristive competitive neural networks (CVMCNNs) with mixed delays is the main topic of this paper. Firstly, two new fixed-time (FT) stability criteria are obtained. In the FT stability criterion, the exponent is usually positive, but the exponent can be less than zero and varies with the error state in this paper. Then, based on two new stability theorems, the FTS of CVMCNNs is studied in the sense of 1-norm and 2-norm, respectively, without dividing the complex-valued state variables into the real part (RP) and the imaginary part (IP). Finally, two numerical simulation examples are given to further demonstrate the validity and superiority of our results.},
  archive      = {J_NCA},
  author       = {Xu, Chenguang and Jiang, Minghui and Hu, Junhao},
  doi          = {10.1007/s00521-023-08874-6},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22605-22620},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fixed-time synchronization of complex-valued memristive competitive neural networks based on two novel fixed-time stability theorems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Photoelectric factor prediction using automated learning and
uncertainty quantification. <em>NCA</em>, <em>35</em>(30), 22595–22604.
(<a href="https://doi.org/10.1007/s00521-023-08911-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The photoelectric factor (PEF) is an important well-logging tool to distinguish between different types of reservoir rocks because PEF measurement is sensitive to elements with high atomic numbers. Furthermore, the ratio of rock minerals could be determined by combining PEF log with other well logs. However, PEF logs could be missing in some cases such as in old well logs and wells drilled with barite-based mud. Therefore, developing models for estimating missing PEF logs is essential in those circumstances. In this work, we developed various machine learning models to predict PEF values using the following well logs as inputs: bulk density (RHOB), neutron porosity (NPHI), gamma ray (GR), compressional and shear velocity. The predictions of PEF values using adaptive-network-fuzzy inference system (ANFIS) and artificial neural network (ANN) models have errors of about 16\% and 14\% average absolute percentage error (AAPE) in the testing dataset, respectively. Thus, a different approach was proposed that is based on the concept of automated machine learning. It works by automatically searching for the optimal model type and optimizes its hyperparameters for the dataset under investigation. This approach selected a Gaussian process regression (GPR) model for the accurate estimation of PEF values. The developed GPR model decreases the AAPE of the predicted PEF values in the testing dataset to about 10\% AAPE. This error could be further decreased to about 2\% by modeling the potential noise in the measurements using the GPR model.},
  archive      = {J_NCA},
  author       = {Alsamadony, Khalid and Ibrahim, Ahmed Farid and Elkatatny, Salaheldin and Abdulraheem, Abdulazeez},
  doi          = {10.1007/s00521-023-08911-4},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22595-22604},
  shortjournal = {Neural Comput. Appl.},
  title        = {Photoelectric factor prediction using automated learning and uncertainty quantification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel varying-parameter periodic rhythm neural network for
solving time-varying matrix equation in finite energy noise environment
and its application to robot arm. <em>NCA</em>, <em>35</em>(30),
22577–22593. (<a
href="https://doi.org/10.1007/s00521-023-08895-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving matrix equation with noise interference is a challenging problem in mathematical and engineering applications. Unlike the traditional recurrent neural network, a novel varying-parameter periodic rhythm neural network (VP-PRNN) is proposed and used to solve the time-varying matrix equation in finite energy noise environment online. Particularly, VP-PRNN can enable the state solution to converge to the theoretical solution rapidly and robustly, which is also proved by theoretical analysis. Four kinds of noise are used to test the system, which proves the effectiveness of VP-PRNN. Compared with the zeroing neural network and circadian rhythms learning network with fixed parameters, VP-PRNN with variable parameters shows superior convergence performance in the disturbance of finite energy noise.},
  archive      = {J_NCA},
  author       = {Li, Chunquan and Zheng, Boyu and Ou, Qingling and Wang, Qianqian and Yue, Chong and Chen, Limin and Zhang, Zhijun and Yu, Junzhi and Liu, Peter X.},
  doi          = {10.1007/s00521-023-08895-1},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22577-22593},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel varying-parameter periodic rhythm neural network for solving time-varying matrix equation in finite energy noise environment and its application to robot arm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ACRE: Actor-critic with reward-preserving exploration.
<em>NCA</em>, <em>35</em>(30), 22563–22576. (<a
href="https://doi.org/10.1007/s00521-023-08845-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While reinforcement learning (RL) algorithms have generated impressive strategies for a wide range of tasks, the performance improvements in continuous-domain, real-world problems do not follow the same trend. Poor exploration and quick convergence to locally optimal solutions play a dominant role. Advanced RL algorithms attempt to mitigate this issue by introducing exploration signals during the training procedure. This successful integration has paved the way to introduce signals from the intrinsic exploration branch. ACRE algorithm is a framework that concretely describes the conditions for such an integration, avoiding transforming the Markov decision process into time varying, and as a result, making the whole optimization scheme brittle and susceptible to instability. The key distinction of ACRE lies in the way of handling and storing both extrinsic and intrinsic rewards. ACRE is an off-policy, actor-critic style RL algorithm that separately approximates the forward novelty return. ACRE is shipped with a Gaussian mixture model to calculate the instantaneous novelty; however, different options could also be integrated. Using such an effective early exploration, ACRE results in substantial improvements over alternative RL methods, in a range of continuous control RL environments, such as learning from policy-misleading reward signals. Open-source implementation is available here: https://github.com/athakapo/ACRE .},
  archive      = {J_NCA},
  author       = {Kapoutsis, Athanasios Ch. and Koutras, Dimitrios I. and Korkas, Christos D. and Kosmatopoulos, Elias B.},
  doi          = {10.1007/s00521-023-08845-x},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22563-22576},
  shortjournal = {Neural Comput. Appl.},
  title        = {ACRE: Actor-critic with reward-preserving exploration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Single-scale robust feature representation for occluded
person re-identification. <em>NCA</em>, <em>35</em>(30), 22551–22562.
(<a href="https://doi.org/10.1007/s00521-023-08770-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occluded person re-identification (Re-ID) task has been a long-standing challenge since occlusions inevitably lead to the deficiency of pedestrian information. Most existing methods tackle the challenge by employing auxiliary models, including pose estimation or graph matching models, to learn multi-scale or part-level features. However, the methods heavily rely on the external cues, the performance degrades when the target pedestrian is occluded severely or occluded by another pedestrian. This paper develops a novel Re-ID model single-scale robust feature representation (SRFR) to learn discriminative single-scale features without external cues. Specifically, a light-weight spatial memory module is investigated which takes the advantages of key-value memory network to store occlusion features and utilizes self-attention architecture to get fine-grained features. Furthermore, a camera-constrained triplet loss (CTL) function is exploited to mitigate the negative effects of different pedestrian samples under the same camera on the basis of the triplet loss. Experimental results show the SRFR achieves superior performance on both occluded and holistic datasets, which prove that single-scale features can also work well on mining discriminative features.},
  archive      = {J_NCA},
  author       = {Song, Yihu and Liu, Shuaishi and Sun, Zhongbo and Zhou, Siyu},
  doi          = {10.1007/s00521-023-08770-z},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22551-22562},
  shortjournal = {Neural Comput. Appl.},
  title        = {Single-scale robust feature representation for occluded person re-identification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rough fermatean fuzzy decision-based approach for modelling
IDS classifiers in the federated learning of IoMT applications.
<em>NCA</em>, <em>35</em>(30), 22531–22549. (<a
href="https://doi.org/10.1007/s00521-023-08933-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems (IDSs) are commonly employed to mitigate network security threats in various fields, including federated learning applications within the Internet of Medical Things (IoMT). However, IDSs face challenges owing to the sheer volume of network traffic, high-dimensional datasets and the necessity for real-time detection. Although machine learning integration assists IDSs in overcoming these challenges, modelling difficulties persist due to varied evaluation criteria and levels of conflict and importance. Multi-criteria decision-making (MCDM) solutions have been utilised in IoMT and IDS, yet they fall short in capturing the subjective judgements of experts and rely on normalisation approaches, which can impact results. This study seeks to address these issues through the integration of robust MCDM methodologies, namely fuzzy-weighted zero-inconsistency (FWZIC) and fuzzy decision by opinion score method (FDOSM). Utilising rough Fermatean fuzzy sets (RFFSs), this integration produces precise solutions with reduced uncertainty. Our methodology involves adopting a decision matrix for IDS classifiers based on integrated evaluation criteria, followed by deriving new formulations and developments for RFFSs-based FDOSM and FWZIC for the modelling and weighting of criteria, respectively. Evaluations using datasets involving 125,973 records and 41 features across 17 evaluation criteria revealed that accuracy–security and training time–performance weights yielded the highest scores, whereas false negative rate–security and CPU time–performance criteria received the lowest weights. The random forest emerged as the optimal IDS classifier. Systematic modelling, sensitivity analysis and comparative studies confirmed the robustness of our results.},
  archive      = {J_NCA},
  author       = {Albahri, O. S. and Al-Samarraay, Mohammed S. and AlSattar, H. A. and Alamoodi, A. H. and Zaidan, A. A. and Albahri, A. S. and Zaidan, B. B. and Jasim, Ali Najm},
  doi          = {10.1007/s00521-023-08933-y},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22531-22549},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rough fermatean fuzzy decision-based approach for modelling IDS classifiers in the federated learning of IoMT applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Superpixel-based adaptive salient region analysis for
infrared and visible image fusion. <em>NCA</em>, <em>35</em>(30),
22511–22529. (<a
href="https://doi.org/10.1007/s00521-023-08916-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion aims to highlight the infrared target and preserve valuable texture details as much as possible. However, the infrared target needs to be more apparent in most image fusion methods. A large amount of infrared noise remains in the fusion results, significantly reducing the proportion of valuable texture details in the fusion results. How to highlight the salient of infrared targets, lower noise, and retain more valuable texture details in the fusion results still need to be solved. We propose an adaptive salient region analysis method based on superpixels (SSRA) for infrared and visible fusion to solve this problem. This method uses salient region analysis based on superpixels to highlight the salience region effectively. We design a texture detail fusion method based on brightness analysis of the visible image to suppress noise and keep more meaningful texture detail information. The experimental results show that our proposed method performs better in subjective vision and quantitative evaluation than some advanced methods. In addition, we also demonstrate that SSRA is capable of supporting high-level visual tasks well. Our code is publicly available at: https://github.com/VCMHE/SSRA .},
  archive      = {J_NCA},
  author       = {Li, Chengzhou and He, Kangjian and Xu, Dan and Tao, Dapeng and Lin, Xu and Shi, Hongzhen and Yin, Wenxia},
  doi          = {10.1007/s00521-023-08916-z},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22511-22529},
  shortjournal = {Neural Comput. Appl.},
  title        = {Superpixel-based adaptive salient region analysis for infrared and visible image fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MNoR-BERT: Multi-label classification of non-functional
requirements using BERT. <em>NCA</em>, <em>35</em>(30), 22487–22509. (<a
href="https://doi.org/10.1007/s00521-023-08833-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of Internet access, software is easily available on digital distribution platforms such as app stores. The distribution of software on these platforms makes user feedback more accessible and can be used from requirements engineering to software maintenance context. However, such user reviews might contain technical information about the app that can be valuable for developers and software companies. Due to pervasive use of mobile apps, a large amount of data is created by users on daily basis. Manual identification and classification of such reviews are time-consuming and laborious tasks. Hence, automating this process is essential for assisting developers in managing these reviews efficiently. Prior studies have focused on classification of these reviews into bug reports, user experience, and feature requests. Nevertheless to date, a very few research papers have extracted Non-Functional Requirements (NFRs) present in these reviews. NFRs are considered as the set of quality attributes such as reliability, performance, security and usability of the software. Previous studies have utilized machine learning techniques to classify these reviews into their respective classes. However, it was observed that existing studies treat review classification problems as single-label classification problem, and also underestimate the contextual relationship between the words of review statements. To alleviate this limitation, the proposed research work used a transfer learning model to classify multi-label app reviews into four NFRs: Dependability, Performance, Supportability, and Usability. The proposed approach evaluates the performance of the pre-trained language model for multi-label review classification. In this paper, a set of experiments are conducted to compare the performance of the proposed model against the baseline machine learning with binary relevance and keyword based approach. We evaluated our approach over a dataset of 6000 user reviews of 24 iOS apps. Experimental results show that the proposed model outperforms state-of-the-art baseline techniques with respect to precision, recall, and F1-measure.},
  archive      = {J_NCA},
  author       = {Kaur, Kamaljit and Kaur, Parminder},
  doi          = {10.1007/s00521-023-08833-1},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22487-22509},
  shortjournal = {Neural Comput. Appl.},
  title        = {MNoR-BERT: Multi-label classification of non-functional requirements using BERT},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessing the simulation of streamflow with the LSTM model
across the continental united states using the MOPEX dataset.
<em>NCA</em>, <em>35</em>(30), 22469–22486. (<a
href="https://doi.org/10.1007/s00521-023-08922-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to assess the spatiotemporal performance of Machine Learning-based techniques for simulating streamflow on a continental scale using Long-Sort Term Memory (LSTM) models. The dataset employed is derived from the Model Parameter Estimation Experiment (MOPEX), encompassing 438 watersheds across the US. MOPEX has the longest data record (55 years) compared to other datasets which makes it very suitable for LSTM training. The impact of incorporating vegetation Greenness Fraction (GF) in the LSTMGF model was assessed. To gauge the models’ performance, temporally and spatially, a range of assessment metrics were employed. Upon the integration of GF, the LSTM models either maintained or enhanced streamflow simulation across the US, contingent upon the watershed location and seasonal variations. Notably, the overall median KGE and Percent Bias (PB) values with the inclusion of GF were 0.723 and 4.09, in contrast to 0.717 and 4.94 without the incorporation of GF. In addition, the results indicated that LSTMGF had superior performance compared to LSTM in areas where there was significant seasonal variation in vegetation cover. Results show that using extensive data record (MOPEX) bolstered the performance of LSTM with a Kling-Gupta Efficiency (KGE) reaching up to 0.97 at certain stations compared to only 0.86 when 25 years are used for the training as it is the case of the Catchment Attributes and Meteorology for Large-sample Studies (CAMELS) dataset. These findings corroborate the potential for integrating LSTM models into continental scale hydrological models such as the NOAA NextGen National Water Model.},
  archive      = {J_NCA},
  author       = {Tounsi, Achraf and Abdelkader, Mohamed and Temimi, Marouane},
  doi          = {10.1007/s00521-023-08922-1},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22469-22486},
  shortjournal = {Neural Comput. Appl.},
  title        = {Assessing the simulation of streamflow with the LSTM model across the continental united states using the MOPEX dataset},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Fault diagnosis of air handling unit via combining
probabilistic slow feature analysis and attention residual network.
<em>NCA</em>, <em>35</em>(30), 22449–22467. (<a
href="https://doi.org/10.1007/s00521-023-08910-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the heating, ventilation and air conditioning (HVAC) system, the fault diagnosis of the air handling unit (AHU) is critical to ensure the proper operation of the whole system. The AHU system with complex feature variables is susceptible to noise in operation, which influences the diagnostic performance of the fault diagnosis approach. To further improve the fault diagnosis accuracy, this paper proposes an AHU fault diagnosis model based on probabilistic slow feature analysis (PSFA) and attention residual network (AResNet). Firstly, to suppress the influence of noise on fault diagnosis while dealing with the AHU dynamic temporal characteristics, the PSFA-based feature extraction method is proposed. Further, in order to focus on significant features and suppress unnecessary regional responses of the observed data, the AResNet is utilized to construct the fault diagnosis classifier. Before building the AResNet classifier, we adopt the data spatialization method to convert the process data into spatial grayscale images to achieve spatial placement of key features and enhance the spatial correlation characteristics between multiple features. Finally, detailed experiments and comparisons are made, in which three different intensities of noise are added to the experimental data provided by ASHRAE research project RP-1312. Experimental results show that the proposed PSFA-AResNet model has the best fault diagnosis performance at all three noise levels compared with other deep and shallow popular methods.},
  archive      = {J_NCA},
  author       = {Li, Chengdong and Yu, Yulong and Shang, Linyuan and Zhang, Hanyuan and Jiang, Yongqing},
  doi          = {10.1007/s00521-023-08910-5},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22449-22467},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fault diagnosis of air handling unit via combining probabilistic slow feature analysis and attention residual network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Power-law initialization algorithm for convolutional neural
networks. <em>NCA</em>, <em>35</em>(30), 22431–22447. (<a
href="https://doi.org/10.1007/s00521-023-08881-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Well-honed CNN architectures trained with massive labeled images datasets are the state-of-the-art solution in many fields. In this paper, the weights of five commonly used pre-trained models are carefully analyzed for extracting their numerical characteristics and spatial distribution law. The general characteristics are: (1) the weights of a single convolutional layer conform to the distribution of symmetric power law. (2) the power exponent at the center of its convolutional kernel is relatively large, and the power exponent decreases radially from the center. (3) the value range of power exponents between layers is continuous from $$- 0.5$$ to $$- 3.5$$ . Based on these founding, a weight initialization method is proposed in order to speed up the convergence and improve the performance of CNN models. The proposed weight initialization method is compared with several commonly used methods. Extensive experiments show that it can improve the convergence speed of the CNN models, and the model accuracy is improved by 1–3\%.},
  archive      = {J_NCA},
  author       = {Jiang, Kaiwen and Liu, Jian and Xing, Tongtong and Li, Shujing and Wu, Shunyao and Shao, Fengjing and Sun, Rencheng},
  doi          = {10.1007/s00521-023-08881-7},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22431-22447},
  shortjournal = {Neural Comput. Appl.},
  title        = {Power-law initialization algorithm for convolutional neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Obstacle avoidance for a robotic navigation aid using fuzzy
logic controller-optimal reciprocal collision avoidance (FLC-ORCA).
<em>NCA</em>, <em>35</em>(30), 22405–22429. (<a
href="https://doi.org/10.1007/s00521-023-08856-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic Navigation Aids (RNAs) assist visually impaired individuals in independent navigation. However, existing research overlooks diverse obstacles and assumes equal responsibility for collision avoidance among intelligent entities. To address this, we propose Fuzzy Logic Controller-Optimal Reciprocal Collision Avoidance (FLC-ORCA). Our FLC-ORCA method assigns responsibility for collision avoidance and predicts the velocity of obstacles using a LiDAR-based mobile robot. We conduct experiments in the presence of static, dynamic, and intelligent entities, recording navigation paths, time taken, angle changes, and rerouting occurrences. The results demonstrate that the proposed FLC-ORCA successfully avoids collisions among objects with different collision avoidance protocols and varying liabilities in circumventing obstacles. Comparative analysis reveals that FLC-ORCA outperforms other state-of-the-art methods such as Improved A* and Directional Optimal Reciprocal Collision Avoidance (DORCA). It reduces the overall time taken to complete navigation by 16\% and achieves the shortest completion time of 1 min and 38 s, with minimal rerouting (1 occurrence) and the smallest angle change (12°). Our proposed FLC-ORCA challenges assumptions of equal responsibility and enables collision avoidance without pairwise manoeuvres. This approach significantly enhances obstacle avoidance, ensuring safer and more efficient robotic navigation for visually impaired individuals.},
  archive      = {J_NCA},
  author       = {Mohd Romlay, Muhammad Rabani and Mohd Ibrahim, Azhar and Toha, Siti Fauziah and De Wilde, Philippe and Venkat, Ibrahim and Ahmad, Muhammad Syahmi},
  doi          = {10.1007/s00521-023-08856-8},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22405-22429},
  shortjournal = {Neural Comput. Appl.},
  title        = {Obstacle avoidance for a robotic navigation aid using fuzzy logic controller-optimal reciprocal collision avoidance (FLC-ORCA)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level wavelet network based on CNN-transformer hybrid
attention for single image deraining. <em>NCA</em>, <em>35</em>(30),
22387–22404. (<a
href="https://doi.org/10.1007/s00521-023-08899-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Removing rain streaks from rainy images can improve the accuracy of computer vision applications such as object detection. In order to make full use of the frequency domain analysis characteristics of wavelet and combine the advantages of Convolutional Neural Network (CNN) and Transformer, a Multi-level Wavelet Network Based on CNN-Transformer Hybrid Attention (MWN-CTHA) for single image deraining is proposed. MWN-CTHA obtains multi-scale low-frequency and high-frequency images through multi-level non-separable lifting wavelet transform and uses CNN-Transformer Hybrid Attention Block (CTHAB) to learn global structure and detail information from low-frequency and high-frequency, respectively. CTHAB consists of CA-SA Layer (CSL) and Detail-enhanced Attention Feed-forward Layer (DAFL). CSL uses the non-local modeling ability of self-attention to capture long-range rain streaks and uses convolutional attention to enhance the search ability for local rain streaks, where convolution can assist self-attention to achieve better feature representation. DAFL utilizes Depth-wise Convolutional Layer to supplement detailed features and filters the information of feed-forward layer through Dual-branch Attention. The experimental results on the four synthetic datasets demonstrate that the proposed method achieves higher PSNR and SSIM than the state-of-the-art method DANet, with an improvement of 1.07 dB and 0.0098, respectively. The code is available at https://github.com/fashyon/MWN-CTHA .},
  archive      = {J_NCA},
  author       = {Liu, Bin and Fang, Siyan},
  doi          = {10.1007/s00521-023-08899-x},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22387-22404},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-level wavelet network based on CNN-transformer hybrid attention for single image deraining},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel consensus PSO-assisted trajectory unified and
trust-tech methodology for DNN training and its applications.
<em>NCA</em>, <em>35</em>(30), 22375–22385. (<a
href="https://doi.org/10.1007/s00521-023-08893-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep neural network (DNN) relies heavily on local solvers like stochastic gradient descent (SGD). However, these methods are sensitive to initial points and hyperparameters for their local property, which affects the stability of the optimization of DNN. This paper presents a novel three-stage methodology, termed consensus particle swarm optimization-based trajectory unified optimization-assisted Trust-Tech (CPTT), for DNN training with high accuracy and robustness. The CPTT is composed of Stage I: exploration and consensus, Stage II: robustly convergence, and Stage III: search optima. We explore the effect of each stage of the CPTT methodology proposed in this paper to accomplish the following advantages: (1) high-quality local optimal solutions (LOSs) and (2) stable convergence in random initialization. The performance of CPTT has been evaluated in stages on popular classification model structures and benchmark datasets, and the performance improvement of CPTT has been evaluated in object detection models. Its optimization performance is also illustrated in a real-world application for drone-based visual inspection of electric power transmission line corridors.},
  archive      = {J_NCA},
  author       = {Lv, Xian-Long and Chiang, Hsiao-Dong and Zhang, Yong-Feng},
  doi          = {10.1007/s00521-023-08893-3},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22375-22385},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel consensus PSO-assisted trajectory unified and trust-tech methodology for DNN training and its applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online cross-layer knowledge distillation on graph neural
networks with deep supervision. <em>NCA</em>, <em>35</em>(30),
22359–22374. (<a
href="https://doi.org/10.1007/s00521-023-08900-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have become one of the most popular research topics in both academia and industry communities for their strong ability in handling irregular graph data. However, large-scale datasets are posing great challenges for deploying GNNs in edge devices with limited resources and model compression techniques have drawn considerable research attention. Existing model compression techniques such as knowledge distillation mainly focus on convolutional neural networks. Only limited attempts have been made recently for distilling knowledge from GNNs in an offline manner. As the performance of the teacher model does not necessarily improve as the number of layers increases in GNNs, selecting an appropriate teacher model will require substantial efforts. To address these challenges, we propose a novel online knowledge distillation framework called Alignahead++ in this paper. Alignahead++ transfers structure and feature information in a student layer to the previous layer of another simultaneously trained student model in an alternating training procedure. Meanwhile, to avoid over-smoothing problem in GNNs, deep supervision is employed in Alignahead++ by adding an auxiliary classifier in each intermediate layer to prevent the collapse of the node feature embeddings. Experimental results on four datasets including PPI, Cora, PubMed and CiteSeer demonstrate that the student performance is consistently boosted in our collaborative training framework without the supervision of a pre-trained teacher model and its effectiveness can generally be improved by increasing the number of students.},
  archive      = {J_NCA},
  author       = {Guo, Jiongyu and Chen, Defang and Wang, Can},
  doi          = {10.1007/s00521-023-08900-7},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22359-22374},
  shortjournal = {Neural Comput. Appl.},
  title        = {Online cross-layer knowledge distillation on graph neural networks with deep supervision},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CNN autoencoders and LSTM-based reduced order model for
student dropout prediction. <em>NCA</em>, <em>35</em>(30), 22341–22357.
(<a href="https://doi.org/10.1007/s00521-023-08894-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Massive Open Online Courses (MOOCs) have become the main online learning method for students all over the world, but their development has been affected by the high dropout rate for a long time. Therefore, dropout prediction is a vital task for early teaching intervention and user retention. The students’ learning records are stored in MOOCs, which contain high-dimensional time series features. However, these features are hard to process, and the nonlinear relationship between the features is difficult to learn. These limitations have become obstacles to improve the performance in dropout prediction. In this paper, we propose a new neural dimension-reduced dropout prediction model based on neural network model to address the limitations. The proposed model, called CNNAE-LSTM, is constructed by convolutional neural network autoencoder (CNNAE) and long short-term memory neural network (LSTM). Specifically, CNNAE-LSTM compresses the students’ learning features into a low-dimensional latent space for reconstruction through CNNAE, then projects the latent space, retains the representative features in the learning records, and finally minimizes the reconstruction error to obtain the nonlinear relationship between features and dropout. The introduced LSTM neural network can obtain the time evolution of its latent vector. Our experiments on the KDD CUP 2015 dataset and the real-world dataset XuetangX demonstrate that the proposed model exhibits better predictive performance compared to the state-of-the-art baseline methods.},
  archive      = {J_NCA},
  author       = {Niu, Ke and Lu, Guoqiang and Peng, Xueping and Zhou, Yuhang and Zeng, Jingni and Zhang, Ke},
  doi          = {10.1007/s00521-023-08894-2},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22341-22357},
  shortjournal = {Neural Comput. Appl.},
  title        = {CNN autoencoders and LSTM-based reduced order model for student dropout prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel group decision-making method based on interval-valued
m-polar fuzzy soft expert information. <em>NCA</em>, <em>35</em>(30),
22313–22340. (<a
href="https://doi.org/10.1007/s00521-023-08869-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mathematical modeling and decision analysis, the multipolar uncertainty is prevalent and requires specialized approaches. The theory of m-polar fuzzy (mF, in short) set is a strong extension of the fuzzy set because of its feature for dealing with multi-polar information, and robust hybrid models such as mF soft sets and interval-valued mF soft sets have emerged for significant real-life multi-criteria decision-making applications. However, these models are limited when it comes to accommodating multiple decision-makers individually in some real situations that emphasize making the use of multi-polar, multi-agent, and multi-object approaches of uncertainty. For example, in the selection of a professor, different evaluation reports are considered from more than one expert. In contrast, the soft expert set model can deal with the opinions of multiple experts about available alternatives regarding multiple attributes but fails to accommodate interval-valued mF knowledge. Motivated by these facts, in this research study, we introduce the notion of an interval-valued mF soft expert set (IV $$_m$$ FSE set) model, a multiple criteria group decision-making (MCGDM) approach, by integrating interval-valued m-polar fuzziness with soft expert sets. The initiated hybrid model is an expert extension of the IV $$_m$$ F soft sets or an interval-valued extension of the mF soft expert sets. Moreover, we discuss properties of certain unary and binary operations and relations on IV $$_m$$ FSE sets (the ‘AND’ operation, the ‘OR’ operation, subset-relation, equality, complement, agree- and disagree-IV $$_m$$ FSE sets, union, and intersection) and illustrate these operations with numerical examples. Further, we implement the proposed theory in a group decision-making problem for the fabrication of upper limb prosthesis samples to visualize its importance and significance. We also design an algorithm to illustrate the procedure of the proposed method. Finally, to validate the aptitude and novelty of the proposed theory, we give its comparative analysis with some preexisting fuzzy theories, including mF soft expert sets and fuzzy soft expert sets, by applying them to a real-world problem in which nine upper limb prosthesis samples are considered, and the computed results depict that the optimal decision alternative is $$x_2$$ .},
  archive      = {J_NCA},
  author       = {Ali, Ghous and Sarwar, Musavarah and Nabeel, Muhammad},
  doi          = {10.1007/s00521-023-08869-3},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22313-22340},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel group decision-making method based on interval-valued m-polar fuzzy soft expert information},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal neighborhood kernel clustering with adaptive local
kernels and block diagonal property. <em>NCA</em>, <em>35</em>(30),
22297–22312. (<a
href="https://doi.org/10.1007/s00521-023-08885-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of multiple kernel clustering (MKC) is usually to generate an optimal kernel by fusing the information of multiple base kernels. Among the methods of generating the optimal kernel, a neighborhood kernel is usually used to enlarge the search range of the optimal kernel, or local base kernels are selected to avoid the redundancy of base kernels. However, few studies combine both methods simultaneously; then, the quality of the optimal kernel cannot be improved very well. Furthermore, most MKC methods require two-step strategy to cluster, that is, first generate clustering indicator matrix, and then execute clustering. This does not guarantee that the final clustering results are optimal. In order to overcome the above drawbacks, an optimal neighborhood kernel clustering with adaptive local kernel and block diagonal property (ONKC-ALK-BD) is proposed in this paper. In our proposed method, a simple weight strategy of selecting local base kernels is used to produce a consensus kernel, a neighborhood kernel of which is chosen as the optimal kernel. And a block diagonal (BD) regularizer imposed on the clustering indicator matrix encourages the matrix to be BD. On one hand, our proposed method avoids the redundancy of base kernels and ensures the diversity of selected base kernels. On the other hand, it expands the search range of the optimal kernel and improves its representation ability. Thus, the quality of the optimal kernel is enhanced. In addition, the BD property of the indicator matrix is helpful to obtain explicit clustering indicators and achieve one-step clustering, which ensures that the final results of our method are optimal for the original problem. Finally, extensive experiments on twelve data sets and comparisons with seven clustering methods show that ONKC-ALK-BD is effective.},
  archive      = {J_NCA},
  author       = {Chen, Cuiling and Wei, Jian and Li, Zhi},
  doi          = {10.1007/s00521-023-08885-3},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22297-22312},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal neighborhood kernel clustering with adaptive local kernels and block diagonal property},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Double deep q-network-based self-adaptive scheduling
approach for smart shop floor. <em>NCA</em>, <em>35</em>(30),
22281–22296. (<a
href="https://doi.org/10.1007/s00521-023-08877-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of smart manufacturing, the data-driven scheduling approach has become an effective way to solve the smart shop floor scheduling problem with high complexity and dynamics. However, most existing approaches rely too heavily on manual supervision in implementation, resulting in poor adaptability and effectiveness in dynamic production environments. Therefore, this paper proposes a self-adaptive scheduling approach based on double deep Q-network (DDQN), which can reduce manual supervision and realize the autonomy of the whole scheduling process. In the presented approach, first, a self-adaptive scheduling framework, which forms a closed-loop optimization structure for scheduling model evaluation, generation/updating, and application, is designed. Second, the interactive learning mechanism of reinforcement learning is introduced, and the scheduling model is generated through the DDQN algorithm without manual supervision. In addition, dynamic reward function based on simulation is proposed to promote the rationality and accuracy of the reward in reinforcement learning. The effectiveness of the proposed approach is validated on a semiconductor production shop floor, and the experimental results illustrate that the proposed approach can improve the effectiveness of self-adaptive scheduling and significantly reduce the time and labour costs in the dynamic production environments.},
  archive      = {J_NCA},
  author       = {Ma, Yumin and Cai, Jingwen and Li, Shengyi and Liu, Juan and Xing, Jianmin and Qiao, Fei},
  doi          = {10.1007/s00521-023-08877-3},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22281-22296},
  shortjournal = {Neural Comput. Appl.},
  title        = {Double deep Q-network-based self-adaptive scheduling approach for smart shop floor},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). TIM-SLR: A lightweight network for video isolated sign
language recognition. <em>NCA</em>, <em>35</em>(30), 22265–22280. (<a
href="https://doi.org/10.1007/s00521-023-08873-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on video isolated sign language recognition (SLR) algorithms has made leaping progress, but there are problems that need to be solved urgently in the field of SLR. On the one hand, traditional sign language acquisition equipment has the disadvantages of being expensive and not easy to carry. Sign language collected based on Kinect contains rich information, but it is complicated to use. The data acquired by RGB cameras are beneficial to practical applications, but the existing sign language datasets collected by RGB cameras have disadvantages such as few demonstrators and small vocabulary. On the other hand, most of the existing SLR methods use complex network structures to achieve high accuracy, but complex networks mean longer inference time, which cannot meet practical application scenarios at all. In this paper, we propose a Chinese large-scale isolated sign language dataset named CSLD, which is collected using RGB camera, and each vocabulary is illustrated 10 times by 30 demonstrators, including 400 words. In addition, we proposed a lightweight TIM-SLR network. In order to verify lightweight and validity of the network, we not only conducted experiments on sign language datasets CSLD and LSA64, and obtained 91.6\% and 99.8\% accuracy, respectively, but also performed experiments on action recognition datasets Sth-Sth (V1 and V2) and both achieve state-of-the-art performance. Not only can it obtain higher accuracy, but also inference speed and parameter of the network can meet practical application scenarios, because TIM-SLR network is only composed of 2D convolution and temporal interaction module (TIM).},
  archive      = {J_NCA},
  author       = {Wang, Fei and Zhang, Libo and Yan, Hao and Han, Shuai},
  doi          = {10.1007/s00521-023-08873-7},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22265-22280},
  shortjournal = {Neural Comput. Appl.},
  title        = {TIM-SLR: A lightweight network for video isolated sign language recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NFSDense201: Microstructure image classification based on
non-fixed size patch division with pre-trained DenseNet201 layers.
<em>NCA</em>, <em>35</em>(30), 22253–22263. (<a
href="https://doi.org/10.1007/s00521-023-08825-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of nanoscience, the scanning electron microscope (SEM) is widely employed to visualize the surface topography and composition of materials. In this study, we present a novel SEM image classification model called NFSDense201, which incorporates several key components. Firstly, we propose a unique nested patch division approach that divides each input image into four patches of varying dimensions. Secondly, we utilize DenseNet201, a deep neural network pretrained on ImageNet1k, to extract 2920 deep features from the last fully connected and global average pooling layers. Thirdly, we introduce an iterative neighborhood component analysis function to select the most discriminative features from the merged feature vector, which is formed by concatenating the four feature vectors extracted per input image. This process results in a final feature vector of optimal length 698. Lastly, we employ a standard shallow support vector machine classifier to perform the actual classification. To evaluate the performance of NFSDense201, we conducted experiments using a large public SEM image dataset. The dataset consists of 972, 162, 326, 4590, 3820, 3925, 4755, 181, 917, and 1624.jpeg images belonging to the following microstructural categories: “biological,” “fibers,” “film-coated surfaces,” “MEMS devices and electrodes,” “nanowires,” “particles,” “pattern surfaces,” “porous sponge,” “powder,” and “tips,” respectively. For both four-class and ten-class classification tasks, we evaluated NFSDense201 using subsets of the dataset containing 5080 and 21,272 images, respectively. The results demonstrate the superior performance of NFSDense201, achieving a four-class classification accuracy rate of 99.53\% and a ten-class classification accuracy rate of 97.09\%. These accuracy rates compare favorably against previously published SEM image classification models. Additionally, we report the performance of NFSDense201 for each class in the dataset.},
  archive      = {J_NCA},
  author       = {Barua, Prabal Datta and Dogan, Sengul and Kavuran, Gurkan and Tuncer, Turker and Tan, Ru-San and Rajendra Acharya, U.},
  doi          = {10.1007/s00521-023-08825-1},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22253-22263},
  shortjournal = {Neural Comput. Appl.},
  title        = {NFSDense201: Microstructure image classification based on non-fixed size patch division with pre-trained DenseNet201 layers},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stable emotional adaptive neuro-control of uncertain affine
nonlinear systems with input saturation. <em>NCA</em>, <em>35</em>(30),
22235–22252. (<a
href="https://doi.org/10.1007/s00521-023-08725-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotional controllers have been successfully pursued toward various control objectives in the past two decades, but there remain considerable challenges in exploiting their theoretical and cognitive aspects. This paper addresses these two challenges by proposing a modified thalamic connection based on an averaging operator using a radial basis emotional network (RBEN-ATC). From a theoretical perspective, we prove that the resulting RBEN-ATC mapping has the universal function approximation property. It also becomes continuous and differentiable with respect to the network weights. We then incorporate this structure to approximate the unknown dynamics of a nonlinear affine system with nonsymmetric input saturation and develop a stable adaptive radial basis emotional controller (ARBEC). From a cognitive perspective, we stay committed to the fundamental laws of the emotional brain. While this standpoint considerably complicates the design process, the resulting control system becomes interpretable from a biological perspective. For these purposes, a two-prong approach is employed here. Firstly, we incorporate a first-order compensator that handles the errors due to the nonsymmetric actuator saturation with unknown bounds. Secondly, we use a robust adaptive compensator that lessens the effect of uncertainties. Lyapunov stability analysis shows the overall ARBEC closed-loop stability of the nonlinear system. Furthermore, comparisons with other competing neuro- and fuzzy approaches show that ARBEC has better noise rejection and steady-state tracking while having comparable control energy consumption.},
  archive      = {J_NCA},
  author       = {Baghbani, Fahimeh and Akbarzadeh Totonchi, Mohammad Reza},
  doi          = {10.1007/s00521-023-08725-4},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22235-22252},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stable emotional adaptive neuro-control of uncertain affine nonlinear systems with input saturation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving unified named entity recognition by incorporating
mention relevance. <em>NCA</em>, <em>35</em>(30), 22223–22234. (<a
href="https://doi.org/10.1007/s00521-023-08820-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is a fundamental task for natural language processing, which aims to detect mentions of real-world entities from text and classifying them into predefined types. Recently, research on overlapped and discontinuous named entity recognition has received increasing attention. However, we note that few studies have considered both overlapped and discontinuous entities. In this paper, we proposed a novel sequence-to-sequence model that is capable of recognizing both overlapped and discontinuous entities based on machine reading comprehension. The model utilizes machine reading comprehension formulation to encode significant inferior information about the entity category. Then input sequence passes through a question-answering model to predict the mention relevance of the given source sentences to the query. Finally, we incorporate the mention relevance into the BART-based generation model. We conducted experiments on three type of NER datasets to show the generality of our model. The experimental results demonstrate that our model beats almost all the current top-performing baselines achieves a vast amount of performance boost over current SOTA models on overlapped and discontinuous NER datasets.},
  archive      = {J_NCA},
  author       = {Ji, Lijun and Yan, Danfeng and Cheng, Zhuoran and Song, Yan},
  doi          = {10.1007/s00521-023-08820-6},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22223-22234},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving unified named entity recognition by incorporating mention relevance},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end speaker identification research based on
multi-scale SincNet and CGAN. <em>NCA</em>, <em>35</em>(30),
22209–22222. (<a
href="https://doi.org/10.1007/s00521-023-08906-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has improved the performance of speaker identification systems in recent years, but it has also presented significant challenges. Typically, data-driven modeling approaches based on DNNs rely on large-scale training data, but due to environmental constraints, large amounts of user speech data are not obtainable. As a result, this work proposes a new SincGAN speaker identification (SI) model that directly recognizes the input’s raw waveform, allowing speaker identification with only a small number of training utterances. Unlike methods that use standard hand-crafted feature recognition, this method is real end-to-end recognition. In this case, a generator is utilized to reconstruct the input samples to enhance the amount of training data, and a discriminator is employed to finish the SI classification task. A multi-scale SincNet layer based on three bespoke filter banks is also added to capture the low-level speech representation of the three channels in the waveform, allowing the model to better catch critical narrowband speaker properties (e.g., pitch and resonance peaks). Experiments reveal that the method achieves better recognition results on the TIMIT and LIBRISPEECH datasets under the constraints of limited training data. Furthermore, the proposed model has a competitive advantage over existing models.},
  archive      = {J_NCA},
  author       = {Wei, Guangcun and Zhang, Yanna and Min, Hang and Xu, Yunfei},
  doi          = {10.1007/s00521-023-08906-1},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22209-22222},
  shortjournal = {Neural Comput. Appl.},
  title        = {End-to-end speaker identification research based on multi-scale SincNet and CGAN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023e). TSP-UDANet: Two-stage progressive unsupervised domain
adaptation network for automated cross-modality cardiac segmentation.
<em>NCA</em>, <em>35</em>(30), 22189–22207. (<a
href="https://doi.org/10.1007/s00521-023-08939-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of cardiac anatomy is a prerequisite for the diagnosis of cardiovascular disease. However, due to differences in imaging modalities and imaging devices, known as domain shift, the segmentation performance of deep learning models lacks reliability. In this paper, we propose a two-stage progressive unsupervised domain adaptation network (TSP-UDANet) to reduce domain shift when segmenting cardiac images from various sources. We alleviate the domain shift between the feature distribution of the source and target domains by introducing an intermediate domain as a bridge. The TSP-UDANet consists of three sub-networks: a style transfer sub-network, a segmentation sub-network, and a self-training sub-network. We conduct cooperative alignment of different domains at image level, feature level, and output level. Specifically, we transform the appearance of images across domains and enhance domain invariance by adversarial learning in multiple aspects to achieve unsupervised segmentation of the target modality. We validate the TSP-UDANet on the MMWHS (unpaired MRI and CT images), MS-CMRSeg (cross-modality MRI images), and M&amp;Ms (cross-vendor MRI images) datasets. The experimental results demonstrate excellent segmentation performance and generalizability for unlabeled target modality images.},
  archive      = {J_NCA},
  author       = {Wang, Yonghui and Zhang, Yifan and Xu, Lisheng and Qi, Shouliang and Yao, Yudong and Qian, Wei and Greenwald, Stephen E. and Qi, Lin},
  doi          = {10.1007/s00521-023-08939-6},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22189-22207},
  shortjournal = {Neural Comput. Appl.},
  title        = {TSP-UDANet: Two-stage progressive unsupervised domain adaptation network for automated cross-modality cardiac segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel uncertainty-aware deep learning technique with an
application on skin cancer diagnosis. <em>NCA</em>, <em>35</em>(30),
22179–22188. (<a
href="https://doi.org/10.1007/s00521-023-08930-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, primarily resulting from the abnormal growth of skin cells, is among the most common cancer types. In recent decades, the incidence of skin cancer cases worldwide has risen significantly (one in every three newly diagnosed cancer cases is a skin cancer). Such an increase can be attributed to changes in our social and lifestyle habits coupled with devastating man-made alterations to the global ecosystem. Despite such a notable increase, diagnosis of skin cancer is still challenging, which becomes critical as its early detection is crucial for increasing the overall survival rate. This calls for advancements of innovative computer-aided systems to assist medical experts with their decision making. In this context, there has been a recent surge of interest in machine learning (ML), in particular, deep neural networks (DNNs), to provide complementary assistance to expert physicians. While DNNs have a high processing capacity far beyond that of human experts, their outputs are deterministic, i.e., providing estimates without prediction confidence. Therefore, it is of paramount importance to develop DNNs with uncertainty-awareness to provide confidence in their predictions. Monte Carlo dropout (MCD) is vastly used for uncertainty quantification; however, MCD suffers from overconfidence and being miss calibrated. In this paper, we use MCD algorithm to develop an uncertainty-aware DNN that assigns high predictive entropy to erroneous predictions and enable the model to optimize the hyper-parameters during training, which leads to more accurate uncertainty quantification. We use two synthetic (two moons and blobs) and a real dataset (skin cancer) to validate our algorithm. Our experiments on these datasets prove effectiveness of our approach in quantifying reliable uncertainty. Our method achieved 85.65 ± 0.18 prediction accuracy, 83.03 ± 0.25 uncertainty accuracy, and 1.93 ± 0.3 expected calibration error outperforming vanilla MCD and MCD with loss enhanced based on predicted entropy.},
  archive      = {J_NCA},
  author       = {Shamsi, Afshar and Asgharnezhad, Hamzeh and Bouchani, Ziba and Jahanian, Khadijeh and Saberi, Morteza and Wang, Xianzhi and Razzak, Imran and Alizadehsani, Roohallah and Mohammadi, Arash and Alinejad-Rokny, Hamid},
  doi          = {10.1007/s00521-023-08930-1},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22179-22188},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel uncertainty-aware deep learning technique with an application on skin cancer diagnosis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning-based quantized deep learning models for
nail melanoma classification. <em>NCA</em>, <em>35</em>(30),
22163–22178. (<a
href="https://doi.org/10.1007/s00521-023-08925-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, has remained a severe issue for many years due to its increasing incidences. The rising mortality rate associated with melanoma demands immediate attention at early stages to facilitate timely diagnosis and effective treatment. Due to the similar visual appearance of malignant tumors and normal cells, the detection and classification of melanoma are considered to be one of the most challenging tasks. Detecting melanoma accurately and promptly is essential to diagnosis and treatment, which can contribute significantly to patient survival. A new dataset, Nailmelonma, is presented in this study in order to train and evaluate various deep learning models applying transfer learning for an indigenous nail melanoma localization dataset. Using the dermoscopic image datasets, seven CNN-based DL architectures (viz., VGG19, ResNet101, ResNet152V2, Xception, InceptionV3, MobileNet, and MobileNetv2) have been trained and tested for the classification of skin lesions for melanoma detection. The trained models have been validated, and key performance parameters (i.e., accuracy, recall, specificity, precision, and F1-score) are systematically evaluated to test the performance of each transfer learning model. The results indicated that the proposed workflow could realize and achieve more than 95\% accuracy. In addition, we show how the quantization of such models can enable them for memory-constrained mobile/edge devices. To facilitate an accurate, timely, and faster diagnosis of nail melanoma and to evaluate the early detection of other types of skin cancer, the proposed workflow can be readily applied and robust to the early detection of nail melanoma.},
  archive      = {J_NCA},
  author       = {Hussain, Mujahid and Fiza, Makhmoor and Khalil, Aiman and Siyal, Asad Ali and Dharejo, Fayaz Ali and Hyder, Waheeduddin and Guzzo, Antonella and Krichen, Moez and Fortino, Giancarlo},
  doi          = {10.1007/s00521-023-08925-y},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22163-22178},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transfer learning-based quantized deep learning models for nail melanoma classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An uncertainty estimator method based on the application of
feature density to classify mammograms for breast cancer detection.
<em>NCA</em>, <em>35</em>(30), 22151–22161. (<a
href="https://doi.org/10.1007/s00521-023-08904-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the area of medical imaging, one of the factors that can negatively influence the performance of prediction algorithms is the limited number of observations for each class within a labeled dataset. Usually, in order to increase the samples, a second set of unlabeled images is used. However, this set adds two new problems (i) finding patient observations with different pathologies than those observed in the labeled data set and (ii) finding images belonging to a different distribution from the dataset used in the model training process. This way, merging datasets from different sources can have an adverse effect on the distribution of features. Encountering this type of data (better known as out-of-distribution data) within the deployment environments may also lead to varying degrees of performance degradation as can be seen in the different experimental results obtained. In this research, a study of the behavior of Feature Density is made, as a mathematical model for the estimation of predictive uncertainty in supervised classification algorithms, in order to improve the behavior when out-of-distribution data are presented in the dataset. The Feature Density method is based on the estimation of feature density by means of histogram calculation (or Probability Density Function). The advantage of this method over the baseline approach (Mahalanobis distance) is that it does not assume a Gaussian-type distribution of sample characteristics and serves to estimate the uncertainty. This work focuses on the binary classification of mammography X-ray images from three different datasets simulating the condition of a different degree of contamination with out-of-distribution sample. According to the obtained results, the performance of the proposed method depends directly on the architecture of the implemented neural network.},
  archive      = {J_NCA},
  author       = {Fuentes-Fino, Ricardo and Calderón-Ramírez, Saúl and Domínguez, Enrique and López-Rubio, Ezequiel and Elizondo, David and Molina-Cabello, Miguel A.},
  doi          = {10.1007/s00521-023-08904-3},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22151-22161},
  shortjournal = {Neural Comput. Appl.},
  title        = {An uncertainty estimator method based on the application of feature density to classify mammograms for breast cancer detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel framework of adaptive fuzzy-GLCM segmentation and
fuzzy with capsules network (f-CapsNet) classification. <em>NCA</em>,
<em>35</em>(30), 22133–22149. (<a
href="https://doi.org/10.1007/s00521-023-08666-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, offer a new framework for skin disease image recognition using deep learning techniques and local descriptor encoding approaches. For the purpose of detecting melanoma early, skin lesions must be accurately classified. In this research, an automatic image preprocessing approach is proposed for the removal of noise artefacts in photographs, including thin and thick hair objects, surgical ink markings, dark halo effects, and ebony frames. Due to hazy contrasts and distortions at the border margins, segmenting images are quite challenging. So, this research suggests a partitioning technique based on a fuzzy gray-level co-occurrence matrix (GLCM) that is both effective and adaptive. An alternative to convolutional neural networks (CNN) is proposed: the capsule-based network. An object&#39;s existence and the relationship between its functions are represented by a group of neurons (in logical units) that make up a vector called a capsule. While synthetic product neural networks use max-pooling layers to define capsule coupling between subsequent layers, capsule networks repeatedly utilise a dynamic routing technique to do so. Alternatively said, the routing-by-agreement approach offers learning between capsule layers. To assess the efficacy of the F-CapsNet technique, three widely used datasets—the ISIC 2017 Challenge, the 2019 Challenge, and the PH2 datasets—are employed. The suggested technique has an average accuracy of 99.16\% for the ISBI 2017 test dataset and 99.45\% accuracy for the ISBI 2019 test dataset. Additionally, the PH2 test dataset shows that the suggested approach has an average accuracy of 98.42\%.},
  archive      = {J_NCA},
  author       = {Ali, Rizwan and Manikandan, A. and Xu, Jinghong},
  doi          = {10.1007/s00521-023-08666-y},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22133-22149},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel framework of adaptive fuzzy-GLCM segmentation and fuzzy with capsules network (F-CapsNet) classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BF2SkNet: Best deep learning features fusion-assisted
framework for multiclass skin lesion classification. <em>NCA</em>,
<em>35</em>(30), 22115–22131. (<a
href="https://doi.org/10.1007/s00521-022-08084-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convolutional neural network showed considerable success in medical imaging with explainable AI for cancer detection and recognition. However, the irrelevant and large number of features increases the computational time and decreases the accuracy. This work proposes a deep learning and fuzzy entropy slime mould algorithm-based architecture for multiclass skin lesion classification. In the first step, we employed the data augmentation technique to increase the training data and further utilized it for training two fine-tuned deep learning models such as Inception-ResNetV2 and NasNet Mobile. Then, we used transfer learning on augmented datasets to train both models and obtained two feature vectors from newly fine-tuned models. Later, we applied a fuzzy entropy slime mould algorithm on both vectors to get optimal features that are finally fused using the Serial-Threshold fusion technique and classified using several machine learning classifiers. Eventually, the explainable AI technique named Gradcam opted for the visualization of the lesion region. The experimental process was conducted on two datasets, such as HAM10000 and ISIC 2018, and achieved 97.1 and 90.2\% accuracy, better than the other techniques.},
  archive      = {J_NCA},
  author       = {Ajmal, Muhammad and Khan, Muhammad Attique and Akram, Tallha and Alqahtani, Abdullah and Alhaisoni, Majed and Armghan, Ammar and Althubiti, Sara A. and Alenezi, Fayadh},
  doi          = {10.1007/s00521-022-08084-6},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22115-22131},
  shortjournal = {Neural Comput. Appl.},
  title        = {BF2SkNet: Best deep learning features fusion-assisted framework for multiclass skin lesion classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully automatic identification of post-treatment infarct
lesions after endovascular therapy based on non-contrast computed
tomography. <em>NCA</em>, <em>35</em>(30), 22101–22114. (<a
href="https://doi.org/10.1007/s00521-022-08094-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-contrast computed tomography (NCCT) of the brain is critical to patients with acute ischemic stroke who receive thrombolysis and thrombectomy. It can help identify reperfusion-related hemorrhage, edema which need intervention. It also can guide the timing and intensity of antithrombotic therapy. Rapid, accurate, and automated detection and segmentation of acute ischemic lesions after endovascular therapy (EVT) are highly needed. In this work, we propose a novel encoder-decoder network for fully automatic segmentation of acute ischemic lesions after EVT on NCCT, which is named ISCT-EDN. NCCT images of AIS (acute ischemic stroke) patients who underwent EVT in a multicenter cohort study were collected in this study. ISCT-EDN takes hierarchical network as backbone. Feature pyramid network (FPN) is designed to aggregate features from multi stages of backbone. Reasonable feature fusion strategy is considered in FPN to enhance multi-level propagation. In addition, to overcome the limitation of fixed geometric structure of convolution for multi-range dependency exploitation, non-local parallel decoder is introduced with deformable convolution and self-attention. The proposed model was compared with 7 segmentation models which are commonly used in the medical domain and the performance was superior to other models in in the segmentation of post-treatment infarct lesions on NCCT images of AIS patients after EVT.},
  archive      = {J_NCA},
  author       = {Nie, Ximing and Liu, Xiran and Yang, Hao and Shi, Feng and Gu, Weibin and Hou, Xinyi and Wei, Yufei and Lu, Qixuan and Bai, Haiwei and Chen, Jiaping and Liu, Tianhang and Yan, Hongyi and Yang, Zhonghua and Wen, Miao and Pan, Yuesong and Huang, Chao and Wang, Long and Liu, Liping},
  doi          = {10.1007/s00521-022-08094-4},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22101-22114},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fully automatic identification of post-treatment infarct lesions after endovascular therapy based on non-contrast computed tomography},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explaining COVID-19 diagnosis with taylor decompositions.
<em>NCA</em>, <em>35</em>(30), 22087–22100. (<a
href="https://doi.org/10.1007/s00521-022-08021-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has devastated the entire globe since its first appearance at the end of 2019. Although vaccines are now in production, the number of contaminations remains high, thus increasing the number of specialized personnel that can analyze clinical exams and points out the final diagnosis. Computed tomography and X-ray images are the primary sources for computer-aided COVID-19 diagnosis, but we still lack better interpretability of such automated decision-making mechanisms. This manuscript presents an insightful comparison of three approaches based on explainable artificial intelligence (XAI) to light up interpretability in the context of COVID-19 diagnosis using deep networks: Composite Layer-wise Propagation, Single Taylor Decomposition, and Deep Taylor Decomposition. Two deep networks have been used as the backbones to assess the explanation skills of the XAI approaches mentioned above: VGG11 and VGG16. We hope that such work can be used as a basis for further research on XAI and COVID-19 diagnosis for each approach figures its own positive and negative points.},
  archive      = {J_NCA},
  author       = {Hassan, Mohammad Mehedi and AlQahtani, Salman A. and Alelaiwi, Abdulhameed and Papa, João P.},
  doi          = {10.1007/s00521-022-08021-7},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22087-22100},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explaining COVID-19 diagnosis with taylor decompositions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Region-based evidential deep learning to quantify
uncertainty and improve robustness of brain tumor segmentation.
<em>NCA</em>, <em>35</em>(30), 22071–22085. (<a
href="https://doi.org/10.1007/s00521-022-08016-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite recent advances in the accuracy of brain tumor segmentation, the results still suffer from low reliability and robustness. Uncertainty estimation is an efficient solution to this problem, as it provides a measure of confidence in the segmentation results. The current uncertainty estimation methods based on quantile regression, Bayesian neural network, ensemble, and Monte Carlo dropout are limited by their high computational cost and inconsistency. In order to overcome these challenges, Evidential Deep Learning (EDL) was developed in recent work but primarily for natural image classification and showed inferior segmentation results. In this paper, we proposed a region-based EDL segmentation framework that can generate reliable uncertainty maps and accurate segmentation results, which is robust to noise and image corruption. We used the Theory of Evidence to interpret the output of a neural network as evidence values gathered from input features. Following Subjective Logic, evidence was parameterized as a Dirichlet distribution, and predicted probabilities were treated as subjective opinions. To evaluate the performance of our model on segmentation and uncertainty estimation, we conducted quantitative and qualitative experiments on the BraTS 2020 dataset. The results demonstrated the top performance of the proposed method in quantifying segmentation uncertainty and robustly segmenting tumors. Furthermore, our proposed new framework maintained the advantages of low computational cost and easy implementation and showed the potential for clinical application.},
  archive      = {J_NCA},
  author       = {Li, Hao and Nan, Yang and Del Ser, Javier and Yang, Guang},
  doi          = {10.1007/s00521-022-08016-4},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22071-22085},
  shortjournal = {Neural Comput. Appl.},
  title        = {Region-based evidential deep learning to quantify uncertainty and improve robustness of brain tumor segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning in multimodal medical imaging for cancer
detection. <em>NCA</em>, <em>35</em>(30), 22069–22070. (<a
href="https://doi.org/10.1007/s00521-023-08955-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Bansal, Priti and Piuri, Vincenzo and Palade, Vasile and Ding, Weiping},
  doi          = {10.1007/s00521-023-08955-6},
  journal      = {Neural Computing and Applications},
  number       = {30},
  pages        = {22069-22070},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning in multimodal medical imaging for cancer detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature extraction from unstructured texts as a combination
of the morphological and the syntactic analysis and its usage in fake
news classification tasks. <em>NCA</em>, <em>35</em>(29), 22055–22067.
(<a href="https://doi.org/10.1007/s00521-023-08967-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new technique of feature extraction is proposed, which is considered an essential part of natural language processing. Feature extraction is the process of transformation of the unstructured text to a format which is recognizable by computers. This means a transformation to a vector of numbers. The study evaluates and compares the performance of three methods: M1, which is the baseline method TfIdf; M2, which combines TfIdf with POS tags; and M3, a novel technique called MDgwPosF that incorporates weighted TfIdf values based on word depths and the relative frequency of POS tags. The primary focus of the study is to assess and compare the performance of these methods, with particular emphasis on evaluating how M3 performs in comparison with M1 and M2. Two different datasets and feed-forward, LSTM and GRU neural networks were used in this study. The results showed that the feed-forward model with the proposed method MDgwPosF in moderate topology achieved the best performance across various measures. The dataset created automatically performed better than the manual dataset. The differences between methods and topologies were not statistically significant. Statistically significant differences between the classification models were proven. The MDgwPosF method achieved higher accuracy compared to the baseline TfIdf, indicating that incorporating additional information into the vector can enhance the performance of TfIdf.},
  archive      = {J_NCA},
  author       = {Szabó Nagy, Kitti and Kapusta, Jozef and Munk, Michal},
  doi          = {10.1007/s00521-023-08967-2},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {22055-22067},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feature extraction from unstructured texts as a combination of the morphological and the syntactic analysis and its usage in fake news classification tasks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel graph-based multi-view spectral clustering:
Application to x-ray image analysis for COVID-19 recognition.
<em>NCA</em>, <em>35</em>(29), 22043–22053. (<a
href="https://doi.org/10.1007/s00521-023-08975-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, machine learning tools and, in particular, classification methods are often used to diagnose COVID-19 cases. However, these methods use a single view of the dataset and assume that the labels of the datasets are known in advance. Due to the extensive use of COVID-19 and the enormous amount of patient data whose labels are unknown, unsupervised learning may be useful in evaluating these photographs. The contribution of this work is twofold. First, we present an improved and generic method for direct multi-view clustering. Second, we apply this method to unsupervised clustering of chest X-ray images. To our knowledge, this is the first attempt to apply unsupervised multi-view clustering to chest X-ray images. We can use an unsupervised learning paradigm and benefit from the wealth of unlabeled data without relying on human experts to label a large number of images. Here, we present an improved version of a recently developed direct method that estimates both nonnegative cluster indices and spectral embeddings. The proposed model includes two types of constraints in addition to the advantages of this method: (i) consistent smoothing of cluster labels across all views and (ii) an orthogonality constraint on the nonnegative embedding matrix (cluster assignment). The COVIDx dataset with three classes is used to demonstrate the advantages of the proposed method. Chest X-ray images were clustered into different classes with promising results. To demonstrate the efficiency of the proposed strategy, other image datasets are used to evaluate the proposed clustering method.},
  archive      = {J_NCA},
  author       = {Dornaika, F. and Hoang, V. Truong},
  doi          = {10.1007/s00521-023-08975-2},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {22043-22053},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel graph-based multi-view spectral clustering: Application to X-ray image analysis for COVID-19 recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel deep convolutional encoder–decoder network:
Application to moving object detection in videos. <em>NCA</em>,
<em>35</em>(29), 22027–22041. (<a
href="https://doi.org/10.1007/s00521-023-08956-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moving object detection is one of the key applications of video surveillance. Deep convolutional neural networks have gained increasing attention in the field of video surveillance due to their effective feature learning ability. The performance of deep neural networks is often affected by the characteristics of videos like poor illumination and inclement weather conditions. It is important to design an innovative architecture of deep neural networks to deal with the videos effectively. Here, the convolutional layers for the networks require to be in an appropriate number and it’s important to determine the number. In this study, we propose a customized deep convolutional encoder–decoder network, say CEDSegNet, for moving object detection in a video sequence. Here, the CEDSegNet is based on SegNet, and its encoder and decoder parts are chosen to be two. By customizing the SegNet with two encoder and decoder parts, the proposed CEDSegNet improves detection performance, where its parameters are reduced to an extent. The two encoder and decoder parts function towards generating feature maps preserving the fine details of object pixels in videos. The proposed CEDSegNet is tested on multiple video sequences of the CDNet dataset2012. The results obtained using CEDSegNet for moving object detection in the video frames are interpreted qualitatively. Further, the performance of CEDSegNet is evaluated using several quantitative indices. Both the qualitative and quantitative results demonstrate that the performance of CEDSegNet is superior to the state-of-the-network models, VGG16, VGG19, ResNet18 and ResNet50.},
  archive      = {J_NCA},
  author       = {Ganivada, Avatharam and Yara, Srinivas},
  doi          = {10.1007/s00521-023-08956-5},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {22027-22041},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel deep convolutional encoder–decoder network: Application to moving object detection in videos},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-view LSTM variational auto-encoder for fault detection
and diagnosis in multivariable manufacturing processes. <em>NCA</em>,
<em>35</em>(29), 22007–22026. (<a
href="https://doi.org/10.1007/s00521-023-08949-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process monitoring of industrial production has always been one of the main concerns of process industry systems. As artificial intelligence booms, fault detection and diagnosis via deep learning has been widely used in industrial process monitoring, such as chemical process monitoring flow. Whereas, the current deep framework is difficult to simultaneously reconcile the relationship between different variables and time series caused by the increasing complexity of industrial systems, which reduces the accuracy of fault detection and diagnosis. Considering the significant time series processing potential of long short-term memory (LSTM) networks, this paper proposes a novel two-view LSTM variational auto-encoder, aliased as TVAE. First, the running data in period T is obtained through sliding window, then it utilizes two-view embedding to compress time series information and capture the correlation between time variables, after that it is judged whether it is fault data according to the anomaly score of the variational auto-encoder. Finally, since the encoding process makes the time-dependent and variable dependent features more obvious, the fault characteristic of the encoded data can be obtained by neuron grouping convolution, and then classified for diagnosis. Experimental results on Tennessee Eastman process benchmark show that TVAE is superior to the state-of-the-art methods and provides a new paradigm for industrial process fault detection and diagnosis.},
  archive      = {J_NCA},
  author       = {Qi, Li and Ren, Yuwei and Fang, Yixian and Zhou, Jinglin},
  doi          = {10.1007/s00521-023-08949-4},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {22007-22026},
  shortjournal = {Neural Comput. Appl.},
  title        = {Two-view LSTM variational auto-encoder for fault detection and diagnosis in multivariable manufacturing processes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dimensionality reduction approach based on modified hunger
games search: Case study on parkinson’s disease phonation. <em>NCA</em>,
<em>35</em>(29), 21979–22005. (<a
href="https://doi.org/10.1007/s00521-023-08936-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hunger Games Search (HGS) is a newly developed swarm-based algorithm inspired by the cooperative behavior of animals and their hunting strategies to find prey. However, HGS has been observed to exhibit slow convergence and may struggle with unbalanced exploration and exploitation phases. To address these issues, this study proposes a modified version of HGS called mHGS, which incorporates five techniques: (1) modified production operator, (2) modified variation control, (3) modified local escaping operator, (4) modified transition factor, and (5) modified foraging behavior. To validate the effectiveness of the mHGS method, 18 different benchmark datasets for dimensionality reduction are utilized, covering a range of sizes (small, medium, and large). Additionally, two Parkinson’s disease phonation datasets are employed as real-world applications to demonstrate the superior capabilities of the proposed approach. Experimental and statistical results obtained through the mHGS method indicate its significant performance improvements in terms of Recall, selected attribute count, Precision, F-score, and accuracy when compared to the classical HGS and seven other well-established methods: Gradient-based optimizer (GBO), Grasshopper Optimization Algorithm (GOA), Gray Wolf Optimizer (GWO), Salp Swarm Algorithm (SSA), Whale Optimization Algorithm (WOA), Harris Hawks Optimizer (HHO), and Ant Lion Optimizer (ALO).},
  archive      = {J_NCA},
  author       = {Hashim, Fatma A. and Neggaz, Nabil and Mostafa, Reham R. and Abualigah, Laith and Damasevicius, Robertas and Hussien, Abdelazim G.},
  doi          = {10.1007/s00521-023-08936-9},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21979-22005},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dimensionality reduction approach based on modified hunger games search: Case study on parkinson’s disease phonation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic finite-time stabilization for stochastic
multi-links coupled systems with time delays. <em>NCA</em>,
<em>35</em>(29), 21967–21978. (<a
href="https://doi.org/10.1007/s00521-023-08934-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the issues pertaining with the stochastic finite-time stability of stochastic multi-links coupled systems with time delays (SMCSTD) via delayed feedback control are considered. And the model investigated in this paper is constructed on strongly connected digraphs (SCD) and digraphs without strong connectedness, respectively. Besides, stabilization criteria for SMCSTD based on SCD are obtained by the graph theory and the Lyapunov method. In addition, for SMCSTD based on digraphs without strong connectedness, stabilization criteria are proposed by means of the Lyapunov method, the graph theory and the theory of asymptotically autonomous systems. It is worth noting that the theoretical results in this paper relax the constraint of the differential operator $${\mathcal {L}}U$$ , which is meaningful. Finally, two numerical examples are provided to demonstrate the validity of the theoretical theorems proposed in this paper.},
  archive      = {J_NCA},
  author       = {Liu, Yan and Ke, Zundong and Guan, Zhen},
  doi          = {10.1007/s00521-023-08934-x},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21967-21978},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stochastic finite-time stabilization for stochastic multi-links coupled systems with time delays},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the thermal performance during flow dynamics of
viscoelastic fluid in a channel: Jaffrey–hamel extension. <em>NCA</em>,
<em>35</em>(29), 21949–21965. (<a
href="https://doi.org/10.1007/s00521-023-08854-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An extended Jaffrey–Hamel problem with heat and mass transfer attributes of viscoelastic fluid over an isothermal porous conduit, where the flow is produced by injecting the fluid at the inlet of the convergent section, has been described. The homogeneous processes dictated by first-order kinetics take place in the adjacent fluid, whereas the heterogeneous reactions supplied by cubic autocatalytic dynamics are believed to take place on the channel wall. To simulate both inertial drag and bulk permeable drag of the porosity medium, a non-Darcy-drag force concept is used. Slow velocity leads to the disregarding of viscous dissipation. Thermal radiation and a heat source or sink work together to keep the temperature in equilibrium in the flow domain. The simulation-based numerical solutions for dimensionless temperature, velocity, and concentration have been derived by applying appropriate similarity transformations to the highly nonlinear momentum equation, thermal, and species concentration equations. A more secure velocity profile results from a longer strain retardation time and a shorter stress relaxation time, whereas both viscoelastic times have reverse consequences. The thermal distribution is quantitatively improved with an increase in the radiation parameter, suggesting a higher rate of heat transmission. Concentration drops as heterogeneous reaction parameters are amplified . With an increase in the porosity number, surface viscous drag becomes more intense. Divergent cross section shows a greater tendency for heat and mass transfer.},
  archive      = {J_NCA},
  author       = {Rehman, Sohail and Alqahtani, Sultan and Hashim and Alshehery, Sultan},
  doi          = {10.1007/s00521-023-08854-w},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21949-21965},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the thermal performance during flow dynamics of viscoelastic fluid in a channel: Jaffrey–Hamel extension},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural nets for sustainability conversations: Modeling
discussion disciplines and their impacts. <em>NCA</em>, <em>35</em>(29),
21935–21947. (<a
href="https://doi.org/10.1007/s00521-023-08819-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We live in the age polarization, where conversations on matters of sustainability more often produce acrimony or stalemate than productive action. Better understanding conversation features and their impacts may lead to better innovation, solution-design, and ongoing collaboration. We describe a study to test alternate machine learning models for classifying six “discussion disciplines”, which are conversation features associated with rhetorical intent. The model providing the best outcome used the Bi-directional Encoder Representations from Transformers (BERT) layered with a Residual Network (ResNet). The training data were 1135 utterances from Maine aquaculture town hall-like meetings and similar conversations, which had been hand-coded for the discussion disciplines. In addition, we generated 300 phrases corresponding to three conversation outcomes: Intent-to-Act, Options-Generation, and Relationship-Building. We then used the trained model and information retrieval to classify a large corpus of 591 open-source transcripts, containing over 21,000 utterances. A binary logistic regression analysis showed that two discussion disciplines, “Inclusion” and “Courtesy,” had positive, statistically significant, impacts on Intent-to-act: a 10 percentage point increase in the share of the Inclusion or Courtesy yielded a 45\% or 34\% increase, respectively, in the likelihood of Intent-to-Act. This study shows the applicability of neural networks in modeling conversations and identifying the dialog acts that can provide measurable and predictable impact on conversation outcomes. Conversational intelligence can support a variety of human interactions, such as town halls, policy-deliberations, private–public partnerships, and sustainability teamwork.},
  archive      = {J_NCA},
  author       = {Pugh, Katrina and Musavi, Mohamad and Johnson, Teresa and Burke, Christopher and Yoeli, Erez and Currie, Emily and Pugh, Benjamin},
  doi          = {10.1007/s00521-023-08819-z},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21935-21947},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural nets for sustainability conversations: Modeling discussion disciplines and their impacts},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing a constant mean function using functional
regression. <em>NCA</em>, <em>35</em>(29), 21915–21934. (<a
href="https://doi.org/10.1007/s00521-023-08952-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study functional ordinary least squares estimator and its properties in testing the hypothesis of a constant zero mean function or an unknown constant nonzero mean function. We exploit the recent work by Cho, Phillips, and Seo (Int Econ Rev 170:391–456, 2022) and show that the associated Wald test statistics have standard chi-square limiting null distributions, standard noncentral chi-square distributions for local alternatives converging to zero at a $$\sqrt{n}$$ rate, and are consistent against global alternatives. These properties permit computationally convenient tests of hypotheses involving nuisance parameters. In particular, we develop new alternatives to tests for regression misspecification using the neural network model, that involves nuisance parameters identified only under the alternative. Our Monte Carlo simulations affirm the theory of the current study. Finally, we apply our methodology to the probit models for voter turnout that are estimated by Wolfinger and Rosenstone (Who votes? Yale University Press, New Haven, 1980), Nagler (Am Political Sci Rev 85:1393–1405, 1991) and test whether the models are correctly specified or not.},
  archive      = {J_NCA},
  author       = {Cho, Jin Seo and Huang, Meng and White, Halbert},
  doi          = {10.1007/s00521-023-08952-9},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21915-21934},
  shortjournal = {Neural Comput. Appl.},
  title        = {Testing a constant mean function using functional regression},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using particle swarm optimization of fuzzy logic systems as
a hybrid soft computing method to enhance solar energy prediction.
<em>NCA</em>, <em>35</em>(29), 21903–21914. (<a
href="https://doi.org/10.1007/s00521-023-08912-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models of artificial intelligence (AI) and numerical weather prediction (NWP) have been widely used to successfully forecast solar radiation. Nevertheless, hybridized versions of these models can improve prediction accuracy and reliability and lessen the biased outcomes that can arise from one model in order to take advantage of the power elements of each model. In this research, a hybrid soft computing method based on particle swarm optimization (PSO) of fuzzy logic systems (FLSs) is applied to hybridize the outputs of an optimized FLS with an NWP model to forecast daily solar radiation. By building a spatially and temporally independent system in two stages, the applied hybrid technique focuses on the design of a practical and general model. In the first stage, the FLS is optimized using the simulated annealing algorithm (SA). In the second stage, a new FLS is designed using the PSO algorithm to estimate the final prediction. The PSO-FLS utilizes the outputs of both the SA-FLS and the NWP model in a straightforward and practical manner. The NWP model that is utilized is the fifth generation of atmospheric reanalysis of the global climate, or ERA5, developed by the European Centre for Medium-Range Weather Forecasts. The findings regarding the prediction procedures of FLSs, NWP, and the hybrid model are reported and compared using a data set gathered from nine stations in Saudi Arabia. The results demonstrate that the hybridization process can increase the accuracy and reliability of AI-based predictions while reducing their bias.},
  archive      = {J_NCA},
  author       = {Almaraashi, Majid},
  doi          = {10.1007/s00521-023-08912-3},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21903-21914},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using particle swarm optimization of fuzzy logic systems as a hybrid soft computing method to enhance solar energy prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonlinear feature selection using sparsity-promoted
centroid-encoder. <em>NCA</em>, <em>35</em>(29), 21883–21902. (<a
href="https://doi.org/10.1007/s00521-023-08938-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contribution of our work is two-fold. First, we propose a novel feature selection technique, sparsity-promoted centroid-encoder (SCE). The model uses the nonlinear mapping of artificial neural networks to reconstruct a sample as its class centroid and, at the same time, apply a ℓ1-penalty to the weights of a sparsity promoting layer, placed between the input and first hidden layer, to select discriminative features from input data. Using the proposed method, we designed a feature selection framework that first ranks each feature and then, compiles the optimal set using validation samples. The second part of our study investigates the role of stochastic optimization, such as Adam, in minimizing ℓ1-norm. The empirical analysis shows that the hyper-parameters of Adam (mini-batch size, learning rate, etc.) play a crucial role in promoting feature sparsity by SCE. We apply our technique to numerous real-world data sets and find that it significantly outperforms other state-of-the-art methods, including LassoNet, stochastic gates (STG), feature selection networks (FsNet), supervised concrete autoencoder (CAE), deep feature selection (DFS), and random forest (RF).},
  archive      = {J_NCA},
  author       = {Ghosh, Tomojit and Kirby, Michael},
  doi          = {10.1007/s00521-023-08938-7},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21883-21902},
  shortjournal = {Neural Comput. Appl.},
  title        = {Nonlinear feature selection using sparsity-promoted centroid-encoder},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hypergraph convolutional network for hyperspectral image
classification. <em>NCA</em>, <em>35</em>(29), 21863–21882. (<a
href="https://doi.org/10.1007/s00521-023-08935-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph-based neural networks have been investigated in hyperspectral image (HSI) classification to address the limited global feature representation capability issue of HSI classification methods based on convolutional neural networks (CNN). However, most of the existing graph-based neural networks for HSI classification methods either characterize the relation information by the pair-wise modeling or rely on the CNNs to extract the local spectral–spatial features. To solve this problem, in this paper, a concise hypergraph convolutional network (HGCN) is proposed for semi-supervised HSI classification. To effectively and efficiently capture the global and local features of HSI, the hypergraph model is established on superpixel level which characterizes the spectral affinities rather than the spatial distance. The designed hypergraph model not only incorporates the local homogeneity and complex correlations of HSI but also consumes little computation. Two hypergraph convolution layers are designed to propagate and update the features of nodes. To construct an end-to-end architecture, a mapping matrix is defined for pixels encoding and superpixels decoding. The proposed method is hinged on the goodness the clustering algorithm used in superpixel segmentation and the experiments has shown that the clustering algorithm affects the effectiveness of proposed method. Thus, we give a strategy for selecting the segmentation parameter. The comparison experiments conducted on four real-world benchmark HSI data sets demonstrate that the proposed method provides more stable and effective classification performance than some state-of-the-art deep approaches with very limited training samples. The overall accuracies are 95.42\% on Indian Pines, 98.48\% on Kennedy Space center, 98.23\% on Salinas Valley and 96.91\% on Pavia University.},
  archive      = {J_NCA},
  author       = {Xu, Qin and Lin, Jing and Jiang, Bo and Liu, Jinpei and Luo, Bin},
  doi          = {10.1007/s00521-023-08935-w},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21863-21882},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hypergraph convolutional network for hyperspectral image classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A conditional input-based GAN for generating spatio-temporal
motor imagery electroencephalograph data. <em>NCA</em>, <em>35</em>(29),
21841–21861. (<a
href="https://doi.org/10.1007/s00521-023-08927-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain Computer Interface is an emerging technology for assisting patients having long term disability. Electroencephalography is the best technique for recording neural activities, however, recording bio signal data from patients is a hectic task. Therefore, Data augmentation using generative adversarial networks is expected to solve this problem. In this paper, we present temporal generative adversarial network with conditional input labels to learn the spatio-temporal features of electroencephalograph and generate realistic data. In order to evaluate the performance of proposed model, we introduce qualitative, quantitative and feature visualization techniques on motor imagery electroencephalograph dataset. Further, we used 1-dimensional temporal convolutional neural network to investigate whether augmented data can replace real data or not for training models. The presented data augmentation framework was compared to three more data augmentation techniques like: copula generative adversarial network, conditional tabular generative adversarial network and tabular variational autoencoder. Our presented technique showed significantly better results to other data augmentation techniques for Electroencephalograph data. The experimental results show that the value of Kullback–Leibler Divergence (KL Divergence) and Inverted Kolmogorov Smirnov D static test (KS test) of data generated by proposed model is the lowest i.e., 0.8940 and 0.7674 respectively. Further, we have tested exhaustively our new data and used a new testing strategy achieving an accuracy of 94.1\%. Finally, it is concluded that a time series-based data augmentation technique for Electroencephalograph can reduce long calibration process and thus improve the overall performance of motor imagery user action classification.},
  archive      = {J_NCA},
  author       = {Raoof, Ifrah and Gupta, Manoj Kumar},
  doi          = {10.1007/s00521-023-08927-w},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21841-21861},
  shortjournal = {Neural Comput. Appl.},
  title        = {A conditional input-based GAN for generating spatio-temporal motor imagery electroencephalograph data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based spatial-temporal graph transformer for
traffic flow forecasting. <em>NCA</em>, <em>35</em>(29), 21827–21839.
(<a href="https://doi.org/10.1007/s00521-023-08951-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is significant for establishing intelligent traffic systems. However, the complex spatial-temporal relationships of traffic flow data make it challenging. Despite some studies investigating this problem, capturing complex spatial structures and learning the temporal dependence of the long-term prediction are still challenges that need to be addressed. In this paper, we propose a novel attention-based spatial-temporal graph transformer (ASTGT) model to solve the traffic flow forecasting problem. ASTGT primarily consists of two independent components: temporal encoder and spatial-temporal decoder. Precisely, in temporal encoder, we capture the temporal dynamics of traffic data through the self-attention mechanism. The traffic flow data with long-term periodic dependence are also integrated. Moreover, spatial-temporal decoder superimposes the gated spatial graph convolution block to acquire both temporal and spatial relationships at the same time. Extensive experiments are conducted on PEMS04 and PEMS08 datasets from the Caltrans Performance Measurement System. The results show that our proposed ASTGT model outperforms the state-of-the-art baselines.},
  archive      = {J_NCA},
  author       = {Zhang, Qingyong and Chang, Wanfeng and Li, Changwu and Yin, Conghui and Su, Yixin and Xiao, Peng},
  doi          = {10.1007/s00521-023-08951-w},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21827-21839},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention-based spatial-temporal graph transformer for traffic flow forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MetaScleraSeg: An effective meta-learning framework for
generalized sclera segmentation. <em>NCA</em>, <em>35</em>(29),
21797–21826. (<a
href="https://doi.org/10.1007/s00521-023-08937-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sclera segmentation is a key component of sclera recognition, which decides the region-of-interest (ROI) for recognition and has a considerable impact on the overall performance. In recent years, a growing interest has been seen in deep learning-based sclera segmentation. Despite their promising segmentation performance for diverse eye images, they are still inherently limited in generalizing to unseen target domains. In this paper, we aim to bridge this gap and learn a generalized sclera segmentation model that can handle new unseen domains well. To this end, we introduce meta-learning in the sclera segmentation problem and propose an effective learning framework, named MetaScleraSeg. Specifically, we first design a meta-sampling strategy to simulate the source/target domain shift in real-world scenarios. Then, a style-invariant UNet 3+ base model is developed for accurate and robust sclera segmentation. To make the base model not only perform well on synthesized source domains but also on synthesized target domains, we employ the bilevel optimization strategy to update the base model, where three useful loss functions are contained. In the experiments, we build a cross-domain sclera segmentation (CDSS) dataset with diverse ethnicity and quality as domain labels to supplement the existing dataset. Besides, three protocols (cross-dataset, cross-ethnicity, and cross-quality) are designed for comprehensively evaluating the generalization of sclera segmentation models. Both quantitative and qualitative experimental results validate the superiority of our method compared to several baselines, which indicates that MetaScleraSeg can learn the transferable knowledge across domains to generalize well on unseen target domains. Models and dataset of this paper are publicly available at https://github.com/lhqqq/MetaScleraSeg .},
  archive      = {J_NCA},
  author       = {Wang, Caiyong and Li, Haiqing and Ma, Wenhui and Zhao, Guangzhe and He, Zhaofeng},
  doi          = {10.1007/s00521-023-08937-8},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21797-21826},
  shortjournal = {Neural Comput. Appl.},
  title        = {MetaScleraSeg: An effective meta-learning framework for generalized sclera segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable ensembles of hyper-rectangles as base models.
<em>NCA</em>, <em>35</em>(29), 21771–21795. (<a
href="https://doi.org/10.1007/s00521-023-08929-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new extremely simple ensemble-based model with the uniformly generated axis-parallel hyper-rectangles as base models (HRBM) is proposed. Two types of HRBMs are studied: closed rectangles and corners. The main idea behind HRBM is to consider training examples inside and outside each rectangle. It is proposed to incorporate HRBMs into the gradient boosting machine (GBM) to construct effective ensemble-based models and to avoid overfitting. A simple method for calculating optimal regularization parameters of the model, which can be modified in the explicit way at each iteration of GBM, is considered. Moreover, a new regularization called the “step height penalty” is studied in addition to the L1 and L2 regularizations. An extremely simple approach to the proposed ensemble-based model prediction interpretation by using the well-known method SHAP is proposed. It is shown that GBM with HRBM can be regarded as a model extending a set of interpretable models for explaining black-box models. Numerical experiments with real datasets illustrate the proposed GBM with HRBMs for regression and classification problems. The best p-values in the t-test comparing the proposed model with the well-known ensemble-based regression and classification models are 0.004 and 0.0031, respectively. Experiments also illustrate computational efficiency of the proposed SHAP modifications. The code of proposed algorithms implementing GBM with HRBM is publicly available.},
  archive      = {J_NCA},
  author       = {Konstantinov, Andrei V. and Utkin, Lev V.},
  doi          = {10.1007/s00521-023-08929-8},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21771-21795},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interpretable ensembles of hyper-rectangles as base models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binary multi-view sparse subspace clustering. <em>NCA</em>,
<em>35</em>(29), 21751–21770. (<a
href="https://doi.org/10.1007/s00521-023-08915-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering, which partitions multi-view data into their respective underlying subspaces, has achieved the remarkable clustering performance by extracting abundant complementary information from data of different views. However, existing subspace clustering methods almost suffer from very heavy computational burden that restricts their capacity on computational efficiency for large-scale datasets. Recently, hashing/binary code learning has attracted intensive attentions due to fast Hamming distance computation and much less storage requirement, but existing related research does not explore underlying subspace clustering structure well that widely exists in real-world data. In order to handle the both issues, in this paper, we propose a multi-view subspace clustering method named Hashing Multi-view Sparse Subspace Learning (HMSSL). HMSSL incorporates multi-view binary code learning and binary sparse subspace learning with a “thin” dictionary into a unified framework. HMSSL encodes multi-view real-valued features in the original space into compact common binary codes in the Hamming space for fast Hamming distance computation by multi-view binary code learning and learns the binary sparse subspace representation matrix for exploring the underlying subspace clustering structure efficiently and effectively by binary sparse subspace learning with a “thin” dictionary matrix. All the columns of the dictionary matrix are randomly and uniformly sampled from all the columns of the compact common binary code matrix. We design an effective binary optimization algorithm based on alternating direction multiplier method and analyze its time complexity. Extensive experiments performed on six benchmark multi-view datasets demonstrate the effectiveness of HMSSL in comparison with ten state-of-the-art baselines in this field.},
  archive      = {J_NCA},
  author       = {Zhao, Jianxi and Li, Yang},
  doi          = {10.1007/s00521-023-08915-0},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21751-21770},
  shortjournal = {Neural Comput. Appl.},
  title        = {Binary multi-view sparse subspace clustering},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessing of causes of accidents based on a novel integrated
interval-valued fermatean fuzzy methodology: Towards a sustainable
construction site. <em>NCA</em>, <em>35</em>(29), 21725–21750. (<a
href="https://doi.org/10.1007/s00521-023-08948-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The statistics pertaining to accidents occurring at construction sites underscore the pressing requirement for a substantial and timely reevaluation of safety measures within the construction sector. Accidents do not occur randomly; rather, they arise from the presence of unsafe actions, hazardous conditions, or a combination of both. The majority of accidents stem from a combination of contributing causes, including unsafe acts and conditions. To enhance safety performance on a broader scale, this study undertakes an extensive analysis to identify these causes, evaluate their importance, and determine the countries that are most and least impacted by them. Ten African countries were selected as potential alternatives based on the frequency of infrastructure construction projects. A thorough review of existing literature was conducted to establish a three-level criteria framework. The framework was further refined through the Modified Delphi method to gather expert opinions. The weights assigned to the criteria were determined using the interval-valued Fermatean fuzzy analytical hierarchy process methodology. The Technique for Order Preference by Similarity to Ideal Solution method under the same fuzzy environment was then employed to rank the alternative countries. A sensitivity analysis was carried out to assess the robustness of the proposed methodology. The analysis revealed that the main cause of accidents was attributed to poor management, as it included ineffective project supervision, inadequate safety policies, poor organizational structure, and inappropriate scheduling/planning as the main underlying sub-factors. Additionally, it was observed that the sixth alternative country exhibited the highest susceptibility to accidents occurring at construction sites.},
  archive      = {J_NCA},
  author       = {Bouraima, Mouhamed Bayane and Gore, Abibata and Ayyildiz, Ertugrul and Yalcin, Selin and Badi, Ibrahim and Kiptum, Clement Kiprotich and Qiu, Yanjun},
  doi          = {10.1007/s00521-023-08948-5},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21725-21750},
  shortjournal = {Neural Comput. Appl.},
  title        = {Assessing of causes of accidents based on a novel integrated interval-valued fermatean fuzzy methodology: Towards a sustainable construction site},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A real-time arabic avatar for deaf–mute community using
attention mechanism. <em>NCA</em>, <em>35</em>(29), 21709–21723. (<a
href="https://doi.org/10.1007/s00521-023-08858-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech-impaired people use Sign Language (SL), an efficient natural form of communication, all over the world. This paper aims to use deep learning technology in the realm of SL translation and identification. In order to ease communication between hearing-impaired and sighted individuals and to enable the social inclusion of hearing-impaired people in their daily lives, it presents a transformer as a neural machine translation model. The article details the creation of a machine translation system that converts Arabic audio and text into Arabic Sign Language (ArSL) automatically. It does this by utilizing an animated character to produce the correct sign for each spoken word. Since Arabic has few resources, it was challenging to obtain an Arabic-Sign dataset, so we created our own Arabic–Arabic sign gloss, which consists of 12,187 pairs, to train the model. We use bidirectional encoder representations from transformers as an embedding layer to interpret input text tokens and represent an appropriate natural language vector space for deep learning models. To represent the structure of each Arabic word, the Ferasa Part-of-Speech Tagging module was used and then the extracted rules from the ArSL structure were applied. This paper shows a detailed description of a natural language translator (for converting an Arabic word sequence into a sequence of signs belonging to the ArSL) and a 2D avatar animation module (for playing back the signs). In our prototype, we train the software-based module using the attention mechanism. The evaluation was carried out in our developed Arabic sentences with the corresponding Arabic gloss. The proposed model achieves promising results and indicates significant improvements to direct communication between hearing and deaf people, with a training accuracy of 94.71\% and an 87.04\% testing accuracy for Arabic–Arabic sign gloss translation.},
  archive      = {J_NCA},
  author       = {Mosa, Diana T. and Nasef, Nada A. and Lotfy, Mohamed A. and Abohany, Amr A. and Essa, Reham M. and Salem, Ahmed},
  doi          = {10.1007/s00521-023-08858-6},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21709-21723},
  shortjournal = {Neural Comput. Appl.},
  title        = {A real-time arabic avatar for deaf–mute community using attention mechanism},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neuro-evolutionary for time series forecasting and its
application in hourly energy consumption prediction. <em>NCA</em>,
<em>35</em>(29), 21697–21707. (<a
href="https://doi.org/10.1007/s00521-023-08942-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed an ensemble methodology comprising neural networks, modified differential evolution algorithm and nonlinear autoregressive network with exogenous inputs (NARX) (called neuro-evolutionary NARX or NE-NARX model) for time series forecasting. In NE-NARX, the structure is designed by connecting the neural model and NARX model, and the weight value connection is optimized by a modified differential evolution algorithm. The effectiveness of the proposed NE-NARX model is tested on two well-known benchmark datasets, including the Canadian lynx and the Wolf sunspot. The proposed model is compared to other models, including the classical backpropagation algorithm, particle swarm optimization, differential evolution (DE) and DE variants. Additionally, an ARIMA model is employed as the benchmark for evaluating the capacity of the proposed model. And then, NE-NARX model is used for hourly energy consumption prediction through comparison with other machine learning models including gated recurrent units, convolutional neural networks (CNN), long short-term memory (LSTM), a hybrid CNN-LSTM and sequence-to-sequence learning. Results show convincingly the superiority of the proposed NE-NARX model over other models.},
  archive      = {J_NCA},
  author       = {Son, Nguyen Ngoc and Van Cuong, Nguyen},
  doi          = {10.1007/s00521-023-08942-x},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21697-21707},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neuro-evolutionary for time series forecasting and its application in hourly energy consumption prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of the companies for applied education under
fuzzy environment: A case in an industrial university. <em>NCA</em>,
<em>35</em>(29), 21675–21695. (<a
href="https://doi.org/10.1007/s00521-023-08926-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the problem of university graduates being unemployed is gradually increasing. To keep down unemployment, universities are integrating the concept of “applied education” into their educational curricula. The concept of applied education brings with it the problem of the correct student-company matching. In this study, the company selection criteria were focused on to determine the companies that university students will be sent to within the scope of applied education. Company selection criteria are determined by experts in the field. However, the evaluation of experts with precise criteria values can be very challenging in the decision-making process. For this purpose, the criteria weights were calculated using the Pythagorean Fuzzy AHP method in this study. Evaluation of companies to which students will be matched for applied/workplace education is ranked with these fuzzy weights by using TOPSIS and PROMETHEE II methods. To evaluation the proposed decision process, a real case study is carried out in an industrial private university in Turkey. The case study results show that the proposed method can provide effective and consistent results in the evaluation of companies under fuzzy environment.},
  archive      = {J_NCA},
  author       = {Çiftçi, Sema and Pınarbaşı, Mehmet and Yazıcı, Emre and Alakaş, Hacı Mehmet},
  doi          = {10.1007/s00521-023-08926-x},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21675-21695},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation of the companies for applied education under fuzzy environment: A case in an industrial university},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based risk reduction approach using novel
banking parameters on a standardized dataset. <em>NCA</em>,
<em>35</em>(29), 21663–21673. (<a
href="https://doi.org/10.1007/s00521-023-08836-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most critical issue for financial and entrepreneurship institutions is determining customers&#39; ability to repay the facilities. Furthermore, the customers&#39; success in running and fulfilling their business should be considered. A wide range of research studies has been carried out on customers’ authentication about granting personal credit cards and consumer loans to them. The issue that has remained untouched or less investigated is that most loans paid for starting up a business encounter the problem of not setting up that business; moreover, applicants may fail to maintain their business after launch. These issues can result in several issues such as inflation in society, non-growth of assets and stalled transactions, and huge losses for loan lending institutions. One appropriate solution to overcome such problems is to select proper applicants for granting facilities with minimum failure probability for project fulfillment or facility non-repayment. From this standpoint, the present study presents a decision-making model for the automatic selection of facility applicants which is a critical need in financial institutions. For this purpose, a relatively comprehensive and complete dataset based on existing standards is generated. This dataset is designed by considering the patterns of prosperous and non-prosperous customers in four areas of prediction: supervision status, facility status, number of generated jobs, and activity time duration. A deep feedforward neural network (DFNN) model is designed and developed to extract features from input data. The proposed DFNN model is tested and investigated not only on the generated dataset, but also on other datasets, and it is then compared to other methods available. It is observed that the proposed model is significantly successful and efficient.},
  archive      = {J_NCA},
  author       = {Haddadi, Hamed and Razavi, Seyed Naser and Babazadeh Sangar, Amin},
  doi          = {10.1007/s00521-023-08836-y},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21663-21673},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based risk reduction approach using novel banking parameters on a standardized dataset},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fractional-order chaotic oscillator-based aquila
optimization algorithm for maximization of the chaotic with lorentz
oscillator. <em>NCA</em>, <em>35</em>(29), 21645–21662. (<a
href="https://doi.org/10.1007/s00521-023-08945-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random structures in the Aquila optimization algorithm are modeled with fractional chaotic oscillators, and the fractional-order chaotic oscillator-based Aquila optimization (FOCOBAO) algorithm was suggested in this study. First of all, the basic AO algorithm was examined. In particular, random variables that affect the optimization performance of the AO algorithm have been determined. Then, instead of the determined random variables, the coefficients were derived with fractional chaotic oscillators and used in the FOCOBAO. The superiority of the proposed algorithm was primarily demonstrated via twenty-three benchmark functions. The results were matched with GO, EO, GWO, MPA, WOA, SMA and basic AO optimization algorithms. Then, the design of the Lorenz chaotic oscillator, according to maximum chaotic objective function, is a topic that remains up to date in the literature. In this study, a fractional chaotic Lorenz oscillator was designed with FOCOBAO as an engineering application. Especially for maximum chaoticity, maximum positive Lyapunov exponents were determined. In this way, a different design process has been proposed in the literature. The basic AO algorithm, which includes stochastic processes, was developed with fractional chaotic oscillators, and a deterministic method was obtained. The parameters of the Lorenz system were calculated for maximum chaoticity, and the results were presented comparatively.},
  archive      = {J_NCA},
  author       = {Cavlak, Yakup and Ateş, Abdullah and Abualigah, Laith and Elaziz, Mohammed Abd},
  doi          = {10.1007/s00521-023-08945-8},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21645-21662},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fractional-order chaotic oscillator-based aquila optimization algorithm for maximization of the chaotic with lorentz oscillator},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A non-global disturbance targeted adversarial example
algorithm combined with c&amp;w and grad-cam. <em>NCA</em>,
<em>35</em>(29), 21633–21644. (<a
href="https://doi.org/10.1007/s00521-023-08921-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples are artificially crafted to mislead deep learning systems into making wrong decisions. In the research of attack algorithms against multi-class image classifiers, an improved strategy of applying category explanation to the generation control of targeted adversarial example is proposed to reduce the perturbation noise and improve the adversarial robustness. On the basis of C&amp;W adversarial attack algorithm, the method uses Grad-Cam, a category visualization explanation algorithm of CNN, to dynamically obtain the salient regions according to the signal features of source and target categories during the iterative generation process. The adversarial example of non-global perturbation is finally achieved by gradually shielding the non-salient regions and fine-tuning the perturbation signals. Compared with other similar algorithms under the same conditions, the method enhances the effects of the original image category signal on the perturbation position. And it makes up for the shortcomings of the adversarial example algorithm in terms of interpretability and teaching intuitiveness. Experimental results show that the improved adversarial examples have higher PSNR. In addition, in a variety of different defense processing tests, the examples can keep high adversarial performance and show strong attacking robustness.},
  archive      = {J_NCA},
  author       = {Zhu, Yinghui and Jiang, Yuzhen},
  doi          = {10.1007/s00521-023-08921-2},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21633-21644},
  shortjournal = {Neural Comput. Appl.},
  title        = {A non-global disturbance targeted adversarial example algorithm combined with C&amp;W and grad-cam},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Swin-LBP: A competitive feature engineering model for urine
sediment classification. <em>NCA</em>, <em>35</em>(29), 21621–21632. (<a
href="https://doi.org/10.1007/s00521-023-08919-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated urine sediment analysis has become an essential part of diagnosing, monitoring, and treating various diseases that affect the urinary tract and kidneys. However, manual analysis of urine sediment is time-consuming and prone to human bias, and hence there is a need for an automated urine sediment analysis systems using machine learning algorithms. In this work, we propose Swin-LBP, a handcrafted urine sediment classification model using the Swin transformer architecture and local binary pattern (LBP) technique to achieve high classification performance. The Swin-LBP model comprises five phases: preprocessing of input images using shifted windows-based patch division, six-layered LBP-based feature extraction, neighborhood component analysis-based feature selection, support vector machine-based calculation of six predicted vectors, and mode function-based majority voting of the six predicted vectors to generate four additional voted vectors. Our newly reconstructed urine sediment image dataset, consisting of 7 distinct classes, was utilized for training and testing our model. Our proposed model has several advantages over existing automated urinalysis systems. Firstly, we used a feature engineering model that enables high classification performance with linear complexity. This means that it can provide accurate results quickly and efficiently, making it an attractive alternative to time-consuming and biased manual urine sediment analysis. Additionally, our model outperformed existing deep learning models developed on the same source urine sediment image dataset, indicating its superiority in urine sediment classification. Our model achieved 92.60\% accuracy for 7-class urine sediment classification, with an average precision of 92.05\%. These results demonstrate that the proposed Swin-LBP model can provide a reliable and efficient solution for the diagnosis, surveillance, and therapeutic monitoring of various diseases affecting the kidneys and urinary tract. The proposed model&#39;s accuracy, speed, and efficiency make it an attractive option for clinical laboratories and healthcare facilities. In conclusion, the Swin-LBP model has the potential to revolutionize urine sediment analysis and improve patient outcomes in the diagnosis and treatment of urinary tract and kidney diseases.},
  archive      = {J_NCA},
  author       = {Erten, Mehmet and Barua, Prabal Datta and Tuncer, Ilknur and Dogan, Sengul and Baygin, Mehmet and Tuncer, Turker and Tan, Ru-San and Acharya, U. Rajendra},
  doi          = {10.1007/s00521-023-08919-w},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21621-21632},
  shortjournal = {Neural Comput. Appl.},
  title        = {Swin-LBP: A competitive feature engineering model for urine sediment classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Qoe-guaranteed distributed offloading decision via partially
observable deep reinforcement learning for edge-enabled internet of
things. <em>NCA</em>, <em>35</em>(29), 21603–21619. (<a
href="https://doi.org/10.1007/s00521-023-08905-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In edge-enabled Internet of Things (IoT), Quality of Experience (QoE)-guaranteed offloading decision is to decide which IoT tasks can be offloaded to edge servers with QoE guarantee. Centralized QoE-guaranteed offloading decision methods construct a global decision model for all IoT tasks with complete information. However, centralized offloading decision methods entail collecting global information from IoT devices, edge servers, and network environment, which may not be practical in large-scale distributed edge-enabled IoT environments, and it is unrealistic for privacy-critical and heterogeneous IoT tasks in many real-world edge-enabled IoT systems, where IoT devices may refuse to expose their private information and heterogeneous IoT tasks may have different QoE requirements, these issues make the application of centralized offloading decision method limited. To address these limitations, we propose a distributed offloading decision method which enables each IoT device to make decisions by partially observable global information in a decentralized manner. The distributed offloading decision process is modeled as a multi-agent partially observable Markov decision process, and a novel model-free deep reinforcement learning-based distributed algorithm named GRU Fictitious Self-Play Dueling Double Deep Recurrent Q Network(GFSP-D3RQN) is introduced to solve the problem. Furthermore, we measure the QoE of each IoT device based on a combination of latency and energy consumption, which are weighted differently according to the individual preferences of each IoT device, using a non-dimensionalized adjustment to accommodate the varying requirements of these IoT devices. Extensive simulation results show that our algorithm can achieve a higher average QoE and higher success ratio compared with baseline algorithms, which improved by at least 6.38 $$\%$$ and 5.91 $$\%$$ , respectively.},
  archive      = {J_NCA},
  author       = {Hou, Jiaxin and Wu, Yingbo and Cai, Junpeng and Zhou, Zhiwen},
  doi          = {10.1007/s00521-023-08905-2},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21603-21619},
  shortjournal = {Neural Comput. Appl.},
  title        = {Qoe-guaranteed distributed offloading decision via partially observable deep reinforcement learning for edge-enabled internet of things},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on sentiment analysis and its applications.
<em>NCA</em>, <em>35</em>(29), 21567–21601. (<a
href="https://doi.org/10.1007/s00521-023-08941-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing and understanding the sentiments of social media documents on Twitter, Facebook, and Instagram has become a very important task at present. Analyzing the sentiment of these documents gives meaningful knowledge about the user opinions, which will help understand the overall view on these platforms. The problem of sentiment analysis (SA) can be regarded as a classification problem in which the text is classified as positive, negative, or neutral. This paper aims to give an intensive, but not exhaustive, review of the main concepts of SA and the state-of-the-art techniques; other aims are to make a comparative study of their performances, the main applications of SA as well as the limitations and the future directions for SA. Based on our analysis, researchers have utilized three main approaches for SA, namely lexicon/rules, machine learning (ML), and deep learning (DL). The performance of lexicon/rules-based models typically falls within the range of 55–85\%. ML models, on the other hand, generally exhibit performance ranging from 55\% to 90\%, while DL models tend to achieve higher performance, ranging from 70\% to 95\%. These ranges are estimated and may be higher or lower depending on various factors, including the quality of the datasets, the chosen model architecture, the preprocessing techniques employed, as well as the quality and coverage of the lexicon utilized. Moreover, to further enhance models’ performance, researchers have delved into the implementation of hybrid models and optimization techniques which have demonstrated an ability to enhance the overall performance of SA models.},
  archive      = {J_NCA},
  author       = {Al-Qablan, Tamara Amjad and Mohd Noor, Mohd Halim and Al-Betar, Mohammed Azmi and Khader, Ahamad Tajudin},
  doi          = {10.1007/s00521-023-08941-y},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21567-21601},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey on sentiment analysis and its applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MVDroid: An android malicious VPN detector using neural
networks. <em>NCA</em>, <em>35</em>(29), 21555–21565. (<a
href="https://doi.org/10.1007/s00521-023-08512-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of Virtual Private Networks (VPNs) fail when it comes to protecting our privacy. If we are using a VPN to protect our online privacy, many of the well-known VPNs are not secure to use. When examined closely, VPNs can appear to be perfect on the surface but still be a complete privacy and security disaster. Some VPNs will steal our bandwidth, infect our computers with malware, install secret tracking libraries on our devices, steal our personal data, and leave our data exposed to third parties. Generally, Android users should be cautious when installing any VPN software on their devices. As a result, it is important to identify malicious VPNs before downloading and installing them on our Android devices. This paper provides an optimised deep learning neural network for identifying fake VPNs, and VPNs infected by malware based on the permissions of the apps, as well as a novel dataset of malicious and benign Android VPNs. Experimental results indicate that our proposed classifier identifies malicious VPNs with high accuracy, while it outperforms other standard classifiers in terms of evaluation metrics such as accuracy, precision, and recall.},
  archive      = {J_NCA},
  author       = {Seraj, Saeed and Khodambashi, Siavash and Pavlidis, Michalis and Polatidis, Nikolaos},
  doi          = {10.1007/s00521-023-08512-1},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21555-21565},
  shortjournal = {Neural Comput. Appl.},
  title        = {MVDroid: An android malicious VPN detector using neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving explainability results of convolutional neural
networks in microscopy images. <em>NCA</em>, <em>35</em>(29),
21535–21553. (<a
href="https://doi.org/10.1007/s00521-023-08452-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explaining the predictions of neural networks to comprehend which region of an image influences the most its decision has become an imperative prerequisite when classifying medical images. In the case of convolutional neural networks, gradient-weighted class activation mapping is an explainability scheme that is more than often utilized for the unveiling of connections between stimuli and predictions especially in classification tasks that address the determination of the class between distinct objects in an image. However, certain categories of medical imaging such as confocal and histopathology images contain rich and dense information that differs from the cat versus dog paradigm. To further improve the performance of the gradient-weighted class activation mapping technique and the generated visualizations, we propose a segmentation-based explainability scheme that focuses on the common visual characteristics of each segment in an image to provide enhanced visualizations instead of highlighting rectangular regions. The explainability performance was quantified by applying random noise perturbations on microscopy images. The area over perturbation curve is utilized to demonstrate the improvement of the proposed methodology when utilizing the Slic superpixel algorithm against the Grad-CAM technique by an average of 4\% for the confocal dataset and 9\% for histopathology dataset. The results show that the generated visualizations are more comprehensible to humans than the initial heatmaps and demonstrate improved performance against the original Grad-CAM technique.},
  archive      = {J_NCA},
  author       = {Kallipolitis, Athanasios and Yfantis, Panayiotis and Maglogiannis, Ilias},
  doi          = {10.1007/s00521-023-08452-w},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21535-21553},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving explainability results of convolutional neural networks in microscopy images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A trusted authentication scheme based on super SIM card for
mobile office for industry 4.0. <em>NCA</em>, <em>35</em>(29),
21525–21533. (<a
href="https://doi.org/10.1007/s00521-023-08540-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development and wide popularity of Internet technology, mobile application services have become an indispensable part of people&#39;s daily life. As a typical mobile application service, mobile office can provide an anytime, anywhere platform, enabling users to use fragmented time and fully improve office efficiency. However, it differs from the traditional one in that the user’s identity cannot be directly identified in real space. Therefore, the need to ensure the authenticity of the user&#39;s identity is not negligible. Authentication technology is one of the effective technologies to verify the identity of users. However, there are few authentication schemes for the mobile office. Therefore, this paper proposes a trusted authentication scheme based on a super SIM card for the mobile office. Based on the Generic Bootstrapping Architecture (GBA) authentication technology of the super SIM card, the authentication between the terminal device and the operator is realized. The authentication credentials are generated to provide trusted authentication for mobile office applications. We also have a comprehensive security analysis and proof that the scheme satisfies two-way authentication, anti-replay attack, anti-forgery attack, anti-man-in-the-middle attack and non-repudiation.},
  archive      = {J_NCA},
  author       = {Kong, Lingnan and Qian, Zhendong and Xu, Lvbin and Yang, Jun and Shao, Quanyuan},
  doi          = {10.1007/s00521-023-08540-x},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21525-21533},
  shortjournal = {Neural Comput. Appl.},
  title        = {A trusted authentication scheme based on super SIM card for mobile office for industry 4.0},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural clustering based on implicit maximum likelihood.
<em>NCA</em>, <em>35</em>(29), 21511–21524. (<a
href="https://doi.org/10.1007/s00521-023-08524-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is one of the most fundamental unsupervised learning tasks with numerous applications in various fields. Clustering methods based on neural networks, called deep clustering methods, leverage the representational power of neural networks to enhance clustering performance. ClusterGan constitutes a generative deep clustering method that exploits generative adversarial networks (GANs) to perform clustering. However, it inherits some deficiencies of GANs, such as mode collapse, vanishing gradients and training instability. In order to tackle those deficiencies, the generative approach of implicit maximum likelihood estimation (IMLE) has been recently proposed. In this paper, we present a clustering method based on generative neural networks, called neural implicit maximum likelihood clustering, which adopts ideas from both ClusterGAN and IMLE. The proposed method has been compared with ClusterGAN and other neural clustering methods on both synthetic and real datasets, demonstrating promising results.},
  archive      = {J_NCA},
  author       = {Vardakas, Georgios and Likas, Aristidis},
  doi          = {10.1007/s00521-023-08524-x},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21511-21524},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural clustering based on implicit maximum likelihood},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure sharing of industrial IoT data based on distributed
trust management and trusted execution environments: A federated
learning approach. <em>NCA</em>, <em>35</em>(29), 21499–21509. (<a
href="https://doi.org/10.1007/s00521-023-08375-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (I-IoT) has become an emerging driver to operate industrial systems and a primary empowerer to future industries. With the advanced technologies such as artificial intelligence (AI) and machine learning widely used in IoT, the Industrial IoT is also witnessing changes driven by new technologies. Generally, AI technologies require centralized data collection and processing to learn from the data to obtain viable models for application. In industrial IoT, data security and privacy problems associated with reliable and interconnected end devices are being faced and reliable solutions are urgently needed. A trusted execution environment in IoT devices is gradually becoming a feasible approach, and a distributed solution is a natural choice for artificial intelligence technologies in I-IoT. Moreover, Federated Learning as a distributed machine learning paradigm with privacy-preserving properties can be used in I-IoT. This paper introduces a feasible secure data circulation and sharing scheme for I-IoT devices in a trusted implementation platform by employing federated learning. The suggested framework has proved to be efficient, reliable, and accurate.},
  archive      = {J_NCA},
  author       = {Zheng, Wei and Cao, Yang and Tan, Haining},
  doi          = {10.1007/s00521-023-08375-6},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21499-21509},
  shortjournal = {Neural Comput. Appl.},
  title        = {Secure sharing of industrial IoT data based on distributed trust management and trusted execution environments: A federated learning approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multivariate ensemble learning method for medium-term
energy forecasting. <em>NCA</em>, <em>35</em>(29), 21479–21497. (<a
href="https://doi.org/10.1007/s00521-023-08777-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the contemporary context, both production and consumption of energy, being concepts intertwined through a condition of synchronicity, are pivotal for the orderly functioning of society, with their management being a building block in maintaining regularity. Hence, the pursuit to develop reliable computational tools for modeling such serial and time-dependent phenomena becomes similarly crucial. This paper investigates the use of ensemble learners for medium-term forecasting of the Greek energy system load using additional information from injected energy production from various sources. Through an extensive experimental process, over 435 regression schemes and 64 different modifications of the feature inputs were tested over five different prediction time frames, creating comparative rankings regarding two case studies: one related to methods and the other to feature setups. Evaluations according to six widely used metrics indicate an aggregate but clear dominance of a specific efficient and low-cost ensemble layout. In particular, an ensemble method that incorporates the orthogonal matching pursuit together with the Huber regressor according to an averaged combinatorial scheme is proposed. Moreover, it is shown that the use of multivariate setups improves the derived predictions.},
  archive      = {J_NCA},
  author       = {Liapis, Charalampos M. and Karanikola, Aikaterini and Kotsiantis, Sotiris},
  doi          = {10.1007/s00521-023-08777-6},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21479-21497},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multivariate ensemble learning method for medium-term energy forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Speech emotion recognition and text sentiment analysis for
financial distress prediction. <em>NCA</em>, <em>35</em>(29),
21463–21477. (<a
href="https://doi.org/10.1007/s00521-023-08470-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been an increasing interest in text sentiment analysis and speech emotion recognition in finance due to their potential to capture the intentions and opinions of corporate stakeholders, such as managers and investors. A considerable performance improvement in forecasting company financial performance was achieved by taking textual sentiment into account. However, far too little attention has been paid to managerial emotional states and their potential contribution to financial distress prediction. This study seeks to address this problem by proposing a deep learning architecture that uniquely combines managerial emotional states extracted using speech emotion recognition with FinBERT-based sentiment analysis of earnings conference call transcripts. Thus, the obtained information is fused with traditional financial indicators to achieve a more accurate prediction of financial distress. The proposed model is validated using 1278 earnings conference calls of the 40 largest US companies. The findings of this study provide evidence on the essential role of managerial emotions in predicting financial distress, even when compared with sentiment indicators obtained from text. The experimental results also demonstrate the high accuracy of the proposed model compared with state-of-the-art prediction models.},
  archive      = {J_NCA},
  author       = {Hajek, Petr and Munk, Michal},
  doi          = {10.1007/s00521-023-08470-8},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21463-21477},
  shortjournal = {Neural Comput. Appl.},
  title        = {Speech emotion recognition and text sentiment analysis for financial distress prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining deep reinforcement learning with technical
analysis and trend monitoring on cryptocurrency markets. <em>NCA</em>,
<em>35</em>(29), 21445–21462. (<a
href="https://doi.org/10.1007/s00521-023-08516-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptocurrency markets experienced a significant increase in the popularity, which motivated many financial traders to seek high profits in cryptocurrency trading. The predominant tool that traders use to identify profitable opportunities is technical analysis. Some investors and researchers also combined technical analysis with machine learning, in order to forecast upcoming trends in the market. However, even with the use of these methods, developing successful trading strategies is still regarded as an extremely challenging task. Recently, deep reinforcement learning (DRL) algorithms demonstrated satisfying performance in solving complicated problems, including the formulation of profitable trading strategies. While some DRL techniques have been successful in increasing profit and loss (PNL) measures, these techniques are not much risk-aware and present difficulty in maximizing PNL and lowering trading risks simultaneously. This research proposes the combination of DRL approaches with rule-based safety mechanisms to both maximize PNL returns and minimize trading risk. First, a DRL agent is trained to maximize PNL returns, using a novel reward function. Then, during the exploitation phase, a rule-based mechanism is deployed to prevent uncertain actions from being executed. Finally, another novel safety mechanism is proposed, which considers the actions of a more conservatively trained agent, in order to identify high-risk trading periods and avoid trading. Our experiments on 5 popular cryptocurrencies show that the integration of these three methods achieves very promising results.},
  archive      = {J_NCA},
  author       = {Kochliaridis, Vasileios and Kouloumpris, Eleftherios and Vlahavas, Ioannis},
  doi          = {10.1007/s00521-023-08516-x},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21445-21462},
  shortjournal = {Neural Comput. Appl.},
  title        = {Combining deep reinforcement learning with technical analysis and trend monitoring on cryptocurrency markets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysing sentiment change detection of covid-19 tweets.
<em>NCA</em>, <em>35</em>(29), 21433–21443. (<a
href="https://doi.org/10.1007/s00521-023-08662-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Covid-19 pandemic made a significant impact on society, including the widespread implementation of lockdowns to prevent the spread of the virus. This measure led to a decrease in face-to-face social interactions and, as an equivalent, an increase in the use of social media platforms, such as Twitter. As part of Industry 4.0, sentiment analysis can be exploited to study public attitudes toward future pandemics and sociopolitical situations in general. This work presents an analysis framework by applying a combination of natural language processing techniques and machine learning algorithms to classify the sentiment of each tweet as positive, or negative. Through extensive experimentation, we expose the ideal model for this task and, subsequently, utilize sentiment predictions to perform time series analysis over the course of the pandemic. In addition, a change point detection algorithm was applied in order to identify the turning points in public attitudes toward the pandemic, which were validated by cross-referencing the news report at that particular period of time. Finally, we study the relationship between sentiment trends on social media and, news coverage of the pandemic, providing insights into the public’s perception of the pandemic and its influence on the news.},
  archive      = {J_NCA},
  author       = {Theocharopoulos, Panagiotis C. and Tsoukala, Anastasia and Georgakopoulos, Spiros V. and Tasoulis, Sotiris K. and Plagianakos, Vassilis P.},
  doi          = {10.1007/s00521-023-08662-2},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21433-21443},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analysing sentiment change detection of covid-19 tweets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multilingual text categorization and sentiment analysis: A
comparative analysis of the utilization of multilingual approaches for
classifying twitter data. <em>NCA</em>, <em>35</em>(29), 21415–21431.
(<a href="https://doi.org/10.1007/s00521-023-08629-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text categorization and sentiment analysis are two of the most typical natural language processing tasks with various emerging applications implemented and utilized in different domains, such as health care and policy making. At the same time, the tremendous growth in the popularity and usage of social media, such as Twitter, has resulted on an immense increase in user-generated data, as mainly represented by the corresponding texts in users’ posts. However, the analysis of these specific data and the extraction of actionable knowledge and added value out of them is a challenging task due to the domain diversity and the high multilingualism that characterizes these data. The latter highlights the emerging need for the implementation and utilization of domain-agnostic and multilingual solutions. To investigate a portion of these challenges this research work performs a comparative analysis of multilingual approaches for classifying both the sentiment and the text of an examined multilingual corpus. In this context, four multilingual BERT-based classifiers and a zero-shot classification approach are utilized and compared in terms of their accuracy and applicability in the classification of multilingual data. Their comparison has unveiled insightful outcomes and has a twofold interpretation. Multilingual BERT-based classifiers achieve high performances and transfer inference when trained and fine-tuned on multilingual data. While also the zero-shot approach presents a novel technique for creating multilingual solutions in a faster, more efficient, and scalable way. It can easily be fitted to new languages and new tasks while achieving relatively good results across many languages. However, when efficiency and scalability are less important than accuracy, it seems that this model, and zero-shot models in general, can not be compared to fine-tuned and trained multilingual BERT-based classifiers.},
  archive      = {J_NCA},
  author       = {Manias, George and Mavrogiorgou, Argyro and Kiourtis, Athanasios and Symvoulidis, Chrysostomos and Kyriazis, Dimosthenis},
  doi          = {10.1007/s00521-023-08629-3},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21415-21431},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multilingual text categorization and sentiment analysis: A comparative analysis of the utilization of multilingual approaches for classifying twitter data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural networks as building blocks for the design of
efficient learned indexes. <em>NCA</em>, <em>35</em>(29), 21399–21414.
(<a href="https://doi.org/10.1007/s00521-023-08841-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The new area of Learned Data Structures consists of mixing Machine Learning techniques with those specific to Data Structures, with the purpose to achieve time/space gains in the performance of those latter. The perceived paradigm shift in computer architectures, that would favor the employment of graphics/tensor units over traditional central processing units, is one of the driving forces behind this new area. The advent of the corresponding branch-free programming paradigm would then favor the adoption of Neural Networks as the fundamental units of Classic Data Structures. This is the case of Learned Bloom Filters. The equally important field of Learned Indexes does not appear to make use of Neural Networks at all. In this paper, we offer a comparative experimental investigation regarding the potential uses of Neural Networks as a fundamental building block of Learned Indexes. Our results provide a solid and much-needed evaluation of the role Neural Networks can play in Learned Indexing. Based on our findings, we highlight the need for the creation of highly specialised Neural Networks customised to Learned Indexes. Because of the methodological significance of our findings and application of Learned Indexes in strategic domains, such as Computer Networks and Databases, care has been taken to make the presentation of our results accessible to the general audience of scientists and engineers working in Neural Networks and with no background about Learned Indexing.},
  archive      = {J_NCA},
  author       = {Amato, Domenico and Lo Bosco, Giosué and Giancarlo, Raffaele},
  doi          = {10.1007/s00521-023-08841-1},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21399-21414},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural networks as building blocks for the design of efficient learned indexes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid artificial intelligence solution approach to
aftercare for cancer patients. <em>NCA</em>, <em>35</em>(29),
21381–21397. (<a
href="https://doi.org/10.1007/s00521-023-08765-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This publication presents a solution approach to oncological aftercare for cancer patients by means of artificial intelligence (AI) methods. This approach shall support patients in overcoming the after-effects of therapy effectively with suitable supportive actions and health-care professionals in goal-oriented planning of these actions. Different AI methods are used for analyzing patients’ needs for supportive actions depending on the available health data and for a monitoring of these actions. Decision support methods are used for effective planning of actions based on the AI results of analysis. The solution approach is realized in the form of a web application for health-care professionals, which allows for data analysis and planning of actions, and a mobile application for patients, which facilitates documentation and monitoring of supportive actions. In combination, they facilitate a closed-loop workflow for the effective cooperation of health-care professionals and cancer patients. The solution approach is illustrated for an exemplary case scenario of colorectal cancer.},
  archive      = {J_NCA},
  author       = {Scherrer, Alexander and Zimmermann, Tobias and Riedel, Sinan and Venios, Stefanos and Koussouris, Sotiris and Plakia, Maria and Diamantopoulos, Sotiris and Athanassopoulos, Sotiris and Laras, Paris and Mousa, Fihmi and Zifrid, Robert and Tillil, Hartmut and Musisi, Isa Wasswa and Kosmidis, Thanos and Reis, Joaquim C. and Moehler, Markus and Oestreicher, Gabrielle and Kalamaras, Ilias and Pantelidou, Konstantina and Votis, Konstantinos and Vassiliou, Charalampos},
  doi          = {10.1007/s00521-023-08765-w},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21381-21397},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid artificial intelligence solution approach to aftercare for cancer patients},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixed-precision quantization-aware training for photonic
neural networks. <em>NCA</em>, <em>35</em>(29), 21361–21379. (<a
href="https://doi.org/10.1007/s00521-023-08848-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The energy demanding nature of deep learning (DL) has fueled the immense attention for neuromorphic architectures due to their ability to operate in a very high frequencies in a very low energy consumption. To this end, neuromorphic photonics are among the most promising research directions, since they are able to achieve femtojoule per MAC efficiency. Although electrooptical substances provide a fast and efficient platform for DL, they also introduce various noise sources that impact the effective bit resolution, introducing new challenges to DL quantization. In this work, we propose a quantization-aware training method that gradually performs bit reduction to layers in a mixed-precision manner, enabling us to operate lower-precision networks during deployment and further increase the computational rate of the developed accelerators while keeping the energy consumption low. Exploiting the observation that intermediate layers have lower-precision requirements, we propose to gradually reduce layers’ bit resolutions, by normally distributing the reduction probability of each layer. We experimentally demonstrate the advantages of mixed-precision quantization in both performance and inference time. Furthermore, we experimentally evaluate the proposed method in different tasks, architectures, and photonic configurations, highlighting its immense capabilities to reduce the average bit resolution of DL models while significantly outperforming the evaluated baselines.},
  archive      = {J_NCA},
  author       = {Kirtas, Manos and Passalis, Nikolaos and Oikonomou, Athina and Moralis-Pegios, Miltos and Giamougiannis, George and Tsakyridis, Apostolos and Mourgias-Alexandris, George and Pleros, Nikolaos and Tefas, Anastasios},
  doi          = {10.1007/s00521-023-08848-8},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21361-21379},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mixed-precision quantization-aware training for photonic neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A trusted routing mechanism for multi-attribute chain energy
optimization for industrial internet of things. <em>NCA</em>,
<em>35</em>(29), 21349–21359. (<a
href="https://doi.org/10.1007/s00521-023-08215-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the improvement of network transmission level and hardware storage and computing capacity, the Internet of Things (IoT) has been rapidly developed, and its application has attracted extensive attention. As an innovative application of Internet of Things technology in the field of industrial automation production, the Industrial Internet of Things includes technologies such as edge computing, big data analysis and intelligent sensing, which greatly improves production efficiency and reduces management costs. At present, Industrial Internet of Things (IIoT) has become the key competitiveness of the country. However, the heterogeneity of equipment, the limitation of resources and the low security of data have greatly hindered the development of IIoT. Therefore, in terms of ensuring efficient energy utilization, a trusted relay routing mechanism for optimizing chain performance based on multi-attribute comprehensive evaluation for the IIoT is proposed. It is an improvement of the low-energy adaptive clustering hierarchy (LEACH) algorithm (a cluster routing protocol that is mainly used in WSN) to improve the network&#39;s data security transmission, energy efficiency and load balancing characteristics.},
  archive      = {J_NCA},
  author       = {Wang, Bingquan and Liao, Xue},
  doi          = {10.1007/s00521-023-08215-7},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21349-21359},
  shortjournal = {Neural Comput. Appl.},
  title        = {A trusted routing mechanism for multi-attribute chain energy optimization for industrial internet of things},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent trusted edge data production method for
distributed internet of things. <em>NCA</em>, <em>35</em>(29),
21333–21347. (<a
href="https://doi.org/10.1007/s00521-023-08651-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of distributed edge intelligence in the Internet of things (IoT) scenarios has resulted in massive edge devices continuously generating data, leading to great pressure on traditional centralized trustworthy processing security protection systems. With the continuous enhancement of edge device computing capabilities, it is now possible to achieve the goal of trusted decision while generating edge data. Therefore, research on intelligent trusted decision methods for data production is an urgent issue to be addressed. To tackle this problem, an edge intelligent trusted decision mechanism is designed. In our trusted decision mechanism, a unified mapping model based on multidimensional attributes of edge devices is first constructed. Based on the descriptive model, three important trusted decision components (TDCs) are included: static, dynamic, and comprehensive trusted decision component (TDC). In static TDC, unidirectional and bidirectional trusted decision functions of edge devices are defined, respectively. In dynamic TDC, dynamic direct and indirect recommendation trusted decision are included. The dynamic comprehensive trusted decision is calculated by effectively weighting them. In comprehensive TDC, a particle swarm optimization algorithm is introduced to adaptively adjust the weighting factors of static and dynamic TDC, and the comprehensive trusted decision is calculated. To verify the performance of our proposed trusted decision mechanism, three broad experiments are carried out. Static and dynamic TDCs are verified on randomly generated data sets, while comprehensive TDC is verified on a real data set. The simulation results show that our static and dynamic TDCs can timely and accurately detect malicious devices. Moreover, the comprehensive TDC based on the real data set performs well on different performance measurement indicators.},
  archive      = {J_NCA},
  author       = {Zhang, Jiangjiang and Ning, Zhenhu and Cao, Hangrui},
  doi          = {10.1007/s00521-023-08651-5},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21333-21347},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligent trusted edge data production method for distributed internet of things},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Technologies of the 4th industrial revolution with
applications. <em>NCA</em>, <em>35</em>(29), 21331–21332. (<a
href="https://doi.org/10.1007/s00521-023-08986-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Iliadis, Lazaros and Pimenidis, Elias},
  doi          = {10.1007/s00521-023-08986-z},
  journal      = {Neural Computing and Applications},
  number       = {29},
  pages        = {21331-21332},
  shortjournal = {Neural Comput. Appl.},
  title        = {Technologies of the 4th industrial revolution with applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TRF-net: A transformer-based RGB-d fusion network for
desktop object instance segmentation. <em>NCA</em>, <em>35</em>(28),
21309–21330. (<a
href="https://doi.org/10.1007/s00521-023-08886-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To perform object-specific tasks on the desktop, robots need to perceive different objects. The challenge is to calculate the pixel-wise mask for each object, even in the presence of occlusions and unseen objects. We take a step toward this problem by proposing a metric learning-based network called TRF-Net to perform desktop object instance segmentation. We design two ResNet-based branches to process the RGB and depth images separately. Then, we propose a Transformer-based fusion module called TranSE to fuse the features from both branches. This module also transfers the fused features to the decoder part, which helps generate fine-grained decoder features. After that, we propose a multi-scale feature embedding loss function called MFE loss to reduce the intra-class distance and increase the inter-class distance, which contributes to the feature clustering in embedding space. Due to the lack of large-scale real-world datasets for desktop objects, the proposed TRF-Net is trained with the synthetic dataset and tested with the small-scale real-world dataset. The target objects in the testing dataset do not present in the training dataset, ensuring the novelty of testing objects. We demonstrate that our method can produce accurate instance segmentation masks, outperforming other state-of-the-art methods on desktop object instance segmentation.},
  archive      = {J_NCA},
  author       = {Cao, He and Zhang, Yunzhou and Shan, Dexing and Liu, Xiaozheng and Zhao, Jiaqi},
  doi          = {10.1007/s00521-023-08886-2},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21309-21330},
  shortjournal = {Neural Comput. Appl.},
  title        = {TRF-net: A transformer-based RGB-D fusion network for desktop object instance segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A lightweight model using frequency, trend and temporal
attention for long sequence time-series prediction. <em>NCA</em>,
<em>35</em>(28), 21291–21307. (<a
href="https://doi.org/10.1007/s00521-023-08871-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep learning makes great success in increasing the accuracy for long sequence time-series forecasting, its complex neural network structure, which comprises many different types of layers and each layer containing hundreds and thousands of neurons, challenges the computing and memory capability of embedded platforms. This paper proposes a lightweight and efficient neural network called TTFNet, which forecasts long time series using three types of features (i.e., the Trend, Temporal attention, and Frequency attention) extracted from raw time series. In TTFNet, we perform a pooling operation on the historical data in a recent time window to extract a general trend, use a multi-layer perceptron to discover the temporal correlation between data as temporal attention, and apply the fast Fourier transforms on data to obtain frequency information as frequency attention. Each feature is separately extracted from its neural network branch with an output result, and we weight the three results to generate the final prediction while optimal weights are learnt. Also, the three prediction results can run in parallel since they are independent from one another. The experimental results show that the proposed method reduces the memory overhead and runtime by 62\% and 81\% of the five counterpart methods on average while achieving comparable performance.},
  archive      = {J_NCA},
  author       = {Chen, Lingqiang and Li, Guanghui and Huang, Guangyan and Zhao, Qinglin},
  doi          = {10.1007/s00521-023-08871-9},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21291-21307},
  shortjournal = {Neural Comput. Appl.},
  title        = {A lightweight model using frequency, trend and temporal attention for long sequence time-series prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Focus nuance and toward diversity: Exploring domain-specific
fine-grained few-shot recognition. <em>NCA</em>, <em>35</em>(28),
21275–21290. (<a
href="https://doi.org/10.1007/s00521-023-08787-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world industrial applications, learning to recognize novel visual categories from a few samples is challenging and promising. Although some efforts have been made in the academic field for few-shot classification studies, there is still a lack of high-precision fine-grained few-shot classification models in some specific fields, especially in the fine-grained agricultural field. As far as we know, this study is the first work on meta-learning few-shot classification for fine-grained plant disease classification (specific to disease severity). We propose a multi-perspective hybrid attention meta-learning model based on a Batch Nuclear-norm constraint. The model explores discriminative features by focusing on key regions, and the hybrid attention module is divided into two sub-modules, soft attention model and patch-hard attention model. The discriminability and diversity constraint module is introduced in the loss function to constrain the Batch Nuclear-norm of the classification matrix, which improves the discriminative properties of the classification model and increases its diversity at the same time. In this paper, a large number of experiments have been carried out on multiple datasets. The experimental results demonstrate that our work has better performance than state-of-the-art models. It can be said that our work is a valuable supplement to the domain-specific industrial application models.},
  archive      = {J_NCA},
  author       = {Li, Minghui and Yao, Hongxun and Wang, Yong},
  doi          = {10.1007/s00521-023-08787-4},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21275-21290},
  shortjournal = {Neural Comput. Appl.},
  title        = {Focus nuance and toward diversity: Exploring domain-specific fine-grained few-shot recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TongueMobile: Automated tongue segmentation and diagnosis on
smartphones. <em>NCA</em>, <em>35</em>(28), 21259–21274. (<a
href="https://doi.org/10.1007/s00521-023-08902-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tongue diagnosis is a useful process in traditional Chinese medicine to assess diseases non-invasively by visually inspecting the tongue and its various properties. In this study, we developed an automated tongue diagnosis system with a mobile app for the general public. The image-segmentation component extracts the tongue body image from an input photograph taken by a smartphone. The tongue-coating color classification component predicts the category of the coating color. The segmented image and diagnosis results are returned to the app and shown to the user. Experimental results show that Mask R-CNN is the optimal choice for tongue-image segmentation under various input image conditions based on the mean interaction over union value of $$91\%$$ and the Dice score of $$95\%$$ . ResNeXt outperformed other baseline tongue-coating color classification models. In addition, when the input image is adjusted with our color-correction modules in advance, the classification accuracy of ResNeXt101 is improved by approximately $$12\%$$ .},
  archive      = {J_NCA},
  author       = {Huang, Zih-Hao and Huang, Wei-Cheng and Wu, Hsien-Chang and Fang, Wen-Chieh},
  doi          = {10.1007/s00521-023-08902-5},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21259-21274},
  shortjournal = {Neural Comput. Appl.},
  title        = {TongueMobile: Automated tongue segmentation and diagnosis on smartphones},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-grained unsupervised evidence retrieval for question
answering. <em>NCA</em>, <em>35</em>(28), 21247–21257. (<a
href="https://doi.org/10.1007/s00521-023-08892-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidence retrieval is a crucial step in question answering (QA) tasks, which can filter original context to provide supporting evidence for reading comprehension and reduce the time of answer inference. Most research interests in evidence retrieval have been paid to supervised methods, while unsupervised evidence retrieval received limited attention. However, most existing works for unsupervised evidence retrieval regard sentence-level and passage-level evidence retrieval as two independent processes. In order to fuse these two levels of information, we propose an efficient and unsupervised multi-grained evidence retrieval method for QA, which considers multiple interactions, including query–sentence, query–passage, and passage–passage. Specifically, we use sentence-level retrieval to obtain an evidence framework. Then we propose a score fusion mechanism to model the unilateral guiding relationship between sentence-level and passage-level retrieval. On the basis of score fusion, we propose a gated selection mechanism to retrieve evidence passages, which can supplement reasoning information for the evidence framework. Extensive experiments on open-domain and multi-hop QA datasets show that our method has fast retrieval speed while achieving better retrieval and QA performance than baselines.},
  archive      = {J_NCA},
  author       = {You, Hao},
  doi          = {10.1007/s00521-023-08892-4},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21247-21257},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-grained unsupervised evidence retrieval for question answering},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Activity recognition in rehabilitation training based on
ensemble stochastic configuration networks. <em>NCA</em>,
<em>35</em>(28), 21229–21245. (<a
href="https://doi.org/10.1007/s00521-023-08829-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rehabilitation training for patients with limb activity dysfunction and sub-healthy state has gradually shifted from therapies to strategies with remote assistance. Stochastic configuration networks (SCNs) are characterized by a structure that varies with task complexity, making them ideal for use as the lightweight AI activity recognition model in a remote rehabilitation training system. Given an imbalanced data classification and large-scale data analytics task, the original SCN classifiers may fail to provide satisfied performance. In this paper, we propose two solution that are Bagging SCNs and Boosting SCNs for HAR based on SCNs. Bagging SCNs use the bootstrap method to generate balanced subsets to reduce the influence caused by imbalance dataset. Then, multiple SCNs models are trained in parallel, followed by the identification of the best ensemble model through validation sets. Boosting SCNs employ forward stagewise additive modeling and utilize the SAMME algorithm to minimize the multi-class exponential loss for multi-class classification. This algorithm progressively enhances the base learner’s focus on previously misclassified instances from previous rounds, ultimately lowering the misclassification rate. The activity datasets of three groups of tests are collected by using a self-built experimental platform. Our experiments compare the performance of two Ensemble SCNs with original SCNs, Convolutional Neural Networks, Long Short-Term Memory, Gradient Boosting Decision Tree(GBDT) and Support Vector Classifier. Results in the performance of two Ensemble SCNs demonstrate that our proposed algorithm has good potential to be applied for HAR algorithm.},
  archive      = {J_NCA},
  author       = {Jiao, Wenhua and Li, Ruilin and Wang, Jianguo and Wang, Dianhui and Zhang, Kuan},
  doi          = {10.1007/s00521-023-08829-x},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21229-21245},
  shortjournal = {Neural Comput. Appl.},
  title        = {Activity recognition in rehabilitation training based on ensemble stochastic configuration networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting science achievement scores with machine learning
algorithms: A case study of OECD PISA 2015–2018 data. <em>NCA</em>,
<em>35</em>(28), 21201–21228. (<a
href="https://doi.org/10.1007/s00521-023-08901-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the performance of machine learning methods was examined in terms of predicting the science education achievement scores of the students who took the exam for the next term, PISA 2018, and the science average scores of the countries, using PISA 2015 data. The research sample consists of a total of 67,329 students who took the PISA 2015 exam from 13 randomly selected countries (Brazil, Chinese Taipei, Dominican Republic, Estonia, Finland, Hungary, Italy, Japan, Lithuania, Luxembourg, Peru, Singapore, Türkiye). In this study, multiple linear regression, support vector regression, random forest, and extreme gradient boosting (XGBoost) machine learning algorithms were used. For the machine learning process, a randomly determined part from the PISA-2015 data of each country researched was divided as training data and the remaining part as testing data to evaluate model performance. As a result of the research, it was determined that the XGBoost algorithm showed the best performance in estimating both PISA-2015 test data and PISA-2018 science academic achievement scores in all researched countries. Furthermore, it was determined that the highest PISA-2018 science achievement scores of the students who participated in the exam, estimated by this algorithm, were in Luxembourg (r = 0.600, RMSE = 75.06, MAE = 59.97), while the lowest were in Finland (r = 0.467, RMSE = 79.38, MAE = 63.24). In addition, the average PISA-2018 science scores of the countries were estimated with the XGBoost algorithm, and the average science scores calculated for all the countries studied were estimated with very high accuracy.},
  archive      = {J_NCA},
  author       = {Acıslı-Celik, Sibel and Yesilkanat, Cafer Mert},
  doi          = {10.1007/s00521-023-08901-6},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21201-21228},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting science achievement scores with machine learning algorithms: A case study of OECD PISA 2015–2018 data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A correlation information-based spatiotemporal network for
traffic flow forecasting. <em>NCA</em>, <em>35</em>(28), 21181–21199.
(<a href="https://doi.org/10.1007/s00521-023-08831-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow forecasting technology plays an important role in intelligent transportation systems. Based on graph neural networks and attention mechanisms, most previous works utilize the transformer architecture to discover spatiotemporal dependencies and dynamic relationships. However, they have not thoroughly considered correlation information among spatiotemporal sequences. In this paper, based on the maximal information coefficient, we present two elaborate spatiotemporal representations, spatial correlation information (SCorr) and temporal correlation information (TCorr). Using SCorr, we propose a correlation information-based spatiotemporal network (CorrSTN) that includes a dynamic graph neural network component for integrating correlation information into spatial structure effectively and a multi-head attention component for modeling dynamic temporal dependencies accurately. Utilizing TCorr, we explore the correlation pattern among different periodic data to identify the most relevant data, and then design an efficient data selection scheme to further enhance model performance. The experimental results on the highway traffic flow (PEMS03, PEMS04, PEMS07 and PEMS08) and metro crowd flow (HZME inflow and outflow) datasets demonstrate that CorrSTN outperforms the state-of-the-art methods in terms of predictive performance. In particular, on the HZME (outflow) dataset, our model makes significant improvements compared with the ASTGNN model by 13.2\%, 15.3\% and 29.3\% in the metrics of MAE, RMSE and MAPE, respectively.},
  archive      = {J_NCA},
  author       = {Zhu, Weiguo and Sun, Yongqi and Yi, Xintong and Wang, Yan and Liu, Zhen},
  doi          = {10.1007/s00521-023-08831-3},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21181-21199},
  shortjournal = {Neural Comput. Appl.},
  title        = {A correlation information-based spatiotemporal network for traffic flow forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel error correction-based key frame extraction technique
for dynamic hand gesture recognition. <em>NCA</em>, <em>35</em>(28),
21165–21180. (<a
href="https://doi.org/10.1007/s00521-023-08774-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Before languages came into existence, sign language was the mode of communication. For human–computer interaction, recognizing these sign languages is vital; thus, hand gesture recognition comes into play. With the advancement of technology and its vast applications, hand gesture recognition has become a common field of research. Gesture recognition has gained a lot of popularity due to its application in sign language detection for speech and hearing-impaired people. This paper presents a methodology for hand gesture recognition using a 3D convolutional neural network. The dataset used for this purpose is MINDS-Libras, a Brazilian sign language dataset. We propose a novel error correction-based key frame extraction technique that selects significant key frames for video summarization. The chosen key frames are preprocessed through the steps of the region of interest selection, background removal, segmentation, binarization, and resizing. The frames are given as input to the proposed three-dimensional convolutional neural network for the classification of hand gestures, which offers an accuracy of 98\% and performs better than state-of-the-art techniques.},
  archive      = {J_NCA},
  author       = {Bharti, Snehal and Balmik, Archana and Nandy, Anup},
  doi          = {10.1007/s00521-023-08774-9},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21165-21180},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel error correction-based key frame extraction technique for dynamic hand gesture recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Curriculum learning and evolutionary optimization into deep
learning for text classification. <em>NCA</em>, <em>35</em>(28),
21129–21164. (<a
href="https://doi.org/10.1007/s00521-023-08632-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of social networks has given rise to a wide variety of content. Some social content violates the integrity and dignity of users, therefore, this task has become challenging. The need to deal with short texts, poorly written language, unbalanced classes, and non-thematic aspects. These can lead to overfitting in deep neural network (DNN) models used for classification tasks. Empirical evidence in previous studies indicates that some of these problems can be overcome by improving the optimization process of the DNN weights to avoid overfitting. Moreover, a well-defined learning process in the input examples could improve the order of the patterns learned throughout the optimization process. In this paper, we propose four Curriculum Learning strategies and a new Hybrid Genetic–Gradient Algorithm that proved to improve the performance of DNN models detecting the class of interest even in highly imbalanced datasets.},
  archive      = {J_NCA},
  author       = {Elías-Miranda, Alfredo Arturo and Vallejo-Aldana, Daniel and Sánchez-Vega, Fernando and López-Monroy, A. Pastor and Rosales-Pérez, Alejandro and Muñiz-Sanchez, Victor},
  doi          = {10.1007/s00521-023-08632-8},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21129-21164},
  shortjournal = {Neural Comput. Appl.},
  title        = {Curriculum learning and evolutionary optimization into deep learning for text classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computing brain networks with complex dynamics.
<em>NCA</em>, <em>35</em>(28), 21115–21127. (<a
href="https://doi.org/10.1007/s00521-023-08903-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interplay between neuronal network connectivity and neuron dynamics is known to drive global brain behavior; however, the exact relationship between network connectivity and node dynamics is complex and remains poorly understood. Previous theoretical and modeling work has shown that in small toy networks, when nodes are equipped with discrete quadratic dynamics, properties of the emergent behavior of the complex quadratic network (CQN) can give rise to features that relate to the underlying topology. Specifically, when the long-term behavior of CQNs is represented by asymptotic fractal sets, certain topological features of the fractal can be used to classify the network topology. However, the success of this approach has thus far not been tested on more complex real-world networks. Here, we apply a CQN modeling approach to capture individual differences in real-world brain networks derived from human connectome data. We show that CQNs are more sensitive than traditional graph theoretic measures at capturing individual differences in the topology of the human connectome, and that features of the associated equi-M sets can differentiate between male and female connectomes. This study, therefore, provides a basis upon which future work can build in order to better quantify individual differences in brain connectivity, and how these differences drive brain function and behavior.},
  archive      = {J_NCA},
  author       = {Rǎdulescu, Anca and Nakuci, Johan and Evans, Simone and Muldoon, Sarah},
  doi          = {10.1007/s00521-023-08903-4},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21115-21127},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computing brain networks with complex dynamics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BC-PINN: An adaptive physics informed neural network based
on biased multiobjective coevolutionary algorithm. <em>NCA</em>,
<em>35</em>(28), 21093–21113. (<a
href="https://doi.org/10.1007/s00521-023-08876-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics informed neural network (PINN) has become a promising method for solving partial differential equations (PDEs). The loss function of PINN is a weighted sum of multiple items. This makes it easy to fall into local optima, especially the gradient pathologies when solving high frequency problems. The value of penalty coefficients has a crucial impact on the prediction results. Therefore, a new PINN with adaptive penalty coefficients iteratively optimized by biased multiobjective coevolutionary algorithm (BC-PINN) is presented. In BC-PINN, a two-stage optimization mechanism is used to search for parameters of neural network and penalty coefficients respectively. This method involves constructing the fitness function of penalty coefficients based on the biased dominance ranking by data item and regularization item. Compared with the previous works of others, the accuracy of fitting the initial conditions and boundary conditions is considered to be given priority, which is more conducive to PINN converging to the particular solution of PDE. In addition, the set of penalty coefficients is divided into multiple populations to improve the optimization efficiency through coevolutionary algorithm. The empirical results show that: (1) Our method can improve the gradient pathologies and effectively capture the high-frequency features. (2) Compared to the original PINN, it reduces the MSE by 1–6 orders of magnitude in our benchmark functions.},
  archive      = {J_NCA},
  author       = {Zhu, Zhicheng and Hao, Jia and Huang, Jin and Huang, Biao},
  doi          = {10.1007/s00521-023-08876-4},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21093-21113},
  shortjournal = {Neural Comput. Appl.},
  title        = {BC-PINN: An adaptive physics informed neural network based on biased multiobjective coevolutionary algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structure correlation-aware attention for iris recognition.
<em>NCA</em>, <em>35</em>(28), 21071–21091. (<a
href="https://doi.org/10.1007/s00521-023-08800-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formation of a human iris is mainly determined by anatomical characteristics that are identity-related and stable for personal recognition. However, existing deep Convolutional Neural Network (ConvNet)-based iris recognition methods fail to make fully use of such anatomical structure. To address this issue, we propose a dual attention block, dubbed unified global radial and angular attention (UGRAA), which focuses on both global radial and angular correlations of iris texture by aggregating the global contexts. The UGRAA is a lightweight and architecture-agnostic module, suitable for commonly used ConvNets in an end-to-end fashion. Furthermore, for better characterizing spatial relationships between iris regions, we introduce pair-wise spatial correlations via second-order pooling. We conduct extensive experiments to evaluate the proposed network, which is called UGRAA-Net, on four challenging iris recognition benchmarks. The results verify that our UGRAA-Net consistently outperforms its counterparts, achieving state-of-the-art (SOTA) performance.},
  archive      = {J_NCA},
  author       = {Jia, Lingyao and Sun, Qiule and Li, Peihua},
  doi          = {10.1007/s00521-023-08800-w},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21071-21091},
  shortjournal = {Neural Comput. Appl.},
  title        = {Structure correlation-aware attention for iris recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Industrial few-shot fractal object detection. <em>NCA</em>,
<em>35</em>(28), 21055–21069. (<a
href="https://doi.org/10.1007/s00521-023-08889-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical industrial visual inspection tasks, foreign object data are difficult to collect and accumulate, hence few-shot object detection has gradually become the focus of research. It has been observed that industrial foreign objects are often different from natural data and are always fractal objects. Its form is a rough or fragmented geometric shape, and its features are relatively monotonous and difficult to distinguish. Optimization-based meta-learning is a powerful approach to few-shot learning. It updates model weights through a parameter optimization strategy enabling more efficient learning when faced with new tasks with few samples. Therefore, we proposed a gradient scout strategy, which used the intelligent optimization idea to optimize the meta-training outer-loop parallel gradient optimization method to improve the training effect of few-shot fractal object detection. Meanwhile, we proposed a fractal information amplified learning module, which could improve the detection ability of few-shot fractal objects more quickly under the same training period. They formed FLGS (fractal information amplified learning with gradient scout), which was deployed at zero cost. YOLOv7 was advanced to a new industrial fractal object detection model under FLGS. The experimental results on the IGBT surface foreign object dataset showed that our gradient scout strategy was superior to the other eight few-shot meta-learning algorithms. FLGS significantly accelerated the improvement of fractal object detection ability and maintained a high-level mean average precision.},
  archive      = {J_NCA},
  author       = {Huang, Haoran and Luo, Xiaochuan and Yang, Chen},
  doi          = {10.1007/s00521-023-08889-z},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21055-21069},
  shortjournal = {Neural Comput. Appl.},
  title        = {Industrial few-shot fractal object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HRI: Human reasoning inspired hand pose estimation with
shape memory update and contact-guided refinement. <em>NCA</em>,
<em>35</em>(28), 21043–21054. (<a
href="https://doi.org/10.1007/s00521-023-08884-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand pose estimation is a challenging task in hand-object interaction scenarios due to the uncertainty caused by object occlusions. Inspired by human reasoning from a hand-object interaction video sequence, we propose a hand pose estimation model. It uses three cascaded modules to imitate human’s estimation and observation process. The first module predicts an initial pose based on the visible information and the prior hand knowledge. The second module updates the hand shape memory based on the new information coming from the subsequent frames. The bone’s length updating is initiated by the predicted joint’s reliability. The third module refines the coarse pose according to the hand-object contact state represented by the object’s Signed Distance Function field. Our model gets the mean joints estimation error of 21.3 mm, the Procrustes error of 9.9 mm, and the Trans &amp;Scale error of 22.3 mm on HO3Dv2, and Root-Relative error of 12.3 mm on DexYCB which are superior to other state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Li, Xuefeng and Lin, Xiangbo},
  doi          = {10.1007/s00521-023-08884-4},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21043-21054},
  shortjournal = {Neural Comput. Appl.},
  title        = {HRI: Human reasoning inspired hand pose estimation with shape memory update and contact-guided refinement},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multistep prediction for earthworks unloading duration: A
fuzzy att-Seq2Seq network with optimal partitioning and multi-time
granularity modeling. <em>NCA</em>, <em>35</em>(28), 21023–21042. (<a
href="https://doi.org/10.1007/s00521-023-08883-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unloading activities directly impact the progress of earthmoving and filling projects, and a reliable multistep-ahead unloading duration prediction could help optimize equipment scheduling and improve operational efficiency. However, unloading prediction is greatly challenging owing to the complex uncertainties and nonlinearities implied in the unloading process, as well as the difficulty of modeling long-term temporal dependencies. Thus, this study devises a new fuzzy sequence-to-sequence network for unloading time forecasting. First, a quantization error-improved information granulation method is exploited to establish the fuzzy partition function. The global and localized distribution characteristics of unloading time are utilized to adaptively optimize the number and distribution of nonuniform fuzzy intervals. Then, periodic and recent branches were developed to model the variation of unloading time in multiple temporal granularities. In each branch, based on the encoder–decoder structure, the underlying gated recurrent units learn the sequence features collaborating with the attention mechanism to capture implicit long-term dependencies, mitigating the effects of error accumulation in multistep forecasting. Finally, the temporal information of different granularities is fused to form the final prediction. We evaluate the proposed model using an unloading dataset from a heavy infrastructure project in southwest China. We conducted geo-fencing and unloading operation analysis to extract the unloading information of different construction areas. The experimental results show that our method can generate high-quality multistep predictions for unloading duration, and exhibits superior performance compared with baseline models. The novel approach has great potential to support earthwork management in complex environments.},
  archive      = {J_NCA},
  author       = {Zhang, Yunuo and Wang, Xiaoling and Yu, Jia and Zeng, Tuocheng and Wang, Jiajun},
  doi          = {10.1007/s00521-023-08883-5},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21023-21042},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multistep prediction for earthworks unloading duration: A fuzzy att-Seq2Seq network with optimal partitioning and multi-time granularity modeling},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AGRCNet: Communicate by attentional graph relations in
multi-agent reinforcement learning for traffic signal control.
<em>NCA</em>, <em>35</em>(28), 21007–21022. (<a
href="https://doi.org/10.1007/s00521-023-08875-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic signal control (TSC) can be described as a multi-agent cooperative game. To realize cooperation, multi-agent reinforcement learning (MARL) is a significant approach, with communication being a core component. The large-scale traffic signals and the partially observable information in TSC pose a considerable challenge in finding the optimal joint control policy. This paper proposed a deep MARL model named attentional graph relations communications network (AGRCNet). Based on the Actor-Critic framework, AGRCNet designs a communication network to exchange observation information with agents to help obtain the optimal joint action, reducing the decision error caused by the partially observable condition. Specifically, through the communication network, the chain propagation of graph attention networks (GAT) and graph convolutional networks is used to expand the receptive domain of agents, improve communication efficiency and promote cooperative behavior. We simulate the traffic situation near the Nanjing Yangtze River Bridge in Simulation of Urban MObility. With a compound reward, our method performs best. Meanwhile, AGRCNet is applied to two abstract environments, and the results show that our approach can also adapt to dynamic agent relationships and is more efficient than comparison algorithms.},
  archive      = {J_NCA},
  author       = {Ma, Tinghuai and Peng, Kexing and Rong, Huan and Qian, Yurong},
  doi          = {10.1007/s00521-023-08875-5},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {21007-21022},
  shortjournal = {Neural Comput. Appl.},
  title        = {AGRCNet: Communicate by attentional graph relations in multi-agent reinforcement learning for traffic signal control},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid deep learning framework for automated visual image
classification using EEG signals. <em>NCA</em>, <em>35</em>(28),
20989–21005. (<a
href="https://doi.org/10.1007/s00521-023-08870-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the concept of reading people&#39;s minds while performing specific tasks has grown in popularity, especially in the field of brain–computer interface systems. The goal of this research is to offer a new comprehensive framework for visual image classification utilizing EEG signals. Here, LSTM network is chosen to extract the feature of the EEG signal. To improve the classification accuracy in comparison to recent works in this field, a ResNet is used to extract the feature from the images, and a fuzzy regression is used to map the features extracted from the images on the features extracted from the EEG signal. Because medical data usually have uncertainty and ambiguity, and the number of data samples is small, in this research, interval type-2 fuzzy regression is used. This study makes use of data from Stanford University. Classification accuracy, precision, recall, and F1 score are the measures used to evaluate outcomes. In this case, the LSTM network is able to classify images based on EEG signals with 55.55\% accuracy and 55.73\% precision. The findings of utilizing ResNet and interval type-2 fuzzy regression suggest that regression can significantly enhance classification accuracy. Classification accuracy and precision obtained with interval type-2 fuzzy regression and SVM classifier are 66.67\% and 66.66\%, respectively, for all participants. These results outperform classification accuracy and precision obtained using type-1 fuzzy, neural network and polynomial regression. In addition, the mean accuracy for all participants obtained in this article is 4.09\% greater than the best result reported in a previous article using the same database. This leads to the conclusion that fuzzy regression, especially interval type-2 fuzzy regression, performs better in high uncertainty environments. Therefore, it is concluded that the method proposed in this research can be used for decoding brain response to visual image stimuli and classifying the stimulus images with acceptable accuracy, thereby advancing the goal of mind reading.},
  archive      = {J_NCA},
  author       = {Ahmadieh, Hajar and Gassemi, Farnaz and Moradi, Mohammad Hasan},
  doi          = {10.1007/s00521-023-08870-w},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20989-21005},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid deep learning framework for automated visual image classification using EEG signals},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered finite-time attitude consensus control of
multiple rigid-body systems based on distributed observers.
<em>NCA</em>, <em>35</em>(28), 20977–20988. (<a
href="https://doi.org/10.1007/s00521-023-08880-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of leader-following attitude consensus for multiple rigid-body systems is addressed for communication limitation in this paper. The leader and followers are described in unit quaternions forms. For each follower, a nonlinear finite-time distributed observer is proposed to estimate the states of the leader, and the event-triggered finite-time sliding mode controllers are constructed by using the estimation information to decrease the system’s communication and computation consumption. The result demonstrates that in a finite time, the attitude tracking error can converge to an invariant set, and the communication interaction is decreased by the proposed event-triggered-based controller. Moreover, Zeno behavior is rigorously proved to be excluded, and the lower bound of the triggered time interval is provided. Finally, a numerical simulation is provided to validate the efficiency of the proposed control protocol.},
  archive      = {J_NCA},
  author       = {Zhou, Hongtao and Sun, Kangting and Su, Housheng},
  doi          = {10.1007/s00521-023-08880-8},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20977-20988},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-triggered finite-time attitude consensus control of multiple rigid-body systems based on distributed observers},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classifier selection using geometry preserving feature.
<em>NCA</em>, <em>35</em>(28), 20955–20976. (<a
href="https://doi.org/10.1007/s00521-023-08828-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of proper classifiers for a given data set is full of challenges. The critical problem of classifier selection is how to extract feature from data sets. This paper proposes a new method for feature extraction of a data set. Our method not only preserves the geometrical structure of a data set, but also characterizes the decision boundary of classification problems. Specifically speaking, the extracted feature can recover a data set that has the same Euclidean geometrical structure as the original data set. We present an efficient algorithm to compute the similarity between data set features. We theoretically analyze how the similarity between our features affects the performance of the support vector machine, a well-known classifier. The empirical results show that our method is effective in finding suitable classifiers.},
  archive      = {J_NCA},
  author       = {Pan, Binbin and Chen, Wen-Sheng and Deng, Liping and Xu, Chen and Zhou, Xiaobo},
  doi          = {10.1007/s00521-023-08828-y},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20955-20976},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classifier selection using geometry preserving feature},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved fire detection approach based on YOLO-v8 for
smart cities. <em>NCA</em>, <em>35</em>(28), 20939–20954. (<a
href="https://doi.org/10.1007/s00521-023-08809-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fires in smart cities can have devastating consequences, causing damage to property, and endangering the lives of citizens. Traditional fire detection methods have limitations in terms of accuracy and speed, making it challenging to detect fires in real time. This paper proposes an improved fire detection approach for smart cities based on the YOLOv8 algorithm, called the smart fire detection system (SFDS), which leverages the strengths of deep learning to detect fire-specific features in real time. The SFDS approach has the potential to improve the accuracy of fire detection, reduce false alarms, and be cost-effective compared to traditional fire detection methods. It can also be extended to detect other objects of interest in smart cities, such as gas leaks or flooding. The proposed framework for a smart city consists of four primary layers: (i) Application layer, (ii) Fog layer, (iii) Cloud layer, and (iv) IoT layer. The proposed algorithm utilizes Fog and Cloud computing, along with the IoT layer, to collect and process data in real time, enabling faster response times and reducing the risk of damage to property and human life. The SFDS achieved state-of-the-art performance in terms of both precision and recall, with a high precision rate of 97.1\% for all classes. The proposed approach has several potential applications, including fire safety management in public areas, forest fire monitoring, and intelligent security systems.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and ZainEldin, Hanaa},
  doi          = {10.1007/s00521-023-08809-1},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20939-20954},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved fire detection approach based on YOLO-v8 for smart cities},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Experimental investigations ANN and GEP modeling of failure
load for AA7075-T6/CFRP adhesive bond. <em>NCA</em>, <em>35</em>(28),
20923–20938. (<a
href="https://doi.org/10.1007/s00521-023-08796-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that bond strength is affected by the application conditions and methods of adhesive connections. Knowing which method can increase the joint strength more and choosing those methods is important in terms of preventing time loss and financial losses. This study aims to experimentally examine the effects of aluminum alloy and carbon fiber reinforced polymer (CFRP) composite panels on the mechanical properties of adhesive thickness, different temperatures, pressure and filler in adhesive joints and model data. Experiments were carried out by using AA7075-T6/CFRP panels with single lap joint bonding joints, unfilled, 1\% and 2\% by weight carbon fiber filled, at 19, 50 and 100 °C and also by pressing under 2 MPa pressure without applying pressure. It is understood from the results that the parameters that affect the bond strength the most are the adhesive thickness and the amount of pressing applied on it. The effect of the experiments carried out under these conditions on the tensile failure load values was examined, and also artificial neural network (ANN) and gene expression programming (GEP) models were presented for failure load estimation. The R2 values of the ANN model are 0.9456. The R2 values of the GEP model are 0.9029–0.9572 for training and validation, respectively. High accuracy rates were obtained with both models. It is seen that there is a good agreement between the observed and predicted values in the errors of the training and validation sets. As a result, it was concluded that ANN and GEP models can be used to select the optimum value in similar applications.},
  archive      = {J_NCA},
  author       = {Hamamci, Benek},
  doi          = {10.1007/s00521-023-08796-3},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20923-20938},
  shortjournal = {Neural Comput. Appl.},
  title        = {Experimental investigations ANN and GEP modeling of failure load for AA7075-T6/CFRP adhesive bond},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive one-stage generative adversarial network for
unpaired image super-resolution. <em>NCA</em>, <em>35</em>(28),
20909–20922. (<a
href="https://doi.org/10.1007/s00521-023-08888-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep learning-based image super-resolution (SR) algorithms have made great achievements on synthetic LR–HR pairs in a fully supervised manner. However, the real image degradation process is complicated and unclear, leading to a domain gap between the synthetic LR images and real LR images. To address this issue, the most widely used alternatives are GAN-based methods trained with unpaired data. But most GAN-based methods tend to follow complex multi-stage pipelines and still suffer from the vast cost of hyperparameter tuning on the loss function. In this paper, in contrast to complicated two-stage or multi-stage GAN, a straightforward and simple one-stage GAN-based framework is proposed. Different from the current one-stage GAN, our approach exclusively fits the CycleGAN pattern without any other restrictions, fully leveraging images from unpaired datasets. Specifically, our framework consists of a DegradeNet and an SRNet, which implicitly models the degradation and SR process between the source LR domain and target HR domain. Such a simple one-stage GAN allows us to flexibly learn the data distribution without any assumptions, greatly reducing the model complexity and training difficulty. To further address the inherent practice of empirically setting hyperparameters in previous methods, we propose an adaptive weighting network to automatically learn the contribution weights of different losses in a meta-learning manner. This flexible strategy could shorten the gap between various losses and meanwhile help the model to adaptively optimize in an efficient way. Extensive experiments demonstrate the superiority of our proposed method in terms of indicators and perceptual quality.},
  archive      = {J_NCA},
  author       = {Shao, Mingwen and Liu, Huan and Yang, Jianxin and Cao, Feilong},
  doi          = {10.1007/s00521-023-08888-0},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20909-20922},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive one-stage generative adversarial network for unpaired image super-resolution},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Indian sign language recognition system using network
deconvolution and spatial transformer network. <em>NCA</em>,
<em>35</em>(28), 20889–20907. (<a
href="https://doi.org/10.1007/s00521-023-08860-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sign language recognition system can be applied to reduce a communication gap between deaf and normal persons. However, the Indian sign language recognition (ISL) systems are in the developing stage. Most of the recent ISL recognition systems use convolutional neural networks (CNNs) where applied convolution operation shifts a kernel to overlapping portions over the image. However, these kernels may learn redundant data since real-world images have very high correlations. The training process of neural networks is challenging for redundant image data. To overcome this limitation, an ISL recognition system has been proposed in this paper that uses the network deconvolution technique. This technique reduces not only pixel-wise correlation but also a channel-wise correlation in images. The proposed model is also augmented with a spatial transformer network to increase spatial invariance of convolution operations against spatial transformations. The proposed recognizer offers better accuracy most of the time than other experimented systems on two ISL datasets VUCS_ISL_I and created VUCS_ISL_II and standard datasets of other sign languages, i.e., American sign language, Arabic sign language, Spanish sign language.},
  archive      = {J_NCA},
  author       = {Ghorai, Anudyuti and Nandi, Utpal and Changdar, Chiranjit and Si, Tapas and Singh, Moirangthem Marjit and Mondal, Jyotsna Kumar},
  doi          = {10.1007/s00521-023-08860-y},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20889-20907},
  shortjournal = {Neural Comput. Appl.},
  title        = {Indian sign language recognition system using network deconvolution and spatial transformer network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Depth-guided deep filtering network for efficient single
image bokeh rendering. <em>NCA</em>, <em>35</em>(28), 20869–20887. (<a
href="https://doi.org/10.1007/s00521-023-08852-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bokeh effect is usually used to highlight major contents in an image. Limited by the small sensors, cameras on smartphones are less sensitive to the depth information and cannot directly produce bokeh effect as pleasant as digital single lens reflex cameras. To address this problem, a depth-guided deep filtering network, called DDFN, is proposed in this study. Specifically, the focused region detection block is designed to detect the salient areas, and the depth estimated block is introduced to estimate depth maps from full-focus images. Further, combining depth maps and focused features, an adaptive rendering block is proposed to synthesize bokeh effect with adaptive cross 1-D filters. Both quantitative and qualitative evaluations on the public datasets demonstrate that the proposed model performs favorably against state-of-the-art methods in terms of rendering effects and has lower computational cost, e.g., 24.07 dB PSNR on EBB! dataset and 0.45 s inference times for a $$512 \times 768$$ image on a Snapdragon 865 mobile processor.},
  archive      = {J_NCA},
  author       = {Chen, Quan and Zheng, Bolun and Zhou, Xiaofei and Huang, Aiai and Sun, Yaoqi and Chen, Chuqiao and Yan, Chenggang and Yuan, Shanxin},
  doi          = {10.1007/s00521-023-08852-y},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20869-20887},
  shortjournal = {Neural Comput. Appl.},
  title        = {Depth-guided deep filtering network for efficient single image bokeh rendering},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpreting open-domain dialogue generation by
disentangling latent feature representations. <em>NCA</em>,
<em>35</em>(28), 20855–20867. (<a
href="https://doi.org/10.1007/s00521-023-08815-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently end-to-end deep learning based open-domain dialogue systems remain black box models, making it easy to generate irrelevant contents with data-driven models. Specifically, latent variables are highly entangled with different semantics in the latent space due to the lack of priori knowledge to guide the training. To address this problem, this paper proposes to harness the generative model with a priori knowledge through a cognitive approach involving feature disentanglement. Particularly, the model integrates the guided-category knowledge and open-domain dialogue data for the training, leveraging the priori knowledge into the latent space, which enables the model to disentangle the latent variables. Besides, this paper proposes a new metric for open-domain dialogues, which can objectively evaluate the interpretability of the latent space distribution. Finally, this paper validates our model on different datasets and experimentally demonstrate that our model is able to generate higher quality and more interpretable dialogues than other models.},
  archive      = {J_NCA},
  author       = {Wang, Ye and Liao, Jingbo and Yu, Hong and Wang, Guoyin and Zhang, Xiaoxia and Liu, Li},
  doi          = {10.1007/s00521-023-08815-3},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20855-20867},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interpreting open-domain dialogue generation by disentangling latent feature representations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive finite-time neurodynamic approach to distributed
consensus-based optimization problem. <em>NCA</em>, <em>35</em>(28),
20841–20853. (<a
href="https://doi.org/10.1007/s00521-023-08794-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel distributed adaptive neurodynamic approach (DANA) based on proportional integral technique is proposed to solve distributed optimization problem on multi-agent systems. The goal is that all agents reach consensus in finite time and converge to the optimal solution of the global objective function in fixed time. In the proposed approach, the proportional technique drives all agents to reach consensus, and the integral technique is used to offset the influence of the gradient term of the objective function. On the other hand, in order to avoid the prior estimation of gain parameter and the global gradient information, as the main contribution of this paper, the adaptive idea is considered into proportional integral technique. The results show that the adaptive integral technique can automatically adjust the gain according to the maximum consensus error between agents, so as to ensure that agents can achieve consensus in finite time. Then the theoretical results are applied to voltage distribution and logistic regression. Numerical simulation verifies the effectiveness of DANA.},
  archive      = {J_NCA},
  author       = {Li, Qingfa and Wang, Mengxin and Sun, Haowen and Qin, Sitian},
  doi          = {10.1007/s00521-023-08794-5},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20841-20853},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive finite-time neurodynamic approach to distributed consensus-based optimization problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lagging problem in financial time series forecasting.
<em>NCA</em>, <em>35</em>(28), 20819–20839. (<a
href="https://doi.org/10.1007/s00521-023-08879-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate financial time series forecasting is important in financial markets. However, for financial time series with low fluctuation, there is an unusual forecasting phenomenon in the popular recurrent network model forecasting, with the predictive value lagging the truth value. We call this phenomenon the lagging problem. This study proposes new evaluation measures for assessing the lagging problem, including lagging relative error, lagging value error, and lagging trend error. Moreover, the state analysis method and linear fitting model are developed to explain the causes of the lagging problem. Experimental results show that all popular recurrent network models adopted suffer from the lagging problem. This problem is caused by the failure of the nonlinear function in the prediction model and the linear degeneration of the prediction model thereafter, resulting in the suppression of the nonlinear fitting ability.},
  archive      = {J_NCA},
  author       = {Li, Jincheng and Song, Liangtu and Wu, Di and Shui, Jiahao and Wang, Tao},
  doi          = {10.1007/s00521-023-08879-1},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20819-20839},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lagging problem in financial time series forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An approach for total organic carbon prediction using
convolutional neural networks optimized by differential evolution.
<em>NCA</em>, <em>35</em>(28), 20803–20817. (<a
href="https://doi.org/10.1007/s00521-023-08865-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most reliable indicators of the amount and condition of organic matter in a basin is the total organic carbon (TOC) content of rock samples. The manual estimation primarily involves inspecting rock samples for organic carbon analysis. However, this method is costly and time-consuming due to the necessity of collecting samples from a wide range of well intervals within the source rocks. Consequently, studies have been conducted to facilitate this process. Emerging alternative methods for estimating TOC involve utilizing well logs and stratigraphic analysis data in conjunction with machine learning (ML) algorithms. Recent studies advocate for the application of ML algorithms in estimating TOC. The model parameters were selected using a metaheuristics approach and cross-validation to enhance the model’s flexibility. This computational technique enables the identification of models with greater generalization potential. Convolutional neural networks (CNNs), extreme learning machines, Elastic Net, and Extreme Gradient Boosting (XGB) were employed for the estimation of TOC. The suggested data intelligent framework was validated using samples from various sedimentary basins. In several metrics investigations, the CNN model exhibits notable distinctions against the other models, highlighting its potential to assist geologists in predicting concentrations of total organic carbon.},
  archive      = {J_NCA},
  author       = {Silva, Rodrigo Oliveira and Saporetti, Camila Martins and Yaseen, Zaher Mundher and Pereira, Egberto and Goliatt, Leonardo},
  doi          = {10.1007/s00521-023-08865-7},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20803-20817},
  shortjournal = {Neural Comput. Appl.},
  title        = {An approach for total organic carbon prediction using convolutional neural networks optimized by differential evolution},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guided golden jackal optimization using elite-opposition
strategy for efficient design of multi-objective engineering problems.
<em>NCA</em>, <em>35</em>(28), 20771–20802. (<a
href="https://doi.org/10.1007/s00521-023-08850-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization (MOO) issues that are encountered in the realm of real engineering applications are characterized by the curse of economically or computationally expensive objectives, which can strike insufficient performance evaluations for optimization methods to converge to Pareto optimal front (POF). To address these concerns, this paper develops a guided multi-objective golden jackal optimization (MOGJO) to promote the coverage and convergence capabilities toward the true POF while solving MOO issues. MOGJO embeds four reproduction stages during the seeking process. Firstly, the population of golden jackals is initialized according to the operational search space and then the updating process is performed. Secondly, an opposition-based learning scheme is adopted to improve the coverage of the Pareto optimal solutions. Thirdly, an elite-based guiding strategy is incorporated to guide the leader golden jackal toward the promising areas within the search space and then promote the convergence propensity. Finally, the crowding distance is also integrated to provide a better compromise among the diversity and convergence of the searched POF. To evaluate the MOGJO’s performance, it is analyzed against sixteen frequently utilized unconstrained MOO issues, five complex constrained problems, four constrained engineering designs, and real dynamic economic-emission power dispatch (DEEPD) problem. The experimental results are performed using the generational distance (GD), hypervolume (HV), spacing (SP) metrics to validate the efficacy of the proposed methods, which affirms the progressive and competitive performance compared to thirteen state-of-the-art methods. Finally, the results of the Wilcoxon rank sum test with reference to GD and HV exhibited that the proposed algorithm is significantly better than the compared methods, with a 95\% significance level. Furthermore, the results of the nonparametric Friedman test were performed to detect the significant of average ranking among the compared algorithm, where the results confirmed that the proposed MOGJO outperforms the best algorithm among thirteen state-of-the-art algorithms by an average rank of Friedman test greater than 41\% while outperforming the worst one, MOALO, by 84\% for ZDT and DTLZ1 suits. Additionally, the proposed algorithm saved the overall energy cost and total emission of the DEEPD problem by 1.89\%, and 1.48\%, respectively, compared with the best existing results and thus, it is commended to adopt for new applications.},
  archive      = {J_NCA},
  author       = {Snášel, Václav and Rizk-Allah, Rizk M. and Hassanien, Aboul Ella},
  doi          = {10.1007/s00521-023-08850-0},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20771-20802},
  shortjournal = {Neural Comput. Appl.},
  title        = {Guided golden jackal optimization using elite-opposition strategy for efficient design of multi-objective engineering problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved weighted mean of vectors algorithm for microgrid
energy management considering demand response. <em>NCA</em>,
<em>35</em>(28), 20749–20770. (<a
href="https://doi.org/10.1007/s00521-023-08813-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of demand response programs (DRPs) into the energy management (EM) system of microgrids (MGs) helps in improving the load characteristics by allowing consumers to interoperate for achieving techno-economic advantages. In this paper, an improved algorithm is called LINFO is proposed for modifying search ability of the original weIghted meaN oF vectOrs (INFO) algorithm as well as avoiding its weaknesses like trapping in a local optima. The improved algorithm&#39;s efficiency is confirmed by comparing its results with those obtained by the original INFO and other optimization techniques using different standard benchmark test functions. Moreover, this improved algorithm and the original version are applied for solving the EM problem with the aim of optimizing the operation cost of the MGs in the presence DRPs. They are used to solve day-ahead EM problem for optimal operation of renewable energy resources, the optimal generation from a conventional diesel engines (DEs); taking into account the participation of customers in DRP for minimizing MG operating cost, which includes the cost of DEs fuel and the power transactions cost with the main grid. To demonstrate the efficacy of the proposed LINFO, simulation results are compared with the results of well-known and newly developed optimization techniques.},
  archive      = {J_NCA},
  author       = {Alamir, Nehmedo and Kamel, Salah and Hassan, Mohamed H. and Abdelkader, Sobhy M.},
  doi          = {10.1007/s00521-023-08813-5},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20749-20770},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved weighted mean of vectors algorithm for microgrid energy management considering demand response},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Narrowing the language gap: Domain adaptation guided
cross-lingual passage re-ranking. <em>NCA</em>, <em>35</em>(28),
20735–20748. (<a
href="https://doi.org/10.1007/s00521-023-08803-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a given query, the objective of Cross-lingual Passage Re-ranking (XPR) is to rank a list of candidate passages in multiple languages, where only a portion of the passages are in the query’s language. Multilingual BERT (mBERT) is often used for the XPR task and achieves impressive performance. Nevertheless, there still exist two essential issues to be addressed in mBERT, including the performance gap between high- and low-resource languages, and the lack of explicit embedding distribution alignment. Regarding each language as a separated domain, we theoretically explore how these problems lead to errors in XPR under the guidance of domain adaptation. Based on the theoretical analysis, we propose a novel framework that comprises two modules, namely knowledge distillation and adversarial learning. The former enables the knowledge to be transferred from high-resource languages to low-resource ones, narrowing their performance gap. The latter encourages mBERT to align the embedding distributions across different languages by utilizing a novel language-distinguish task and adversarial training. Extensive experiments on in-domain and out-domain datasets confirm the effectiveness and robustness of the proposed framework and show that it can outperform state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Chen, Dongmei and Zhang, Xin and Zhang, Sheng},
  doi          = {10.1007/s00521-023-08803-7},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20735-20748},
  shortjournal = {Neural Comput. Appl.},
  title        = {Narrowing the language gap: Domain adaptation guided cross-lingual passage re-ranking},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online diagnosis of COVID-19 from chest radiography images
by using deep learning algorithms. <em>NCA</em>, <em>35</em>(28),
20717–20734. (<a
href="https://doi.org/10.1007/s00521-023-08867-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 outbreak, which has a devastating impact on the health and well-being of the global population, is a respiratory disease. It is vital to determine, isolate and treat people with the disease as soon as possible to fight against the COVID-19 pandemic. Even though the reverse transcription polymerase chain reaction (RT-PCR) test, the accuracy of which is about 63\%, seems to be a good option for determining COVID-19, it is a disadvantage is that test kits are few, are difficult to obtain in remote rural areas and have low accuracy. Chest X-ray (CXR) has become essential for rapidly diagnosing the rapidly spreading COVID-19 disease worldwide, so it is urgent to develop an online system that will help specialists identify infected patients with CXR images. In this study developed a transfer learning-based diagnosis system for online diagnosis of COVID-19 patients using CXR images. Transfer learning-based deep learning models VGG16, VGG19, ResNet50, InceptionV3, Xception, MobileNet, DenseNet121 and DenseNet201 were used for the experimental studies. We explored the COVID-19 radiography database from Kaggle, which is open to the public, using image preprocessing techniques and data augmentation. The images captured by the various terminals are transferred to the web server in the created system. Similar to the ensemble learning approach, the percentage accuracy of the model with the highest prediction value among the eight deep learning models is displayed on the screen. The results show that the proposed online diagnosis system performs better than others with the highest accuracy, precision, recall and F1 values of 98\%, 99\%, 97\% and 97\%, respectively. The results show that deep learning models help to increase the efficiency of chest radiograph scanning and have promising potential in predicting COVID-19 cases. The online diagnostic system will be a helpful tool for radiologists as it diagnoses COVID-19 quickly and with high accuracy.},
  archive      = {J_NCA},
  author       = {Budak, Cafer and Mençik, Vasfiye and Varışlı, Osman},
  doi          = {10.1007/s00521-023-08867-5},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20717-20734},
  shortjournal = {Neural Comput. Appl.},
  title        = {Online diagnosis of COVID-19 from chest radiography images by using deep learning algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Face photo-sketch recognition based on multi-directional
line features projection. <em>NCA</em>, <em>35</em>(28), 20697–20715.
(<a href="https://doi.org/10.1007/s00521-023-08801-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face photo-sketch recognition plays an important role in law enforcement, particularly in narrowing down the search for potential suspects based on limited sketch information. However, the issues of large modality gap and having a relatively small number of sketch samples for training remained a challenging task. In this paper, we propose a novel feature descriptor network for automated face photo-sketch recognition that is suitable for modality discrepancy and small dataset learning. By stacking a multi-directional image difference operation over a pooling projection in a multilayer fashion, our proposal forms an interpretable learning system that does not show obvious overfitting on limited training data. Extensive evaluation using three public face photo-sketch databases shows competing rank-1 recognition accuracy of the proposed method comparing with state-of-the-art methods. In terms of average ranking on the three experimented databases, the proposed method has the top average rank of 2 among 17 algorithms with the runner-up LFDA algorithm having an average rank of 2.83.},
  archive      = {J_NCA},
  author       = {Kim, Jooyoung and Lin, Zhiping and Kim, Donghyun and Toh, Kar-Ann},
  doi          = {10.1007/s00521-023-08801-9},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20697-20715},
  shortjournal = {Neural Comput. Appl.},
  title        = {Face photo-sketch recognition based on multi-directional line features projection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSGAN: Multi-stage generative adversarial network-based data
recovery in cyber-attacks. <em>NCA</em>, <em>35</em>(28), 20675–20695.
(<a href="https://doi.org/10.1007/s00521-023-08791-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an industrial control system, a programmable logic controller (PLC) plays a vital role in maintaining the stable operation of the system. Cyber-attacks can affect the regular operation by tampering with the data stored in the PLC, thereby damaging to the system. Thus, it is particularly important to develop an efficient cyber-attacks recovery method. However, owing to the impact of unknown factors in theoretical methods, poor scalability of automaton theory, and a lack of constraints during the training process of deep learning network models, the restoration accuracy and stability are low. Therefore, it is a significant challenge to design an appropriate method to improve the accuracy and stability of cyber-attacks recovery. In this study, the generative adversarial networks were applied to the problem of cyber-attacks recovery; furthermore, a multi-stage generative adversarial networks was designed. The model consisted of a Variational Autoencoder and two conditional energy-based generative adversarial networks (CEBGANs). Then the second CEBGAN uses the fitted random noise appending with the data generated by the previous stage and the historical data as additional information to obtain the restoration results. Moreover, a self-adaptive decision policy was established to enhance the restoration accuracy and stability. Experimental results demonstrated that the proposed method in this manuscript could effectively improve the accuracy of cyber-attacks data recovery and reduce the possibility of outliers in data recovery.},
  archive      = {J_NCA},
  author       = {Tian, Bitao and Lai, Yingxu and Sun, Motong and Wang, Yipeng and Liu, Jing},
  doi          = {10.1007/s00521-023-08791-8},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20675-20695},
  shortjournal = {Neural Comput. Appl.},
  title        = {MSGAN: Multi-stage generative adversarial network-based data recovery in cyber-attacks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph neural networks for deep portfolio optimization.
<em>NCA</em>, <em>35</em>(28), 20663–20674. (<a
href="https://doi.org/10.1007/s00521-023-08862-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is extensive literature dating back to the Markowitz model on portfolio optimization. Recently, with the introduction of deep models in finance, there has been a shift in the trend of portfolio optimization toward data-driven models, departing from the traditional model-based approaches. However, deep portfolio models often encounter issues due to the non-stationary nature of data, giving unstable results. To address this issue, we advocate the utilization of graph neural networks to incorporate graphical knowledge and enhance model stability, thereby improving results in comparison with state-of-the-art recurrent architectures. Moreover, we conduct an analysis of the algorithmic risk-return trade-off for deep portfolio optimization models, offering insights into risk for fully data-driven models.},
  archive      = {J_NCA},
  author       = {Ekmekcioğlu, Ömer and Pınar, Mustafa Ç.},
  doi          = {10.1007/s00521-023-08862-w},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20663-20674},
  shortjournal = {Neural Comput. Appl.},
  title        = {Graph neural networks for deep portfolio optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An advanced diagnostic ColoRectalCADx utilises CNN and
unsupervised visual explanations to discover malignancies. <em>NCA</em>,
<em>35</em>(28), 20631–20662. (<a
href="https://doi.org/10.1007/s00521-023-08859-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer (CRC) is one of the most lethal kinds of cancer, so early detection is critical. Three datasets, namely CNN transfer learning with discrete wavelet transform (DWT), discrete cosine transform (DCT), and support vector machines (SVMs), were used to find CRC. In these instances, a quick and precise visual diagnosis of polyps is needed in the current scenario. The proposed process involves four distinct phases. First and foremost, convolutional neural networks (CNNs) are developed to test the efficacy of the model. Further, a transfer learning approach was incorporated using SVM and LSTM. Using the K-means technique, a visual explanation is finally presented. This system works with the balanced Hyper Kvasir and mixed datasets, which are made up of CVC Clinic DB, Kvasir2, and Hyper Kvasir. The system is called &quot;ColoRectalCADx&quot;. The convolutional neural network (CNN) models are ResNet-50V2, DenseNet-201, VGG-16, and RDV-22. The system achieved the highest accuracy with CNN DesnseNet-201 in Hyper Kvasir (98.92\% training, 98.91\% testing, 93.62\% SVM training, and 95.87\% SVM tests). CNN DenseNet-201 also achieved the highest accuracy with the mixed dataset (98.91\% training, 96.13\% testing, 95.41\% SVM training, and 94.86\% SVM testing). The process involved three phases, namely individual CNN, combination of CNN with SVM, and combination of CNN, LSTM, and SVM. After three phases of the system, across both datasets, the CNN + SVM + LSTM combination was proven to be the most effective. Finally, the unsupervised K-means learning algorithm extracts the location of any cancerous polyps and upon classification using SVM classifier resulted with an accuracy of 80\%. The K-means algorithm, which uses segmented images as input, accurately predicts the sites of tumours in colorectal cancer patients.},
  archive      = {J_NCA},
  author       = {Raju, Akella S. Narasimha and Jayavel, Kayalvizhi and Rajalakshmi, T.},
  doi          = {10.1007/s00521-023-08859-5},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20631-20662},
  shortjournal = {Neural Comput. Appl.},
  title        = {An advanced diagnostic ColoRectalCADx utilises CNN and unsupervised visual explanations to discover malignancies},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning approach to text-based personality
prediction using multiple data sources mapping. <em>NCA</em>,
<em>35</em>(28), 20619–20630. (<a
href="https://doi.org/10.1007/s00521-023-08846-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated personality traits prediction from widely available social media text data, is finding its increased applications in recommender systems, psychology, forecasting, and decision making. The aim of this research is to break the digital text data into features, analyse and map it to an appropriate personality model. Because of its simplicity and shown competence, a well-known personality model known as the Big Five personality characteristics has frequently been welcomed in the literature as the norm for personality evaluation. Recent advances in automated personality detection have focused on including sentiments, emotions, linguistic styles, and other natural language processing techniques. All these approaches are proposed by a fact concerned with the limited amount of data available for processing by deep learning algorithms. Personality datasets with conventional personality labels are few, and collecting them is challenging due to privacy concerns, as well as the high expense of hiring expert psychologists to label them. The performance of the model can even be increased if a large amount of labelled data is available. This research proposes a new personality prediction model using data source mapping and data fusion techniques. The results are evident that the proposed methodology has outperformed the existing methodologies. To be more precise, the results had the highest accuracy of 87.89\% and 0.924 F1 measure score after mapping MBTI into Big Five personality traits and later, fusion with Essays and myPersonality datasets.},
  archive      = {J_NCA},
  author       = {Sirasapalli, Joshua Johnson and Malla, Ramakrishna Murty},
  doi          = {10.1007/s00521-023-08846-w},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20619-20630},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning approach to text-based personality prediction using multiple data sources mapping},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A CNN-LSTM hybrid network for automatic seizure detection in
EEG signals. <em>NCA</em>, <em>35</em>(28), 20605–20617. (<a
href="https://doi.org/10.1007/s00521-023-08832-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a chronic neurological disorder. Epileptics are prone to sudden seizures that cause disruptions in their daily lives. The separation of epileptic and non-epileptic activity on the electroencephalogram (EEG) and identification of the form of epileptic activity play critical roles in providing patients with appropriate treatment. To recognize epileptic seizures, medical experts visually inspect recordings of EEG signals, which require much time and effort. Therefore, a seizure detection system can improve the monitoring and diagnosis of epilepsy and reduce the doctors&#39; workload. This paper presents an end-to-end automated seizure detection method based on deep learning that does not require considerable EEG data preprocessing or feature extraction. As a result presents a one-dimensional convolutional neural network-long short-term memory (1D-CNN-LSTM) model for differentiating normal, ictal, and interictal EEG data. This method is evaluated using the University of Bonn (BoU) and Neurology and Sleep Centre database (NSC). We achieved accuracy values of 99–100\% for the BoU dataset and 100\% for the NSC dataset with our best model. In contrast with recent studies, our hybrid automated approach does not require any pre-selected features to be estimated and shows high performance with promising possibilities for their use in clinical practice.},
  archive      = {J_NCA},
  author       = {Shanmugam, Shalini and Dharmar, Selvathi},
  doi          = {10.1007/s00521-023-08832-2},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20605-20617},
  shortjournal = {Neural Comput. Appl.},
  title        = {A CNN-LSTM hybrid network for automatic seizure detection in EEG signals},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Repformer: A robust shared-encoder dual-pipeline transformer
for visual tracking. <em>NCA</em>, <em>35</em>(28), 20581–20603. (<a
href="https://doi.org/10.1007/s00521-023-08824-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Siamese-based trackers have achieved outstanding tracking performance. However, these trackers in complex scenarios struggle to adequately integrate the valuable target feature information, which results in poor tracking performance. In this paper, a novel shared-encoder dual-pipeline Transformer architecture is proposed to achieve robust visual tracking. The proposed method integrates several main components based on a hybrid attention mechanism, namely the shared encoder, the feature enhancement pipelines with functional complementarity, and the pipeline feature fusion head. The shared encoder is adopted to process template features and provide useful target feature information for the feature enhancement pipeline. The feature enhancement pipeline is responsible for enhancing feature information, establishing feature dependencies between the template and the search region, and employing global information adequately. To further correlate the global information, the pipeline feature fusion head integrates the feature information from the feature enhancement pipelines. Eventually, we propose a robust Siamese-based Repformer tracker, which incorporates a concise tracking prediction network to obtain efficient tracking representations. Experiments show that our tracking method surpasses numerous state-of-the-art trackers on multiple tracking benchmarks, with a running speed of 57.3 fps.},
  archive      = {J_NCA},
  author       = {Gu, Fengwei and Lu, Jun and Cai, Chengtao and Zhu, Qidan and Ju, Zhaojie},
  doi          = {10.1007/s00521-023-08824-2},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20581-20603},
  shortjournal = {Neural Comput. Appl.},
  title        = {Repformer: A robust shared-encoder dual-pipeline transformer for visual tracking},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The use of generative adversarial networks for multi-site
one-class follicular lymphoma classification. <em>NCA</em>,
<em>35</em>(28), 20569–20579. (<a
href="https://doi.org/10.1007/s00521-023-08810-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in digital technologies have lowered the costs and improved the quality of digital pathology Whole Slide Images (WSI), opening the door to apply Machine Learning (ML) techniques to assist in cancer diagnosis. ML, including Deep Learning (DL), has produced impressive results in diverse image classification tasks in pathology, such as predicting clinical outcomes in lung cancer and inferring regional gene expression signatures. Despite these promising results, the uptake of ML as a common diagnostic tool in pathology remains limited. A major obstacle is the insufficient labelled data for training neural networks and other classifiers, especially for new sites where models have not been established yet. Recently, image synthesis from small, labelled datasets using Generative Adversarial Networks (GAN) has been used successfully to create high-performing classification models. Considering the domain shift and complexity in annotating data, we investigated an approach based on GAN that minimized the differences in WSI between large public data archive sites and a much smaller data archives at the new sites. The proposed approach allows the tuning of a deep learning classification model for the class of interest to be improved using a small training set available at the new sites. This paper utilizes GAN with the one-class classification concept to model the class of interest data. This approach minimizes the need for large amounts of labelled data from the new site to train the network. The GAN generates synthesized one-class WSI images to jointly train the classifier with WSIs available from the new sites. We tested the proposed approach for follicular lymphoma data of a new site by utilizing the data archives from different sites. The synthetic images for the one-class data generated from the data obtained from different sites with minimum amount of data from the new site have resulted in a significant improvement of 15\% for the Area Under the curve (AUC) for the new site that we want to establish a new follicular lymphoma classifier. The test results have shown that the classifier can perform well without the need to obtain more training data from the test site, by utilizing GAN to generate the synthetic data from all existing data in the archives from all the sites.},
  archive      = {J_NCA},
  author       = {Somaratne, Upeka Vianthi and Wong, Kok Wai and Parry, Jeremy and Laga, Hamid},
  doi          = {10.1007/s00521-023-08810-8},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20569-20579},
  shortjournal = {Neural Comput. Appl.},
  title        = {The use of generative adversarial networks for multi-site one-class follicular lymphoma classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A perspective on human activity recognition from inertial
motion data. <em>NCA</em>, <em>35</em>(28), 20463–20568. (<a
href="https://doi.org/10.1007/s00521-023-08863-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) using inertial motion data has gained a lot of momentum in recent years both in research and industrial applications. From the abstract perspective, this has been driven by the rapid dynamics for building intelligent, smart environments, and ubiquitous systems that cover all aspects of human life including healthcare, sports, manufacturing, commerce, etc., which necessitate and subsume activity recognition aiming at recognizing the actions, characteristics, and goals of one or more agent(s) from a temporal series of observations streamed from one or more sensors. From a more concrete and seemingly orthogonal perspective, such momentum has been driven by the ubiquity of inertial motion sensors on-board mobile and wearable devices including smartphones, smartwatches, etc. In this paper we give an introductory and a comprehensive survey to the subject from a given perspective. We focus on a subset of topics, that we think are major, that will have significant and influential impacts on the future research and industrial-scale deployment of HAR systems. These include: (1) a comprehensive and detailed description of the inertial motion benchmark datasets that are publicly available and/or accessible, (2) feature selection and extraction techniques and the corresponding learning methods used to build workable HAR systems; we survey classical handcrafted datasets as well as data-oriented automatic representation learning approach to the subject, (3) transfer learning as a way to overcome many hurdles in actual deployments of HAR systems on a large scale, (4) embedded implementations of HAR systems on mobile and/or wearable devices, and finally (5) we touch on adversarial attacks, a topic that is essentially related to the security and privacy of HAR systems. As the field is very huge and diverse, this article is by no means comprehensive; it is though meant to provide a logically and conceptually rather complete picture to advanced practitioners, as well as to present a readable guided introduction to newcomers. Our logical and conceptual perspectives mimic the typical data science pipeline for state-of-the-art AI-based systems.},
  archive      = {J_NCA},
  author       = {Gomaa, Walid and Khamis, Mohamed A.},
  doi          = {10.1007/s00521-023-08863-9},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20463-20568},
  shortjournal = {Neural Comput. Appl.},
  title        = {A perspective on human activity recognition from inertial motion data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GAME: GAussian mixture error-based meta-learning
architecture. <em>NCA</em>, <em>35</em>(28), 20445–20461. (<a
href="https://doi.org/10.1007/s00521-023-08843-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supervised learning, the gap between the truth label and the model output is always portrayed by an error function, and a fixed error function corresponds to a specific noise distribution that provides for model optimization. However, the actual noise usually has a much more complex structure. To be better fit for it, in this paper, we propose a robust noise model that embeds a mixture of Gaussian (MoG) noise modeling strategy into a baseline classification model, which is selected as the Gaussian mixture model (GMM) here. Further, to facilitate the automatic selection of the number of mixture components, we apply the penalized likelihood method. Then, we utilize an alternative strategy to update the parameters of the noisy model and the basic GMM classifier. From the meta-learning perspective, the proposed model offers a novel approach to defining the hyperparameters from the error representation. Finally, we compare the proposed approach with three conventional and related classification methods on the synthetic, two benchmark handwriting recognition datasets and the Yale Face dataset. In addition, we embed the noise modeling strategy into the semantic segmentation task. The numerical results validate that our approach achieves the best performance and the efficiency of MoG noise modeling.},
  archive      = {J_NCA},
  author       = {Dong, Jinhe and Shi, Jun and Gao, Yue and Ying, Shihui},
  doi          = {10.1007/s00521-023-08843-z},
  journal      = {Neural Computing and Applications},
  number       = {28},
  pages        = {20445-20461},
  shortjournal = {Neural Comput. Appl.},
  title        = {GAME: GAussian mixture error-based meta-learning architecture},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: A limited-size ensemble of homogeneous
CNN/LSTMS for high-performance word classification. <em>NCA</em>,
<em>35</em>(27), 20443–20444. (<a
href="https://doi.org/10.1007/s00521-023-08855-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ameryan, Mahya and Schomaker, Lambert},
  doi          = {10.1007/s00521-023-08855-9},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20443-20444},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: A limited-size ensemble of homogeneous CNN/LSTMS for high-performance word classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: Multi-level context-driven interaction
modeling for human future trajectory prediction. <em>NCA</em>,
<em>35</em>(27), 20441. (<a
href="https://doi.org/10.1007/s00521-023-08789-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {He, Zhiquan and Sun, Hao and Cao, Wenming and He, Henry Z.},
  doi          = {10.1007/s00521-023-08789-2},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20441},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Multi-level context-driven interaction modeling for human future trajectory prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive practical predefined-time neural tracking control
for multi-joint uncertain robotic manipulators with input saturation.
<em>NCA</em>, <em>35</em>(27), 20423–20440. (<a
href="https://doi.org/10.1007/s00521-023-08797-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predefined-time stability contributes to constraining the tracking time of robotic manipulators, but the stringent judgment conditions restrict its practical application. This paper studies an adaptive practical predefined-time neural control scheme for uncertain multi-joint robotic manipulators with input saturation. First, a practical predefined-time stability criterion is established to ensure the closed-loop stability of uncertain systems. Then, the unknown robotic dynamic model can be approximated by radial basis function neural networks. Meanwhile, the input saturation of the robotic manipulator is compensated by introducing an adaptive term. Based on the constructed stability criterion, the proposed controller is proved to guarantee that the tracking error of the system converges to a small neighborhood of the origin within a predefined time and is independent of the initial state. Finally, the effectiveness of the proposed control scheme is emphasized by numerical simulations and experiments of a two-joint and a nine-joint robotic manipulator, respectively.},
  archive      = {J_NCA},
  author       = {Sai, Huayang and Xu, Zhenbang and Zhang, Enyang},
  doi          = {10.1007/s00521-023-08797-2},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20423-20440},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive practical predefined-time neural tracking control for multi-joint uncertain robotic manipulators with input saturation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving a many-objective PFSP with reinforcement cumulative
prospect theory in low-volume PCB manufacturing. <em>NCA</em>,
<em>35</em>(27), 20403–20422. (<a
href="https://doi.org/10.1007/s00521-023-08792-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Permutation flow-shop scheduling problems with many objectives have wide applications in the modern manufacturing domain such as the printed circuit board (PCB) industry. In this paper, an upgraded method called reinforcement cumulative prospect theory is proposed for solving many-objective permutation flow-shop scheduling problems. Reinforcement cumulative prospect theory is determined by two reference points, the improved prospect value function, and the entropy-based decision weight function. A novel many-objective optimization algorithm, namely, an optimal foraging algorithm based on the reinforcement cumulative prospect theory (OFA/RCPT), is presented. The comprehensive prospect value is used as the fitness strategy of the OFA/RCPT algorithm to guide the optimization process. The performance of the proposed algorithm is assessed by a comparison with nine state-of-the-art algorithms. Three classification experiments are carried out on six Walking-Fish-Group test cases, seven permutation flow-shop scheduling benchmark instances, and a practical permutation flow-shop scheduling problem in low-volume PCB manufacturing. For the experiment, four performance metrics are adopted, and the commercial software Quest is used to simulate a PCB production line. The simulation results show that the proposed algorithm has better performance than the other algorithms.},
  archive      = {J_NCA},
  author       = {Ding, Chen and Qiao, Fei and Zhu, GuangYu},
  doi          = {10.1007/s00521-023-08792-7},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20403-20422},
  shortjournal = {Neural Comput. Appl.},
  title        = {Solving a many-objective PFSP with reinforcement cumulative prospect theory in low-volume PCB manufacturing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reinforcement learning-based approach for online optimal
control of self-adaptive real-time systems. <em>NCA</em>,
<em>35</em>(27), 20375–20401. (<a
href="https://doi.org/10.1007/s00521-023-08778-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with self-adaptive real-time embedded systems (RTES). A self-adaptive system can operate in different modes. Each mode encodes a set of real-time tasks. To be executed, each task is allocated to a processor (placement) and assigned a priority (scheduling), while respecting timing constraints. An adaptation scenario allows switching between modes by adding, removing, and updating task parameters that must meet related deadlines after adaptation. For such systems, anticipating all operational modes at design time is usually impossible. Online reinforcement learning is increasingly used in the presence of design-time uncertainty. To tackle this problem, we formalize the placement and scheduling problems in self-adaptive RTES as a Markov decision process and propose related algorithms based on Q-learning. Then, we introduce an approach that integrates the proposed algorithms to assist designers in the development of self-adaptive RTES. At the design level, the RL Placement and the RL Scheduler are proposed to process predictable adaptation scenarios. These modules are designed to generate placement and scheduling models for an application while maximizing system extensibility and ensuring real-time feasibility. At the execution level, the RL Adapter is defined to process online adaptations. Indeed, the goal of the RL Adapter agent is to reject the adaptation scenario when feasibility concerns are raised; otherwise, it generates a new feasible placement and scheduling. We apply and simulate the proposed approach to a healthcare robot case study to show its applicability. Performance evaluations are conducted to prove the effectiveness of the proposed approach compared to related works.},
  archive      = {J_NCA},
  author       = {Haouari, Bakhta and Mzid, Rania and Mosbahi, Olfa},
  doi          = {10.1007/s00521-023-08778-5},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20375-20401},
  shortjournal = {Neural Comput. Appl.},
  title        = {A reinforcement learning-based approach for online optimal control of self-adaptive real-time systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel neural adaptive terminal sliding mode control for TCP
network systems with arbitrary convergence time. <em>NCA</em>,
<em>35</em>(27), 20365–20374. (<a
href="https://doi.org/10.1007/s00521-023-08746-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of adaptive arbitrary convergence time terminal sliding mode control (TSMC) for nonlinear networked systems with completely unknown functions and nonresponsive UDP stream disturbances is studied. In this work, an improved sliding surface based on arbitrary convergence time is designed to overcome the issue that the convergence rate depends on the system state. Different from the traditional TSMC, this paper introduces holistically an auxiliary term (nonautonomous differential equation) into the design of a sliding mode controller, which can compensate for the influence of neural adaptive approximation error and ensure the convergence of a closed-loop system at prescribed time. A robust compensation signal is also constructed by introducing a super twisting disturbance observer to process nonresponsive UDP flows. In addition, the controller is designed in a piecewise continuous manner, so that the sliding mode surface can be selected arbitrarily, according to the adaptation after the prescribed time. The effectiveness of the new controller is verified by extensive simulations in comparison with related works.},
  archive      = {J_NCA},
  author       = {Qi, Xuelei and Li, Chen and Chen, Bao and Ni, Wei and Ma, Hongjun},
  doi          = {10.1007/s00521-023-08746-z},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20365-20374},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel neural adaptive terminal sliding mode control for TCP network systems with arbitrary convergence time},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-stage deep convolutional neural network for
histopathological analysis of osteosarcoma. <em>NCA</em>,
<em>35</em>(27), 20351–20364. (<a
href="https://doi.org/10.1007/s00521-023-08837-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteosarcoma has the highest incidence rate among malignant bone tumours. It is particularly detrimental to human health because it is a highly malignant tumour. Also makes up 40\% of initial malignant bone tumours while having a 3–10 per million incidences. High mortality and morbidity rates are associated with osteosarcoma, particularly in underdeveloped nations. To increase patient survival, early osteosarcoma screening and diagnosis are essential. In this study, we suggest a novel encoder–decoder method that associations nested connections and an effective attention mechanism. The encoder, decoder, and skip connection make up the model&#39;s structure. The DropBlock regularization technique makes it easier to discard local semantic information while still encouraging the network to learn resilient and useful features. An effective attention module leverages the right kind of cross-channel contact to collect more detailed global data. In the skip connection section, the semantic gap left by a direct simple connection is filled by using the nested connection method to combine the feature maps obtained from the intermediate decoder with the original feature maps from the encoder. The original image is then enhanced with data to increase robustness and avoid the over-fitting issue brought on by insufficient data. Three separate data sets and a variety of performance indicators are used to examine the robustness of the proposed model. The suggested model outperforms other current models thanks to its strong performance, achieving an average accuracy of 99.13\%. Here, Datasets 1, 2, and 3 each have an accuracy of 99.67\%, 98.16\%, and 99.76\%, respectively. The investigational results show that our proposed method can significantly progress the presence of convolutional neural networks and state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Jayachandran, A. and Ganesh, S. and Kumar, S. Ratheesh},
  doi          = {10.1007/s00521-023-08837-x},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20351-20364},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-stage deep convolutional neural network for histopathological analysis of osteosarcoma},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). All-in-one picture: Visual summary of items in a recommender
system. <em>NCA</em>, <em>35</em>(27), 20339–20349. (<a
href="https://doi.org/10.1007/s00521-023-08822-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigation through large volumes of images is a complex and tedious task that requires tools to facilitate the exploration and discovery of visual information. Photo summaries are one of these tools, which consist of selecting a reduced set of images that best represent the original data source. However, creating photo summaries in the context of recommender systems poses several challenges: How to select the most relevant images for each item? How to encode each image? How to evaluate the quality of the generated summary? In this manuscript, we propose a clustering-based method to create a visual summary in the context of a restaurant recommender system, which includes the photos taken by users who visited the restaurants (items) in a given city. These photos are encoded using a deep neural network that takes into account not only their content but also the relationships between users and restaurants. This encoding will allow us to create a visual summary that captures the essence of user tastes and illustrates the gastronomic offer of the city. We also propose a similarity measure between items based on the users who have visited them and an evaluation method that calculates to what extent the summary obtained represents the original data source. The experimentation carried out includes five datasets and the obtained results demonstrate the adequacy of our proposal for the construction of these summaries.},
  archive      = {J_NCA},
  author       = {Pérez-Núñez, Pablo and Díez, Jorge and Remeseiro, Beatriz and Luaces, Oscar and Bahamonde, Antonio},
  doi          = {10.1007/s00521-023-08822-4},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20339-20349},
  shortjournal = {Neural Comput. Appl.},
  title        = {All-in-one picture: Visual summary of items in a recommender system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel methodology for malicious traffic detection in smart
devices using BI-LSTM–CNN-dependent deep learning methodology.
<em>NCA</em>, <em>35</em>(27), 20319–20338. (<a
href="https://doi.org/10.1007/s00521-023-08818-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to propose a new technique for identifying and categorizing malevolent Internet traffic within the context of security for smart devices. Given the rising usage of smart devices, including mobile phones, wearables, smart transportation-based devices, and the Internet of Things, concerns regarding their security are increasing. The need to develop effective security measures arises from the potential for attackers to compromise user data. In this study, we introduce an innovative approach that combines deep learning techniques, specifically convolutional neural networks (CNN), with long short-term memory (LSTM) for the purpose of detecting and categorizing malevolent Internet traffic. The objective of the proposed technique is to address the challenges related to time estimation by focusing on level prediction, resulting in a substantial reduction in prediction time for the identification of malevolent traffic. We utilize bidirectional long short-term memory–CNN (BI-LSTM–CNN) to identify malevolent communication and provide support for voice input. Experimental outcomes illustrate the effectiveness of our proposed technique in terms of precision, accuracy, F1 factor, false acceptance rate (FAR), false positive rate (FPR), and detection rate. In comparison with existing methods for detecting malevolent traffic, our approach achieves a 99.62\% traffic detection rate, 99.98\% accuracy, and 0.01\% FAR, whereas the accuracy, detection rate of malevolent traffic, and FAR of existing methods are 99.88\%, 97.32\%, and 4.31\%, respectively. These outcomes emphasize the superior performance and analysis of our technique, rendering it a valuable contribution to the realm of smart device security. In summary, this paper proposes a novel BI-LSTM–CNN technique for detecting malevolent traffic in smart devices. The proposed methodology tackles time estimation challenges and exhibits superior performance when compared to existing techniques.},
  archive      = {J_NCA},
  author       = {Anitha, T. and Aanjankumar, S. and Poonkuntran, S. and Nayyar, Anand},
  doi          = {10.1007/s00521-023-08818-0},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20319-20338},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel methodology for malicious traffic detection in smart devices using BI-LSTM–CNN-dependent deep learning methodology},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). T2RFIS: Type-2 regression-based fuzzy inference system.
<em>NCA</em>, <em>35</em>(27), 20299–20317. (<a
href="https://doi.org/10.1007/s00521-023-08811-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses a novel type-2 fuzzy inference system with multiple variables in which no fuzzy rules are explicitly defined. By using a rule-free system, we avoid the serious disadvantage of rule-based systems, which are burdened with the curse of dimensionality. In the proposed system, Gaussian membership functions are used for its inputs, and linearly parameterized system functions are used to obtain its output. To obtain the system parameters, a genetic algorithm with multi-objective function is applied. In the presented method, the genetic algorithm is combined with a feature selection method and a regularized ridge regression. The objective functions consist of a pair in which one function is defined as the number of active features and the other as the validation error for regression models or the accuracy for classification models. In this way, the models are selected from the Pareto front considering some compromise between their quality and simplification. Compared to the author’s previous work on the regression-based fuzzy inference system, a new inference scheme with type-2 fuzzy sets has been proposed, and the quality has been improved compared to the system based on type-1 fuzzy sets. Four experiments involving the approximation of a function, the prediction of fuel consumption, the classification of breast tissue, and the prediction of concrete compressive strength confirmed the efficacy of the presented method.},
  archive      = {J_NCA},
  author       = {Wiktorowicz, Krzysztof},
  doi          = {10.1007/s00521-023-08811-7},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20299-20317},
  shortjournal = {Neural Comput. Appl.},
  title        = {T2RFIS: Type-2 regression-based fuzzy inference system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bio-inspired machine learning: Programmed death and
replication. <em>NCA</em>, <em>35</em>(27), 20273–20298. (<a
href="https://doi.org/10.1007/s00521-023-08806-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze algorithmic and computational aspects of biological phenomena, such as replication and programmed death, in the context of machine learning. We use two different measures of neuron efficiency to develop machine learning algorithms for adding neurons to the system (i.e., replication algorithm) and removing neurons from the system (i.e., programmed death algorithm). We argue that the programmed death algorithm can be used for compression of neural networks and the replication algorithm can be used for improving performance of the already trained neural networks. We also show that a combined algorithm of programmed death and replication can improve the learning efficiency of arbitrary machine learning systems. The computational advantages of the bio-inspired algorithms are demonstrated by training feedforward neural networks on the MNIST dataset of handwritten images.},
  archive      = {J_NCA},
  author       = {Grabovsky, Andrey and Vanchurin, Vitaly},
  doi          = {10.1007/s00521-023-08806-4},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20273-20298},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bio-inspired machine learning: Programmed death and replication},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-graph embedding for partial label learning.
<em>NCA</em>, <em>35</em>(27), 20253–20271. (<a
href="https://doi.org/10.1007/s00521-023-08793-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning (PLL) is an essential weakly supervised learning method. In PLL, the example’s ground-truth label is unknown and hidden in a candidate label set comprising a subset of the label set. A multi-classifier is trained through a set of examples and candidate labels. The obscurity of the candidate label set makes the PLL challenging. Although high-efficiency graph-based methods without any parameters have been proposed to disambiguate, it is challenging to adapt a single graph structure for various actual data. The current work presents a new multi-graph embedding collaborative disambiguation PLL algorithm (PL-MGECD) to address the mentioned problem. The contributions of the current work are: (1) A unified framework for graph-based PLL is presented for the first time, which combines a least squares regression loss and a graph regularization term with ambiguous label constraints. (2) PL-MGECD adopts various graph structures in partial label learning for the first time and compensates for the lack of single graph representation data by fusing the complementarity of different graph structures. (3) PL-MGECD first introduces a graph structure constructed by candidate label information and employs the candidate tag information to modify the graph structure to compensate for the label disambiguation shortage through feature spatial similarity. (4) An efficient optimization algorithm is proposed. Extensive experiments demonstrate that the proposed PL-MGECD method has a competitive or superior performance over some traditional PLL methods.},
  archive      = {J_NCA},
  author       = {Li, Hongyan and Vong, Chi Man and Wan, Zhonglin},
  doi          = {10.1007/s00521-023-08793-6},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20253-20271},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-graph embedding for partial label learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-based delayed impulsive control for fractional-order
dynamic systems with application to synchronization of fractional-order
neural networks. <em>NCA</em>, <em>35</em>(27), 20241–20251. (<a
href="https://doi.org/10.1007/s00521-023-08738-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, delayed impulsive control for fractional-order dynamic systems via event-triggering mechanism (ETM) is investigated, in which the impact of time delays in impulses is taken into account. Combining the novel event-triggering function into the transformed fractional-order delayed impulsive control system, the event-triggered impulsive sequence is generated. Under the frame of event-based delayed impulsive control (EDIC) technique, system signals are only allowed to be transmitted at discrete instants, while no additional control input is required for two successive impulsive instants. Then, the positive quantity of inter-execution is proved, which can exclude the Zeno behavior. Furthermore, the relationship is discussed among delayed impulsive functions, event-triggering parameters, and the order of controlled fractional-order systems. Compared with traditional time-triggered mechanism where the impulsive instants are required to be set in advance, EDIC can be viewed as a more flexible impulsive control since it makes impulsive control only activate when designed events occur, effectively improving the control efficiency. The simulation results are provided to verified the effectiveness of the proposed method at the end of this paper.},
  archive      = {J_NCA},
  author       = {Zheng, Bibo and Wang, Zhanshan},
  doi          = {10.1007/s00521-023-08738-z},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20241-20251},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-based delayed impulsive control for fractional-order dynamic systems with application to synchronization of fractional-order neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep reinforcement learning of passenger behavior in
multimodal journey planning with proportional fairness. <em>NCA</em>,
<em>35</em>(27), 20221–20240. (<a
href="https://doi.org/10.1007/s00521-023-08733-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal transportation systems require an effective journey planner to allocate multiple passengers to transport operators. One example is mobility-as-a-service, a new mobility service that integrates various transport modes through a single platform. In such a multimodal and diverse journey planning problem, accommodating heterogeneous passengers with different and dynamic preferences can be challenging. Furthermore, passengers may behave based on experiences and expectations, in the sense that the transport experience affects their state and decision of the next transport service. Current methods of treating each journey planning optimization as a non-time varying single experience problem cannot adequately model passenger experience and memories over many journeys over time. In this paper, we model passenger experience as a Markov model where prior experiences have a transient effect on future long-term satisfaction and retention rate. As such, we formulate a multi-objective journey planning problem that considers individual passenger preferences, experiences, and memories. The proposed approach dynamically determines utility weights to obtain an optimal journey plan for individual passengers based on their status. To balance the profit received by each transport operator, we present a variant-based proportional fairness. Our experiments using real-world and synthetic datasets show that our approach enhances passenger satisfaction, compared to baseline methods. We demonstrate that the overall profit is increased by 2.3 times, resulting in a higher retention rate caused by higher satisfaction levels. Our proposed approach can facilitate the participation of transport operators and promote passenger acceptance of MaaS.},
  archive      = {J_NCA},
  author       = {Chu, Kai-Fung and Guo, Weisi},
  doi          = {10.1007/s00521-023-08733-4},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20221-20240},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep reinforcement learning of passenger behavior in multimodal journey planning with proportional fairness},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Degramnet: Effective audio analysis based on a fully
learnable time–frequency representation. <em>NCA</em>, <em>35</em>(27),
20207–20219. (<a
href="https://doi.org/10.1007/s00521-023-08849-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current state-of-the-art audio analysis algorithms based on deep learning rely on hand-crafted Spectrogram-like audio representations, that are more compact than descriptors obtained from the raw waveform; the latter are, in turn, far from achieving good generalization capabilities when few data are available for the training. However, Spectrogram-like representations have two main limitations: (1) The parameters of the filters are defined a priori, regardless of the specific audio analysis task; (2) such representations do not perform any denoising operation on the audio signal, neither in the time domain nor in the frequency domain. To overcome these limitations, we propose a new general-purpose convolutional architecture for audio analysis tasks that we call DEGramNet, which is trained with audio samples described with a novel, compact and learnable time–frequency representation that we call DEGram. The proposed representation is fully trainable: Indeed, it is able to learn the frequencies of interest for the specific audio analysis task; in addition, it performs denoising through a custom time–frequency attention module, which amplifies the frequency and time components in which the sound is actually located. It implies that the proposed representation can be easily adapted to the specific problem at hands, for instance giving more importance to the voice frequencies when the network needs to be used for speaker recognition. DEGramNet achieved state-of-the-art performance on the VGGSound dataset (for Sound Event Classification) and comparable accuracy with a complex and special-purpose approach based on network architecture search over the VoxCeleb dataset (for Speaker Identification). Moreover, we demonstrate that DEGram allows to achieve high accuracy with lightweight neural networks that can be used in real-time on embedded systems, making the solution suitable for Cognitive Robotics applications.},
  archive      = {J_NCA},
  author       = {Foggia, Pasquale and Greco, Antonio and Roberto, Antonio and Saggese, Alessia and Vento, Mario},
  doi          = {10.1007/s00521-023-08849-7},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20207-20219},
  shortjournal = {Neural Comput. Appl.},
  title        = {Degramnet: Effective audio analysis based on a fully learnable time–frequency representation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning class-agnostic masks with cross-task refinement for
weakly supervised semantic segmentation. <em>NCA</em>, <em>35</em>(27),
20189–20205. (<a
href="https://doi.org/10.1007/s00521-023-08826-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised semantic segmentation (WSSS) commonly relies on Class Activation Mapping (CAM) to produce pseudo semantic labels using image-level annotations. However, because CAM maps often form sparse object regions with poor boundaries, they cannot provide sufficient segmentation supervision. Because off-the-shelf saliency maps can provide rich object boundaries that can be leveraged to improve semantic segmentation, we propose to jointly learn semantic segmentation and class-agnostic masks by using image-level annotations and off-the-shelf saliency maps as supervision. We also propose a cross-task label refinement mechanism, which takes advantage of the learned class-agnostic masks and semantic segmentation masks, to refine the pseudo labels and provide more accurate supervision to both tasks. Moreover, we introduce a new normalization method for CAM to generate more complete class-specific localization maps. The improved CAM maps complement our learned class-agnostic masks, leading to high-quality pseudo semantic segmentation labels. Extensive experiments demonstrate the effectiveness of the proposed approach, with state-of-the-art WSSS results established on PASCAL VOC 2012 and MS COCO.},
  archive      = {J_NCA},
  author       = {Xu, Lian and Bennamoun, Mohammed and Boussaid, Farid and Ouyang, Wanli and Xu, Dan},
  doi          = {10.1007/s00521-023-08826-0},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20189-20205},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning class-agnostic masks with cross-task refinement for weakly supervised semantic segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Multi-scale network with shared cross-attention for
audio–visual correlation learning. <em>NCA</em>, <em>35</em>(27),
20173–20187. (<a
href="https://doi.org/10.1007/s00521-023-08817-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal audio–visual correlation learning has been an interesting research topic, which aims to capture and understand semantic correspondences between audio and video. We face two challenges during audio–visual correlation learning: (i) audio and visual feature sequences, respectively, belong to different feature spaces, and (ii) semantic mismatch between audio and visual sequences inevitably happens. To solve these challenges, existing works mainly focus on how to efficiently extract discriminative features, while ignoring the abundant granular features of audio and visual modalities. In this work, we introduce the multi-scale network with shared cross-attention (MSNSCA) module for audio–visual correlation learning, a supervised representation learning framework for capturing semantic audio–visual correspondences by integrating a multi-scale feature extraction module with strong cross-attention into an end-to-end trainable deep network. MSNSCA can extract more effective audio–visual particle features with excellent audio–visual semantic matching capability. Experiments on various audio–visual learning tasks, including audio–visual matching and retrieval on benchmark datasets, demonstrate the effectiveness of the proposed MSNSCA model.},
  archive      = {J_NCA},
  author       = {Zhang, Jiwei and Yu, Yi and Tang, Suhua and Li, Wei and Wu, Jianming},
  doi          = {10.1007/s00521-023-08817-1},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20173-20187},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale network with shared cross-attention for audio–visual correlation learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered observer-based t-s fuzzy dynamic positioning
fault-tolerant control for unmanned surface vehicle. <em>NCA</em>,
<em>35</em>(27), 20157–20171. (<a
href="https://doi.org/10.1007/s00521-023-08786-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the anti-disturbance and reliability performance for unmanned surface vehicles subject to actuator faults and external disturbances, an adaptive event-triggered observer-based output feedback control method is proposed. Firstly, a Takagi-Sugeno fuzzy system is established by considering unknown disturbances and actuator faults. Secondly, an adaptive event-triggered mechanism is designed and then the state and disturbance observers are constructed using the output of the event generator. Based on the outputs of the observers, an adaptive event-triggered observer-based output feedback dynamic positioning controller is developed and the asymptotical stability with $$H_\infty$$ performance is analyzed via the Lyapunov function method. Finally, the advantages of the proposed method are demonstrated via an example.},
  archive      = {J_NCA},
  author       = {Sun, Haibin and Shi, Jierong and Hou, Linlin},
  doi          = {10.1007/s00521-023-08786-5},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20157-20171},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-triggered observer-based T-S fuzzy dynamic positioning fault-tolerant control for unmanned surface vehicle},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Importance attribution in neural networks by means of
persistence landscapes of time series. <em>NCA</em>, <em>35</em>(27),
20143–20156. (<a
href="https://doi.org/10.1007/s00521-023-08731-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes a method to analyze time series with a neural network using a matrix of area-normalized persistence landscapes obtained with topological data analysis. The network’s architecture includes a gating layer that is able to identify the most relevant landscape levels for a classification task, thus working as an importance attribution system. Next, a matching is performed between the selected landscape levels and the corresponding critical points of the original time series. This matching enables reconstruction of a simplified shape of the time series that gives insight into the grounds of the classification decision. As a use case, this technique is tested in the article with input data from a dataset of electrocardiographic signals. The classification accuracy obtained using only a selection of landscape levels from data was $$94.00\%\pm 0.13$$ averaged after five runs of a neural network, while the original signals achieved $$98.41\% \pm 0.09$$ and landscape-reduced signals yielded $$97.04\% \pm 0.14$$ .},
  archive      = {J_NCA},
  author       = {Ferrà, Aina and Casacuberta, Carles and Pujol, Oriol},
  doi          = {10.1007/s00521-023-08731-6},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20143-20156},
  shortjournal = {Neural Comput. Appl.},
  title        = {Importance attribution in neural networks by means of persistence landscapes of time series},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-camera person re-identification using spatiotemporal
context modeling. <em>NCA</em>, <em>35</em>(27), 20117–20142. (<a
href="https://doi.org/10.1007/s00521-023-08799-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (ReID) aims at identifying a person of interest (POI) across multiple non-overlapping cameras. The POI can be either in an image or in a video sequence. Factors such as occlusion, variable viewpoint, misalignment, unrestrained poses, background clutter are the major challenges in developing robust, person ReID models. To address these issues, an attention mechanism that comprises local part/region-aggregated feature representation learning is presented in this paper by incorporating long-range local and global context modeling. The part-aware local attention blocks are aggregated into the widely used modified pre-trained ResNet50 CNN architecture as a backbone employing two attention blocks, i.e., Spatio-Temporal Attention Module (STAM) and Channel Attention Module (CAM). The spatial attention block of STAM can learn contextual dependencies between different human body parts/regions like head, upper body, lower body, and shoes from a single frame. On the other hand, the temporal attention modality can learn temporal contextual dependencies of the same person’s body parts across all video frames. Lastly, the channel-based attention modality, i.e., CAM, can model semantic connections between the channels of feature maps. These STAM and CAM blocks are combined sequentially to form a unified attention network named as Spatio-Temporal Channel Attention Network (STCANet) that will be able to learn both short-range and long-range global feature maps, respectively. Extensive experiments are carried out to study the effectiveness of STCANet on three image-based and two video-based benchmark datasets, i.e., Market-1501, DukeMTMC-ReID, MSMT17, DukeMTC-VideoReID, and MARS. K-reciprocal re-ranking of gallery set is also applied in which the proposed network showed a significant improvement over these datasets in comparison with state of the art. Lastly, to study the generalizability of STCANet on unseen test instances, cross-validation on external cohorts is also applied that showed the robustness of the proposed model that can be easily deployed to the real world for practical applications.},
  archive      = {J_NCA},
  author       = {Zulfiqar, Fatima and Bajwa, Usama Ijaz and Raza, Rana Hammad},
  doi          = {10.1007/s00521-023-08799-0},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20117-20142},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-camera person re-identification using spatiotemporal context modeling},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BoW-based neural networks vs. Cutting-edge models for
single-label text classification. <em>NCA</em>, <em>35</em>(27),
20103–20116. (<a
href="https://doi.org/10.1007/s00521-023-08754-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reliably and accurately classify complicated &quot;big&quot; datasets, machine learning models must be continually improved. This research proposes straightforward yet competitive neural networks for text classification, even though graph neural networks (GNN) have reignited interest in graph-based text classification models. Convolutional neural networks (CNN), artificial neural networks (ANN), and their refined “fine-tuned” models (denoted as FT-CNN and FT-ANN) are the names given to our proposed models. The models presented in this paper demonstrate that our simple models like (CNN, ANN, FT-CNN, and FT-ANN) can perform better than more complex GNN ones such as (SGC, SSGC, and TextGCN) and are comparable to others (i.e., HyperGAT and Bert). The process of fine-tuning is also highly recommended because it improves the performance and reliability of models. The performance of our suggested models on five benchmark datasets (namely, Reuters (R8), R52, 20NewsGroup, Ohsumed, and Mr) is vividly illustrated. According to the experimental findings, on the majority of the target datasets, these models—especially those that have been fine-tuned—perform surprisingly better than SOTA approaches, including GNN-based models.},
  archive      = {J_NCA},
  author       = {Abdalla, Hassan I. and Amer, Ali A. and Ravana, Sri Devi},
  doi          = {10.1007/s00521-023-08754-z},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20103-20116},
  shortjournal = {Neural Comput. Appl.},
  title        = {BoW-based neural networks vs. cutting-edge models for single-label text classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy-based bee algorithm for machine learning and pattern
recognition of computational data of nanofluid heat transfer.
<em>NCA</em>, <em>35</em>(27), 20087–20101. (<a
href="https://doi.org/10.1007/s00521-023-08851-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The CFD approach could waste a lot of time, effort, and cost for three-dimensional turbulent flow modeling. In the CFD method, any changes in the grid numbers in a specific region, the whole domain must be meshed and simulated again. More computational expenses are imposed when the mesh density must be increased. This study, for the first time, is aimed to develop a supplementary method using the artificial intelligence algorithm to reduce the post-processing calculations of the CFD approach. Eddy viscosity of alumina–water nanofluid turbulent flow inside a straight pipe is considered for prediction. The finite volume technique is used for solving the governing equations (i.e., mass, momentum, and energy) and the k–ɛ turbulence model of the CFD approach. Algorithms for artificial intelligence have shown promise for data learning and data patterning. In this study, the FVM solutions are learned by the artificial intelligence of the bee algorithm-based fuzzy inference system (BAFIS). The finite volume technique in the CFD modeling is integrated with the BAFIS to predict eddy viscosity in the nanofluid turbulent flow. Besides, the BAFIS performance and application are examined for meshing in the post-processing step of the CFD. In this way, the BAFIS learned the CFD-driven data for the existing nodes. Then the CFD data pattern is captured by the BAFIS. Finally, this CFD pattern is extended to more nodes. For achieving the intelligence, different input numbers (2 and 3), cluster numbers (5, 10, 15, and 20), as the fuzzy C-means clustering parameter, and neighborhood damping radius rates (0.85, 0.90, 0.95, and 0.99), as bee algorithm parameter, are investigated. The intelligence of the BAFIS was achieved for 3 inputs, the cluster number of 20, and the neighborhood damping radius rate of 0.99. The predictions of the eddy viscosity of BAFIS were the same as those of CFD. The BAFIS shows the ability for the accurate prediction of the eddy viscosity (regression number of 0.98). Comparing the time consumption of the methods, for the same number of nodes (i.e., 4,473) and the same computer specifications, the prediction time of the CFD (110 min) was around half of the learning time of BAFIS (52 min). It should be noted that after the data learning, the target variable, eddy viscosity in this study, could be predicted for any number of nodes (i.e., 774,771 nodes) within a negligible time (22 s). So, no significant time was consumed by BAFIS for the mesh increment. The BAFIS results covered the CFD results for additional nodes in the new dense mesh.},
  archive      = {J_NCA},
  author       = {Azma, Aliasghar and Behroyan, Iman and Babanezhad, Meisam and Liu, Yakun},
  doi          = {10.1007/s00521-023-08851-z},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20087-20101},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy-based bee algorithm for machine learning and pattern recognition of computational data of nanofluid heat transfer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning a data-efficient model for a single agent in
homogeneous multi-agent systems. <em>NCA</em>, <em>35</em>(27),
20069–20085. (<a
href="https://doi.org/10.1007/s00521-023-08838-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training Reinforcement Learning (RL) policies for a robot requires an extensive amount of data recorded while interacting with the environment. Acquiring such a policy on a real robot is a tedious and time-consuming task. This is more challenging in a multi-agent system where individual data may be required from each agent. While training in simulations is the common approach due to efficiency and low-cost, they rarely describe the real world. Consequently, policies trained in simulations and transferred to the real robot usually perform poorly. In this paper, we present a novel real-to-sim-to-real framework to bridge the reality gap for an agent in collective motion of a homogeneous multi-agent system. First, we propose a novel deep neural-network architecture termed Convolutional-Recurrent Network (CR-Net) to capture the complex state transition of an agent and simulate its motion. Once trained with data from one agent, we show that the CR-Net can accurately predict motion of all agents in the group. Second, we propose to invest a limited amount of real data from the agent in a generative model. Then, training the CR-Net with synthetic data sampled from the generative model is shown to be at least equivalent to real data. Hence, the proposed approach provides a sufficiently accurate model with significantly less real data. The generative model can also be disseminated along with open-source hardware for easier usage. We show experiments on ground and underwater vehicles in which multi-agent RL policies are trained in the simulation for collective motion and successfully transferred to the real-world.},
  archive      = {J_NCA},
  author       = {Gurevich, Anton and Bamani, Eran and Sintov, Avishai},
  doi          = {10.1007/s00521-023-08838-w},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20069-20085},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning a data-efficient model for a single agent in homogeneous multi-agent systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced binary artificial rabbits optimization for
feature selection in medical diagnosis. <em>NCA</em>, <em>35</em>(27),
20013–20068. (<a
href="https://doi.org/10.1007/s00521-023-08812-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes binary versions of artificial rabbits optimization (ARO) for feature selection (FS) with medical diagnosis data. ARO is a recent swarm-based optimization algorithm that mimics rabbits’ natural survival tactics and eating habits. It was modeled in an optimization context to tackle optimization problems of continuous search spaces. In this paper, ARO is improved to deal with the binary domain of FS. The improvements include three additions: First, different alternatives of transfer functions were used to convert ARO from continuous to binary; second, the global-best concept was added to the binary ARO to improve the exploitation capability of the proposed algorithm; and finally, Lévy flight and opposition-based learning strategies were injected into the proposed algorithm to enhance its diversity and thus improve the balance between global exploration and local exploitation during all stages of the search process. Six binary variants of ARO were designed across an extensive set of experiments to study the impact of using the proposed amendments on the performance of the proposed ARO algorithm. These variants are: binary ARO with S-shaped transfer function (BAROS), binary ARO with V-shaped transfer function (BAROV), BAROS with the global-best concept (BGAROS), BGAROV with the global-best concept (BGAROV), BGAROS with Lévy flight and opposition-based learning strategies (BGAROSLO), and BGAROV with Lévy flight and opposition-based learning strategies (BGAROVLO). The proposed binary ARO versions were evaluated using 23 medical FS datasets. In addition, the proposed algorithm was applied to detect coronavirus disease using a real COVID-19 dataset. Five performance measures were used: classification accuracy, sensitivity, specificity, fitness value, and the number of selected features. In a nutshell, the proposed binary ARO versions were able to achieve success rates for these performance metrics as follows: 66.7\%, 50\%, 33.3\%, 66.7\%, and 83.3\%, respectively. In conclusion, the success of the proposed ARO versions was realized due to the suitable design of the parameters of the proposed ARO version, such as transfer functions, global-best concept, Lévy flight, and opposition-based learning strategies. A comprehensive comparative evaluation was studied against ten well-established methods using the same datasets with a high preference for the proposed ARO versions, especially BGAROSLO which can achieve the best accuracy for the majority of the FS datasets. This is proven using Friedman’s statistical test ad-hocked by Holm’s test.},
  archive      = {J_NCA},
  author       = {Awadallah, Mohammed A. and Braik, Malik Shehadeh and Al-Betar, Mohammed Azmi and Abu Doush, Iyad},
  doi          = {10.1007/s00521-023-08812-6},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {20013-20068},
  shortjournal = {Neural Comput. Appl.},
  title        = {An enhanced binary artificial rabbits optimization for feature selection in medical diagnosis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive probabilistic neural network based on hybrid
PSO–ALO for predicting wind speed in different regions. <em>NCA</em>,
<em>35</em>(27), 19997–20011. (<a
href="https://doi.org/10.1007/s00521-023-08807-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning neural network (NN) algorithms are being applied for the past few years in all engineering and science domain, economic sectors, image processing synthesis and analysis, and so on. Due to this, this paper work considered employing these machine learning neural models for forecasting application in respect of renewable energy applications and in particular focused on the forecasting of wind speed. It is crucial for power grid dispatchability, stability, and controllability, and its precision is necessary for making the most use of wind resources. This article describes the development of a novel hybrid forecasting system to anticipate the wind speed of real-time wind farm datasets using a hybrid probabilistic neural network (PNN) model and optimization method. The particle swarm optimization (PSO)–ant lion optimization technique is utilized to modify the designed adaptive PNN in order to optimize the weight parameters. The machine learning model employed in this study is an adaptive PNN with a probability density function and a decision-making function that adhere to Bayes’ rule to achieve faster convergence and higher prediction accuracy. The obtained simulation results show that the recommended hybrid optimized PNN model outperforms the other techniques that were evaluated and compared from the literature. This establishes that the built optimized adaptive PNN model is applicable and suitable to serve as a predictor, as shown by the outcome of the statistical analysis.},
  archive      = {J_NCA},
  author       = {Vinothkumar, T. and Deepa, S. N. and Raj, F. Vijay Amirtha},
  doi          = {10.1007/s00521-023-08807-3},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19997-20011},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive probabilistic neural network based on hybrid PSO–ALO for predicting wind speed in different regions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MFGCN: An efficient graph convolutional network based on
multi-order feature information for human skeleton action recognition.
<em>NCA</em>, <em>35</em>(27), 19979–19995. (<a
href="https://doi.org/10.1007/s00521-023-08814-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of depth sensors and pose estimation algorithms, human skeleton action recognition based on graph convolutional networks has acquired widespread attention and application. The latest methods achieve dynamically learning different topologies for modeling and use first-order, second-order, and third-order features, i.e., joint, bone, and motion representations, which has led to high accuracy. However, many models are still confused by actions that have similar motion trajectories, and most of the existing methods model the spatial dimension before the temporal dimension, whereas in fact, spatial and temporal information should be interrelated. In this paper, we propose an efficient graph convolutional network based on multi-order feature information (MFGCN) for human skeleton action recognition. Firstly, our method introduces angle features (noted as fourth-order features), which are implicitly embedded in other third-order features by encoding angular features, to powerfully capture detailed features in the spatio-temporal dimension and enhance the ability to distinguish similar actions. Secondly, we use a content-adaptive approach to construct the adjacency matrix and dynamically learn the topology between the skeleton joints. Finally, we develop a spatio-temporal information sliding extraction module (STISE) to improve the inter-correlation of spatial and temporal information. The proposed method has extensively experimented on the NTU-RGB D, NTU-RGB D 120, and Northwestern-UCLA datasets, and the experimental results show that our method can achieve superior performance compared to the current state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Qi, Yongfeng and Hu, Jinlin and Han, Xiang and Hu, Liang and Zhao, Zongtao},
  doi          = {10.1007/s00521-023-08814-4},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19979-19995},
  shortjournal = {Neural Comput. Appl.},
  title        = {MFGCN: An efficient graph convolutional network based on multi-order feature information for human skeleton action recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel hybrid PSO- and GS-based hyperparameter optimization
algorithm for support vector regression. <em>NCA</em>, <em>35</em>(27),
19961–19977. (<a
href="https://doi.org/10.1007/s00521-023-08805-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperparameter optimization is vital in improving the prediction accuracy of support vector regression (SVR), as in all machine learning algorithms. This study introduces a new hybrid optimization algorithm, namely PSOGS, which consolidates two strong and widely used algorithms, particle swarm optimization (PSO) and grid search (GS). This hybrid algorithm was experimented on five benchmark datasets. The speed and the prediction accuracy of PSOGS-optimized SVR models (PSOGS-SVR) were compared to those of its constituent algorithms (PSO and GS) and another hybrid optimization algorithm (PSOGSA) that combines PSO and gravitational search algorithm (GSA). The prediction accuracies were evaluated and compared in terms of root mean square error and mean absolute percentage error. For the sake of reliability, the results of the experiments were obtained by performing 10-fold cross-validation on 30 runs. The results showed that PSOGS-SVR yields prediction accuracy comparable to GS-SVR, performs much faster than GS-SVR, and provides better results with less execution time than PSO-SVR. Besides, PSOGS-SVR presents more effective results than PSOGSA-SVR in terms of both prediction accuracy and execution time. As a result, this study proved that PSOGS is a fast, stable, efficient, and reliable algorithm for optimizing hyperparameters of SVR.},
  archive      = {J_NCA},
  author       = {Açıkkar, Mustafa and Altunkol, Yunus},
  doi          = {10.1007/s00521-023-08805-5},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19961-19977},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel hybrid PSO- and GS-based hyperparameter optimization algorithm for support vector regression},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-dimensional, multi-functional and multi-level
attention in YOLO for underwater object detection. <em>NCA</em>,
<em>35</em>(27), 19935–19960. (<a
href="https://doi.org/10.1007/s00521-023-08781-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater object detection is a prerequisite for underwater robots to achieve autonomous operation and ocean exploration. However, poor imaging quality, harsh underwater environments and concealed underwater targets greatly aggravate the difficulty of underwater object detection. In order to reduce underwater background interference and improve underwater object perception, we propose a multi-dimensional, multi-functional and multi-level attention module (mDFLAM). The multi-dimensional strategy first enhances the robustness of attention application by collecting valuable information in different target dimensions. The multi-functional strategy further improves the flexibility of attention calibration by capturing the importance of channel semantic information and the dependence of spatial location information. The multi-level strategy finally enriches the diversity of attention perception by extracting the intrinsic information under different receptive fields. In pre-processing and post-processing stages, cross-splitting and cross-linking stimulate the synergistic calibration advantage of multi-dimensional and multi-functional attention by redistributing channel dimensions and restoring feature states. In the attention calibration stage, adaptive fusion stimulates the synergistic calibration advantage of multi-level attention by assigning learnable parameters. In order to meet the high-precision and real-time requirements for underwater object detection, we integrate the plug-and-play mDFLAM into YOLO detectors. The full-port embedding further strengthens the semantic information expression by improving the feature fusion quality between scales. In underwater detection tasks, ablation and comparison experiments demonstrate the rationality and effectiveness of our attention design. In other detection tasks, our work shows good robustness and generalization.},
  archive      = {J_NCA},
  author       = {Shen, Xin and Sun, Xudong and Wang, Huibing and Fu, Xianping},
  doi          = {10.1007/s00521-023-08781-w},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19935-19960},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-dimensional, multi-functional and multi-level attention in YOLO for underwater object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New conditional generative adversarial capsule network for
imbalanced classification of human sperm head images. <em>NCA</em>,
<em>35</em>(27), 19919–19934. (<a
href="https://doi.org/10.1007/s00521-023-08742-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Male infertility negatively affects the lives of infertile couples. Sperm head morphology is an essential factor in evaluating semen in male infertility. The lack of samples with abnormal sperm heads compared to the normal sperm head samples makes the classification of sperm head images an imbalance classification problem. In comparison with other deep networks such as convolutional neural networks, capsule neural networks (CapsNets) provide an optimal platform for designing imbalanced classification models by considering spatial relationships of features. Also, generative adversarial networks (GANs) help to improve the imbalanced classification of images by producing suitable synthetic samples. In this paper, a new architecture based on CapsNets and GANs is proposed and evaluated for imbalanced classification of human sperm head images. The new proposed conditional generative adversarial capsule network outperformed other deep learning networks in the balanced and imbalanced classification of human sperm head images. Based on the comparison between the general methods for increasing the data and the proposed network, the general methods have less robustness to reducing the amount of data than the proposed network. The presented network performed a balanced classification of sperm head images with 97.8\% accuracy. Additionally, the proposed network maintained an accuracy of over 80\% up to the ratio of minority to majority class of 1:30, indicating that it performed properly in the imbalanced classification of sperm images.},
  archive      = {J_NCA},
  author       = {Jabbari, Hamed and Bigdeli, Nooshin},
  doi          = {10.1007/s00521-023-08742-3},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19919-19934},
  shortjournal = {Neural Comput. Appl.},
  title        = {New conditional generative adversarial capsule network for imbalanced classification of human sperm head images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel optimal <span
class="math display">PI<sup><em>λ</em><sub>1</sub></sup>I<sup><em>λ</em><sub>2</sub></sup>D<sup><em>μ</em><sub>1</sub></sup>D<sup><em>μ</em><sub>2</sub></sup></span>
controller using mayfly optimization algorithm for automatic voltage
regulator system. <em>NCA</em>, <em>35</em>(27), 19899–19918. (<a
href="https://doi.org/10.1007/s00521-023-08834-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel $${\mathrm{PI}}^{{\uplambda }_{1}}{\mathrm{I}}^{{\uplambda }_{2}}{\mathrm{D}}^{{\upmu }_{1}}{\mathrm{D}}^{{\upmu }_{2}}$$ controller for the automatic voltage regulator (AVR) system. The AVR system controls the terminal voltage of synchronous generators. In this way, it contributes to voltage stability in power systems. The parameters of the proposed controller are optimized with the recently developed Mayfly algorithm for various objective functions. These objective functions are Zwe-Lee Gaing, the integral of time multiplied absolute error, the integral of squared error, the integral of time multiplied squared error and the integral of absolute error (IAE). The best result in terms of transient response parameters (settling time, rise time, and maximum overshoot) at terminal voltage is compared to controllers developed in recent years. Both time domain analysis and frequency domain analysis is used in this comparison. From the comparison results, it has been observed that the proposed controller provided better performance as compared to existing controllers in the literature. In addition to time and frequency domain analysis, robustness, nonlinear effect, and external disturbance rejection performances of the proposed controller are analyzed for the AVR system. As a result of all these analyses, it is seen that the proposed controller displays outstanding performance.},
  archive      = {J_NCA},
  author       = {Çavdar, Bora and Şahin, Erdinç and Akyazı, Ömür and Nuroğlu, Fatih Mehmet},
  doi          = {10.1007/s00521-023-08834-0},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19899-19918},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel optimal $${\mathrm{PI}}^{{\uplambda }_{1}}{\mathrm{I}}^{{\uplambda }_{2}}{\mathrm{D}}^{{\upmu }_{1}}{\mathrm{D}}^{{\upmu }_{2}}$$ controller using mayfly optimization algorithm for automatic voltage regulator system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognizing factors effecting the use of mobile banking apps
through sentiment and thematic analysis on user reviews. <em>NCA</em>,
<em>35</em>(27), 19885–19897. (<a
href="https://doi.org/10.1007/s00521-023-08827-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We live in an age where the use of smart devices and Internet are redefining our community standards. Additionally, the pandemic Covid-19 enforced the community to use applications on smart devices for various activities. Currently, many organizations are developing their applications that are accessible through various platforms, including Windows Phone Store, Apple App Store, and Google Play. To facilitate the customer the banking sector is also providing their mobile applications for various online services. Mobile banking applications (mbanking apps) have considerably upgraded the efficiency of the banks and living standards of the people. The people can easily download applications from app stores and are permitted to leave reviews or comments on the mobile application. The sentiment analysis is an area that allows us to examine the user opinion to improve the online services. Therefore, for any organization it is of prime importance to explore and evaluate the weaknesses affecting the delivery of their online services. In this work, sentiment analysis is performed to evaluate ten (10) mbanking apps of Pakistan using valence aware dictionary for sentiment reasoning and machine learning (ML) based approaches. Performance of three classifiers through supervised ML techniques multinomial Naïve Bayes, logistic regression, support vector machine, and ensemble model is compared and employed. Moreover, the thematic analysis of reviews is also performed to discover various factors as themes that affect the effectiveness of the mbanking apps by using Top2Vec Model. The results indicate that the ensemble model is best performing model with f1-score of 90\%. The thematical analysis uncovers 346 positive themes like ease of use, helpful, reliable, user friendly, good aesthetics, convenience, secured and many more, whereas 441 negative themes comprise performance issue, poor updates/new version in apps, account registration issue, app crash problem, etc.},
  archive      = {J_NCA},
  author       = {Mahmood, Toqeer and Naseem, Saba and Ashraf, Rehan and Asif, Muhammad and Umair, Muhammad and Shah, Mohsin},
  doi          = {10.1007/s00521-023-08827-z},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19885-19897},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recognizing factors effecting the use of mobile banking apps through sentiment and thematic analysis on user reviews},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to colorize near-infrared images with limited data.
<em>NCA</em>, <em>35</em>(27), 19865–19884. (<a
href="https://doi.org/10.1007/s00521-023-08768-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With large amount of training data, Convolutional Neural Network (CNN)-based methods have made great progress for colorizing visible grayscale images. However, existing models rarely consider colorizing near-infrared (NIR) images, which are usually captured with less color or texture information. In this paper, we propose a novel two-stage framework to recover visible color for NIR images with limited data. Firstly, we propose a grayscale preprocessing network to cope with the visual blur and low contrast in NIR gray images, which provides grayscale image as close as the ground truth of visible ones. For the second stage, i.e., image colorization, a novel bilateral Res-Unet network is proposed to transfer color features on both sides of the encoder and decoder to improve the semantic correctness of the colored image. To deal with limited data, a feature memory module is adopted to memorize the color features of training images, providing color conditions for the colorization network. Furthermore, a multi-feature semantic perception loss is reformulated to make the final results with more semantic information and increases the vividness and naturalness. To verify the proposed method, we conduct various experiments on four limited datasets and achieve state-of-the-art against existing CNN-based methods.},
  archive      = {J_NCA},
  author       = {Liu, Yu and Guo, Zhe and Guo, Haojie and Xiao, Huaxin},
  doi          = {10.1007/s00521-023-08768-7},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19865-19884},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning to colorize near-infrared images with limited data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Expert demonstrations guide reward decomposition for
multi-agent cooperation. <em>NCA</em>, <em>35</em>(27), 19847–19863. (<a
href="https://doi.org/10.1007/s00521-023-08785-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans are able to achieve good teamwork through collaboration, since the contributions of the actions from human team members are properly understood by each individual. Therefore, reasonable credit assignment is crucial for multi-agent cooperation. Although existing work uses value decomposition algorithms to mitigate the credit assignment problem, since they decompose the global value function at multi-agents’ local value function level, the overall evaluation of the value function can easily lead to approximation errors. Moreover, such strategies are vulnerable to sparse reward scenarios. In this paper, we propose to use expert demonstrations to guide the team reward decomposition at each time step, rather than value decomposition. The proposed method computes the reward ratio of each agent according to the similarity between the state-action pair of the agent and the expert demonstrations. In addition, under this setting, each agent can independently train its value function and evaluate its behavior, which makes the algorithm highly robust to team rewards. Moreover, the proposed method constrains the policy to collect data with similar distribution to the expert data during the exploration, which makes policy update more robust. We conduct extensive experiments to validate our proposed method in various MARL environments, the results show that our algorithm outperforms the state-of-the-art algorithms in most scenarios; our method is robust to various reward functions; and the trajectories by our policy is closer to that of the expert policy.},
  archive      = {J_NCA},
  author       = {Weiwei, Liu and Wei, Jing and Shanqi, Liu and Yudi, Ruan and Kexin, Zhang and Jiang, Yang and Yong, Liu},
  doi          = {10.1007/s00521-023-08785-6},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19847-19863},
  shortjournal = {Neural Comput. Appl.},
  title        = {Expert demonstrations guide reward decomposition for multi-agent cooperation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy optimized v-detector algorithm on apache spark for
class imbalance issue of intrusion detection in big data. <em>NCA</em>,
<em>35</em>(27), 19821–19845. (<a
href="https://doi.org/10.1007/s00521-023-08783-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data come with new challenges for network intrusion detection as it provides large-scale data with a variety of sophisticated attacks (e.g., malware, advanced persistent threats APTs, zero-day attacks). For that, the demand for new tools and approaches specialized in big data analytics is increasing. In addition, The false alarm rate of anomaly-based intrusion detection systems (IDS) is a major concern. The majority of the existing methods for large-scale network intrusion detection reach a high false-positive rate (FPR) due to the class imbalance of large-scale intrusion datasets, which can affect the network. Subsequently, the critical challenge is to reduce FPR with the lowest decrease in true-positive rate (TPR) to retain detection quality at a feasible level. To face up to these challenges, we have proposed a new network intrusion detection system for big network intrusion based on the negative selection principle and big data frameworks. One of the promising negative selection methods of the artificial immune system (AIS) for network intrusion detection is the variable-sized detector algorithm. Unfortunately, this algorithm cannot analyze big datasets, because the generation of the radius of each detector is related to the self-space, and it will be more complex when the self-space is too big. Furthermore, the search for new detectors is done randomly, and the generated detectors do not have maximum coverage of the self and non-self-space. To confront the shortcoming of this algorithm, we have proposed an extended V-detector algorithm that is built using clonal selection and fuzzy rules, and it is implemented on Apache Spark. The proposed algorithm is scalable and more efficient when applied to large-scale imbalanced datasets. The proposed framework is implemented in a fully distributed cluster of Apache Spark workers and evaluated on the KDDcup99 benchmark dataset, on a large up-to-date dataset CICIDS2017, and on large-scale synthetic datasets. Results reveal that the proposed algorithm outperforms state-of-the-art baselines and achieves high detection accuracy of 0.9984 and 0.9994 and very low positive rates of 0.0002 and 0.0001 with comparable detection rates for the KDDcup99 dataset and the imbalanced dataset CICIDS2017, respectively. Moreover, it improves the scalability and execution time, key for big intrusion detection analysis in real-time.},
  archive      = {J_NCA},
  author       = {Kourid, Ahlam and Chikhi, Salim and Recupero, Diego Reforgiato},
  doi          = {10.1007/s00521-023-08783-8},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19821-19845},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy optimized V-detector algorithm on apache spark for class imbalance issue of intrusion detection in big data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Controllable lyrics-to-melody generation. <em>NCA</em>,
<em>35</em>(27), 19805–19819. (<a
href="https://doi.org/10.1007/s00521-023-08728-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lyrics-to-melody generation is an interesting and challenging topic in AI music research field. Due to the difficulty of learning the correlations between lyrics and melody, previous methods suffer from low generation quality and lack of controllability. Controllability of generative models enables human interaction with models to generate desired contents, which is especially important in music generation tasks towards human-centered AI that can facilitate musicians in creative activities. To address these issues, we propose a controllable lyrics-to-melody generation network, ConL2M, which is able to generate realistic melodies from lyrics in user-desired musical style. Our work contains three main novelties: (1) to model the dependencies of music attributes cross multiple sequences, inter-branch memory fusion (Memofu) is proposed to enable information flow between multi-branch stacked LSTM architecture; (2) reference style embedding (RSE) is proposed to improve the quality of generation as well as control the musical style of generated melodies; (3) sequence-level statistical loss (SeqLoss) is proposed to help the model learn sequence-level features of melodies given lyrics. Verified by evaluation metrics for music quality and controllability, initial study of controllable lyrics-to-melody generation shows better generation quality and the feasibility of interacting with users to generate the melodies in desired musical styles when given lyrics.},
  archive      = {J_NCA},
  author       = {Zhang, Zhe and Yu, Yi and Takasu, Atsuhiro},
  doi          = {10.1007/s00521-023-08728-1},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19805-19819},
  shortjournal = {Neural Comput. Appl.},
  title        = {Controllable lyrics-to-melody generation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fuzzy approach for prioritization of pharmacies to improve
mask distribution process during COVID-19 pandemic—a pilot study for
i̇stanbul. <em>NCA</em>, <em>35</em>(27), 19783–19804. (<a
href="https://doi.org/10.1007/s00521-023-08749-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the whole world struggles with the COVID-19 pandemic, there are many different measures taken by countries. In this sense, the distribution of free masks to citizens between the ages of 20–65 in Turkey is one of the important measures taken against to spread of the pandemic. This distribution process is carried out through pharmacies and people can obtain their masks from any pharmacy in their area of residence. However, this situation may cause some pharmacies to be very busy, and thus social distance cannot be maintained and health and safety of the people may be threatened. In this paper, we aim to prioritize pharmacies so that only determined pharmacies in certain regions perform mask distribution process to prevent virus transmission. For this purpose, Esenler district is taken into consideration for a pilot study which is one of the risky regions in terms of virus spread in Istanbul, Turkey. Multi-criteria decision-making approach (MCDM) is used because of the necessity of handling many factors in decision-making process and the contradiction of evaluation factors in the prioritization of pharmacies. In order to best model the uncertainty in the decision process, the MCDM approach is applied in a fuzzy environment. In addition, spherical fuzzy AHP and VIKOR MCDM approaches are used as novel hybrid method in this paper. As a result of spherical fuzzy multi-criteria analysis, the pharmacies that need to provide free mask distribution in the Esenler region have been successfully identified.},
  archive      = {J_NCA},
  author       = {Erdoğan, Melike},
  doi          = {10.1007/s00521-023-08749-w},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19783-19804},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fuzzy approach for prioritization of pharmacies to improve mask distribution process during COVID-19 pandemic—a pilot study for İstanbul},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent air combat with two-stage graph-attention
communication. <em>NCA</em>, <em>35</em>(27), 19765–19781. (<a
href="https://doi.org/10.1007/s00521-023-08784-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air-to-air combat system is a complex multi-agent system (MAS) wherein a large number of unmanned combat aerial vehicles learn to combat with their opponents in a highly dynamic and uncertain environment. Because of the local observability of each individual, it is difficult for classical multi-agent learning methods to get effective cooperative strategies. Recently, a communication mechanism has been proposed to solve the local observability issue of MAS. However, existing methods with predefined rules easily cause an exponential increase in state–action pairs, leading to high communication costs. Taking this cue, this paper designs a graph neural network based on a two-stage graph-attention mechanism to capture the key interaction relationships and communication connections between agents in complex air-to-air combat scenarios. Based on an essential backbone multi-agent reinforcement learning method, known as Multi-Agent Proximal Policy Optimization, the proposed method with a hard- and soft-attention scheme can realize the dynamic adjustment of the communication relationship and ad hoc network of multiple agents, by cutting off the unrelated interaction connections while building the correlation importance between pair agents, concurrently. Last but not least, the experimental study in the simulation environment has validated the significance of our proposed method in solving the large-scale air-to-air combat problems.},
  archive      = {J_NCA},
  author       = {Sun, Zhixiao and Wu, Huahua and Shi, Yandong and Yu, Xiangchao and Gao, Yifan and Pei, Wenbin and Yang, Zhen and Piao, Haiyin and Hou, Yaqing},
  doi          = {10.1007/s00521-023-08784-7},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19765-19781},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-agent air combat with two-stage graph-attention communication},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-based singularity-free fixed-time fuzzy control for
active suspension systems with displacement constraint. <em>NCA</em>,
<em>35</em>(27), 19751–19763. (<a
href="https://doi.org/10.1007/s00521-023-08780-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the event-based adaptive fixed-time (FT) control problem for active suspension systems (ASSs) with actuator faults. The fuzzy approximator is utilized to estimate the continuous function with the unknown car body mass parameters. The FT controller with continuous piecewise function is presented to avoid the singularity problem caused by the derivation of the virtual controller in the backstepping method and to compensate the actuator faults. A switching threshold event-triggered mechanism is evolved for ASSs, which has the advantages of fixed threshold strategy and relative threshold strategy to reduce the communication burden more reasonably. The suspension vertical displacement is restricted by constructing a time-varying barrier Lyapunov function. It is proved that the signals in the closed-loop systems are bounded by Lyapunov stability criterion. Finally, simulation results show that the controller is effective in suppressing the vertical vibration of ASSs.},
  archive      = {J_NCA},
  author       = {Jia, Tinghan and Cao, Liang and Zhang, Pengchao and Pan, Yingnan},
  doi          = {10.1007/s00521-023-08780-x},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19751-19763},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-based singularity-free fixed-time fuzzy control for active suspension systems with displacement constraint},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TVA-GAN: Attention guided generative adversarial network for
thermal to visible image transformations. <em>NCA</em>, <em>35</em>(27),
19729–19749. (<a
href="https://doi.org/10.1007/s00521-023-08724-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent improvement in deep learning approaches for realistic image generation and translation, Generative Adversarial Networks (GANs) delivered favorable results. GAN generates novel samples that look indistinguishable from authentic images. This paper proposes a novel generative network for thermal-to-visible image translation. Thermal to Visible synthesis is challenging due to the non-availability of accurate semantic and textural information in thermal images. The thermal sensors acquire the thermal face images by capturing the object’s luminance with fewer details about the actual facial information. However, it is advantageous for low-light and night-time vision, where image information cannot be captured in a complex environment by an RGB camera. We design a new Attention-guided Cyclic Generative Adversarial Network for Thermal to Visible Face transformation (TVA-GAN) by integrating a new attention network. We utilize attention guidance with a recurrent block with an Inception module to simplify the learning space toward the optimum solution. The proposed TVA-GAN is trained and evaluated for thermal to visible face synthesis over three benchmark datasets, including the WHU-IIP, Tufts Face Thermal2RGB, and CVBL-CHILD datasets. The proposed TVA-GAN results show promising improvement in face synthesis compared to the state-of-the-art GAN methods. For the proposed TVA-GAN, code is available at: https://github.com/GANGREEK/TVA-GAN .},
  archive      = {J_NCA},
  author       = {Yadav, Nand Kumar and Singh, Satish Kumar and Dubey, Shiv Ram},
  doi          = {10.1007/s00521-023-08724-5},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19729-19749},
  shortjournal = {Neural Comput. Appl.},
  title        = {TVA-GAN: Attention guided generative adversarial network for thermal to visible image transformations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligence parameter classification approach for energy
storage and natural convection and heat transfer of nano-encapsulated
phase change material: Deep neural networks. <em>NCA</em>,
<em>35</em>(27), 19719–19727. (<a
href="https://doi.org/10.1007/s00521-023-08708-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A deep neural network is utilized to classify the parameters of a natural convection heat transfer of a nano-encapsulated phase change material suspension using the isotherm images for the first time. A natural convection flow and heat transfer simulation dataset were created and used as a training and validation tool. Then, a deep neural network, consisting of three parts, was used for the classification task. The first part was made of several conventional layers, and a rectified linear unit activation layer supported each layer. The second part was a preparation layer for reshaping from 2D images to 1D classification. The third layer was made of a classifier layer. The results showed that the impact of the Rayleigh number and volume concentrations of nanoparticles could be classified by 99.8 and 93.32\% accuracy, respectively. However, the Stefan number was classified weakly. As a part of the current research, a transfer learning approach was used to improve accuracy. The learning transfer approach was quite effective and improved the accuracy of the Stefan number classification by 16.6\%.},
  archive      = {J_NCA},
  author       = {Ghalambaz, Mohammad and Edalatifar, Mohammad and Moradi Maryamnegari, Sara and Sheremet, Mikhail},
  doi          = {10.1007/s00521-023-08708-5},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19719-19727},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligence parameter classification approach for energy storage and natural convection and heat transfer of nano-encapsulated phase change material: Deep neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomising the simple recurrent network: A lightweight,
energy-efficient RNN model with application to forecasting problems.
<em>NCA</em>, <em>35</em>(27), 19707–19718. (<a
href="https://doi.org/10.1007/s00521-023-08775-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-variate time-series (MTS) forecasting is the prediction of future for a sequence of data. The process of analysing obtained data can benefit the community financially and securely, for instance observing stock exchange trends and predicting malicious attacks whenabout. MTS forecasting models face many problems including data and model complexity, energy constraints and computational cost. These problems could affect budget allocation, latency and carbon emission. Recurrent neural networks are one of these models, which are known for their computational complexity due to slow learning process which requires more energy to train. Contributing to green AI, in this paper, we propose a competitive and energy-efficient lightweight recurrent neural network based on a hybrid neural architecture that combines Random Neural Network (RaNN) and Simple Recurrent Network (SRN), namely Random Simple Recurrent Network (RSRN). We consider RaNN for its distinctive probabilistic properties and SRN for adding lightweight recurrent ability to the RaNN to process sequential data. The paper shows how RSRN is trained using adapted and optimised versions of back propagation (BP), back propagation through time (BPTT) and truncated BPTT (TBPTT). The latter two algorithms use penalised gradient descent to prevent gradient explosion problems by employing the average of total gradient over time. Evaluated on several datasets, RSRN achieves best performance when using TBPTT. Moreover, we performed a comparative study against well-known recurrent models showing its superiority compared to the state-of-the-art models, while requiring much less computational time and training parameters. In addition, we investigated the multi-layer architecture and its properties.},
  archive      = {J_NCA},
  author       = {Khennour, Mohammed Elmahdi and Bouchachia, Abdelhamid and Kherfi, Mohammed Lamine and Bouanane, Khadra},
  doi          = {10.1007/s00521-023-08775-8},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19707-19718},
  shortjournal = {Neural Comput. Appl.},
  title        = {Randomising the simple recurrent network: A lightweight, energy-efficient RNN model with application to forecasting problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A systematic review of generative adversarial imputation
network in missing data imputation. <em>NCA</em>, <em>35</em>(27),
19685–19705. (<a
href="https://doi.org/10.1007/s00521-023-08840-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data missing has always occurred in data processing. To solve this problem, researchers have improved the process methods of the missing data with diverse strategies, which range from directly deleting missing data samples to using artificial intelligence technology to filling in incomplete data. The processing methods of the missing data have been improved. Generative adversarial imputation network (GAIN) is a kind of neural network which has an excellent performance in missing data imputation. A number of publications that research and cite the GAIN model show a significant growth trend after GAIN was proposed in 2018. GAIN has been studied and improved by many scholars in their specific fields. However, few studies have systematically surveyed the GAIN model&#39;s development trends on missing data from its birth to the present, which result in a lack of comprehensive information about GAINs general performance in different fields. In this review, we summarize the development of the GAIN model in missing data imputation from 2018 to 2022. Based on the WOS database, 32 publications are selected according to the PRISMA statement. The outcome of this paper is from the following aspects: (1) analyzing the publication information and application fields quantitatively; (2) expounding the GAIN-based models, classification, and research trends; (3) elaborating the model attributes and missing data mechanism; and (4) summarizing the existing issues and proposing the future directions. Above all, this paper can help scholars gain further insight into the missing data issues and better understand the optimized directions of GAIN models.},
  archive      = {J_NCA},
  author       = {Zhang, Yuqing and Zhang, Runtong and Zhao, Butian},
  doi          = {10.1007/s00521-023-08840-2},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19685-19705},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic review of generative adversarial imputation network in missing data imputation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning models for forecasting water demand for the
metropolitan region of salvador, bahia. <em>NCA</em>, <em>35</em>(27),
19669–19683. (<a
href="https://doi.org/10.1007/s00521-023-08842-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new hybrid SVR-ANN model for water demand forecasting. Where an adaptation of the methodology proposed by Zhang (Neurocomputing 50:159–175, 2003) is used to decompose the time series of 10 reservoirs that supply the Metropolitan Region of Salvador (RMS). The data used are from the historical consumption from January 2017 to February 2022, obtained from the local supply company, Empresa Baiana de Águas e Saneamento, and meteorological data obtained from the National Institute of Meteorology of Brazil. The results demonstrated the feasibility of using the proposed model, compared to other traditional models such as the multilayer perceptron (MLP), support vector regression (SVR), short long-term memory (LSTM) and autoregressive integrated moving average (ARIMA).},
  archive      = {J_NCA},
  author       = {Santos de Jesus, Edmilson dos and Silva Gomes, Gecynalda Soares da},
  doi          = {10.1007/s00521-023-08842-0},
  journal      = {Neural Computing and Applications},
  number       = {27},
  pages        = {19669-19683},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning models for forecasting water demand for the metropolitan region of salvador, bahia},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient big data classification using elastic collision
seeker optimization based faster r-CNN. <em>NCA</em>, <em>35</em>(26),
19651–19668. (<a
href="https://doi.org/10.1007/s00521-023-08707-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data is a large set of data that is analyzed with the calculation to manifest myriad sources. Big data is capable of handling various challenges to processing huge amounts of data. To handle issues based on large-scale databases, a MapReduce framework is employed which provides robust and simple infrastructure for huge datasets. This paper proposes a novel Elastic collision seeker optimization based Faster R-CNN (ECSO-FRCNN) classifier for efficient big data classification. The proposed ECSO-FRCNN classifier is capable of handling missing attributes, and incremental learning and improves training performance effectively. As the proposed technique deals with large data samples, it necessitates the inclusion of the MapReduce framework. The adaption of MapReduce design in big data classification prevents the classification results from uncertainties such as data redundancy, misclassification, and storage issues. The proposed method is examined with three standard datasets, namely the skin segmentation dataset, mushroom dataset, and localization dataset, collected from the University of California, UCI machine learning repository. Finally, extensive experimental analysis is carried out for various parameters to depict the efficiency of the system.},
  archive      = {J_NCA},
  author       = {Chidambaram, S. and Cyril, C. Pretty Diana and Ganesh, S. Sankar},
  doi          = {10.1007/s00521-023-08707-6},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19651-19668},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient big data classification using elastic collision seeker optimization based faster R-CNN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Archimedes optimization algorithm based approaches for
solving energy demand estimation problem: A case study of turkey.
<em>NCA</em>, <em>35</em>(26), 19627–19649. (<a
href="https://doi.org/10.1007/s00521-023-08769-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption is getting rising gradually around the planet. Therefore, the importance of energy management has increased for all nations worldwide, and long-term energy demand estimation is becoming a vital problem for all countries. In this study, linear, quadratic and exponential models based six different Archimedes optimization algorithms (AOA) such as AOA-Linear, AOA-Quadratic, AOA-Exponential, IAOA-Linear, IAOA-Quadratic and IAOA-Exponential have been proposed to make some future projections of Turkey for the years (2021–2050). The previous studies in the literature were used the data set of Turkey, such as observed energy demand (OED), population, gross domestic product (GDP), export and import data for the years (1979–2005) or (1979–2011) obtained from the Turkish Statistical Institute (TUIK) and the Ministry of Energy and Natural Resources (MENR). However, in this study, a new data set is organized with the OED, population, GDP, export and import data of Turkey for the years (1997–2020) to make some long-term energy demand estimations of Turkey, and this dataset is used for the first time in this study. AOA-Linear, AOA-Quadratic and AOA-Exponential algorithms are based on linear, quadratic and exponential mathematical models and the basic AOA method. IAOA-Linear, IAOA-Quadratic and IAOA-Exponential algorithms are also based on linear, quadratic and exponential mathematical models and the improved AOA (For short, IAOA) proposed in this study. Once a sensitivity analysis is made for determining the effect of algorithmic parameters of AOA and IAOA, the proposed algorithms are realized for Turkey’s long-term energy demand estimation for the years (2021–2050) with three different future scenarios. According to the experimental results, the quadratic model-based proposed IAOA produces better or comparable performance on the problem dealt with in this study in terms of solution quality and robustness.},
  archive      = {J_NCA},
  author       = {Aslan, Murat},
  doi          = {10.1007/s00521-023-08769-6},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19627-19649},
  shortjournal = {Neural Comput. Appl.},
  title        = {Archimedes optimization algorithm based approaches for solving energy demand estimation problem: A case study of turkey},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective QoS-aware optimization for deployment of IoT
applications on cloud and fog computing infrastructure. <em>NCA</em>,
<em>35</em>(26), 19581–19626. (<a
href="https://doi.org/10.1007/s00521-023-08759-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) technology serves many industries to improve their performance. As such, utilizing far distant cloud datacenters to run time-sensitive IoT applications has become a great challenge for the sake of real-time interaction and accurate service delivery time requests. Therefore, the fog computing as a deployment approach of IoT applications has been presented in the edge network. However, inefficient deployment of applications’ modules on the fog infrastructure leads to physical resource and bandwidth dissipations, and debilitation of quality of service (QoS), and also increases the power consumption. When all application’s modules are highly utilized on a single fog node owing to the reduction in the power consumption, the level of service reliability is decreased. To obviate the problem, this paper takes the concept of fault tolerance threshold into account as a criterion to guarantee applications’ running reliability. This paper formulates deployment of IoT applications’ modules on fog infrastructure as a multi-objective optimization problem with minimizing both bandwidth wastage and power consumption approach. To solve this combinatorial problem, a multi-objective optimization genetic algorithm (MOGA) is proposed which considers physical resource utilization and bandwidth wastage rate in their objective functions along with reliability and application’s QoS in their constraints. To validate the proposed method, extensive scenarios have been conducted. The result of simulations proves that the proposed MOGA model has 18, 38, 9, and 43 percent of improvement against MODCS, MOGWO-I, MOGWO-II, and MOPSO in terms of total power consumption (TPC) and it has 6.4, 15.99, 28.15, and 15.43 dominance percent against them in term of link wastage rate (LWR), respectively.},
  archive      = {J_NCA},
  author       = {Hosseini Shirvani, Mirsaeid and Ramzanpoor, Yaser},
  doi          = {10.1007/s00521-023-08759-8},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19581-19626},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective QoS-aware optimization for deployment of IoT applications on cloud and fog computing infrastructure},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven and uncertainty-aware robust airstrip surface
estimation. <em>NCA</em>, <em>35</em>(26), 19565–19580. (<a
href="https://doi.org/10.1007/s00521-023-08779-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performances of aircraft braking control systems are strongly influenced by the tire friction force experienced during the braking phase. The availability of an accurate estimate of the current airstrip characteristics is a recognized issue for developing optimized braking control schemes. The study presented in this paper is focused on the robust online estimation of the airstrip characteristics from sensory data usually available on an aircraft. In order to capture the nonlinear dependency of the current best slip on sequential slip-friction measurements acquired during the braking maneuver, multilayer perceptron (MLP) approximators have been proposed. The MLP training is based on a synthetic data set derived from a widely used tire–road friction model. In order to achieve robust predictions, MLP architectures based on the drop-out mechanism have been applied not only in the offline training phase but also during the braking. This allowed to online compute a confidence interval measure for best friction estimate that has been exploited to refine the estimation via Kalman Filtering. Open loop and closed loop simulation studies in 15 representative airstrip scenarios (with multiple surface transitions) have been performed to evaluate the performance of the proposed robust estimation method in terms of estimation error, aircraft braking distance, and time, together with a quantitative comparison with a state-of-the-art benchmark approach.},
  archive      = {J_NCA},
  author       = {Crocetti, Francesco and Fravolini, Mario Luca and Costante, Gabriele and Valigi, Paolo},
  doi          = {10.1007/s00521-023-08779-4},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19565-19580},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-driven and uncertainty-aware robust airstrip surface estimation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimation of coconut maturity based on fuzzy neural network
and sperm whale optimization. <em>NCA</em>, <em>35</em>(26),
19541–19564. (<a
href="https://doi.org/10.1007/s00521-023-08761-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coconut water is the clear liquid found inside coconuts, famous for rehydrating after exercise or while suffering from a minor sickness. The essential issue tackled in this paper is how to estimate the appropriate stage of maturity of coconut water, which is a time-consuming task in the beverage industry since, as the coconut age increases, the coconut water flavor varies. Accordingly, to handle this issue, an adaptive model based on Fuzzy Neural Network and Sperm Whale Optimization, dubbed FNN–SWO, is developed to assess coconut water maturity. The Sperm Whale Optimization (SWO) algorithm is a meta-heuristic optimization algorithm. It is embedded in this model along with neural networks and fuzzy techniques (FNN system), which can be employed as an essential building block in the beverage industry. The proposed FNN–SWO model is trained and tested utilizing fuzzy rules with an adaptive network. In contrast, the SWO algorithm is adopted to determine the optimal weights for the fuzzy rules. Three subsets of data divided according to three levels of coconut water maturity-tender, mature, and very mature, are used to validate the combined FNN–SWO model. Depending on these three subsets of data, a comparison of the proposed FNN–SWO model has been conducted against a set of the most common conventional techniques. These techniques include Support Vector Machine, Naïve Bayes, FNN, Artificial Neural Network, as well as their embedding with other meta-heuristic optimization algorithms. For various key performance indicators, such as recall, F1-score, specificity, and accuracy, the proposed FNN–SWO model provides the best prediction outcomes compared to the current time-consuming techniques. The dominance of the proposed FNN–SWO model is evident from the final findings compared to its time-consuming peers for estimating coconut water maturity on time. As a result, the proposed FNN–SWO model is an effective heuristic for locating optimal solutions to classification problems. It can thereby be reassuringly applicable to other similar prediction problems. Additionally, it would benefit the scientific community interested in evaluating coconut water.},
  archive      = {J_NCA},
  author       = {El-Shafeiy, Engy and Abohany, Amr A. and Elmessery, Wael M. and El-Mageed, Amr A. Abd},
  doi          = {10.1007/s00521-023-08761-0},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19541-19564},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimation of coconut maturity based on fuzzy neural network and sperm whale optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep intelligent framework for software risk prediction
using improved firefly optimization. <em>NCA</em>, <em>35</em>(26),
19523–19539. (<a
href="https://doi.org/10.1007/s00521-023-08756-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the success of a software project, early and precise discrimination of software requirement risks are essential. Researchers have suggested several predictive methods based on conventional deep learning techniques, but the common factor is the high misclassification rate. Setting the appropriate hyperparameters is a complex problem in deep learning. Manual, grid and random searches are the most common methods for locating the best deep neural network hyperparameters. However, these are not the choice when experience is lacking. In this article, we proposed Deep Neural Network with Memetic firefly. The deep neural network performs classification tasks, and deep neural network hyperparameters have been optimized using a memetic firefly algorithm. Moreover, a novel perturbation operator is introduced to get rid of locally optimal solutions of the traditional firefly algorithm. The proposed method’s performance has been validated by comparing various hybrid techniques such as a deep neural network with firefly hill-climbing, a deep neural network with firefly, a deep neural network with PSO, and a deep neural network to identify the risk in software requirements. The proposed deep neural network with the memetic firefly algorithm outperforms all compared approaches with a 98.8\% accuracy. It is adaptable for accurate software risk prediction in projects.},
  archive      = {J_NCA},
  author       = {Pemmada, Suresh Kumar and Nayak, Janmenjoy and Naik, Bighnaraj},
  doi          = {10.1007/s00521-023-08756-x},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19523-19539},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep intelligent framework for software risk prediction using improved firefly optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Orthogonal learning metaheuristics for structural
optimization. <em>NCA</em>, <em>35</em>(26), 19497–19521. (<a
href="https://doi.org/10.1007/s00521-023-08743-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main aim of this article is to hybridize orthogonal experimental design (OED) in different population-based metaheuristics to make them more suitable for structural optimization problems. OED is an efficient statistics method that can predict the optimal combination of a multi-level multi-factor problem with far fewer experiments. The motivation of the current study is to design different guidance (transmission) vectors that can efficiently utilize the search information of a couple of candidate solutions and thus balance the exploration/exploitation capabilities of optimization algorithms. Furthermore, by using this method, the convergence speed and accuracy of the final results are enhanced. Four well-known metaheuristics are selected to strengthen their performance by integrating learning strategies based on OED, known as orthogonal learning (OL), in them, and their viability was validated on a set of benchmark structural optimization problems. The performances of the enhanced metaheuristics are compared with each other and their standard versions. The results are discussed based on accuracy, convergence rate, robustness, and diversity index. Furthermore, the Friedman test is utilized to rank different scenarios to investigate the best one. The results demonstrate the effectiveness of the OL to improve the metaheuristics in comparison with their basic versions and show that OL scenarios are an especially useful tool to strengthen the potency of the algorithms for the most complicated structural optimization problems.},
  archive      = {J_NCA},
  author       = {Bakhshpoori, Taha and Asadi Abadi, Arash},
  doi          = {10.1007/s00521-023-08743-2},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19497-19521},
  shortjournal = {Neural Comput. Appl.},
  title        = {Orthogonal learning metaheuristics for structural optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network robustness evaluation based on interval
analysis. <em>NCA</em>, <em>35</em>(26), 19481–19496. (<a
href="https://doi.org/10.1007/s00521-023-08737-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are widely deployed in many scenarios and have reached or exceeded human-level performance in some tasks. However, the researchers found that existing neural networks are vulnerable to attacks. One of the cases is that the network outputs the wrong result in the presence of small perturbations in the input. It indicates that the neural network does not meet the robustness. Neural networks, which do not meet robustness, will limit their application in safety-critical systems such as automatic driving and wise medical. Hence, the research on the robustness of neural networks is significant. Interval analysis is a mathematical technique used to put bounds on rounding errors and measurement errors in mathematical computation and can be used to calculate the exact output range of a real-valued function. Based on the theoretical framework of interval analysis, we define the interval extension of neural networks and prove that it includes the inclusion isotonicity and Lipschitzian property. It illustrates the feasibility of using interval extension to compute the output range of a neural network corresponding to a given input range. In order to evaluate the robustness of the neural network, we further analyze the characteristics of the neural network interval extension and design a neural network robustness evaluation method based on the greedy strategy. Experiment results on the MNIST and ACAS Xu datasets show that the method can effectively evaluate the robustness of the neural network with good time performance.},
  archive      = {J_NCA},
  author       = {Xu, Yiqun and Wei, Zhen and Li, Zhehao and Wei, Xing and Lu, Yang},
  doi          = {10.1007/s00521-023-08737-0},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19481-19496},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network robustness evaluation based on interval analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time traffic, accident, and potholes detection by deep
learning techniques: A modern approach for traffic management.
<em>NCA</em>, <em>35</em>(26), 19465–19479. (<a
href="https://doi.org/10.1007/s00521-023-08767-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practical applications of social media have raised the bar for real-time event detection all over the globe. It has been deemed useful for extracting important data that enables people across the world to access information within mere seconds of its occurrence. Among the many use cases of the aforementioned applications lies detection of issues regarding the smooth mobility of traffic on the road. Machine learning models that were developed earlier used support vector machines with Bag of Words. However, BoW (Bag of Words) suffers from problems such as the inability to manage semantic relationships between words, limited representation, and high dimensional representation. Our model developed for a similar cause fetches the required data from Twitter to make the target authorities aware of the issues like potholes, accidents, and high traffic density (congestion) of the Chandigarh tri-city area. The data collected then undergoes multiple stages of pre-processing. After that, multiple word embedding models come into play to build semantic relationships between the words and intra software jargon. The resultant is then processed through the several recently introduced deep learning based natural language processing. The current study aims to perform a comparative evaluation of the several advanced state-of-the-art classification models at the target traffic event detection activity. The developed models make a fact-based prediction to make multi-class classification into the aforementioned categories. From the comparative evaluation, it has been observed that the proposed language processing model (RoBERTa based) pipeline outperforms the existing approaches and is 97\% accurate at classifying the real-time tweets. Moreover, the proposed pipeline achieves 96\% recall at segregating the traffic events efficiently.},
  archive      = {J_NCA},
  author       = {Babbar, Sarthak and Bedi, Jatin},
  doi          = {10.1007/s00521-023-08767-8},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19465-19479},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time traffic, accident, and potholes detection by deep learning techniques: A modern approach for traffic management},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel LOF-based ensemble regression tree methodology.
<em>NCA</em>, <em>35</em>(26), 19453–19463. (<a
href="https://doi.org/10.1007/s00521-023-08773-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of digitilization, numeric prediction has become a prominent problem in various fields including finance, engineering, industry, and medicine. Among several machine learning methods, regression tree is a widely preferred method due to its simplicity, interpretability and robustness. Motivated by this, we introduce a novel ensemble regression tree based methodology, namely LOF-BRT+OR. The proposed methodology is an integrated solution approach with outlier removal, regression tree and ensemble learning. First, irregular data points are removed using local outlier factor (LOF), which measures the degree of being an outlier for each point. Next, a novel regression tree with LOF weighted node model is introduced. In the proposed node model, the weights of the points in the nodes are determined according to their surrounding neighborhood, as a function of LOF values and neighbor ranks. Finally, in order to increase the prediction performance, ensemble learning is adopted. In particular, bootstrap aggregation is used to generate multiple regression trees with LOF weighted node model. The experimental study shows that the proposed methodology yields the best root mean squared error (RMSE) values in five out of nine data sets. Also, the non-parametric tests demonstrate the statistical significance of the proposed approach over the benchmark methods. The proposed methodology can be applicable to various prediction problems.},
  archive      = {J_NCA},
  author       = {Öngelen, Gözde and İnkaya, Tülin},
  doi          = {10.1007/s00521-023-08773-w},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19453-19463},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel LOF-based ensemble regression tree methodology},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binary improved white shark algorithm for intrusion
detection systems. <em>NCA</em>, <em>35</em>(26), 19427–19451. (<a
href="https://doi.org/10.1007/s00521-023-08772-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion Detection (ID) is an essential task in the cyberattacks domain built to secure Internet applications and networks from malicious actors. The main shortcoming of the current Intrusion Detection Systems (IDSs) is their attack detection performance because the existing solutions fail to detect the threats efficiently. Therefore, improving the prediction model of the IDS can improve its performance. Several studies suggest improving the Machine Learning (ML)-based IDS prediction models by selecting the most informative features from the security data before utilizing it in the ML-IDS model. Thus, meta-heuristic algorithms such as White Shark Optimizer (WSO) are adapted to deal with such feature selection problems. For the IDS prediction model, in this paper, the WSO algorithm is improved to cope with the binary domain of the feature selection task as follows: Firstly, two transfer functions are used to map the continuous domain into binary. Secondly, the modified K-means algorithm is proposed to assess building the initial population with a high level of diversity. Finally, several crossover operators are utilized to improve the evolution process of the binary WSO. The three improved versions are BIWSO1 which is WSO with transfer functions, BIWSO2, which is BIWSO1 with a modified k-means algorithm, and BIWSO3, which is BIWSO2 with crossover operators. The proposed versions of BIWSO are tested using twelve public real-world IDS and IoT datasets. Comparative evaluations against well-established meta-heuristic algorithms are conducted where the BIWSO3 proves its efficiency in terms of classification accuracy, precision, recall, and F1 measurements. For further validation, statistical evidence using Friedman’s, Wilcoxon’s, and Mann–Whitney U tests has been conducted where BIWSO3 proves its performance at a remarkably significant level.},
  archive      = {J_NCA},
  author       = {Alawad, Noor Aldeen and Abed-alguni, Bilal H. and Al-Betar, Mohammed Azmi and Jaradat, Ameera},
  doi          = {10.1007/s00521-023-08772-x},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19427-19451},
  shortjournal = {Neural Comput. Appl.},
  title        = {Binary improved white shark algorithm for intrusion detection systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic detection of colorectal polyps with mixed
convolutions and its occlusion testing. <em>NCA</em>, <em>35</em>(26),
19409–19426. (<a
href="https://doi.org/10.1007/s00521-023-08762-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual detection of colorectal polyps in the colonoscopy videos during diagnosis of colorectal cancer can be challenging due to the large no. of sequential frames and high chances of false positive rate. So, researchers are working to develop an automatic computer-aided decision system to successfully detect colorectal polyps for early diagnosis of colorectal cancer. This work proposes an end-to-end, automatic colorectal polyp detection architecture called ‘Window-based Detection after Mixed Convolutions Polyp Identification (WD-MCPI)’. It has been trained and validated on the Etis-Larib, CVC-Colon, and Kvasir v1 data. Varying sequential and non-sequential colonoscopy frames and developed occlusive frames have been considered in the test set. Systematic hyperparameter tuning of various convolutional layers, optimizers, kernel size, color space, image dimension, and filter size has been performed to build the proposed architecture. The robustness and explainability of the proposed architecture have been estimated through various evaluation metrics, feature mapping, ablation studies, occlusion testing, and class activation mapping. The proposed work has achieved an overall accuracy, precision, recall, specificity, F1 score, and area-under-curve score up to 94.23, 91.16, 94.00, 92.67, 91.75, and 92.53\%, respectively. An average test set accuracy up to 93\% has been achieved on a newly developed test set named ‘Gastrointestinal atlas-Colon Polyp’ (available here). Upon comparison with the existing state-of-the-art works and vanilla inception v3 architecture, the proposed architecture has been tested on varying colonoscopy frames, achieving optimum results with reduced trainable parameters, and inference time per epoch.},
  archive      = {J_NCA},
  author       = {Handa, Palak and Goel, Nidhi and Indu, Sreedevi and Gunjan, Deepak},
  doi          = {10.1007/s00521-023-08762-z},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19409-19426},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic detection of colorectal polyps with mixed convolutions and its occlusion testing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An innovative cluster-based power-aware protocol for
internet of things sensors utilizing mobile sink and particle swarm
optimization. <em>NCA</em>, <em>35</em>(26), 19365–19408. (<a
href="https://doi.org/10.1007/s00521-023-08752-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, the Internet of Things (IoT) has become a necessary technology increasingly applied in many fields of research and development, such as smart cities and homes, health, industry, agriculture, security, and surveillance. In IoT systems, the use of sensors is considered an important common manner in which all devices communicate with a wireless sensor network to form an information system that comprises a massive number of sensor nodes performing accurately to create a smart decision-making method. However, these sensor nodes might be employed in severe environments, where replacing or recharging their batteries is considered an impossible mission. Simultaneously, the limitation of energy resources in sensor nodes presents a challenging issue that reduces the lifespan of individual nodes and the overall network system as a result of energy depletion. These obstacles necessitate energy-efficient routing protocols. According to the literature review, various routing protocols have been introduced, especially those that use clustering techniques. However, they have many drawbacks due to the way of selecting the cluster head (CH), which results in consuming energy dramatically, and consequently shortening the network lifetime. Additionally, instead of using the static sink, which was inefficient in collecting data, many researchers studied the behavior of the mobile sink (MS), which also has many downsides that negatively impact network performance. This paper presents a novel energy-conscious protocol for clusters that incorporates an adaptive movement for mobile stations and utilizes particle swarm optimization (PSO). The circular network area is divided into clusters, each of which has an elected CH based on the PSO technique. The MS aims to distribute energy among nodes to prevent hotspot issues. To achieve better coverage, it moves in a circular pattern with a constant angular velocity, starting from the center of the network area and moving forward and backward along the radius of the network. This research conducts intensive simulations, which run on MATLAB R2018, to assess the performance of our proposed protocol and compare its results with those of pertinent works. The results obtained are encouraging and demonstrate that the protocol we proposed surpasses its counterparts by significantly extending the lifespan of the network.},
  archive      = {J_NCA},
  author       = {Darabkh, Khalid A. and Amareen, Asma’a B. and Al-Akhras, Muna and Kassab, Wafa’a K.},
  doi          = {10.1007/s00521-023-08752-1},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19365-19408},
  shortjournal = {Neural Comput. Appl.},
  title        = {An innovative cluster-based power-aware protocol for internet of things sensors utilizing mobile sink and particle swarm optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A decoupled generative adversarial network for anterior
cruciate ligament tear localization and quantification. <em>NCA</em>,
<em>35</em>(26), 19351–19364. (<a
href="https://doi.org/10.1007/s00521-023-08776-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anterior cruciate ligament (ACL) is one of the most commonly injured ligaments in the knee. Accurate tear quantification of ACL plays a crucial role in the treatment of patients. This study aims to propose an auxiliary diagnosis scheme based on deep learning (DL) to assist orthopedic surgeons in automatic ACL tear localization and quantification. The proposed scheme adopted a decoupled generative adversarial network (GAN) to generate the distal residual mask and the normal ACL mask, thereby achieving ACL tear classification. Since the edge information of ACL is important in tear classification, we built the decoupled GAN by decoupling the body and edge parts of masks with different supervision and improved its segmentation performance through a histogram equalization for enhancing image quality, an atrous spatial pyramid pooling (ASPP) module and a distribution module for improving feature representations as well as an effective channel attention mechanism. The experiments showed that the decoupled GAN model achieved promising results in the test set and demonstrated its feasibility in ACL segmentation. The proposed scheme also achieved good results in ACL tear quantification (accuracy: 0.929) and yielded a comparable performance with a senior orthopedic surgeon. This work can provide valuable diagnosis evidence of ACL tear for orthopedic surgeons and is expected to apply in clinical practice.},
  archive      = {J_NCA},
  author       = {Wang, Jiaoju and Luo, Jiewen and Hounye, Alphonse Houssou and Wang, Zheng and Liang, Jiehui and Cao, Yangbo and Feng, Jing and Tan, Lingjie and Wang, Zhengcheng and Kong, Menglin and Hou, Muzhou and He, Jinshen},
  doi          = {10.1007/s00521-023-08776-7},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19351-19364},
  shortjournal = {Neural Comput. Appl.},
  title        = {A decoupled generative adversarial network for anterior cruciate ligament tear localization and quantification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributional reinforcement learning for run-to-run control
in semiconductor manufacturing processes. <em>NCA</em>, <em>35</em>(26),
19337–19350. (<a
href="https://doi.org/10.1007/s00521-023-08760-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has been preliminarily applied to run-to-run (RtR) control. However, the existing works have mainly conducted on shift and drift disturbances in the chemical mechanical polishing (CMP) process and have not taken the non-stationary time-series disturbances into full consideration. Inspiring from the powerful self-learning mechanism of DRL, a new distributional reinforcement learning controller, quantile option structure deep deterministic policy gradient (QUOTA-DDPG), is designed to generate control policies without precise numerical model in this work. Specifically, the procedure for adjusting the recipe is formulated as a Markovian decision process. Meanwhile, state, action and reward are reasonably designed. Regarding QUOTA-DDPG, an option is first determined based on the option strategy, and the action is decided via intra-option policy at each time step. Moreover, target network and empirical replay mechanisms are utilized to enhance the stability and trainability. Simulations demonstrate that the presented approach outperforms the existing methods regarding the disturbance compensation and target tracking. The application of QUOTA-DDPG controller enriches the development of semiconductor smart manufacturing.},
  archive      = {J_NCA},
  author       = {Ma, Zhu and Pan, Tianhong},
  doi          = {10.1007/s00521-023-08760-1},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19337-19350},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distributional reinforcement learning for run-to-run control in semiconductor manufacturing processes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A generative adversarial active learning method for
mechanical layout generation. <em>NCA</em>, <em>35</em>(26),
19315–19335. (<a
href="https://doi.org/10.1007/s00521-023-08751-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Layout generation is frequently encountered in the field of mechanical design. The direct application of generative adversarial network, which was originally used to generate pixel-level images, usually cannot guarantee the interrelation between components such as the non-overlap requirement. In addition, the number and the size of components cannot be precisely controlled. These all constitute the characteristics of mechanical layout. To address the above problems, we propose a hierarchical layout generation generative adversarial network (LGGAN) for mechanical layout generation. The layout generator consists of three modules. The first is hierarchical layout generation, where the shape and distribution of components are generated separately using two neural networks. Such a hierarchical structure greatly improves the generation capacity. To reduce the accumulated noise when multiple components are added, a denoiser is included as the second module. The third module is a refinement step used to fine-tune the layouts, which adjusts the size of each component to the prescribed value. All of the three modules are neural network-based, and can be trained through backpropagation. Additionally, an active learning strategy for training the LGGAN is proposed, which allows LGGAN to converge with a small amount of training data in situations where getting a significant amount of training data is not possible. Quantitative and qualitative experiments demonstrate the effectiveness of LGGAN.},
  archive      = {J_NCA},
  author       = {Li, Kangjie and Ye, Wenjing},
  doi          = {10.1007/s00521-023-08751-2},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19315-19335},
  shortjournal = {Neural Comput. Appl.},
  title        = {A generative adversarial active learning method for mechanical layout generation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bounding convolutional network for refining object
locations. <em>NCA</em>, <em>35</em>(26), 19297–19313. (<a
href="https://doi.org/10.1007/s00521-023-08782-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection, an important task in computer vision, has achieved a conspicuous improvement. Among the methods for object detection, the one-stage detector is a simple, end-to-end, anchor-free, and straightforward deep learning pipeline. Many one-stage detectors locate the bounding box using regression, and the regression loss is the maximum among all errors. Hence, locating the bounding box accurately is one of the keys for improving the average precision (AP) for a detector. In this paper, we suggest a simple and precise locator named the bounding convolutional network (BoundConvNet) to draw “bounding features” from heatmaps to refine the object locations and apply a category-aware collaborative intersection over union (Co-IoU) loss function to optimize the bounding box regression for dealing with a problem of different class center point overlap. BoundConvNet is a head network for bounding box regression, which contains several depthwise separable dilated convolutional layers to decouple the classification task from the regression task. Extensive experiments demonstrate that BoundConvNet improves the AP of the one-stage detector CenterNet and helps the CenterNet mark the bounding box of objects more accurately. For small object detection, the AP of CenterNet is improved by 13.8\% relative on MS COCO dataset with ResNet-18 as backbone.},
  archive      = {J_NCA},
  author       = {Zhang, Shenyong and Wang, Wenmin and Li, Honglei and Zhang, Shixiong},
  doi          = {10.1007/s00521-023-08782-9},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19297-19313},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bounding convolutional network for refining object locations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of brain space-occupying lesions using quantum
machine learning. <em>NCA</em>, <em>35</em>(26), 19279–19295. (<a
href="https://doi.org/10.1007/s00521-023-08717-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain is a complex organ of the body. Any abnormality in brain cells can affect the function of the human body. Brain space-occupying lesions include tumors, abscesses, and cysts. Brain MRI images are noisy that degrades the detection accuracy. Therefore, 32-layers-denoise neural network is proposed on the selected hyper-parameters to improve the image quality. To classify the healthy/abnormal MRI slices, a novel seven layers Javeria Quanvolutional Neural Network model is proposed named as J. Qnet, that consists of the four dense, two drop-out, and one flattened layers. To localize the classified images, the open exchange neural network (ONNX)-YOLOv2tiny model is proposed based on the selected layers that is trained on the optimal hyper-parameters. To segment the localized images more accurately, 34 layers of U-net model are proposed, which is trained from the scratch using selected hyperparameters. The proposed model is evaluated on locally acquired images and BRATS-2020 dataset providing an accuracy of 0.96 and 0.98, respectively. Overall, the proposed method performed better as compared to the existing research works that authenticate the novelty of this work.},
  archive      = {J_NCA},
  author       = {Amin, Javaria and Anjum, Muhammad Almas and Gul, Nadia and Sharif, Muhammad},
  doi          = {10.1007/s00521-023-08717-4},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19279-19295},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of brain space-occupying lesions using quantum machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepGraviLens: A multi-modal architecture for classifying
gravitational lensing data. <em>NCA</em>, <em>35</em>(26), 19253–19277.
(<a href="https://doi.org/10.1007/s00521-023-08766-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gravitational lensing is the relativistic effect generated by massive bodies, which bend the space-time surrounding them. It is a deeply investigated topic in astrophysics and allows validating theoretical relativistic results and studying faint astrophysical objects that would not be visible otherwise. In recent years, machine learning methods have been applied to support the analysis of the gravitational lensing phenomena by detecting lensing effects in datasets consisting of images associated with brightness variation time series. However, the state-of-the-art approaches either consider only images and neglect time-series data or achieve relatively low accuracy on the most difficult datasets. This paper introduces DeepGraviLens, a novel multi-modal network that classifies spatio-temporal data belonging to one non-lensed system type and three lensed system types. It surpasses the current state-of-the-art accuracy results by $$\approx 3\%$$ to $$\approx 11\%$$ , depending on the considered data set. Such an improvement will enable the acceleration of the analysis of lensed objects in upcoming astrophysical surveys, which will exploit the petabytes of data collected, e.g., from the Vera C. Rubin Observatory.},
  archive      = {J_NCA},
  author       = {Pinciroli Vago, Nicolò Oreste and Fraternali, Piero},
  doi          = {10.1007/s00521-023-08766-9},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19253-19277},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepGraviLens: A multi-modal architecture for classifying gravitational lensing data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble feature selection for single-label text
classification: A comprehensive analytical study. <em>NCA</em>,
<em>35</em>(26), 19235–19251. (<a
href="https://doi.org/10.1007/s00521-023-08763-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the large amount of textual data, text classification is a crucial problem in the modern era. In text classification studies, feature selection is one of the most crucial processes because it has a big impact on classification accuracy. Many feature selection techniques are suggested in the field of text classification in the literature. Each method sorts the features by assigning a score according to its algorithm. Then, the classification process is performed by selecting top-N features. However, the feature order for each method is different from each other. Each method selects by assigning a high score to the features that are important according to its algorithm, while it does not select by assigning a low score to the insignificant features. However, each method selects different distinguishing features according to its algorithm. With combinations of these distinguishing features, a higher performance classification process can be achieved. So, the classification process is to combine the features in a different order according to each method in this study. Thus, it will be observed which methods are successful or unsuccessful when combined. In addition, it was observed that the methods chose how many different features from each other. Accordingly, the classification is made by combining the features of different sizes and combining two local and two global feature selection methods. Numerous studies using three benchmark datasets have shown that the combination of feature selection approaches performs better than any single feature selection method used alone. However, some combinations have lower performance rates than individual methods. Thus, a comprehensive study was carried out in text classification domain.},
  archive      = {J_NCA},
  author       = {Parlak, Bekir},
  doi          = {10.1007/s00521-023-08763-y},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19235-19251},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ensemble feature selection for single-label text classification: A comprehensive analytical study},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effects of data time lag in a decision-making system using
machine learning for pork price prediction. <em>NCA</em>,
<em>35</em>(26), 19221–19233. (<a
href="https://doi.org/10.1007/s00521-023-08730-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spain is the third-largest producer of pork meat in the world, and many farms in several regions depend on the evolution of this market. However, the current pricing system is unfair, as some actors have better market information than others. In this context, historical pricing is an easy-to-find and affordable data source that can help all agents to be better informed. However, the time lag in data acquisition can affect their pricing decisions. In this paper, we study the effect that data acquisition delay has on a price prediction system using multiple prediction algorithms. We describe the integration of the best proposal into a decision support system prototype and test it in a real-case scenario. Specifically, we use public data from the most important regional pork meat markets in Spain published by the Ministry of Agriculture with a two-week delay and subscription-based data of the same markets obtained on the same day. The results show that the error difference between the best public and data subscription models is 0.6 Euro cents in favour of the data without delay. The market dimension makes these differences significant in the supply chain, giving pricing agents a better tool to negotiate market prices.},
  archive      = {J_NCA},
  author       = {Suaza-Medina, Mario E. and Zarazaga-Soria, F. Javier and Pinilla-Lopez, Jorge and Lopez-Pellicer, Francisco J. and Lacasta, Javier},
  doi          = {10.1007/s00521-023-08730-7},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19221-19233},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effects of data time lag in a decision-making system using machine learning for pork price prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DRI-UNet: Dense residual-inception UNet for nuclei
identification in microscopy cell images. <em>NCA</em>, <em>35</em>(26),
19187–19220. (<a
href="https://doi.org/10.1007/s00521-023-08729-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclei segmentation has great significance in biomedical applications as the preliminary step for disease diagnosis and treatment analysis. In this study, we propose a model for automated nuclei identification of varying cell shapes and types from microscopy images. Identifying nuclei helps to understand the underlying mechanism of various diseases in their early stages and provides solutions to enable faster cures. The foremost aim of the study is to develop a lightweight model, capable of segmenting varied shapes and sizes. The proposed architecture exploits multi-scale low-level features following dense high-level feature extraction with multi-feature fusion and special skip connections resulting in enhanced learning capability. The multi-scale feature extractor module extracts low-level information which is further processed using attention-based dense connections to extract semantically meaningful information. The special short-skip residual connections replacing long-skip connections reduced the semantic gap between encoder–decoder features. Moreover, the context encoder module extracts higher-level contextual information of different receptive fields using dilated convolutions making the model robust to different shapes and sizes. The higher-level feature maps propagate upward the decoder connections following the shared attention mechanism of an encoder to decoder features to reconstruct a better segmentation map. Moreover, the evaluation scheme following the proposed test-time augmentation operations improved the mean segmentation performance. The experiments on KDSB18, Synthetic cells, Triple-negative breast cancer (TNBC), MoNuSeg, CryoNuSeg, and BUS datasets demonstrate the suitability of the model for the nuclei segmentation tasks. The DRI-UNet model holds good segmentation performance outperforming baseline architecture by 8.12\%, 4.71\%, 10.19\%, 2.46\%, 3.14\%, 8.91\%, and 9.32\% on KDSB18, synthetic cells, TNBC, MoNuSeg, CryoNuSeg, CVC-ClinicDB, and BUS datasets, respectively. We further conducted generalization tests of the proposed model for cross-dataset validation, and two independent MIS datasets confirm model effectiveness for nuclei cell and biomedical image segmentation.},
  archive      = {J_NCA},
  author       = {Sharma, Ajay and Mishra, Pramod Kumar},
  doi          = {10.1007/s00521-023-08729-0},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19187-19220},
  shortjournal = {Neural Comput. Appl.},
  title        = {DRI-UNet: Dense residual-inception UNet for nuclei identification in microscopy cell images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting nordic electricity spot price using deep
learning networks. <em>NCA</em>, <em>35</em>(26), 19169–19185. (<a
href="https://doi.org/10.1007/s00521-023-08734-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a common data-driven method, artificial neural networks have been widely used in electricity spot price forecasting. To improve the accuracy of short-term forecasts, this paper proposes an optimized artificial neural network model for monthly electricity spot prices forecasting. A genetic algorithm is applied to regulate the weights and biases parameters of the artificial neural network structure. This study uses various historical dataset at monthly periods selected from Nordic electricity spot prices. For efficiency comparison, one-step ahead forecast method based on Schwartz-Smith stochastic model and two other prediction models, artificial neural network trained by Levenberg–Marquardt and particle swarm optimization algorithms are also presented. The comparison results show that the prediction model based on the genetic optimization algorithm is more accurate than the other prediction models. The proposed forecasting model can be considered as an alternative technique for the electricity spot price forecasting in the Nordic regions.},
  archive      = {J_NCA},
  author       = {Mehrdoust, Farshid and Noorani, Idin and Belhaouari, Samir Brahim},
  doi          = {10.1007/s00521-023-08734-3},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19169-19185},
  shortjournal = {Neural Comput. Appl.},
  title        = {Forecasting nordic electricity spot price using deep learning networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel encoder–decoder wavelet model for multifocal region
segmentation of TAO facial images. <em>NCA</em>, <em>35</em>(26),
19145–19167. (<a
href="https://doi.org/10.1007/s00521-023-08727-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thyroid-associated ophthalmopathy (TAO) is an organ-specific autoimmune disease that has a significant impact on patients` life and health of. Clinically, the Clinical Activity Score (CAS) is one of the crucial methods for the early diagnosis of TAO. However, due to the diversity of TAO symptoms, utilizing medical expertise to artificially obtain CAS scores is challenging and highly dependent on personal subjectivity. Therefore, accurate identification of TAO regions segmented by scientific techniques is one of the essential prerequisites for the objective acquisition of the CAS scores. In this study, an encoder–decoder wavelet model (EDWM) with multiple-scale cascaded attention mechanism (MCAM) and residual deformable convolution (RDC) was proposed for multifocal region segmentation of TAO from facial images. The proposed method employs the discrete wavelet transform (DWT) to construct an encoder structure for the coarse feature extraction of the diseased regions. The inverse wavelet transform (IWT) is designed to build a decoder structure for resolution recovery. Meanwhile, the MCAM is developed to extract finer features of adjacent wavelet scales in the encoder structure by suppressing the background and focusing on the coarse segmentation of the diseased regions. The RDC is ultimately utilized for enlargement of arbitrary receptive fields and the accurate multi-segmentation task in different regions. In comparison with other selected benchmark models, the EDWM has, respectively, achieved state-of-the-art segmentation performance with 93.12\% and 0.804 of the precision and the MIoU when tested on the images of 600 TAO patients. Since the EDWM is characterized by compact structure, interpretability, and strong feature extraction capability, it can provide a much more reliable and scientific basis for the early detection and diagnosis of TAO, reducing reliance on subjective experience in obtaining CAS scores.},
  archive      = {J_NCA},
  author       = {Zhu, Haipeng and Zhou, Huifang and He, Hong and Chen, Jiayu and Song, Xuefei and Li, Kunhao and Zhou, Lei},
  doi          = {10.1007/s00521-023-08727-2},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19145-19167},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel encoder–decoder wavelet model for multifocal region segmentation of TAO facial images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural compensator for PI soil moisture control.
<em>NCA</em>, <em>35</em>(26), 19131–19144. (<a
href="https://doi.org/10.1007/s00521-023-08723-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatial and temporal variability of a cultivated soil, with technified irrigation systems, requires adaptive control systems to the varying conditions of the water–soil–crop intersystem. Therefore, an adaptive control based on a Radial Basis Function Neural Network (RBF-NN) is proposed in this paper. A static Proportional-Integral (PI) controller was tuned without modifying its parameters by adding a compensation based on RBF-NNs. In this way, the dynamic variation is approximated in real time by means of a RBF-NN. The controller is tested in simulation from a model of water distribution in the soil with extraction by a crop. The results obtained with this method are compared with a traditional Proportional-Integral-Derivative (PID) controller. The comparisons are made taking into account compromise between the amount of water applied and irrigation frequency to keep soil moisture values within the allowed limits. Water savings of 20\% and a reduced valve activations 2 times less than the traditional PID were achieved. Finally, the behavior of the controller in the event of disturbances was evaluated, verifying the rejection it produces in the face of these eventualities.},
  archive      = {J_NCA},
  author       = {Gomez, Juan A. and Rossomando, Francisco and Capraro, Flavio and Soria, Carlos},
  doi          = {10.1007/s00521-023-08723-6},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19131-19144},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural compensator for PI soil moisture control},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep intelligent transportation system for travel time
estimation on spatio-temporal data. <em>NCA</em>, <em>35</em>(26),
19117–19129. (<a
href="https://doi.org/10.1007/s00521-023-08726-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart cities can effectively improve urban life quality. But, with the rise in population size, there is an increase in the use of vehicles for transportation. In smart city development, traffic control and route planning are the primary tasks to address the problem of travel time estimation. It has become complex due to concerns of wrapped spatio-temporal data on dynamic real-time traffic conditions. The existing methods failed to estimate travel time efficiently due to not considering the spatio-temporal features and lack of computing resources. There is a need for a system like intelligent transportation system to monitor and accurately predict traffic flow to avoid traffic congestion and reduce the impact on the ecological system. This paper developed a novel hybrid deep learning model to estimate optimized travel time and possible trajectories. In this work, U-Net used to reduce the number of feature points for each temporal data and GNN is used to build the graph with connectivity between vehicular nodes. This hybrid model helps us predict traffic flow and aims to estimate accurate travel time from one location (node) to another. The model’s performance is evaluated on the standard benchmark datasets Q-Traffic, TaxiBJ, and Chengdu. The experimental results show that the proposed framework significantly improves performance in extracting travel patterns and provides an optimal route with an estimated travel time than existing methods with RMSE 4\%, MAE 20.49\%, and MAPE 18\%. The proposed model has accurately predicted the estimation of travel time of the vehicle for the given urban traffic data.},
  archive      = {J_NCA},
  author       = {Vankdoth, Srinivasa Rao and Arock, Michael},
  doi          = {10.1007/s00521-023-08726-3},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19117-19129},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep intelligent transportation system for travel time estimation on spatio-temporal data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent tuning scheme with a master/slave approach
for efficient control of the automatic voltage regulator. <em>NCA</em>,
<em>35</em>(26), 19099–19115. (<a
href="https://doi.org/10.1007/s00521-023-08740-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new master/slave model driven, and an optimization algorithm-based proportional–integral–derivative (PID) plus second-order derivative (PIDD2) controller is proposed in this work for a stable and efficient operation of an automatic voltage regulator (AVR) system. In this context, an ideal reference model of Bode is used as a master model. The new improved optimization algorithm is constructed via integrating the Lévy flight mechanism into Runge–Kutta optimizing algorithm. This algorithm optimally tunes the PIDD2 controller with the aid of a cost function known as integral of squared error. The latter control mechanism forms the slave model. As the PIDD2 controller and the intelligent tuning algorithm attempt to follow the response dictated by the ideal reference model of the master model, a significant improvement is achieved for the efficiency and the stability of the AVR system. The proposed master/slave driven, and intelligent optimization algorithm-based PIDD2 control approach presents more excellent transient response (steady state error, rise time, settling time, peak time, percent overshoot), frequency response (gain margin, phase margin and bandwidth), robustness and stability. Nonideal conditions such as measurement noise and the saturation at the input of the generator in the AVR are also considered to demonstrate the efficacy of the proposed method. Furthermore, the existing fifty-eight techniques in the literature are also used for performance comparison in order to present the more excellent efficiency of the proposed method from a wider perspective.},
  archive      = {J_NCA},
  author       = {Izci, Davut and Ekinci, Serdar and Mirjalili, Seyedali and Abualigah, Laith},
  doi          = {10.1007/s00521-023-08740-5},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19099-19115},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligent tuning scheme with a master/slave approach for efficient control of the automatic voltage regulator},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep recurrent q-learning for energy-constrained coverage
with a mobile robot. <em>NCA</em>, <em>35</em>(26), 19087–19097. (<a
href="https://doi.org/10.1007/s00521-023-08735-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of coverage of an environment with an energy-constrained robot in the presence of multiple charging stations. As the robot’s on-board power supply is limited, it might not have enough energy to cover all the points in the environment with a single charge. Instead, it will need to stop at one or more charging stations to recharge its battery intermittently. The robot cannot violate the energy constraint, i.e., visit a location with negative available energy. To solve this problem, we propose a deep Q-learning framework that produces a policy to maximize the coverage and minimize the budget violations. Our proposed framework also leverages the memory of a recurrent neural network (RNN) to better suit this multi-objective optimization problem. We have tested the presented framework within a $$16 \times 16$$ grid environment having different charging station layouts and various obstacle configurations. Results show that our proposed method finds feasible solutions while performing favorably against two comparable techniques.},
  archive      = {J_NCA},
  author       = {Zellner, Aaron and Dutta, Ayan and Kulbaka, Iliya and Sharma, Gokarna},
  doi          = {10.1007/s00521-023-08735-2},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19087-19097},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep recurrent Q-learning for energy-constrained coverage with a mobile robot},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FireClassNet: A deep convolutional neural network approach
for PJF fire images classification. <em>NCA</em>, <em>35</em>(26),
19069–19085. (<a
href="https://doi.org/10.1007/s00521-023-08750-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In these recent years, the world has been faced with fires’ outbreak, which represented the most serious problem causing huge casualties and considerable destructions. It is therefore essential to early detect fire in video surveillance scenes accurately and reliably in order to overcome the common weaknesses of the available flame detection methods. Nowadays, exploring the recent deep learning (DL)-based methods within the modern surveillance systems has become a great challenge. Thereby, a novel DL-based approach is introduced for fire images detection in this paper. It is based on a convolutional neural network architecture (CNN), designed from scratch and named Fire Classification Network “FireClassNet.” Firstly, the input frames are preprocessed to highlight fire regions. Then, they are fed into the proposed “FireClassNet” in order to train the classification model. The presented network includes small number of layers when compared to existing CNNs, resulting in fewer parameters number. Experiments show the effectiveness of the produced model on the constructed dataset in terms of improving the accuracy which reaches 99.73\%. It is also demonstrated that the developed model is able to clearly outperform the related methods and the baseline CNN architectures for fire frames classification.},
  archive      = {J_NCA},
  author       = {Daoud, Zeineb and Ben Hamida, Amal and Ben Amar, Chokri},
  doi          = {10.1007/s00521-023-08750-3},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19069-19085},
  shortjournal = {Neural Comput. Appl.},
  title        = {FireClassNet: A deep convolutional neural network approach for PJF fire images classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved arabic image captioning model using feature
concatenation with pre-trained word embedding. <em>NCA</em>,
<em>35</em>(26), 19051–19067. (<a
href="https://doi.org/10.1007/s00521-023-08744-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic captioning of images contributes to identifying features of multimedia content and helps in the detection of interesting patterns, trends, and occurrences. English image captioning has recently made incredible progress; however, Arabic image captioning is still lagging. In the field of machine learning, Arabic image-caption generation is generally a very difficult problem. This paper presents a more accurate model for Arabic image captioning by using transformer models in both the encoder and decoder phases as feature extractors from images in the encoder phase and a pre-trained word embedding model in the decoder phase. The models are demonstrated, and all of them are implemented, trained, and tested on Arabic Flickr8k datasets. For the image feature extraction subsystem, we compared using three different individual vision models (SWIN, XCIT, and ConvNexT) with concatenation to get among them the most expressive extracted feature vector of the image, and for the caption generation lingual subsystem, which is tested by four different pre-trained language embedding models: (ARABERT, ARAELECTRA, MARBERTv2, and CamelBERT), to select from them the most accurate pre-trained language embedding model. Our experiments showed that building an Arabic image captioning system that uses a concatenation of the three transformer-based models ConvNexT combined with SWIN and XCIT as an image feature extractor, combined with the CamelBERT language embedding model produces the best results among the other combinations, having scores of 0.5980 with BLEU-1 and with ConvNexT combined with SWIN the araelectra language embedding model having a score of 0.1664 with BLEU-4 which are higher than the previously reported values of 0.443 and 0.157.},
  archive      = {J_NCA},
  author       = {Elbedwehy, Samar and Medhat, T.},
  doi          = {10.1007/s00521-023-08744-1},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19051-19067},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved arabic image captioning model using feature concatenation with pre-trained word embedding},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal sensor network routing with secure network
monitoring using deep learning architectures. <em>NCA</em>,
<em>35</em>(26), 19039–19050. (<a
href="https://doi.org/10.1007/s00521-023-08753-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor network (WSN) comprises the interconnection of things or objects that are embedded with both hardware and software. The WSN is a tiny sensor with end device sensors that are connected to the Internet. To perform effective routing in the WSN efficient and reliable data collection, schemes are deployed with the routing protocol for low power and lossy networks (RPL) routing scheme for the low power and lossy network. The RPL routing scheme of the low and lossy routing protocol design for the network with the objective function. The objective function in RPL routing involved network construction and maintenance through hop count. The RPL scheme uses the destination-oriented directed acyclic graph (DODAG) with the greedy election for estimation of instability in the network. The routers in the WSN are enabled with the software-defined network (SDN) server node. The process of routing comprises detection of routes between the source and the destination. This paper focused on secure routing and monitoring schemes in WSN. To improve the secure routing process in WSN, this paper developed a deep RPL-software-defined network (DRPL_SDN). The DRPL_SDN concentrated on the parent selection through RPL based on the predicted energy level of the parent node. The prediction is performed with the DRPL_SDN-based reinforcement learning method with the estimation of child count through a partial stability routing mechanism. The secure prediction is performed through the deep reinforcement learning method in DRPL_SDN for the succeeded node count for the routing stability. The security model is evaluated with the utilization of the knowledge discovery in database (KDD) dataset. With the KDD dataset, the different attacks are evaluated in the proposed DRPL_SDN model. Additionally, the proposed DRPL_SDN exhibits better load balancing with the uncontrolled node in the network. The DRPL_SDN focused on the establishment of a link in the available network path through a dynamic controlled environment. The simulation analysis expressed that DRPL_SDN achieves the minimal packet loss of 236 and the energy consumption is minimal for 6\%. The simulation examination expressed that the DRPL_SDN model exhibits the ~ 13\% higher performance than the RPL and ELDR.},
  archive      = {J_NCA},
  author       = {Qamar, Shamimul},
  doi          = {10.1007/s00521-023-08753-0},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19039-19050},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal sensor network routing with secure network monitoring using deep learning architectures},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). JAMsFace: Joint adaptive margins loss for deep face
recognition. <em>NCA</em>, <em>35</em>(26), 19025–19037. (<a
href="https://doi.org/10.1007/s00521-023-08732-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep feature learning has become crucial in large-scale face recognition, and margin-based loss functions have demonstrated impressive success in this field. These methods aim to enhance the discriminative power of the softmax loss by increasing the feature margin between different classes. These methods assume class balance, where a fixed margin is sufficient to squeeze intra-class variation equally. However, real-face datasets often exhibit imbalanced classes, where the fixed margin is suboptimal, limiting the discriminative power and generalizability of the face recognition model. Furthermore, margin-based approaches typically focus on enhancing discrimination either in the angle or cosine space, emphasizing one boundary while disregarding the other. To overcome these limitations, we propose a joint adaptive margins loss function (JAMsFace) that learns class-related margins for both angular and cosine spaces. This approach allows adaptive margin penalties to adjust adaptively for different classes. We explain and analyze the proposed JAMsFace geometrically and present comprehensive experiments on multiple face recognition benchmarks. The results show that JAMsFace outperforms existing face recognition losses in mainstream face recognition tasks. Specifically, JAMsFace advances the state-of-the-art face recognition performance on LFW, CPLFW, and CFP-FP and achieves comparable results on CALFW and AgeDB-30. Furthermore, for the challenging IJB-B and IJB-C benchmarks, JAMsFace achieves impressive true acceptance rates (TARs) of 89.09\% and 91.81\% at a false acceptance rate (FAR) of 1e-4, respectively.},
  archive      = {J_NCA},
  author       = {Khalifa, Aly and Al-Hamadi, Ayoub},
  doi          = {10.1007/s00521-023-08732-5},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19025-19037},
  shortjournal = {Neural Comput. Appl.},
  title        = {JAMsFace: Joint adaptive margins loss for deep face recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-class classifier based on principal curves.
<em>NCA</em>, <em>35</em>(26), 19015–19024. (<a
href="https://doi.org/10.1007/s00521-023-08721-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-class classification is a special multi-class approach where data from only a single class are available for classifier training. It is an approach with several applications in real-world scenarios, for instance, for outlier or novelty detection. This paper presents a new one-class classifier based on principal curves. The method exploits the good capacity of data representation of the principal curves to build a compact data representation of the known class. The use of principal curves gives the proposed method a good capacity for dealing with different shapes of the feature space, leading to better performance rates. The results showed high performances of the proposed method for synthetic and real data sets, outperforming other known one-class learning algorithms. Moreover, it builds decision boundaries more uniform around the known class than other models and is a fast method during the operating stage since classification is performed by simply mapping the Euclidean distances from data to the principal curve.},
  archive      = {J_NCA},
  author       = {de Melo Borges, Fernando Elias and Mota, Otavio Fidelis and Ferreira, Danton Diego and Barbosa, Bruno Henrique Groenner},
  doi          = {10.1007/s00521-023-08721-8},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {19015-19024},
  shortjournal = {Neural Comput. Appl.},
  title        = {One-class classifier based on principal curves},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Object detection in traffic videos: An optimized approach
using super-resolution and maximal clique algorithm. <em>NCA</em>,
<em>35</em>(26), 18999–19013. (<a
href="https://doi.org/10.1007/s00521-023-08741-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of small objects is one of the main challenges to be improved in deep learning, mainly due to the small number of pixels and scene’s context, leading to a loss in performance. In this paper, we present an optimized approach based on deep object detection models that allow the detection of a higher number of elements and improve the score obtained for their class inference. The main advantage of the presented methodology is that it is not necessary to modify the internal structure of the selected convolutional neural network model or re-training for a specific scene. Our proposal is based on detecting initial regions to generate several sub-images using super-resolution (SR) techniques, increasing the number of pixels of the elements, and re-infer over these areas using the same pre-trained model. A reduced set of windows is calculated in the super-resolved image by analyzing a computed graph that describes the distances among the preliminary object detections. This analysis is done by finding maximal cliques on it. This way, the number of windows to be examined is diminished, significantly speeding up the detection process. This framework has been successfully tested on real traffic sequences obtained from the U.S. Department of Transportation. An increase of up to 44.6\% is achieved, going from an average detection rate for the EfficientDet D4 model of 14.5\% compared to 59.1\% using the methodology presented for the first sequence. Qualitative experiments have also been performed over the Cityscapes and VisDrone datasets.},
  archive      = {J_NCA},
  author       = {García-Aguilar, Iván and García-González, Jorge and Luque-Baena, Rafael Marcos and López-Rubio, Ezequiel},
  doi          = {10.1007/s00521-023-08741-4},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18999-19013},
  shortjournal = {Neural Comput. Appl.},
  title        = {Object detection in traffic videos: An optimized approach using super-resolution and maximal clique algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classifying breast lesions in brazilian thermographic images
using convolutional neural networks. <em>NCA</em>, <em>35</em>(26),
18989–18997. (<a
href="https://doi.org/10.1007/s00521-023-08720-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the leading cause of death from malignant tumors in women worldwide. Early diagnosis is essential for the treatment and cure of patients. Breast anomalies, such as cysts, cancers and benign tumors, show an increase in blood supply in their region, causing temperature variations in the area, which can be detected through thermographic images. Thermography has shown to be a promising tool in the detection of breast cancer as it is low cost, harmless to the patient and it can be performed in younger people, whose breast tissue is denser, making the diagnosis more difficult through mammography, which is currently the gold standard for detecting this disease. The aim of this work is to develop a computer vision technique based on a convolutional neural network in order to detect breast cancer using thermographic images. Thus, a single dataset with thermographic data obtained from 97 patients was used with two different class assignments. First, the dataset was separated into three classes: benign, malignant and cyst, resulting in a global error rate of $$7.5\%$$ and a sensitivity of $$98.46\%$$ . Afterward, a binary classification was performed in order to label the images into cancer and non-cancer, obtaining a $$21.94\%$$ global error rate and $$81.66\%$$ sensitivity. The method proposed in this work had the best performance in both cases when compared with the results obtained by existing algorithms in the literature.},
  archive      = {J_NCA},
  author       = {Brasileiro, Flávia R. S. and Sampaio Neto, Delmiro D. and Silva Filho, Telmo M. and Souza, Renata M. C. R. de and Araújo, Marcus C. de},
  doi          = {10.1007/s00521-023-08720-9},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18989-18997},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classifying breast lesions in brazilian thermographic images using convolutional neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An advanced spatio-temporal convolutional recurrent neural
network for storm surge predictions. <em>NCA</em>, <em>35</em>(26),
18971–18987. (<a
href="https://doi.org/10.1007/s00521-023-08719-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research paper, we study the capability of artificial neural network models to emulate storm surge based on the storm track/size/intensity history, leveraging a database of synthetic storm simulations. Traditionally, computational fluid dynamics (CFD) solvers are employed to numerically solve the storm surge governing equations that correspond to expensive to evaluate partial differential equations (PDE). This study presents a neural network model that can predict storm surge, informed by a database of synthetic storm simulations. This model can serve as a fast and affordable emulator for the expensive CFD solvers creating the original database. The neural network model is trained with the storm track parameters used to drive the CFD solvers, and the output of the model is the time-series evolution of the predicted storm surge across multiple nodes within the spatial domain of interest. Once the model is trained, it can be deployed for further predictions based on new storm track inputs. The developed neural network model is a time-series model, composed of a long short-term memory (LSTM), a variation of recurrent neural network (RNN), further enriched with convolutional neural networks (CNNs). The convolutional neural network is employed to capture the correlation of data spatially (across the aforementioned nodes). Therefore, the temporal and spatial correlations of data are captured by the combination of the mentioned models, representing the ConvLSTM model. As the problem is a sequence to sequence time-series problem, an encoder–decoder ConvLSTM model is designed. Furthermore, the performance of the developed convolutional recurrent neural network model is improved by residual connection networks. Additional techniques are employed in the process of model training to enrich the model performance that the model can learn from the data in a more effective way. The performance of the developed model is compared with the results provided by a Gaussian process (GP) implementation, representing a state-of-the-art alternative for establishing time-series emulation of storm surge predictions. The results show that the proposed convolutional recurrent neural network outperforms the GP implementation for the examined synthetic storm database.},
  archive      = {J_NCA},
  author       = {Adeli, Ehsan and Sun, Luning and Wang, Jianxun and Taflanidis, Alexandros A.},
  doi          = {10.1007/s00521-023-08719-2},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18971-18987},
  shortjournal = {Neural Comput. Appl.},
  title        = {An advanced spatio-temporal convolutional recurrent neural network for storm surge predictions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deploying deep learning networks based advanced techniques
for image processing on FPGA platform. <em>NCA</em>, <em>35</em>(26),
18949–18969. (<a
href="https://doi.org/10.1007/s00521-023-08718-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) have emerged as a dominant deep learning technique in various fields, including image processing, computer vision, and intelligent decision-making on embedded devices. Although the underlying structure is simple, the high computation and memory requirements pose significant challenges. To address this issue, low-precision representations of neurons, inputs, model parameters, and activations have become a promising solution. These reduced-precision models offer scalability in performance, storage, and power efficiency while sacrificing some accuracy. By leveraging reconfigurable hardware such as FPGAs-SoC, deep learning systems can take advantage of low-precision inference engines while achieving the desired accuracy and balancing performance, power consumption, and programmability. Despite the high redundancy and excellent classification accuracy provided by CNN, the increasing model size makes it challenging to execute applications on embedded FPGAs. However, recent studies have shown that high levels of accuracy can still be achieved even when weight and activation are scaled down from floating-point (FP) to binary values using approaches such as quantized neural networks (QNN) and binarized neural networks (BNN). In this paper, we review recent works that have utilized binarization and quantization frameworks to explore design space and automate the building of fully customizable inference engines for image processing on FPGAs.},
  archive      = {J_NCA},
  author       = {Ghodhbani, Refka and Saidani, Taoufik and Zayeni, Hafedh},
  doi          = {10.1007/s00521-023-08718-3},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18949-18969},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deploying deep learning networks based advanced techniques for image processing on FPGA platform},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust DNN model for text-independent speaker
identification using non-speaker embeddings in diverse data conditions.
<em>NCA</em>, <em>35</em>(26), 18933–18947. (<a
href="https://doi.org/10.1007/s00521-023-08736-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has provided many advantages including the ability to extract features from the voice samples and represents the data in a more decisive mode. In speaker identification, many studies have been done to extract more and more meaningful speaker embeddings to improve the system performance. These models perform quite satisfactorily under clean and unambiguous data conditions but with noise and non-speech segments, the functioning of these systems drastically drops down. For real-world scenarios, class noise is more significant as compared to attribute noise for classification problems. The same instances in a sample with different class labels and different classes with similar instances are referred to as class noise. The non-speech regions in different speaker samples carry the same properties and hinder the classification process. We have observed that this non-speaker information (present in noise and non-speech segments) plays a crucial role in the operation of a system. This paper emphasizes the non-speaker embeddings which are very essential for developing an effective model. But in this direction, sufficient research has not yet been done. In this study, we concentrate on this problem and analyses the effect of non-speaker embeddings on the speaker identification process. We have introduced non-speaker classes to solve this issue by learning the non-speaker parameters. Two state-of-art methods, convolutional neural network (CNN), and SincNet with non-speaker embeddings are analyzed to check the performance. The models are trained on non-speaker classes (like silence and noise) along with individual speaker classes resulting in improved system performance with respect to baseline CNN and the SincNet model. We also compare the performance of our approach with the hand-crafted feature (MFCC and FBANK)-based speaker identification process. Here, also, we observed a substantial amount of improvement in classification by our approach. Learning the non-speaker embeddings improve the system performance because the misclassified non-speaker segments are addressed by our approach. For this analysis, speaker data are taken from the LibriSpeech dataset, and non-speaker data are taken from NOISEX-92(Synthetic noise), TESDHE (Natural noise), and Silent CD (Silence) databases.},
  archive      = {J_NCA},
  author       = {Shome, Nirupam and Saritha, Banala and Kashyap, Richik and Laskar, Rabul Hussain},
  doi          = {10.1007/s00521-023-08736-1},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18933-18947},
  shortjournal = {Neural Comput. Appl.},
  title        = {A robust DNN model for text-independent speaker identification using non-speaker embeddings in diverse data conditions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A parallel multi-objective imperialist competitive algorithm
to solve the load offloading problem in mobile cloud computing.
<em>NCA</em>, <em>35</em>(26), 18905–18932. (<a
href="https://doi.org/10.1007/s00521-023-08714-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is a modern architecture for performing complex and immense processes. It consists of configurable computational resource sets that communicate with each other through communication networks. With the advent of the cloud computing architecture and increasing its applications for mobile devices, the growth rate of mobile data has proliferated exponentially. Consequently, processing the tasks of mobile users has become difficult due to the limitations of these devices, such as low computing power and low capacity. Therefore, the idea of mobile cloud computing (MCC) for mobile devices using cloud-based storage and computing resources was introduced. In MCC, processing information is transferred from the user&#39;s mobile devices to the cloud servers. This process is known as the tasks offloading and scheduling of mobile users. In this case, the task execution time, CPU power consumption, network bandwidth, and task allocation time must be specified. Due to many tasks and different resources, the process of task offloading and scheduling is considered a challenging subject in the field of MCC. Therefore, in this paper, a multi-objective parallel imperialist competitive algorithm (MPICA) is proposed. The main objective of this parallel algorithm is to reduce the algorithm&#39;s execution time for searching the problem space, reducing processing time, reducing energy consumption, and improving load balance. The simulation results of the proposed algorithm represent that the parallelization of the imperialist competitive algorithm (ICA) has a significant effect on reducing the execution time of the algorithm. In general, the proposed algorithm performs better than the state-of-the-art algorithms based on the proposed criteria.},
  archive      = {J_NCA},
  author       = {Alipour, Sara and Saadatfar, Hamid and Poor, Mahdi Khazaie},
  doi          = {10.1007/s00521-023-08714-7},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18905-18932},
  shortjournal = {Neural Comput. Appl.},
  title        = {A parallel multi-objective imperialist competitive algorithm to solve the load offloading problem in mobile cloud computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shoulder rehabilitation: A neuro-fuzzy inference approach to
recovery prediction. <em>NCA</em>, <em>35</em>(26), 18891–18903. (<a
href="https://doi.org/10.1007/s00521-023-08713-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a system for predicting the recovery status of patients with shoulder damage by estimating the results of the Disabilities of the Arm, Shoulder, and Hand (DASH) questionnaire using an Adaptive Neuro-Fuzzy Inference System (ANFIS). The study aimed to answer two primary research questions: First, is it possible to accurately predict the recovery status of patients with shoulder damage using the proposed system during treatment? Second, how does this estimation contribute to the treatment process? A literature review indicates that artificial intelligence is often used in rehabilitation to help patients perform exercises correctly. However, previous studies have typically focused solely on exercise execution, without addressing recovery prediction. In contrast, this study aims to predict the recovery status of patients and integrate it into a physiotherapy application, allowing for real-time observation of patient progress. To develop the recovery prediction model, we collected data on the treatment processes of 105 shoulder patients at Bilecik State Hospital and estimated the results of the DASH questionnaire using an ANFIS-based model. The developed model has a mean square error of 9.4E − 3 for the training data and a mean square error of 2.56E − 2 for the test data. The proposed model was integrated into a physiotherapy application using the best weight values from 1000 runs. In this way, it is ensured that successfully predicted recovery status can be observed in real-time. The findings of this study have important implications for shoulder injury rehabilitation. By integrating recovery prediction into a physiotherapy application, healthcare providers can monitor patient progress more effectively and make more informed decisions about the timing and intensity of rehabilitation exercises.},
  archive      = {J_NCA},
  author       = {Çubukçu, Burakhan and Yüzgeç, Uğur},
  doi          = {10.1007/s00521-023-08713-8},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18891-18903},
  shortjournal = {Neural Comput. Appl.},
  title        = {Shoulder rehabilitation: A neuro-fuzzy inference approach to recovery prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of turkish mutual funds’ net asset value using
the fund portfolio distribution. <em>NCA</em>, <em>35</em>(26),
18873–18890. (<a
href="https://doi.org/10.1007/s00521-023-08716-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of mutual funds’ net asset value (NAV) has become increasingly important for investors. Mutual fund investors will be significantly supported by the development of models that accurately predict the future performances of mutual funds. Using these models will facilitate the selection of suitable mutual funds for investors who want to invest in the medium and long term. The aim of this study, using artificial neural networks and nonlinear autoregressive networks with exogenous inputs (NARX) methods and Levenberg–Marquardt (LM), Bayesian regularization (BR), and scaled conjugate gradient training algorithms, is to predict the NAV of two Turkish mutual funds, which are Deniz Asset Management First Variable Fund (DBP) and İstanbul Asset Management Short-Term Bonds and Bills Fund, with the funds’ their portfolio distributions. For this purpose, prediction models were developed with these methods, training algorithms, and some specific hyperparameters and applied to the datasets of the funds examined in the study. The performances of the developed models were compared according to the method and training algorithm pairs for each fund. For performance evaluation, mean squared error, mean absolute percent error, and coefficient of correlation statistical measures are used. From the result, it can be clearly suggested that the NARX-BR pair outperforms other models for DBP, and the NARX-LM pair outperforms other models for IST.},
  archive      = {J_NCA},
  author       = {Yılmaz, Ümit and Orbak, Âli Yurdun},
  doi          = {10.1007/s00521-023-08716-5},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18873-18890},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of turkish mutual funds’ net asset value using the fund portfolio distribution},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). State of the art on adversarial attacks and defenses in
graphs. <em>NCA</em>, <em>35</em>(26), 18851–18872. (<a
href="https://doi.org/10.1007/s00521-023-08839-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) had shown excellent performance in complex graph data modelings such as node classification, link prediction and graph classification. However, GNNs are vulnerable to adversarial attacks resulting in severe performance degradation, which brings many security and privacy issues. Such vulnerability of GNNs limits its application in safety–critical fields such as finance and transportation. Studying the principles and implementation of graph adversarial attacks and their countermeasures can provide insight into the reason behind the vulnerability of GNNs and consequently improve the robustness and generalization of the model. This paper introduces the related concepts of existing graph adversarial attack and defense algorithms and analyzes the basic idea and implementation of each algorithm. Moreover, we compare the strategies, target tasks, advantages and disadvantages of typical algorithms. Through the summary of the state of the art, the limitations and possible development directions of graph adversarial attacks and defenses are analyzed, which provides a useful reference for the further developing relative researches.},
  archive      = {J_NCA},
  author       = {Zhai, Zhengli and Li, Penghui and Feng, Shu},
  doi          = {10.1007/s00521-023-08839-9},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18851-18872},
  shortjournal = {Neural Comput. Appl.},
  title        = {State of the art on adversarial attacks and defenses in graphs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scientometric analysis of ICT-assisted intelligent control
systems response to COVID-19 pandemic. <em>NCA</em>, <em>35</em>(26),
18829–18849. (<a
href="https://doi.org/10.1007/s00521-023-08788-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 outbreak has caused a devastating impact on the daily lives of people, public health, and economic progress of infected countries. It has become a leading cause of substantial mortality and morbidity around the world. The emergence of new variants of virus has posed severe challenges for humanitarian society. Information and Communication Technology (ICT) has played a vital role in this pandemic and offered various promising innovations to control its dissemination. The current research study presents a scientometric analysis on the literature of ICT-assisted COVID-19 research. In this paper, ICT has been classified into six major categories; artificial intelligence and medical imaging, mobile technology, ubiquitous computing, big data analytics, social media platforms, and printing technology. It extensively examines the role of these technologies in COVID-19 by applying various empirical approaches such as co-citation analysis, publication and citation behavior analysis, participating nations, and knowledge mapping of scientific literature using visualization tool CiteSpace. Furthermore, it provides a visual approach to identify developing paths, evolution trends, research hotspots, cluster analysis, and potential future directions in medical informatics.},
  archive      = {J_NCA},
  author       = {Sood, Sandeep Kumar and Rawat, Keshav Singh and Kumar, Dheeraj},
  doi          = {10.1007/s00521-023-08788-3},
  journal      = {Neural Computing and Applications},
  number       = {26},
  pages        = {18829-18849},
  shortjournal = {Neural Comput. Appl.},
  title        = {Scientometric analysis of ICT-assisted intelligent control systems response to COVID-19 pandemic},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based approaches for robust classification of
cervical cancer. <em>NCA</em>, <em>35</em>(25), 18813–18828. (<a
href="https://doi.org/10.1007/s00521-023-08757-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer is the fourth most common cancer worldwide, and early diagnosis is crucial for successful treatment, as with all types of cancer. The pap-smear test is considered the gold standard for diagnosing cervical cancer. However, the success of diagnosis depends on the expertise and effort of the physician, as with all cancer types. Computer-aided diagnosis systems aim to improve the speed and accuracy of cancer diagnosis by constantly improving medical image analysis and diagnosis. One of the main challenges in classifying cervical cancer with deep learning-based methods is the availability and quality of data, as well as the variability in size, shape, and appearance of cervical cancer images. This study presents effective techniques for overcoming these challenges and developing a more efficient diagnostic system. Specifically, the study applies the latest and most powerful deep learning techniques in two categories: convolutional neural network (CNN) approaches and vision transformer (ViT) approaches. The study also utilizes data augmentation techniques to increase data diversity and ensemble learning techniques to improve the accuracy of model outputs. This study presents a detailed comparison and the most extensive study in the literature by applying 40 CNN-based models and more than 20 ViT-based models on SIPaKMeD pap-smear dataset. The experimental results show that the latest ViT-based models perform better, and the existing CNN models perform similarly to the ViT models. By utilizing data augmentation and ensemble learning techniques in ViT-based models, the research exceeds previous studies and attains a level of success that has potential to be implemented in clinical settings. This progress is expected to bring down the mortality rate by enabling the early and precise identification of cancer.},
  archive      = {J_NCA},
  author       = {Pacal, Ishak and Kılıcarslan, Serhat},
  doi          = {10.1007/s00521-023-08757-w},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18813-18828},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based approaches for robust classification of cervical cancer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A topic-aware classifier based on a hybrid quantum-classical
model. <em>NCA</em>, <em>35</em>(25), 18803–18812. (<a
href="https://doi.org/10.1007/s00521-023-08706-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of Large Language Models, there is still potential for improvement in current Natural Language Processing (NLP) methods in terms of verifiability and consistency. NLP classical approaches are computationally expensive due to their high-power consumption, computing power, and storage requirements. Another computationally efficient approach to NLP is categorical quantum mechanics, which combines grammatical structure and individual word meaning to deduce the sentence meaning. As both quantum theory and natural language use vector space to describe states which are more efficient on quantum hardware, QNLP models can achieve up to quadratic speedup over classical direct calculation methods. In recent years, there is significant progress in utilizing quantum features such as superposition and entanglement to represent linguistic meaning on quantum hardware. Earlier research work has already demonstrated QNLP’s potential quantum advantage in terms of speeding up search, enhancing classification tasks’ accuracy and providing an exponentially large quantum state space in which complex linguistic structures can be efficiently embedded. In this work, a QNLP model is used to determine if two sentences are related to the same topic or not. By comparing our QNLP model to a classical tensor network-based one, our model improved training accuracy by up to 45\% and validation accuracy by 35\%, respectively. The QNLP model convergence is also studied when varying: first, the problem size, second, parametrized quantum circuits used for model’s training, and last, the backend quantum simulator noise model. The experimental results show that strongly entangled ansatz designs result in fastest model convergence.},
  archive      = {J_NCA},
  author       = {Metawei, Maha A. and Taher, Mohamed and ElDeeb, Hesham and Nassar, Salwa M.},
  doi          = {10.1007/s00521-023-08706-7},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18803-18812},
  shortjournal = {Neural Comput. Appl.},
  title        = {A topic-aware classifier based on a hybrid quantum-classical model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SCRE: Special cargo relation extraction using representation
learning. <em>NCA</em>, <em>35</em>(25), 18783–18801. (<a
href="https://doi.org/10.1007/s00521-023-08704-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The airfreight industry of shipping goods with special handling needs, also known as special cargo, often deals with non-transparent data and outdated technology, resulting in significant inefficiency. A special cargo ontology is a means of extracting, structuring, and storing domain knowledge and representing the concepts and relationships that can be processed by computers. This ontology can be used as the base of semantic data retrieval in many artificial intelligence applications, such as planning for special cargo shipments. Domain information extraction is an essential task in implementing and maintaining special cargo ontology. However, the absence of domain information makes instantiating the cargo ontology challenging. We propose a relation representation learning approach based on a hierarchical attention-based multi-task model and leverage it in the special cargo domain. The proposed relation representation learning architecture is applied for identifying and categorizing samples of various relation types in the special cargo ontology. The model is trained with domain-specific documents on a number of semantic tasks that vary from lightweight tasks in the bottom layers to the heavyweight tasks in the top layers of the model in a hierarchical setting. Therefore, it conveys complementary input features and learns a rich representation. We also train a domain-specific relation representation model that relies only on an entity-linked corpus of cargo shipment domain. These two relation representation models are then employed in a supervised multi-class classifier called Special Cargo Relation Extractor (SCRE). The results of the experiments show that the proposed relation representation models can represent the complex semantic information of the special cargo domain efficiently.},
  archive      = {J_NCA},
  author       = {Reshadat, Vahideh and Akcay, Alp and Zervanou, Kalliopi and Zhang, Yingqian and de Jong, Eelco},
  doi          = {10.1007/s00521-023-08704-9},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18783-18801},
  shortjournal = {Neural Comput. Appl.},
  title        = {SCRE: Special cargo relation extraction using representation learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated model based on deep kernel extreme learning
machine and variational mode decomposition for day-ahead electricity
load forecasting. <em>NCA</em>, <em>35</em>(25), 18763–18781. (<a
href="https://doi.org/10.1007/s00521-023-08702-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term electricity load forecasts are critical for the secure and economic operation of power systems. This paper presents a computationally efficient and powerful three-stage model to accurately forecast short-term electricity load. Variational mode decomposition (VMD) was used in the first stage to extract features from the historical load signal. The stacked kernel extreme learning machine (KELM)-based auto-encoders were utilized in the unsupervised feature learning-based second stage. In the third stage, the high-order learned features were used as the inputs for the KELM-based regression model. The proposed deep KELM architecture combines stacked KELM-based auto-encoders and a KELM-based regression model to forecast short-term electricity load effectively. In order to examine the performance improvement of the proposed forecasting model, several performance comparison tests were realized using publicly available electricity load and day-ahead forecast data from the Turkish transmission system operator (TSO). The proposed model results were compared with state-of-the-art deep extreme learning machine (ELM) architectures as well as the benchmark forecasting models based on original ELM, KELM, artificial neural network (ANN), support vector machine (SVM), and regression tree (RT). The comparison results indicated that the proposed model outperformed state-of-the-art architectures and was significantly more successful than the TSO model.},
  archive      = {J_NCA},
  author       = {Yıldız, Ceyhun},
  doi          = {10.1007/s00521-023-08702-x},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18763-18781},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated model based on deep kernel extreme learning machine and variational mode decomposition for day-ahead electricity load forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MiRNA subset selection for microarray data classification
using grey wolf optimizer and evolutionary population dynamics.
<em>NCA</em>, <em>35</em>(25), 18737–18761. (<a
href="https://doi.org/10.1007/s00521-023-08701-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-ribonucleic acids (miRNAs) are tiny noncoding ribonucleic acid (RNA) molecules that involve various biological processes for cancer advancements. Classification of cancer is a crucial problem in microarray technology because of the huge number of miRNAs and a limited number of samples. Therefore, to improve the classification of cancer between benign and malignant samples, this paper presents a hybrid filter-wrapper method that uses the multi-filter ensemble (MFE) approach as a filter method used in selecting the top-ranked miRNAs. For the wrapper approach, three different algorithms based on simultaneous utilization of the grey wolf optimizer (GWO), evolutionary population dynamics (EPD), and two selection mechanisms, are presented to enhance the GWO algorithm performance. The first approach involves the application of the EPD mechanisms to the GWO to eliminate the worst solutions of GWO and repositions them toward alpha, beta, or delta wolves to improve exploitation. So also, the GWO needed to randomly reinitialize its poor solutions near to the search space, using the EPD for the enhancement of the exploration process. In the second and third approaches, the Roulette wheel selection (RWS) and tournament selection (TS) are applied to offer a chance for low fitness individuals to be selected during the search process that maintains the diversity of the selected solutions. The proposed GWO_EPD algorithms are applied for miRNAs selection, and obtained results demonstrate that the EPD can improve the search capability of GWO in terms of avoiding local optima, exploration, and convergence rate. Moreover, the results of GWO_EPD are compared with twelve miRNAs subset selection approaches using classification accuracy and the number of selected miRNAs.},
  archive      = {J_NCA},
  author       = {Almotairi, Khaled H.},
  doi          = {10.1007/s00521-023-08701-y},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18737-18761},
  shortjournal = {Neural Comput. Appl.},
  title        = {MiRNA subset selection for microarray data classification using grey wolf optimizer and evolutionary population dynamics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RamanNet: A generalized neural network architecture for
raman spectrum analysis. <em>NCA</em>, <em>35</em>(25), 18719–18735. (<a
href="https://doi.org/10.1007/s00521-023-08700-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Raman spectroscopy provides a vibrational profile of the molecules and thus can be used to uniquely identify different kinds of materials. This sort of molecule fingerprinting has thus led to the widespread application of Raman spectrum in various fields like medical diagnosis, forensics, mineralogy, bacteriology, virology, etc. Despite the recent rise in Raman spectra data volume, there has not been any significant effort in developing generalized machine learning methods targeted toward Raman spectra analysis. We examine, experiment, and evaluate existing methods and conjecture that neither current sequential models nor traditional machine learning models are satisfactorily sufficient to analyze Raman spectra. Both have their perks and pitfalls; therefore, we attempt to mix the best of both worlds and propose a novel network architecture RamanNet. RamanNet is immune to the invariance property in convolutional neural networks (CNNs) and at the same time better than traditional machine learning models for the inclusion of sparse connectivity. This has been achieved by incorporating shifted multi-layer perceptrons (MLP) at the earlier levels of the network to extract significant features across the entire spectrum, which are further refined by the inclusion of triplet loss in the hidden layers. Our experiments on 4 public datasets demonstrate superior performance over the much more complex state-of-the-art methods, and thus, RamanNet has the potential to become the de facto standard in Raman spectra data analysis.},
  archive      = {J_NCA},
  author       = {Ibtehaz, Nabil and Chowdhury, Muhammad E. H. and Khandakar, Amith and Kiranyaz, Serkan and Rahman, M. Sohel and Zughaier, Susu M.},
  doi          = {10.1007/s00521-023-08700-z},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18719-18735},
  shortjournal = {Neural Comput. Appl.},
  title        = {RamanNet: A generalized neural network architecture for raman spectrum analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrosion and coating defect assessment of coal handling and
preparation plants (CHPP) using an ensemble of deep convolutional neural
networks and decision-level data fusion. <em>NCA</em>, <em>35</em>(25),
18697–18718. (<a
href="https://doi.org/10.1007/s00521-023-08699-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the problems of ineffective feature extraction and low detection accuracy in existing detection system, this study presents a novel machine vision-based approach composed of an ensemble of deep convolutional neural networks (CNNs) and improved Dempster-Shafer (D-S) theory-based data fusion to evaluate corrosion and coating defect of coal handling and preparation plants. To start with, the structural surface image is sent to each transferred CNN for initial defect identification. Then, an improved D-S fusion algorithm is proposed to combine the identification results from different CNNs, which are vectors consisting of statistical indicators of all the potential damage severity categories. The decision-level fusion of different CNNs can effectively improve image classification. To validate the performance of the proposed method, a dataset made of 3593 surface images with different defect severities captured from mining infrastructure in field is established together with data augmentation. The validation result demonstrates that the proposed method is able to effectively improve the recognition accuracy of defect severity and reduce the wrong recognition rate. Finally, the robustness of the proposed approach is also appraised by polluting the images with different types and intensities of noise, with satisfactory results.},
  archive      = {J_NCA},
  author       = {Yu, Yang and Hoshyar, Azadeh Noori and Samali, Bijan and Zhang, Guang and Rashidi, Maria and Mohammadi, Masoud},
  doi          = {10.1007/s00521-023-08699-3},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18697-18718},
  shortjournal = {Neural Comput. Appl.},
  title        = {Corrosion and coating defect assessment of coal handling and preparation plants (CHPP) using an ensemble of deep convolutional neural networks and decision-level data fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). An integrated topic modeling and auto-encoder for
semantic-rich network embedding and news recommendation. <em>NCA</em>,
<em>35</em>(25), 18681–18696. (<a
href="https://doi.org/10.1007/s00521-023-08697-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, network representation learning is considered as a crucial research direction which explicitly supports multiple problems in information analysis and mining (INAM) domain. Among downstream tasks of INAM, news recommendation is considered as an important task, especially in semantic-rich/heterogeneous networks. Most of previous news recommendation models are mostly relied on the collaborative filtering (CF) approach. The CF-based techniques support to analyze the historical user–item interacting relationships. These relationships are used to extract latent factors and characterize the user’s preferences which are later utilize to facilitate the different recommendation tasks. Recent attempts also focus on the integrations of news recommendation with complex representation learning techniques to leverage the accuracy performance. Even multiple models have gained remarkable performance recently, they still encounter challenges. These challenges are related to the sparsity of user–item interaction data and thorough topic-driven user’s preference characterization. Moreover, these recent deep neural embedding-based recommendation models also suffer several limitations which are related to the capability of multi-viewed data embedding. Specifically, in the context of semantic-rich/network heterogeneity, they might be unable to fully incorporate the global structural representations of user–item interactions as well as associated data sources. Mainly motivated by remaining challenges, in this paper we propose novel topic-driven heterogeneous information network embedding-based technique which is aimed to effectively deal with the news recommendation, called as THIN4Rec. Our proposed THIN4Rec model enables to jointly capture the rich-semantic latent features of textual data and global structural representations of user–item interactions in the context of heterogeneous networks. The rich-semantic and structural representations of users and items are then used to improve the accuracy performance of news recommendation task. Extensive experiments in benchmark datasets prove the effectiveness of our works in comparison with recent state-of-the-art baselines.},
  archive      = {J_NCA},
  author       = {Vo, Tham},
  doi          = {10.1007/s00521-023-08697-5},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18681-18696},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated topic modeling and auto-encoder for semantic-rich network embedding and news recommendation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved henry gas optimization algorithm for joint
mining decision and resource allocation in a MEC-enabled blockchain
networks. <em>NCA</em>, <em>35</em>(25), 18665–18680. (<a
href="https://doi.org/10.1007/s00521-023-08695-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a wireless blockchain network with mobile edge computing in which Internet of Things (IoT) devices can behave as blockchain users (BUs). This blockchain network’s ultimate goal is to increase the overall profits of all BUs. Because not all BUs join in the mining process, using traditional swarm and evolution algorithms to solve this problem results in a high level of redundancy in the search space. To solve this problem, a modified chaotic Henry single gas solubility optimization algorithm, called CHSGSO, has been proposed. In CHSGSO, the allocation of resources to BUs who decide to engage in mining as an individual is encoded. This results in a different size for each individual in the entire population, which leads to the elimination of unnecessary search space regions. Because the individual size equals the number of participating BUs, we devise an adaptive strategy to fine-tune each individual size. In addition, a chaotic map was incorporated into the original Henry gas solubility optimization to improve resource allocation and accelerate the convergence rate. Extensive experiments on a set of instances were carried out to validate the superiority of the proposed CHSGSO. Its efficiency is demonstrated by comparing it to four well-known meta-heuristic algorithms.},
  archive      = {J_NCA},
  author       = {Hussien, Reda M. and Abohany, Amr A. and Moustafa, Nour and Sallam, Karam M.},
  doi          = {10.1007/s00521-023-08695-7},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18665-18680},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved henry gas optimization algorithm for joint mining decision and resource allocation in a MEC-enabled blockchain networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PDS-MCNet: A hybrid framework using MobileNetV2 with SiLU6
activation function and capsule networks for disease severity estimation
in plants. <em>NCA</em>, <em>35</em>(25), 18641–18664. (<a
href="https://doi.org/10.1007/s00521-023-08693-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced technologies like deep learning have been widely implemented in various agricultural applications, including disease severity estimation. In this study, the authors have leveraged the computational capabilities of MobileNetV2 and capsule networks (CapsNet) to effectively evaluate plant disease severity. In this paper, the authors implemented a hybrid framework constituting multilateral MobileNetV2 for feature extraction and CapsNet for classification, applied to the problem of estimating disease severity in plants, executed on two datasets: one for tomato late blight disease and another for tomato early blight disease. Furthermore, the authors improved the MobileNetV2 architecture by replacing ReLU6 with the SiLU6 activation function, resulting in improved outcomes. To test the robustness of the proposed methodology, the authors added salt-and-pepper noise to the original images and computed the performance measures. Additionally, the impact of data fusion, i.e., combining two datasets, one tomato early blight disease from the PlantVillage dataset and an original tomato early blight (TEB) dataset collected by the authors, was also investigated for disease identification (binary classification) as well as disease severity assessment. Our proposed framework was compared with 15 traditional pre-trained CNN models where classification accuracy, Cohen’s kappa, precision, recall, F1-score, and loss were recorded and compared. A rank, on the basis of performance, was assigned to all models for all implementations. Based on the mean rank values, it was observed that the proposed PDS-MCNet model outperformed all other models, followed by DenseNet169, the best amongst the state-of-the-art CNN architectures, for plant disease severity evaluation. The proposed approach was also validated using three other datasets while establishing the generalizability of the technique. Accurate and timely assessment of disease severity can benefit growers economically by enabling them to take precise corrective actions. Early detection and precise application of agrochemicals can also benefit the environment and maintain the ecological balance.},
  archive      = {J_NCA},
  author       = {Verma, Shradha and Chug, Anuradha and Singh, Amit Prakash and Singh, Dinesh},
  doi          = {10.1007/s00521-023-08693-9},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18641-18664},
  shortjournal = {Neural Comput. Appl.},
  title        = {PDS-MCNet: A hybrid framework using MobileNetV2 with SiLU6 activation function and capsule networks for disease severity estimation in plants},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint contrastive learning and frequency domain defense
against adversarial examples. <em>NCA</em>, <em>35</em>(25),
18623–18639. (<a
href="https://doi.org/10.1007/s00521-023-08688-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are vulnerable to being attacked by adversarial examples, leading to DNN misclassification. Perturbations in adversarial examples usually exist in the form of noise. In this paper, we proposed a lightweight joint contrastive learning and frequency domain denoising network (CFNet), which can effectively remove adversarial perturbations from adversarial examples. First, CFNet separates the channels of the features obtained by the multilayer convolution of the adversarial examples, and the separated feature maps are used to calculate the similarity with the high- and low-frequency feature maps obtained by Gaussian low-pass filtering of the clean examples. Second, by adjusting the network’s attention to high-frequency feature images, CFNet can effectively remove the perturbations in adversarial examples and obtain reconstructed examples with high visual quality. Finally, to further improve the robustness of CFNet, contrastive regularization is proposed to bring the reconstructed examples back to the manifold decision boundary of clean examples, thus improving the classification accuracy of reconstructed examples. On the CIFAR-10 dataset, compared with the existing state-of-the-art defense model, the defense accuracy of CFNet is improved by 16.93\% and 5.67\% under untargeted and targeted projected gradient descent attacks, respectively. The AutoAttack untargeted attack defense accuracy increased by 30.81\%. Experiments show that our approach provides better protection than existing state-of-the-art approaches, especially against unseen (untrained) types of attacks and adaptive attacks.},
  archive      = {J_NCA},
  author       = {Yang, Jin and Li, Zhi and Liu, Shuaiwei and Hong, Bo and Wang, Weidong},
  doi          = {10.1007/s00521-023-08688-6},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18623-18639},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint contrastive learning and frequency domain defense against adversarial examples},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An abstractive text summarization technique using
transformer model with self-attention mechanism. <em>NCA</em>,
<em>35</em>(25), 18603–18622. (<a
href="https://doi.org/10.1007/s00521-023-08687-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating a summarized version of a text document that still conveys precise meaning is an incredibly complex endeavor in natural language processing (NLP). Abstract text summarization (ATS) is the process of using facts from source sentences and merging them into concise representations while maintaining the content and intent of the text. Manually summarizing large amounts of text are challenging and time-consuming for humans. Therefore, text summarization has become an exciting research focus in NLP. This research paper proposed an ATS model using a Transformer Technique with Self-Attention Mechanism (T2SAM). The self-attention mechanism is added to the transformer to solve the problem of coreference in text. This makes the system to understand the text better. The proposed T2SAM model improves the performance of text summarization. It is trained on the Inshorts News dataset combined with the DUC-2004 shared tasks dataset. The performance of the proposed model has been evaluated using the ROUGE metrics, and it has been shown to outperform the existing state-of-the-art baseline models. The proposed model gives the training loss minimum to 1.8220 from 10.3058 (at the starting point) up to 30 epochs, and it achieved model accuracy 48.50\% F1-Score on both the Inshorts and DUC-2004 news datasets.},
  archive      = {J_NCA},
  author       = {Kumar, Sandeep and Solanki, Arun},
  doi          = {10.1007/s00521-023-08687-7},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18603-18622},
  shortjournal = {Neural Comput. Appl.},
  title        = {An abstractive text summarization technique using transformer model with self-attention mechanism},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive radio map reconstruction via adversarial wireless
fingerprint learning. <em>NCA</em>, <em>35</em>(25), 18585–18602. (<a
href="https://doi.org/10.1007/s00521-023-08684-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi signals play an essential role in indoor location-based services. However, the Wi-Fi radio map is vulnerable to deployment changes, leading to significant localization errors. Therefore, surveyors must regularly carry out a labor-intensive and time-consuming site survey to keep the radio map up-to-date. To address this, we propose a radio map reconstruction framework (RMRec), which adopts adversarial learning to efficiently reconstruct the latest radio map with new signal samples collected at a small portion of reference points (RPs). The reconstruction model we built reveals the inherent spatial relations of the Wi-Fi signals in a large-scale building structure and by which the coarse-grained radio map is mapped into the corresponding fine-grained one, thus reducing the cost of the site survey significantly. The adversarial mechanism in RMRec enhances the textural features of the updated radio map, consequently improving the localization service. Meanwhile, we employ the scene-constrained downsample method and the CutPaste data augmentation to improve our model’s reconstruction accuracy and transferability. Besides, we design a non-uniform sampling strategy to reduce the site survey cost by allocating different selection rates for each subarea according to its anti-noise ability for location service. Experimental results demonstrate that RMRec can precisely reconstruct radio maps with 25 $$\%$$ new samples and exceeds an average of 18.83 $$\%$$ over the state-of-the-art methods in reconstruction accuracy. In addition, RMRec is also efficient for changed access points (APs), newly deployed APs, and scene changes.},
  archive      = {J_NCA},
  author       = {Jiang, Weina and Niu, Qun and He, Suining and Liu, Ning},
  doi          = {10.1007/s00521-023-08684-w},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18585-18602},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive radio map reconstruction via adversarial wireless fingerprint learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stress monitoring using wearable sensors: IoT techniques in
medical field. <em>NCA</em>, <em>35</em>(25), 18571–18584. (<a
href="https://doi.org/10.1007/s00521-023-08681-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept “Internet of Things” (IoT), which facilitates communication between linked devices, is relatively new. It refers to the next generation of the Internet. IoT supports healthcare and is essential to numerous applications for tracking medical services. By examining the pattern of observed parameters, the type of the disease can be anticipated. For people with a range of diseases, health professionals and technicians have developed an excellent system that employs commonly utilized techniques like wearable technology, wireless channels, and other remote equipment to give low-cost healthcare monitoring. Whether put in living areas or worn on the body, network-related sensors gather detailed data to evaluate the patient&#39;s physical and mental health. The main objective of this study is to examine the current e-health monitoring system using integrated systems. Automatically providing patients with a prescription based on their status is the main goal of the e-health monitoring system. The doctor can keep an eye on the patient&#39;s health without having to communicate with them. The purpose of the study is to examine how IoT technologies are applied in the medical industry and how they help to raise the bar of healthcare delivered by healthcare institutions. The study will also include the uses of IoT in the medical area, the degree to which it is used to enhance conventional practices in various health fields, and the degree to which IoT may raise the standard of healthcare services. The main contributions in this paper are as follows: (1) importing signals from wearable devices, extracting signals from non-signals, performing peak enhancement; (2) processing and analyzing the incoming signals; (3) proposing a new stress monitoring algorithm (SMA) using wearable sensors; (4) comparing between various ML algorithms; (5) the proposed stress monitoring algorithm (SMA) is composed of four main phases: (a) data acquisition phase, (b) data and signal processing phase, (c) prediction phase, and (d) model performance evaluation phase; and (6) grid search is used to find the optimal values for hyperparameters of SVM (C and gamma). From the findings, it is shown that random forest is best suited for this classification, with decision tree and XGBoost following closely behind.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and El-Balka, Rana Mohamed},
  doi          = {10.1007/s00521-023-08681-z},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18571-18584},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stress monitoring using wearable sensors: IoT techniques in medical field},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HierMDS: A hierarchical multi-document summarization model
with global–local document dependencies. <em>NCA</em>, <em>35</em>(25),
18553–18570. (<a
href="https://doi.org/10.1007/s00521-023-08680-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-document summarization (MDS) has attracted increasing attention in recent years. Most existing MDS systems simply encode the flat connected sequence of multiple documents, which limits the representation capabilities for multi-documents. To address this issue, we propose a Hierarchical Multi-Document Summarization Model with Global-Local Document Dependencies (HierMDS). HierMDS consists of five sub-blocks, i.e., an embedding block, an internal document encoding block, a local document encoding block, a global document encoding block, and a fusion block, which are stacked in a hierarchical structure to gradually produce dependency-enriched document representations. Specifically, the embedding block encodes tokens, and the internal document encoding block encodes each document. Then, for a certain document, two kinds of document dependencies are extracted: (1) The global document dependency indicates that the representation of this document is affected by all the other documents. (2) The local document dependency indicates that the representation of this document is only affected by the relevant documents. We suppose that the global document dependency represents the global background information, while the local document dependency condenses the most relevant information. To be specific, the global document encoding block modeled with the vanilla transformer layer encodes the global document dependencies, and the local document encoding block modeled with the graph attention neural networks encodes the local document dependencies. Finally, HierMDS produces document dependency-enriched representations by fusing the local and global document dependencies with the fusion block. Experimental results on Multi-News and DUC-2004 datasets have demonstrated competitive advantages of HierMDS compared with several state-of-the-art MDS models.},
  archive      = {J_NCA},
  author       = {Li, Shuimin and Xu, Jungang},
  doi          = {10.1007/s00521-023-08680-0},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18553-18570},
  shortjournal = {Neural Comput. Appl.},
  title        = {HierMDS: A hierarchical multi-document summarization model with global–local document dependencies},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SoURA: A user-reliability-aware social recommendation system
based on graph neural network. <em>NCA</em>, <em>35</em>(25),
18533–18551. (<a
href="https://doi.org/10.1007/s00521-023-08679-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting user trust information for developing a recommendation system has gained increasing research interest in recent years. Due to the exchange of opinions about items over the social network, trust plays a crucial role for a user to like or dislike an item. Graph Neural Networks (GNNs), which have the intrinsic power of integrating node information and topological structure, have a high potential to advance the field of trust-aware social recommendation. However, as of now, this area is little explored, with most of the existing GNN-based models ignoring the trust propagation and trust composition properties. To address this issue, in this paper, we propose a novel GNN-based framework that can capture such trust propagation and trust composition aspects by incorporating the concept of ‘user-reliability.’ Our proposed user-reliability-aware social recommendation framework, termed as SoURA, generates the user-embedding and item-embedding with consideration to the user-reliability values, which, in turn, helps in better evaluation of the user trust. Experimental evaluations on the benchmark Ciao and Epinion datasets demonstrate the effectiveness of incorporating user-reliability for finding user-embedding and item embedding in a social recommendation system. The proposed SoURA is found to show a minimum of 25\% improvement over the state-of-the-art GNN-based recommendation algorithms.},
  archive      = {J_NCA},
  author       = {Dawn, Sucheta and Das, Monidipa and Bandyopadhyay, Sanghamitra},
  doi          = {10.1007/s00521-023-08679-7},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18533-18551},
  shortjournal = {Neural Comput. Appl.},
  title        = {SoURA: A user-reliability-aware social recommendation system based on graph neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting the state of synchronization of financial time
series using cross recurrence plots. <em>NCA</em>, <em>35</em>(25),
18519–18531. (<a
href="https://doi.org/10.1007/s00521-023-08674-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-correlation analysis is a powerful tool for understanding the mutual dynamics of time series. This study introduces a new method for predicting the future state of synchronization of the dynamics of two financial time series. To this end, we use the cross recurrence plot analysis as a nonlinear method for quantifying the multidimensional coupling in the time domain of two time series and for determining their state of synchronization. We adopt a deep learning framework for methodologically addressing the prediction of the synchronization state based on features extracted from dynamically sub-sampled cross recurrence plots. We provide extensive experiments on several stocks, major constituents of the S &amp;P100 index, to empirically validate our approach. We find that the task of predicting the state of synchronization of two time series is in general rather difficult, but for certain pairs of stocks attainable with very satisfactory performance (84\% F1-score, on average).},
  archive      = {J_NCA},
  author       = {Shabani, Mostafa and Magris, Martin and Tzagkarakis, George and Kanniainen, Juho and Iosifidis, Alexandros},
  doi          = {10.1007/s00521-023-08674-y},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18519-18531},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting the state of synchronization of financial time series using cross recurrence plots},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training energy-based single-layer hopfield and oscillatory
networks with unsupervised and supervised algorithms for image
classification. <em>NCA</em>, <em>35</em>(25), 18505–18518. (<a
href="https://doi.org/10.1007/s00521-023-08672-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates how to solve image classification with Hopfield neural networks (HNNs) and oscillatory neural networks (ONNs). This is a first attempt to apply ONNs for image classification. State-of-the-art image classification networks are multi-layer models trained with supervised gradient back-propagation, which provide high-fidelity results but require high energy consumption and computational resources to be implemented. On the contrary, HNN and ONN networks are single-layer, requiring less computational resources, however, they necessitate some adaptation as they are not directly applicable for image classification. ONN is a novel brain-inspired computing paradigm that performs low-power computation and is attractive for edge artificial intelligence applications, such as image classification. In this paper, we perform image classification with HNN and ONN by exploiting their auto-associative memory (AAM) properties. We evaluate precision of HNN and ONN trained with state-of-the-art unsupervised learning algorithms. Additionally, we adapt the supervised equilibrium propagation (EP) algorithm to single-layer AAM architectures, proposing the AAM-EP. We test and validate HNN and ONN classification on images of handwritten digits using a simplified MNIST set. We find that using unsupervised learning, HNN reaches 65.2\%, and ONN 59.1\% precision. Moreover, we show that AAM-EP can increase HNN and ONN precision up to 67.04\% for HNN and 62.6\% for ONN. While intrinsically HNN and ONN are not meant for classification tasks, to the best of our knowledge, these are the best-reported precisions of HNN and ONN performing classification of images of handwritten digits.},
  archive      = {J_NCA},
  author       = {Abernot, Madeleine and Todri-Sanial, Aida},
  doi          = {10.1007/s00521-023-08672-0},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18505-18518},
  shortjournal = {Neural Comput. Appl.},
  title        = {Training energy-based single-layer hopfield and oscillatory networks with unsupervised and supervised algorithms for image classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-stream ternary enhanced graph convolutional network
for skeleton-based action recognition. <em>NCA</em>, <em>35</em>(25),
18487–18504. (<a
href="https://doi.org/10.1007/s00521-023-08671-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel mechanism for skeleton-based action recognition is proposed in this paper by enhancing and fusing diverse skeleton features from distinct levels. Graph convolutional neural networks (GCNs) have been proven to be efficient in skeleton-based action recognition. However, most graph convolutional networks tend to capture and fuse discriminative information from different forms of data in spatial neighborhoods. In that case, the deeper interactions among different forms of data as well as the extraction of information in the temporal and channel dimensions are limited. To tackle the issue, we propose the ternary adaptive graph convolution (TAGC) module to capture spatiotemporal information by graph convolution. A novel skeleton information, called parallax information, is explored from original joints or bones with little computation to further improve the performance of action recognition. In addition, in order to make better use of multiple streams, multi-stream feature fusion (MSFF) is proposed to mine deeper-level hybrid features supplementing the original streams. And a graph-based ternary enhance (GTE) module is proposed to further refine the extracted discriminative features. Finally, the proposed multi-stream ternary enhanced graph convolutional network (MS-TEGCN) achieves the state-of-the-art results through extensive experiments on three challenging datasets for skeleton-based action recognition, NTU-60, NTU-120 and Kinetics-Skeleton.},
  archive      = {J_NCA},
  author       = {Kong, Jun and Wang, Shengquan and Jiang, Min and Liu, TianShan},
  doi          = {10.1007/s00521-023-08671-1},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18487-18504},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-stream ternary enhanced graph convolutional network for skeleton-based action recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The joint detection and classification model for
spatiotemporal action localization of primates in a group. <em>NCA</em>,
<em>35</em>(25), 18471–18486. (<a
href="https://doi.org/10.1007/s00521-023-08670-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis of primate behavior is crucial for neuroscience research and drug evaluation. Although many methods of automatically recording animal behavior have been proposed, none of them can meet the requirements of both speed and accuracy. In order to implement real-time and high-precision automatic recording of primate behavior, we proposed a novel Joint Detection and Classification (JDC) model to predict the location, identity and actions of monkeys simultaneously. Different from the existing complex non-end-to-end models, our model is the first end-to-end method in this field. In order to explore how to efficiently fuse spatiotemporal information, we constructed the JDC model with a single frame or different fusion approaches. In addition, we collected a new dataset named Spatiotemporal Action Localization of Monkeys in a Group (SALMG), which is the first one containing the location, identity and actions of monkeys in a group. The JDC model with middle fusion approach (JDC-MF) on the SALMG dataset outperforms all compared methods. The F1 score of the JDC-MF is 81.4\%, which is 15.3\% and 10.6\% higher than the Separate Detection and Classification model and the two-stage model, respectively. Moreover, the JDC-MF achieves the highest accuracy of 99.1\% on public Pig Novelty Preference Behavior dataset, which is 4.1\% higher than the second-best model. The JDC-MF only takes 0.027 s for a clip on a Nvidia GeForce RTX 2080 Ti. Therefore, the JDC-MF can realize real-time and high-precision spatiotemporal action localization of monkeys, and provide an effective reference scheme for automatic recording and analysis of animal behavior. Code has been made available at: https://github.com/Kewei-Liang/JDC-MF .},
  archive      = {J_NCA},
  author       = {Liang, Kewei and Chen, Zhiyuan and Yang, Sen and Yang, Yang and Qin, Caijie and Ma, Xibo},
  doi          = {10.1007/s00521-023-08670-2},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18471-18486},
  shortjournal = {Neural Comput. Appl.},
  title        = {The joint detection and classification model for spatiotemporal action localization of primates in a group},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A time-varying stock portfolio selection model based on
optimized PSO-BiLSTM and multi-objective mathematical programming under
budget constraints. <em>NCA</em>, <em>35</em>(25), 18445–18470. (<a
href="https://doi.org/10.1007/s00521-023-08669-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing the optimal portfolio is an ongoing challenging research area and a complex process involving selecting the best investment plan according to various factors, such as investor preferences for expected return, risk, and duration of investments. Although various methods have been presented so far, they failed to obtain a holistic approach to the existing data, and the need for a comprehensive mechanism based on the investor’s time preferences is felt. In this paper, by considering the fundamental characteristics, technical indicators, time-series data, and budget constraints, we developed a comprehensive and time-varying methodology to forecast stock prices and form an optimal portfolio. The proposed method consists of recurrent neural networks and multi-objective mathematical programming (MOMP). In this regard, the bidirectional long short-term memory model is adopted and optimized by the particle swarm optimization (PSO) algorithm, called PSO-BiLSTM. Furthermore, the hybrid MOMP models are developed based on long-, mid-, and short-term strategies to provide the optimal portfolio of the stocks with investment constraints. The main objectives of this research were to address the following issues: (1) developing a precise and efficient model to forecast the stocks prices, taking account of fundamental characteristics, technical indicators, time-series data appropriate to the period considered by the investor, (2) providing an optimized time-varying portfolio through developing the hybrid MOMP models, and generally (3) proposing a holistic step-by-step methodology considering three groups of market data and deep learning to apply investment constraints as well as investor’s time preferences in the process of building more realistic portfolios. The results highlight that the tuned PSO-BiLSTM method performs better than the conventional methods in all three constructed models using fundamental characteristics, technical indicators, and time-series data. Compared to the conventional methods, the proposed methodology outperforms in generalization power, is more precise in forecasting prices, and provides portfolios with more profit.},
  archive      = {J_NCA},
  author       = {Vaziri, Jalil and Farid, Dariush and Nazemi Ardakani, Mehdi and Hosseini Bamakan, Seyed Mojtaba and Shahlaei, MohammadAli},
  doi          = {10.1007/s00521-023-08669-9},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18445-18470},
  shortjournal = {Neural Comput. Appl.},
  title        = {A time-varying stock portfolio selection model based on optimized PSO-BiLSTM and multi-objective mathematical programming under budget constraints},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical capsule network for hyperspectral image
classification. <em>NCA</em>, <em>35</em>(25), 18417–18443. (<a
href="https://doi.org/10.1007/s00521-023-08664-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral imaging is a highly advanced and sophisticated method for capturing images in hundreds of narrow, contiguous spectral bands. However, processing and analyzing such large amounts of data are challenging. Deep learning algorithms, especially those based on convolutional neural networks (CNNs), effectively extract rich feature representations from complex datasets, such as hyperspectral images (HSIs). These representations capture high-level patterns and characteristics that can facilitate accurate classification. The success of this approach has led to its widespread use in various remote sensing applications. However, the standard CNN inputs and outputs are scalars, ignoring the relative position relationships between features. In this paper, we propose a hierarchical capsule network for HSI classification. This network incorporates a multi-level convolutional structure for feature extraction and fusion. It utilizes convolutional feature maps of various depths to generate initial capsules, followed by vector computation using capsule neurons and a weight matrix to encode spatial location relationships among features. Furthermore, the shallow convolution of the hierarchical capsule network is pre-trained based on transfer learning to further improve the performance of HSI classification. According to experimental results, the proposed method for hyperspectral image classification has been found to outperform other state-of-the-art deep learning models on four benchmark datasets.},
  archive      = {J_NCA},
  author       = {Shi, Meilin and Wang, Ruoxiang and Ren, Jiansi},
  doi          = {10.1007/s00521-023-08664-0},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18417-18443},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical capsule network for hyperspectral image classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HATDO: Hybrid archimedes tasmanian devil optimization CNN
for classifying offensive comments and non-offensive comments.
<em>NCA</em>, <em>35</em>(25), 18395–18415. (<a
href="https://doi.org/10.1007/s00521-023-08657-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of social media and online platforms created more opportunities to express one’s thoughts without any burden. This emergence paved the way to construct more intelligent systems but by taking advantage of these platforms some people display their vengeance by harassing or abusing comments. The attackers leak sensitive information about an individual or an organization through the internet using abusive words, hate comments, threatening information, fake news, etc. So, online shaming detection with an optimum classification mechanism becomes necessary to avoid such negative consequences. In this paper, a novel online shaming detection mechanism using a Convolutional Neural Network Bidirectional Gated Recurrent Unit-based Hybrid Archimedes Tasmanian Devil (CNNBiGRU-HATD) approach is proposed to detect and classify the offensive comments and non-offensive comments. If the comment seems offensive, it is further classified into six categories according to shaming types such as abusive, doxing, Passing Judgment, Ethnic/Religious, Joke/Sarcasm, and Whataboutery. The utilized four Twitter-based datasets are initially preprocessed and feature extracted to improve the classification performance of the CNNBiGRU-HATD approach. After accurate classification, the information from the classified shaming types is collected and authenticated. The proposed approach is simulated using the Python platform. To validate the potential capability of the proposed CNNBiGRU-HATD approach, it is related to the existing methods by various parameters. The experimental result reveals that the proposed CNNBiGRU-HATD method achieves higher accuracy of 96.5\% for the labeled hate speech detection dataset.},
  archive      = {J_NCA},
  author       = {Aarthi, B. and Chelliah, Balika J.},
  doi          = {10.1007/s00521-023-08657-z},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18395-18415},
  shortjournal = {Neural Comput. Appl.},
  title        = {HATDO: Hybrid archimedes tasmanian devil optimization CNN for classifying offensive comments and non-offensive comments},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chaotic stabilization analysis for neutral-type memristive
neural networks via reliable and sampled-data controller. <em>NCA</em>,
<em>35</em>(25), 18377–18393. (<a
href="https://doi.org/10.1007/s00521-023-08656-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with chaotic stabilization analysis for a class of memristive neural networks (MNNs) with the effects of neutral delay and time-varying delay. We introduce a time-varying delay into reliable controller to enhance the model, while actuators experience failure signals. Sampled-data controller and reliable time-varying controller are implemented using input-delay approach and linear matrix inequality (LMI) approach. The main analysis of this present work is to utilize Lyapunov stability theory, differential inclusion theory and set-valued maps. By constructing a proper Lyapunov functionals, some sets of sufficient conditions are achieved in terms of LMIs. The considered MNNs with actuator fault guarantee the global asymptotic stability for known and unknown actuators cases. The process of congruence transformation has been applied to reliable time-varying controller to get a gain matrix. Finally, numerical examples demonstrate the less conservatism and effectiveness of the proposed results via MATLAB simulations.},
  archive      = {J_NCA},
  author       = {Suvetha, R. and Prakash, P.},
  doi          = {10.1007/s00521-023-08656-0},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18377-18393},
  shortjournal = {Neural Comput. Appl.},
  title        = {Chaotic stabilization analysis for neutral-type memristive neural networks via reliable and sampled-data controller},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GAN–XGB–cavity: Automated estimation of underground
cavities’ properties using GPR data. <em>NCA</em>, <em>35</em>(25),
18357–18376. (<a
href="https://doi.org/10.1007/s00521-023-08655-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, various techniques have been implemented to investigate the cavity beneath the pavement using ground-penetrating radar (GPR) data. These techniques usually focus on the determination of the height of the cavity and the depth at which it is located, which play a vital role in the agencies’ decision-making on the appropriate rehabilitation method for the pavement. Image processing, a relatively advanced technique that utilizes the image generated from the GPR data, has been used for this purpose. However, it is still time-consuming and yields low accuracy. As a solution, this study proposes a machine learning (ML)-based method to estimate cavity properties, such as depth and height, from GPR images with high precision in a significantly reduced time. In this study, a deep convolutional generative adversarial networks-based hyperbolic fitting algorithm, called GAN–cavity, was developed based on the Pix2Pix model to identify multi-shape signature segmentation from the GPR data. The GAN–cavity was trained and tested using 1920 and 480 images, respectively, and the model performed well with an average F1–score of 83.1 per cent. Consequently, an extreme gradient boosting (XGBoost) algorithm was used to predict the cavity depth and height based on the GAN–cavity results. Moreover, the developed model (XGB–cavity classifier) can classify the cavity’s height into three classes: small, medium, and large. The XGBoost model XGB–cavity regressor used 341 and 87 cavities for training and testing, respectively, yielding regression scores (R2) and root mean squared error (RMSE) of 0.88 and 3.28 cm in cavity depth prediction, respectively. By applying the support vector machine synthetic minority oversampling technique (SVM–SMOTE) algorithm to overcome the data imbalance, the XGB–cavity classifier model obtained a high accuracy of 0.89 with precision–avg, recall–avg, and F1–score–avg of 0.83, 0.83, and 0.83, respectively. Based on the results, the proposed method (GAN–XGB–cavity) of combining the GAN–cavity and XGB–cavity can successfully identify and fit multi-shape segmentation for depth estimation and height classification of cavities.},
  archive      = {J_NCA},
  author       = {Tran, Van Phuc and Nguyen, Son Dong and Lee, Hyun Jong and Tran, Thai Son and Elipse, Carlo},
  doi          = {10.1007/s00521-023-08655-1},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18357-18376},
  shortjournal = {Neural Comput. Appl.},
  title        = {GAN–XGB–cavity: Automated estimation of underground cavities’ properties using GPR data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of non-trivial preservable quotient spaces in
s-box(es). <em>NCA</em>, <em>35</em>(25), 18343–18355. (<a
href="https://doi.org/10.1007/s00521-023-08654-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Substitution Box (S-Box) is employed in block ciphers to ensure non-linearity. An n-bit bijective S-Box is a member of the Symmetric Group $$\mathbb {S}_{2^{n}}$$ . Ideally, an S-Box must follow a stringent cryptographic profile. Designing an S-Box is a transparent and justified process. The concerning point for an evaluator is the presence of vulnerabilities in the design of an S-Box, i.e., Kuznyechick. If a malicious designer keeps the non-trivial subspaces secret, it leads to sophisticated cryptanalytic attacks. This article investigates the behaviour of non-trivial subspaces in an S-Box and its Affine, Extended Affine (EA) and Carlet-Charpin-Zinoviev (CCZ) equivalence classes. This paper presents a novel algorithm for finding preservable quotient spaces in an S-Box, thus leveraging a way for shortlisting the potential candidates for an S-Box with backdoors. The proposed work emphasizes checking whether a target S-Box is a potential backdoor candidate. The backdoored designs proposed by KG Paterson, Carlo Harpes and Bannier are being identified and validated with the help of the proposed algorithm. Our findings establish that the additive linear structures responsible for the non-trivial subspace are not invariant under the EA and CCZ. Moreover, the analysis of $$3{-}bit$$ permutations reveals that almost 23\% population of $$\mathbb {S}_{2^{3}}$$ preserve the quotient subspaces. Irrespective of the linear structures in its non-linear layer, the NIST Lightweight competitors do not preserve the quotient spaces in both the input and output space.},
  archive      = {J_NCA},
  author       = {Fahd, Shah and Afzal, Mehreen and Shah, Dawood and Iqbal, Waseem and Abbas, Yawar},
  doi          = {10.1007/s00521-023-08654-2},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18343-18355},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of non-trivial preservable quotient spaces in S-box(es)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Applicable image cryptosystem using bit-level permutation,
particle swarm optimisation, and quantum walks. <em>NCA</em>,
<em>35</em>(25), 18325–18341. (<a
href="https://doi.org/10.1007/s00521-023-08643-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital data plays a paramount part in various fields of life, in which multimedia data represent the majority of transferred digital data via communication networks. Consequently, cryptographers and researchers have paid attention to the security of multimedia. Chaotic models are utilised intensely with optimisation techniques for designing modern multimedia cryptosystems, but the role of optimisation approaches is to improve experimental outcomes rather than complex computations in designing cryptosystems. Amidst the rapid evolution of quantum resources, current multimedia cryptosystems may be cracked because their construction relies on mathematical paradigms. This paper introduces a robust image cryptosystem that leverages bit-level permutation, particle swarm optimization, the 3D logistic system, and quantum walk. In the presented cryptosystem, the probability distribution generated by quantum walk and the chaotic sequences produced by the 3D logistic function are utilized as inputs for a customized particle swarm optimization algorithm. The resulting keystreams are then employed in both the permutation phase (at the pixel and bit levels) and substitution phase of the image cryptosystem. Experimental results indicate that the suggested cryptosystem has high-security contra different raids such as differential, statistical, and occlusion attacks. The average outcome for local entropy, global entropy, NPCR (Number of Pixel Change Rate), UACI (Unified Average Changed Intensity), Chi-square, and encryption speed are measured at 7.9025, 7.99985, 99.61306\%, 33.4657\%, 256.960725, and 1.7081 megabits per second, respectively.},
  archive      = {J_NCA},
  author       = {Abd-El-Atty, Bassem and Abd EL-Latif, Ahmed A.},
  doi          = {10.1007/s00521-023-08643-5},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18325-18341},
  shortjournal = {Neural Comput. Appl.},
  title        = {Applicable image cryptosystem using bit-level permutation, particle swarm optimisation, and quantum walks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FDDN: Frequency-guided network for single image dehazing.
<em>NCA</em>, <em>35</em>(25), 18309–18324. (<a
href="https://doi.org/10.1007/s00521-023-08637-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haze appearing in natural scene images generally contains nonhomogeneous characteristics such as filaments, masses, and mist. The high-frequency part of hazy images contains variable background textures and haze shapes, whereas regions with mostly uniform distribution are dominated by low-frequency information. Although existing methods based on convolutional neural networks have achieved remarkable progress in single image dehazing, the intrinsic hazy image patterns have been neglected in most models. We propose a frequency division dehazing network to leverage prior knowledge characterizing hazy images. The proposed network processes shallow feature maps through high-, medium-, and low-frequency branches. This separation facilitates a flexible architecture, whose branch handling lower-frequency components is less redundant given its relatively simpler background and haze shapes. Then, by integrating knowledge extracted from all the network branches using feature fusion, the proposed network fully exploits the variety of frequency characteristics in hazy images and achieves 39.51 PSNR and 0.9931 SSIM on the RESIDE dataset. Experiments on both synthetic and real hazy images demonstrate the superiority of the proposed network over several existing state-of-the-art methods, demonstrating the effectiveness of exploiting prior knowledge in hazy images.},
  archive      = {J_NCA},
  author       = {Shen, Haozhen and Wang, Chao and Deng, Liangjian and He, Liangtian and Lu, Xiaoping and Shao, Mingwen and Meng, Deyu},
  doi          = {10.1007/s00521-023-08637-3},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18309-18324},
  shortjournal = {Neural Comput. Appl.},
  title        = {FDDN: Frequency-guided network for single image dehazing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic analysis of deep learning methods and potential
attacks in internet-of-things surfaces. <em>NCA</em>, <em>35</em>(25),
18293–18308. (<a
href="https://doi.org/10.1007/s00521-023-08634-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usage of intelligent IoT devices is exponentially rising, and so the possibility of attacks in the IoT surfaces. The deep leaning algorithms are competent for directing the sanctuary investigation of IoT systems but have not upgraded the analysis of potential attacks in IoT. This paper aims to advance deep learning methods to create upgraded security strategies for IoT frameworks quickly. The study of the IoT security threats identified with inalienable or recently presented risks is done. Also, this paper does a quick examination of different possible attack surfaces for the IoT framework, and the potential risks identified with each character. The systematic survey of deep learning methods for IoT security and the existence of the chances, focal points, and weaknesses of every strategy opens the door significant for future research.},
  archive      = {J_NCA},
  author       = {Barnawi, Ahmed and Gaba, Shivani and Alphy, Anna and Jabbari, Abdoh and Budhiraja, Ishan and Kumar, Vimal and Kumar, Neeraj},
  doi          = {10.1007/s00521-023-08634-6},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18293-18308},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic analysis of deep learning methods and potential attacks in internet-of-things surfaces},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ingot oxide slag detection using two-stage UNet network
based on mixed supervised learning. <em>NCA</em>, <em>35</em>(25),
18277–18292. (<a
href="https://doi.org/10.1007/s00521-023-08600-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new method for detecting the amount of oxide slag on metal ingots, which is a critical indicator of the quality of the ingots. The challenge arises due to the irregular shape and small number of samples of the oxide slag, which makes it difficult to create a pixel-level label dataset for training a semantic segmentation network. To overcome this, a two-stage UNet network based on mixed supervised learning is proposed in this paper. The network uses a combination of a small number of pixel-level labels and a large number of weak label samples to reduce the cost of creating the dataset while achieving better detection accuracy. To solve the issue of overfitting due to the small number of samples, an improved generative adversarial network (GAN) is used to generate oxide slag images with arbitrary shapes to expand the dataset and improve the detection accuracy. Experiments show that the proposed network is highly effective in accurately detecting the distribution of oxide slag on metal ingots. Compared to existing segmentation algorithms, the network achieves higher accuracy while requiring a lower cost for dataset creation. The results of this work have important implications for the practical application of intelligent sensing in slag-picking robots.},
  archive      = {J_NCA},
  author       = {Wu, Jie and Xu, Degang and Yang, Chunhua and Gui, Weihua},
  doi          = {10.1007/s00521-023-08600-2},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18277-18292},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ingot oxide slag detection using two-stage UNet network based on mixed supervised learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot semantic segmentation: A review on recent
approaches. <em>NCA</em>, <em>35</em>(25), 18251–18275. (<a
href="https://doi.org/10.1007/s00521-023-08758-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot semantic segmentation (FSS) is a challenging task that aims to learn to segment novel categories with only a few labeled images, and it has a wide range of real-world applications. Recently, the performance of FSS has been greatly promoted by using deep learning approaches. In this paper, we provide a systematic review of recent advances to fully understand FSS. Firstly, we introduce the definition and evaluation metrics of FSS as well as popular datasets. Next, we review representative FSS approaches and categorize them into FSS based on parametric metric learning and FSS based on non-parametric metric learning from the parameter learning perspectives in the metric phase. With this taxonomy, we summarize and discuss the pros and cons of different FSS methods, and quantitative results are given for the described methods, following up with a discussion of the results. We then introduce some representative applications of FSS. Finally, we discuss the limitations of the existing approaches and provide potential future research directions for FSS.},
  archive      = {J_NCA},
  author       = {Chang, Zhaobin and Lu, Yonggang and Ran, Xingcheng and Gao, Xiong and Wang, Xiangwen},
  doi          = {10.1007/s00521-023-08758-9},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18251-18275},
  shortjournal = {Neural Comput. Appl.},
  title        = {Few-shot semantic segmentation: A review on recent approaches},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep reinforcement learning empowered joint mode selection
and resource allocation for RIS-aided D2D communications. <em>NCA</em>,
<em>35</em>(25), 18231–18249. (<a
href="https://doi.org/10.1007/s00521-023-08745-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Device-to-device (D2D) communication has been regarded as a promising solution to alleviate the mobile traffic explosion problem for its capabilities of improving system data rate and resource utilization. A reconfigurable intelligent surface (RIS) aided mobile D2D communications framework is investigated, where the RIS is deployed to improve communication quality. As the transmission distance of D2D pairs changes, the mode selection for D2D pairs and the phase shift design for RIS is essential for mobile scenarios. Therefore, we formulate a joint optimization problem of mode selection, channel assignment, power allocation, and discrete phase shift selection to maximize the average sum data rate of D2D pairs. This problem is also constrained by the maximum transmit power and the minimum data rate requirements of users, where the latter is to guarantee the fairness of D2D pairs. We first reformulate the original sequential decision-making problem into a Markov game (MG) problem to solve the challenging optimization. Furthermore, a multi-agent deep reinforcement learning (MADRL) framework is proposed, in which multiple agents cooperatively determine the joint mode selection and resource allocation strategy. The proposed MADRL-based framework combines both the multi-pass deep Q-networks (MP-DQN) algorithm and the decaying DQN algorithm to solve the optimization problem. Specifically, we adopt the MP-DQN algorithm for D2D pairs to handle the hybrid discrete-continuous action space. Moreover, the decaying DQN algorithm is invoked by the RIS agent to select discrete phase shifts. Simulation results demonstrate that the proposed algorithm can converge under different cases. The proposed MADRL-based algorithm outperforms the combination algorithm of DQN and the deep deterministic policy gradient (DDPG) in terms of system performance. Moreover, it is also shown that the average sum data rate of D2D pairs can be significantly improved by deploying the RIS and further enhanced by increasing the number of reflecting elements (REs).},
  archive      = {J_NCA},
  author       = {Guo, Liang and Jia, Jie and Chen, Jian and Du, An and Wang, Xingwei},
  doi          = {10.1007/s00521-023-08745-0},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18231-18249},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep reinforcement learning empowered joint mode selection and resource allocation for RIS-aided D2D communications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Human engagement providing evaluative and informative
advice for interactive reinforcement learning. <em>NCA</em>,
<em>35</em>(25), 18215–18230. (<a
href="https://doi.org/10.1007/s00521-021-06850-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive reinforcement learning proposes the use of externally sourced information in order to speed up the learning process. When interacting with a learner agent, humans may provide either evaluative or informative advice. Prior research has focused on the effect of human-sourced advice by including real-time feedback on the interactive reinforcement learning process, specifically aiming to improve the learning speed of the agent, while minimising the time demands on the human. This work focuses on answering which of two approaches, evaluative or informative, is the preferred instructional approach for humans. Moreover, this work presents an experimental setup for a human trial designed to compare the methods people use to deliver advice in terms of human engagement. The results obtained show that users giving informative advice to the learner agents provide more accurate advice, are willing to assist the learner agent for a longer time, and provide more advice per episode. Additionally, self-evaluation from participants using the informative approach has indicated that the agent’s ability to follow the advice is higher, and therefore, they feel their own advice to be of higher accuracy when compared to people providing evaluative advice.},
  archive      = {J_NCA},
  author       = {Bignold, Adam and Cruz, Francisco and Dazeley, Richard and Vamplew, Peter and Foale, Cameron},
  doi          = {10.1007/s00521-021-06850-6},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18215-18230},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human engagement providing evaluative and informative advice for interactive reinforcement learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FIRe-GAN: A novel deep learning-based infrared-visible
fusion method for wildfire imagery. <em>NCA</em>, <em>35</em>(25),
18201–18213. (<a
href="https://doi.org/10.1007/s00521-021-06691-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wildfire detection is of paramount importance to avoid as much damage as possible to the environment, properties, and lives. In this regard, the fusion of thermal and visible information into a single image can potentially increase the robustness and accuracy of wildfire detection models. In the field of visible-infrared image fusion, there is a growing interest in Deep Learning (DL)-based image fusion techniques due to their reduced complexity; however, the most DL-based image fusion methods have not been evaluated in the domain of fire imagery. Additionally, to the best of our knowledge, no publicly available dataset contains visible-infrared fused fire images. In the present work, we select three state-of-the-art (SOTA) DL-based image fusion techniques and evaluate them for the specific task of fire image fusion, and compare the performance of these methods on selected metrics. Finally, we also present an extension to one of the said methods, that we called FIRe-GAN, that improves the generation of artificial infrared and fused images.},
  archive      = {J_NCA},
  author       = {Ciprián-Sánchez, J. F. and Ochoa-Ruiz, G. and Gonzalez-Mendoza, M. and Rossi, L.},
  doi          = {10.1007/s00521-021-06691-3},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18201-18213},
  shortjournal = {Neural Comput. Appl.},
  title        = {FIRe-GAN: A novel deep learning-based infrared-visible fusion method for wildfire imagery},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective sample size, dimensionality, and generalization in
covariate shift adaptation. <em>NCA</em>, <em>35</em>(25), 18187–18199.
(<a href="https://doi.org/10.1007/s00521-021-06615-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supervised learning, training and test datasets are often sampled from distinct distributions. Domain adaptation techniques are thus required. Covariate shift adaptation yields good generalization performance when domains differ only by the marginal distribution of features. Covariate shift adaptation is usually implemented using importance weighting, which may fail, according to common wisdom, due to small effective sample sizes (ESS). Previous research argues this scenario is more common in high-dimensional settings. However, how effective sample size, dimensionality, and model performance/generalization are formally related in supervised learning, considering the context of covariate shift adaptation, is still somewhat obscure in the literature. Thus, a main challenge is presenting a unified theory connecting those points. Hence, in this paper, we focus on building a unified view connecting the ESS, data dimensionality, and generalization in the context of covariate shift adaptation. Moreover, we also demonstrate how dimensionality reduction or feature selection can increase the ESS and argue that our results support dimensionality reduction before covariate shift adaptation as a good practice.},
  archive      = {J_NCA},
  author       = {Maia Polo, Felipe and Vicente, Renato},
  doi          = {10.1007/s00521-021-06615-1},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18187-18199},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effective sample size, dimensionality, and generalization in covariate shift adaptation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Triplet loss-based embeddings for forensic speaker
identification in spanish. <em>NCA</em>, <em>35</em>(25), 18177–18186.
(<a href="https://doi.org/10.1007/s00521-021-06408-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of digital technology, it is more common that committed crimes or legal disputes involve some form of speech recording where the identity of a speaker is questioned [28]. In face of this situation, the field of forensic speaker identification has been looking to shed light on the problem by quantifying how much a speech recording belongs to a particular person in relation to a population. In this work, we explore the use of speech embeddings obtained by training a CNN using the triplet loss. In particular, we focus on the Spanish language, which has not been extensively studied. We propose extracting the embeddings from speech spectrograms samples, then explore several configurations of such spectrograms, and finally, quantify the embeddings quality. We also show some limitations of our data setting which is predominantly composed by male speakers. At the end, we propose two approaches to calculate the likelihood ratio given out speech embeddings and we show that triplet loss is a good alternative to create speech embeddings for forensic speaker identification.},
  archive      = {J_NCA},
  author       = {Maqueda, Emmanuel and Alvarez-Jimenez, Javier and Mena, Carlos and Meza, Ivan},
  doi          = {10.1007/s00521-021-06408-6},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18177-18186},
  shortjournal = {Neural Comput. Appl.},
  title        = {Triplet loss-based embeddings for forensic speaker identification in spanish},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformers analyzing poetry: Multilingual metrical pattern
prediction with transfomer-based language models. <em>NCA</em>,
<em>35</em>(25), 18171–18176. (<a
href="https://doi.org/10.1007/s00521-021-06692-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The splitting of words into stressed and unstressed syllables is the foundation for the scansion of poetry, a process that aims at determining the metrical pattern of a line of verse within a poem. Intricate language rules and their exceptions, as well as poetic licenses exerted by the authors, make calculating these patterns a nontrivial task. Some rhetorical devices shrink the metrical length, while others might extend it. This opens the door for interpretation and further complicates the creation of automated scansion algorithms useful for automatically analyzing corpora on a distant reading fashion. In this paper, we compare the automated metrical pattern identification systems available for Spanish, English, and German, against fine-tuned monolingual and multilingual language models trained on the same task. Despite being initially conceived as models suitable for semantic tasks, our results suggest that transformers-based models retain enough structural information to perform reasonably well for Spanish on a monolingual setting, and outperforms both for English and German when using a model trained on the three languages, showing evidence of the benefits of cross-lingual transfer between the languages.},
  archive      = {J_NCA},
  author       = {de la Rosa, Javier and Pérez, Álvaro and de Sisto, Mirella and Hernández, Laura and Díaz, Aitor and Ros, Salvador and González-Blanco, Elena},
  doi          = {10.1007/s00521-021-06692-2},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18171-18176},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transformers analyzing poetry: Multilingual metrical pattern prediction with transfomer-based language models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using weak supervision to generate training datasets from
social media data: A proof of concept to identify drug mentions.
<em>NCA</em>, <em>35</em>(25), 18161–18169. (<a
href="https://doi.org/10.1007/s00521-021-06614-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twitter has been a remarkable resource for research in pharmacovigilance in the last decade. Traditionally, rule- or lexicon-based methods have been utilized for automatically extracting drug tweets for human annotation. The process of human annotation to create labeled sets for machine learning models is laborious, time consuming and not scalable. In this work, we demonstrate the feasibility of applying weak supervision (noisy labeling) to select drug data, and build machine learning models using large amounts of noisy labeled data instead of limited gold standard labelled sets. Our results demonstrate the models built with large amounts of noisy data achieve similar performance than models trained on limited gold standard datasets, hence demonstrating that weak supervision helps reduce the need to rely on manual annotation, allowing more data to be easily labeled and useful for downstream machine learning applications, in this case drug mention identification.},
  archive      = {J_NCA},
  author       = {Tekumalla, Ramya and Banda, Juan M.},
  doi          = {10.1007/s00521-021-06614-2},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18161-18169},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using weak supervision to generate training datasets from social media data: A proof of concept to identify drug mentions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning a causal structure: A bayesian random graph
approach. <em>NCA</em>, <em>35</em>(25), 18147–18159. (<a
href="https://doi.org/10.1007/s00521-021-06506-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Random Graph is a random object which takes its values in a space of graphs. We take advantage of the expressibility of graphs in order to model uncertainty about the existence of causal relations within a given set of variables. We adopt a Bayesian point of view which leads us to propose a belief updating procedure with the objective of capturing a causal structure via interaction with a causal environment. Besides learning a causal structure, our proposal is also able to learn optimal actions, i.e., an optimal policy. We test our method in two experiments, each on a different scenario. Our experiments confirm that the proposed technique is able to learn a causal structure as well as an optimal policy. On the other hand, the second experiment shows that our proposal manages to learn an underlying causal model within several tasks in which different configurations of the causal structure are used.},
  archive      = {J_NCA},
  author       = {Gonzalez-Soto, Mauricio and Feliciano-Avelino, Ivan and Sucar, L. Enrique and Escalante, Hugo Jair},
  doi          = {10.1007/s00521-021-06506-5},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18147-18159},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning a causal structure: A bayesian random graph approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-branch deep radial basis function networks for facial
emotion recognition. <em>NCA</em>, <em>35</em>(25), 18131–18145. (<a
href="https://doi.org/10.1007/s00521-021-06420-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition (ER) from facial images is one of the landmark tasks in affective computing with major developments in the last decade. Initial efforts on ER relied on handcrafted features that were used to characterize facial images and then feed to standard predictive models. Recent methodologies comprise end-to-end trainable deep learning methods that simultaneously learn both, features and predictive model, where the most successful models are based on convolutional neural networks (CNNs). While these models have excelled at this task, they still fail at capturing local patterns that emerge in the learning process. We hypothesize these patterns could be captured by variants based on locally weighted learning. Specifically, in this paper we propose a CNN-based architecture enhanced with multiple branches formed by radial basis function (RBF) units that aims at exploiting local information at the final stage of the learning process (i.e., in the layers close to the output layer). Intuitively, these RBF units capture local patterns shared by similar instances using an intermediate representation, then the outputs of the RBFs are feed to a softmax layer that exploits this information to improve the predictive performance of the model. This feature could be particularly advantageous in ER as cultural / ethnicity differences may be potentially identified by the local units. We evaluate the proposed method in several ER datasets and show the proposed methodology achieves state-of-the-art performance in some of them, even when we adopt a pre-trained VGG-Face model as backbone. We show the proposed method outperforms consistently CNNs that do not have the proposed local learning component. Moreover, we found the proposed model is advantageous when training datasets are reduced and when merging images coming from different distributions (e.g., combining two ER datasets). We show it is the incorporation of local information what makes the proposed model competitive.},
  archive      = {J_NCA},
  author       = {Hernández-Luquin, Fernanda and Escalante, Hugo Jair},
  doi          = {10.1007/s00521-021-06420-w},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18131-18145},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-branch deep radial basis function networks for facial emotion recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable robotic systems: Understanding goal-driven
actions in a reinforcement learning scenario. <em>NCA</em>,
<em>35</em>(25), 18113–18130. (<a
href="https://doi.org/10.1007/s00521-021-06425-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic systems are more present in our society everyday. In human–robot environments, it is crucial that end-users may correctly understand their robotic team-partners, in order to collaboratively complete a task. To increase action understanding, users demand more explainability about the decisions by the robot in particular situations. Recently, explainable robotic systems have emerged as an alternative focused not only on completing a task satisfactorily, but also on justifying, in a human-like manner, the reasons that lead to making a decision. In reinforcement learning scenarios, a great effort has been focused on providing explanations using data-driven approaches, particularly from the visual input modality in deep learning-based systems. In this work, we focus rather on the decision-making process of reinforcement learning agents performing a task in a robotic scenario. Experimental results are obtained using 3 different set-ups, namely, a deterministic navigation task, a stochastic navigation task, and a continuous visual-based sorting object task. As a way to explain the goal-driven robot’s actions, we use the probability of success computed by three different proposed approaches: memory-based, learning-based, and introspection-based. The difference between these approaches is the amount of memory required to compute or estimate the probability of success as well as the kind of reinforcement learning representation where they could be used. In this regard, we use the memory-based approach as a baseline since it is obtained directly from the agent’s observations. When comparing the learning-based and the introspection-based approaches to this baseline, both are found to be suitable alternatives to compute the probability of success, obtaining high levels of similarity when compared using both the Pearson’s correlation and the mean squared error.},
  archive      = {J_NCA},
  author       = {Cruz, Francisco and Dazeley, Richard and Vamplew, Peter and Moreira, Ithan},
  doi          = {10.1007/s00521-021-06425-5},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18113-18130},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explainable robotic systems: Understanding goal-driven actions in a reinforcement learning scenario},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Source tasks selection for transfer deep reinforcement
learning: A case of study on atari games. <em>NCA</em>, <em>35</em>(25),
18099–18111. (<a
href="https://doi.org/10.1007/s00521-021-06419-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) combines the benefits of deep learning and reinforcement learning. However, it still requires long training times and a large number of instances to reach an acceptable performance. Transfer learning (TL) offers an alternative to reduce the training time of DRL agents, using less instances and in some cases improving performance. In this work, we propose a transfer learning formulation for DRL across tasks. A relevant problem of TL that we address herein is how to select a proper pre-trained model that will be useful for the target task. We consider the entropy of feature maps in the hidden layers of the convolutional neural network and their actions spaces as relevant features to select a pre-trained model that is then fine-tuned for the target task. We report experimental results of the proposed source task selection methodology when using Deep Q-Networks for learning to play Atari games. Nevertheless, the proposed method could be used in other DRL algorithms (e.g., DDQN, C51, etc.) and also other domains. Results reveal that most of the time our proposed method is capable of selecting source tasks that improve the performance of a model trained from scratch. Additionally, we introduce a method for selecting the most relevant kernels for the target task, the results show that transferring a subset of the convolutional kernels results in similar performance to training the model from scratch while using less parameters.},
  archive      = {J_NCA},
  author       = {García-Ramírez, Jesús and Morales, Eduardo F. and Escalante, Hugo Jair},
  doi          = {10.1007/s00521-021-06419-3},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18099-18111},
  shortjournal = {Neural Comput. Appl.},
  title        = {Source tasks selection for transfer deep reinforcement learning: A case of study on atari games},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LatinX in AI research. <em>NCA</em>, <em>35</em>(25),
18097–18098. (<a
href="https://doi.org/10.1007/s00521-023-08790-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Banda, Juan M. and Ruiz-Garcia, Ariel and Montoya, Laura N. and Arraut, Ivan},
  doi          = {10.1007/s00521-023-08790-9},
  journal      = {Neural Computing and Applications},
  number       = {25},
  pages        = {18097-18098},
  shortjournal = {Neural Comput. Appl.},
  title        = {LatinX in AI research},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Bat algorithm as a metaheuristic
optimization approach in materials and design: Optimal design of a new
float for different materials. <em>NCA</em>, <em>35</em>(24), 18095. (<a
href="https://doi.org/10.1007/s00521-023-08691-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Jalal, Mostafa and Mukhopadhyay, Anal K. and Goharzay, Maral},
  doi          = {10.1007/s00521-023-08691-x},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18095},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: bat algorithm as a metaheuristic optimization approach in materials and design: optimal design of a new float for different materials},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: Color constancy for non-uniform illumination
estimation with variable number of illuminants. <em>NCA</em>,
<em>35</em>(24), 18093. (<a
href="https://doi.org/10.1007/s00521-023-08626-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Domislović, Ilija and Vršnak, Donik and Subašić, Marko and Lončarić, Sven},
  doi          = {10.1007/s00521-023-08626-6},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18093},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Color constancy for non-uniform illumination estimation with variable number of illuminants},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction: Flow-based intrusion detection on
software-defined networks: A multivariate time series anomaly detection
approach. <em>NCA</em>, <em>35</em>(24), 18091. (<a
href="https://doi.org/10.1007/s00521-023-08711-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zavrak, Sultan and Iskefiyeli, Murat},
  doi          = {10.1007/s00521-023-08711-w},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18091},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: flow-based intrusion detection on software-defined networks: a multivariate time series anomaly detection approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Correction to: An enhanced multi-operator differential
evolution algorithm for tackling knapsack optimization problem.
<em>NCA</em>, <em>35</em>(24), 18089. (<a
href="https://doi.org/10.1007/s00521-023-08692-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sallam, Karam M. and Abohany, Amr A. and Rizk-Allah, Rizk M.},
  doi          = {10.1007/s00521-023-08692-w},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18089},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: An enhanced multi-operator differential evolution algorithm for tackling knapsack optimization problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: Multi-valued neural networks i: A
multi-valued associative memory. <em>NCA</em>, <em>35</em>(24),
18087–18088. (<a
href="https://doi.org/10.1007/s00521-023-08690-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Here we provide a corrigendum on Theorem 2 to Article Title: Multi-Valued Neural Networks I: A Multi-Valued Associative Memory. https://doi.org/10.1007/s00521-021-05781-6.},
  archive      = {J_NCA},
  author       = {Maximov, Dmitry and Goncharenko, Vladimir I. and Legovich, Yury S.},
  doi          = {10.1007/s00521-023-08690-y},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18087-18088},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: multi-valued neural networks i: a multi-valued associative memory},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction to: Testing machine learning explanation
methods. <em>NCA</em>, <em>35</em>(24), 18085. (<a
href="https://doi.org/10.1007/s00521-023-08747-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Anderson, Andrew A.},
  doi          = {10.1007/s00521-023-08747-y},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18085},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Testing machine learning explanation methods},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Testing machine learning explanation methods. <em>NCA</em>,
<em>35</em>(24), 18073–18084. (<a
href="https://doi.org/10.1007/s00521-023-08597-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many methods for explaining why a machine learning model produces a given output in response to a given input. The relative merits of these methods are often debated using theoretical arguments and illustrative examples. This paper provides a large-scale empirical test of four widely used explanation methods by comparing how well their algorithmically generated denial reasons align with lender-provided denial reasons using a dataset of home mortgage applications. On a held-out sample of 10,000 denied applications, Shapley additive explanations (SHAP) correspond most closely with lender-provided reasons. SHAP is also the most computationally efficient. As a second contribution, this paper presents a method for computing integrated gradient explanations that can be used for non-differentiable models such as XGBoost.},
  archive      = {J_NCA},
  author       = {Anderson, Andrew A.},
  doi          = {10.1007/s00521-023-08597-8},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18073-18084},
  shortjournal = {Neural Comput. Appl.},
  title        = {Testing machine learning explanation methods},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A2M-LEUK: Attention-augmented algorithm for blood cancer
detection in children. <em>NCA</em>, <em>35</em>(24), 18059–18071. (<a
href="https://doi.org/10.1007/s00521-023-08678-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leukemia is a malignancy that affects the blood and bone marrow. Its detection and classification are conventionally done through labor-intensive and specialized methods. The diagnosis of blood cancer in children is a critical task that requires high precision and accuracy. This study proposes a novel approach utilizing attention mechanism-based machine learning in conjunction with image processing techniques for the precise detection and classification of leukemia cells. The proposed attention-augmented algorithm for blood cancer detection in children (A2M-LEUK) is an innovative algorithm that leverages attention mechanisms to improve the detection of blood cancer in children. A2M-LEUK was evaluated on a dataset of blood cell images and achieved remarkable performance metrics: Precision = 99.97\%, Recall = 100.00\%, F1-score = 99.98\%, and Accuracy = 99.98\%. These results indicate the high accuracy and sensitivity of the proposed approach in identifying and categorizing leukemia, and its potential to reduce the workload of medical professionals and improve the diagnosis of leukemia. The proposed method provides a promising approach for accurate and efficient detection and classification of leukemia cells, which could potentially improve the diagnosis and treatment of leukemia. Overall, A2M-LEUK improves the diagnosis of leukemia in children and reduces the workload of medical professionals.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and Gamel, Samah A.},
  doi          = {10.1007/s00521-023-08678-8},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18059-18071},
  shortjournal = {Neural Comput. Appl.},
  title        = {A2M-LEUK: Attention-augmented algorithm for blood cancer detection in children},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient lightweight algorithm for scheduling tasks onto
dynamically reconfigurable hardware using graph-oriented simulated
annealing. <em>NCA</em>, <em>35</em>(24), 18035–18057. (<a
href="https://doi.org/10.1007/s00521-023-08682-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling complex applications as task graphs on finite computational resources assuring task interdependencies is a well-known NP-complete optimization problem. This problem is well-addressed for microprocessor systems but for Dynamically Reconfigurable Hardware (DRHW) systems in which, in addition to tasks, the reconfiguration time and complexity also have to be scheduled; this problem is more complicated. DRHW reconfiguration overhead is considerable and can be crucial for real-world applications. To deal with this overhead, in this paper, a meta-heuristic method named Graph-Oriented Simulated Annealing (GOSA) is proposed. By introducing an innovative graph and solution structures called schedule graphs, and also some controlling functions which are inherited from the nature of the problem, the proposed method adapts itself to the characteristics of the problem. This helps the algorithm to adjust its exploration and exploitation speed and accuracy according to the requirements of the given problem and consequently find high-quality solutions quickly. To demonstrate the performance of the proposed method, it was tested on several synthetic and real-world benchmark task graphs, and the results were compared with a selection of classic and state-of-the-art algorithms. The method is comprehensively evaluated by performing numerous experiments in terms of execution time, makespan, scalability, and reliability. The results of the experiments on benchmarks show that in terms of the quality of the solutions, GOSA outperforms BGA, HPSO-GA, and FATS by 17\%, 13\%, and 5\%, respectively, and its execution time is considerably less than all competing algorithms. Moreover, according to the experiments done on synthetic graphs, the makespan of the solutions generated by GOSA, Genetic Algorithm (GA), and the Gxhaustive Search over the List Scheduler are improved on average by 7.2\%, 8.1\%, and 19.1\%, respectively. The most significant achievement of the proposed method is its execution time which is 31 times faster than GA. Finally, the results confirm that the proposed method is scalable for large task graphs, and its reliability is superior.},
  archive      = {J_NCA},
  author       = {Mollajafari, Morteza},
  doi          = {10.1007/s00521-023-08682-y},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18035-18057},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient lightweight algorithm for scheduling tasks onto dynamically reconfigurable hardware using graph-oriented simulated annealing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New weighted BERT features and multi-CNN models to enhance
the performance of MOOC posts classification. <em>NCA</em>,
<em>35</em>(24), 18019–18033. (<a
href="https://doi.org/10.1007/s00521-023-08673-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning is an essential requirement for humans, and its means have evolved. Ten years ago, Massive Open Online Courses (MOOCs) were introduced, attracting many interests and learners. MOOCs provide forums for learners to interact with instructors and to express any problems they encounter in the educational process. However, MOOCs have a high dropout rate due to the difficulties of following up on learners&#39; posts and identifying the urgent ones to react quickly. This research aims to assist instructors in automatically identifying urgent posts, making it easier to respond to such posts rapidly, increasing learner engagement, and improving course completion rate. In this paper, we propose a novel classification model for identifying urgent posts. The proposed model consists of four stages. In the first stage, the post-text is code-encoded and vectorized using a pre-trained BERT model. In the second stage, a novel feature aggregation model is proposed to reveal data-based relationships between token features and their representation in a higher-level feature. In the third stage, a novel model based on convolutional neural networks (CNNs) is proposed to reveal the meaning of a text context more accurately. In the last stage, the extracted composite features are used to classify the text of the post. Several experimental studies were conducted to get the best performance of the proposed stages of the system. The experimental results demonstrated the architectural efficiency of the proposed feature aggregation and multiple CNN models, as well as the accuracy of the proposed system compared to the current research.},
  archive      = {J_NCA},
  author       = {El-Rashidy, Mohamed A. and Farouk, Ahmed and El-Fishawy, Nawal A. and Aslan, Heba K. and Khodeir, Nabila A.},
  doi          = {10.1007/s00521-023-08673-z},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18019-18033},
  shortjournal = {Neural Comput. Appl.},
  title        = {New weighted BERT features and multi-CNN models to enhance the performance of MOOC posts classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level consistency regularization for domain adaptive
object detection. <em>NCA</em>, <em>35</em>(24), 18003–18018. (<a
href="https://doi.org/10.1007/s00521-023-08677-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the adaptability of detectors, most existing domain adaptation algorithms adopt adversarial learning to align feature distributions between source and target datasets. Different from previous methods, this work explores the possibility of transferring detectors with only source domain data and style information of the target domain. Specifically, we propose three consistency regularizations to enhance the adaptation performance of the detector. First, the source domain and the synthetic domain share the same image content, and the supervision regularization fully exploits the source annotations, which narrows the domain gap and saves labeling costs. Second, prediction regularization improves the robustness of the detector to category semantics and location awareness in different domains. Third, self-discovering feature regularization projects the detector’s attention to object-related regions, which are more discriminative than background noise. In addition, our method can cooperate with the classic domain adaptation algorithm to further improve the generalization of the detector, which shows that both the content and style information of target domain images are crucial for the transfer process. Extensive experiments have been conducted on multiple detection benchmarks, including Foggy Cityscapes, Sim10k, KITTI, Clipart, and Watercolor datasets. The favorable performance compared with existing state-of-the-art methods confirms the effectiveness of the proposed consistency regularizations.},
  archive      = {J_NCA},
  author       = {Tian, Kun and Zhang, Chenghao and Wang, Ying and Xiang, Shiming},
  doi          = {10.1007/s00521-023-08677-9},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {18003-18018},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-level consistency regularization for domain adaptive object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new hybrid model of convolutional neural networks and
hidden markov chains for image classification. <em>NCA</em>,
<em>35</em>(24), 17987–18002. (<a
href="https://doi.org/10.1007/s00521-023-08644-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have lately proven to be extremely effective in image recognition. Besides CNN, hidden Markov chains (HMCs) are probabilistic models widely used in image processing. This paper presents a new hybrid model composed of both CNNs and HMCs. The CNN model is used for feature extraction and dimensionality reduction and the HMC model for classification. In the new model, named CNN-HMC, convolutional and pooling layers of the CNN model are applied to extract features maps. Also a Peano scan is applied to obtain several HMCs. Expectation–Maximization (EM) algorithm is used to estimate HMC’s parameters and to make the Bayesian Maximum Posterior Mode (MPM) classification method used unsupervised. The objective is to enhance the performances of the CNN models for the image classification task. To evaluate the performance of our proposal, it is compared to six models in two series of experiments. In the first series, we consider two CNN-HMC and compare them to two CNNs, 4Conv and Mini AlexNet, respectively. The results show that CNN-HMC model outperforms the classical CNN model, and significantly improves the accuracy of the Mini AlexNet. In the second series, it is compared to four models CNN-SVMs, CNN-LSTMs, CNN-RFs, and CNN-gcForests, which only differ from CNN-HMC by the second classification step. Based on five datasets and four metrics recall, precision, F1-score, and accuracy, results of these comparisons show again the interest of the proposed CNN-HMC. In particular, with a CNN model of 71\% of accuracy, the CNN-HMC gives an accuracy ranging between 81.63\% and 92.5\%.},
  archive      = {J_NCA},
  author       = {Goumiri, Soumia and Benboudjema, Dalila and Pieczynski, Wojciech},
  doi          = {10.1007/s00521-023-08644-4},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17987-18002},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new hybrid model of convolutional neural networks and hidden markov chains for image classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prioritization of strategies for a sustainable regional
transportation infrastructure by hybrid spherical fuzzy group
decision-making approach. <em>NCA</em>, <em>35</em>(24), 17967–17986.
(<a href="https://doi.org/10.1007/s00521-023-08660-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The East African Community, inspired by successful trading blocs, has already begun major transportation strategic plans that will necessarily require large investments. Additionally, significant efforts have been made to harmonize regional transportation legislation and regulations. However, some challenges that may arise in developing such a sustainable regional transportation infrastructure should be carefully determined. In this study, a spherical fuzzy multi-criteria decision-making method is proposed. Ten criteria characterizing the challenges in the regional transportation infrastructure problem have been identified as a result of the pertaining reviewed literature and expert opinions. These criteria were used to prioritize seven strategies for sustainable regional transportation infrastructure. To address complex group decision-making issues, this study presents the integration of Weighted Aggregated Sum Product Assessment (WASPAS) with Step-Wise Weight Assessment Ratio Analysis (SWARA) in a spherical fuzzy (SF) environment. The weight and importance levels of criteria are evaluated using SF-SWARA. SF-WASPAS is then used to prioritize the strategies based on the SF-SWARA-weighted criteria. To assess the effectiveness of the proposed methodology, a sensitivity analysis is carried out, revealing that research and development (S7) and adequate institutional and regulatory framework (S4) are the most appropriate strategies for dealing with these challenges, respectively. The study offers a novel approach for regional political leaders who aim to promote progressive policy, regulatory, and economic frameworks, along with a strong human and institutional capacity for collaborative research, technology, and innovation.},
  archive      = {J_NCA},
  author       = {Bouraima, Mouhamed Bayane and Qiu, Yanjun and Ayyildiz, Ertugrul and Yildiz, Aslihan},
  doi          = {10.1007/s00521-023-08660-4},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17967-17986},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prioritization of strategies for a sustainable regional transportation infrastructure by hybrid spherical fuzzy group decision-making approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep reinforcement learning-based proportional–integral
control for dual-active-bridge converter. <em>NCA</em>, <em>35</em>(24),
17953–17966. (<a
href="https://doi.org/10.1007/s00521-023-08667-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the wide zero-voltage-switching range and low power losses, triple-phase-shift (TPS) modulation is commonly utilized in dual-active-bridge (DAB) converters. However, it is difficult to model it and design its controller for the reasons of model uncertainties and nonlinearity. In this paper, a deep reinforcement learning (DRL)-supervised proportional–integral (PI) control algorithm is proposed. The PI controller is used as a base controller to stabilize the output voltage of the DAB converter. In order to improve the control accuracy and the dynamic performance, the PI parameters are tuned by DRL. Besides, all operation modes of the TPS are learned during the training process. Thus, the operation mode with maximum power efficiency can be selected under a wide operation range. The simulation comparison results demonstrate the efficacy and superiorities of the proposed method.},
  archive      = {J_NCA},
  author       = {You, Weiyu and Yang, Genke and Chu, Jian and Ju, Changjiang},
  doi          = {10.1007/s00521-023-08667-x},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17953-17966},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep reinforcement learning-based proportional–integral control for dual-active-bridge converter},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Function matrix projective synchronization for unknown and
delayed fractional-order neural network. <em>NCA</em>, <em>35</em>(24),
17941–17952. (<a
href="https://doi.org/10.1007/s00521-023-08641-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional-order neural networks (FONNs) can improve the computational ability and facilitate the information transmission of neurons, whose projective synchronization and applications have been widely used in the fields of security communication. Our main work will propose a new synchronization type, i.e., function matrix projective synchronization (FMPS), and realize the FMPS for delayed and unknown FONNs for the first time. Firstly, based on the traditional PS, we generalize the projective proportionality factors to any function matrix depending on time $$t$$ , present the error function and define the FMPS, which is more extensive and practical than other synchronization types. Then, for delayed and unknown FONNs, the adaptive control strategy with the controlling strength updated rules and the unknown parameter adaptive rules are designed and the FMPS is realized by establishing a Lyapunov function. Finally, for a numerical example, trajectories of the synchronization errors approach to 0 and unknown parameters converge to the fixed constants, which illustrate the efficiency of the proposed theory analysis. This work may offer a useful method to explore FMPS for fractional-order systems.},
  archive      = {J_NCA},
  author       = {He, Jin-Man and Pei, Li-Jun},
  doi          = {10.1007/s00521-023-08641-7},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17941-17952},
  shortjournal = {Neural Comput. Appl.},
  title        = {Function matrix projective synchronization for unknown and delayed fractional-order neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning-based protection scheme for fault detection
and classification in wind integrated HVDC transmission system under
dissimilar fault scenarios and uncertain conditions. <em>NCA</em>,
<em>35</em>(24), 17929–17940. (<a
href="https://doi.org/10.1007/s00521-023-08663-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need of HVDC transmission is continuously escalating due to the far distances from power generation sites and load centers. HVDC transmission is superior to AC transmission because it eliminates the need for intermediate substations, reduces power loss, and eliminates the need for synchronization. However, protection of the HVDC system is the main challenge due to the rapid rise in the fault current and the varying operational dynamics of the renewable sources. Under these conditions, traditional relaying algorithms based on the threshold measurement of the current may fail to detect the operational dynamics of the renewable sources. In addition to the above-mentioned issues, detection of the fault is more critical and challenging if the value of the fault resistance is high. In these conditions, it is quite complex to detect the fault due to the lower magnitude of fault current. Motivated by the above challenge in the proposed HVDC system, in this manuscript, a convolutional neural network (CNN)-based protection scheme has been proposed to perform the tasks of fault detection and fault classification as well as location estimation under diverse fault parameters. To validate the robustness of the protection scheme, two statistical-reliability indices, i.e., dependability and security, have been considered and analyzed for a number of fault scenarios. To analyze the robustness of the proposed protection scheme, SVM- and DT-based machine learning classifiers are considered. The result in Sect. 5 indicates that the proposed protection scheme is capable and accurate enough to detect the fault in diverse operating conditions.},
  archive      = {J_NCA},
  author       = {Tiwari, Shankarshan Prasad},
  doi          = {10.1007/s00521-023-08663-1},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17929-17940},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning-based protection scheme for fault detection and classification in wind integrated HVDC transmission system under dissimilar fault scenarios and uncertain conditions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regional realness-aware generative adversarial networks for
stain normalization. <em>NCA</em>, <em>35</em>(24), 17915–17927. (<a
href="https://doi.org/10.1007/s00521-023-08659-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stain normalization is the standardization of the color appearance and has been commonly used in computer-aided diagnosis (CAD) systems. Recently, Generative Adversarial Networks (GANs)-based methods are becoming popular for stain style transfer since they succeed in maintaining structural and color information. The CycleGAN, which is a variant of GANs, has been applied to stain normalization, showing state-of-the-art performance. CycleGAN uses PatchGAN as a discriminator that returns a matrix where each pixel represents the local region of the image. However, the generator utilizes the output of the PatchGAN only for network optimization. The gradient returning to the generator from discriminator is also quite small during training which causes optimizing the network parameters inefficiently. In this paper, we aim to extend the CycleGAN to handle this problem using the output of the convolution layer in the PatchGAN, which we call Regional Realness-Aware Mask, to guide the generator about which regions are incorrect in the input image. In this context, the generator pays more attention to these regions in the next iterations, producing more realistic images. The performance of the proposed Regional Realness-Aware Generative Adversarial Networks (RRAGAN) model was evaluated on a commonly used MITOS-ATYPIA histopathology dataset. The RRAGAN method achieved the highest results in stain normalization compared to the five state-of-the art methods with a large margin in terms of PSNR, SSIM, and RMSE metrics. It achieved PSNR of 24.109, SSIM of 0.933, and RMSE of 8.3576 under the same settings. We also evaluated the impact of the RRAGAN to the segmentation performance on the MICCAI’16 GlaS dataset. It improved the segmentation performance by 4.3\% as it reduces the stain color variation. The proposed method could potentially be used as a preprocessing step and can significantly help CAD systems to demonstrate stable performance under color variations.},
  archive      = {J_NCA},
  author       = {Baykal Kablan, Elif},
  doi          = {10.1007/s00521-023-08659-x},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17915-17927},
  shortjournal = {Neural Comput. Appl.},
  title        = {Regional realness-aware generative adversarial networks for stain normalization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task-aware prototype refinement for improved few-shot
learning. <em>NCA</em>, <em>35</em>(24), 17899–17913. (<a
href="https://doi.org/10.1007/s00521-023-08645-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In realistic scenarios, few-shot classification aims to generalize from common classes to novel classes with limited labeled samples. Most of existing transductive methods concentrate on probing into instance-prototype relations in a fixed way, without considering task-relevant information. In this paper, we perform task-aware prototype refinement (TAPR) explicitly for metric-based few-shot learning. Instead of utilizing fixed prior of queries, we adaptively estimate the query distribution, which can accommodate to both balanced and imbalanced situations. Concretely, on the basis of discriminative features from a holistic pre-training and pre-processing stage, we make novel attempts to make the best of task-aware and instance-aware knowledge to conduct selecting and denoising of samples for prototype generation and iterative rectification, which are complementary to each other. Extensive experimental results on four popular benchmark datasets (CUB, CIFAR-FS, miniImageNet and tieredImageNet) demonstrate that our TAPR outperforms most methods in inductive and balanced transductive settings. Besides, it achieves good generalization while maintaining high accuracy in the imbalanced and cross-domain setting.},
  archive      = {J_NCA},
  author       = {Zhang, Wei and Gu, Xiaodong},
  doi          = {10.1007/s00521-023-08645-3},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17899-17913},
  shortjournal = {Neural Comput. Appl.},
  title        = {Task-aware prototype refinement for improved few-shot learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Web-S4AE: A semi-supervised stacked sparse autoencoder model
for web robot detection. <em>NCA</em>, <em>35</em>(24), 17883–17898. (<a
href="https://doi.org/10.1007/s00521-023-08668-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web robots are automated computer programs that can be exploited for benign and malicious activities such as website indexing, monitoring, or unauthorized content scraping and scalping. Several methods are available to detect automated web robots through their footprints and behaviors. Although the accuracy and efficiency of existing methods depend highly on the labeled web log data, countless web requests are generated daily with the help of web robots. Exhaustive and accurate manual labeling of reconstructed sessions is time-consuming and challenging. Further, effective detection of web robots is more challenging with unlabeled or partially labeled data. To address the aforementioned issues, we reformulated web robot detection as a semi-supervised learning problem. In this paper, we propose a deep learning-based Semi-Supervised Stacked Sparse AutoEncoder (Web-S4AE) for web robot detection. The proposed model uses content-based features and features extracted from web access log data to effectively classify web robots. The experiments were conducted on publicly available web log data from a library and information portal to assess the performance of Web-S4AE. The Web-S4AE model was trained in two phases. The first phase; comprises training the model with unlabeled data to extract the hidden information, and in the second phase, the model is fine-tuned using labeled data. The results suggest that incorporating more unlabeled data can significantly improve the classifier&#39;s performance. The Web-S4AE model’s performance was also compared with other models such as the Decision Tree (DT), Random Forest (RF), eXtreme Gradient Boosting (XGBoost), and Multi-Layer Perceptron (MLP).},
  archive      = {J_NCA},
  author       = {Jagat, Rikhi Ram and Sisodia, Dilip Singh and Singh, Pradeep},
  doi          = {10.1007/s00521-023-08668-w},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17883-17898},
  shortjournal = {Neural Comput. Appl.},
  title        = {Web-S4AE: A semi-supervised stacked sparse autoencoder model for web robot detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A 1-d CNN-FCM model for the classification of epileptic
seizure disorders. <em>NCA</em>, <em>35</em>(24), 17871–17881. (<a
href="https://doi.org/10.1007/s00521-023-08665-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seizure is an unusual event of the brain, which leads to the second most common disease of the brain called epilepsy. Electroencephalography (EEG) has the potential to provide insight into the diagnosis of seizure. Our objective is to explore the practical efficiency of the convolutional neural network (CNN) in detecting seizures using EEG signal. A novel CNN-FCM architecture is proposed to classify the seizure signals. The conventional CNN is modified with Fuzzy C-means (FCM) clustering algorithm. The competency of the clustering method is confirmed with the cluster validity index (CVI) parameters such as partition entropy (PE), partition coefficient (PC) and the Xie-Beni index (XB). The efficiency of proposed CNN-FCM architecture is validated and confirmed by considering the standard classification parameters such as accuracy, sensitivity, specificity and F-measure. The two different seizure EEG datasets are utilized to examine the proposed system. The proposed CNN-FCM architecture achieved the classification accuracy of 98.33\% and outperformed with other existing deep learning methods, achieving a less computational time of 0.3286 s in classification. The performance outcomes exhibit the efficiency of the proposed one-dimensional CNN-FCM in the diagnosis of epilepsy. In contrast to other existing automatic seizure detection techniques, the CNN-FCM architecture can perform real-time seizure detection and classification.},
  archive      = {J_NCA},
  author       = {C, Sateesh Kumar Reddy and M, Suchetha},
  doi          = {10.1007/s00521-023-08665-z},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17871-17881},
  shortjournal = {Neural Comput. Appl.},
  title        = {A 1-D CNN-FCM model for the classification of epileptic seizure disorders},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of smart grid stability prediction using
cascade machine learning methods and the internet of things in smart
grid. <em>NCA</em>, <em>35</em>(24), 17851–17869. (<a
href="https://doi.org/10.1007/s00521-023-08605-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a smart grid, the main goals are to provide grid stability, improve power system performance and security, and reduce operations, system maintenance, and planning costs. The prediction stability of smart grid (SG) systems is essential in terms of power loss minimization and the importance of adequate energy policies. SG systems must accurately predict the energy demand and ensure the right amount of energy is available at the right time. If the prediction is inaccurate, it can lead to costly energy production or usage errors and create considerable inefficiencies in the power grid. Due to this, this manuscript offers five different cascade methods to detect the stability of SG systems. Detecting the stability of SG systems enables the grid to respond quickly to changes in demand and supply, improves system reliability, reduces power outages, and increases the overall efficiency of the grid. The present work proposed five different cascade methods with pre-processing, training and testing division, and the classification stages of the classification procedure for estimating SG stability. In the first pre-processing stage, the SG dataset is pre-proceeded with the feature selection (Relief, Fast Correlation-Based Filter (FCBF), and supervised attribute filter). The resampling (the bootstrapping), the Fuzzy C-Means Clustering-Based Feature Weighting (FCMFW), the resampling then feature selection (supervised attribute filter), and the feature selection (supervised attribute filter), then FCMFW. In the second stage, the training and testing division stage, the SG dataset was separated into three test and training data methods before the classification algorithm: The 5 Fold Cross Validation (FVC), 10 FVC, and hold-out (50–50\%). In the third stage, the classification stage, five different classification algorithms, including Naive Kernel Bayes, Linear Support Vector Machine (SVM), Weighted K-Nearest Neighbors, Begged Trees, and Narrow Neural Network classifying algorithms, are used to classify the SG dataset. The simulation results of this study demonstrated that the suggested cascade ML system had achieved significant accuracy in predicting SG stability. The best cascade method is the feature selection (supervised attribute filter) + FCMFW + 10 FCV and then performing the bagged trees algorithm; thus, the new approach affords an accuracy of 99.9\%. Furthermore, due to the rapid growth of ML techniques, sensors, and smart meters technologies, with Machine to Machine communication via the internet of things (IoT), the real-time identification process is made practical with higher accuracy. For this reason, our future research will focus on an IoT-based SG system, an E-stability determination system. Thanks to the proposed cascade method, the SG dataset can be classified easily, quickly, and reliably. E-stability determination systems can help to fast detect, predict, and respond, which is an important application of IoT on the grid systems.},
  archive      = {J_NCA},
  author       = {Önder, Mithat and Dogan, Muhsin Ugur and Polat, Kemal},
  doi          = {10.1007/s00521-023-08605-x},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17851-17869},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of smart grid stability prediction using cascade machine learning methods and the internet of things in smart grid},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multilevel image thresholding based on renyi’s entropy and
golden sinus algorithm II. <em>NCA</em>, <em>35</em>(24), 17837–17850.
(<a href="https://doi.org/10.1007/s00521-023-08658-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image thresholding methods consume a lot of time due to computational complexity when the number of threshold levels increases. In order to reduce computation time and improve thresholding performance, we propose a new thresholding method based on the golden sinus algorithm II (GoldSa-II) and Renyi’s entropy. GoldSa-II narrows the search space and converges to the targeted optimum point (optimal thresholds) more accurately in a shorter time using the decreasing sine function and the golden ratio. Firstly, a two-dimensional non-local means histogram is constructed and segmentation is carried out based on the gray-level images with various thresholding levels. Performance evaluation is done using 12 different image quality measurement indices (BDE, PRI, GCE, SSIM, FSIM, VOI, RMSE, NAE, PSNR, CC, MD, and AD) using proposed the two-dimensional, non-local means golden sinus algorithm II segmentation method (NLM-GoldSa-II). Experimental results have been performed with 300 images obtained from the Berkeley-Benchmark dataset. The results are compared with six other segmentation methods in terms of computational times, fitness values, and optimal thresholding values. In the segmentation performed with 3-level and 5-level thresholding, it is seen from the studies that 7 out of 12 quality measurement indices give the best results when compared to the other segmentation methods. Improvements in the indicated indices have been achieved by 5.4151\% in MD, 33.11\% in CC, 0.1011\% in RMSE, 0.1618\% in FSIM, 0.6180\% in VOI, 0.0615\% in BDE and 0.4557\% in PRI for 3-level thresholding. Improvements in the indicated indices have been achieved by 1.3591\% in NAE, 3.2552\% in MD, 17.6973\% in CC, 0.2176\% in RMSE, 0.1939\% in SSIM, 0.02551\% in FSIM and 1.7236\% in BDE for 5-level thresholding. In addition, it has been shown that the proposed method reaches the highest fitness value when compared to other methods, thus achieving the optimal thresholds. Segmentations of sample images from the BSDS300 dataset are illustrated based on the proposed method, plus other existing segmentation methods, with the proposed method producing superior results over the current methods.},
  archive      = {J_NCA},
  author       = {Olmez, Yagmur and Koca, Gonca Ozmen and Tanyildizi, Erkan and Sengur, Abdulkadir},
  doi          = {10.1007/s00521-023-08658-y},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17837-17850},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multilevel image thresholding based on renyi’s entropy and golden sinus algorithm II},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A generalized hardware architecture for real-time spiking
neural networks. <em>NCA</em>, <em>35</em>(24), 17821–17835. (<a
href="https://doi.org/10.1007/s00521-023-08650-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an area- and power-efficient hardware architecture for the brain-implantable spiking neural networks (SNNs). The proposed generalized hardware architecture is parameterizable and reconfigurable such that the maximum supported number of neurons, the interconnection structure among neurons, and the resolution of the time step can be readily adjusted for realizing various SNN topologies. The designed SNN hardware architecture is capable of emulating moderately-sized SNNs with tens of thousands of neurons in real-time with varying degrees of parallelism, while reducing the resource utilization by 34\% for similarly sized SNNs implemented on a single field-programmable gate array (FPGA). We evaluate the model using the MNIST digit recognition benchmark and show that the network can accurately classify handwritten digits with 89.8\% accuracy. Compared to the other recently implemented SNN emulators based on FPGAs, the designed and implemented single-FPGA system is able to emulate moderately-sized SNNs instead of using a cluster of FPGAs or CPUs. The application-specific integrated circuit (ASIC) implementation of a moderately-sized SNN is estimated to occupy 3.6 mm2 of silicon area. Post-layout synthesis and simulation results show that the ASIC will dissipate 3.6 mW of power from a 1.16 V supply while operating at 34.7 MHz in a standard 32-nm CMOS process.},
  archive      = {J_NCA},
  author       = {Valencia, Daniel and Alimohammad, Amir},
  doi          = {10.1007/s00521-023-08650-6},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17821-17835},
  shortjournal = {Neural Comput. Appl.},
  title        = {A generalized hardware architecture for real-time spiking neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Landslide detection in real-time social media image streams.
<em>NCA</em>, <em>35</em>(24), 17809–17819. (<a
href="https://doi.org/10.1007/s00521-023-08648-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lack of global data inventories obstructs scientific modeling of and response to landslide hazards which are oftentimes deadly and costly. To remedy this limitation, new approaches suggest solutions based on citizen science that requires active participation. In contrast, as a non-traditional data source, social media has been increasingly used in many disaster response and management studies in recent years. Inspired by this trend, we propose to capitalize on social media data to mine landslide-related information automatically with the help of artificial intelligence techniques. Specifically, we develop a state-of-the-art computer vision model to detect landslides in social media image streams in real-time. To that end, we first create a large landslide image dataset labeled by experts with a data-centric perspective, and then, conduct extensive model training experiments. The experimental results indicate that the proposed model can be deployed in an online fashion to support global landslide susceptibility maps and emergency response.},
  archive      = {J_NCA},
  author       = {Ofli, Ferda and Imran, Muhammad and Qazi, Umair and Roch, Julien and Pennington, Catherine and Banks, Vanessa and Bossu, Remy},
  doi          = {10.1007/s00521-023-08648-0},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17809-17819},
  shortjournal = {Neural Comput. Appl.},
  title        = {Landslide detection in real-time social media image streams},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Adaptive NN-based distributed consensus control for
nonlinear multi-agent systems under direct graphs. <em>NCA</em>,
<em>35</em>(24), 17795–17807. (<a
href="https://doi.org/10.1007/s00521-023-08646-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is mainly concerned with the leaderless consensus problem for nonlinear multi-agent systems (MAS) with unknown mismatched nonlinear dynamics and external disturbances. First, a novel adaptive controller is designed to achieve bounded consensus with a linear feedback term, the RBF neural network (RBFNN) adaptive approximation term, a discontinuous feedback term, and a state constraint term. Furthermore, on this basis, an observer-based robust uniform control scheme against disturbance is proposed to achieve the leaderless consensus of MAS with unmeasurable states under the directed graph. Compared with the previous works, the proposed controller is less conservative. Finally, two simulation-based examples are provided to verify the effectiveness of the proposed control scheme.},
  archive      = {J_NCA},
  author       = {Chen, Bao and Li, Chen and Qi, Xuelei and Ma, Hong-Jun},
  doi          = {10.1007/s00521-023-08646-2},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17795-17807},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive NN-based distributed consensus control for nonlinear multi-agent systems under direct graphs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced data-driven framework for early kick detection
based on imbalanced multivariate time series classification.
<em>NCA</em>, <em>35</em>(24), 17777–17793. (<a
href="https://doi.org/10.1007/s00521-023-08636-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early kick detection (EKD) is viewed as an effective way to prevent blowouts in the drilling industry. Data-driven EKD methods are increasingly attracting interests from both academia and industry. However, the available kick data are usually sparse, heterogeneous, and high-dimensional, restricting the efficient application of data-driven EKD methods. To address the issue, we propose a novel EKD method named PRIL (Practical Internal Features Learning Framework), which can fully exploit the implicit feature of sparse kick data and can be deployed to diverse wellbores. Specifically, we exploit the sparse kick data in two ways: (1) adopting a robust scale method to improve the generalization performance of PRIL; (2) using a hybrid-sampling method (including over-sampling and under-sampling) to mitigate the impact of imbalanced kick data on a single wellbore and the risk of over-fitting. In addition, we integrate the domain knowledge of kick prediction into a classification model named InterLearn to further improve the EKD accuracy. Finally, our method is experimentally evaluated on a real-world dataset, and the experimental results indicate the effectiveness of PRIL and superiority of InterLearn against the conventional data-driven EKD methods.},
  archive      = {J_NCA},
  author       = {Xing, Shiwang and Niu, Jianwei and Wang, Haige and Ren, Tao and Cui, Meng and Shi, Xiaoyan},
  doi          = {10.1007/s00521-023-08636-4},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17777-17793},
  shortjournal = {Neural Comput. Appl.},
  title        = {An enhanced data-driven framework for early kick detection based on imbalanced multivariate time series classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamic multiobjective optimization algorithm based on
decision variable relationship. <em>NCA</em>, <em>35</em>(24),
17749–17775. (<a
href="https://doi.org/10.1007/s00521-023-08633-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems exist in daily life and industrial practice. The objectives of dynamic multiobjective optimization problems conflict with each other. In most dynamic multiobjective optimization algorithms, the decision variables are optimized in the same way, without considering the different characteristics of the decision variables. To better track Pareto-optimal front and Pareto-optimal set at different times, a dynamic multiobjective optimization algorithm based on decision variable relationship (DVR) is proposed. Firstly, the decision variables are divided into two categories based on the detection mechanism of the contribution of decision variables to diversity and convergence. Secondly, different optimization methods are used for different types of decision variables. And a diversity maintenance mechanism is proposed. Finally, the individuals generated by these two parts and the perturbed individuals are combined. The combination individuals are nondominated sorted to form a population in the new environment. To verify the performance of the proposed algorithm, DVR is compared with five state-of-the-art dynamic multiobjective optimization evolutionary algorithms on 15 benchmark instances. The experimental results show that the DVR algorithm obtains 24 inverse generation distance optimal values in 45 groups of test data.},
  archive      = {J_NCA},
  author       = {Hu, Ziyu and Li, Zihan and Wei, Lixin and Sun, Hao and Ma, Xuemin},
  doi          = {10.1007/s00521-023-08633-7},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17749-17775},
  shortjournal = {Neural Comput. Appl.},
  title        = {A dynamic multiobjective optimization algorithm based on decision variable relationship},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Transformer guidance dual-stream network for salient object
detection in optical remote sensing images. <em>NCA</em>,
<em>35</em>(24), 17733–17747. (<a
href="https://doi.org/10.1007/s00521-023-08640-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) has achieved remarkable performance in natural scene images (NSIs). However, current SOD methods still face serious challenges in processing optical remote sensing images (RSIs) due to cluttered backgrounds, diverse scales, and different views, which are distinguished from NSIs. In this paper, a transformer guidance dual-stream network (TGDNet) is proposed for SOD in optical RSIs. The key insight is to extract multi-scale features by global receptive fields and separately refine them according to the characteristics of feature hierarchies. Specifically, inspired by the long-range dependencies of transformer, a transformer guidance dual-stream strategy is proposed to compensate the extracted details such as boundaries and edges using global information. To overcome the issue of diverse scales of salient objects in optical RSIs, a sequence inheritance channel attention module is built to focus more on high-level semantic features at different scales. In addition, a pyramid spatial attention module is elaborately designed to refine low-level features as well as to suppress background interference for accurate SOD in optical RSIs. At last, a coarse-to-fine decoder is utilized to progressively predict salient objects. In the experiment, the EORSSD dataset is employed to train and evaluate the proposed TGDNet. It achieves performance of 0.0049, 0.8964, and 0.9286 in terms of MAE, F-measure, and S-measure, respectively. Furthermore, ORSSD dataset is also utilized to evaluate the generality. Experimental results demonstrate the advantages of TGDNet over the state-of-the-art SOD methods.},
  archive      = {J_NCA},
  author       = {Zhang, Yi and Guo, Jichang and Yue, Huihui and Yin, Xiangjun and Zheng, Sida},
  doi          = {10.1007/s00521-023-08640-8},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17733-17747},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transformer guidance dual-stream network for salient object detection in optical remote sensing images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EduNER: A chinese named entity recognition dataset for
education research. <em>NCA</em>, <em>35</em>(24), 17717–17731. (<a
href="https://doi.org/10.1007/s00521-023-08635-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high-quality domain-oriented dataset is crucial for the domain-specific named entity recognition (NER) task. In this study, we introduce a novel education-oriented Chinese NER dataset (EduNER). To provide representative and diverse training data, we collect data from multiple sources, including textbooks, academic papers, and education-related web pages. The collected documents span ten years (2012–2021). A team of domain experts is invited to accomplish the education NER schema definition, and a group of trained annotators is hired to complete the annotation. A collaborative labeling platform is built for accelerating human annotation. The constructed EduNER dataset includes 16 entity types, 11k+ sentences, and 35,731 entities. We conduct a thorough statistical analysis of EduNER and summarize its distinctive characteristics by comparing it with eight open-domain or domain-specific NER datasets. Sixteen state-of-the-art models are further utilized for NER tasks validation. The experimental results can enlighten further exploration. To the best of our knowledge, EduNER is the first publicly available dataset for NER task in the education domain, which may promote the development of education-oriented NER models.},
  archive      = {J_NCA},
  author       = {Li, Xu and Wei, Chengkun and Jiang, Zhuoren and Meng, Wenlong and Ouyang, Fan and Zhang, Zihui and Chen, Wenzhi},
  doi          = {10.1007/s00521-023-08635-5},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17717-17731},
  shortjournal = {Neural Comput. Appl.},
  title        = {EduNER: A chinese named entity recognition dataset for education research},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GRU-based model-free adaptive control for industrial
processes. <em>NCA</em>, <em>35</em>(24), 17701–17715. (<a
href="https://doi.org/10.1007/s00521-023-08652-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many industrial processes have the characteristics such as large time delay, strong coupling or nonlinearity, which make them difficult to control. When exact process models are available, model-based control methods can achieve good performance. However, it is difficult to satisfy in many cases. This paper proposes a novel Model-free adaptive control scheme with an encoder–decoder structure based on gated recurrent unit (GRU) network and attention mechanism. The control objective is to make the process output track a known reference input. The controller does not need to know an accurate process model and can adjust the weight of each neuron of the neural network according to the error signal to achieve process control. The gating mechanism of GRU neural network enables the controller to take full advantage of the system’s history information. Lyapunov-based stability analysis is provided to guarantee the stability of the whole control system. Some process simulations and a Wood/Berry distillation column example show that only by adjusting a few parameters, the proposed controller can control a multivariable process with coupling or large time delay well.},
  archive      = {J_NCA},
  author       = {Sun, Jinggao and Wei, Ziqing and Liu, Xing},
  doi          = {10.1007/s00521-023-08652-4},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17701-17715},
  shortjournal = {Neural Comput. Appl.},
  title        = {GRU-based model-free adaptive control for industrial processes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepGCSS: A robust and explainable contour classifier
providing generalized curvature scale space features. <em>NCA</em>,
<em>35</em>(24), 17689–17700. (<a
href="https://doi.org/10.1007/s00521-023-08639-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we build a novel, robust, and explainable deep neural network architecture for contour classification whose feature extraction layers are a deep version of the Generalized CSS (Generalized Curvature Scale Space) descriptors. For particular kernels, the proposed model behaves exactly like GCSS when extracting areas with strong curvatures. Such architecture is firstly essential to establish a comparison between the efficiency of hand-crafted kernels and the learned ones and secondly to study the ability of the classifier to map the input data into an invariant representation. Experimental results on MPEG-7 and MNIST contour datasets prove that the feature extraction block with hand-crafted kernels leads to an invariant and explainable CSS-based representation. Even though the number of parameters in the DeepGCSS model is much smaller compared to the conventional contour classifiers, the performance remains close. The robustness study was carried out using the ContourVerifier and proves that the features extraction block with hand-crafted kernels leads to a more robust GCSS-based representation model.},
  archive      = {J_NCA},
  author       = {Mziou-Sallami, Mallek and Khalsi, Rania and Smati, Imen and Mhiri, Slim and Ghorbel, Faouzi},
  doi          = {10.1007/s00521-023-08639-1},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17689-17700},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepGCSS: A robust and explainable contour classifier providing generalized curvature scale space features},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GCPAN: An adaptive global cross-scale prior attention
network for image super-resolution. <em>NCA</em>, <em>35</em>(24),
17671–17688. (<a
href="https://doi.org/10.1007/s00521-023-08642-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Super-resolution has achieved remarkable results in recent years, which is attributed to the rapid development of convolutional neural networks (CNN). However, most CNN-based algorithms have complex network structures and are not very adaptive in reconstructing detailed information. In this paper, we propose an adaptive global cross-scale prior attention network (GCPAN) to address this problem. GCPAN consists of nonlocal similarity prior module(NLS), adaptive cross-scale prior fusion module (CSF), and adaptive wide activation residual attention module (WARA). Specifically, we propose the nonlocal similarity prior module (NLS) to extract contextual associations between feature layers to alleviate the pressure of network complexity. NLS ensures the accuracy of the obtained global information utilizing SENet attention. Secondly, the adaptive cross-scale prior fusion (CSF) module is proposed to capture similarity relations of different scales adaptively and takes advantage of the internal prior information of the image to enhance texture details. Finally, we design an adaptive wide activation residual attention (WARA) module to learn more effective detail information. Extensive ablation and comparative experiments show that GCPAN obtains pleasing objective values and is visually closer to real images compared with other state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Shi, Mingzhu and Kong, Siqi and Zao, Bin and Tan, Muxian},
  doi          = {10.1007/s00521-023-08642-6},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17671-17688},
  shortjournal = {Neural Comput. Appl.},
  title        = {GCPAN: An adaptive global cross-scale prior attention network for image super-resolution},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal energy planning of multi-microgrids at stochastic
nature of load demand and renewable energy resources using a modified
capuchin search algorithm. <em>NCA</em>, <em>35</em>(24), 17645–17670.
(<a href="https://doi.org/10.1007/s00521-023-08623-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of interconnected multi-microgrids (MMGs) is presented as a promising solution for the improvement in the operation, control, and economic performance of the distribution networks. The energy management of the MMGs is a strenuous and challenging task, especially with the integration of renewable energy resources (RERs) and variation in the loading due to the intermittency of these resources and the stochastic nature of the load demand. In this regard, the energy management of the MMGs is optimized with optimal inclusion of a hybrid system consisting of a photovoltaic (PV) and a wind turbine (WT)-based distributed generation (DGs) under uncertainties of the generated powers and the load variation. A modified Capuchin Search Algorithm (MCapSA) is presented and applied for the energy management of the MMGs. The MCapSA is based on enhancing the searching abilities of the standard Capuchin Search Algorithm (CapSA) using three improvement strategies including the quasi-oppositional-based learning (QOBL), the random movement-based Levy flight distribution, and the exploitation mechanism of the prairie dogs in the prairie dog optimization (PDO). The optimized function is a multi-objective function that comprises of the cost and the voltage deviation reduction along with stability enhancement. The effectiveness of the proposed technique is verified on standard benchmark functions and the obtained results. Then, the proposed method is used for energy management of IEEE 33-bus and 69-bus MMGs at uncertainties conation. The results depict that the energy management with inclusion of WTs and PVs using the proposed technique can reduce the cost and summation of the VD by 46.41\% and 62.54\%, and the VSI is enhanced by 15.1406\% for the first MMG. Likewise, for the second MMG, the cost and summation of the VD are reduced by 44.19\% and 39.70\%, and the VSI is enhanced by 4.49\%.},
  archive      = {J_NCA},
  author       = {Ebeed, Mohamed and Ahmed, Deyaa and Kamel, Salah and Jurado, Francisco and Shaaban, Mostafa F. and Ali, Abdelfatah and Refai, Ahmed},
  doi          = {10.1007/s00521-023-08623-9},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17645-17670},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal energy planning of multi-microgrids at stochastic nature of load demand and renewable energy resources using a modified capuchin search algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge guided multi-filter residual convolutional neural
network for ICD coding from clinical text. <em>NCA</em>,
<em>35</em>(24), 17633–17644. (<a
href="https://doi.org/10.1007/s00521-023-08581-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common challenge encountered when using Deep Neural Network models for automatic ICD coding is their potential inability to effectively handle unseen clinical texts, especially when these models are only trained on a limited number of examples. This is because these models rely solely on the patterns and relationships present in the training data, and may not be able to effectively incorporate additional knowledge about the relationships between medical entities. To address this issue, we introduce KG-MultiResCNN—Knowledge Guided Multi-filter Residual Convolutional Neural Network model, which combines training examples with external knowledge from the Wikidata Knowledge Graph (KG) in order to better capture the relationships between medical entities. The KG is a structured database that contains a wealth of information about various entities, including medical concepts and their relationships with one another. By incorporating this external knowledge into our model, we are able to improve its ability to predict ICD codes for new clinical texts. In our experiments with the MIMIC-III dataset, we found that the KG-MultiResCNN model significantly outperformed the baseline approaches. This demonstrates the effectiveness of using external knowledge, in addition to training examples, to improve the performance of deep learning models for automatic ICD coding.},
  archive      = {J_NCA},
  author       = {Boukhers, Zeyd and Goswami, Prantik and Jürjens, Jan},
  doi          = {10.1007/s00521-023-08581-2},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17633-17644},
  shortjournal = {Neural Comput. Appl.},
  title        = {Knowledge guided multi-filter residual convolutional neural network for ICD coding from clinical text},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HAAN-ERC: Hierarchical adaptive attention network for
multimodal emotion recognition in conversation. <em>NCA</em>,
<em>35</em>(24), 17619–17632. (<a
href="https://doi.org/10.1007/s00521-023-08638-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotional expressions affect the progress of conversation in complex ways in our lives. For multimodal emotion recognition in conversation (ERC), previous studies focus on modeling partial influences of speaker and modality to infer emotion states in historical context based on traditional modeling units. However, with the tremendous success of Transformer in broad fields, how to effectively model intra- and inter-speaker, intra- and intermodal influences in historical dialog context based on Transformer is still not been tackled. In this paper, we propose a novel methodology HAAN-ERC, which hierarchically uses dialogue context information to model intra-speaker, inter-speaker, intra-modal, and intermodal influences to infer the emotional state of speakers. Meanwhile, we propose an adaptive attention mechanism, which can be trained in an end-to-end manner and automatically makes the unique decision for each speaker to omit redundant or valueless utterances from historical contexts in multiple hierarchies for adaptive fusion. The performance of HAAN-ERC is comprehensively evaluated on two popular multimodal ERC datasets of IEMOCAP and MELD, and achieves new state-of-the-art results. The encouraging results prove the validity of our HAAN-ERC. Our original codes will be publicly available at https://github.com/TAN-OpenLab/HAAN-ERC .},
  archive      = {J_NCA},
  author       = {Zhang, Tao and Tan, Zhenhua and Wu, Xiaoer},
  doi          = {10.1007/s00521-023-08638-2},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17619-17632},
  shortjournal = {Neural Comput. Appl.},
  title        = {HAAN-ERC: Hierarchical adaptive attention network for multimodal emotion recognition in conversation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Best-response planning for urban fleet coordination.
<em>NCA</em>, <em>35</em>(24), 17599–17618. (<a
href="https://doi.org/10.1007/s00521-023-08631-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The modeling of fleet vehicles as self-interested agents brings a realistic perspective to open fleet transportation research. This feature allows us to model the fleet operation from a non-cooperative point of view. In this work, we study parcel delivery in a city with limited resources (roads and charging stations). We designed and implemented a system composed of a multi-agent planner and a game-theoretic coordination algorithm: a Best-Response Fleet Planner. The system allows for the self-organization of the transportation system by coordinating a fleet of self-interested electric vehicles. The system’s operation is optimized together with resource usage while preserving the agents’ private interests, allowing each agent to plan its actions. The results show that our system has higher scalability than similar approaches, allowing it to function for a considerable number of agents in settings that feature congestion and conflicts. Additionally, overall solution quality is improved compared to other coordination systems, reducing congestion and avoiding unnecessary waiting times.},
  archive      = {J_NCA},
  author       = {Martí, Pasqual and Jordán, Jaume and Julian, Vicente},
  doi          = {10.1007/s00521-023-08631-9},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17599-17618},
  shortjournal = {Neural Comput. Appl.},
  title        = {Best-response planning for urban fleet coordination},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prototype generation method using a growing self-organizing
map applied to the banking sector. <em>NCA</em>, <em>35</em>(24),
17579–17597. (<a
href="https://doi.org/10.1007/s00521-023-08630-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In fields like security risk analysis, Fast Moving Consumer Goods, Internet of Things, or the banking sector, it is necessary to deal with large datasets containing a great list of variables. In these situations, the analysis becomes intricate and computationally expensive, so data reduction techniques play an important role. Prototype generation methods provide a reduced dataset with the same properties as the original. GSOMs (growing self-organizing maps) reduce the data size without the need for prefixing the number of neurons needed to represent the input space. To the best of the authors’ knowledge, this is the first time that the GSOM is applied for reduction and generation of prototypes, posing an advantage over their predecessors, the SOMs (self-organizing maps), which do not have the automatic growth feature. This work addresses the use of a GSOM to reduce the number of prototypes to use in a 1-NN (1 nearest neighbor) classifier. The proposed methodology is applied to an income dataset for testing and a large bank dataset that contain classifications into two different groups. The 1-NN classifier is used to obtain predictions using the nodes of the GSOM as prototypes. This article demonstrates that GSOMs save a significant amount of time in obtaining nearly the same validation results as SOMs by comparing the classifications obtained in the bank dataset. The results show data reductions of more than 99\%, and accuracies greater than 80\% for the income dataset and 74\% for the bank dataset.},
  archive      = {J_NCA},
  author       = {Ruiz-Moreno, Sara and Núñez-Reyes, Amparo and García-Cantalapiedra, Adrián and Pavón, Fernando},
  doi          = {10.1007/s00521-023-08630-w},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17579-17597},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prototype generation method using a growing self-organizing map applied to the banking sector},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A domain-region based evaluation of ML performance
robustness to covariate shift. <em>NCA</em>, <em>35</em>(24),
17555–17577. (<a
href="https://doi.org/10.1007/s00521-023-08622-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most machine learning methods assume that the input data distribution is the same in the training and testing phases. However, in practice, this stationarity is usually not met and the distribution of inputs differs, leading to unexpected performance of the learned model in deployment. The issue in which the training and test data inputs follow different probability distributions while the input–output relationship remains unchanged is referred to as covariate shift. In this paper, the performance of conventional machine learning models was experimentally evaluated in the presence of covariate shift. Furthermore, a region-based evaluation was performed by decomposing the domain of probability density function of the input data to assess the classifier’s performance per domain region. Distributional changes were simulated in a two-dimensional classification problem. Subsequently, a higher four-dimensional experiments were conducted. Based on the experimental analysis, the Random Forests algorithm is the most robust classifier in the two-dimensional case, showing the lowest degradation rate for accuracy and F1-score metrics, with a range between 0.1\% and 2.08\%. Moreover, the results reveal that in higher-dimensional experiments, the performance of the models is predominantly influenced by the complexity of the classification function, leading to degradation rates exceeding 25\% in most cases. It is also concluded that the models exhibit high bias toward the region with high density in the input space domain of the training samples.},
  archive      = {J_NCA},
  author       = {Bayram, Firas and Ahmed, Bestoun S.},
  doi          = {10.1007/s00521-023-08622-w},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17555-17577},
  shortjournal = {Neural Comput. Appl.},
  title        = {A domain-region based evaluation of ML performance robustness to covariate shift},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient zeroing neural network for solving time-varying
nonlinear equations. <em>NCA</em>, <em>35</em>(24), 17537–17554. (<a
href="https://doi.org/10.1007/s00521-023-08621-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defining efficient families of recurrent neural networks (RNN) models for solving time-varying nonlinear equations is an interesting research topic in applied mathematics. Accordingly, one of the underlying elements in designing RNN is the use of efficient nonlinear activation functions. The role of the activation function is to bring out an output from a set of input values that are supplied into a node. Our goal is to define new family of activation functions consisting of a fixed gain parameter and a functional part. Corresponding zeroing neural networks (ZNN) is defined, termed as varying-parameter improved zeroing neural network (VPIZNN), and applied to solving time-varying nonlinear equations. Compared with previous ZNN models, the new VPIZNN models reach an accelerated finite-time convergence due to the new time-varying activation function which is embedded into the VPIZNN design. Theoretical results and numerical experiments are presented to demonstrate the superiority of the novel VPIZNN formula. The capability of the proposed VPIZNN models are demonstrated in studying and solving the Van der Pol equation and finding the root $$\root m \of {a(t)}$$ .},
  archive      = {J_NCA},
  author       = {Behera, Ratikanta and Gerontitis, Dimitris and Stanimirović, Predrag and Katsikis, Vasilios and Shi, Yang and Cao, Xinwei},
  doi          = {10.1007/s00521-023-08621-x},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17537-17554},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient zeroing neural network for solving time-varying nonlinear equations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating information by kullback–leibler constraint for
text classification. <em>NCA</em>, <em>35</em>(24), 17521–17535. (<a
href="https://doi.org/10.1007/s00521-023-08602-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is an important assignment for various text-related downstream assignments, such as fake news detection, sentiment analysis, and question answering. In recent years, the graph-based method achieves excellent results in text classification tasks. Instead of regarding a text as a sequence structure, this method regards it as a co-occurrence set of words. The task of text classification is then accomplished by aggregating the data from nearby nodes using the graph neural network. However, existing corpus-level graph models are difficult to incorporate the local semantic information and classify new coming texts. To address these issues, we propose a Global–Local Text Classification (GLTC) model, based on the KL constraints to realize inductive learning for text classification. Firstly, a global structural feature extractor and a local semantic feature extractor are designed to capture the structural and semantic information of text comprehensively. Then, the KL divergence is introduced as a regularization term in the loss calculation process, which ensures that the global structural feature extractor can constrain the learning of the local semantic feature extractor to achieve inductive learning. The comprehensive experiments on benchmark datasets present that GLTC outperforms baseline methods in terms of accuracy.},
  archive      = {J_NCA},
  author       = {Yin, Shu and Zhu, Peican and Wu, Xinyu and Huang, Jiajin and Li, Xianghua and Wang, Zhen and Gao, Chao},
  doi          = {10.1007/s00521-023-08602-0},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17521-17535},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integrating information by Kullback–Leibler constraint for text classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lexicon-based probabilistic indexing of handwritten text
images. <em>NCA</em>, <em>35</em>(24), 17501–17520. (<a
href="https://doi.org/10.1007/s00521-023-08620-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyword Spotting (KWS) is here considered as a basic technology for Probabilistic Indexing (PrIx) of large collections of handwritten text images to allow fast textual access to the contents of these collections. Under this perspective, a probabilistic framework for lexicon-based KWS in text images is presented. The presentation aims at providing formal insights which help understanding classical statements of KWS (from which PrIx borrows fundamental concepts), as well as the relative challenges entailed by these statements. The development of the proposed framework makes it clear that word recognition or classification implicitly or explicitly underlies any formulation of KWS. Moreover, it suggests that the same statistical models and training methods successfully used for handwriting text recognition can advantageously be used also for PrIx, even though PrIx does not generally require or rely on any kind of previously produced image transcripts. Experiments carried out using these approaches support the consistency and the general interest of the proposed framework. Results on three datasets traditionally used for KWS benchmarking are significantly better than those previously published for these datasets. In addition, good results are also reported on two new, larger handwritten text image datasets (Bentham and Plantas), showing the great potential of the methods proposed in this paper for indexing and textual search in large collections of untranscribed handwritten documents. Specifically, we achieved the following Average Precision values: IAMDB: 0.89, George Washington: 0.91, Parzival: 0.95, Bentham: 0.91 and Plantas: 0.92.},
  archive      = {J_NCA},
  author       = {Vidal, Enrique and Toselli, Alejandro H. and Puigcerver, Joan},
  doi          = {10.1007/s00521-023-08620-y},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17501-17520},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lexicon-based probabilistic indexing of handwritten text images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of discharge coefficient of the trapezoidal
broad-crested weir flow using soft computing techniques. <em>NCA</em>,
<em>35</em>(24), 17485–17499. (<a
href="https://doi.org/10.1007/s00521-023-08615-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weirs are hydraulic structures mostly used to measure the flow discharge and control the flow level in artificial or natural open channels. The ratio of the actual discharge to the theoretical discharge (discharge coefficient—Cd) must be known, in order to calculate the discharge of the channel having the weir. In this study, 91 experimental measurements are taken on seven trapezoidal broad-crested weirs with different upstream and downstream slopes. Experimentally measured flow properties are used to validate numerical models based on the computational fluid dynamics (CFD) methods. Two new weir geometries, not experimentally measured, are added in the numerical modeling, and 270 Cd values are calculated for nine weir geometries using numerical modeling. Theoretical Cd values are estimated using the artificial neural network (ANN), support vector machine (SVM), and M5Tree methods. In the models, the Froude number in the upstream region and dimensionless parameters of the flow are used as inputs. The performance of these methods has been examined to estimate the Cd values for eight cases. The performances of the methods are evaluated by the coefficient of determination (R2), root-mean-square error, mean absolute percentage error, and Nash–Sutcliffe model efficiency coefficient. The study results show that the Froude number significantly increases the performance of the models in estimating Cd values, and the ANN method is more successful in determining Cd than other methods.},
  archive      = {J_NCA},
  author       = {Simsek, Oguz and Gumus, Veysel and Ozluk, Abdulkadir},
  doi          = {10.1007/s00521-023-08615-9},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17485-17499},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of discharge coefficient of the trapezoidal broad-crested weir flow using soft computing techniques},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BIO-CXRNET: A robust multimodal stacking machine learning
technique for mortality risk prediction of COVID-19 patients using chest
x-ray images and clinical data. <em>NCA</em>, <em>35</em>(24),
17461–17483. (<a
href="https://doi.org/10.1007/s00521-023-08606-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, quick, and accurate diagnosis of COVID-19 is a pressing need. This study presents a multimodal system to meet this need. The presented system employs a machine learning module that learns the required knowledge from the datasets collected from 930 COVID-19 patients hospitalized in Italy during the first wave of COVID-19 (March–June 2020). The dataset consists of twenty-five biomarkers from electronic health record and Chest X-ray (CXR) images. It is found that the system can diagnose low- or high-risk patients with an accuracy, sensitivity, and F1-score of 89.03\%, 90.44\%, and 89.03\%, respectively. The system exhibits 6\% higher accuracy than the systems that employ either CXR images or biomarker data. In addition, the system can calculate the mortality risk of high-risk patients using multivariate logistic regression-based nomogram scoring technique. Interested physicians can use the presented system to predict the early mortality risks of COVID-19 patients using the web-link: Covid-severity-grading-AI. In this case, a physician needs to input the following information: CXR image file, Lactate Dehydrogenase (LDH), Oxygen Saturation (O2\%), White Blood Cells Count, C-reactive protein, and Age. This way, this study contributes to the management of COVID-19 patients by predicting early mortality risk.},
  archive      = {J_NCA},
  author       = {Rahman, Tawsifur and Chowdhury, Muhammad E. H. and Khandakar, Amith and Mahbub, Zaid Bin and Hossain, Md Sakib Abrar and Alhatou, Abraham and Abdalla, Eynas and Muthiyal, Sreekumar and Islam, Khandaker Farzana and Kashem, Saad Bin Abul and Khan, Muhammad Salman and Zughaier, Susu M. and Hossain, Maqsud},
  doi          = {10.1007/s00521-023-08606-w},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17461-17483},
  shortjournal = {Neural Comput. Appl.},
  title        = {BIO-CXRNET: A robust multimodal stacking machine learning technique for mortality risk prediction of COVID-19 patients using chest X-ray images and clinical data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning-based gait anomaly detection using a
sensorized tip: An individualized approach. <em>NCA</em>,
<em>35</em>(24), 17443–17459. (<a
href="https://doi.org/10.1007/s00521-023-08601-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower limb motor impairment affects greatly the autonomy and quality of life of those people suffering from it. Recent studies have shown that an appropriate rehabilitation can significantly improve their condition, but, for this purpose, it is essential to know the patient’s functional state and to be able to detect any changes that occur in it as soon as possible. Traditionally, standardized clinical scales have been used to make that assessment, however, as the number of patients to be assessed is high, assessment frequency is usually low. In response to this problem, the aim of the present work is to design a new personalized methodology for developing a Machine Learning-based gait anomaly detector that is able to detect significant changes in the functional state of patients based on data provided by a sensorized tip; a system that will serve as support for the therapist who is treating the monitored patient’s case. Taking into account the variability that exists among patients, the proposed design focuses on an individualized approach, so that the system characterizes the state change of each patient case only on his/her own data. Once developed, the proposed methodology has been validated in ten healthy people of different complexions, achieving an average accuracy of 87.5\%. Finally, five case studies have been analyzed, in which data from five multiple sclerosis patients have been captured and studied, obtaining an average accuracy of 82.5\%.},
  archive      = {J_NCA},
  author       = {Otamendi, Janire and Zubizarreta, Asier and Portillo, Eva},
  doi          = {10.1007/s00521-023-08601-1},
  journal      = {Neural Computing and Applications},
  number       = {24},
  pages        = {17443-17459},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning-based gait anomaly detection using a sensorized tip: An individualized approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diabetic retinopathy detection and diagnosis by means of
robust and explainable convolutional neural networks. <em>NCA</em>,
<em>35</em>(23), 17429–17441. (<a
href="https://doi.org/10.1007/s00521-023-08608-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diabetic retinopathy is a disease affecting the retina and it is currently manually diagnosed by specialists. In order to help the clinician in this time-consuming task, we propose a method aimed at automatically identify the diabetic retinopathy presence from ocular angiography by exploiting convolutional neural networks. In particular, two models are proposed: the first one is aimed to discriminate between healthy eyes and eyes with retinopathy, while the second one is designed to distinguish between non-proliferative retinopathy and weakly and severely proliferative retinopathy. The results we obtained, i.e., an accuracy of 0.98 for the first model and an accuracy of 0.91 relative to the second model, demonstrate that the proposed models can effectively aid the clinician in diagnosis. Moreover, the proposed method is aimed to localize the disease in the angiography, providing a kind of explainability behind the model diagnosis, by taking into account two different class activation mapping algorithms showing on the images the areas symptomatic of the disease, in order to increase model trustworthiness from doctors and patients. We also introduce a similarity index aimed to evaluate the model robustness by quantifying how much the heatmaps generated by the class activation mapping algorithms of the same model differ from each other.},
  archive      = {J_NCA},
  author       = {Mercaldo, Francesco and Di Giammarco, Marcello and Apicella, Arianna and Di Iadarola, Giacomo and Cesarelli, Mario and Martinelli, Fabio and Santone, Antonella},
  doi          = {10.1007/s00521-023-08608-8},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17429-17441},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diabetic retinopathy detection and diagnosis by means of robust and explainable convolutional neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Refinement of ensemble strategy for acute lymphoblastic
leukemia microscopic images using hybrid CNN-GRU-BiLSTM and MSVM
classifier. <em>NCA</em>, <em>35</em>(23), 17415–17427. (<a
href="https://doi.org/10.1007/s00521-023-08607-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acute lymphocytic leukemia (ALL) is a common serious cancer in white blood cells (WBC) that advances quickly and produces abnormal cells in the bone marrow. Cancerous cells associated with ALL lead to impairment of body systems. Microscopic examination of ALL in a blood sample is applied manually by hematologists with many defects. Computer-aided leukemia image detection is used to avoid human visual recognition and to provide a more accurate diagnosis. This paper employs the ensemble strategy to detect ALL cells versus normal WBCs using three stages automatically. Firstly, image pre-processing is applied to handle the unbalanced database through the oversampling process. Secondly, deep spatial features are generated using a convolution neural network (CNN). At the same time, the gated recurrent unit (GRU)-bidirectional long short-term memory (BiLSTM) architecture is utilized to extract long-distance dependent information features or temporal features to obtain active feature learning. Thirdly, a softmax function and the multiclass support vector machine (MSVM) classifier are used for the classification mission. The proposed strategy has the resilience to classify the C-NMC 2019 database into two categories by using splitting the entire dataset into 90\% as training and 10\% as testing datasets. The main motivation of this paper is the novelty of the proposed framework for the purposeful and accurate diagnosis of ALL images. The proposed CNN-GRU-BiLSTM-MSVM is simply stacked by existing tools. However, the empirical results on C-NMC 2019 database show that the proposed framework is useful to the ALL image recognition problem compared to previous works. The DenseNet-201 model yielded an F1-score of 96.23\% and an accuracy of 96.29\% using the MSVM classifier in the test dataset. The findings exhibited that the proposed strategy can be employed as a complementary diagnostic tool for ALL cells. Further, this proposed strategy will encourage researchers to augment the rare database, such as blood microscopic images by creating powerful applications in terms of combining machine learning with deep learning algorithms.},
  archive      = {J_NCA},
  author       = {Mohammed, Kamel K. and Hassanien, Aboul Ella and Afify, Heba M.},
  doi          = {10.1007/s00521-023-08607-9},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17415-17427},
  shortjournal = {Neural Comput. Appl.},
  title        = {Refinement of ensemble strategy for acute lymphoblastic leukemia microscopic images using hybrid CNN-GRU-BiLSTM and MSVM classifier},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comparative study of anti-swing radial basis neural-fuzzy
LQR controller for multi-degree-of-freedom rotary pendulum systems.
<em>NCA</em>, <em>35</em>(23), 17397–17413. (<a
href="https://doi.org/10.1007/s00521-023-08599-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anti-swing radial basis neuro-fuzzy LQR (RBNFLQR) controller for a multi-degree-of-freedom (DOF) rotary inverted pendulum is developed in this paper. One of the major challenges is to design an anti-swing RBNFLQR controller that has high precision, robustness, and vibration suppression to control the multi-DOF rotary inverted pendulum system. The study here demonstrates a novel RBNFLQR controller in which the positions and velocities of state variables multiplied by the LQR gains are tuned using the radial basis neural networks (RBNNs) architecture. The outputs of the RBNN are fuzzified by the fuzzy controller to obtain the desired torque of the pendulum systems. The RBNN based on the Bayesian regularization (BR) algorithm is able to self-adjust the LQR gains of the state variables. In order to stabilize the pendulums to zero positions more effectively, the tuned gains of LQR help to reduce the aggressiveness of the fuzzy control rules. The control performance of the anti-swing RBNFLQR controller was verified by simulation and experimental results in two, three, and four DOF rotary inverted pendulum systems. The proposed controller exhibits robustness to external disturbances and has much better vibration suppression capability. The present work provides a novel and effective framework to develop an anti-swing RBNFLQR controller for multi-DOF pendulum systems.},
  archive      = {J_NCA},
  author       = {Ben Hazem, Zied and Bingül, Zafer},
  doi          = {10.1007/s00521-023-08599-6},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17397-17413},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comparative study of anti-swing radial basis neural-fuzzy LQR controller for multi-degree-of-freedom rotary pendulum systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven intelligent decision support system that
combines predictive and prescriptive analytics for the design of new
textile fabrics. <em>NCA</em>, <em>35</em>(23), 17375–17395. (<a
href="https://doi.org/10.1007/s00521-023-08596-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an Intelligent Decision Support System (IDSS) for the design of new textile fabrics. The IDSS uses predictive analytics to estimate fabric properties (e.g., elasticity) and composition values (\% cotton) and then prescriptive techniques to optimize the fabric design inputs that feed the predictive models (e.g., types of yarns used). Using thousands of data records from a Portuguese textile company, we compared two distinct Machine Learning (ML) predictive approaches: Single-Target Regression (STR), via an Automated ML (AutoML) tool, and Multi-target Regression, via a deep learning Artificial Neural Network. For the prescriptive analytics, we compared two Evolutionary Multi-objective Optimization (EMO) methods (NSGA-II and R-NSGA-II) when optimizing 100 new fabrics, aiming to simultaneously minimize the physical property predictive error and the distance of the optimized values when compared with the learned input space. The two EMO methods were applied to design of 100 new fabrics. Overall, the STR approach provided the best results for both prediction tasks, with Normalized Mean Absolute Error values that range from 4\% (weft elasticity) to 11\% (pilling) in terms of the fabric properties and a textile composition classification accuracy of 87\% when adopting a small tolerance of 0.01 for predicting the percentages of six types of fibers (e.g., cotton). As for the prescriptive results, they favored the R-NSGA-II EMO method, which tends to select Pareto curves that are associated with an average 11\% predictive error and 16\% distance.},
  archive      = {J_NCA},
  author       = {Ribeiro, Rui and Pilastri, André and Moura, Carla and Morgado, José and Cortez, Paulo},
  doi          = {10.1007/s00521-023-08596-9},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17375-17395},
  shortjournal = {Neural Comput. Appl.},
  title        = {A data-driven intelligent decision support system that combines predictive and prescriptive analytics for the design of new textile fabrics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new covid-19 diagnosis strategy using a modified KNN
classifier. <em>NCA</em>, <em>35</em>(23), 17349–17373. (<a
href="https://doi.org/10.1007/s00521-023-08588-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covid-19 is a very dangerous disease as a result of the rapid and unprecedented spread of any previous disease. It is truly a crisis that threatens the world since its first appearance in December 2019 until our time. Due to the lack of a vaccine that has proved sufficiently effective so far, the rapid and more accurate diagnosis of this disease is extremely necessary to enable the medical staff to identify infected cases and isolate them from the rest to prevent further loss of life. In this paper, Covid-19 diagnostic strategy (CDS) as a new classification strategy that consists of two basic phases: Feature selection phase (FSP) and diagnosis phase (DP) has been introduced. During the first phase called FSP, the best set of features in laboratory test findings for Covid-19 patients will be selected using enhanced gray wolf optimization (EGWO). EGWO combines both types of selection techniques called wrapper and filter. Accordingly, EGWO includes two stages called filter stage (FS) and wrapper stage (WS). While FS uses many different filter methods, WS uses a wrapper method called binary gray wolf optimization (BGWO). The second phase called DP aims to give fast and more accurate diagnosis using a hybrid diagnosis methodology (HDM) based on the selected features from FSP. In fact, the HDM consists of two phases called weighting patient phase (WP2) and diagnostic patient phase (DP2). WP2 aims to calculate the belonging degree of each patient in the testing dataset to class category using naïve Bayes (NB) as a weight method. On the other hand, K-nearest neighbor (KNN) will be used in DP2 based on the weights of patients in the testing dataset as a new training dataset to give rapid and more accurate detection. The suggested CDS outperforms other strategies according to accuracy, precision, recall (or sensitivity) and F-measure calculations that are equal to 99\%, 88\%, 90\% and 91\%, respectively, as showed in experimental results.},
  archive      = {J_NCA},
  author       = {Rabie, Asmaa H. and Mohamed, Alaa M. and Abo-Elsoud, M. A. and Saleh, Ahmed I.},
  doi          = {10.1007/s00521-023-08588-9},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17349-17373},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new covid-19 diagnosis strategy using a modified KNN classifier},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MOCOVIDOA: A novel multi-objective coronavirus disease
optimization algorithm for solving multi-objective optimization
problems. <em>NCA</em>, <em>35</em>(23), 17319–17347. (<a
href="https://doi.org/10.1007/s00521-023-08587-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel multi-objective Coronavirus disease optimization algorithm (MOCOVIDOA) is presented to solve global optimization problems with up to three objective functions. This algorithm used an archive to store non-dominated POSs during the optimization process. Then, a roulette wheel selection mechanism selects the effective archived solutions by simulating the frameshifting technique Coronavirus particles use for replication. We evaluated the efficiency by solving twenty-seven multi-objective (21 benchmarks &amp; 6 real-world engineering design) problems, where the results are compared against five common multi-objective metaheuristics. The comparison uses six evaluation metrics, including IGD, GD, MS, SP, HV, and delta p ( $$\Delta \mathrm{P}$$ ). The obtained results and the Wilcoxon rank-sum test show the superiority of this novel algorithm over the existing algorithms and reveal its applicability in solving multi-objective problems.},
  archive      = {J_NCA},
  author       = {Khalid, Asmaa M. and Hamza, Hanaa M. and Mirjalili, Seyedali and Hosny, Khaid M.},
  doi          = {10.1007/s00521-023-08587-w},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17319-17347},
  shortjournal = {Neural Comput. Appl.},
  title        = {MOCOVIDOA: A novel multi-objective coronavirus disease optimization algorithm for solving multi-objective optimization problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ant path integration: A novel optimization algorithm
inspired by the path integration of desert ants. <em>NCA</em>,
<em>35</em>(23), 17293–17318. (<a
href="https://doi.org/10.1007/s00521-023-08611-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several algorithms have been proposed in recent decades to solve optimization problems, some of which have been inspired by nature. The collective behavior of ants is an example of intelligence in the nature which has been a source of inspiration for optimization algorithms. Based on the concept of path integration, ants are able to continuously calculate their current location from their previous trajectory when exploring to find food. In the return journey, they go by calculating the outcome of the route, without returning exactly from their path, choosing a direct path to return to their original point. In this paper, the behavior of desert ants in finding their return path to the nest is the source of inspiration. By modeling the swarm intelligence of these ants based on the results of empirical scientific research, a new optimization algorithm is presented, termed Ant Path Integration. In this paper, the mathematical relationships governing the concept of path integration are presented. Simulation results on a variety of benchmark functions, including some of the CEC2019 benchmarks, show the superiority of this algorithm in finding the optimal solution in comparison to some well-known optimization algorithms.},
  archive      = {J_NCA},
  author       = {Fathtabar, Abbas and Ebrahimzadeh, Ataollah and Kazemitabar, Javad},
  doi          = {10.1007/s00521-023-08611-z},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17293-17318},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ant path integration: A novel optimization algorithm inspired by the path integration of desert ants},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Crop yield prediction algorithm (CYPA) in precision
agriculture based on IoT techniques and climate changes. <em>NCA</em>,
<em>35</em>(23), 17281–17292. (<a
href="https://doi.org/10.1007/s00521-023-08619-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture faces a significant challenge in predicting crop yields, a critical aspect of decision-making at international, regional, and local levels. Crop yield prediction utilizes soil, climatic, environmental, and crop traits extracted via decision support algorithms. This paper presents a novel approach, the Crop Yield Prediction Algorithm (CYPA), utilizing IoT techniques in precision agriculture. Crop yield simulations simplify the comprehension of cumulative impacts of field variables such as water and nutrient deficits, pests, and illnesses during the growing season. Big data databases accommodate multiple characteristics indefinitely in time and space and can aid in the analysis of meteorology, technology, soils, and plant species characterization. The proposed CYPA incorporates climate, weather, agricultural yield, and chemical data to facilitate the anticipation of annual crop yields by policymakers and farmers in their country. The study trains and verifies five models using optimal hyper-parameter settings for each machine learning technique. The DecisionTreeRegressor achieved a score of 0.9814, RandomForestRegressor scored 0.9903, and ExtraTreeRegressor scored 0.9933. Additionally, we introduce a new algorithm based on active learning, which can enhance CYPA&#39;s performance by reducing the number of labeled data needed for training. Incorporating active learning into CYPA can improve the efficiency and accuracy of crop yield prediction, thereby enhancing decision-making at international, regional, and local levels.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M.},
  doi          = {10.1007/s00521-023-08619-5},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17281-17292},
  shortjournal = {Neural Comput. Appl.},
  title        = {Crop yield prediction algorithm (CYPA) in precision agriculture based on IoT techniques and climate changes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HCPG: A highlighted contrastive learning framework for
exemplar-guided paraphrase generation. <em>NCA</em>, <em>35</em>(23),
17267–17279. (<a
href="https://doi.org/10.1007/s00521-023-08609-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exemplar-guided Paraphrase Generation aims to use an exemplar sentence to guide the generation of a paraphrase that retains the semantic content of the source sentence, along with the syntax of the exemplar. Some methods use syntax structure extracted from exemplars to guide generation, but the preprocesses may cause information loss. The other methods directly use the natural exemplar sentences (NES) as syntactic guidance, which avoids the loss of information but fails to capture and integrate the exemplar’s syntax and source sentence’s semantics effectively. In this paper, we propose a Highlighted Contrastive learning framework for exemplar-guided Paraphrase Generation (HCPG), which solves the shortcomings of using NES as syntactic guidance. The “highlight” refers to a continuous process of supplementing and refining, which effectively captures both the semantic and syntactic information of the sentences. HCPG also includes a contrastive loss layer to help the decoder fully integrate the highlighted semantic and syntactic information to generate final paraphrases. Experiments on ParaNMT and QQP-Pos show that HCPG is comparable to several state-of-the-art models, including SAGP and GCPG, and achieves an average 3.19\% improvement compared with CLPG.},
  archive      = {J_NCA},
  author       = {Zhang, Haoran and Li, Li},
  doi          = {10.1007/s00521-023-08609-7},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17267-17279},
  shortjournal = {Neural Comput. Appl.},
  title        = {HCPG: A highlighted contrastive learning framework for exemplar-guided paraphrase generation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early detection of COPD patients’ symptoms with personal
environmental sensors: A remote sensing framework using probabilistic
latent component analysis with linear dynamic systems. <em>NCA</em>,
<em>35</em>(23), 17247–17265. (<a
href="https://doi.org/10.1007/s00521-023-08554-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a cohort study involving 106 COPD patients using portable environmental sensor nodes with attached air pollution sensors and activity-related sensors, as well as daily symptom records and peak flow measurements to monitor patients’ activity and personal exposure to air pollution. This is the first study which attempts to predict COPD symptoms based on personal air pollution exposure. We developed a system that can detect COPD patients’ symptoms one day in advance of symptoms appearing. We proposed using the Probabilistic Latent Component Analysis (PLCA) model based on 3-dimensional and 4-dimensional spectral dictionary tensors for personalised and population monitoring, respectively. The model is combined with Linear Dynamic Systems (LDS) to track the patients’ symptoms. We compared the performance of PLCA and PLCA-LDS models against Random Forest models in the identification of COPD patients’ symptoms, since tree-based classifiers were used for remote monitoring of COPD patients in the literature. We found that there was a significant difference between the classifiers, symptoms and the personalised versus population factors. Our results show that the proposed PLCA-LDS-3D model outperformed the PLCA and the RF models between 4 and 20\% on average. When we used only air pollutants as input, the PLCA-LDS-3D forecasting results in personalised and population models were 48.67 and 36.33\% accuracy for worsening of lung capacity and 38.67 and 19\% accuracy for exacerbation of COPD patients’ symptoms, respectively. We have shown that indicators of the quality of an individual’s environment, specifically air pollutants, are as good predictors of the worsening of respiratory symptoms in COPD patients as a direct measurement.},
  archive      = {J_NCA},
  author       = {Kolozali, Şefki and Chatzidiakou, Lia and Jones, Roderic and Quint, Jennifer K. and Kelly, Frank and Barratt, Benjamin},
  doi          = {10.1007/s00521-023-08554-5},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17247-17265},
  shortjournal = {Neural Comput. Appl.},
  title        = {Early detection of COPD patients’ symptoms with personal environmental sensors: A remote sensing framework using probabilistic latent component analysis with linear dynamic systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Arabic spam tweets classification using deep learning.
<em>NCA</em>, <em>35</em>(23), 17233–17246. (<a
href="https://doi.org/10.1007/s00521-023-08614-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increased use of social network sites, such as Twitter, attackers exploit these platforms to spread counterfeit content. Such content can be fake advertisements or illegal content. Classifying such content is a challenging task, especially in Arabic. The Arabic language has a complex structure and makes classification tasks more difficult. This paper presents an approach to classifying Arabic tweets using classical machine learning (non-deep machine learning) and deep learning techniques. Tweets corpus were collected through Twitter API and labelled manually to get a reliable dataset. For an efficient classifier, feature extraction is applied to the corpus dataset. Then, two learning techniques are used for each feature extraction technique on the created dataset using N-gram models (uni-gram, bi-gram, and char-gram). The applied classical machine learning algorithms are support vector machines, neural networks, logistics regression, and naïve Bayes. Global vector (GloVe) and fastText learning models are utilised for the deep learning approaches. The Precision, Recall, and F1-score are the suggested performance measures calculated in this paper. Afterwards, the dataset is increased using the synthetic minority oversampling technique class to create a balanced dataset. After applying the classical machine learning models, the experimental results show that the neural network algorithm outperforms the other algorithms. Moreover, the GloVe outperforms the fastText model for the deep learning approach.},
  archive      = {J_NCA},
  author       = {Kaddoura, Sanaa and Alex, Suja A. and Itani, Maher and Henno, Safaa and AlNashash, Asma and Hemanth, D. Jude},
  doi          = {10.1007/s00521-023-08614-w},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17233-17246},
  shortjournal = {Neural Comput. Appl.},
  title        = {Arabic spam tweets classification using deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based spatial–temporal adaptive dual-graph
convolutional network for traffic flow forecasting. <em>NCA</em>,
<em>35</em>(23), 17217–17231. (<a
href="https://doi.org/10.1007/s00521-023-08582-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow forecasting (TFF) is a prerequisite for urban traffic control and guidance, which has become the key to avoiding traffic congestion and improving traffic management in intelligent transportation systems. To precisely characterize the spatial structure of road networks and discover temporal and spatial characteristics, we propose an attention-based spatial–temporal adaptive dual-graph convolutional network (ASTA-DGCN) for TFF in this paper. Specifically, we employ a spatial–temporal attention module to explore the hidden temporal correlation information of traffic data and the implicit influence of weights among road network nodes and to further capture the dynamic influence of different spatial–temporal positions on the current spatial–temporal position. Then, we utilize an adaptive graph modeling module to automatically extract the one-way relationship between variables and integrate external knowledge into the module. The FastDTW algorithm is exploited to measure the similarity of road network nodes, and the non-Euclidean pairwise association between regions is encoded into graphs to discover the hidden temporal pattern similarity effectively. Furthermore, temporal and spatial correlations are explicitly modeled using dual-graph convolution and sequential convolution based on the obtained graphs to mine the spatial–temporal patterns in dynamic traffic flow, and the final prediction result is produced based on the weighted fusion of the output values of the recent, daily, and weekly components. Finally, the ASTA-DGCN algorithm is successfully applied to TFF on two real-world traffic datasets. The experimental results indicate that our ASTA-DGCN algorithm outperforms ARIMA, VAR, FNN, GCN, GAT, GWNet, STGCN, ASTGCN, and STSGCN.},
  archive      = {J_NCA},
  author       = {Xia, Dawen and Shen, Bingqi and Geng, Jian and Hu, Yang and Li, Yantao and Li, Huaqing},
  doi          = {10.1007/s00521-023-08582-1},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17217-17231},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention-based spatial–temporal adaptive dual-graph convolutional network for traffic flow forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sle-CNN: A novel convolutional neural network for sleep
stage classification. <em>NCA</em>, <em>35</em>(23), 17201–17216. (<a
href="https://doi.org/10.1007/s00521-023-08598-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many classical methods have been used in automatic sleep stage classification but few methods explore deep learning. Meanwhile, most deep learning methods require extensive expertise and suffer from a mass of handcrafted steps which are time-consuming. In this paper, we propose an efficient convolutional neural network, Sle-CNN, for five-sleep-stage classification. We attach each kernel in the first layers with a trainable coefficient to enhance the learning ability and flexibility of the kernel. Then, we make full use of the genetic algorithm’s heuristic search and the advantage of no need for the gradient to search for the sleep stage classification architecture. We verify the convergence of Sle-CNN and compare the performance of traditional convolutional neural networks before and after using the trainable coefficient. Meanwhile, we compare the performance between the Sle-CNN generated through genetic algorithm and the traditional convolutional neural networks. The experiments demonstrate that the convergence of Sle-CNN is faster than the normal convolutional neural networks and the Sle-CNN generated by genetic algorithm outperforms the traditional handcrafted counterparts too. Our research suggests that deep learning has a great potential on electroencephalogram signal processing, especially with the intensification of neural architecture search. Meanwhile, neural architecture search can exert greater power in practical engineering applications. We conduct the Sle-CNN with the Python library, Pytorch, and the code and models will be publicly available.},
  archive      = {J_NCA},
  author       = {Zhang, Zhenman and Xue, Yu and Slowik, Adam and Yuan, Ziming},
  doi          = {10.1007/s00521-023-08598-7},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17201-17216},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sle-CNN: A novel convolutional neural network for sleep stage classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new classification method for diagnosing COVID-19
pneumonia based on joint CNN features of chest x-ray images and parallel
pyramid MLP-mixer module. <em>NCA</em>, <em>35</em>(23), 17187–17199.
(<a href="https://doi.org/10.1007/s00521-023-08604-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past three years, the coronavirus disease 2019 (COVID-19) has swept the world. The rapid and accurate recognition of covid-19 pneumonia are ,therefore, of great importance. To handle this problem, we propose a new pipeline of deep learning framework for diagnosing COVID-19 pneumonia via chest X-ray images from normal, COVID-19, and other pneumonia patients. In detail, the self-trained YOLO-v4 network was first used to locate and segment the thoracic region, and the output images were scaled to the same size. Subsequently, the pre-trained convolutional neural network was adopted to extract the features of X-ray images from 13 convolutional layers, which were fused with the original image to form a 14-dimensional image matrix. It was then put into three parallel pyramid multi-layer perceptron (MLP)-Mixer modules for comprehensive feature extraction through spatial fusion and channel fusion based on different scales so as to grasp more extensive feature correlation. Finally, by combining all image features from the 14-channel output, the classification task was achieved using two fully connected layers as well as Softmax classifier for classification. Extensive simulations based on a total of 4099 chest X-ray images were conducted to verify the effectiveness of the proposed method. Experimental results indicated that our proposed method can achieve the best performance in almost all cases, which is good for auxiliary diagnosis of COVID-19 and has great clinical application potential.},
  archive      = {J_NCA},
  author       = {Liu, Yiwen and Xing, Wenyu and Zhao, Mingbo and Lin, Mingquan},
  doi          = {10.1007/s00521-023-08604-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17187-17199},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new classification method for diagnosing COVID-19 pneumonia based on joint CNN features of chest X-ray images and parallel pyramid MLP-mixer module},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic document classification via transformers for
regulations compliance management in large utility companies.
<em>NCA</em>, <em>35</em>(23), 17167–17185. (<a
href="https://doi.org/10.1007/s00521-023-08555-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation of large utility companies such as Consolidated Edison Company of New York, Inc. (Con Edison) typically rely on large quantities of regulation documents from external institutions which inform the company of upcoming or ongoing policy changes or new requirements the company might need to comply with if deemed applicable. As a concrete example, if a recent regulatory publication mentions that the timeframe for the Company to respond to a reported system emergency in its service territory changes from within X time to within Y time—then the affected operating groups will be notified, and internal Company operating procedures may need to be reviewed and updated accordingly to comply with the new regulatory requirement. Each such regulation document needs to be reviewed manually by an expert to determine if the document is relevant to the company and, if so, which department it is relevant to. In order to help enterprises improve the efficiency of their operation, we propose an automatic document classification pipeline that determines whether a document is important for the company or not, and if deemed important it forwards those documents to the departments within the company for further review. Binary classification task of determining the importance of a document is done via ensembling the Naive Bayes (NB), support vector machine (SVM), random forest (RF), and artificial neural network (ANN) together for the final prediction, whereas the multi-label classification problem of identifying the relevant departments for a document is executed by the transformer-based DocBERT model. We apply our pipeline to a large corpus of tens of thousands of text data provided by Con Edison and achieve an accuracy score over $$80\%$$ . Compared with existing solutions for document classification which rely on a single classifier, our paper i) ensemble multiple classifiers for better accuracy results and escaping from the problem of overfitting, ii) utilize pretrained transformer-based DocBERT model to achieve ideal performance for multi-label classification task and iii) introduce a bi-level structure to improve the performance of the whole pipeline where the binary classification module works as a rough filter before finally distributing the text to corresponding departments through the multi-label classification module.},
  archive      = {J_NCA},
  author       = {Dimlioglu, Tolga and Wang, Jing and Bisla, Devansh and Choromanska, Anna and Odie, Simon and Bukhman, Leon and Olomola, Afolabi and Wong, James D.},
  doi          = {10.1007/s00521-023-08555-4},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17167-17185},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic document classification via transformers for regulations compliance management in large utility companies},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Personality traits prediction model from turkish contents
with semantic structures. <em>NCA</em>, <em>35</em>(23), 17147–17165.
(<a href="https://doi.org/10.1007/s00521-023-08603-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Users&#39; personality traits can provide different clues about them in the Internet environment. Some areas where these clues can be used are law enforcement, advertising agencies, recruitment processes, and e-commerce applications. In this study, it is aimed to create a dataset and a prediction model for predicting the personality traits of Internet users who produce Turkish content. The main contribution of the study is the personality traits dataset composed of the Turkish Twitter content. In addition, the preprocessing, vectorization, and deep learning model comparisons made in the proposed prediction system will contribute to both current usages and future studies in the relevant literature. It has been observed that the success of the Bidirectional Encoder Representations from Transformers vectorization method and the Stemming preprocessing step on the Turkish personality traits dataset is high. In the previous studies, the effects of these processes on English datasets were reported to have lower success rates. In addition, the results show that the Bidirectional Long Short-Term Memory deep learning method has a better level of success than other methods both for the Turkish dataset and English datasets.},
  archive      = {J_NCA},
  author       = {Kosan, Muhammed Ali and Karacan, Hacer and Urgen, Burcu A.},
  doi          = {10.1007/s00521-023-08603-z},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17147-17165},
  shortjournal = {Neural Comput. Appl.},
  title        = {Personality traits prediction model from turkish contents with semantic structures},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards robust CNN-based malware classifiers using
adversarial examples generated based on two saliency similarities.
<em>NCA</em>, <em>35</em>(23), 17129–17146. (<a
href="https://doi.org/10.1007/s00521-023-08590-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Targeted malware attacks are usually more purposeful and harmful than untargeted attacks, so it is important to perform the malware family classification. In classification tasks, convolutional neural networks (CNN) have shown superior performance. However, clean samples with intentional small-scale perturbations (i.e. adversarial examples) may lead to incorrect decisions made by CNN-based classifiers. The most successful approach to improve the robustness of classifiers is adversarially trained on practical adversarial examples. Despite many attempts, previous works have not dealt with generating executable adversarial examples in a pure black-box manner to emulate adversarial threats. The aim of this work is to generate realistic adversarial malware examples and improve the robustness of classifiers against these attacks. We first explain the decision of malware classification by the saliency detection technique and argue that there are two similarities in saliency distribution of CNN classifiers. To explore the under-researched Malware to Malware threats that deceive PE malware classifiers into targeted misclassification, we propose the Saliency Append (SA) attack method based on the two saliency similarities, which produces adversarial examples via only one query, achieving higher attack success rate than other append-based attacks. We use these examples to improve the robustness of classifiers by adversarially trained on the generated adversarial examples. Compared to classifiers trained on other attacks, our approach produces classifiers that are significantly more robust against the proposed SA attack as well as others.},
  archive      = {J_NCA},
  author       = {Zhan, Dazhi and Hu, Yue and Li, Weili and Chen, Jun and Guo, Shize and Pan, Zhisong},
  doi          = {10.1007/s00521-023-08590-1},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17129-17146},
  shortjournal = {Neural Comput. Appl.},
  title        = {Towards robust CNN-based malware classifiers using adversarial examples generated based on two saliency similarities},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CaDenseNet: A novel deep learning approach using capsule
network with attention for the identification of HIV-1 integration site.
<em>NCA</em>, <em>35</em>(23), 17113–17128. (<a
href="https://doi.org/10.1007/s00521-023-08585-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human immunodeficiency virus (HIV) is one of the many variants of the retrovirus and it affects the human immune system. HIV integration site (IS) is a key determinant in the entire infection process and in finding a cure for the fatal disease owing to the fact that it is critical in determining the entire latent viral reservoir formation process. The ISs are specific to the retrovirus and in the case of HIV, the integration may take place at any stage of the cell cycle. The extent and process of the rebound of the virus when the antiretroviral therapy is disturbed is also determined by the IS. IS databases are mainly populated by lab-based observations/experiments which are performed for their isolation and analysis of some ‘other’ related characteristics in an attempt to influence the integration process. This work proposes a unique Deep Learning (DL) approach, using the recently developed Capsule Network along with attention, for the prediction of IS. Retrovirus Integration Database has been used as it is one amongst the few publicly available gold standard databases of retrovirus IS in the human genome and has the cells transfected under lab conditions. This work achieves a performance much better than the existing state-of-the-art method (both with and without additional genomic markers), presented here in terms of the metrics AUC-ROC, AUC-PR and F-score. It looks beyond lab-based studies for HIV IS analysis and suggests that some advanced DL- based automated architecture can help in progressing towards a cure to the disease.},
  archive      = {J_NCA},
  author       = {Boruah, Minakshi and Das, Ranjita},
  doi          = {10.1007/s00521-023-08585-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17113-17128},
  shortjournal = {Neural Comput. Appl.},
  title        = {CaDenseNet: A novel deep learning approach using capsule network with attention for the identification of HIV-1 integration site},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A modified adam algorithm for deep neural network
optimization. <em>NCA</em>, <em>35</em>(23), 17095–17112. (<a
href="https://doi.org/10.1007/s00521-023-08568-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are widely regarded as the most effective learning tool for dealing with large datasets, and they have been successfully used in thousands of applications in a variety of fields. Based on these large datasets, they are trained to learn the relationships between various variables. The adaptive moment estimation (Adam) algorithm, a highly efficient adaptive optimization algorithm, is widely used as a learning algorithm in various fields for training DNN models. However, it needs to improve its generalization performance, especially when training with large-scale datasets. Therefore, in this paper, we propose HN Adam, a modified version of the Adam Algorithm, to improve its accuracy and convergence speed. The HN_Adam algorithm is modified by automatically adjusting the step size of the parameter updates over the training epochs. This automatic adjustment is based on the norm value of the parameter update formula according to the gradient values obtained during the training epochs. Furthermore, a hybrid mechanism was created by combining the standard Adam algorithm and the AMSGrad algorithm. As a result of these changes, the HN_Adam algorithm, like the stochastic gradient descent (SGD) algorithm, has good generalization performance and achieves fast convergence like other adaptive algorithms. To test the proposed HN_Adam algorithm performance, it is evaluated to train a deep convolutional neural network (CNN) model that classifies images using two different standard datasets: MNIST and CIFAR-10. The algorithm results are compared to the basic Adam algorithm and the SGD algorithm, in addition to other five recent SGD adaptive algorithms. In most comparisons, the HN Adam algorithm outperforms the compared algorithms in terms of accuracy and convergence speed. AdaBelief is the most competitive of the compared algorithms. In terms of testing accuracy and convergence speed (represented by the consumed training time), the HN-Adam algorithm outperforms the AdaBelief algorithm by an improvement of 1.0\% and 0.29\% for the MNIST dataset, and 0.93\% and 1.68\% for the CIFAR-10 dataset, respectively.},
  archive      = {J_NCA},
  author       = {Reyad, Mohamed and Sarhan, Amany M. and Arafa, M.},
  doi          = {10.1007/s00521-023-08568-z},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17095-17112},
  shortjournal = {Neural Comput. Appl.},
  title        = {A modified adam algorithm for deep neural network optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-stage screening framework for enhanced oil recovery
methods, using artificial neural networks. <em>NCA</em>,
<em>35</em>(23), 17077–17094. (<a
href="https://doi.org/10.1007/s00521-023-08557-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a two-stage screening system to predict the most suitable EOR method for a candidate reservoir using artificial neural networks (ANN) trained with more than 1000 worldwide experiences of EOR projects. In the first stage, an ANN is trained to classify the projects into three main categories including water-based, gas and thermal EOR. The prediction accuracy of the trained model in this stage is around 90\% over non-observed projects. More specifically, for thermal category, 99 out of 108, for gas category, 96 out of 104 and for water-based category, 47 out of 55 projects in the test data (non-observed data) were assigned to the right category by the model. In the second stage, for each of three categories, a separate ANN is trained with the corresponding datasets to classify the projects into their main sub-categories. The three models developed for classifying water-based, gas and thermal EOR projects into their main sub-categories, delivered a very well performance with average accuracies of 96, 90 and 94\%, respectively. The proposed screening system in this work introduces two main opportunities over the previous works in this field. First, the two-stage structure allows for a more accurate EOR selection since the model is less probable to be biased by larger EOR classes, and second, it allows for using additional input features for specific methods which are not available for all types of EOR methods. Finally, we demonstrated the applicability of the proposed system, by considering 12 Iranian candidate reservoirs, for which the primary EOR screening processes was performed in a study established by Mashayekhizadeh et al. in 2014. Screening results in both works are in a full agreement which demonstrates the efficiency and quickness of the proposed system.},
  archive      = {J_NCA},
  author       = {Cheraghi, Yasaman and Kord, Shahin and Mashayekhizadeh, Vahid},
  doi          = {10.1007/s00521-023-08557-2},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17077-17094},
  shortjournal = {Neural Comput. Appl.},
  title        = {A two-stage screening framework for enhanced oil recovery methods, using artificial neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stacked autoencoder with novel integrated activation
functions for the diagnosis of autism spectrum disorder. <em>NCA</em>,
<em>35</em>(23), 17043–17075. (<a
href="https://doi.org/10.1007/s00521-023-08565-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism screening is crucial for the early diagnosis of developmental disorder. The combination of machine learning (ML) and deep learning (DL) approaches are applied to produce memory efficient and less complex deep learning models for the computer aided diagnosis (CAD) of autism screening. In the proposed work, two novel integrated activation functions such as Li-ReLU and S-RReLU are developed to aid in the classification of autistic subjects and typical controls (TC) with maximum accuracy. As functional magnetic resonance imaging (fMRI) data is noisy, it undergoes temporal and spatial pre-processing. The artifact free high dimensional fMRI data is exercised for the process of feature extraction and dimensionality reduction employing group principal component analysis (Group PCA) and group independent component analysis (Group ICA). The selected features are normalized using 0–1 normalization and converted to tensors. Stacked autoencoder (SAE) utilizes the fMRI tensor data for the classification of autism spectrum disorder (ASD) subjects and typical controls. The proposed work is implemented and tested on all datasets of ABIDE I database. The validation accuracy of CMU_a, KKI, UCLA_2, OLIN, Yale and NYU datasets are obtained as 100, 80, 71.43, 100, 85.71 and 93.33\% using novel Li-ReLU activation function in the proposed system. With the help of new activation function called S-RReLU, the proposed system achieves validation accuracy of about 10, 100, 57.14, 100, 78.57 and 93.33\% for CMU_a, KKI, UCLA_2, OLIN, Yale and NYU datasets. Thus, the proposed method outperforms all other existing state-of-the-art works in terms of accuracy.},
  archive      = {J_NCA},
  author       = {M, Kaviya Elakkiya and Dejey},
  doi          = {10.1007/s00521-023-08565-2},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17043-17075},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stacked autoencoder with novel integrated activation functions for the diagnosis of autism spectrum disorder},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-series benchmarks based on frequency features for fair
comparative evaluation. <em>NCA</em>, <em>35</em>(23), 17029–17041. (<a
href="https://doi.org/10.1007/s00521-023-08562-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series prediction and imputation receive lots of attention in academic and industrial areas. Machine learning methods have been developed for specific time-series scenarios; however, it is difficult to evaluate the effectiveness of a certain method on other new cases. In the perspective of frequency features, a comprehensive benchmark for time-series prediction is designed for fair evaluation. A prediction problem generation process, composed of the finite impulse response filter-based approach and problem setting module, is adopted to generate the NCAA2022 dataset, which includes 16 prediction problems. To reduce the computational burden, the filter parameters matrix is divided into sub-matrices. The discrete Fourier transform is introduced to analyze the frequency distribution of transformed results. In addition, a baseline experiment further reflects the benchmarking capability of NCAA2022 dataset.},
  archive      = {J_NCA},
  author       = {Wu, Zhou and Jiang, Ruiqi},
  doi          = {10.1007/s00521-023-08562-5},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17029-17041},
  shortjournal = {Neural Comput. Appl.},
  title        = {Time-series benchmarks based on frequency features for fair comparative evaluation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level membership inference attacks in federated
learning based on active GAN. <em>NCA</em>, <em>35</em>(23),
17013–17027. (<a
href="https://doi.org/10.1007/s00521-023-08593-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, federated learning has been widely used in various fields, such as smart healthcare and financial forecast, due to its ability to protect the privacy of user secret data. Although federated learning has the capability of protecting users’ data privacy, recent research results demonstrated that federated learning still suffers from many privacy attacks. Among them, membership inference attacks are the most common privacy attacks in which attackers infer whether the record belongs to a member message or not. However, the current studies are unable to provide further depth to infer membership information, meaning that existing attack methods have difficulty deducing specifically which user the record belongs to. Moreover, there is a lack of training data in the training process which seriously impacts the effectiveness of membership inference attacks. In this paper, from the perspective of inferring both model-level and user-level membership information, we not only infer whether a record belongs to members but furthermore identify which member the record belongs to. In addition, we augment the training dataset by leveraging the generative adversarial networks (GANs) approach and address the lack of labeling of the newly generated data with the aid of the active learning approach. To demonstrate the effectiveness of our method, we implement our proposed methods on the five benchmark datasets. Extensive experimental results demonstrate that both model-level and user-level membership inference attacks can be achieved with good effectiveness.},
  archive      = {J_NCA},
  author       = {Sui, Hao and Sun, Xiaobing and Zhang, Jiale and Chen, Bing and Li, Wenjuan},
  doi          = {10.1007/s00521-023-08593-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {17013-17027},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-level membership inference attacks in federated learning based on active GAN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent identification and classification system for
malicious uniform resource locators (URLs). <em>NCA</em>,
<em>35</em>(23), 16995–17011. (<a
href="https://doi.org/10.1007/s00521-023-08592-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uniform Resource Locator (URL) is a unique identifier composed of protocol and domain name used to locate and retrieve a resource on the Internet. Like any Internet service, URLs (also called websites) are vulnerable to compromise by attackers to develop Malicious URLs that can exploit/devastate the user’s information and resources. Malicious URLs are usually designed with the intention of promoting cyber-attacks such as spam, phishing, malware, and defacement. These websites usually require action on the user’s side and can reach users across emails, text messages, pop-ups, or devious advertisements. They have a potential impact that can reach, in some cases, to compromise the machine or network of the user, especially those arriving by email. Therefore, developing systems to detect malicious URLs is of great interest nowadays. This paper proposes a high-performance machine learning-based detection system to identify Malicious URLs. The proposed system provides two layers of detection. Firstly, we identify the URLs as either benign or malware using a binary classifier. Secondly, we classify the URL classes based on their feature into five classes: benign, spam, phishing, malware, and defacement. Specifically, we report on four ensemble learning approaches, viz. the ensemble of bagging trees (En_Bag) approach, the ensemble of k-nearest neighbor (En_kNN) approach, and the ensemble of boosted decision trees (En_Bos) approach, and the ensemble of subspace discriminator (En_Dsc) approach. The developed approaches have been evaluated on an inclusive and contemporary dataset for uniform resource locators (ISCX-URL2016). ISCX-URL2016 provides a lightweight dataset for detecting and categorizing malicious URLs according to their attack type and lexical analysis. Conventional machine learning evaluation measurements are used to evaluate the detection accuracy, precision, recall, F Score, and detection time. Our experiential assessment indicates that the ensemble of bagging trees (En_Bag) approach provides better performance rates than other ensemble methods. Alternatively, the ensemble of the k-nearest neighbor (En_kNN) approach provides the highest inference speed. We also contrast our En_Bag model with state-of-the-art solutions and show its superiority in binary classification and multi-classification with accuracy rates of 99.3\% and 97.92\%, respectively.},
  archive      = {J_NCA},
  author       = {Abu Al-Haija, Qasem and Al-Fayoumi, Mustafa},
  doi          = {10.1007/s00521-023-08592-z},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16995-17011},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligent identification and classification system for malicious uniform resource locators (URLs)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MMNet: A medical image-to-image translation network based on
manifold-value correction and manifold matching. <em>NCA</em>,
<em>35</em>(23), 16975–16994. (<a
href="https://doi.org/10.1007/s00521-023-08685-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-to-image translation (I2I) has broad application prospects for assisting physicians in diagnosis of medical image missing scenarios. Considering that there is no medical I2I model constructed from a geometric view of simultaneously preserving local manifold-value and global manifold structure, we propose an I2I model based on manifold-value correction and manifold matching (MMNet) to translate one modal image to another in a paired and unpaired fashion and preserve the texture details of the target model image. For local manifold-value preservation, each manifold-value of the generated image is aligned with the corresponding real image as much as possible by jointly optimizing the distribution corrector and the distribution generator. For global manifold structure preservation, three distance metrics are defined to globally reduce the difference between the manifold of the generated images and the manifold of the real images through optimizing the manifold matching loss. Experimental results demonstrate that the proposed MMNet outperforms multiple state-of-the-art GANs-based methods for MR image translation in both qualitative and quantitative measures.},
  archive      = {J_NCA},
  author       = {Zeng, Xianhua and Li, Biao and Wang, Xinyu},
  doi          = {10.1007/s00521-023-08685-9},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16975-16994},
  shortjournal = {Neural Comput. Appl.},
  title        = {MMNet: A medical image-to-image translation network based on manifold-value correction and manifold matching},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on deep learning models for detection of COVID-19.
<em>NCA</em>, <em>35</em>(23), 16945–16973. (<a
href="https://doi.org/10.1007/s00521-023-08683-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of the COVID-19 started back in 2019; and so far, more than 4 million people around the world have lost their lives to this deadly virus and its variants. In view of the high transmissibility of the Corona virus, which has turned this disease into a global pandemic, artificial intelligence can be employed as an effective tool for an earlier detection and treatment of this illness. In this review paper, we evaluate the performance of the deep learning models in processing the X-Ray and CT-Scan images of the Corona patients’ lungs and describe the changes made to these models in order to enhance their Corona detection accuracy. To this end, we introduce the famous deep learning models such as VGGNet, GoogleNet and ResNet and after reviewing the research works in which these models have been used for the detection of COVID-19, we compare the performances of the newer models such as DenseNet, CapsNet, MobileNet and EfficientNet. We then present the deep learning techniques of GAN, transfer learning, and data augmentation and examine the statistics of using these techniques. Here, we also describe the datasets introduced since the onset of the COVID-19. These datasets contain the lung images of Corona patients, healthy individuals, and the patients with non-Corona pulmonary diseases. Lastly, we elaborate on the existing challenges in the use of artificial intelligence for COVID-19 detection and the prospective trends of using this method in similar situations and conditions.},
  archive      = {J_NCA},
  author       = {Mozaffari, Javad and Amirkhani, Abdollah and Shokouhi, Shahriar B.},
  doi          = {10.1007/s00521-023-08683-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16945-16973},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey on deep learning models for detection of COVID-19},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantifying the effect of feedback frequency in interactive
reinforcement learning for robotic tasks. <em>NCA</em>, <em>35</em>(23),
16931–16943. (<a
href="https://doi.org/10.1007/s00521-022-07949-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) has become widely adopted in robot control. Despite many successes, one major persisting problem can be very low data efficiency. One solution is interactive feedback, which has been shown to speed up RL considerably. As a result, there is an abundance of different strategies, which are, however, primarily tested on discrete grid-world and small scale optimal control scenarios. In the literature, there is no consensus about which feedback frequency is optimal or at which time the feedback is most beneficial. To resolve these discrepancies we isolate and quantify the effect of feedback frequency in robotic tasks with continuous state and action spaces. The experiments encompass inverse kinematics learning for robotic manipulator arms of different complexity. We show that seemingly contradictory reported phenomena occur at different complexity levels. Furthermore, our results suggest that no single ideal feedback frequency exists. Rather that feedback frequency should be changed as the agent’s proficiency in the task increases.},
  archive      = {J_NCA},
  author       = {Harnack, Daniel and Pivin-Bachler, Julie and Navarro-Guerrero, Nicolás},
  doi          = {10.1007/s00521-022-07949-0},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16931-16943},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quantifying the effect of feedback frequency in interactive reinforcement learning for robotic tasks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI apology: Interactive multi-objective reinforcement
learning for human-aligned AI. <em>NCA</em>, <em>35</em>(23),
16917–16930. (<a
href="https://doi.org/10.1007/s00521-023-08586-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For an Artificially Intelligent (AI) system to maintain alignment between human desires and its behaviour, it is important that the AI account for human preferences. This paper proposes and empirically evaluates the first approach to aligning agent behaviour to human preference via an apologetic framework. In practice, an apology may consist of an acknowledgement, an explanation and an intention for the improvement of future behaviour. We propose that such an apology, provided in response to recognition of undesirable behaviour, is one way in which an AI agent may both be transparent and trustworthy to a human user. Furthermore, that behavioural adaptation as part of apology is a viable approach to correct against undesirable behaviours. The Act-Assess-Apologise framework potentially could address both the practical and social needs of a human user, to recognise and make reparations against prior undesirable behaviour and adjust for the future. Applied to a dual-auxiliary impact minimisation problem, the apologetic agent had a near perfect determination and apology provision accuracy in several non-trivial configurations. The agent subsequently demonstrated behaviour alignment with success that included up to complete avoidance of the impacts described by these objectives in some scenarios.},
  archive      = {J_NCA},
  author       = {Harland, Hadassah and Dazeley, Richard and Nakisa, Bahareh and Cruz, Francisco and Vamplew, Peter},
  doi          = {10.1007/s00521-023-08586-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16917-16930},
  shortjournal = {Neural Comput. Appl.},
  title        = {AI apology: Interactive multi-objective reinforcement learning for human-aligned AI},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable reinforcement learning for broad-XAI: A
conceptual framework and survey. <em>NCA</em>, <em>35</em>(23),
16893–16916. (<a
href="https://doi.org/10.1007/s00521-023-08423-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad-XAI moves away from interpreting individual decisions based on a single datum and aims to provide integrated explanations from multiple machine learning algorithms into a coherent explanation of an agent’s behaviour that is aligned to the communication needs of the explainee. Reinforcement Learning (RL) methods, we propose, provide a potential backbone for the cognitive model required for the development of Broad-XAI. RL represents a suite of approaches that have had increasing success in solving a range of sequential decision-making problems. However, these algorithms operate as black-box problem solvers, where they obfuscate their decision-making policy through a complex array of values and functions. EXplainable RL (XRL) aims to develop techniques to extract concepts from the agent’s: perception of the environment; intrinsic/extrinsic motivations/beliefs; Q-values, goals and objectives. This paper aims to introduce the Causal XRL Framework (CXF), that unifies the current XRL research and uses RL as a backbone to the development of Broad-XAI. CXF is designed to incorporate many standard RL extensions and integrated with external ontologies and communication facilities so that the agent can answer questions that explain outcomes its decisions. This paper aims to: establish XRL as a distinct branch of XAI; introduce a conceptual framework for XRL; review existing approaches explaining agent behaviour; and identify opportunities for future research. Finally, this paper discusses how additional information can be extracted and ultimately integrated into models of communication, facilitating the development of Broad-XAI.},
  archive      = {J_NCA},
  author       = {Dazeley, Richard and Vamplew, Peter and Cruz, Francisco},
  doi          = {10.1007/s00521-023-08423-1},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16893-16916},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explainable reinforcement learning for broad-XAI: A conceptual framework and survey},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RePReL: A unified framework for integrating relational
planning and reinforcement learning for effective abstraction in
discrete and continuous domains. <em>NCA</em>, <em>35</em>(23),
16877–16892. (<a
href="https://doi.org/10.1007/s00521-022-08119-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a hybrid planner-(deep)reinforcement learning (RL) architecture, RePReL, that leverages a relational planner to efficiently provide useful state abstractions. State abstractions have a tremendous advantage for better generalization and transfer in RL. Our framework takes an important step toward constructing these abstractions. Specifically, the framework enables multi-level abstractions by leveraging a high-level planner to communicate with a low-level (deep) reinforcement learner. Our empirical results demonstrate the generalization and transfer capabilities of the framework in both discrete and continuous domains with rich structures (objects and relations between these objects). A key aspect of RePReL is that it can be seen as a plug-and-play framework where different planners can be used in combination with different (deep) RL agents.},
  archive      = {J_NCA},
  author       = {Kokel, Harsha and Natarajan, Sriraam and Ravindran, Balaraman and Tadepalli, Prasad},
  doi          = {10.1007/s00521-022-08119-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16877-16892},
  shortjournal = {Neural Comput. Appl.},
  title        = {RePReL: A unified framework for integrating relational planning and reinforcement learning for effective abstraction in discrete and continuous domains},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Who should i trust? Cautiously learning with unreliable
experts. <em>NCA</em>, <em>35</em>(23), 16865–16875. (<a
href="https://doi.org/10.1007/s00521-022-07808-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important problem in reinforcement learning is the need for greater sample efficiency. One approach to dealing with this problem is to incorporate external information elicited from a domain expert in the learning process. Indeed, it has been shown that incorporating expert advice in the learning process can improve the rate at which an agent’s policy converges. However, these approaches typically assume a single, infallible expert; learning from multiple and/or unreliable experts is considered an open problem in assisted reinforcement learning. We present CLUE (cautiously learning with unreliable experts), a framework for learning single-stage decision problems with action advice from multiple, potentially unreliable experts that augments an unassisted learning with a model of expert reliability and a Bayesian method of pooling advice to select actions during exploration. Our results show that CLUE maintains the benefits of traditional approaches when advised by reliable experts, but is robust to the presence of unreliable experts. When learning with multiple experts, CLUE is able to rank experts by their reliability and differentiate experts based on their reliability.},
  archive      = {J_NCA},
  author       = {Love, Tamlin and Ajoodha, Ritesh and Rosman, Benjamin},
  doi          = {10.1007/s00521-022-07808-y},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16865-16875},
  shortjournal = {Neural Comput. Appl.},
  title        = {Who should i trust? cautiously learning with unreliable experts},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Q-learning as a model of utilitarianism in a human–machine
team. <em>NCA</em>, <em>35</em>(23), 16853–16864. (<a
href="https://doi.org/10.1007/s00521-022-08063-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates that Q-learning can be used to model Utilitarian decision-making. Accurately modeling ethical theories from the field of moral philosophy is an important step in the development of ethical machine learning. Modeling Utilitarian decision-making with Q-learning is a step toward ethical human–machine teaming; the human and machine contribute according to their strengths to create a more accurate Utilitarian decision than either would make individually. The Utilitarian decision is output by the Q-learning agent, as well as the ranked order of sub-optimal actions to aid in explainability. Additionally, using RL to mathematically represent Utilitarianism solves the classic drawback of Utilitarianism concerning prohibitive computation. This model can also be used for cost-benefit analysis and business decisions.},
  archive      = {J_NCA},
  author       = {Krening, Samantha},
  doi          = {10.1007/s00521-022-08063-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16853-16864},
  shortjournal = {Neural Comput. Appl.},
  title        = {Q-learning as a model of utilitarianism in a human–machine team},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hu-bot: Promoting the cooperation between humans and mobile
robots. <em>NCA</em>, <em>35</em>(23), 16841–16852. (<a
href="https://doi.org/10.1007/s00521-022-08061-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates human–robot collaboration in a novel setup: a human helps a mobile robot that can move and navigate freely in an environment. Specifically, the human helps by remotely taking over control during the learning of a task. The task is to find and collect several items in a walled arena, and Reinforcement Learning is used to seek a suitable controller. If the human observes undesired robot behavior, they can directly issue commands for the wheels through a game joystick. Experiments in a simulator showed that human assistance improved robot behavior efficacy by 30\% and efficiency by 12\%. The best policies were also tested in real life, using physical robots. Hardware experiments showed no significant difference concerning the simulations, providing empirical validation of our approach in practice.},
  archive      = {J_NCA},
  author       = {Miras, Karine and Mocanu, Decebal and Eiben, A. E.},
  doi          = {10.1007/s00521-022-08061-z},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16841-16852},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hu-bot: Promoting the cooperation between humans and mobile robots},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge- and ambiguity-aware robot learning from
corrective and evaluative feedback. <em>NCA</em>, <em>35</em>(23),
16821–16839. (<a
href="https://doi.org/10.1007/s00521-022-08118-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to deploy robots that could be adapted by non-expert users, interactive imitation learning (IIL) methods must be flexible regarding the interaction preferences of the teacher and avoid assumptions of perfect teachers (oracles), while considering they make mistakes influenced by diverse human factors. In this work, we propose an IIL method that improves the human–robot interaction for non-expert and imperfect teachers in two directions. First, uncertainty estimation is included to endow the agents with a lack of knowledge awareness (epistemic uncertainty) and demonstration ambiguity awareness (aleatoric uncertainty), such that the robot can request human input when it is deemed more necessary. Second, the proposed method enables the teachers to train with the flexibility of using corrective demonstrations, evaluative reinforcements, and implicit positive feedback. The experimental results show an improvement in learning convergence with respect to other learning methods when the agent learns from highly ambiguous teachers. Additionally, in a user study, it was found that the components of the proposed method improve the teaching experience and the data efficiency of the learning process.},
  archive      = {J_NCA},
  author       = {Celemin, Carlos and Kober, Jens},
  doi          = {10.1007/s00521-022-08118-z},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16821-16839},
  shortjournal = {Neural Comput. Appl.},
  title        = {Knowledge- and ambiguity-aware robot learning from corrective and evaluative feedback},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Communicative capital: A key resource for human–machine
shared agency and collaborative capacity. <em>NCA</em>, <em>35</em>(23),
16805–16819. (<a
href="https://doi.org/10.1007/s00521-022-07948-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a perspective on the role machine intelligence can play in supporting human abilities. In particular, we consider research in rehabilitation technologies such as prosthetic devices, as this domain requires tight coupling between human and machine. Taking an agent-based view of such devices, we propose that human–machine collaborations have a capacity to perform tasks which is a result of the combined agency of the human and the machine. We introduce communicative capital as a resource developed by a human and a machine working together in ongoing interactions. Development of this resource enables the partnership to eventually perform tasks at a capacity greater than either individual could achieve alone. We then examine the benefits and challenges of increasing the agency of prostheses by surveying literature which demonstrates that building communicative resources enables more complex, task-directed interactions. The viewpoint developed in this article extends current thinking on how best to support the functional use of increasingly complex prostheses, and establishes insight toward creating more fruitful interactions between humans and supportive, assistive, and augmentative technologies.},
  archive      = {J_NCA},
  author       = {Mathewson, Kory W. and Parker, Adam S. R. and Sherstan, Craig and Edwards, Ann L. and Sutton, Richard S. and Pilarski, Patrick M.},
  doi          = {10.1007/s00521-022-07948-1},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16805-16819},
  shortjournal = {Neural Comput. Appl.},
  title        = {Communicative capital: A key resource for human–machine shared agency and collaborative capacity},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Example-guided learning of stochastic human driving policies
using deep reinforcement learning. <em>NCA</em>, <em>35</em>(23),
16791–16804. (<a
href="https://doi.org/10.1007/s00521-022-07947-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has been successfully applied to the generation of goal-directed behavior in artificial agents. However, existing algorithms are often not designed to reproduce human-like behavior, which may be desired in many environments, such as human–robot collaborations, social robotics and autonomous vehicles. Here we introduce a model-free and easy-to-implement deep reinforcement learning approach to mimic the stochastic behavior of a human expert by learning distributions of task variables from examples. As tractable use-cases, we study static and dynamic obstacle avoidance tasks for an autonomous vehicle on a highway road in simulation (Unity). Our control algorithm receives a feedback signal from two sources: a deterministic (handcrafted) part encoding basic task goals and a stochastic (data-driven) part that incorporates human expert knowledge. Gaussian processes are used to model human state distributions and to assess the similarity between machine and human behavior. Using this generic approach, we demonstrate that the learning agent acquires human-like driving skills and can generalize to new roads and obstacle distributions unseen during training.},
  archive      = {J_NCA},
  author       = {Emuna, Ran and Duffney, Rotem and Borowsky, Avinoam and Biess, Armin},
  doi          = {10.1007/s00521-022-07947-2},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16791-16804},
  shortjournal = {Neural Comput. Appl.},
  title        = {Example-guided learning of stochastic human driving policies using deep reinforcement learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Policy regularization for legible behavior. <em>NCA</em>,
<em>35</em>(23), 16781–16790. (<a
href="https://doi.org/10.1007/s00521-022-07942-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a method to augment a Reinforcement Learning agent with legibility. This method is inspired by the literature in Explainable Planning and allows to regularize the agent’s policy after training, and without requiring to modify its learning algorithm. This is achieved by evaluating how the agent’s optimal policy may produce observations that would make an observer model to infer a wrong policy. In our formulation, the decision boundary introduced by legibility impacts the states in which the agent’s policy returns an action that is non-legible because having high likelihood also in other policies. In these cases, a trade-off between such action, and legible/sub-optimal action is made. We tested our method in a grid-world environment highlighting how legibility impacts the agent’s optimal policy, and gathered both quantitative and qualitative results. In addition, we discuss how the proposed regularization generalizes over methods functioning with goal-driven policies, because applicable to general policies of which goal-driven policies are a special case.},
  archive      = {J_NCA},
  author       = {Persiani, Michele and Hellström, Thomas},
  doi          = {10.1007/s00521-022-07942-7},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16781-16790},
  shortjournal = {Neural Comput. Appl.},
  title        = {Policy regularization for legible behavior},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative training of heterogeneous reinforcement
learning agents in environments with sparse rewards: What and when to
share? <em>NCA</em>, <em>35</em>(23), 16753–16780. (<a
href="https://doi.org/10.1007/s00521-022-07774-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the early stages of human life, babies develop their skills by exploring different scenarios motivated by their inherent satisfaction rather than by extrinsic rewards from the environment. This behavior, referred to as intrinsic motivation, has emerged as one solution to address the exploration challenge derived from reinforcement learning environments with sparse rewards. Diverse exploration approaches have been proposed to accelerate the learning process over single- and multi-agent problems with homogeneous agents. However, scarce studies have elaborated on collaborative learning frameworks between heterogeneous agents deployed into the same environment, but interacting with different instances of the latter without any prior knowledge. Beyond the heterogeneity, each agent’s characteristics grant access only to a subset of the full state space, which may hide different exploration strategies and optimal solutions. In this work we combine ideas from intrinsic motivation and transfer learning. Specifically, we focus on sharing parameters in actor-critic model architectures and on combining information obtained through intrinsic motivation with the aim of having a more efficient exploration and faster learning. We test our strategies through experiments performed over a modified ViZDooM’s My Way Home scenario, which is more challenging than its original version and allows evaluating the heterogeneity between agents. Our results reveal different ways in which a collaborative framework with little additional computational cost can outperform an independent learning process without knowledge sharing. Additionally, we depict the need for modulating correctly the importance between the extrinsic and intrinsic rewards to avoid undesired agent behaviors.},
  archive      = {J_NCA},
  author       = {Andres, Alain and Villar-Rodriguez, Esther and Ser, Javier Del},
  doi          = {10.1007/s00521-022-07774-5},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16753-16780},
  shortjournal = {Neural Comput. Appl.},
  title        = {Collaborative training of heterogeneous reinforcement learning agents in environments with sparse rewards: What and when to share?},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incorporating rivalry in reinforcement learning for a
competitive game. <em>NCA</em>, <em>35</em>(23), 16739–16752. (<a
href="https://doi.org/10.1007/s00521-022-07746-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in reinforcement learning with social agents have allowed such models to achieve human-level performance on certain interaction tasks. However, most interactive scenarios do not have performance alone as an end-goal; instead, the social impact of these agents when interacting with humans is as important and largely unexplored. In this regard, this work proposes a novel reinforcement learning mechanism based on the social impact of rivalry behavior. Our proposed model aggregates objective and social perception mechanisms to derive a rivalry score that is used to modulate the learning of artificial agents. To investigate our proposed model, we design an interactive game scenario, using the Chef’s Hat Card Game, and examine how the rivalry modulation changes the agent’s playing style, and how this impacts the experience of human players on the game. Our results show that humans can detect specific social characteristics when playing against rival agents when compared to common agents, which affects directly the performance of the human players in subsequent games. We conclude our work by discussing how the different social and objective features that compose the artificial rivalry score contribute to our results.},
  archive      = {J_NCA},
  author       = {Barros, Pablo and Yalçın, Özge Nilay and Tanevska, Ana and Sciutti, Alessandra},
  doi          = {10.1007/s00521-022-07746-9},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16739-16752},
  shortjournal = {Neural Comput. Appl.},
  title        = {Incorporating rivalry in reinforcement learning for a competitive game},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proxemic behavior in navigation tasks using reinforcement
learning. <em>NCA</em>, <em>35</em>(23), 16723–16738. (<a
href="https://doi.org/10.1007/s00521-022-07628-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human interaction starts with a person approaching another one, respecting their personal space to prevent uncomfortable feelings. Spatial behavior, called proxemics, allows defining an acceptable distance so that the interaction process begins appropriately. In recent decades, human-agent interaction has been an area of interest for researchers, where it is proposed that artificial agents naturally interact with people. Thus, new alternatives are needed to allow optimal communication, avoiding humans feeling uncomfortable. Several works consider proxemic behavior with cognitive agents, where human-robot interaction techniques and machine learning are implemented. However, it is assumed that the personal space is fixed and known in advance, and the agent is only expected to make an optimal trajectory toward the person. In this work, we focus on studying the behavior of a reinforcement learning agent in a proxemic-based environment. Experiments were carried out implementing a grid-world problem and a continuous simulated robotic approaching environment. These environments assume that there is an issuer agent that provides non-conformity information. Our results suggest that the agent can identify regions where the issuer feels uncomfortable and find the best path to approach the issuer. The results obtained highlight the usefulness of reinforcement learning in order to identify proxemic regions.},
  archive      = {J_NCA},
  author       = {Millán-Arias, Cristian and Fernandes, Bruno and Cruz, Francisco},
  doi          = {10.1007/s00521-022-07628-0},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16723-16738},
  shortjournal = {Neural Comput. Appl.},
  title        = {Proxemic behavior in navigation tasks using reinforcement learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A huber reward function-driven deep reinforcement learning
solution for cart-pole balancing problem. <em>NCA</em>, <em>35</em>(23),
16705–16722. (<a
href="https://doi.org/10.1007/s00521-022-07606-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lots of learning tasks require experience learning based on activities performed in real scenarios which are affected by environmental factors. Therefore, real-time systems demand a model to learn from working experience—such as physical object properties-driven system models, trajectory prediction, and Atari games. This experience-driven learning model uses reinforcement learning which is considered as an important research topic and needs problem-specific reasoning model simulation. In this research paper, cart-pole balancing problem is selected as a problem where the system learns using Q-learning and Deep Q network reinforcement learning approaches. Pragmatic foundation of cart-pole problem and its solution with the help of Q learning and DQN reinforcement learning model are validated, and a comparison of achieved outcome in the form of accuracy and fast convergence is presented. An unexperienced Huber loss function is applied on cart-pole balancing problem, and results are in favor of Huber loss function in comparison with mean-squared error loss function. Hence, experimental study suggests the use of DQN with Huber loss reward function for fast learning and convergence of cart pole in balanced condition.},
  archive      = {J_NCA},
  author       = {Mishra, Shaili and Arora, Anuja},
  doi          = {10.1007/s00521-022-07606-6},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16705-16722},
  shortjournal = {Neural Comput. Appl.},
  title        = {A huber reward function-driven deep reinforcement learning solution for cart-pole balancing problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical goals contextualize local reward decomposition
explanations. <em>NCA</em>, <em>35</em>(23), 16693–16704. (<a
href="https://doi.org/10.1007/s00521-022-07280-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-step reinforcement learning explanation methods account for individual actions but fail to consider the agent’s future behavior, which can make their interpretation ambiguous. We propose to address this limitation by providing hierarchical goals as context for one-step explanations. By considering the current hierarchical goal as a context, one-step explanations can be interpreted with higher certainty, as the agent’s future behavior is more predictable. We combine reward decomposition with hierarchical reinforcement learning into a novel explainable reinforcement learning framework, which yields more interpretable, goal-contextualized one-step explanations. With a qualitative analysis of one-step reward decomposition explanations, we first show that their interpretability is indeed limited in scenarios with multiple, different optimal policies—a characteristic shared by other one-step explanation methods. Then, we show that our framework retains high interpretability in such cases, as the hierarchical goal can be considered as context for the explanation. To the best of our knowledge, our work is the first to investigate hierarchical goals not as an explanation directly but as additional context for one-step reinforcement learning explanations.},
  archive      = {J_NCA},
  author       = {Rietz, Finn and Magg, Sven and Heintz, Fredrik and Stoyanov, Todor and Wermter, Stefan and Stork, Johannes A.},
  doi          = {10.1007/s00521-022-07280-8},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16693-16704},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical goals contextualize local reward decomposition explanations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-aligned reinforcement learning for autonomous agents
and robots. <em>NCA</em>, <em>35</em>(23), 16689–16691. (<a
href="https://doi.org/10.1007/s00521-023-08748-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Cruz, Francisco and Karimpanal, Thommen George and Solis, Miguel A. and Barros, Pablo and Dazeley, Richard},
  doi          = {10.1007/s00521-023-08748-x},
  journal      = {Neural Computing and Applications},
  number       = {23},
  pages        = {16689-16691},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human-aligned reinforcement learning for autonomous agents and robots},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RGRN: Relation-aware graph reasoning network for object
detection. <em>NCA</em>, <em>35</em>(22), 16671–16688. (<a
href="https://doi.org/10.1007/s00521-023-08550-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of object detection, due to the complexity of realistic scenarios, the objects are mostly obscured and semantic-confusable. The existing CNNs-based object detectors focus only on the information within the region proposal and ignore the auxiliary role of objects-objects relationships, leading to difficulties distinguishing difficult samples in complex spaces. Accordingly, in this paper, we propose a novel relation-aware graph reasoning network (RGRN) to adaptively discover and integrate key semantic and spatial relationships in images. Specifically, in order to realize information interaction and relational reasoning between nodes, we design two parallel modules: the semantic relational reasoning module (SRRM) and the spatial relational reasoning module (SPRM). SRRM mines the semantic relationships between objects by discriminating the semantic similarity between graph nodes, and SPRM finds the spatial relationships between objects by the relative positions between nodes. Our method considers the relative spatial location and semantic correlation between objects, which can easily embed in existing networks in real-time to improve performance. Solid experiments verify the effectiveness of our method, which achieves around 16 $$\%$$ improvement on MS COCO and 10 $$\%$$ on PASCAL VOC in terms of mAP and outperforms the state-of-the-art relation-based methods, which indicates the superiority and effectiveness of RGRN.},
  archive      = {J_NCA},
  author       = {Zhao, Jianjun and Chu, Jun and Leng, Lu and Pan, Chaolin and Jia, Tao},
  doi          = {10.1007/s00521-023-08550-9},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16671-16688},
  shortjournal = {Neural Comput. Appl.},
  title        = {RGRN: Relation-aware graph reasoning network for object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating urban rail transit passenger inflow caused by
special events occurrences fusing multi-source data. <em>NCA</em>,
<em>35</em>(22), 16649–16670. (<a
href="https://doi.org/10.1007/s00521-023-08546-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is essential to provide accurate real-time forecasting to manage the intense passenger inflow (IPF) of urban rail transit (URT) stations caused by special events such as concerts and football matches. The IPF is predictable due to the fluctuations in passenger outflow before the special event, which also allows the management department to take measures to control the situation. By combining individual travel card data with event data, station data and others, this article proposes a system for estimating URT station IPF before it happens. It consists of two parts: (1) Offline model training is responsible for modeling the relationship between historical special events information, affected station information and traveler characteristics; (2) Online Inflow prediction takes the current event and affected station information as the input of the model trained in the offline part to estimate the IPF. By using the Shanghai, China URT system as an example, the results show that the proposed passenger inflow estimation system can provide a significant reduction in estimation error compared to the traditional prediction model. Additionally, the constructed system has certain robustness, which could provide a basis for the URT management department to make informed decisions.},
  archive      = {J_NCA},
  author       = {Lu, Wenbo and Zhang, Yong and Li, Peikun and Wang, Ting},
  doi          = {10.1007/s00521-023-08546-5},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16649-16670},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimating urban rail transit passenger inflow caused by special events occurrences fusing multi-source data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Actor-critic reinforcement learning leads decision-making in
energy systems optimization—steam injection optimization. <em>NCA</em>,
<em>35</em>(22), 16633–16647. (<a
href="https://doi.org/10.1007/s00521-023-08537-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steam injection is a popular technique to enhance oil recovery in mature oil fields. However, the conventional approach of using a constant steam rate over an extended period can lead to sub-optimal performance due to the complex nature of the problem and reservoir heterogeneity. To address this issue, the Markov decision process can be employed to formulate the problem for reinforcement learning (RL) applications. The RL agent is trained to optimize the steam injection rate by interacting with a reservoir simulation model and receives rewards for each action. The agent’s policy and value functions are updated through continuous interaction with the environment until convergence is achieved, leading to a more efficient steam injection strategy for enhancing oil recovery. In this study, an actor-critic RL architecture was employed to train the agent to find the optimal strategy (i.e., policy). The environment was represented by a reservoir simulation model, and the agent’s actions were based on the observed state. The policy function gave a probability distribution of the actions that the agent could take, while the value function determined the expected yield for an agent starting from a given state. The agent interacted with the environment for several episodes until convergence was achieved. The improvement in net present value (NPV) achieved by the agent was a significant indication of the effectiveness of the RL-based approach. The NPV reflects the economic benefits of the optimized steam injection strategy. The agent was able to achieve this improvement by finding the optimal policies. One of the key advantages of the optimal policy was the decrease in total field heat losses. This is a critical factor in the efficiency of the steam injection process. Heat loss can reduce the efficiency of the process and lead to lower oil recovery rates. By minimizing heat loss, the agent was able to optimize the steam injection process and increase oil recovery rates. The optimal policy had four regions characterized by slight changes in a stable injection rate to increase the average reservoir pressure, increasing the injection rate to a maximum value, steeply decreasing the injection rate, and slightly changing the injection rate to maintain the average reservoir temperature. These regions reflect the different phases of the steam injection process and demonstrate the complexity of the problem. Overall, the results of this study demonstrate the effectiveness of RL in optimizing steam injection in mature oil fields. The use of RL can help address the complexity of the problem and improve the efficiency of the oil recovery process. This study provides a framework for future research in this area and highlights the potential of RL for addressing other complex problems in the energy industry.},
  archive      = {J_NCA},
  author       = {Abdalla, Ramez and Hollstein, Wolfgang and Carvajal, Carlos Paz and Jaeger, Philip},
  doi          = {10.1007/s00521-023-08537-6},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16633-16647},
  shortjournal = {Neural Comput. Appl.},
  title        = {Actor-critic reinforcement learning leads decision-making in energy systems optimization—steam injection optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MADM and assessment of pilot health projects based on
spherical fuzzy information. <em>NCA</em>, <em>35</em>(22), 16619–16632.
(<a href="https://doi.org/10.1007/s00521-023-08533-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertainty and ambiguity in information is the major problem to aggregate. Some fuzzy frameworks and aggregation operators (AOs) have been formalized to cope with the uncertainty in information. A framework known as a spherical fuzzy set (SFS) covers the maximum possible information from real-life scenarios. Hence, the use of the SFS in multi-attribute decision-making (DM) (MADM) is very significant. This article consists of the development of some new AOs for the framework of the SFS. A family of the AOs spherical fuzzy Schweizer-Sklar (SS) McLaurin symmetric mean (MSM) (SFSSMSM), spherical fuzzy SS weighted MSM (SFSSWMSM), spherical fuzzy SS dual MSM (SFSSDMSM), and spherical fuzzy SS dual weighted MSM (PFSSDWMSM) is introduced, and their basic properties are investigated. The developed AOs are applied to the MADM problem where some pilot health projects (PHP) are assessed.},
  archive      = {J_NCA},
  author       = {Masmali, Ibtisam and Ahmad, Ali and Azeem, Muhammad and Koam, Ali N. A.},
  doi          = {10.1007/s00521-023-08533-w},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16619-16632},
  shortjournal = {Neural Comput. Appl.},
  title        = {MADM and assessment of pilot health projects based on spherical fuzzy information},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatially aligned sketch-based fine-grained 3D shape
retrieval. <em>NCA</em>, <em>35</em>(22), 16607–16617. (<a
href="https://doi.org/10.1007/s00521-023-08532-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained 3D shape retrieval supports finding a specific 3D model to serve VR/AR applications. Sketches can convey concepts that are difficult to describe in words, albeit highly concise and abstract, making it suitable for retrieving 3D shapes. Compared to sketch-based 3D shape retrieval, fine-grained sketch-based 3D shape retrieval is still a relatively under-studied problem. Previous work on FG-SBSR has mainly focused on view alignment of sketches and 3D shape projections during retrieval. However, spatial alignment across modalities is neglected, which is helpful for extracting fine-grained features. To address the spatial alignment problem, we propose an end-to-end multi-regional spatial alignment network (MRSAN) that learns spatially aligned multi-regional discriminative feature representations of sketches and projections from 3D shape. Meanwhile, for cross-domain variance, we design identity consistency loss and regional similarity loss from three aspects: identity, feature distance, and feature distribution. Instead of fusing multi-view features before ranking, a ranking method based on multi-view similarity aggregation is proposed, which utilizes multi-view information related to the query view and makes it unnecessary to recompute feature representations of 3D shapes for each query. Systematic comparative evaluations performed on Chair and Lamp datasets showed that our approach robustly achieved state-of-the-art performances. For instance, on the Chair dataset, we achieve (82.59 + 0.49)\% Top-1 accuracy and (94.20 + 2.81)\% Top-5 accuracy.},
  archive      = {J_NCA},
  author       = {Chen, Xu and Zhong, Zheng and Zhou, Dongbo},
  doi          = {10.1007/s00521-023-08532-x},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16607-16617},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatially aligned sketch-based fine-grained 3D shape retrieval},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). InvolutionGAN: Lightweight GAN with involution for
unsupervised image-to-image translation. <em>NCA</em>, <em>35</em>(22),
16593–16605. (<a
href="https://doi.org/10.1007/s00521-023-08530-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unsupervised image-to-image translation aims to learn a mapping that translates images from one domain to the target domain. Current state-of-the-art generative adversarial network (GAN) models utilize time and space-costly operators to produce impressive translated images. However, further research and model deployment are under restrictions due to the high computational costs of the models. In order to resolve the problem, we enhance the GAN structure by employing a lightweight operator named involution that facilitates extracting both local features and long-range dependencies across channels. Besides, we also notice that previous works attach less importance to feature-level reconstruction discrepancy between original and reconstructed images. Nevertheless, such information is crucial in improving the quality of the synthesized images. Thus, we develop a novel loss term that evaluates the learned perceptual similarity distance to regulate the training process. The qualitative and quantitative experiment results on several prevailing benchmarks demonstrate that our model, dubbed InvolutionGAN, could produce competitive image results while saving computational costs up to 91.9\%. In addition, extensive ablation studies are conducted to search for the best model structure and verify that each component we introduced is effective.},
  archive      = {J_NCA},
  author       = {Deng, Haipeng and Wu, Qiuxia and Huang, Han and Yang, Xiaowei and Wang, Zhiyong},
  doi          = {10.1007/s00521-023-08530-z},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16593-16605},
  shortjournal = {Neural Comput. Appl.},
  title        = {InvolutionGAN: Lightweight GAN with involution for unsupervised image-to-image translation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SimCPD: A simple framework for contrastive prompts of
target-aspect-sentiment joint detection. <em>NCA</em>, <em>35</em>(22),
16577–16592. (<a
href="https://doi.org/10.1007/s00521-023-08529-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target-aspect-sentiment detection (TASD) task is a vital task for aspect-based sentiment analysis, which aims to detect (target, aspect, sentiment) triples from sentences. However, most of the existing methods do not generate high-quality textual representations and thus produce poor performances on the TASD task. Moreover, how to deal with insufficient high-quality labeled data is also a great challenge. In this paper, we design DPDA, a Dual Prompts-based Data Augmentation method, that can generate diverse sentences with a question prompt view and an answer prompt view for each input. Then, we propose SimCPD, a Simple Framework for Contrastive Prompts of Target-Aspect-Sentiment Joint Detection, that maximizes the agreement between the two prompt views to obtain high-quality textual representations. Experiments on SemEval-2015 and SemEval-2016 demonstrate that the proposed DPDA can generate high-quality semantic information and alleviate the problem of sparsely labeled data. Moreover, the proposed SimCPD can detect (target, aspect, sentiment) triples more efficiently than other methods. Furthermore, it also achieves better performance on five TASD subtasks.},
  archive      = {J_NCA},
  author       = {Ke, Cai and Xiong, Qingyu and Wu, Chao and Yi, Hualing and Gao, Min and Chen, Jie},
  doi          = {10.1007/s00521-023-08529-6},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16577-16592},
  shortjournal = {Neural Comput. Appl.},
  title        = {SimCPD: A simple framework for contrastive prompts of target-aspect-sentiment joint detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MADDPG-based joint optimization of task partitioning and
computation resource allocation in mobile edge computing. <em>NCA</em>,
<em>35</em>(22), 16559–16576. (<a
href="https://doi.org/10.1007/s00521-023-08527-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continual development of mobile edge computing efficiently solves the problem that mobile devices are unable to handle computation-intensive tasks due to their computation capacity and battery restrictions. In this paper, we consider mobile awareness and dynamic battery charging in a multi-user and multi-server mobile edge computing system, where various tasks are generated successively on the user devices. Servers act as learning agents and collaborate with user devices to develop task partitioning and computation resource allocation strategies. With the purpose of decreasing task failure rate and improving system utility in the long term, which is closely related to latency, energy consumption, and server cost, optimal strategies are demanded by the system. We model the joint optimization problem as a multi-agent Markov decision process game. And a deep reinforcement learning method based on the multi-agent deep deterministic policy gradient algorithm is proposed, which employs neural networks and works in a centralized training and decentralized execution manner to optimize the strategies. Finally, simulation results demonstrate the effectiveness of our proposed algorithm in terms of reducing task failure rate and improving system utility.},
  archive      = {J_NCA},
  author       = {Lu, Kun and Li, Rong-Da and Li, Ming-Chu and Xu, Guo-Rui},
  doi          = {10.1007/s00521-023-08527-8},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16559-16576},
  shortjournal = {Neural Comput. Appl.},
  title        = {MADDPG-based joint optimization of task partitioning and computation resource allocation in mobile edge computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Query focused summarization via relevance distillation.
<em>NCA</em>, <em>35</em>(22), 16543–16557. (<a
href="https://doi.org/10.1007/s00521-023-08525-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating a short version of a concise and relevant summary regarding a specific query can broadly meet a user’s information needs in many areas. In a summarization system, the extractive technique is attractive because it is simple and fast and produces reliable outputs. Salience and relevance are two key points for the extractive summarization. The majority of existing approaches to achieving them are augmenting input features, incorporating additional attention, or expanding the training scales. Yet, there is much unsupervised but query-related knowledge needs better exploration. To this end, in this paper, we frame the query-focused document summarization as a combination of salience prediction and relevance prediction. Concretely, in addition to the oracle summary set for the salience task, we further create a pseudo-summary set regarding user-specific queries (i.e., title or image captions as the query) for the relevance task. Then, based on a modified BERT fine-tune summarization, we propose two methods, called guidance and distillation, respectively. Specifically, the guidance training essentially shares salient information to reinforce the useful contextual representations in a two-stage training with the salience-and-relevance objective. For the distillation, we propose a new “guide-student” learning paradigm that the relevance knowledge of the query is distilled and transferred from a guide model to a salience-oriented student model. Experiment results demonstrate that guidance training prevails at improving the salience of the summary and distillation training is significantly advanced at relevance learning. Both of them achieve the best state of the arts in unsupervised query-focused settings of CNN and DailyMail dataset.},
  archive      = {J_NCA},
  author       = {Yue, Ye and Li, Yuanli and Zhan, Jia-ao and Gao, Yang},
  doi          = {10.1007/s00521-023-08525-w},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16543-16557},
  shortjournal = {Neural Comput. Appl.},
  title        = {Query focused summarization via relevance distillation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel fixed-time stability criteria of nonlinear systems and
applications in fuzzy competitive neural network and chua’s oscillator.
<em>NCA</em>, <em>35</em>(22), 16527–16542. (<a
href="https://doi.org/10.1007/s00521-023-08523-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the fixed-time stability forms of nonlinear systems satisfy strict conditions, there are few general forms for nonlinear systems to achieve fixed-time stability. This work proposes a new class of more general fixed-time stability criteria. It is worth mentioning that, compared with the traditional method of estimating the convergence time, this paper obtains a more conservative stable time estimation formula through the integration method of the generalized integral mean theorem. In addition, given that the fixed-time stabilization of neural networks and chaotic oscillators have attracted extensive attention in recent years, and there are still many fixed-time stabilizations of nonlinear systems that have not been studied. Therefore, a discontinuous controller is designed in this paper. The above stability theory results are applied to the fixed-time stabilization of the Takagi-Sugeno (T-S) fuzzy competitive neural network and chaotic system (coupled Chua’s oscillator). Finally, the validity and applicability of the theoretical results are verified by examples.},
  archive      = {J_NCA},
  author       = {Ren, Fangmin and Wang, Xiaoping and Zeng, Zhigang},
  doi          = {10.1007/s00521-023-08523-y},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16527-16542},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel fixed-time stability criteria of nonlinear systems and applications in fuzzy competitive neural network and chua’s oscillator},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint-product representation learning for domain
generalization in classification and regression. <em>NCA</em>,
<em>35</em>(22), 16509–16526. (<a
href="https://doi.org/10.1007/s00521-023-08520-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the problem of generalizing a prediction (classification or regression) model trained on a set of source domains to an unseen target domain, where the source and target domains are different but related, i.e, the domain generalization problem. The challenge in this problem lies in the domain difference, which could degrade the generalization ability of the prediction model. To tackle this challenge, we propose to learn a neural network representation function to align a joint distribution and a product distribution in the representation space, and show that such joint-product distribution alignment conveniently leads to the alignment of multiple domains. In particular, we align the joint distribution and the product distribution under the $$L^{2}$$ -distance, and show that this distance can be analytically estimated by exploiting its variational characterization and a linear variational function. This allows us to comfortably align the two distributions by minimizing the estimated distance with respect to the network representation function. Our experiments on synthetic and real-world datasets for classification and regression demonstrate the effectiveness of the proposed solution. For example, it achieves the best average classification accuracy of 82.26\% on the text dataset Amazon Reviews, and the best average regression error of 0.114 on the WiFi dataset UJIIndoorLoc.},
  archive      = {J_NCA},
  author       = {Chen, Sentao and Chen, Liang},
  doi          = {10.1007/s00521-023-08520-1},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16509-16526},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint-product representation learning for domain generalization in classification and regression},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Environment modeling and localization from datasets of
omnidirectional scenes using machine learning techniques. <em>NCA</em>,
<em>35</em>(22), 16487–16508. (<a
href="https://doi.org/10.1007/s00521-023-08515-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a framework to create a visual model of the environment which can be used to estimate the position of a mobile robot by means of artificial intelligence techniques. The proposed framework retrieves the structure of the environment from a dataset composed of omnidirectional images captured along it. These images are described by means of global-appearance approaches. The information is arranged in two layers, with different levels of granularity. The first layer is obtained by means of classifiers and the second layer is composed of a set of data fitting neural networks. Subsequently, the model is used to estimate the position of the robot, in a hierarchical fashion, by comparing the image captured from the unknown position with the information in the model. Throughout this work, five classifiers are evaluated (Naïve Bayes, SVM, random forest, linear discriminant classifier and a classifier based on a shallow neural network) along with three different global-appearance descriptors (HOG, gist, and a descriptor calculated from an intermediate layer of a pre-trained CNN). The experiments have been tackled with some publicly available datasets of omnidirectional images captured indoors with the presence of dynamic changes. Several parameters are used to assess the efficiency of the proposal: the ability of the algorithm to estimate coarsely the position (hit ratio), the average error (cm) and the necessary computing time. The results prove the efficiency of the framework to model the environment and localize the robot from the knowledge extracted from a set of omnidirectional images with the proposed artificial intelligence techniques.},
  archive      = {J_NCA},
  author       = {Cebollada, Sergio and Payá, Luis and Peidró, Adrián and Mayol, Walterio and Reinoso, Oscar},
  doi          = {10.1007/s00521-023-08515-y},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16487-16508},
  shortjournal = {Neural Comput. Appl.},
  title        = {Environment modeling and localization from datasets of omnidirectional scenes using machine learning techniques},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantized <span class="math display">ℋ<sub>∞</sub></span>
stabilization for delayed memristive neural networks. <em>NCA</em>,
<em>35</em>(22), 16473–16486. (<a
href="https://doi.org/10.1007/s00521-023-08510-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of $${\mathcal {H}}_{\infty }$$ stabilization for delayed memristive neural networks with dynamic quantization is considered. The aim is to design a quantized sampled-data controller guaranteeing that the closed-loop system is globally asymptotically stable with a prescribed $${\mathcal {H}}_{\infty }$$ disturbance attenuation level. By means of set-valued maps and the differential inclusion theory, the network under consideration is transformed into a dynamic model subject to time-dependent bounded uncertainty. Then, two different time-dependent two-sided loop functionals are constructed for the non-necessarily and necessarily differential time delay situations, respectively. Two sufficient conditions on the stability and $${\mathcal {H}}_{\infty }$$ performance are derived via using these constructed functionals and a few inequality techniques. On the foundation of these conditions, co-designs of the needed feedback gain and dynamic quantization parameter are presented. Finally, three examples are provided to verify the applicability of the quantized sampled-data controller design methods.},
  archive      = {J_NCA},
  author       = {Yan, Zhilian and Zuo, Dandan and Guo, Tong and Zhou, Jianping},
  doi          = {10.1007/s00521-023-08510-3},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16473-16486},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quantized $${\mathcal {H}}_\infty$$ stabilization for delayed memristive neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive neural time-varying full-state constraints
quantized consensus control for nonlinear multiagent networks systems
without feasibility conditions. <em>NCA</em>, <em>35</em>(22),
16457–16472. (<a
href="https://doi.org/10.1007/s00521-023-08509-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the adaptive neural time-varying full-state constraints quantized consensus control is investigated for a class of nonlinear multiagent network systems with switching topologies. In most existing state constraints control schemes, the state constraints are achieved based on error constraints, and the feasibility conditions are required, which is a difficult problem for the application of controllers. Thus, based on the adaptive neural control method, this paper designs the integral Lyapunov functions to remove the restriction of the feasibility conditions completely. Therefore, the boundaries of state constraints control can be designed directly without feasibility conditions. Moreover, the boundaries of state constraints are considered as time-varying since there exist various factors affecting the boundaries, which is more suitable for practical multiagent systems. In multiagent network control, data transmission is a crucial element for system performance. For this problem, this paper designs the time-varying state constraints input quantization signals, which can reduce chattering and achieve low communication rates in the digital signal transmission for the multiagent systems under switching topologies communication networks. Then, the proposed strategy is validated in the simulation section. All the closed-loop signals are bounded under the proposed strategy.},
  archive      = {J_NCA},
  author       = {Hao, Ruolan and Wang, Hongbin and Zheng, Wei},
  doi          = {10.1007/s00521-023-08509-w},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16457-16472},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive neural time-varying full-state constraints quantized consensus control for nonlinear multiagent networks systems without feasibility conditions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early diagnosis and clinical score prediction of parkinson’s
disease based on longitudinal neuroimaging data. <em>NCA</em>,
<em>35</em>(22), 16429–16455. (<a
href="https://doi.org/10.1007/s00521-023-08508-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson&#39;s disease (PD) is an irreversible neurodegenerative disease that has serious impacts on patients&#39; lives. To provide timely accurate treatment and delay the deterioration of the disease, the accurate early diagnosis and clinical score prediction of PD are extremely important. Differing from previous studies on PD, we propose a network combining feature selection method with feature learning to obtain the most discriminative feature representation for longitudinal early diagnosis and clinical score prediction. Specifically, we first preprocess the multi-modal neuroimaging data at multiple time points to extract original longitudinal multi-modal features. Then, the feature selection method is performed to preliminary reduce the feature dimensions. Finally, the stacked sparse nonnegative autoencoder (SSNAE) is employed to obtain more discriminative longitudinal multi-modal features to improve the accuracy of early diagnosis and clinical score prediction at multiple time points. To verify our proposed network, diverse and extensive experiments are performed on the Parkinson&#39;s Progression Markers Initiative dataset, which aims to identify biological markers of PD risk, onset and progression. The results demonstrate that our proposed method is more efficient and achieves promising performance on both longitudinal early diagnosis and clinical scores prediction compared to state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Lei, Haijun and Lei, Yukang and Chen, Zihao and Li, Shiqi and Huang, Zhongwei and Zhou, Feng and Tan, Ee-Leng and Xiao, Xiaohua and Lei, Yi and Hu, Huoyou and Huang, Yaohui and Liu, Chien-Hung and Lei, Baiying},
  doi          = {10.1007/s00521-023-08508-x},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16429-16455},
  shortjournal = {Neural Comput. Appl.},
  title        = {Early diagnosis and clinical score prediction of parkinson&#39;s disease based on longitudinal neuroimaging data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CSiamese: A novel semi-supervised anomaly detection
framework for gas turbines via reconstruction similarity. <em>NCA</em>,
<em>35</em>(22), 16403–16427. (<a
href="https://doi.org/10.1007/s00521-023-08507-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main problem in data-driven anomaly detection of gas turbines is that the monitoring data consists of only a very small number of abnormal samples with the overwhelming majority of normal samples. To address this problem, this paper develops a novel semi-supervised anomaly detection framework, namely CSiamese, and the parameters of the framework are optimized only using normal samples, with the ultimate purpose of improving the anomaly detection performance on imbalanced data sets. First, the convolutional auto-encoder is used to learn the reconstructed representation of the input sample. Second, the Siamese network is selected to learn to measure the similarity between the input and its reconstructed representation under noise conditions. Besides, a new loss function is developed by improving the contrastive loss, namely triangle loss, and can reduce the risk of collapsing solutions of the Siamese network when only using positive sample pairs. Third, maximum likelihood estimation is used to set the proper detection threshold to separate abnormal samples from normal samples. Finally, the effectiveness of the developed CSiamese has been evaluated using the real monitoring data of gas turbines and a public CIFAR-10 data set.},
  archive      = {J_NCA},
  author       = {Liu, Dan and Zhong, Shisheng and Lin, Lin and Zhao, Minghang and Fu, Xuyun and Liu, Xueyun},
  doi          = {10.1007/s00521-023-08507-y},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16403-16427},
  shortjournal = {Neural Comput. Appl.},
  title        = {CSiamese: A novel semi-supervised anomaly detection framework for gas turbines via reconstruction similarity},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis of regional climate variables by using neural
granger causality. <em>NCA</em>, <em>35</em>(22), 16381–16402. (<a
href="https://doi.org/10.1007/s00521-023-08506-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, how to discover causality rather than correlation among climate variables and how to use causality to help in time-series tasks have received great concern. However, the high dimensionality and nonlinearity of climate variables are the main issues for causal inference based on historical large-scale climate time series. Therefore, a method based on neural Granger causality inference is proposed to study the interactions of climate variables, with focus on the variables commonly used in the energy field, especially in photovoltaics. Firstly, for each climate variable, the time-varying causality and global causality are, respectively, obtained on each time window and on the whole series by neural Granger causality inference. Secondly, the global causality is used as a feature selection map of the input variables in the prediction task. Finally, compared with some existing feature selection methods, the experiments determine that the proposed method not only reveals the appropriate causality rather than the correlation among climate variables, but also efficiently reduces the input dimensionality and improves the performance and interpretability of the predicting model.},
  archive      = {J_NCA},
  author       = {Shan, Shuo and Wang, Yiye and Xie, Xiangying and Fan, Tao and Xiao, Yushun and Zhang, Kanjian and Wei, Haikun},
  doi          = {10.1007/s00521-023-08506-z},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16381-16402},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analysis of regional climate variables by using neural granger causality},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). An adaptive variance vector-based evolutionary algorithm
for large scale multi-objective optimization. <em>NCA</em>,
<em>35</em>(22), 16357–16379. (<a
href="https://doi.org/10.1007/s00521-023-08505-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large scale multi-objective optimization problems often involve hundreds or thousands of decision variables. Regular methods tend to divide decision variables into multiple groups by identifying the contributions to objectives. However, they may suffer from a large computational budget prior to the start of optimization, resulting in a less computational budget for the actual optimization of problems. Different from them, this paper proposes an adaptive variance vector strategy, which is able to identify convergence-related and diversity-related variables by the variance features of variables in the decision space. The adaptive variance vector not only consumes no additional computational budget, but also is proved to be empirically effective in categorizing decision variables. Based on the adaptive variance vector strategy, an adaptive variance vector-based evolutionary algorithm is designed for tackling large scale multi-objective optimization. Experimental results and empirical analyses on LSMOP and DTLZ test suites with up to 5000 decision variables demonstrate the effectiveness of the adaptive variance vector strategy in identifying the convergence-related and diversity-related variables, and the superiority of the proposed method over state-of-the-art methods in terms of the convergence and diversity.},
  archive      = {J_NCA},
  author       = {Zhang, Maoqing and Li, Wuzhao and Jin, Hao and Zhang, Liang and Mu, Yashuang and Wang, Lei},
  doi          = {10.1007/s00521-023-08505-0},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16357-16379},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive variance vector-based evolutionary algorithm for large scale multi-objective optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dictionary learning algorithm for denoising polynomial
phase signal based on neural networks. <em>NCA</em>, <em>35</em>(22),
16341–16355. (<a
href="https://doi.org/10.1007/s00521-023-08501-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the influence of additive white Gaussian noise, most dictionary learning algorithms whose training data come from the noisy signal cannot effectively remove noise associated with the polynomial phase signal (PPS) via sparse representation, such as K-SVD and RLS-DLA. In this paper, we present a novel dictionary learning algorithm based on neural networks to denoise PPS. In the proposed algorithm, we first use RLS-DLA to train the dictionary. Next, the neural network is used to refine atoms in the learned dictionary. To reduce the computational complexity of iterative calculations in the neural network, direct weight determination of the network is used to denoise atoms. In this way, the signal-to-noise ratio of the reconstructed signal obtained using the proposed algorithm is clearly higher than that of other algorithms, whereas the mean squared error is lower than that of other algorithms. Therefore, the proposed dictionary learning algorithm demonstrates noteworthy denoising performance.},
  archive      = {J_NCA},
  author       = {Ou, Guojian and Zou, Sai and Liu, Song and Tang, Jianguo},
  doi          = {10.1007/s00521-023-08501-4},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16341-16355},
  shortjournal = {Neural Comput. Appl.},
  title        = {A dictionary learning algorithm for denoising polynomial phase signal based on neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Employing machine learning techniques in monitoring
autocorrelated profiles. <em>NCA</em>, <em>35</em>(22), 16321–16340. (<a
href="https://doi.org/10.1007/s00521-023-08483-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In profile monitoring, it is usually assumed that the observations between or within each profile are independent of each other. However, this assumption is often violated in manufacturing practice, and it is of utmost importance to carefully consider autocorrelation effects in the underlying models for profile monitoring. For this reason, various statistical control charts have been proposed to monitor profiles when between- or within-data is correlated in Phase II, in which the main aim is to develop control charts with quicker detection ability. As a novel approach, this study aims to employ machine learning techniques as control charts instead of statistical approaches in monitoring profiles with between-profile autocorrelations. Specifically, new input features based on conventional statistical control chart statistics and normalized estimated parameters are defined that are capable of adequately accounting for the between-autocorrelation effect of profiles. In addition, six machine learning techniques are extended and compared by means of Monte Carlo simulations. The simulation results indicate that machine learning techniques can obtain more accurate results compared with statistical control charts. Moreover, adaptive neuro-fuzzy inference systems outperform other machine learning techniques and the conventional statistical control charts.},
  archive      = {J_NCA},
  author       = {Yeganeh, Ali and Johannssen, Arne and Chukhrova, Nataliya and Abbasi, Saddam Akber and Pourpanah, Farhad},
  doi          = {10.1007/s00521-023-08483-3},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16321-16340},
  shortjournal = {Neural Comput. Appl.},
  title        = {Employing machine learning techniques in monitoring autocorrelated profiles},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient multi-task learning with adaptive temporal
structure for progression prediction. <em>NCA</em>, <em>35</em>(22),
16305–16320. (<a
href="https://doi.org/10.1007/s00521-023-08461-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel efficient multi-task learning formulation for the class of progression problems in which its state will continuously change over time. To use the shared knowledge information between multiple tasks to improve performance, existing multi-task learning methods mainly focus on feature selection or optimizing the task relation structure. The feature selection methods usually fail to explore the complex relationship between tasks and thus have limited performance. The methods centring on optimizing the relation structure of tasks are not capable of selecting meaningful features and have a bi-convex objective function which results in high computation complexity of the associated optimization algorithm. Unlike these multi-task learning methods, motivated by a simple and direct idea that the state of a system at the current time point should be related to all previous time points, we first propose a novel relation structure, termed adaptive global temporal relation structure (AGTS). Then we integrate the widely used sparse group Lasso, fused Lasso with AGTS to propose a novel convex multi-task learning formulation that not only performs feature selection but also adaptively captures the global temporal task relatedness. Since the existence of three non-smooth penalties, the objective function is challenging to solve. We first design an optimization algorithm based on the alternating direction method of multipliers (ADMM). Considering that the worst-case convergence rate of ADMM is only sub-linear, we then devise an efficient algorithm based on the accelerated gradient method which has the optimal convergence rate among first-order methods. We show the proximal operator of several non-smooth penalties can be solved efficiently due to the special structure of our formulation. Experimental results on four real-world datasets demonstrate that our approach not only outperforms multiple baseline MTL methods in terms of effectiveness but also has high efficiency.},
  archive      = {J_NCA},
  author       = {Zhou, Menghui and Zhang, Yu and Liu, Tong and Yang, Yun and Yang, Po},
  doi          = {10.1007/s00521-023-08461-9},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16305-16320},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient multi-task learning with adaptive temporal structure for progression prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Imbalanced multi-label data classification as a bi-level
optimization problem: Application to miRNA-related diseases diagnosis.
<em>NCA</em>, <em>35</em>(22), 16285–16303. (<a
href="https://doi.org/10.1007/s00521-023-08458-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label classification, each instance could be assigned multiple labels at the same time. In such a situation, the relationships between labels and the class imbalance are two serious issues that should be addressed. Despite the important number of existing multi-label classification methods, the widespread class imbalance among labels has not been adequately addressed. Two main issues should be solved to come up with an effective classifier for imbalanced multi-label data. On the one hand, the imbalance could occur between labels and/or within a label. The “Between-labels imbalance” occurs where the imbalance is between labels however the “Within-label imbalance” occurs where the imbalance is in the label itself and it could occur across multiple labels. On the other hand, the labels’ processing order heavily influences the quality of a multi-label classifier. To deal with these challenges, we propose in this paper a bi-level evolutionary approach for the optimized induction of multivariate decision trees, where the upper-level role is to design the classifiers while the lower-level approximates the optimal labels’ ordering for each classifier. Our proposed method, named BIMLC-GA (Bi-level Imbalanced Multi-Label Classification Genetic Algorithm), is compared to several state-of-the-art methods across a variety of imbalanced multi-label data sets from several application fields and then applied on the miRNA-related diseases case study. The statistical analysis of the obtained results shows the merits of our proposal.},
  archive      = {J_NCA},
  author       = {Chabbouh, Marwa and Bechikh, Slim and Mezura-Montes, Efrén and Said, Lamjed Ben},
  doi          = {10.1007/s00521-023-08458-4},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16285-16303},
  shortjournal = {Neural Comput. Appl.},
  title        = {Imbalanced multi-label data classification as a bi-level optimization problem: Application to miRNA-related diseases diagnosis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Polynomial and ANN models applied to the formation of gums
in brazilian ethanol–gasoline blends—impact of gasoline composition,
ethanol concentration, storage temperature, and aging duration.
<em>NCA</em>, <em>35</em>(22), 16267–16284. (<a
href="https://doi.org/10.1007/s00521-023-08396-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to define the influence of different parameters (such as ethanol concentration, type (regular or homologation fuel), and formulation (olefin and aromatic contents) of gasoline, temperature, and aging duration) in gum formation in Brazilian ethanol–gasoline blends. As a result, a database with more than 500 cases was built gathering experimental measures of unwashed and washed gum contents from the literature and original experimental data. Two approaches considered to define the mathematical models capable of predicting gum formation are compared: a linear equation with rectangular interaction terms and artificial neural network (ANN) models. Different ANN topologies were investigated and the most robust models were compared to polynomial equations. Then, response surfaces were plotted to verify the consistency of the model in the entire experimental domain. The ANN models performed better. Indeed, the coefficient of determination reached values as high as 0.953 and 0.984, for the testing data of washed and unwashed gum content, respectively, and lower differences with experimental data were observed, up to 0.5 and 0.2\%, respectively. Additionally, the ANN models were more robust than the specific quadratic model available in the literature. In terms of the impact of the ethanol, it is possible to confirm a catalytic effect after aging at medium or high temperatures for washed gum formation at low concentrations of ethanol in gasoline. Without aging or after storage at low temperatures, ethanol has a simple dilution effect. Such conclusions are in agreement with previous literature and explain why some authors observed either catalytic or dilution effects of ethanol.},
  archive      = {J_NCA},
  author       = {S. P. Carvalho, José Eduardo and F. Santos, Brunno and F. A. Martins, Ana Rosa and L. Braga, Sergio and N. C. Pradelle, Renata and Turkovics, Franck and Perrier, Béatrice and Maire, François and Pradelle, Florian},
  doi          = {10.1007/s00521-023-08396-1},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16267-16284},
  shortjournal = {Neural Comput. Appl.},
  title        = {Polynomial and ANN models applied to the formation of gums in brazilian ethanol–gasoline blends—impact of gasoline composition, ethanol concentration, storage temperature, and aging duration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective deep reinforcement learning for crowd-aware
robot navigation with dynamic human preference. <em>NCA</em>,
<em>35</em>(22), 16247–16265. (<a
href="https://doi.org/10.1007/s00521-023-08385-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing development of autonomous systems is driving the application of mobile robots in crowded environments. These scenarios often require robots to satisfy multiple conflicting objectives with different relative preferences, such as work efficiency, safety, and smoothness, which inherently cause robots’ poor exploration in seeking policies optimizing several performance criteria. In this paper, we propose a multi-objective deep reinforcement learning framework for crowd-aware robot navigation problems to learn policies over multiple competing objectives whose relative importance preference is dynamic to the robot. First, a two-stream structure is introduced to separately extract the spatial and temporal features of pedestrian motion characteristics. Second, to learn navigation policies for each possible preference, a multi-objective deep reinforcement learning method is proposed to maximize a weighted-sum scalarization of different objective functions. We consider path planning and path tracking tasks, which focus on conflicting objectives of collision avoidance, target reaching, and path following. Experimental results demonstrate that our method can effectively navigate through crowds in simulated environments while satisfying different task requirements.},
  archive      = {J_NCA},
  author       = {Cheng, Guangran and Wang, Yuanda and Dong, Lu and Cai, Wenzhe and Sun, Changyin},
  doi          = {10.1007/s00521-023-08385-4},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16247-16265},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective deep reinforcement learning for crowd-aware robot navigation with dynamic human preference},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Normal vibration distribution search-based differential
evolution algorithm for multimodal biomedical image registration.
<em>NCA</em>, <em>35</em>(22), 16223–16245. (<a
href="https://doi.org/10.1007/s00521-023-08649-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In linear registration, a floating image is spatially aligned with a reference image after performing a series of linear metric transformations. Additionally, linear registration is mainly considered a preprocessing version of nonrigid registration. To better accomplish the task of finding the optimal transformation in pairwise intensity-based medical image registration, in this work, we present an optimization algorithm called the normal vibration distribution search-based differential evolution algorithm (NVSA), which is modified from the Bernstein search-based differential evolution (BSD) algorithm. We redesign the search pattern of the BSD algorithm and import several control parameters as part of the fine-tuning process to reduce the difficulty of the algorithm. In this study, 23 classic optimization functions and 16 real-world patients (resulting in 41 multimodal registration scenarios) are used in experiments performed to statistically investigate the problem solving ability of the NVSA. Nine metaheuristic algorithms are used in the conducted experiments. When compared to the commonly utilized registration methods, such as ANTS, Elastix, and FSL, our method achieves better registration performance on the RIRE dataset. Moreover, we prove that our method can perform well with or without its initial spatial transformation in terms of different evaluation indicators, demonstrating its versatility and robustness for various clinical needs and applications. This study establishes the idea that metaheuristic-based methods can better accomplish linear registration tasks than the frequently used approaches; the proposed method demonstrates promise that it can solve real-world clinical and service problems encountered during nonrigid registration as a preprocessing approach.The source code of the NVSA is publicly available at https://github.com/PengGui-N/NVSA .},
  archive      = {J_NCA},
  author       = {Gui, Peng and He, Fazhi and Ling, Bingo Wing-Kuen and Zhang, Dengyi and Ge, Zongyuan},
  doi          = {10.1007/s00521-023-08649-z},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16223-16245},
  shortjournal = {Neural Comput. Appl.},
  title        = {Normal vibration distribution search-based differential evolution algorithm for multimodal biomedical image registration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Breaking the traditional: A survey of algorithmic mechanism
design applied to economic and complex environments. <em>NCA</em>,
<em>35</em>(22), 16193–16222. (<a
href="https://doi.org/10.1007/s00521-023-08647-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mechanism design theory can be applied not only in the economy but also in many fields, such as politics and military affairs, which has important practical and strategic significance for countries in the period of system innovation and transformation. As Nobel Laureate Paul said, the complexity of the real economy makes it difficult for “Unorganized Markets” to ensure supply-demand balance and the efficient allocation of resources. When traditional economic theory cannot explain and calculate the complex scenes of reality, we require a high-performance computing solution based on traditional theory to evaluate the mechanisms, meanwhile, get better social welfare. The mechanism design theory is undoubtedly the best option. Different from other existing works, which are based on the theoretical exploration of optimal solutions or single perspective analysis of scenarios, this paper focuses on the more real and complex markets. It explores to discover the common difficulties and feasible solutions for the applications. Firstly, we review the history of traditional mechanism design and algorithm mechanism design. Subsequently, we present the main challenges in designing the actual data-driven market mechanisms, including the inherent challenges in the mechanism design theory, the challenges brought by new markets and the common challenges faced by both. In addition, we also comb and discuss theoretical support and computer-aided methods in detail. This paper guides cross-disciplinary researchers who wish to explore the resource allocation problem in real markets for the first time and offers a different perspective for researchers struggling to solve complex social problems. Finally, we discuss and propose new ideas and look to the future.},
  archive      = {J_NCA},
  author       = {Chen, Qian and Wang, Xuan and Jiang, Zoe Lin and Wu, Yulin and Li, Huale and Cui, Lei and Sun, Xiaozhen},
  doi          = {10.1007/s00521-023-08647-1},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16193-16222},
  shortjournal = {Neural Comput. Appl.},
  title        = {Breaking the traditional: A survey of algorithmic mechanism design applied to economic and complex environments},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VIRFIM: An AI and internet of medical things-driven
framework for healthcare using smart sensors. <em>NCA</em>,
<em>35</em>(22), 16175–16192. (<a
href="https://doi.org/10.1007/s00521-021-06434-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After affecting the world in unexpected ways, the virus has started mutating which is evident with the insurgence of its new variants. The governments, hospitals, schools, industries, and humans, in general, are looking for a potential solution in the vaccine which will eventually be available, but its timeline for eradicating the virus is yet unknown. Several researchers have encouraged and recommended the use of good practices such as physical healthcare monitoring, immunity boosting, personal hygiene, mental healthcare, and contact tracing for slowing down the spread of the virus. In this article, we propose the use of smart sensors integrated with the Internet of Medical Things to cover the spectrum of good practices in an automated manner. We present hypothetical frameworks for each of the good practice modules and propose the VIrus Resistance Framework using the Internet of Medical Things (VIRFIM) to tie all the individual modules in a unified architecture. Furthermore, we validate the realization of VIRFIM framework with two case studies related to physical activity monitoring and stress detection services. We envision that VIRFIM would be influential in assisting people with the new normal for current and future pandemics as well as instrumental in halting the economic losses, respectively. We also provide potential challenges and their probable solutions in compliance with the proposed VIRFIM.},
  archive      = {J_NCA},
  author       = {Khowaja, Sunder Ali and Khuwaja, Parus and Dev, Kapal and D’Aniello, Giuseppe},
  doi          = {10.1007/s00521-021-06434-4},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16175-16192},
  shortjournal = {Neural Comput. Appl.},
  title        = {VIRFIM: An AI and internet of medical things-driven framework for healthcare using smart sensors},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pima indians diabetes mellitus classification based on
machine learning (ML) algorithms. <em>NCA</em>, <em>35</em>(22),
16157–16173. (<a
href="https://doi.org/10.1007/s00521-022-07049-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an e-diagnosis system based on machine learning (ML) algorithms to be implemented on the Internet of Medical Things (IoMT) environment, particularly for diagnosing diabetes mellitus (type 2 diabetes). However, the ML applications tend to be mistrusted because of their inability to show the internal decision-making process, resulting in slow uptake by end-users within certain healthcare sectors. This research delineates the use of three interpretable supervised ML models: Naïve Bayes classifier, random forest classifier, and J48 decision tree models to be trained and tested using the Pima Indians diabetes dataset in R programming language. The performance of each algorithm is analyzed to determine the one with the best accuracy, precision, sensitivity, and specificity. An assessment of the decision process is also made to improve the model. It can be concluded that a Naïve Bayes model works well with a more fine-tuned selection of features for binary classification, while random forest works better with more features.},
  archive      = {J_NCA},
  author       = {Chang, Victor and Bailey, Jozeene and Xu, Qianwen Ariel and Sun, Zhili},
  doi          = {10.1007/s00521-022-07049-z},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16157-16173},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pima indians diabetes mellitus classification based on machine learning (ML) algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multilevel depth-wise context attention network with atrous
mechanism for segmentation of COVID19 affected regions. <em>NCA</em>,
<em>35</em>(22), 16143–16155. (<a
href="https://doi.org/10.1007/s00521-021-06636-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Severe acute respiratory syndrome coronavirus (SARS-CoV-2) also named COVID-19, aggressively spread all over the world in just a few months. Since then, it has multiple variants that are far more contagious than its parent. Rapid and accurate diagnosis of COVID-19 and its variants are crucial for its treatment, analysis of lungs damage and quarantine management. Deep learning-based solution for efficient and accurate diagnosis to COVID-19 and its variants using Chest X-rays, and computed tomography images could help to counter its outbreak. This work presents a novel depth-wise residual network with an atrous mechanism for accurate segmentation and lesion location of COVID-19 affected areas using volumetric CT images. The proposed framework consists of 3D depth-wise and 3D residual squeeze and excitation block in cascaded and parallel to capture uniformly multi-scale context (low-level detailed, mid-level comprehensive and high-level rich semantic features). The squeeze and excitation block adaptively recalibrates channel-wise feature responses by explicitly modeling inter-dependencies between various channels. We further have introduced an atrous mechanism with a different atrous rate as the bottom layer. Extensive experiments on benchmark CT datasets showed considerable gain (5\%) for accurate segmentation and lesion location of COVID-19 affected areas.},
  archive      = {J_NCA},
  author       = {Qayyum, Abdul and Mazhar, Mona and Razzak, Imran and Bouadjenek, Mohamed Reda},
  doi          = {10.1007/s00521-021-06636-w},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16143-16155},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multilevel depth-wise context attention network with atrous mechanism for segmentation of COVID19 affected regions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint optic disc and cup segmentation based on multi-scale
feature analysis and attention pyramid architecture for glaucoma
screening. <em>NCA</em>, <em>35</em>(22), 16129–16142. (<a
href="https://doi.org/10.1007/s00521-021-06554-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation of optic disc (OD) and optic cup (OC) is an essential task for analysing colour fundus images. In clinical practice, accurate OD and OC segmentation assist ophthalmologists in diagnosing glaucoma. In this paper, we propose a unified convolutional neural network, named ResFPN-Net, which learns the boundary feature and the inner relation between OD and OC for automatic segmentation. The proposed ResFPN-Net is mainly composed of multi-scale feature extractor, multi-scale segmentation transition and attention pyramid architecture. The multi-scale feature extractor achieved the feature encoding of fundus images and captured the boundary representations. The multi-scale segmentation transition is employed to retain the features of different scales. Moreover, an attention pyramid architecture is proposed to learn rich representations and the mutual connection in the OD and OC. To verify the effectiveness of the proposed method, we conducted extensive experiments on two public datasets. On the Drishti-GS database, we achieved a Dice coefficient of 97.59\%, 89.87\%, the accuracy of 99.21\%, 98.77\%, and the Averaged Hausdorff distance of 0.099, 0.882 on the OD and OC segmentation, respectively. We achieved a Dice coefficient of 96.41\%, 83.91\%, the accuracy of 99.30\%, 99.24\%, and the Averaged Hausdorff distance of 0.166, 1.210 on the RIM-ONE database for OD and OC segmentation, respectively. Comprehensive results show that the proposed method outperforms other competitive OD and OC segmentation methods and appears more adaptable in cross-dataset scenarios. The introduced multi-scale loss function achieved significantly lower training loss and higher accuracy compared with other loss functions. Furthermore, the proposed method is further validated in OC to OD ratio calculation task and achieved the best MAE of 0.0499 and 0.0630 on the Drishti-GS and RIM-ONE datasets, respectively. Finally, we evaluated the effectiveness of the glaucoma screening on Drishti-GS and RIM-ONE datasets, achieving the AUC of 0.8947 and 0.7964. These results proved that the proposed ResFPN-Net is effective in analysing fundus images for glaucoma screening and can be applied in other relative biomedical image segmentation applications.},
  archive      = {J_NCA},
  author       = {Sun, Guangmin and Zhang, Zhongxiang and Zhang, Junjie and Zhu, Meilong and Zhu, Xiao-rong and Yang, Jin-Kui and Li, Yu},
  doi          = {10.1007/s00521-021-06554-x},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16129-16142},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint optic disc and cup segmentation based on multi-scale feature analysis and attention pyramid architecture for glaucoma screening},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inverted bell-curve-based ensemble of deep learning models
for detection of COVID-19 from chest x-rays. <em>NCA</em>,
<em>35</em>(22), 16113–16127. (<a
href="https://doi.org/10.1007/s00521-021-06737-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel Coronavirus 2019 disease or COVID-19 is a viral disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The use of chest X-rays (CXRs) has become an important practice to assist in the diagnosis of COVID-19 as they can be used to detect the abnormalities developed in the infected patients’ lungs. With the fast spread of the disease, many researchers across the world are striving to use several deep learning-based systems to identify the COVID-19 from such CXR images. To this end, we propose an inverted bell-curve-based ensemble of deep learning models for the detection of COVID-19 from CXR images. We first use a selection of models pretrained on ImageNet dataset and use the concept of transfer learning to retrain them with CXR datasets. Then the trained models are combined with the proposed inverted bell curve weighted ensemble method, where the output of each classifier is assigned a weight, and the final prediction is done by performing a weighted average of those outputs. We evaluate the proposed method on two publicly available datasets: the COVID-19 Radiography Database and the IEEE COVID Chest X-ray Dataset. The accuracy, F1 score and the AUC ROC achieved by the proposed method are 99.66\%, 99.75\% and 99.99\%, respectively, in the first dataset, and, 99.84\%, 99.81\% and 99.99\%, respectively, in the other dataset. Experimental results ensure that the use of transfer learning-based models and their combination using the proposed ensemble method result in improved predictions of COVID-19 in CXRs.},
  archive      = {J_NCA},
  author       = {Paul, Ashis and Basu, Arpan and Mahmud, Mufti and Kaiser, M. Shamim and Sarkar, Ram},
  doi          = {10.1007/s00521-021-06737-6},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16113-16127},
  shortjournal = {Neural Comput. Appl.},
  title        = {Inverted bell-curve-based ensemble of deep learning models for detection of COVID-19 from chest X-rays},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving sEMG-based motion intention recognition for
upper-limb amputees using transfer learning. <em>NCA</em>,
<em>35</em>(22), 16101–16111. (<a
href="https://doi.org/10.1007/s00521-021-06292-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand gesture recognition from multi-channel surface electromyography (sEMG) have been widely studied in the past decade. By analyzing muscle activities measured from forearm muscles, multiple hand gestures can be recognized. This technology can benefit upper-limb amputees in motion intention recognition, especially for those with trans-radial amputation, in terms of prosthesis control, rehabilitation and further human–computer interaction. However, due to the scarcity of signals collected from amputees, many related studies used signals from intact subjects as a proxy and result in overoptimistic classification performance. Comparing to sEMG signals from intact subjects, signals from upper-limb amputees suffer from signal quality deterioration which relates to the level of amputation and maybe other amputation information. Therefore, this study aims at improving the motion intention recognition performance in trans-radial amputated subjects. To tackle the challenges of data scarcity and signal quality deterioration, we propose a CNN-based transfer learning solution leveraging the knowledge learned from sEMG signals of intact subjects. The proposed method was developed from and tested with NinaPro database where 20 intact subjects and 11 amputees. We obtained 67.5\% accuracy in the mDWT feature after transfer. And the results improved by 9.4\% after transfer compared to no transfer in the RMS feature. In the end of the study, we further discussed the correlation between classification accuracy and amputation information including the percentage of remaining forearm and the number of years since amputation.},
  archive      = {J_NCA},
  author       = {Fan, Jinghua and Jiang, Mingzhe and Lin, Chuang and Li, Gloria and Fiaidhi, Jinan and Ma, Chenfei and Wu, Wanqing},
  doi          = {10.1007/s00521-021-06292-0},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16101-16111},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving sEMG-based motion intention recognition for upper-limb amputees using transfer learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Establishment of a mindmap for medical e-diagnosis as a
service for graph-based learning and analytics. <em>NCA</em>,
<em>35</em>(22), 16089–16100. (<a
href="https://doi.org/10.1007/s00521-021-06200-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As medical services increasingly trying to harness advances in connected medical devices and the use of artificial intelligence, a new modeling strategy is essentially required to enable developers of the emerging medical applications to organize, integrate, and retain information in this new era of service-oriented healthcare. Such strategy needs to adhere to the principle of knowledge coupling that was advocated by Lawrence Weed, the father of modern problem-oriented medical records, in early 1970s where he defined the way medical information should be described for higher decision making. There has never been a more compelling time to use knowledge coupling related to both medical knowledge and the services build around them. The new digital technologies such as microservices, graph-based databases, Internet of Healthcare Things, and Cloud Computing as well as the non-digital disruptive events such as the pandemic have accelerated the adoption of new notions of service integration and knowledge coupling to provide the long waited solution for interoperability in healthcare as well as higher level of knowledge integration and analytics. The cornerstone of every new change is pointing toward the use of microservices and knowledge graph APIs to be able to thrive and lead in the uncertainty and healthcare change. This research paper uses the notion of mindmap to push conversation and guide scholars in developing effective microservice-based care systems that utilize knowledge graphs and the new care standards including the HL7 FHIR. Central to our mindmap is the GraphQL graph-based technology and the medical diagnosis as a service. This mindmap is the starting research point of our MITACS 2021 and NSERC DDG 2021 projects.},
  archive      = {J_NCA},
  author       = {Mohammed, Sabah and Fiaidhi, Jinan},
  doi          = {10.1007/s00521-021-06200-6},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16089-16100},
  shortjournal = {Neural Comput. Appl.},
  title        = {Establishment of a mindmap for medical e-diagnosis as a service for graph-based learning and analytics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based multidimensional feature fusion for
classification of ECG arrhythmia. <em>NCA</em>, <em>35</em>(22),
16073–16087. (<a
href="https://doi.org/10.1007/s00521-021-06487-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction plays an important role in arrhythmia classification, and successful arrhythmia classification generally depends on ECG feature extraction. This paper proposed a feature extraction method combining traditional approaches and 1D-CNN aiming to find the optimal feature set to improve the accuracy of arrhythmia classification. The proposed method is verified by using the MIT-BIH arrhythmia benchmark database. It is found that the features extracted by 1D-CNN and discrete wavelet transform form the optimal feature set with the average classification accuracy up to 98.35\%, which is better than the latest methods.},
  archive      = {J_NCA},
  author       = {Cui, Jianfeng and Wang, Lixin and He, Xiangmin and De Albuquerque, Victor Hugo C. and AlQahtani, Salman A. and Hassan, Mohammad Mehedi},
  doi          = {10.1007/s00521-021-06487-5},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16073-16087},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based multidimensional feature fusion for classification of ECG arrhythmia},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of covid-19 chest x-ray images by means of an
interpretable evolutionary rule-based approach. <em>NCA</em>,
<em>35</em>(22), 16061–16071. (<a
href="https://doi.org/10.1007/s00521-021-06806-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical practice, all decisions, as for example the diagnosis based on the classification of images, must be made reliably and effectively. The possibility of having automatic tools helping doctors in performing these important decisions is highly welcome. Artificial Intelligence techniques, and in particular Deep Learning methods, have proven very effective on these tasks, with excellent performance in terms of classification accuracy. The problem with such methods is that they represent black boxes, so they do not provide users with an explanation of the reasons for their decisions. Confidence from medical experts in clinical decisions can increase if they receive from Artificial Intelligence tools interpretable output under the form of, e.g., explanations in natural language or visualized information. This way, the system outcome can be critically assessed by them, and they can evaluate the trustworthiness of the results. In this paper, we propose a new general-purpose method that relies on interpretability ideas. The approach is based on two successive steps, the former being a filtering scheme typically used in Content-Based Image Retrieval, whereas the latter is an evolutionary algorithm able to classify and, at the same time, automatically extract explicit knowledge under the form of a set of IF-THEN rules. This approach is tested on a set of chest X-ray images aiming at assessing the presence of COVID-19.},
  archive      = {J_NCA},
  author       = {De Falco, Ivanoe and De Pietro, Giuseppe and Sannino, Giovanna},
  doi          = {10.1007/s00521-021-06806-w},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16061-16071},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of covid-19 chest X-ray images by means of an interpretable evolutionary rule-based approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CariesNet: A deep learning approach for segmentation of
multi-stage caries lesion from oral panoramic x-ray image. <em>NCA</em>,
<em>35</em>(22), 16051–16059. (<a
href="https://doi.org/10.1007/s00521-021-06684-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dental caries has been a common health issue throughout the world, which can even lead to dental pulp and root apical inflammation eventually. Timely and effective treatment of dental caries is vital for patients to reduce pain. Traditional caries disease diagnosis methods like naked-eye detection and panoramic radiograph examinations rely on experienced doctors, which may cause misdiagnosis and high time-consuming. To this end, we propose a novel deep learning architecture called CariesNet to delineate different caries degrees from panoramic radiographs. We firstly collect a high-quality panoramic radiograph dataset with 3127 well-delineated caries lesions, including shallow caries, moderate caries, and deep caries. Then we construct CariesNet as a U-shape network with the additional full-scale axial attention module to segment these three caries types from the oral panoramic images. Moreover, we test the segmentation performance between CariesNet and other baseline methods. Experiments show that our method can achieve a mean 93.64\% Dice coefficient and 93.61\% accuracy in the segmentation of three different levels of caries.},
  archive      = {J_NCA},
  author       = {Zhu, Haihua and Cao, Zheng and Lian, Luya and Ye, Guanchen and Gao, Honghao and Wu, Jian},
  doi          = {10.1007/s00521-021-06684-2},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16051-16059},
  shortjournal = {Neural Comput. Appl.},
  title        = {CariesNet: A deep learning approach for segmentation of multi-stage caries lesion from oral panoramic X-ray image},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence with big data analytics-based brain
intracranial hemorrhage e-diagnosis using CT images. <em>NCA</em>,
<em>35</em>(22), 16037–16049. (<a
href="https://doi.org/10.1007/s00521-021-06240-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the fast development of medical imaging technologies, medical image analysis has entered the period of big data for proper disease diagnosis. At the same time, intracerebral hemorrhage (ICH) becomes a serious disease which affects the injury of blood vessels in the brain regions. This paper presents an artificial intelligence and big data analytics-based ICH e-diagnosis (AIBDA-ICH) model using CT images. The presented model utilizes IoMT devices for data acquisition process. The presented AIBDA-ICH model involves graph cut-based segmentation model for identifying the affected regions in the CT images. To manage big data, Hadoop Ecosystem and its elements are mainly used. In addition, capsule network (CapsNet) model is applied as a feature extractor to derive a useful set of feature vectors. Finally, the presented AIBDA-ICH model makes use of the fuzzy deep neural network (FDNN) model to carry out classification process. For validating the superior performance of the AIBDA-ICH method, an extensive set of simulations were performed and the outcomes are examined under diverse aspects. The experimental values pointed out the improved e-diagnostic performance of the AIBDA-ICH model over the other compared methods with the precision and accuracy of 94.96\% and 98.59\%, respectively.},
  archive      = {J_NCA},
  author       = {Mansour, Romany F. and Escorcia-Gutierrez, José and Gamarra, Margarita and Díaz, Vicente García and Gupta, Deepak and Kumar, Sachin},
  doi          = {10.1007/s00521-021-06240-y},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16037-16049},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial intelligence with big data analytics-based brain intracranial hemorrhage e-diagnosis using CT images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-driven rehabilitation and assistive robotic system with
intelligent PID controller based on RBF neural networks. <em>NCA</em>,
<em>35</em>(22), 16021–16035. (<a
href="https://doi.org/10.1007/s00521-021-06785-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a cooperative bilateral upper-limb rehabilitation robotic system based on mirror therapy (MT) and virtual stimulation was developed to assist hemiplegia in rehabilitation training. The hemiplegia’s affected limb can be placed on one of the robotic arms with a servomotor, and the healthy limb is placed on another side without servomotor. With the assistance of the robotic arm, the affected limb can track the healthy limb to perform mirror motion to complete the rehabilitation training. The robotic arm device can be adjusted personally to assist the patient&#39;s elbow joint flexion and wrist joint rotation. In order to enhance the willingness of patients to actively recover. A game-based rehabilitation training was developed to realize human–computer interaction and to provide visual stimulation. The adaptive proportional–integral–derivative (PID) controller based on radial basis function (RBF) neural network has been adopted to improve the tracking performance of the affected side of robotic arm. The RBF neural network updates its parameters through the error signal between output of network and output of the system. The parameters of PID are updated by Jacobian matrix and the movement error between the healthy side and the affected side. Its abilities of RBF-PID controller about response speed, anti-interference and tracks are better than conventional PID controller’s through experimental validations. The system response was analyzed and graphed for different loading conditions. These error values of the angle of corresponding joint on both sides can be interpreted as very low. The system was proved to complete rehabilitation training and reflect the patient’s awareness of active rehabilitation.},
  archive      = {J_NCA},
  author       = {Xiao, Wei and Chen, Kai and Fan, Jiaming and Hou, Yifan and Kong, Weifei and Dan, Guo},
  doi          = {10.1007/s00521-021-06785-y},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16021-16035},
  shortjournal = {Neural Comput. Appl.},
  title        = {AI-driven rehabilitation and assistive robotic system with intelligent PID controller based on RBF neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-based medical e-diagnosis for fast and automatic
ventricular volume measurement in patients with normal pressure
hydrocephalus. <em>NCA</em>, <em>35</em>(22), 16011–16020. (<a
href="https://doi.org/10.1007/s00521-022-07048-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on CT and MRI images acquired from normal pressure hydrocephalus (NPH) patients, using machine learning methods, we aim to establish a multimodal and high-performance automatic ventricle segmentation method to achieve an efficient and accurate automatic measurement of the ventricular volume. First, we extract the brain CT and MRI images of 143 definite NPH patients. Second, we manually label the ventricular volume (VV) and intracranial volume (ICV). Then, we use the machine learning method to extract features and establish automatic ventricle segmentation model. Finally, we verify the reliability of the model and achieved automatic measurement of VV and ICV. In CT images, the Dice similarity coefficient (DSC), intraclass correlation coefficient (ICC), Pearson correlation, and Bland–Altman analysis of the automatic and manual segmentation result of the VV were 0.95, 0.99, 0.99, and 4.2 ± 2.6, respectively. The results of ICV were 0.96, 0.99, 0.99, and 6.0 ± 3.8, respectively. The whole process takes 3.4 ± 0.3 s. In MRI images, the DSC, ICC, Pearson correlation, and Bland–Altman analysis of the automatic and manual segmentation result of the VV were 0.94, 0.99, 0.99, and 2.0 ± 0.6, respectively. The results of ICV were 0.93, 0.99, 0.99, and 7.9 ± 3.8, respectively. The whole process took 1.9 ± 0.1 s. We have established a multimodal and high-performance automatic ventricle segmentation method to achieve efficient and accurate automatic measurement of the ventricular volume of NPH patients. This can help clinicians quickly and accurately understand the situation of NPH patient&#39;s ventricles.},
  archive      = {J_NCA},
  author       = {Zhou, Xi and Ye, Qinghao and Yang, Xiaolin and Chen, Jiakun and Ma, Haiqin and Xia, Jun and Del Ser, Javier and Yang, Guang},
  doi          = {10.1007/s00521-022-07048-0},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {16011-16020},
  shortjournal = {Neural Comput. Appl.},
  title        = {AI-based medical e-diagnosis for fast and automatic ventricular volume measurement in patients with normal pressure hydrocephalus},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel sample and feature dependent ensemble approach for
parkinson’s disease detection. <em>NCA</em>, <em>35</em>(22),
15997–16010. (<a
href="https://doi.org/10.1007/s00521-022-07046-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is a neurological disease that has been reported to have affected most people worldwide. Recent research pointed out that about 90\% of PD patients possess voice disorders. Motivated by this fact, many researchers proposed methods based on multiple types of speech data for PD prediction. However, these methods either face the problem of low rate of accuracy or lack generalization. To develop an approach that will be free of these issues, in this paper we propose a novel ensemble approach. These paper contributions are two folds. First, investigating feature selection integration with deep neural network (DNN) and validating its effectiveness by comparing its performance with conventional DNN and other similar integrated systems. Second, development of a novel ensemble model namely EOFSC (Ensemble model with Optimal Features and Sample Dependant Base Classifiers) that exploits the findings of recently published studies. Recent research pointed out that for different types of voice data, different optimal models are obtained which are sensitive to different types of samples and subsets of features. In this paper, we further consolidate the findings by utilizing the proposed integrated system and propose the development of EOFSC. For multiple types of vowel phonations, multiple base classifiers are obtained which are sensitive to different subsets of features. These features and sample-dependent base classifiers are integrated, and the proposed EOFSC model is constructed. To evaluate the final prediction of the EOFSC model, the majority voting methodology is adopted. Experimental results point out that feature selection integration with neural networks improves the performance of conventional neural networks. Additionally, feature selection integration with DNN outperforms feature selection integration with conventional machine learning models. Finally, the newly developed ensemble model is observed to improve PD detection accuracy by 6.5\%.},
  archive      = {J_NCA},
  author       = {Ali, Liaqat and Chakraborty, Chinmay and He, Zhiquan and Cao, Wenming and Imrana, Yakubu and Rodrigues, Joel J. P. C.},
  doi          = {10.1007/s00521-022-07046-2},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {15997-16010},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel sample and feature dependent ensemble approach for parkinson’s disease detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning based system for handwashing procedure
evaluation. <em>NCA</em>, <em>35</em>(22), 15981–15996. (<a
href="https://doi.org/10.1007/s00521-022-07194-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand washing preparation can be considered as one of the main strategies for reducing the risk of surgical site contamination and thus the infections risks. Within this context, in this paper we propose an embedded system able to automatically analyze, in real-time, the sequence of images acquired by a depth camera to evaluate the quality of the handwashing procedure. In particular, the designed system runs on an NVIDIA Jetson Nano $$^{{\mathrm{TM}}}$$ computing platform. We adopt a convolutional neural network, followed by a majority voting scheme, to classify the movement of the worker according to one of the ten gestures defined by the World Health Organization. To test the proposed system, we collect a dataset built by 74 different video sequences. The results achieved on this dataset confirm the effectiveness of the proposed approach.},
  archive      = {J_NCA},
  author       = {Greco, Antonio and Percannella, Gennaro and Ritrovato, Pierluigi and Saggese, Alessia and Vento, Mario},
  doi          = {10.1007/s00521-022-07194-5},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {15981-15996},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning based system for handwashing procedure evaluation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). A convolution neural network approach for fall detection
based on adaptive channel selection of UWB radar signals. <em>NCA</em>,
<em>35</em>(22), 15967–15980. (<a
href="https://doi.org/10.1007/s00521-021-06795-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the World Health Organization and other authorities, falls are one of the main causes of accidental injuries among the elderly population. Therefore, it is essential to detect and predict the fall activities of older persons in indoor environments such as homes, nursing, senior residential centers, and care facilities. Due to non-contact and signal confidentiality characteristics, radar equipment is widely used in indoor care, detection, and rescue. This paper proposes an adaptive channel selection algorithm to separate the activity signals from the background using an ultra-wideband radar and to generalize fused features of frequency- and time-domain images which will be sent to a lightweight convolutional neural network to detect and recognize fall activities. The experimental results show that the method is able to distinguish three types of fall activities (i.e., stand to fall, bow to fall, and squat to fall) and obtain a high recognition accuracy up to 95.7\%.},
  archive      = {J_NCA},
  author       = {Wang, Ping and Li, Qimeng and Yin, Peng and Wang, Zhonghao and Ling, Yu and Gravina, Raffaele and Li, Ye},
  doi          = {10.1007/s00521-021-06795-w},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {15967-15980},
  shortjournal = {Neural Comput. Appl.},
  title        = {A convolution neural network approach for fall detection based on adaptive channel selection of UWB radar signals},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on deep learning and big data analytics for
medical e-diagnosis/AI-based e-diagnosis. <em>NCA</em>, <em>35</em>(22),
15961–15965. (<a
href="https://doi.org/10.1007/s00521-023-08689-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Fong, Simon and Fortino, Giancarlo and Ghista, Dhanjoo and Piccialli, Francesco},
  doi          = {10.1007/s00521-023-08689-5},
  journal      = {Neural Computing and Applications},
  number       = {22},
  pages        = {15961-15965},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on deep learning and big data analytics for medical e-diagnosis/AI-based e-diagnosis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bi-graph attention network for energy price forecasting via
multiple time scale learning. <em>NCA</em>, <em>35</em>(21),
15943–15959. (<a
href="https://doi.org/10.1007/s00521-023-08583-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Price forecasting of oil products and natural gas is of great interest due to their essential roles in modern industry and human lives. Existing studies on energy price forecasting are mostly concerned with individual energy markets, with less consideration of their interaction. This paper presents a bi-graph attention network (BiGAT) approach for energy price forecasting of oil products and natural gas, aiming at exploiting the price correlations of these energy sources for prediction. Specifically, we introduce the concordance graph and the causality graph into the BiGAT model to quantify the Kendall’s rank correlation and the convergence cross mapping causality of the energy prices. To facilitate training the BiGAT model with the energy price time series of multiple time scale nature, we employ the boosted Hodrick–Prescott (bHP) filter to decompose the price data into slow- and fast-varying parts for learning, respectively. As the original bHP filtering algorithm involves computing an inverse matrix of the data size, it is not in favor of using in expanding or streaming data scenarios directly. Here, we also devise an incremental bHP filtering algorithm that applies to data of arbitrary finite size in a recursive manner, requiring the computation of a third-order initial inverse matrix only. Experimental results on empirical data show that the forecasting accuracy of our model is significantly better than other considered models, and the proposed incremental algorithm effectively extends the application scenarios of the bHP filter.},
  archive      = {J_NCA},
  author       = {Liu, Yuxia and Xiao, Wei and Chu, Tianguang},
  doi          = {10.1007/s00521-023-08583-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15943-15959},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bi-graph attention network for energy price forecasting via multiple time scale learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Archive-based coronavirus herd immunity algorithm for
optimizing weights in neural networks. <em>NCA</em>, <em>35</em>(21),
15923–15941. (<a
href="https://doi.org/10.1007/s00521-023-08577-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of the supervised learning process for feedforward neural networks, especially multilayer perceptron neural network (MLP), depends on the suitable configuration of its controlling parameters (i.e., weights and biases). Normally, the gradient descent method is used to find the optimal values of weights and biases. The gradient descent method suffers from the local optimal trap and slow convergence. Therefore, stochastic approximation methods such as metaheuristics are invited. Coronavirus herd immunity optimizer (CHIO) is a recent metaheuristic human-based algorithm stemmed from the herd immunity mechanism as a way to treat the spread of the coronavirus pandemic. In this paper, an external archive strategy is proposed and applied to direct the population closer to more promising search regions. The external archive is implemented during the algorithm evolution, and it saves the best solutions to be used later. This enhanced version of CHIO is called ACHIO. The algorithm is utilized in the training process of MLP to find its optimal controlling parameters thus empowering their classification accuracy. The proposed approach is evaluated using 15 classification datasets with classes ranging between 2 to 10. The performance of ACHIO is compared against six well-known swarm intelligence algorithms and the original CHIO in terms of classification accuracy. Interestingly, ACHIO is able to produce accurate results that excel other comparative methods in ten out of the fifteen classification datasets and very competitive results for others.},
  archive      = {J_NCA},
  author       = {Abu Doush, Iyad and Awadallah, Mohammed A. and Al-Betar, Mohammed Azmi and Alomari, Osama Ahmad and Makhadmeh, Sharif Naser and Abasi, Ammar Kamal and Alyasseri, Zaid Abdi Alkareem},
  doi          = {10.1007/s00521-023-08577-y},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15923-15941},
  shortjournal = {Neural Comput. Appl.},
  title        = {Archive-based coronavirus herd immunity algorithm for optimizing weights in neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MiMuSA—mimicking human language understanding for
fine-grained multi-class sentiment analysis. <em>NCA</em>,
<em>35</em>(21), 15907–15921. (<a
href="https://doi.org/10.1007/s00521-023-08576-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an important natural language processing (NLP) task due to a wide range of applications. Most existing sentiment analysis techniques are limited to the analysis carried out at the aggregate level, merely providing negative, neutral and positive sentiments. The latest deep learning-based methods have been leveraged to provide more than three sentiment classes. However, such learning-based methods are still black-box-based methods rather than explainable language processing methods. To address this gap, this paper proposes a new explainable fine-grained multi-class sentiment analysis method, namely MiMuSA, which mimics the human language understanding processes. The proposed method involves a multi-level modular structure designed to mimic human’s language understanding processes, e.g., ambivalence handling process, sentiment strength handling process, etc. Specifically, multiple knowledge bases including Basic Knowledge Base, Negation and Special Knowledge Base, Sarcasm Rule and Adversative Knowledge Base, and Sentiment Strength Knowledge Base are built to support the sentiment understanding process. Compared with other multi-class sentiment analysis methods, this method not only identifies positive or negative sentiments, but can also understand fine-grained multi-class sentiments, such as the degree of positivity (e.g., strongly positive or slightly positive) and the degree of negativity (e.g., slightly negative or strongly negative) of the sentiments involved. The experimental results demonstrate that the proposed MiMuSA outperforms other existing multi-class sentiment analysis methods in terms of accuracy and F1-Score.},
  archive      = {J_NCA},
  author       = {Wang, Zhaoxia and Hu, Zhenda and Ho, Seng-Beng and Cambria, Erik and Tan, Ah-Hwee},
  doi          = {10.1007/s00521-023-08576-z},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15907-15921},
  shortjournal = {Neural Comput. Appl.},
  title        = {MiMuSA—mimicking human language understanding for fine-grained multi-class sentiment analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spike time displacement-based error backpropagation in
convolutional spiking neural networks. <em>NCA</em>, <em>35</em>(21),
15891–15906. (<a
href="https://doi.org/10.1007/s00521-023-08567-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a supervised learning algorithm, which avoids backward recursive gradient computation, for training deep convolutional spiking neural networks (SNNs) with single-spike-based temporal coding. The algorithm employs a linear approximation to compute the derivative of the spike latency with respect to the membrane potential, and it uses spiking neurons with piecewise linear postsynaptic potential to reduce the computational cost and the complexity of neural processing. To evaluate the performance of the proposed algorithm in deep architectures, we employ it in convolutional SNNs for the image classification task. For two popular benchmarks of MNIST and Fashion-MNIST datasets, the network reaches accuracies of, respectively, 99.2 and $$92.8\%$$ . The trade-off between memory storage capacity and computational cost with accuracy is analyzed by applying two sets of weights: real-valued weights that are updated in the backward pass and their signs, binary weights, that are employed in the feedforward process. We evaluate the binary CSNN on two datasets of MNIST and Fashion-MNIST and obtain acceptable performance with a negligible accuracy drop with respect to real-valued weights (about 0.6 and $$0.8\%$$ drops, respectively).},
  archive      = {J_NCA},
  author       = {Mirsadeghi, Maryam and Shalchian, Majid and Kheradpisheh, Saeed Reza and Masquelier, Timothée},
  doi          = {10.1007/s00521-023-08567-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15891-15906},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spike time displacement-based error backpropagation in convolutional spiking neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A composite neural network-based adaptive sliding mode
control method for reluctance actuator maglev system. <em>NCA</em>,
<em>35</em>(21), 15877–15890. (<a
href="https://doi.org/10.1007/s00521-023-08551-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve high levitation control performances for a maglev system (MLS) with the uncertainties caused by the inherent nonlinearities and external disturbances, this paper proposes a novel composite adaptive sliding mode control (CASMC) method. The CASMC method comprises an equivalent controller, a composite neural network (NN) compensator, and a composite adaptive switching controller. Firstly, a modified prediction error that adds an adaptive switching term is designed to enlarge the effect of the compensation error. Secondly, a composite weight updating law consisting of the modified prediction error and the sliding mode surface is used for NN to accelerate its convergence speed. Thirdly, a new composite adaptive switching control law, including a prediction error-based adaptive switching gain and a prediction error-based proportion switching gain, is proposed for better dynamic response, stronger disturbance suppression capability, and lower chattering. The stability of the closed-loop control system is analyzed by the Lyapunov theorem. Comparative experiments were performed. Results show that the CASMC method can guarantee high levitation control performances with a better dynamic response, stronger robustness, no overshoot, and lower chattering simultaneously.},
  archive      = {J_NCA},
  author       = {Yunlang, Xu and Feng, Shu and Xinyi, Su and Liang, Guo and Shuo, Han and Xiaofeng, Yang},
  doi          = {10.1007/s00521-023-08551-8},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15877-15890},
  shortjournal = {Neural Comput. Appl.},
  title        = {A composite neural network-based adaptive sliding mode control method for reluctance actuator maglev system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Laplacian generalized elastic net lp-norm nonparallel
support vector machine for semi-supervised classification. <em>NCA</em>,
<em>35</em>(21), 15857–15875. (<a
href="https://doi.org/10.1007/s00521-023-08548-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For semi-supervised learning, a few labeled data and a large number of unlabeled data are used to construct a reasonable classifier. In recent years, many semi-supervised learning methods have been proposed and achieved good performance, especially for the graph-based approaches that can exploit the geometric information embedded in the data. Motivated by the success of generalized elastic net Lp-norm nonparallel support vector machine (GLpNPSVM) and the graph-based regularization term, in this paper, a novel Laplacian generalized elastic net Lp-norm nonparallel support vector machine for semi-supervised learning (Lap-GLpNPSVM) is proposed. A Lp-norm graph regularization term is introduced to improve the performance by the adjustability of the value of p. Experimental results on two synthetic datasets, fifteen UCI datasets, and Handwritten Numeral datasets demonstrate that proposed methods outperform other state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Xie, Xijiong and Sun, Feixiang},
  doi          = {10.1007/s00521-023-08548-3},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15857-15875},
  shortjournal = {Neural Comput. Appl.},
  title        = {Laplacian generalized elastic net lp-norm nonparallel support vector machine for semi-supervised classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). WUSL–SOD: Joint weakly supervised, unsupervised and
supervised learning for salient object detection. <em>NCA</em>,
<em>35</em>(21), 15837–15856. (<a
href="https://doi.org/10.1007/s00521-023-08545-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods for salient object detection (SOD) have been studied actively and promisingly. However, it is still challenging for the studies with two aspects. The first one is a single type of label from the network to convey limit information, which leads to the poor generalization ability of the network. The second one is the difficulty to improve the accuracy and detect details of target. To address these challenges, we develop a novel approach via joint weakly supervised, unsupervised and supervised learning for SOD (WUSL–SOD), which differs from existing methods just based on ground-truth or other sparse labels. Specifically, to optimize the objective of the image, the unsupervised learning module (ULM) is designed to generate coarse saliency feature and suppress background noises via attention guiding mechanism. Then, we propose the weakly supervised learning module (WLM) based on scribbles for producing relatively accurate saliency feature. Note that this structure is used to enhance the details and remedy the deficiency of scribbles in WLM. For further refining information from the ULM and WLM, we propose a supervised learning module (SLM), which is not only applied to process and refine information from the ULM and WLM, but also enhance the image details and capture the entire target area. Furthermore, we also exchange information between the SLM and the WLM to obtain more accurate saliency maps. Extensive experiments on five datasets demonstrate that the proposed approach can effectively outperform the state-of-the-art approaches and achieve real-time.},
  archive      = {J_NCA},
  author       = {Liu, Yan and Zhang, Yunzhou and Wang, Zhenyu and Ma, Rong and Qiu, Feng and Coleman, Sonya and Kerr, Dermot},
  doi          = {10.1007/s00521-023-08545-6},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15837-15856},
  shortjournal = {Neural Comput. Appl.},
  title        = {WUSL–SOD: Joint weakly supervised, unsupervised and supervised learning for salient object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic emission estimation under incomplete information
with spatiotemporal convolutional GAN. <em>NCA</em>, <em>35</em>(21),
15821–15835. (<a
href="https://doi.org/10.1007/s00521-023-08420-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise emission estimation of vehicle exhausts is crucial to urban traffic pollution prevention and control. Existing methods utilize the widely distributed and large number of GPS data to estimate the emission distribution of vehicles in the road network. However, the emission features are insufficient to decrease the estimation accuracy when the data distribution is uneven and sparse in the spatial and temporal domains. To address this problem, we propose a two-step emission estimation model under incomplete information, which exploits the spatiotemporal propagation features of emission information. Specifically, an adaptive smoothing strategy reconstructs a second-by-second emission rate field by modeling the correlation of neighboring traffic states, to address the inconsistency of time intervals between emission models and sampling intervals. Then a spatiotemporal convolutional GAN (ST-CGAN) is proposed, which introduces the spatiotemporal convolution operator to generate the traffic emission by temporal features and structural similarity. We evaluated the proposed method using the GPS trajectory data on Didi Chuxing GAIA Open Dataset. The framework aligns GPS data and emission models and reconstructs effectively the high-emission features in traffic networks. The proposed ST-CGAN generates a more reasonable spatial and temporal distribution of vehicle emissions than state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Zhao, Zhenyi and Cao, Yang and Xu, Zhenyi and Kang, Yu},
  doi          = {10.1007/s00521-023-08420-4},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15821-15835},
  shortjournal = {Neural Comput. Appl.},
  title        = {Traffic emission estimation under incomplete information with spatiotemporal convolutional GAN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid deep learning approach for detection and
segmentation of ovarian tumours. <em>NCA</em>, <em>35</em>(21),
15805–15819. (<a
href="https://doi.org/10.1007/s00521-023-08569-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent days, artificial intelligence (AI) is gaining worldwide popularity in several industries among which healthcare is an important sector. AI is being used in healthcare to reduce human errors and save time thereby aiding in accurate disease diagnosis. In healthcare, AI relies on analysing and interpreting thousands of datasets. This work is one such healthcare application involving a hybrid deep learning approach to detect and segment cancerous ovarian tumours. Doctors and radiologists have revealed that it is highly challenging to detect ovarian cancer. This is because identifying whether the tumour is cancerous or not using medical imaging modalities is a tedious task. Intending to eliminate this stereotype, the proposed model incorporates the efficiency of the YOLO v5 detection model and the accuracy of the attention U-Net segmentation model to pin down cancerous ovarian tumours in computed tomography images. The performance of this model is verified using clinical data and its performance metrics have been analysed. Simulation results have shown that the proposed model works efficiently on ovarian tumours in terms of accuracy and dice scores. The YOLO v5 model has located the ovarian tumours with an accuracy of 98\%, and the attention U-Net has segmented the detected ovarian tumours with an accuracy of 99.2\%. This computer-aided diagnosis system can be used to aid radiologists in the diagnosis of ovarian cancer.},
  archive      = {J_NCA},
  author       = {Maria, H. Heartlin and Jossy, A. Maria and Malarvizhi, S.},
  doi          = {10.1007/s00521-023-08569-y},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15805-15819},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid deep learning approach for detection and segmentation of ovarian tumours},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A video system based on convolutional autoencoder for
drowning detection. <em>NCA</em>, <em>35</em>(21), 15791–15803. (<a
href="https://doi.org/10.1007/s00521-023-08526-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision combined with deep learning technologies is widely used in video surveillance. In this paper, it is applied to drowning detection video systems. Traditional drowning detection methods detect drowning mainly by monitoring the physiological condition, the time and motion of swimmers in the water. But these methods are not applicable to detect early quiet drowning phenomena. Some researchers realize supervised classification by simulative drowning features. But real drowning events are difficult to truly simulate, so these methods are not reliable. In this paper, a drowning detection video system with edge computing is proposed, and it can detect drowning events in swimming pools without any wearable devices. According to the characteristics of drowning people, the strategies for underwater near-vertical human detection are proposed, providing a reliable basis for drowning detection. A lightweight drowning detection convolutional autoencoder is proposed to achieve unsupervised drowning detection, solving the lack of drowning videos and the inauthenticity of simulative videos. Then, an edge device is designed for detecting drowning in real time at the edge. Finally, for training and experimental evaluation, a pool dataset including many pool underwater video sequences is produced. The experimental results show that the proposed drowning detection method has a good comprehensive performance. The system is feasible and valuable.},
  archive      = {J_NCA},
  author       = {He, Xinyu and Yuan, Fei and Liu, Tingzhuang and Zhu, Yi},
  doi          = {10.1007/s00521-023-08526-9},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15791-15803},
  shortjournal = {Neural Comput. Appl.},
  title        = {A video system based on convolutional autoencoder for drowning detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite-time anti-synchronization and fixed-time
quasi-anti-synchronization for complex-valued neural networks with
time-varying delay and application. <em>NCA</em>, <em>35</em>(21),
15775–15790. (<a
href="https://doi.org/10.1007/s00521-023-08474-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the issue of the finite-time anti-synchronization and fixed-time quasi-anti-synchronization for complex-valued neural networks with time-varying delays and leakage delay is explored. First of all, the model is divided into two equivalent real-valued neural networks employing the decomposing technique. Second, by utilizing the Hölder inequality, constructed function and new designed quantized controller, several novel sufficient criteria are obtained to ensure finite-time anti-synchronization of the studied system. In addition, a feedback control strategy is developed to derive some conclusions of quasi-anti-synchronization by applying the Lyapunov function. Meanwhile, the estimated settling time is acquired which does not rely on the initial value. Two methods our paper used to analyze can provide new ideas for future research. Finally, numerical simulation with simulation results is offered to indicate the efficiency and validity of the proposed theoretical results, and the results are applied to the field of image encryption.},
  archive      = {J_NCA},
  author       = {Hui, Meng and Zhang, JiaHuang and Yao, Ning and Wu, Weizhe},
  doi          = {10.1007/s00521-023-08474-4},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15775-15790},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finite-time anti-synchronization and fixed-time quasi-anti-synchronization for complex-valued neural networks with time-varying delay and application},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discrete representation learning for handwritten text
recognition. <em>NCA</em>, <em>35</em>(21), 15759–15773. (<a
href="https://doi.org/10.1007/s00521-023-08445-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten text recognition, i.e., the conversion of scanned handwritten documents into machine-readable text, is a complex exercise due to the variability and complexity of handwriting. A common approach in handwritten text recognition consists of a feature extraction step followed by a recognizer. In this paper, we propose a novel DNN architecture for handwritten text recognition that extracts discrete representation from the input text-line image. The proposed model is constructed of an encoder–decoder network with an added quantization layer which applies a dictionary of representative vectors to discretize the latent variables. The dictionary and the network parameters are trained jointly through the k-means algorithm and back propagation, respectively. The performance of the suggested model is evaluated through conducting extensive experiments on five datasets, analyzing the effect of discrete representation on handwriting recognition. The results demonstrate that the use of feature discretization improves the performance of deep handwriting text recognition models when compared to the conventional DNN models with continuous representation. Specifically, the character error rate is decreased by $$22\%$$ and $$21.1\%$$ on IAM and ICFHR18 datasets, respectively.},
  archive      = {J_NCA},
  author       = {Davoudi, Homa and Traviglia, Arianna},
  doi          = {10.1007/s00521-023-08445-9},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15759-15773},
  shortjournal = {Neural Comput. Appl.},
  title        = {Discrete representation learning for handwritten text recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameter adaptive pulse coupled neural network-based
saliency map fusion strategy for salient object detection. <em>NCA</em>,
<em>35</em>(21), 15743–15757. (<a
href="https://doi.org/10.1007/s00521-023-08579-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, salient object detection has caught the interest of numerous researchers for a variety of applications in computer vision. Most deep learning-based algorithms for SOD tasks produce excellent results but require a lot of data availability and large computational and structural complexities. Also, many methods provide excellent outcomes but are unable to preserve the complete boundaries of the objects in images. The paper discusses an innovative integration method for salient object detection of superpixel segmented images to address these issues. It deals with the integration of saliency maps generated by image decomposition based on non-sub-sampled contourlet transform (NSCT) and by machine learning technique based on the random forest regression using a parameter adaptive pulse coupled neural network (PA-PCNN). The PA-PCNN adaptively estimates each of the free parameters of the pulse-coupled neural network (PCNN). The utilization of PA-PCNN considers neighborhood pixel variances and aids in maintaining object details without fuzziness or distortions. The proposed method restores the edges and boundaries of the objects effectively as PA-PCNN aids in maintaining the perceptually similar attributes of the saliency maps. The results of this study are evaluated using three widely used datasets for detecting salient objects, which show the potential of the proposed system to precisely locate the salient objects in various imaging circumstances like complex background images, images with multiple objects, etc. The quantitative and qualitative experimental results validate a substantial advancement in various evaluation parameters for salient object detection with better boundary preservation of objects.},
  archive      = {J_NCA},
  author       = {Lad, Bhagyashree V. and Hashmi, Mohammad Farukh and Keskar, Avinash G.},
  doi          = {10.1007/s00521-023-08579-w},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15743-15757},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parameter adaptive pulse coupled neural network-based saliency map fusion strategy for salient object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparison and evaluation of machine learning approaches for
estimating heat index map in türkiye. <em>NCA</em>, <em>35</em>(21),
15721–15742. (<a
href="https://doi.org/10.1007/s00521-023-08578-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heat index (HI) is a temperature that the human body feels or perceives, as opposed to the physical air temperature measured by a thermometer. The goal of this study was to create a monthly average HI map in the external environment for Türkiye using a mathematical model developed by AccuWeather, an artificial neural network (ANN), and an adaptive neuro-fuzzy inference system (ANFIS) approach. In creating Türkiye’s HI map, measurable parameters such as hourly dry bulb temperature, relative humidity, wind speed, and atmospheric pressure data from 81 measuring stations were used. According to the simulations, due to the lack of measurable data, HI, which cannot be computed in each location, can be efficiently predicted using geographical inputs to ANN and ANFIS methods. The outcomes demonstrated that predicted HI values with the developed ANN and ANFIS models are in good agreement with the actual HI calculated values using the AccuWeather method for all cities, but the accuracy of the machine learning models varies depending on the city’s measured data. Although MAE and RMSE values for generated ANN and ANFIS machine learning models are within acceptable ranges, ANN outperforms ANFIS for all cities tested during the estimation of HI values. ANN and ANFIS models are capable of correctly predicting HI values when the month of the year, latitude, longitude, and altitude values are provided. This eliminates the need for excessive testing and saves time, labor, and financial resources.},
  archive      = {J_NCA},
  author       = {Tumse, Sergen and Bilgili, Mehmet and Sekertekin, Aliihsan and Ünal, Şaban and Sahin, Besir},
  doi          = {10.1007/s00521-023-08578-x},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15721-15742},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparison and evaluation of machine learning approaches for estimating heat index map in türkiye},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meteor detection and localization using YOLOv3 and YOLOv4.
<em>NCA</em>, <em>35</em>(21), 15709–15720. (<a
href="https://doi.org/10.1007/s00521-023-08575-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meteors in the United Arab Emirates are observed daily through the U.A.E. Meteor Monitoring Network (UAEMMN). As of September 2022, more than 40,000 meteors have been observed. However, the high sensitivity of the network also captures non-meteor objects such as airplanes, birds, insects, and space debris appearing in the atmosphere. To accurately identify and label meteors, this study employs object detection algorithms to reduce data and accurately detect meteor and non-meteor objects. The YOLOv3 and YOLOv4 object detection algorithms, utilizing convolutional neural networks, were utilized in this research. The models were trained on both an imbalanced and a balanced dataset that consisted of thousands of images. The imbalanced YOLOv4 model yielded the highest recall score of 98.5\% followed by the imbalanced YOLOv3 model with a recall score of 98\%. The highest accuracy result was also achieved by the imbalanced YOLOv4 model, with a score of 90\%. Overall, all the four models were successful at labeling meteors with a confidence more than 95\%. The proposed study represents a significant contribution to the field of meteor-related image analysis using low-cost cameras and machine learning. It also holds promising implications for further research and development in this area.},
  archive      = {J_NCA},
  author       = {Al-Owais, Aisha and Sharif, Maryam E. and Ghali, Sarra and Abu Serdaneh, Maha and Belal, Omar and Fernini, Ilias},
  doi          = {10.1007/s00521-023-08575-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15709-15720},
  shortjournal = {Neural Comput. Appl.},
  title        = {Meteor detection and localization using YOLOv3 and YOLOv4},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust gaussian process regression-based model for the
determination of static young’s modulus for sandstone rocks.
<em>NCA</em>, <em>35</em>(21), 15693–15707. (<a
href="https://doi.org/10.1007/s00521-023-08573-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Static Young’s modulus (Es) is one of the leading mechanical rock properties. The Es can be measured from experimental lab methods. However, these methods are costly, time-consuming, and challenging to collect samples. Thus, some researchers have proposed alternative techniques, such as empirical correlations, to determine the Es. However, the previous studies have limitations: lack of accuracy, the need for specific data, and improper validation to prove the proper relationships between the inputs and outputs to show the correct physical behavior. In addition, most previous models were based on the dynamic Young’s modulus. Therefore, this study aims to use the Gaussian process regression (GPR) method for Es determination using 1853 real global datasets. The utilization of global data to develop the Es prediction model is unique. The GPR model was validated by applying trend analysis to show that the correct relationships between the inputs and output are attained. Furthermore, different statistical error analyses, namely an average absolute percentage relative error (AAPRE), were performed to assess the GPR accuracy compared to current methods. This study confirmed that the GPR model has robustly and accurately predicted the Es with AAPRE of 5.41\%, surpassing all the existing studied models that have AAPRE of more than 10\%. The trend analysis results indicated that the GPR model follows the proper physical behaviors for all input trends. The GPR model can accurately predict the Es at different ranges of inputs.},
  archive      = {J_NCA},
  author       = {Alakbari, Fahd Saeed and Mohyaldinn, Mysara Eissa and Ayoub, Mohammed Abdalla and Muhsan, Ali Samer and Hussein, Ibnelwaleed A.},
  doi          = {10.1007/s00521-023-08573-2},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15693-15707},
  shortjournal = {Neural Comput. Appl.},
  title        = {A robust gaussian process regression-based model for the determination of static young’s modulus for sandstone rocks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving chinese spell checking with bidirectional LSTMs
and confusionset-based decision network. <em>NCA</em>, <em>35</em>(21),
15679–15692. (<a
href="https://doi.org/10.1007/s00521-023-08570-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese spell checking is a task to detect and correct Chinese spelling errors, which is very important for natural language understanding. Generally, studies on Chinese spell checking are mainly based on n-gram language model and neural network models. However, the validity of the n-gram model needs to balance the value n and the storage resources, and most neural networks cannot efficiently handle the cases with severely uneven distribution of the correct and incorrect characters. This makes spell checking be limited in text application scenarios that contain many oral expressions. To solve the issues, a confusionset-guided decision network for spoken Chinese spell checking is proposed. By using confusionset to generate candidate set, the model can reasonably locate the wrong characters with decision network which ensures bidirectional long short-term memory pay more attention to the characteristics of the wrong characters. To verify the correctness and effectiveness of our model, extensive experiments were carried out on a logistics question and answer corpus and SIGHAN Bake-off dataset. Experimental results show that the model is efficient. It is much effective in spell checking for spoken Chinese, and it outperforms all competitor models. Besides, it can efficiently correct the wrong characters in real scenarios.},
  archive      = {J_NCA},
  author       = {Ma, Chuanshuai and Hu, Miao and Peng, Junjie and Zheng, Cangzhi and Xu, Qianqian},
  doi          = {10.1007/s00521-023-08570-5},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15679-15692},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving chinese spell checking with bidirectional LSTMs and confusionset-based decision network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatiotemporal estimation of TROPOMI NO2 column with
depthwise partial convolutional neural network. <em>NCA</em>,
<em>35</em>(21), 15667–15678. (<a
href="https://doi.org/10.1007/s00521-023-08558-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite-derived measurements are negatively impacted by cloud cover and surface reflectivity. These biases must be discarded and significantly increase the amount of missing data within remote sensing images. This paper expands the application of a partial convolutional neural network (PCNN) to incorporate depthwise convolution layers, conferring temporal dimensionality to the imputation process. The addition of a temporal dimension to the imputation process adds a state of successive existence within the dataset, which spatial imputation cannot capture. The depthwise convolution process enables the PCNN to independently convolve the data for each channel. The deep learning system is trained with the Community Multiscale Air Quality model-simulated tropospheric column density of Nitrogen Dioxide (TCDNO2) to impute TROPOspheric Monitoring Instrument TCDNO2. The depthwise PCNN model achieves an index of agreement of 0.88 and outperforms the default PCNN models, with and without temporal dimensionality of data, and conventional data imputation methods such as inverse distance weighting by 4–7 and 10–15\% in the index of agreement and correlation, respectively. The model demonstrates more consistency in the reconstruction of TROPOspheric Monitoring Instrument tropospheric column density of NO2 images. The model has also demonstrated the accurate imputation of remote sensing images with over 95\% of the data missing. PCNN enables the accurate imputation of remote sensing data with large regions of missing data and will benefit future researchers conducting data assimilation for numerical models, emission studies, and human health impact analyses from air pollution.},
  archive      = {J_NCA},
  author       = {Lops, Yannic and Ghahremanloo, Masoud and Pouyaei, Arman and Choi, Yunsoo and Jung, Jia and Mousavinezhad, Seyedali and Salman, Ahmed Khan and Hammond, Davyda},
  doi          = {10.1007/s00521-023-08558-1},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15667-15678},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatiotemporal estimation of TROPOMI NO2 column with depthwise partial convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diversity improvement in homogeneous ensemble feature
selection: A case study of its impact on classification performance.
<em>NCA</em>, <em>35</em>(21), 15647–15665. (<a
href="https://doi.org/10.1007/s00521-023-08547-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite ensemble learning has recently been usefully applied in feature selection (FS) models, there are some issues such as the diversity and its effects on model performance that need to be more investigated. Diversity is a crucial property in the success of ensemble FS models, so that ignoring it and trying to improve only accuracy makes the model suffer from “diminishing returns”. This led us in this paper to focus on enhancing the diversity paradigm in the homogeneous ensemble feature selection problem via applying a partitioning approach named recursive balanced partitioning (RBP) that deliberately divides the instances into several different partitions. Besides, a new diversity measurement in ensemble FS and a new aggregation criterion named min-mean by taking “minimum” and “mean” criteria is proposed. Experimental results on twelve datasets illustrated that the proposed RBP efficaciously outperforms the traditional random partitioning as a baseline in terms of diversity achievement. Furthermore, examining the impact of diversity on classification accuracy through a case study revealed that the proposed partitioning approach provides more classification accuracy than the baselines; moreover, it was demonstrated that there is an almost positive relationship between diversity and accuracy. These findings can lead to further understanding of the effectiveness of diversity in an ensemble learning pattern.},
  archive      = {J_NCA},
  author       = {Nosrati, Vahid and Rahmani, Mohsen},
  doi          = {10.1007/s00521-023-08547-4},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15647-15665},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diversity improvement in homogeneous ensemble feature selection: A case study of its impact on classification performance},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-granularity semisupervised active learning for point
cloud semantic segmentation. <em>NCA</em>, <em>35</em>(21), 15629–15645.
(<a href="https://doi.org/10.1007/s00521-023-08455-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent successes in point cloud semantic segmentation heavily rely on a large amount of annotated data. Furthermore, three-dimensional point cloud data are generally sparse and unorganized, and a frame of point cloud usually includes more than 100,000 points, which increases the difficulty of point cloud annotation. To reduce the annotation efforts, we propose a multi-granularity semisupervised active learning pipeline which aims to select representative, uncertain and diverse data to annotate. To better exploit annotating budget, we first leverage the conventional point cloud registration algorithm to develop a matching score function which is used to select a representative subset. And then we change the annotating units from a point cloud scan to segmented regions through two semisupervised methods. Subsequently, in each active selection step, segmented region information is calculated with two terms: softmax entropy and point cloud intensity, and the latter serves to encourage region diversity. Finally, to further reduce annotation effort, semisupervised learning is introduced to our pipeline to automatically select a portion of unlabeled segmented regions with high confidence and assign pseudolabels to them. Extensive experiments show that our approach greatly outperforms previous active learning methods, and we obtain the mean class intersection-over-union performance of 95\% fully supervised learning with merely 3\% of labeled data on SemanticKITTI dataset.},
  archive      = {J_NCA},
  author       = {Ye, Shanding and Yin, Zhe and Fu, Yongjian and Lin, Hu and Pan, Zhijie},
  doi          = {10.1007/s00521-023-08455-7},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15629-15645},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-granularity semisupervised active learning for point cloud semantic segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A constraints-based approach using
ranking-gradient-similarity multi-block matching algorithm.
<em>NCA</em>, <em>35</em>(21), 15615–15627. (<a
href="https://doi.org/10.1007/s00521-023-08574-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many works have been done in stereo vision due to its critical importance to the different uses and various areas of computer vision. Recently, the popularity of research on the local block matching algorithm is difficult to compete with the convolutional neural network (CNN) approach, whereby the latter method can achieve higher accuracy at the expense of time consumption. However, the simplicity of the local block matching algorithm is easier to be implemented in real applications at a lower cost. Therefore, this paper presents a new study that improved computation and cost aggregation using a progressive approach. A new algorithm to aid in searching locally similar blocks called the ranking-gradient-similarity multi-block strategy (RGSMB) has been presented, improving processing time and accuracy. A new cost computation has been introduced in the proposed algorithm, which fully utilises the information from the limited local window region by combining the cost from three different constraints, including a Ranking constraint, a Gradient constraint, and a Similarity constraint. The proposed algorithm can accomplish remarkable accuracy by combining with multi-block matching (MBM), which is developed to diminish the conventional cost aggregation&#39;s constrained shape limitation. We evaluate the RGSMB algorithm&#39;s performance and other CNN methods for comparison. KITTI 2012 dataset of 194 and 195 image pairs and the KITTI 2015 dataset of 200 image pairs were used for training and testing. The results indicate that the proposed algorithm is better than the existing approaches, with a higher matching rate using the KITTI benchmark dataset. Compared to existing local block matching algorithms, the average errors of the RGS are less than the CT approach by nearly 9\%, which is the 2nd ranked in this analysis. Also, the RGSMB has average errors of 21\% less than the $$S_{7}$$ + correlation when comparing with existing CNN methods. It was also observed that the RGSMB could estimate the disparity value more accurately in the depth discontinuities and homogenous regions.},
  archive      = {J_NCA},
  author       = {Kok, Kai Yit and Rajendran, Parvathy},
  doi          = {10.1007/s00521-023-08574-1},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15615-15627},
  shortjournal = {Neural Comput. Appl.},
  title        = {A constraints-based approach using ranking-gradient-similarity multi-block matching algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of global temperature anomaly by machine learning
based techniques. <em>NCA</em>, <em>35</em>(21), 15601–15614. (<a
href="https://doi.org/10.1007/s00521-023-08580-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, anthropogenic and natural factors were used to evaluate and forecast climate change on a global scale by using a variety of machine-learning techniques. First, significance analysis using the Shapley method was conducted to compare the importance of each variable. Accordingly, it was determined that the equivalent CO2 concentration in the atmosphere was the most important variable, which was proposed as further evidence of climate change due to fossil fuel-based energy generation. Following that, a variety of machine learning approaches were utilized to simulate and forecast the temperature anomaly until 2100 based on six distinct scenarios. Compared to the preindustrial period, the temperature anomaly for the best-case scenario was found to increase a mean value of 1.23 °C and 1.11 °C for the mid and end of the century respectively. On the other hand, the anomaly was estimated for the worst-case scenario to reach to a mean value of 2.52 °C and 4.97 °C for the same periods. It was then concluded that machine learning approaches can assist researchers in predicting climate change and developing policies for national governments, such as committing firmly to renewable energy regulations.},
  archive      = {J_NCA},
  author       = {Sen, Doruk and Huseyinoglu, Mehmet Fatih and Günay, M. Erdem},
  doi          = {10.1007/s00521-023-08580-3},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15601-15614},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of global temperature anomaly by machine learning based techniques},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Jointly learning distribution and expectation in a unified
framework for facial age and attractiveness estimation. <em>NCA</em>,
<em>35</em>(21), 15583–15599. (<a
href="https://doi.org/10.1007/s00521-023-08563-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning achieved promising results on ordinal regression tasks such as facial age and attractiveness estimation, especially using deep label distribution learning (DLDL) methods, introducing the label distribution learning into deep convolutional neural networks. However, existing DLDL methods have an inconsistency between the training objectives and the evaluation metric, so they may be suboptimal. In addition, these methods always adopt image classification or face recognition models with a large amount of parameters, which carry expensive computation cost and storage overhead. In this paper, we firstly analyze the essential relationship between two state-of-the-art methods (ranking CNN and DLDL) and show that the ranking method is in fact learning label distribution implicitly. This result thus firstly unifies two existing popular state-of-the-art methods into the DLDL framework. Second, in order to alleviate the inconsistency and reduce resource consumption, we design a lightweight network architecture and propose a unified framework which can jointly learn label distribution and regress expectation value. The effectiveness of our approach has been demonstrated on typical ordinal regression tasks including facial age and attractiveness estimation. Our method achieves new state-of-the-art results using the single model with 36× fewer parameters and 3× faster inference speed.},
  archive      = {J_NCA},
  author       = {Gao, Bin-Bin},
  doi          = {10.1007/s00521-023-08563-4},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15583-15599},
  shortjournal = {Neural Comput. Appl.},
  title        = {Jointly learning distribution and expectation in a unified framework for facial age and attractiveness estimation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Manifold learning by a deep gaussian process autoencoder.
<em>NCA</em>, <em>35</em>(21), 15573–15582. (<a
href="https://doi.org/10.1007/s00521-023-08536-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a novel manifold learning algorithm, the deep Gaussian process autoencoder (DPGA), based on deep Gaussian processes. Deep Gaussian process autoencoder algorithm has the following two main characteristics. The former is a bottleneck structure, borrowed by variational autoencoders and the latter is based on the so-called doubly stochastic variational inference for deep Gaussian processes architecture (DSVI). The main novelties of the paper consist in DGPA algorithm and the experimental protocol for evaluating it. In fact, to the best of our knowledge, deep Gaussian processes algorithms have not been applied to manifold learning, yet. Besides, an experimental protocol is introduced, the so-called manifold learning performance protocol (MLPP), to compare quantitatively the geometric preserved properties of manifold learning projections of the proposed deep Gaussian process autoencoder with the ones of state-of-the-art manifold learning algorithms. Extensive experimental tests on eleven synthetic and five real datasets show that deep Gaussian process autoencoder compares favorably with the other manifold learning competitors.},
  archive      = {J_NCA},
  author       = {Camastra, Francesco and Casolaro, Angelo and Iannuzzo, Gennaro},
  doi          = {10.1007/s00521-023-08536-7},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15573-15582},
  shortjournal = {Neural Comput. Appl.},
  title        = {Manifold learning by a deep gaussian process autoencoder},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IRFLMDNN: Hybrid model for PMU data anomaly detection and
re-filling with improved random forest and levenberg marquardt algorithm
optimized dynamic neural network. <em>NCA</em>, <em>35</em>(21),
15563–15572. (<a
href="https://doi.org/10.1007/s00521-023-08571-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phasor Measurement Units (PMU) are capable to generate multi-dimensional time series data, which is one of the most important parts for monitoring power system operation. However, various internal and external factors frequently cause the system to generate anomalous data randomly, so we expect to clean and re-fill the raw PMU data with anomalies to provide support for further advanced applications such as situational awareness, early warning, and dispatch control of the system. Existing methods mostly use classical mathematics and traditional machine learning to analyze PMU data, which makes it difficult to identify the pattern changes of the data under multiple operating conditions in power systems. In this paper, we propose a hybrid model named IRFLMDNN, which consists of an improved CART random forest model and a dynamic neural network optimized by the Levenberg Marquardt algorithm for PMU data anomaly detection and adaptive data re-filling, respectively. Experimental results based on the IEEE 39-node 10-machine New England Power System show that the proposed method has accurate and robust anomaly detection and data refilling performance.},
  archive      = {J_NCA},
  author       = {Yu, Miao and Yang, Chenyu and Li, Weize and Du, Weijie and Li, Jinglin},
  doi          = {10.1007/s00521-023-08571-4},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15563-15572},
  shortjournal = {Neural Comput. Appl.},
  title        = {IRFLMDNN: Hybrid model for PMU data anomaly detection and re-filling with improved random forest and levenberg marquardt algorithm optimized dynamic neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep reinforcement learning approach for maintenance
planning of multi-component systems with complex structure.
<em>NCA</em>, <em>35</em>(21), 15549–15562. (<a
href="https://doi.org/10.1007/s00521-023-08542-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the trend toward greater integration and complexity of mechanical systems has brought challenges to the formulation of preventive maintenance plans. It is very difficult to realize the traditional condition-based maintenance method that relies on calculating the optimal maintenance threshold to achieve optimal maintenance. However, in solving highly complex and challenging control and decision-making problems, the deep reinforcement learning (DRL) method shows its powerful ability and provides a new idea for the maintenance planning of complex systems. Numerical results show that DRL-based maintenance model can obtain optimization strategies through continuous exploration and realize the trade-off between component maintenance cost and the loss caused by system failure, whether in simple or complex multi-component systems. The policy minimizes the overall cost of the system by choosing actions that minimize the total long-term cost. The comparison with other maintenance strategies shows that the proposed model is superior to various baseline policies and reduces the system lifecycle cost.},
  archive      = {J_NCA},
  author       = {Chen, Jiahao and Wang, Yu},
  doi          = {10.1007/s00521-023-08542-9},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15549-15562},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep reinforcement learning approach for maintenance planning of multi-component systems with complex structure},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). What can a swiped word tell us more? Demographic and
behavioral correlates from shape-writing text entry. <em>NCA</em>,
<em>35</em>(21), 15531–15548. (<a
href="https://doi.org/10.1007/s00521-023-08559-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape-writing (aka gesture typing or swiping) is a word-based text entry method for touchscreen keyboards. It works by landing the finger on (or close to) the first character of the desired word and then sliding over all the other character keys without lifting the finger until the last word character is reached. This generates a trajectory of swiped characters on the keyboard layout which can be translated to a meaningful word by a statistical decoder. We hypothesize that swiping carries rich information about the user, such as demographic (e.g., age or gender) and behavioral (e.g., swiping familiarity or input finger) information. To test our hypothesis, we trained several sequence classifiers using different recurrent neural network architectures to predict demographic and behavioral correlates of users from swipe trajectories. We show that our sequence classifiers are always performing better than a random classifier; therefore, we conclude that cognitive and motor control mechanisms are embodied and reflected in swipe trajectories, validating thus our research hypothesis. Taken together, our results have implications for user privacy. Currently swiping is supported by all mobile vendors and has millions of users, so people may be inadvertently profiled at an unprecedented granularity. Future work should consider new ways of addressing these issues without impacting the user’s swiping experience.},
  archive      = {J_NCA},
  author       = {Lemarquis, Désirée C. A. and Yilma, Bereket A. and Leiva, Luis A.},
  doi          = {10.1007/s00521-023-08559-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15531-15548},
  shortjournal = {Neural Comput. Appl.},
  title        = {What can a swiped word tell us more? demographic and behavioral correlates from shape-writing text entry},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-channel and multi-scale separable dilated
convolutional neural network with attention mechanism for flue-cured
tobacco classification. <em>NCA</em>, <em>35</em>(21), 15511–15529. (<a
href="https://doi.org/10.1007/s00521-023-08544-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tobacco classification is a challenging research topic and plays a crucial role in the process of cigarette production. Tobacco classification mainly relies on manual selection, which is time-consuming, labor-intensive, and subjective. With the development of machine learning, how to automatically classify tobacco leaves has become a fast-growing research issue. However, the lack of high-quality tobacco image dataset limits the applications of deep learning approaches seriously. In addition, a large number of parameters, single-scale features, and high computational complexity further affect the classification results. To address these problems, we establish a new tobacco dataset, which contains 11849 labeled tobacco leaf images in 9 categories. Then, a multi-channel and multi-scale separable dilated convolution neural network with attention mechanism is proposed. The adopted separable dilated convolution increases the receptive fields of the convolution kernels and improves the calculation speed and accuracy of the model without increasing the number of training parameters. Then, the attention mechanism is integrated, so that the network can assign higher weights for discriminative features and get rid of redundant ones by assigning lower even zero weights. Experimental results demonstrate the superiority and effectiveness of the proposed approach. Based on our new dataset, the average classification result of the proposed method achieves 98.4\%.},
  archive      = {J_NCA},
  author       = {Xu, Ming and Gao, Jinfeng and Zhang, Zhong and Guo, Xin},
  doi          = {10.1007/s00521-023-08544-7},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15511-15529},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-channel and multi-scale separable dilated convolutional neural network with attention mechanism for flue-cured tobacco classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A classical–quantum convolutional neural network for
detecting pneumonia from chest radiographs. <em>NCA</em>,
<em>35</em>(21), 15503–15510. (<a
href="https://doi.org/10.1007/s00521-023-08566-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While many quantum computing techniques for machine learning have been proposed, their performance on real-world datasets remains to be studied. In this paper, we explore how a variational quantum circuit could be integrated into a classical neural network for the problem of detecting pneumonia from chest radiographs. We substitute one layer of a classical convolutional neural network with a variational quantum circuit to create a hybrid neural network. We train both networks on an image dataset containing chest radiographs and benchmark their performance. To mitigate the influence of different sources of randomness in network training, we sample the results over multiple rounds. We show that the hybrid network outperforms the classical network on different performance measures and that these improvements are statistically significant. Our work serves as an experimental demonstration of the potential of quantum computing to significantly improve neural network performance for real-world, non-trivial problems relevant to society and industry.},
  archive      = {J_NCA},
  author       = {Kulkarni, Viraj and Pawale, Sanjesh and Kharat, Amit},
  doi          = {10.1007/s00521-023-08566-1},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15503-15510},
  shortjournal = {Neural Comput. Appl.},
  title        = {A classical–quantum convolutional neural network for detecting pneumonia from chest radiographs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Thermal error prediction and control method combining
residual-based one-dimensional convolution-minimum gate unit model with
physical-data-edge-cloud terminal architecture. <em>NCA</em>,
<em>35</em>(21), 15477–15502. (<a
href="https://doi.org/10.1007/s00521-023-08553-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The geometric precision of machined parts is greatly reduced due to thermal errors, thereby the thermal errors should be controlled and compensated timely to improve the machining accuracy. But the previously established thermal error models in related studies are not robust, and the predictive accuracy is not high, and the convergence is weak. Moreover, the error control delay is serious due to the network bandwidth limitation. To overcome the above challenges, the theoretical and data-driven methods are combined. The intrinsic long-term memory characteristic of thermal errors is revealed by the theoretical method and the finite element analysis, providing a theoretical guidance for the data-driven method. Then a residual-based one-dimensional convolution-minimum gate unit model is designed based on the residual connection. The designed one-dimensional convolution layer extracts the data features, and the residual connection with multiple pooling layers is used to compress the dimension of the error data. The minimal gate unit is used to improve the convergence rate. Then a new physical-data-edge-cloud terminal architecture is proposed by combining the advantages of the cloud computing and edge computing. Finally, the experiment was conducted to verify the designed physical-data-edge-cloud terminal architecture. The results indicate that the predictive accuracy is 98.18\% and that the convergence time is shortened to 13.719 s compared with traditional thermal error models. Furthermore, the geometric error is reduced by more than 80\%, and the total time consumption is 166 s, and the data transmission time is 25 s. The system efficiency of the designed physical-data-edge-cloud terminal system is far higher than that of physical-edge-cloud, physical-data-cloud, and physical-cloud systems.},
  archive      = {J_NCA},
  author       = {Luo, Fangqiong and Ma, Chi and Liu, Jialan and Gui, Hongquan and Li, Mengyuan},
  doi          = {10.1007/s00521-023-08553-6},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15477-15502},
  shortjournal = {Neural Comput. Appl.},
  title        = {Thermal error prediction and control method combining residual-based one-dimensional convolution-minimum gate unit model with physical-data-edge-cloud terminal architecture},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing INS/GNSS integrated navigation systems by using
IPO algorithms. <em>NCA</em>, <em>35</em>(21), 15461–15475. (<a
href="https://doi.org/10.1007/s00521-023-08517-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of soft computing techniques can be largely found in engineering sciences. These include the design and optimization of navigation systems for use in land, sea, and air transportation systems. In this paper, an attempt is made to leverage on novel metaheuristic optimization approaches for designing integrated navigation systems. For this purpose, a simplified version of the inclined planes system optimization (called SIPO) algorithm alongside its two standard and modified versions are used in comparison with the two conventional methods of genetic algorithm and particle swarm optimization. Considerations are made on an INS/GNSS problem with IMU MEMS modules. Outputs are presented in terms of statistical and performance indicators, such as runtime, fitness, convergence, navigation accuracy (velocity, latitude, longitude, altitude, roll, pitch, yaw), and routing along with the ranking of algorithms. Competitive performance and relative superiority of the standard IPO over other methods in evaluating results have been confirmed. So that compared to other state-of-the-art algorithms (GA, PSO, IPO, and MIPO), the best runtime rank with a value of 6/4 by SIPO and the best performance rank of fitness, navigation accuracy for the two assumed IMU modules, and the total rank with values of 4/4, 149/60, 165/60, and 332/128 obtained by IPO, respectively.},
  archive      = {J_NCA},
  author       = {Mohammadi, Ali and Sheikholeslam, Farid and Emami, Mehdi and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-023-08517-w},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15461-15475},
  shortjournal = {Neural Comput. Appl.},
  title        = {Designing INS/GNSS integrated navigation systems by using IPO algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nuclei probability and centroid map network for nuclei
instance segmentation in histology images. <em>NCA</em>,
<em>35</em>(21), 15447–15460. (<a
href="https://doi.org/10.1007/s00521-023-08503-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclei instance segmentation is an integral step in digital pathology workflow as it is a prerequisite for most downstream tasks such as patient survival analysis, precision medicine, and cancer prognosis. There exist many challenges such as quality of labeled data, staining variation among tissue slides, high variation among multi-organ &amp; multi-center digital slides and overlapping nuclei that are difficult to separate. Therefore, it is important to have an automatic and robust nuclei instance segmentation model that saves the time of pathologists by delineating accurate nuclei instances. To this end, we develop a nuclei instance segmentation pipeline that estimates distance transform and nuclear masks using an encoder–decoder-based CNN model. These estimated distance transform and nuclear masks are then utilized to delineate accurate nuclei boundaries from overlapping nuclei. We demonstrate that our proposed NC-Net model is lightweight and produces state-of-the-art results on the three recently published largest nuclei instance segmentation datasets to date. Additionally, our proposed NC-Net model is faster and utilizes a fewer number of parameters for learning as compared to other top-performing nuclei instance segmentation models. The purpose of developing a lightweight and state-of-the-art model is to provide capacity building to digital pathology workflows by reducing inference times and delineating accurate nuclear instances. The implementation details and the trained models are made available at this https://github.com/nauyan/NC-Net .},
  archive      = {J_NCA},
  author       = {Rashid, Syed Nauyan and Fraz, Muhammad Moazam},
  doi          = {10.1007/s00521-023-08503-2},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15447-15460},
  shortjournal = {Neural Comput. Appl.},
  title        = {Nuclei probability and centroid map network for nuclei instance segmentation in histology images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantized neural adaptive finite-time preassigned
performance control for interconnected nonlinear systems. <em>NCA</em>,
<em>35</em>(21), 15429–15446. (<a
href="https://doi.org/10.1007/s00521-023-08361-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the issue of neural adaptive decentralized finite-time prescribed performance (FTPP) control is investigated for interconnected nonlinear time-delay systems. First, to bypass the potential singularity difficulties, the hyperbolic tangent function and the radial basis function neural networks are integrated to handle the unknown nonlinear items. Then, an adaptive FTPP control strategy is developed, where an improved fractional-order filter is applied to tackle the tremendous “amount of calculation” and eliminate the filter error simultaneously. Furthermore, by considering the impact of bandwidth limitation, an adaptive self-triggered control law is designed, in which the next trigger instant is determined through the current information. Ultimately, it can be demonstrated that the proposed control scheme not only guarantees that all states of the closed-loop system are semi-globally uniformly ultimately bounded, but also that the system output is confined to a small area in finite time. Two simulation examples are carried out to verify the effectiveness and superiority of the proposed method.},
  archive      = {J_NCA},
  author       = {Song, Xiaona and Sun, Peng and Song, Shuai and Stojanovic, Vladimir},
  doi          = {10.1007/s00521-023-08361-y},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15429-15446},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quantized neural adaptive finite-time preassigned performance control for interconnected nonlinear systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cortex-inspired ensemble based network intrusion detection
system. <em>NCA</em>, <em>35</em>(21), 15415–15428. (<a
href="https://doi.org/10.1007/s00521-023-08561-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the invention of modern network technologies in recent decades, the exponential growth in wireless devices and their ease in wireless connectivity, network traffic is significantly increasing. Unluckily, this ease of connectivity is increasing the risk of network intrusion and exploitation of information. This vulnerability also provides opportunities for attackers to perform malicious activities, resulting in serious security threats such as DDoS, DoS, Brute Force, SQL Injection, Malware, and Phishing attack, thus creating the demand for an effective network intrusion detection system. The traditional approaches for identifying the attacks performed by an intruder are mostly packet analysis-based and thus cannot achieve good performance. Unluckily, inspection of a packet is not possible in the case of a high-speed and encrypted packet. Additionally, a packet is a small chunk of information as compared to flow thereby, extracting the nature (attack) of traffic for which a packet is being used is constrained. Considering the power of information processing in the human brain’s visual cortex, we propose a cortex-inspired ensemble-based network intrusion detection system (CI-EnsID) capable of detecting attacks or intrusions in a network flow. The proposed system consists of a multilayer feed-forward network that processes the information like an ensemble classification in addition to its cortex-like information processing. Moreover, the proposed system hybridizes contemporary unsupervised and supervised learning techniques. This system is to be installed in a cascade to analyze the network flow to identify malicious traffic resulting from network intruders. To evaluate the proposed system, it was tested on standard and publicly available KDDCup99 and CICIDS2017 datasets. The experimental results show that the proposed CI-EnsID outperforms the Naive Bayes, artificial neural network, logistic regression, decision tree, and random forest-based contemporary classification techniques.},
  archive      = {J_NCA},
  author       = {Muhammad, Ali and Murtza, Iqbal and Saadia, Ayesha and Kifayat, Kashif},
  doi          = {10.1007/s00521-023-08561-6},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15415-15428},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cortex-inspired ensemble based network intrusion detection system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of PM2.5 time series by seasonal trend
decomposition-based dendritic neuron model. <em>NCA</em>,
<em>35</em>(21), 15397–15413. (<a
href="https://doi.org/10.1007/s00521-023-08513-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid industrial development in the human society has brought about the air pollution, which seriously affects human health. PM2.5 concentration is one of the main factors causing the air pollution. To accurately predict PM2.5 microns, we propose a dendritic neuron model (DNM) trained by an improved state-of-matter heuristic algorithm (DSMS) based on STL-LOESS, namely DS-DNM. Firstly, DS-DNM adopts STL-LOESS for the data preprocessing to obtain three characteristic quantities from original data: seasonal, trend, and residual components. Then, DNM trained by DSMS predicts the residual values. Finally, three sets of feature quantities are summed to obtain the predicted values. In the performance test experiments, five real-world PM2.5 concentration data are used to test DS-DNM. On the other hand, four training algorithms and seven prediction models were selected for comparison to verify the rationality of the training algorithms and the accuracy of the prediction models, respectively. The experimental results show that DS-DNM has the more competitive performance in PM2.5 concentration prediction problem.},
  archive      = {J_NCA},
  author       = {Yuan, Zijing and Gao, Shangce and Wang, Yirui and Li, Jiayi and Hou, Chunzhi and Guo, Lijun},
  doi          = {10.1007/s00521-023-08513-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15397-15413},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of PM2.5 time series by seasonal trend decomposition-based dendritic neuron model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent dimension-based cat swarm optimization for
efficient cooperative multi-hop relay selection in vehicular network.
<em>NCA</em>, <em>35</em>(21), 15381–15395. (<a
href="https://doi.org/10.1007/s00521-023-08541-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A revolutionary concept for enhancing the geographical differentiations in vehicular ad hoc networks (VANET) is cooperation. Similar to multi-antenna systems such as Multiple-Input Multiple-Output (MIMO) systems, cooperative communication systems may enhance performance and geographical diversity. These systems are also easier to develop with dispersed hardware and traditionally constrained resources. In order to boost VANET efficiency with regard to certain network restrictions like energy efficiency (EE), network capacity (NC), and outage probability (OP), more network solutions are inspired by cooperative communication despite the fact that various successful research on VANET coupled with cooperative communications is mentioned, they have certain basic issues that they do not clearly address. This article primary goal is to develop and suggest an optimization technique for choosing the fewest possible multi-hops among source and destination for a cooperative VANET. The signal is transferred from the source to the cooperating nodes (their relays) and to their comparable destination during the first time slot of the first phase. In order to solve a multi-objective function including goal throughput and OP, how to choose the ideal amount of relays or hops to allow for flexible communication is the main problem being tackled here. The selection of the best source and destination multi-hop is significantly aided by the use of the novel Dimension-based Cat Swarm Optimization (D-CSO). The suggested model was shown to have a reasonable convergence rate and a fair performance over the whole network via the performance assessment.},
  archive      = {J_NCA},
  author       = {Kiran, Uppula and Kumar, Krishan and Roy, Ajay and Qamar, Shamimul and Azeem, Abdul},
  doi          = {10.1007/s00521-023-08541-w},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15381-15395},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligent dimension-based cat swarm optimization for efficient cooperative multi-hop relay selection in vehicular network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoG-trans: Coupled graph convolutional transformer for
multi-label classification of cherry defects. <em>NCA</em>,
<em>35</em>(21), 15365–15379. (<a
href="https://doi.org/10.1007/s00521-023-08521-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diverse categories of defects on the surface of the cherries have different influences on cherries’ quality, so simultaneous detection of these defects is essential for their grading. It is a difficult undertaking that requires to investigate the intrinsic category dependencies while taking the category imbalances into account. We treat cherry defect recognition as a multi-label classification task and present a novel identification network called Coupled Graph convolutional Transformer (CoG-Trans). Utilizing the self-attention mechanism and static co-occurrence patterns via our proposed categorical representation extraction Module, we model the relevance of various categories implicitly and explicitly, respectively. Moreover, we design a VI-Fusion module based on the attention mechanism to fuse the visible and infrared information sources. Additionally, we employ asymmetric-contrastive loss to correct the category imbalance and learn more discriminative features for each label. Our experiments are conducted on the VI-Cherry dataset, which consists of 9492 paired visible and infrared cherry images with six defective categories and one normal category manually annotated. The suggested method yields excellent performance compared to previous work, achieving 99.54\% mAP on the VI-Cherry dataset.},
  archive      = {J_NCA},
  author       = {Lin, Meiling and Li, Gongyan and Hao, Yuexing and Xu, Shaoyun},
  doi          = {10.1007/s00521-023-08521-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15365-15379},
  shortjournal = {Neural Comput. Appl.},
  title        = {CoG-trans: Coupled graph convolutional transformer for multi-label classification of cherry defects},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated semantic lung segmentation in chest CT images
using deep neural network. <em>NCA</em>, <em>35</em>(21), 15343–15364.
(<a href="https://doi.org/10.1007/s00521-023-08407-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung segmentation algorithms play a significant role in segmenting theinfected regions in the lungs. This work aims to develop a computationally efficient and robust deep learning model for lung segmentation using chest computed tomography (CT) images with DeepLabV3 + networks for two-class (background and lung field) and four-class (ground-glass opacities, background, consolidation, and lung field). In this work, we investigate the performance of the DeepLabV3 + network with five pretrained networks: Xception, ResNet-18, Inception-ResNet-v2, MobileNet-v2 and ResNet-50. A publicly available database for COVID-19 that contains 750 chest CT images and corresponding pixel-labeled images are used to develop the deep learning model. The segmentation performance has been assessed using five performance measures: Intersection of Union (IoU), Weighted IoU, Balance F1 score, pixel accu-racy, and global accuracy. The experimental results of this work confirm that the DeepLabV3 + network with ResNet-18 and a batch size of 8 have a higher performance for two-class segmentation. DeepLabV3 + network coupled with ResNet-50 and a batch size of 16 yielded better results for four-class segmentation compared to other pretrained networks. Besides, the ResNet with a fewer number of layers is highly adequate for developing a more robust lung segmentation network with lesser computational complexity compared to the conventional DeepLabV3 + network with Xception. This present work proposes a unified DeepLabV3 + network to delineate the two and four different regions automatically using CT images for CoVID-19 patients. Our developed automated segmented model can be further developed to be used as a clinical diagnosis system for CoVID-19 as well as assist clinicians in providing an accurate second opinion CoVID-19 diagnosis.},
  archive      = {J_NCA},
  author       = {Murugappan, M. and Bourisly, Ali K. and Prakash, N. B. and Sumithra, M. G. and Acharya, U. Rajendra},
  doi          = {10.1007/s00521-023-08407-1},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15343-15364},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated semantic lung segmentation in chest CT images using deep neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Electrocardiogram signal classification in an IoT
environment using an adaptive deep neural networks. <em>NCA</em>,
<em>35</em>(21), 15333–15342. (<a
href="https://doi.org/10.1007/s00521-023-08534-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT is an emerging technology that is rapidly gaining traction throughout the world. With the incredible power and capacity of IoT, anyone may connect to any network or service at any time, from anywhere. IoT-enabled gadgets have transformed the medical industry by granting unprecedented powers such as remote patient monitoring and self-monitoring. Accurate electrocardiogram (ECG) interpretation is critical in the clinical ECG process since it is most often connected with a condition that might create serious difficulties in the body. Cardiologists and medical practitioners frequently utilize ECG to evaluate heart health. The human heart has an electric transmission system that creates regular electrical signals unintentionally and transmits them to the whole heart. Many individuals die as a result of heart disease all around the world. The doctor will be able to provide exceptional treatment to the patients, and the patients will be able to monitor their own health. This research offers an IoT-based ECG monitoring system that uses a heart rate sensor to create data and an intelligent hybrid classification algorithm to classify the data. ECG monitoring has become a widely used method for detecting cardiac problems. The following are the primary contributions of this paper: To begin, this paper introduces WISE (wearable IoT cloud-based health monitoring system), a unique system for real-time personal health monitoring. In order to offer real-time health monitoring, WISE uses the BASN (body area sensor network) infrastructure. Data from the BASN are instantly transferred to the cloud in WISE, and a lightweight wearable LCD may be incorporated to provide rapid access to real-time data. This hybrid model can manage with the problem of class imbalance in the ECG dataset, which will aid in the development of an IoT-based smart and accurate healthcare system. This research uses ADNN, which correctly predicts an abnormal ECG 98.1\% of the time. The suggested hybrid model&#39;s results are compared to those of other classification models to determine its accuracy and suitability.},
  archive      = {J_NCA},
  author       = {Mary, G. Aloy Anuja and Sathyasri, B. and Murali, K. and Prabhu, L. Arokia Jesu and Bharatha Devi, N.},
  doi          = {10.1007/s00521-023-08534-9},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15333-15342},
  shortjournal = {Neural Comput. Appl.},
  title        = {Electrocardiogram signal classification in an IoT environment using an adaptive deep neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chaotic fitness-dependent quasi-reflected aquila optimizer
for superpixel based white blood cell segmentation. <em>NCA</em>,
<em>35</em>(21), 15315–15332. (<a
href="https://doi.org/10.1007/s00521-023-08486-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crisp partitional clustering techniques like K-Means (KM) are an efficient image segmentation algorithm. However, the foremost concern with crisp partitional clustering techniques is local optima trapping. In addition to that, the general crisp partitional clustering techniques exploit all pixels in the image, thus escalating the computational time. In order to prevail over local trapping problem as well as balance the escalating computational time, this paper presents a Chaotic Fitness-Dependent Quasi-Reflected Aquila Optimizer (CFDQRAO) based crisp clustering strategy which is an improved variant of one of the Nature-Inspired Optimization Algorithms (NIOA), i.e., Aquila Optimizer (AO). The chaotic fitness-dependent quasi-reflection based Opposition Based Learning (OBL) has been incorporated into classical AO to make it a more competent optimizer. Alternatively, Simple Linear Iterative Clustering (SLIC)-based super-pixel images have been explored as input to the clustering technique to lower the computational time of the suggested clustering strategy. In this research, the author provides the results of an experiment performed using images of blood pathology for the purpose of segmenting white blood cells (WBCs). The results reveal the preeminence of the proposed CFDQRAO technique over other tested NIOAs in regard to the optimization ability and consistency. Further, the proposed SLIC-CFDQRAO clustering strategy proved itself better than other SLIC-NIOA based clustering strategies and even SLIC-KM in terms of visual analysis and the values of segmentation quality parameters.},
  archive      = {J_NCA},
  author       = {Dhal, Krishna Gopal and Rai, Rebika and Das, Arunita and Ray, Swarnajit and Ghosal, Daipayan and Kanjilal, Rajdeep},
  doi          = {10.1007/s00521-023-08486-0},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15315-15332},
  shortjournal = {Neural Comput. Appl.},
  title        = {Chaotic fitness-dependent quasi-reflected aquila optimizer for superpixel based white blood cell segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). A sketch semantic segmentation method using novel local
feature aggregation and segment-level self-attention. <em>NCA</em>,
<em>35</em>(21), 15295–15313. (<a
href="https://doi.org/10.1007/s00521-023-08504-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketch semantic segmentation presents great challenges, since sketches have simpler appearances and more levels of abstraction than natural images. To overcome these challenges, we propose a sketch semantic segmentation method. Concretely, we treat a sketch as a 2D point set and exploit the structures of strokes and the spatial position relationship among 2D points to develop a novel local feature aggregation module. The novel local feature aggregation module encodes informative local features, which are highly useful to analyze semantics. And we define “stroke distance” to balance the two-dimensional spatial distributions of sketches and the internal structures of strokes. Simultaneously, we design a segment-level self-attention module to establish and enhance the relationship between segments by encoding the contents and positions of segment features. Further, based on the above two modules, we construct a similar encoder–decoder structure with two sub-branches, which retains the features of the significant points and integrates the features of several intermediate stages by utilizing a global multi-scale mechanism. Finally, the two outputs of the two sub-branches are fused to obtain the final sketch semantic segmentation result. Extensive experiments on SPG and SketchSeg-150K show that our method achieves state-of-the-art results.},
  archive      = {J_NCA},
  author       = {Wang, Lei and Zhang, Shihui and Wang, Wei and Zhao, Weibo},
  doi          = {10.1007/s00521-023-08504-1},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15295-15313},
  shortjournal = {Neural Comput. Appl.},
  title        = {A sketch semantic segmentation method using novel local feature aggregation and segment-level self-attention},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of deep learning method for predicting DC power
based on renewable solar energy and multi-parameters function.
<em>NCA</em>, <em>35</em>(21), 15273–15294. (<a
href="https://doi.org/10.1007/s00521-023-08480-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, the world has witnessed a great expansion in the world of technology and electronics, in addition to the tremendous development in various industries, which has led to an increase in the need for electrical energy significantly. Renewable energy generated from environmentally friendly sources such as energy (solar, water, windmills, etc.) is the solution. The alternative is to provide that energy, especially as it is clean energy that does not cause the emission of carbon dioxide, which pollutes the air and the environment in general. This work presents a software model for producing the largest amount of energy by developing one of the best prediction techniques and using multi-parameter objective functions, where the proposed model called zero to maximum energy based on developing gradient boosting machine (DMP-DGBM) consists of several stages. The problem of this work is divided into parts: The first part is related to programming challenges, while the second part is related to application challenges; as we know, the prediction techniques are split based on the scientific field into two fields: prediction techniques related to data mining and predictions related to deep learning techniques; this work deals with the first type of prediction technique. (a) One of the data mining prediction techniques is the gradient boosting machine characterized by many features that make it the best. These features are GBM gives high accuracy results and works with huge data stream of data, but on the other hand, the core of that algorithm is a decision tree (DT) that has many limitations such as requiring choosing the root of the tree, determining the maximum number of levels of the tree, and also having high computation and long time. Therefore, the first challenge of this paper is how can avoid these limitations (i.e., high computation and implementation time) of this algorithm and benefit from their features. (b) The problem of generating electrical energy from environmentally friendly sources with high efficiency is one of the most important challenges in this field. Therefore, the second challenge of this paper is how can avoid these limitations by building an efficient technique to predict maximum energy from solar energy. DMP-DGBM model consists of many stages applied through a stepwise style. The first stage presents capturing datasets from scientific site which contains the data related to both weather and solar plant. The second stage is preprocessing which contains multi-steps including: (a) merging between two datasets; (b) splitting readings into intervals and deleting the duplicate; and (c) applying Pearson’s correlation to the new dataset. In the third stage, the ZME-DGBM model is constructed based on developing gradient boosting techniques by replacing its kernel (i.e., decision tree function) with multi-parameter optimization functions. The stage begins with dividing the dataset into two sets using five cross-validation methods, and the training dataset is used to construct the DMP-DGBM models, while the testing dataset is used to evaluate them. Finally, the results of the DMP-DGBM are evaluated based on three measures (i.e., coefficient of determination, mean error, and root mean square error. The stage of constructing the predictor relied on replacing the GBM kernel with four different multi-parameter functions, as these were the parameters with the highest correlation with the target, and a threshold value of 0.95 was adopted as determining the importance of the parameters. The proposed model was characterized by giving the best results using a three-parameter function MPF4 for the GBM kernel, and those parameters were AC, TEM, and IRR, where the scale was (R2 = 0.9742), while for MSE = 0.0099 and RMSE = 0.0522 also the system is taken only 80 Ms to implement.},
  archive      = {J_NCA},
  author       = {Al-Janabi, Samaher and Al-Janabi, Zainab},
  doi          = {10.1007/s00521-023-08480-6},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15273-15294},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of deep learning method for predicting DC power based on renewable solar energy and multi-parameters function},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new YOLO-based method for social distancing from real-time
videos. <em>NCA</em>, <em>35</em>(21), 15261–15271. (<a
href="https://doi.org/10.1007/s00521-023-08556-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease (COVID-19) is primarily disseminated through physical contact. As a precaution, it is recommended that indoor spaces have a limited number of people and at least one meter apart. This study proposes a real-time method for monitoring physical distancing compliance in indoor spaces using computer vision and deep learning techniques. The proposed method utilizes YOLO (You Only Look Once), a popular convolutional neural network-based object detection model, pre-trained on the Microsoft COCO (Common Objects in Context) dataset to detect persons and estimate their physical distance in real time. The effectiveness of the proposed method was assessed using metrics including accuracy rate, frame per second (FPS), and mean average precision (mAP). The results show that the YOLO v3 model had the most remarkable accuracy (87.07\%) and mAP (89.91\%). On the other hand, the highest fps rate of up to 18.71 was achieved by the YOLO v5s model. The results demonstrate the potential of the proposed method for effectively monitoring physical distancing compliance in indoor spaces, providing valuable insights for future use in other public health scenarios.},
  archive      = {J_NCA},
  author       = {Gündüz, Mehmet Şirin and Işık, Gültekin},
  doi          = {10.1007/s00521-023-08556-3},
  journal      = {Neural Computing and Applications},
  number       = {21},
  pages        = {15261-15271},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new YOLO-based method for social distancing from real-time videos},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the optimal design of low sidelobe level linear antenna
arrays using a class of evolutionary algorithms. <em>NCA</em>,
<em>35</em>(20), 15239–15259. (<a
href="https://doi.org/10.1007/s00521-023-08538-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antenna array synthesis problems are known to be nonlinear and non-convex optimization problems which require more robust optimization techniques than gradient-based techniques. This paper provides a comprehensive study of a class of evolutionary algorithms that consists of ten algorithms on various linear antenna array design problems. These linear antenna array design problems are concerned mostly with the design of low sidelobe level antenna arrays which is one of the most important design metrics for any system that integrates an antenna/array of antennas in its structure. In the past, many global optimization techniques as well as their variants were used in the antenna array design to overcome the weaknesses in gradient-based techniques. Most of the work introduced in the literature lacks the consistency while comparing the performance of more than one optimization technique over a certain set of optimization problems. This paper provides a fair comparison and re-assessment of the performance of a set of evolutionary algorithms that were applied in the past to solve various antenna array design problems. The performance of the contestant algorithms will be assessed, and a statistical analysis will be performed to compare these algorithms and test their robustness.},
  archive      = {J_NCA},
  author       = {Al-Badawi, Ayman Z. and Dib, Nihad I. and Ali, Mostafa Z.},
  doi          = {10.1007/s00521-023-08538-5},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15239-15259},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the optimal design of low sidelobe level linear antenna arrays using a class of evolutionary algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-weighted graph 3D convolution network for traffic
prediction. <em>NCA</em>, <em>35</em>(20), 15221–15237. (<a
href="https://doi.org/10.1007/s00521-023-08519-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting future traffic state (e.g., traffic speed, volume, travel time, etc.) accurately is highly desirable for traffic management and control. However, network-wide traffic flow has complicated spatial-temporal dependencies, making it challenging to predict. This study proposes a multi-weighted graph 3D convolution network (MWG3D) to predict future network-wide traffic speed, considering the spatial-temporal heterogeneous effects of multiple external factors (i.e., points of interests (POIs), roadway physical characteristics and incidents). The network is composed of a Graph-3D convolution (G3D) module and an incident impact module. In G3D module, a weighted graph convolution is developed first, which extracts complex spatial dependencies of traffic flow considering heterogeneous effects of POIs and roadway physical characteristics. These external factors have great influence on the periodicity of human daily activities, which in turn cyclically affect traffic flow. The weighted graph convolution is further connected with 3D convolutions to extract temporal dependencies of traffic flow, accounting for temporal heterogeneous effects of these external factors. An incident impact module is separately developed to account for spatial-temporal heterogeneous effects of incidents. These external factors could lead to abrupt and temporary changes in traffic flow. The proposed network is evaluated on two real-world datasets. The results show that MWG3D outperforms a selection of the state-of-the-art models. Furthermore, the spatial-temporal heterogeneous effects of external factors are crucial to prediction accuracy.},
  archive      = {J_NCA},
  author       = {Liu, Yuqing and Wang, Chen and Xu, Sixuan and Zhou, Wei and Chen, Yuzhi},
  doi          = {10.1007/s00521-023-08519-8},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15221-15237},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-weighted graph 3D convolution network for traffic prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent IDS in wireless sensor networks using deep fuzzy
convolutional neural network. <em>NCA</em>, <em>35</em>(20),
15201–15220. (<a
href="https://doi.org/10.1007/s00521-023-08511-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intrusion detection systems (IDSs) developed based on classification algorithms for securing wireless sensor networks (WSNs) are unable to attain the required detection accuracy. To handle the security issue in WSN, an intelligent IDS is proposed in this work by using a convolution neural network (CNN)-based deep learning approach along with a fuzzy inference model. The proposed IDS keeps track of the network and system activities by using the proposed fuzzy CNN along with spatial and temporal constraints to detect malicious nodes. Moreover, this algorithm has been modelled mathematically by using Feynman Path Integral and Schrodinger equation for handling the spatial and temporal constraints with fuzzy rules. From the experiments conducted in this work, it is proved that the proposed IDS increases the security, detection accuracy and packet delivery ratio, but decreases the delay and false positive rate in WSNs when compared with the existing IDSs.},
  archive      = {J_NCA},
  author       = {Subramani, Shalini and Selvi, M.},
  doi          = {10.1007/s00521-023-08511-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15201-15220},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent IDS in wireless sensor networks using deep fuzzy convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-spatial information joint guidance evolutionary
algorithm for dynamic multi-objective optimization with a changing
number of objectives. <em>NCA</em>, <em>35</em>(20), 15167–15199. (<a
href="https://doi.org/10.1007/s00521-023-08369-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research on dynamic multi-objective optimization problems involving changes in the number of objectives has received little attention, but it is widespread in practical applications. This problem would cause the expansion or contraction of the manifold in the objective space. If it is accompanied by changes in Pareto set/front (PS/PF), the problem becomes more complex. However, several dynamic response techniques have been developed to handling this kind of dynamics. Faced with these issues, a multi-spatial information joint guidance evolutionary algorithm is proposed. To more accurately identify the optimal solutions after the change, a space adaptive transfer strategy is introduced, which adopts the geodesic flow kernel method to extract spatial information at different times. Afterwards it adaptively transfers the space via different changes to generate new individuals. In order to improve the diversity after the change, a dual space multi-dimensional joint sampling strategy is proposed. It fully combines the individual information in the objective and the decision space. Then the promising solutions are sampled in multiple dimensions near the representative individuals. Comprehensive experiments are conducted on 15 benchmark functions with a varying number of objectives and PS/PF. Simulation results verify the capability of the proposed algorithm.},
  archive      = {J_NCA},
  author       = {Ma, Xuemin and Sun, Hao and Hu, Ziyu and Wei, Lixin and Yang, Jingming},
  doi          = {10.1007/s00521-023-08369-4},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15167-15199},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-spatial information joint guidance evolutionary algorithm for dynamic multi-objective optimization with a changing number of objectives},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new NEST-IGWO strategy for determining optimal IGWO
control parameters. <em>NCA</em>, <em>35</em>(20), 15143–15165. (<a
href="https://doi.org/10.1007/s00521-023-08535-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online optimization applications require fast convergence without sacrificing accuracy. Although the gray wolf optimization (GWO) algorithm is showing good convergence performance, it still needs further improvement to achieve these requirements. Optimal determination of the GWO control parameters can substantially improve the converge performance. All studies in the literature introduced efforts in tuning these parameters on try-and-error bases which may not satisfy the requirements of the online applications. For this reason, a novel nested improved GWO (NEST-IGWO) is used to determine the optimal control parameters for the IGWO. This novel strategy substantially improved the convergence time and accuracy, especially with online control systems. This strategy is having two nested IGWO loops. The internal IGWO loop includes the target function needed to be optimized. Meanwhile, the external loop is used to optimally determine the control parameters of the internal one. The objective function of the external loop is the failure rate and convergence time of the internal one. The results obtained from the NEST-IGWO are compared to 10 existing optimization algorithms for 10 different benchmark functions. Moreover, these optimization algorithms were applied to determine the parameters of the PV-cell model as a real-world application. The results showed that NEST-IGWO outperformed the other 10 optimization algorithms for all benchmark functions understudy and the estimations of the PV-cell parameters in terms of failure rate and convergence time. With the use of the NEST-IGWO, the convergence time is reduced by 90\% of the average convergence time for all other algorithms. Moreover, the failure rate is reduced to 0\% which is not the case for other algorithms understudy. These outstanding results prove the superiority of the NEST-IGWO compared to the other algorithms, and it opens a new venue for determining optimal control parameters for all optimization algorithms.},
  archive      = {J_NCA},
  author       = {Rabie, Asmaa H. and Eltamaly, Ali M.},
  doi          = {10.1007/s00521-023-08535-8},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15143-15165},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new NEST-IGWO strategy for determining optimal IGWO control parameters},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust face alignment via adaptive attention-based graph
convolutional network. <em>NCA</em>, <em>35</em>(20), 15129–15142. (<a
href="https://doi.org/10.1007/s00521-023-08531-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of robust face alignment in the presence of occlusions, which remains a lingering problem in facial analysis despite intensive long-term studies. This paper proposes an adaptive attention-based graph convolutional network for face alignment. Different from most existing methods that ignore the structural information, we combine local features and global structural relationships to construct the landmark-connection graph and optimize the graph to improve the robustness of the model under occlusion conditions. Specifically, we introduce a novel graph convolutional network architecture consisting of three parts: GCN-global, GCN-local, and the adaptive channel attention module. GCN-global estimates the global transformation of landmarks through 3D face fitting to obtain initial coordinates. Considering the interaction between vertexes and edges in the graph, GCN-local jointly trains local edges and vertexes to improve the accuracy. The channel attention module can adaptively select essential features to enhance the performance. In addition, to reduce the influence of occlusion parts on the other landmarks and improve the working efficiency, we apply the preprocessing module to select which keypoints need to be connected. Our method achieves 5.17\% mean error with 1.89\% failure rate on COFW dataset and 4.16\% mean error on 300W-Full dataset. Extensive experiments demonstrate that our method outperforms most state-of-the-art models on three public datasets, including WFLW, COFW, and 300W.},
  archive      = {J_NCA},
  author       = {Fan, Jingyan and Liang, Jiuzhen and Liu, Hao and Huan, Zhan and Hou, Zhenjie},
  doi          = {10.1007/s00521-023-08531-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15129-15142},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust face alignment via adaptive attention-based graph convolutional network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Agricultural commodity price prediction model: A machine
learning framework. <em>NCA</em>, <em>35</em>(20), 15109–15128. (<a
href="https://doi.org/10.1007/s00521-023-08528-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient machine learning-based framework for crop price prediction is proposed in this paper to assist the farmers in estimating their profit-loss beforehand. The proposed work is composed of four functional blocks, such as crop yield prediction, determination of supply, demand prediction and crop price prediction. The input datasets consist of the various field values, such as yield, remaining crop at the end of the year, import, demand and price of a crop. Various time series-based algorithms, such as autoregression, moving average, autoregressive moving average, autoregressive integrated moving average and exponential smoothing, are used to forecast the crop yield. The supply of the crop is determined as a sum of three variables, i.e., the predicted crop yield, residue and import values. The demand for the crop is predicted from a year alone as the demand has more correlation with year over other factors. The crop price from demand, supply and year is predicted using different approaches, which include the time series method, statistical approaches and machine learning techniques. Finally, these three techniques for price prediction are compared to determine the best model having minimum root-mean-square error value. In the proposed work, the decision tree regressor is found to be the best model, for predicting crop price, over others. The superiority of the proposed work over existing approaches, in terms of various aspects, is shown by simulation results.},
  archive      = {J_NCA},
  author       = {Mohanty, Manas Kumar and Thakurta, Parag Kumar Guha and Kar, Samarjit},
  doi          = {10.1007/s00521-023-08528-7},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15109-15128},
  shortjournal = {Neural Comput. Appl.},
  title        = {Agricultural commodity price prediction model: A machine learning framework},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scarce data driven deep learning of drones via generalized
data distribution space. <em>NCA</em>, <em>35</em>(20), 15095–15108. (<a
href="https://doi.org/10.1007/s00521-023-08522-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased drone proliferation in civilian and professional settings has created new threat vectors for airports and national infrastructures. The economic damage for a single major airport from drone incursions is estimated to be millions per day. Due to the lack of balanced representation in drone data, training accurate deep learning drone detection algorithms under scarce data is an open challenge. Existing methods largely rely on collecting diverse and comprehensive experimental drone footage data, artificially induced data augmentation, transfer and meta-learning, as well as physics-informed learning. However, these methods cannot guarantee capturing diverse drone designs and fully understanding the deep feature space of drones. Here, we show how understanding the general distribution of the drone data via a generative adversarial network (GAN), and explaining the under-learned data features using topological data analysis (TDA) can allow us to acquire under-represented data to achieve rapid and more accurate learning. We demonstrate our results on a drone image dataset, which contains both real drone images as well as simulated images from computer-aided design. When compared to random, tag-informed and expert-informed data collections (discriminator accuracy of 94.67\%, 94.53\% and 91.07\%, respectively, after 200 epochs), our proposed GAN-TDA-informed data collection method offers a significant 4\% improvement (99.42\% after 200 epochs). We believe that this approach of exploiting general data distribution knowledge from neural networks can be applied to a wide range of scarce data open challenges.},
  archive      = {J_NCA},
  author       = {Li, Chen and Sun, Schyler C. and Wei, Zhuangkun and Tsourdos, Antonios and Guo, Weisi},
  doi          = {10.1007/s00521-023-08522-z},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15095-15108},
  shortjournal = {Neural Comput. Appl.},
  title        = {Scarce data driven deep learning of drones via generalized data distribution space},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boundary-guided context-aware network for camouflaged object
detection. <em>NCA</em>, <em>35</em>(20), 15075–15093. (<a
href="https://doi.org/10.1007/s00521-023-08502-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) aims to identify and segment items that are seamlessly assimilate into the surroundings. Compared with the traditional image segmentation, the indefinable boundaries of camouflaged objects and high intrinsic similarities between the targets and the surrounding background make COD more challenging. Although many models have been designed to settle this issue, these algorithms suffer from inaccurate contours. Besides, existing COD methods mainly strive to expand the receptive field and excavate rich contextual cues using convolutional layers with large dilation rates. However, the tiny detailed information may be degenerated in this process due to the large “holes” in these dilated convolutional layers. This paper develops a novel boundary-guided context-aware network (BCNet) to deal with these problems. Specifically, we design a high-resolution feature enhancement module to excavate multi-scale information and enlarge the receptive field without destroying the tiny details within the input feature maps. The proposed module is effective in enhancing the single-layer feature and boosting the COD performance. Besides, a boundary-guided feature interaction module is designed to aggregate multi-level features and investigate the complementary relationship between the targets and the corresponding contours. We evaluate BCNet on four benchmark datasets to verify the effectiveness of the key modules. The experimental results demonstrate that BCNet achieves a real-time inference speed (49 FPS) on a Titan XP GPU and surpasses 19 cutting-edge contenders. Source code will be available at https://github.com/clelouch/BCNet .},
  archive      = {J_NCA},
  author       = {Xiao, Jin and Chen, Tianyou and Hu, Xiaoguang and Zhang, Guofeng and Wang, Shaojie},
  doi          = {10.1007/s00521-023-08502-3},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15075-15093},
  shortjournal = {Neural Comput. Appl.},
  title        = {Boundary-guided context-aware network for camouflaged object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modified orca predation algorithm: Developments and
perspectives on global optimization and hybrid energy systems.
<em>NCA</em>, <em>35</em>(20), 15051–15073. (<a
href="https://doi.org/10.1007/s00521-023-08492-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a novel, unique, and improved optimization algorithm called the modified Orca Predation Algorithm (mOPA). The mOPA is based on the original Orca Predation Algorithm (OPA), which combines two enhancing strategies: Lévy flight and opposition-based learning. The mOPA method is proposed to enhance search efficiency and avoid the limitations of the original OPA. This mOPA method sets up to solve the global optimization issues. Additionally, its effectiveness is compared with various well-known metaheuristic methods, and the CEC’20 test suite challenges are used to illustrate how well the mOPA performs. Case analysis demonstrates that the proposed mOPA method outperforms the benchmark regarding computational speed and yields substantially higher performance than other methods. The mOPA is applied to ensure that all load demand is met with high reliability and the lowest energy cost of an isolated hybrid system. The optimal size of this hybrid system is determined through simulation and analysis in order to service a tiny distant location in Egypt while reducing costs. Photovoltaic panels, biomass gasifier, and fuel cell units compose the majority of this hybrid system’s configuration. To confirm the mOPA technique’s superiority, its outcomes have been compared with the original OPA and other well-known metaheuristic algorithms.},
  archive      = {J_NCA},
  author       = {Emam, Marwa M. and El-Sattar, Hoda Abd and Houssein, Essam H. and Kamel, Salah},
  doi          = {10.1007/s00521-023-08492-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15051-15073},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified orca predation algorithm: Developments and perspectives on global optimization and hybrid energy systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). McH-HGCN: Multi-curvature hyperbolic heterogeneous graph
convolutional network with type triplets. <em>NCA</em>, <em>35</em>(20),
15033–15049. (<a
href="https://doi.org/10.1007/s00521-023-08473-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing representation learning models for heterogeneous graphs depend on meta-paths, which requires domain-specific prior knowledge and reduces model practicality. In addition, real-world graphs usually conform to power-law distributions, and conventional graph models defined in Euclidean space lead to high distortion for such data. In this paper, we propose a Multi-curvature Hyperbolic Heterogeneous Graph Convolutional Network (McH-HGCN) based on the graph’s inherent type triplets. By selecting triplets as data units for message passing and defining the model in hyperbolic space, our model caters to the power-law properties of heterogeneous graphs while avoiding meta-paths dependence. To model the heterogeneity of the graph, we set distinct hyperbolic curvatures as learnable parameters for different types of nodes to obtain the optimal parameterized space mapping after training. Additionally, we introduce a dynamic heterogeneous attention mechanism to compute the attention weights for heterogeneous neighbor aggregation. Node classification and recommendation experiments with several heterogeneous graph datasets show that our model outperforms state-of-the-art methods on multiple datasets, achieving excellent performance without relying on meta-paths.},
  archive      = {J_NCA},
  author       = {Liu, Yanxi and Lang, Bo},
  doi          = {10.1007/s00521-023-08473-5},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15033-15049},
  shortjournal = {Neural Comput. Appl.},
  title        = {McH-HGCN: Multi-curvature hyperbolic heterogeneous graph convolutional network with type triplets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoConGAN: Cooperative contrastive learning for few-shot
cross-domain heterogeneous face translation. <em>NCA</em>,
<em>35</em>(20), 15019–15032. (<a
href="https://doi.org/10.1007/s00521-023-08518-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherently uneven informative setting in heterogeneous face images makes heterogeneous face translation challenging for synthesizing the analogous face image which preserves the identity of the input image from the source domain and fits the style of the reference image from the target domain. While effective, current methods require access to images with the same identity in both the source and target domains at training time. However, this is a rigid restriction, and the identities from the source domain may not be seen in the target domain, which limits the performance of translation and heterogeneous face recognition. Motivated by the human capability of picking up the essence of a novel face from a small number of examples and generalizing from there, we seek a few-shot, unsupervised diverse face-to-face translation framework that works on previously unseen identities that are specified, at training and testing time, only by a few example images. Besides, two issues have to be solved in this framework: the identity consistency and face diversity. We therefore propose a novel cooperative contrastive loss, which can jointly encourage identity diversity and preserve identity consistency. Through extensive experimental validation and comparisons to several baseline methods on benchmark datasets, we verify the effectiveness of the proposed framework.},
  archive      = {J_NCA},
  author       = {Zhang, Yinghui and Hu, Wansong and Sun, Bo and He, Jun and Yu, Lejun},
  doi          = {10.1007/s00521-023-08518-9},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15019-15032},
  shortjournal = {Neural Comput. Appl.},
  title        = {CoConGAN: Cooperative contrastive learning for few-shot cross-domain heterogeneous face translation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A contrastive knowledge graph embedding model with
hierarchical attention and dynamic completion. <em>NCA</em>,
<em>35</em>(20), 15005–15018. (<a
href="https://doi.org/10.1007/s00521-023-08514-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multi-head Graph Attention Networks (GATs) have achieved satisfactory performance in Knowledge Graph Embedding (KGE) tasks by imposing attention mechanism in local information. However, existing GATs based KGE approaches update entities with few neighbors is difficult to obtain structured semantic information, and these methods only use relations to model the local pairwise importance of entities, which result in missing semantic information of entity embedding. Meanwhile, different entities may have the same position in vector space, which result in poor performance of the model. To this end, we propose a contrastive knowledge graph embedding model named HADC with hierarchical attention network and dynamic completion. HADC dynamically adds the neighbors of entities to complement its local structural information, incorporates both entities’ and relations’ importance in any given entity’s neighborhood, and proposes a contrastive learning-based loss function to distinguish the position of positive and negative samples in vector space. Different experiments on three standard datasets confirm the effectiveness of our innovations, and the performance of our proposed HADC is significantly improved compared to the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Shang, Bin and Zhao, Yinliang and Liu, Jun and Liu, Yifan and Wang, Chenxin},
  doi          = {10.1007/s00521-023-08514-z},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {15005-15018},
  shortjournal = {Neural Comput. Appl.},
  title        = {A contrastive knowledge graph embedding model with hierarchical attention and dynamic completion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective chaos game optimization. <em>NCA</em>,
<em>35</em>(20), 14973–15004. (<a
href="https://doi.org/10.1007/s00521-023-08432-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Chaos Game Optimization (CGO) has only recently gained popularity, but its effective searching capabilities have a lot of potential for addressing single-objective optimization issues. Despite its advantages, this method can only tackle problems formulated with one objective. The multi-objective CGO proposed in this study is utilized to handle the problems with several objectives (MOCGO). In MOCGO, Pareto-optimal solutions are stored in a fixed-sized external archive. In addition, the leader selection functionality needed to carry out multi-objective optimization has been included in CGO. The technique is also applied to eight real-world engineering design challenges with multiple objectives. The MOCGO algorithm uses several mathematical models in chaos theory and fractals inherited from CGO. This algorithm&#39;s performance is evaluated using seventeen case studies, such as CEC-09, ZDT, and DTLZ. Six well-known multi-objective algorithms are compared with MOCGO using four different performance metrics. The results demonstrate that the suggested method is better than existing ones. These Pareto-optimal solutions show excellent convergence and coverage.},
  archive      = {J_NCA},
  author       = {Khodadadi, Nima and Abualigah, Laith and Al-Tashi, Qasem and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-023-08432-0},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14973-15004},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective chaos game optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An automatic improved facial expression recognition for
masked faces. <em>NCA</em>, <em>35</em>(20), 14963–14972. (<a
href="https://doi.org/10.1007/s00521-023-08498-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic facial expression recognition (AFER), sometimes referred to as emotional recognition, is important for socializing. Automatic methods in the past two years faced challenges due to Covid-19 and the vital wearing of a mask. Machine learning techniques tremendously increase the amount of data processed and achieved good results in such AFER to detect emotions; however, those techniques are not designed for masked faces and thus achieved poor recognition. This paper introduces a hybrid convolutional neural network aided by a local binary pattern to extract features in an accurate way, especially for masked faces. The basic seven emotions classified into anger, happiness, sadness, surprise, contempt, disgust, and fear are to be recognized. The proposed method is applied on two datasets: the first represents CK and CK +, while the second represents M-LFW-FER. Obtained results show that emotion recognition with a face mask achieved an accuracy of 70.76\% on three emotions. Results are compared to existing techniques and show significant improvement.},
  archive      = {J_NCA},
  author       = {ELsayed, Yasmeen and ELSayed, Ashraf and Abdou, Mohamed A.},
  doi          = {10.1007/s00521-023-08498-w},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14963-14972},
  shortjournal = {Neural Comput. Appl.},
  title        = {An automatic improved facial expression recognition for masked faces},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint multi-view character embedding model for named entity
recognition of chinese car reviews. <em>NCA</em>, <em>35</em>(20),
14947–14962. (<a
href="https://doi.org/10.1007/s00521-023-08476-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) has always been an important research task in information extraction and knowledge graph construction. Due to the randomness of Chinese user-generated reviews, character substitution and informal expression are very common. Its widespread phenomenon leads to that Chinese car reviews NER is still a major challenge. In this paper, we propose a joint multi-view character embedding model for Chinese NER (JMCE-CNER) of car reviews. Firstly, deeper character features are extracted from pronunciation, radical, and glyph views to generate the multi-view character embedding. Secondly, a car domain dictionary is constructed for providing accurate word-level information. Thirdly, the multi-view character embedding and the word-level embedding are jointly fed into the deep learning model to perform the Chinese car reviews NER. The experimental datasets of Chinese car reviews are obtained by manual annotation, containing four types of entities, namely brand, model, attribute and structure of the car. The experimental results on the Chinese car review datasets demonstrate that our proposed model achieves the optimal performance compared with the other state-of-the-art models. Furthermore, the model substantially reduces the impact of character substitution and informal expression on performing NER tasks.},
  archive      = {J_NCA},
  author       = {Ding, Jiaming and Xu, Wenping and Wang, Anning and Zhao, Shuangyao and Zhang, Qiang},
  doi          = {10.1007/s00521-023-08476-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14947-14962},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint multi-view character embedding model for named entity recognition of chinese car reviews},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding the influence of news on society decision
making: Application to economic policy uncertainty. <em>NCA</em>,
<em>35</em>(20), 14929–14945. (<a
href="https://doi.org/10.1007/s00521-023-08438-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abundance of digital documents offers a valuable chance to gain insights into public opinion, social structure, and dynamics. However, the scale and volume of these digital collections makes manual analysis approaches extremely costly and not scalable. In this paper, we study the potential of using automated methods from natural language processing and machine learning, in particular weak supervision strategies, to understand how news influence decision making in society. Besides proposing a weak supervision solution for the task, which replaces manual labeling to a certain extent, we propose an improvement of a recently published economic index. This index is known as economic policy uncertainty (EPU) index and has been shown to correlate to indicators such as firm investment, employment, and excess market returns. In summary, in this paper, we present an automated data efficient approach based on weak supervision and deep learning (BERT + WS) for identification of news articles about economical uncertainty and adapt the calculation of EPU to the proposed strategy. Experimental results reveal that our approach (BERT + WS) improves over the baseline method centered in keyword search, which is currently used to construct the EPU index. The improvement is over 20 points in precision, reducing the false positive rate typical to the use of keywords.},
  archive      = {J_NCA},
  author       = {Trust, Paul and Zahran, Ahmed and Minghim, Rosane},
  doi          = {10.1007/s00521-023-08438-8},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14929-14945},
  shortjournal = {Neural Comput. Appl.},
  title        = {Understanding the influence of news on society decision making: Application to economic policy uncertainty},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Text classification on heterogeneous information network via
enhanced GCN and knowledge. <em>NCA</em>, <em>35</em>(20), 14911–14927.
(<a href="https://doi.org/10.1007/s00521-023-08494-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks-based text classification methods have shown impressive success in further improving the classification results by considering the structural relationship between words and texts. However, existing GCN-based text classification methods tend to ignore the semantic representation of the node and the global structural information among nodes. Besides, only the word granularity information within the text, i.e., endogenous source, is used to represent the text. Furthermore, the existing graph convolutional network approaches are faced with major challenges to handle large and dense graphs, i.e., neighbor explosion and noisy inputs. To address these shortcomings, this paper proposes an inductive learning-based text classification method that utilizes representation learning on heterogeneous information networks and exogenous knowledge. Firstly, a weighted heterogeneous information network for text (HINT) is constructed by introducing exogenous knowledge, in which the node types cover text, entities and words. The unstructured text is represented as a structured heterogeneous information network, which expands the granularity of text features and makes full use of the exogenous structural information and explicit semantic information to enhance the interpretability of text information. Besides, we also enhanced the graph neural network against the challenges of neighbor explosion and noisy inputs derived from HINT using two strategies: graph sampling and Dropedge, for semi-supervised learning with improved classification performance. The effectiveness of our model is demonstrated by examining four publicly available text classification datasets. Based on experimental results, our approach achieves state-of-the-art performance on the text classification datasets.},
  archive      = {J_NCA},
  author       = {Li, Hui and Yan, Yan and Wang, Shuo and Liu, Juan and Cui, Yunpeng},
  doi          = {10.1007/s00521-023-08494-0},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14911-14927},
  shortjournal = {Neural Comput. Appl.},
  title        = {Text classification on heterogeneous information network via enhanced GCN and knowledge},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-output incremental back-propagation. <em>NCA</em>,
<em>35</em>(20), 14897–14910. (<a
href="https://doi.org/10.1007/s00521-023-08490-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques can form generalized models that can solve any problem that is not solvable by traditional approaches. It explains the omnipresence of deep learning models across all domains. However, a lot of time is spent on finding the optimal hyperparameters to help the model generalize and give the highest accuracy. This paper investigates a proposed model incorporating hybrid layers and a novel approach for weight initialization aimed at—(1) Reducing the overall trial and error time spent in finding the optimal number of layers by providing the necessary insights. (2) Reducing the randomness in weight initialization with the help of a novel incremental backpropagation based model architecture. The model, along with the principal component analysis-based initialization, substantially provides a stable weight initialization, thereby improving the train and test performance and speeding up the process of convergence to an optimal solution. Furthermore, three data sets were tested on the proposed approach, and they outperformed the state-of-the-art initialization methods.},
  archive      = {J_NCA},
  author       = {Chaudhari, Rachana and Agarwal, Dhwani and Ravishankar, Kritika and Masand, Nikita and Sambhe, Vijay K. and Udmale, Sandeep S.},
  doi          = {10.1007/s00521-023-08490-4},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14897-14910},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-output incremental back-propagation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy adaptive event-triggered output feedback control of
electro-hydraulic system. <em>NCA</em>, <em>35</em>(20), 14885–14896.
(<a href="https://doi.org/10.1007/s00521-023-08469-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers a fuzzy adaptive event-triggered control design problem for electro-hydraulic systems. The addressed electro-hydraulic system contains immeasurable states and unknown nonlinear dynamics. Fuzzy logic systems (FLSs) are utilized to model the controlled electro-hydraulic system, and a state observer is formulated to get the estimations of the immeasurable states. Subsequently, a novel event-triggered strategy is introduced by using first-order filter technique, which can reduce the frequent updating of the voltage input. Then, by constructing composite Lyapunov functions, an observer-based fuzzy adaptive event-triggered control method is presented. The stability of the controlled electro-hydraulic system and the convergence of the tracking error are proved. Finally, the computer-simulated studies confirm the effectiveness of the presented control method.},
  archive      = {J_NCA},
  author       = {Jiang, Chenyang and Tong, Shao-cheng and Dai, Wei},
  doi          = {10.1007/s00521-023-08469-1},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14885-14896},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy adaptive event-triggered output feedback control of electro-hydraulic system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph-based superframework for mixture model estimation
using EM: An analysis of US wholesale electricity markets. <em>NCA</em>,
<em>35</em>(20), 14867–14883. (<a
href="https://doi.org/10.1007/s00521-023-08468-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fully unsupervised graph-based superframework is proposed to handle the EM initialization problem for estimating mixture models on financial time series. Using a complex network approach that links time series and graphs, the graph-structured information derived from the observed data is exploited to produce a meaningful starting point for the EM algorithm. It is shown that structural information derived by complex graphs can definitely capture time series behavior and nonlinear relationships between different observations. The proposed methodology is employed to estimate Gaussian mixture models on US wholesale electricity market prices using two different configurations of the superframework. The obtained results show that the proposed methodology performs better than conventional initialization methods, such as K-means based techniques. The improvements are significant on the overall representation of the empirical distribution of log-returns and, in particular, on the first four moments. Moreover, this approach has a high degree of generalization and flexibility, exploiting graph manipulation and employing functional operating blocks, which can be adapted to very different empirical situations.},
  archive      = {J_NCA},
  author       = {Mari, Carlo and Baldassari, Cristiano},
  doi          = {10.1007/s00521-023-08468-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14867-14883},
  shortjournal = {Neural Comput. Appl.},
  title        = {A graph-based superframework for mixture model estimation using EM: An analysis of US wholesale electricity markets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A lightweight convolutional neural network for disease
detection of fruit leaves. <em>NCA</em>, <em>35</em>(20), 14855–14866.
(<a href="https://doi.org/10.1007/s00521-023-08496-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases are one of the major threats to the economy and food security of a country. Detection of such diseases timely and accurately on large scale is prone to human error. Techniques like machine learning (ML) and deep learning (DL) provide alternatives to build automated models that can detect such diseases efficiently. Several researchers have used deep learning techniques for plant disease detection. Fruit crops are major part of agricultural production. This paper proposes a lightweight and accurate deep learning model based on convolutional neural network (CNN) for the detection of diseased leaves in banana, guava and mango fruit crops. The model is proposed with the concept of feature reuse at three different levels. The model was trained using open database which consists of eight distinct classes of diseased and healthy leaves from three different fruit species. From the experiment, it was found that the model uses 101,000 numbers of parameters and achieves 99.14\% success rate for disease leaves identification. Also, it outperforms 15 different state-of-the-art pre-trained models, namely VGG16, VGG19, ResNet50, ResNet50V2, ResNet152, ResNet152V2, InceptionV3, InceptionResNetV2, Xception, DenseNet121, DenseNet169, DenseNet201, MobileNetV2, ConvNeXtBase and ConvNeXtLarge, in terms of both accuracy and model complexity.},
  archive      = {J_NCA},
  author       = {Hari, Pragya and Singh, Maheshwari Prasad},
  doi          = {10.1007/s00521-023-08496-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14855-14866},
  shortjournal = {Neural Comput. Appl.},
  title        = {A lightweight convolutional neural network for disease detection of fruit leaves},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new hand-modeled learning framework for driving fatigue
detection using EEG signals. <em>NCA</em>, <em>35</em>(20), 14837–14854.
(<a href="https://doi.org/10.1007/s00521-023-08491-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fatigue detection is a critical application area for machine learning, and variable input data have been utilized to detect fatigue. One of the most commonly used inputs for fatigue detection is electroencephalography (EEG) signals. The main objective of this study is to accurately detect fatigue using a hand-crafted framework. To achieve this, a new signal classification framework has been proposed, and its performance has been tested on an EEG fatigue detection dataset. Wavelet packet decomposition with 16 mother wavelet functions has been utilized to extract features from the frequency domain and create a multilevel feature extraction method to calculate frequency subbands. To generate classification results, two validation techniques, tenfold cross-validation and leave-one-subject-out (LOSO) validation, have been applied to attain robust classification results. The proposed framework achieved high classification performance with 99.90\% and 82.08\% classification accuracies using tenfold CV and LOSO CV, respectively. Furthermore, the classification performance of each used method in our framework has been analyzed to understand the driving fatigue classification effect of the machine learning functions used. The proposed framework attained superior classification results, demonstrating its efficacy in accurately detecting fatigue.},
  archive      = {J_NCA},
  author       = {Dogan, Sengul and Tuncer, Ilknur and Baygin, Mehmet and Tuncer, Turker},
  doi          = {10.1007/s00521-023-08491-3},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14837-14854},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new hand-modeled learning framework for driving fatigue detection using EEG signals},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Color constancy for non-uniform illumination estimation with
variable number of illuminants. <em>NCA</em>, <em>35</em>(20),
14825–14835. (<a
href="https://doi.org/10.1007/s00521-023-08487-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image white-balancing is an integral part of every camera’s processing pipeline. White-balancing is used to remove illumination chromaticity from an image. Most research in this field has been limited to images with a single uniform illuminant. In this paper, we introduce a novel method for illumination estimation for situations where the scene is illuminated by a variable number of different illuminants and where the illumination in the scene can be non-uniform. The proposed method uses a lightweight convolutional neural network that achieves state-of-the-art results. The method performs illumination estimation on a patch-by-patch basis. We use the assumption that only one illuminant affects each patch since they are so small. Unlike other such methods, our method uses features extracted from the entire image to perform patch illumination estimation. The paper also shows how the image features improve method accuracy with a minimal increase in complexity. The proposed method has around 42 k parameters, and it was tested on three different cameras from the Large-Scale Multi-Illuminant dataset.},
  archive      = {J_NCA},
  author       = {Domislović, Ilija and Vršnjak, Donik and Subašić, Marko and Lončarić, Sven},
  doi          = {10.1007/s00521-023-08487-z},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14825-14835},
  shortjournal = {Neural Comput. Appl.},
  title        = {Color constancy for non-uniform illumination estimation with variable number of illuminants},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GLUE analysis of meteorological-based crop coefficient
predictions to derive the explicit equation. <em>NCA</em>,
<em>35</em>(20), 14799–14824. (<a
href="https://doi.org/10.1007/s00521-023-08466-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crop coefficient (Kc) is a scaling factor to calculate crop evapotranspiration (ETc). Accurate prediction of Kc affects planning to allocate water resources, especially in arid and semi-arid areas with limited water sources availability. The conventional FAO approach has some limited applications due to using plant characteristics. However, existing artificial intelligence approaches have high performances, but encounter some instability in prediction. In the present study, the generalized likelihood uncertainty estimation (GLUE) approach was applied to assess uncertainties arising from both model structure and input parameters. In addition, this study aims to derive the explicit predictive and usable equation for calculating the monthly Kc of maize. The equations were developed from the best hybrid MLP model using minimal meteorological data in four regions of Egypt. For this, the predictive utility of MLP-based models that hybridized with meta-heuristic optimization algorithms was examined. The rat swarm optimization (RSO), firefly algorithm (FFA), bat algorithm (BA), and genetic algorithm (GA) hybridized with MLP (MLP-RSO, MLP-FFA, MLP-BA, and MLP-GA) are used as equation derivation tools. The results showed that a unique hybrid Gamma Test-RSO is a powerful approach for determining the optimal combination (Tmax, Tmin, Rs) as the best input vector. The results showed that the hybrid MLP-RSO model decreased the average RMSE by 13.87, 39.95, 45.68, and 53.09\% than MLP-BA, MLP-FFA, MLP-GA, and MLP models, respectively. In addition, the uncertainty results showed that the Kc predictions were more stable and confident in MLP-RSO, while the average of 95PPU covered 94.5 and 91.5\% of actual Kc for input parameters and model structure uncertainties, respectively. In conclusion, the developed hybrid model and the techniques illustrated in the current study suggest substantial benefits for other researchers to derive mathematical equations from easily available meteorological variables in different regions and climates. Also, the findings provide a fundamental guideline for the local water users and agricultural development planners to achieve accurate and fast irrigation scheduling.},
  archive      = {J_NCA},
  author       = {Elbeltagi, Ahmed and Seifi, Akram and Ehteram, Mohammad and Zerouali, Bilel and Vishwakarma, Dinesh Kumar and Pandey, Kusum},
  doi          = {10.1007/s00521-023-08466-4},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14799-14824},
  shortjournal = {Neural Comput. Appl.},
  title        = {GLUE analysis of meteorological-based crop coefficient predictions to derive the explicit equation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deformable registration of multimodal retinal images using a
weakly supervised deep learning approach. <em>NCA</em>, <em>35</em>(20),
14779–14797. (<a
href="https://doi.org/10.1007/s00521-023-08454-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are different retinal vascular imaging modalities widely used in clinical practice to diagnose different retinal pathologies. The joint analysis of these multimodal images is of increasing interest since each of them provides common and complementary visual information. However, if we want to facilitate the comparison of two images, obtained with different techniques and containing the same retinal region of interest, it will be necessary to make a previous registration of both images. Here, we present a weakly supervised deep learning methodology for robust deformable registration of multimodal retinal images, which is applied to implement a method for the registration of fluorescein angiography (FA) and optical coherence tomography angiography (OCTA) images. This methodology is strongly inspired by VoxelMorph, a general unsupervised deep learning framework of the state of the art for deformable registration of unimodal medical images. The method was evaluated in a public dataset with 172 pairs of FA and superficial plexus OCTA images. The degree of alignment of the common information (blood vessels) and preservation of the non-common information (image background) in the transformed image were measured using the Dice coefficient (DC) and zero-normalized cross-correlation (ZNCC), respectively. The average values of the mentioned metrics, including the standard deviations, were DC = 0.72  ±  0.10 and ZNCC = 0.82  ±  0.04. The time required to obtain each pair of registered images was 0.12 s. These results outperform rigid and deformable registration methods with which our method was compared.},
  archive      = {J_NCA},
  author       = {Martínez-Río, Javier and Carmona, Enrique J. and Cancelas, Daniel and Novo, Jorge and Ortega, Marcos},
  doi          = {10.1007/s00521-023-08454-8},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14779-14797},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deformable registration of multimodal retinal images using a weakly supervised deep learning approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computer-aided methods for combating covid-19 in prevention,
detection, and service provision approaches. <em>NCA</em>,
<em>35</em>(20), 14739–14778. (<a
href="https://doi.org/10.1007/s00521-023-08612-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The infectious disease Covid-19 has been causing severe social, economic, and human suffering across the globe since 2019. The countries have utilized different strategies in the last few years to combat Covid-19 based on their capabilities, technological infrastructure, and investments. A massive epidemic like this cannot be controlled without an intelligent and automatic health care system. The first reaction to the disease outbreak was lockdown, and researchers focused more on developing methods to diagnose the disease and recognize its behavior. However, as the new lifestyle becomes more normalized, research has shifted to utilizing computer-aided methods to monitor, track, detect, and treat individuals and provide services to citizens. Thus, the Internet of things, based on fog-cloud computing, using artificial intelligence approaches such as machine learning, and deep learning are practical concepts. This article aims to survey computer-based approaches to combat Covid-19 based on prevention, detection, and service provision. Technically and statistically, this article analyzes current methods, categorizes them, presents a technical taxonomy, and explores future and open issues.},
  archive      = {J_NCA},
  author       = {Rezazadeh, Bahareh and Asghari, Parvaneh and Rahmani, Amir Masoud},
  doi          = {10.1007/s00521-023-08612-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14739-14778},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computer-aided methods for combating covid-19 in prevention, detection, and service provision approaches},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent heart disease prediction system based on
swarm-artificial neural network. <em>NCA</em>, <em>35</em>(20),
14723–14737. (<a
href="https://doi.org/10.1007/s00521-021-06124-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate prediction of cardiovascular disease is an essential and challenging task to treat a patient efficiently before occurring a heart attack. In recent times, various intelligent healthcare frameworks have been designed with different machine learning and swarm optimization techniques for cardiovascular disease prediction. However, most of the existing strategies failed to achieve higher accuracy for cardiovascular disease prediction due to the lack of data-recognized techniques and proper prediction methodology. Motivated by the existing challenges, in this paper, we propose an intelligent healthcare framework for predicting cardiovascular heart disease based on Swarm-Artificial Neural Network (Swarm-ANN) strategy. Initially, the proposed Swarm-ANN strategy randomly generates predefined numbers of Neural Networks (NNs) for training and evaluating the framework based on their solution consistency. Additionally, the NN populations are trained by two stages of weight changes and their weight is adjusted by a newly designed heuristic formulation. Finally, the weight of the neurons is modified by sharing the global best weight with other neurons and predicts the accuracy of cardiovascular disease. The proposed Swarm-ANN strategy achieves 95.78\% accuracy while predicting the cardiovascular disease of the patients from a benchmark dataset. The simulation results exhibit that the proposed Swarm-ANN strategy outperforms the standard learning techniques in terms of various performance matrices.},
  archive      = {J_NCA},
  author       = {Nandy, Sudarshan and Adhikari, Mainak and Balasubramanian, Venki and Menon, Varun G. and Li, Xingwang and Zakarya, Muhammad},
  doi          = {10.1007/s00521-021-06124-1},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14723-14737},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligent heart disease prediction system based on swarm-artificial neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning techniques for classification of
electroencephalogram (EEG) motor imagery (MI) signals: A review.
<em>NCA</em>, <em>35</em>(20), 14681–14722. (<a
href="https://doi.org/10.1007/s00521-021-06352-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain–computer interface (BCI) is an emerging technology that has the potential to revolutionize the world, with numerous applications ranging from healthcare to human augmentation. Electroencephalogram (EEG) motor imagery (MI) is among the most common BCI paradigms that have been used extensively in smart healthcare applications such as post-stroke rehabilitation and mobile assistive robots. In recent years, the contribution of deep learning (DL) has had a phenomenal impact on MI-EEG-based BCI. In this work, we systematically review the DL-based research for MI-EEG classification from the past ten years. This article first explains the procedure for selecting the studies and then gives an overview of BCI, EEG, and MI systems. The DL-based techniques applied in MI classification are then analyzed and discussed from four main perspectives: preprocessing, input formulation, deep learning architecture, and performance evaluation. In the discussion section, three major questions about DL-based MI classification are addressed: (1) Is preprocessing required for DL-based techniques? (2) What input formulations are best for DL-based techniques? (3) What are the current trends in DL-based techniques? Moreover, this work summarizes MI-EEG-based applications, extensively explores public MI-EEG datasets, and gives an overall visualization of the performance attained for each dataset based on the reviewed articles. Finally, current challenges and future directions are discussed.},
  archive      = {J_NCA},
  author       = {Altaheri, Hamdi and Muhammad, Ghulam and Alsulaiman, Mansour and Amin, Syed Umar and Altuwaijri, Ghadir Ali and Abdul, Wadood and Bencherif, Mohamed A. and Faisal, Mohammed},
  doi          = {10.1007/s00521-021-06352-5},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14681-14722},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning techniques for classification of electroencephalogram (EEG) motor imagery (MI) signals: A review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-enabled block scrambling algorithm for
securing telemedicine data of table tennis players. <em>NCA</em>,
<em>35</em>(20), 14667–14680. (<a
href="https://doi.org/10.1007/s00521-021-05988-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In sports, advance sensing technologies generate massive amount of unstructured telemedicine data that need to be refined for accurate diagnosis of underlying diseases. For accurate prediction of diseases and classification of athletes’ data, deep learning algorithms are frequently used at the cloud. However, the transmission of raw data of athletes to the cloud faces numerous challenges. Among them, security and privacy are a major challenge in view of the sensitive and personal information present within the unstructured data. In this paper, first we present a data block scrambling algorithm (without key management) for secured transmission and storage of ECG (electrocardiogram) data of table tennis players at the cloud. A small piece of original data stored at the cloud is used for scrambling the massive amount of remaining ECG data. The secured telemedicine data is then imported into Hadoop Distributed File System for data management, which is read by Spark framework to form Resilient Distributed Datasets. Finally, a deep learning approach is used that extracts useful features, learns the related information, and weights and sums the feature vectors at different layers for classification. Theoretical analysis proves that our proposed approach is highly robust and resilient to brute force attacks and at the same time has a much better accuracy, sensitivity, and specificity as compared to the existing approaches.},
  archive      = {J_NCA},
  author       = {Yang, Bo and Cheng, Bojin and Liu, Yixuan and Wang, Lijun},
  doi          = {10.1007/s00521-021-05988-7},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14667-14680},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-enabled block scrambling algorithm for securing telemedicine data of table tennis players},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aggregated decentralized down-sampling-based ResNet for
smart healthcare systems. <em>NCA</em>, <em>35</em>(20), 14653–14665.
(<a href="https://doi.org/10.1007/s00521-021-06234-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of the world’s population and urbanization, people are increasingly seeking higher-quality medical services to improve their lives. The classification method based on deep convolutional neural networks (CNNs) is widely used in smart healthcare systems along with advancements in communication and hardware technology. Unfortunately, for conventional deep CNN algorithms, most of the regions do not participate in the convolution operation, resulting in the loss of feature information and the correlation of information between the features. To address this issue, this paper proposes a new strategy of aggregation decentralized down-sampling to prevent the loss of feature information. The regions that are not involved in the convolution operation are re-convoluted and stacked onto depth information in the forward propagation layer and the short-circuit layer, ensuring gradual convergence of the feature map and avoiding the loss of feature information. The accuracy of the proposed residual network (ResNet) system for classification tasks showed an average improvement of 2.57\% compared with the conventional ResNet strategies.},
  archive      = {J_NCA},
  author       = {Jiang, Zhiwen and Ma, Ziji and Wang, Yaonan and Shao, Xun and Yu, Keping and Jolfaei, Alireza},
  doi          = {10.1007/s00521-021-06234-w},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14653-14665},
  shortjournal = {Neural Comput. Appl.},
  title        = {Aggregated decentralized down-sampling-based ResNet for smart healthcare systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Arrhythmia diagnosis of young martial arts athletes based on
deep learning for smart medical care. <em>NCA</em>, <em>35</em>(20),
14641–14652. (<a
href="https://doi.org/10.1007/s00521-021-06159-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular and cerebrovascular diseases are a serious threat to human health and increase the annual death ratio at a considerable pace. This is not uncommon even among teenagers and martial arts athletes. Due to the increased risk associated with strenuous exercise in the context of a quiescent cardiac abnormality, athletes have a higher rate of heart attack and stroke than their nonathletic colleagues. The mortality rate due to this disease is extremely high, which needs to be controlled at the initial stages. At present, the recognition and analysis of ECG signals is still an issue and requires an expert to analyse it and identify its hidden patterns. The most challenging aspect of ECG signal classification is the irregularities in the signals, which are critical for detecting patient status. Each heartbeat is made up of a variety of action impulse waveforms produced by various cardiac tissues. Classification of heartbeats is difficult because waveforms vary from person to person and are identified by certain features. At present, the automatic identification of ECG signals still requires manual design, which has low accuracy and cannot be widely used in clinical practice. This study proposes an intelligent system based on deep learning and machine learning methods to classify and diagnose ECG signals to improve their classification and recognition accuracy. It improves the detection ability of martial arts athletes’ arrhythmia disease and obtains accurate arrhythmia diagnosis information. MIT-BIH arrhythmia dataset has been used for the experimental analysis. The performance of the proposed scheme is evaluated with the help of various performance measures. We conduct comprehensive experiments, and the results show that the algorithms used in this paper are robust.},
  archive      = {J_NCA},
  author       = {Zhuang, Jing and Sun, Jianli and Yuan, Guoliang},
  doi          = {10.1007/s00521-021-06159-4},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14641-14652},
  shortjournal = {Neural Comput. Appl.},
  title        = {Arrhythmia diagnosis of young martial arts athletes based on deep learning for smart medical care},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis and design of dual-feature fusion neural network
for sports injury estimation model. <em>NCA</em>, <em>35</em>(20),
14627–14639. (<a
href="https://doi.org/10.1007/s00521-021-06151-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-level athletes participate in various events that need extreme fitness and stamina. Usually, after competitions, the athletes take part in systematic physical fitness and specialized skills training. The daily training sessions of an athlete are often of higher intensity level. This kind of long-term and high-intensity training affects an athlete both physically and mentally and overloads him/her, leading to sports injuries. As a result, an athlete is no longer capable to perform high-intensity training due to these injuries and unable to achieve the desired results in the competition. Therefore, the need for an intelligent system arises to evaluate, predict and detect sports injuries effectively. The significance of neural networks for target recognition motivates us to propose a novel dual-feature fusion neural network model for athlete injury estimation. Our proposed model solves the problem of feature loss by using a 1 × 1 convolution and hyperlink to form a dual-fusion structure to enhance effective discrimination. Multiple experiments have been performed using different classification models. The performance of the utilized models, including the proposed model, has been evaluated with the help of numerous performance evaluation metrics. Various preprocessing techniques have been used in this study. The proposed model attained an excellent classification accuracy of 97.0\%, a sensitivity of 95.70\%, and a specificity of 97.54\%. Experimental results show that the performance of the proposed model is much better than the rest of the classification models used in this study.},
  archive      = {J_NCA},
  author       = {Meng, Linsheng and Qiao, Endong},
  doi          = {10.1007/s00521-021-06151-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14627-14639},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analysis and design of dual-feature fusion neural network for sports injury estimation model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural network correlation learning mechanism for CT
brain tumor detection. <em>NCA</em>, <em>35</em>(20), 14611–14626. (<a
href="https://doi.org/10.1007/s00521-021-05841-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern medical clinics support medical examinations with computer systems which use Computational Intelligence on the way to detect potential health problems in more efficient way. One of the most important applications is evaluation of CT brain scans, where the most precise results come from deep learning approaches. In this article, we propose a novel correlation learning mechanism (CLM) for deep neural network architectures that combines convolutional neural network (CNN) with classic architecture. The support neural network helps CNN to find the most adequate filers for pooling and convolution layers. As a result, the main neural classifier learns faster and reaches higher efficiency. Results show that our CLM model is able to reach about 96\% accuracy, and about 95\% precision and recall. We have described our proposed mechanism and discussed numerical results to draw conclusions and show future works.},
  archive      = {J_NCA},
  author       = {Woźniak, Marcin and Siłka, Jakub and Wieczorek, Michał},
  doi          = {10.1007/s00521-021-05841-x},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14611-14626},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep neural network correlation learning mechanism for CT brain tumor detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-enabled radiologist in the loop: Novel AI-based framework
to augment radiologist performance for COVID-19 chest CT medical image
annotation and classification from pneumonia. <em>NCA</em>,
<em>35</em>(20), 14591–14609. (<a
href="https://doi.org/10.1007/s00521-022-07055-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A SARS-CoV-2 virus-specific reverse transcriptase-polymerase chain reaction (RT-PCR) test is usually used to diagnose COVID-19. However, this test requires up to 2 days for completion. Moreover, to avoid false-negative outcomes, serial testing may be essential. The availability of RT-PCR test kits is currently limited, highlighting the need for alternative approaches for the precise and rapid diagnosis of COVID-19. Patients suspected to be infected with SARS-CoV-2 can be assessed using chest CT scan images. However, CT images alone cannot be used for ruling out SARS-CoV-2 infection because individual patients may exhibit normal radiological results in the primary phases of the disease. A machine learning (ML)-based recognition and segmentation system was developed to spontaneously discover and compute infection areas in CT scans of COVID-19 patients. The computable assessment exhibited suitable performance for automatic infection region allocation. The ML models developed were suitable for the direct detection of COVID-19 (+). ML was confirmed to be a complementary diagnostic technique for diagnosing COVID-19(+) by forefront medical specialists. The complete manual delineation of COVID-19 often requires up to 225.5 min; however, the proposed RILML method decreases the delineation time to 7 min after four iterations of model updating.},
  archive      = {J_NCA},
  author       = {Ghayvat, Hemant and Awais, Muhammad and Bashir, A. K. and Pandya, Sharnil and Zuhair, Mohd and Rashid, Mamoon and Nebhen, Jamel},
  doi          = {10.1007/s00521-022-07055-1},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14591-14609},
  shortjournal = {Neural Comput. Appl.},
  title        = {AI-enabled radiologist in the loop: Novel AI-based framework to augment radiologist performance for COVID-19 chest CT medical image annotation and classification from pneumonia},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved deep learning mechanism for EEG recognition in
sports health informatics. <em>NCA</em>, <em>35</em>(20), 14577–14589.
(<a href="https://doi.org/10.1007/s00521-021-06118-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing number of studies indicate that concussed athletes may have long-term residual electroencephalography (EEG) defects that can last up to ten years after the injury. With the use of conventional concussion screening techniques, these abnormalities are often ignored. As a result, returning to sports earlier can result in recurrent concussions, raising the risk of recurrent concussions with more severe consequences. This study uses deep learning methods to analyze the EEG signals of athletes. It then proposes and designs a channel attention module connected to the input layer of the convolutional neural network (CNN). The proposed approach automatically learns the EEG signals of different channels for recognizing the contribution of the task. The CNN is then connected to the recurrent neural network (RNN) for further processing. Based on this approach, this study combines the residual unit and the channel attention model to propose a convolutional recurrent neural network (CRNN) structure that is highly effective for EEG signal recognition. In this study, the EEG dataset of the Stanford research project has been used for experimental analysis. The performance of the proposed scheme is evaluated with the help of various performance measures. The experimental result shows that the proposed model improves the recognition accuracy from 82.58\% of ResNet13 to 85.68\% and attained excellent recognition accuracy of 91.05\% by using CAMResNet13 + CRNN architecture.},
  archive      = {J_NCA},
  author       = {Zhao, Tong and Zhang, Jingyi and Wang, Zuocan and Alturki, Ryan},
  doi          = {10.1007/s00521-021-06118-z},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14577-14589},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved deep learning mechanism for EEG recognition in sports health informatics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Internet of things-enabled real-time health monitoring
system using deep learning. <em>NCA</em>, <em>35</em>(20), 14565–14576.
(<a href="https://doi.org/10.1007/s00521-021-06440-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart healthcare monitoring systems are proliferating due to the Internet of Things (IoT)-enabled portable medical devices. The IoT and deep learning in the healthcare sector prevent diseases by evolving healthcare from face-to-face consultation to telemedicine. To protect athletes’ life from life-threatening severe conditions and injuries in training and competitions, real-time monitoring of physiological indicators is critical. In this research work, we present a deep learning-based IoT-enabled real-time health monitoring system. The proposed system uses wearable medical devices to measure vital signs and apply various deep learning algorithms to extract valuable information. For this purpose, we have taken Sanda athletes as our case study. The deep learning algorithms help physicians properly analyze these athletes’ conditions and offer the proper medications to them, even if the doctors are away. The performance of the proposed system is extensively evaluated using a cross-validation test by considering various statistical-based performance measurement metrics. The proposed system is considered an effective tool that diagnoses dreadful diseases among the athletes, such as brain tumors, heart disease, cancer, etc. The performance results of the proposed system are evaluated in terms of precision, recall, AUC, and F1, respectively.},
  archive      = {J_NCA},
  author       = {Wu, Xingdong and Liu, Chao and Wang, Lijun and Bilal, Muhammad},
  doi          = {10.1007/s00521-021-06440-6},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14565-14576},
  shortjournal = {Neural Comput. Appl.},
  title        = {Internet of things-enabled real-time health monitoring system using deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A machine learning-enabled intelligent application for
public health and safety. <em>NCA</em>, <em>35</em>(20), 14551–14564.
(<a href="https://doi.org/10.1007/s00521-021-06301-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article uses a machine learning approach to analyze and detect burst signals in a smart healthcare system to protect and safeguard the public health. We consider the time-series electrocardiogram (ECG) waveforms for the detection of burst signals. For this purpose, we propose an intelligent differential correlation burst detection (DCBD) approach by establishing a mathematical model and deriving the analytical expressions to detect false alarm rate and missed detection rate in ECG signals. DCBD feeds the burst signals of a large-scale ECG waveform into various filters for noise removal, which are then passed through data augmentation to achieve high specificity and sensitivity. These waveforms are then segmented for feature extraction and machine learning (ML) classification. Finally, burst-free ECG waveforms are broadcast to a database server, where ML algorithms are used to detect the presence of any abnormal activities. Furthermore, the ECG signal is classified to a set of heart diseases using the well-known LSTM (Long Short-Term Memory) and CNN (Convolutional Neural Network) models. Our proposed approach highlights that the probability of false alarm rate is similar to that caused by pure noise within the ECG waveforms. Our evaluation, using numerical experiments, suggests that the accuracy of the LSTM based ECG signal classification could be approximately 11.7\% and 12.8\% improved, subsequently, using the proposed burst detection method.},
  archive      = {J_NCA},
  author       = {Yong, Zhang and Xiaoming, Zhang and Alshehri, Mohammad Dahman},
  doi          = {10.1007/s00521-021-06301-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14551-14564},
  shortjournal = {Neural Comput. Appl.},
  title        = {A machine learning-enabled intelligent application for public health and safety},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Segmentation of ultrasound image sequences by combing a
novel deep siamese network with a deformable contour model.
<em>NCA</em>, <em>35</em>(20), 14535–14549. (<a
href="https://doi.org/10.1007/s00521-022-07054-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformable contours are widely applied in medical image segmentation, which are usually derived from appearance cues in medical images. However, the performance of deformed contour is suppressed in ultrasonic image segmentation by the weak, misleading boundaries and the complex shapes of lesion regions. In this paper, a novel deformable contour model is proposed for segmenting ultrasound image sequences, which aims to utilize the powerful ability of deep learning network in learning of image features to help the deformable contour model resist weaknessses of ultrasound images. The deep learning network is designed as a densely connected siamese architecture. It trains a contrastive loss that serves as a boundary searching metric of a deformable contour to segment ultrasound image sequences. In this network, the densely residual blocks and the attention focused blocks are designed to make the network efficiently propagate features and focus on the lesion region, and the feature memory module stores and generates the prior features to aid the evolution of a deformable contour. Moreover, for resisting the impact of misleading or weak boundary, the shape similarity of lesion regions is used to as a shape prior and integrated into the framework of deformable contour to constrain the change of contours. The experimental results for the clinical ultrasound image sequences demonstrate that compared to the state-of-the-art methods, the proposed method can provide more accurate results in HIFU ultrasound images.},
  archive      = {J_NCA},
  author       = {Ni, Bo and Liu, Zhiyuan and Cai, Xiantao and Nappi, Michele and Wan, Shaohua},
  doi          = {10.1007/s00521-022-07054-2},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14535-14549},
  shortjournal = {Neural Comput. Appl.},
  title        = {Segmentation of ultrasound image sequences by combing a novel deep siamese network with a deformable contour model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated methods for diagnosis of parkinson’s disease and
predicting severity level. <em>NCA</em>, <em>35</em>(20), 14499–14534.
(<a href="https://doi.org/10.1007/s00521-021-06626-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advancements in information technology and bioinformatics have led to exceptional contributions in medical sciences. Extensive developments have been recorded for digital devices, thermometers, digital equipments and health monitoring systems for the automated disease diagnosis of different diseases. These automated systems assist doctors with accurate and efficient disease diagnosis. Parkinson’s disease is a neurodegenerative disorder that affects the nervous system. Over the years, numerous efforts have been reported for the efficient automatic detection of Parkinson’s disease. Different datasets including voice data samples, radiology images, and handwriting samples and gait specimens have been used for analysis and detection. Techniques such as machine learning and deep learning have been used broadly and reported promising results. This review paper aims to provide a comprehensive survey of the use of artificial intelligence for Parkinson’s disease diagnosis. The available datasets and their various properties are discussed in detail. Further, a thorough overview is provided for the existing algorithms, methods and approaches utilizing different datasets. Several key peculiarities and challenges are also provided based on the comprehensive literature review to diagnose a healthy or unhealthy person.},
  archive      = {J_NCA},
  author       = {Ayaz, Zainab and Naz, Saeeda and Khan, Naila Habib and Razzak, Imran and Imran, Muhammad},
  doi          = {10.1007/s00521-021-06626-y},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14499-14534},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated methods for diagnosis of parkinson’s disease and predicting severity level},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid machine learning approach for hypertension risk
prediction. <em>NCA</em>, <em>35</em>(20), 14487–14497. (<a
href="https://doi.org/10.1007/s00521-021-06060-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypertension is a primary or contributing cause for premature death in the entire world. As a matter of fact, there is a high prevalence and low control rates in low- and middle-income countries, such that the prevention and treatment of hypertension should remain a top priority in global health. In the recent years, the awareness, treatment, and control rates of hypertension patients in China have been significantly improved to 51.6\%, 45.8\%, and 16.8\%, respectively. However, those rates are still far from a satisfactory level. Clinical studies suggest that for people in the pre-clinical stage of hypertension or having the risk of hypertension, the progression of the disease may be significanly reduced through a change in lifestyle, or by an effective drug therapy. In this paper, we address risk prediction for hypertension in the next five years, and put forward a model merging KNN and LightGBM. Our approach allows us to predict the hypertension risk for a specific individual using features such as the age of the subject and blood indicators. Results shows that our model is reliable and achieves accuracy and recall rate over 86\% and 92\%, respectively.},
  archive      = {J_NCA},
  author       = {Fang, Min and Chen, Yingru and Xue, Rui and Wang, Huihui and Chakraborty, Nilesh and Su, Ting and Dai, Yuyan},
  doi          = {10.1007/s00521-021-06060-0},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14487-14497},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid machine learning approach for hypertension risk prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification and classification of pneumonia disease using
a deep learning-based intelligent computational framework. <em>NCA</em>,
<em>35</em>(20), 14473–14486. (<a
href="https://doi.org/10.1007/s00521-021-06102-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pneumonia is one of the hazardous diseases that lead to life insecurity. It needs to be diagnosed at the initial stages to prevent a person from more damage and help them save their lives. Various techniques are used to identify pneumonia, including chest X-ray, blood culture, sputum culture, fluid sample, bronchoscopy, and pulse oximetry. Chest X-ray is the most widely used method to diagnose pneumonia and is considered one of the most reliable approaches. To analyse chest X-ray images accurately, an expert radiologist needs expertise and experience in the desired domain. However, human-assisted approaches have some drawbacks: expert availability, treatment cost, availability of diagnostic tools, etc. Hence, the need for an intelligent and automated system comes into place that operates on chest X-ray images and diagnoses pneumonia. The primary purpose of technology is to develop algorithms and tools that assist humans and make their lives easier. This study proposes a scalable and interpretable deep convolutional neural network (DCNN) to identify pneumonia using chest X-ray images. The proposed modified DCNN model first extracts useful features from the images and then classifies them into normal and pneumonia classes. The proposed system has been trained and tested on chest X-ray images dataset. Various performance metrics have been utilized to inspect the stability and efficacy of the proposed model. The experimental result shows that the proposed model&#39;s performance is greater compared to the other state-of-the-art methodologies used to identify pneumonia.},
  archive      = {J_NCA},
  author       = {Yi, Rong and Tang, Lanying and Tian, Yuqiu and Liu, Jie and Wu, Zhihui},
  doi          = {10.1007/s00521-021-06102-7},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14473-14486},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification and classification of pneumonia disease using a deep learning-based intelligent computational framework},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Topical collection on machine learning for big data
analytics in smart healthcare systems. <em>NCA</em>, <em>35</em>(20),
14469–14471. (<a
href="https://doi.org/10.1007/s00521-023-08627-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Jan, Mian Ahmad and Song, Houbing and Khan, Fazlullah and Rehman, Ateeq Ur and Yang, Lie-Liang},
  doi          = {10.1007/s00521-023-08627-5},
  journal      = {Neural Computing and Applications},
  number       = {20},
  pages        = {14469-14471},
  shortjournal = {Neural Comput. Appl.},
  title        = {Topical collection on machine learning for big data analytics in smart healthcare systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Correction to: A genetic algorithm integrated with the
initial solution procedure and parameter tuning for capacitated p-median
problem. <em>NCA</em>, <em>35</em>(19), 14467. (<a
href="https://doi.org/10.1007/s00521-023-08564-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Oksuz, Mehmet Kursat and Buyukozkan, Kadir and Bal, Alperen and Satoglu, Sule Itir},
  doi          = {10.1007/s00521-023-08564-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14467},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: A genetic algorithm integrated with the initial solution procedure and parameter tuning for capacitated P-median problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction to: Exploring a q-learning-based chaotic naked
mole rat algorithm for s-box construction and optimization.
<em>NCA</em>, <em>35</em>(19), 14465. (<a
href="https://doi.org/10.1007/s00521-023-08416-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zamli, Kamal Z. and Din, Fakhrud and Alhadawi, Hussam S.},
  doi          = {10.1007/s00521-023-08416-0},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14465},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Exploring a Q-learning-based chaotic naked mole rat algorithm for S-box construction and optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IR <span class="math display"><sup>2</sup></span> net:
Information restriction and information recovery for accurate binary
neural networks. <em>NCA</em>, <em>35</em>(19), 14449–14464. (<a
href="https://doi.org/10.1007/s00521-023-08495-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight and activation binarization can efficiently compress deep neural networks and accelerate model inference, but they cause severe accuracy degradation. Existing optimization methods for binary neural networks (BNNs) focus on fitting full-precision networks to reduce quantization errors and suffer from a tradeoff between accuracy and efficiency. In contrast, considering information loss and the mismatch between model capacity and input information quantity caused by network binarization, we propose Information Restriction and Information Recovery Network (IR $$^2$$ Net) to stimulate the potential of BNNs and achieve improved network accuracy by restricting the input information and recovering feature information. The proposed approach includes (1) information restriction, which evaluates the feature information extracted from the input by a BNN, discards some of the information it cannot focus on, and reduces the amount of the input information to match the model capacity; and (2) information recovery: due to the information loss incurred during forward propagation, the extracted feature information of the network is not sufficient for supporting accurate classification. Shallow feature maps with richer information are selected, and these feature maps are fused with the final feature maps to recover the extracted feature information and further enhance the model capacity to match the amount of input information. In addition, the computational cost is reduced by streamlining the information recovery method to strike a better tradeoff between accuracy and efficiency. Experimental results demonstrate that our approach still achieves comparable accuracy even with a $$\sim$$ 10x floating-point operations (FLOPs) reduction for ResNet-18. The models and code are available at https://github.com/pingxue-hfut/IR2Net .},
  archive      = {J_NCA},
  author       = {Xue, Ping and Lu, Yang and Chang, Jingfei and Wei, Xing and Wei, Zhen},
  doi          = {10.1007/s00521-023-08495-z},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14449-14464},
  shortjournal = {Neural Comput. Appl.},
  title        = {IR $$^2$$ net: Information restriction and information recovery for accurate binary neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparison of deep convolution and least squares GANs for
diabetic retinopathy image synthesis. <em>NCA</em>, <em>35</em>(19),
14431–14448. (<a
href="https://doi.org/10.1007/s00521-023-08482-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inaccessibility to medical image datasets in today’s technology limits deep-learning studies in the healthcare field. Generative adversarial networks (GANs) can fill this gap by synthesizing data comparable to actual images. GAN is a generative-modeling approach that emulates dataset content using deep learning techniques. Vanilla GAN is not compatible enough to synthesize images, so variants have been developed. In this study, the performances of the deep convolutional GAN (DCGAN) using the sigmoid-based cross-entropy loss function and the least squares GAN (LSGAN) using the mean square error function on diabetic retinopathy images were analyzed. Inception score, which measures visual acuity, and Frechet inception distance, which calculates structural similarity, were used to validate the qualitative results of the generated images. In detailed analyzes, the DCGAN model performed better than the LSGAN model. The evaluations made depend on the loss of generator and discriminator, classification accuracy, quality of generated images and training epoch of the models. As a result, were reported the effect of changing hyperparameters in DCGAN and LSGAN models and the compatibility of the produced images with the quantitative results.},
  archive      = {J_NCA},
  author       = {Ataş, İsa},
  doi          = {10.1007/s00521-023-08482-4},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14431-14448},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparison of deep convolution and least squares GANs for diabetic retinopathy image synthesis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drift speed adaptive memristor model. <em>NCA</em>,
<em>35</em>(19), 14419–14430. (<a
href="https://doi.org/10.1007/s00521-023-08401-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different memristive devices have different characteristic curves; how to describe and simulate various kinds of memristive devices with a unified model is still a significant work. In this work, a new memristor model is presented—DSAM, drift speed adaptive memristor model. This model is composed of a linear i–v relation function and a speed adaptive state function. A detailed analysis of model parameters’ effect is proposed. It is shown that different parameters perform different drift speed curves, which can be adjusted to describe various memristive devices. The proposed model can also adapt to various voltage inputs. Finally, the model is tested in fitting different memristor devices with an average error of less than $$5.5\%$$ .},
  archive      = {J_NCA},
  author       = {Li, Ya and Xie, Lijun and Xiao, Pingdan and Zheng, Ciyan and Hong, Qinghui},
  doi          = {10.1007/s00521-023-08401-7},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14419-14430},
  shortjournal = {Neural Comput. Appl.},
  title        = {Drift speed adaptive memristor model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved hover-net for nuclear segmentation and
classification in histopathology images. <em>NCA</em>, <em>35</em>(19),
14403–14417. (<a
href="https://doi.org/10.1007/s00521-023-08394-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concurrent nuclear segmentation and classification in Hematoxylin &amp; Eosin-stained histopathology images are a crucial task in disease diagnosis and prognosis. Albeit recent advancement of deep learning models, this task remains challenging as each nucleus occupies a limited number of pixels, and nuclei have large intra-class variability and high inter-class similarities in morphology. In this work, we proposed a tissue region-guided dilated Hover-net (TRG-Dilated Hover-net) that consists of a tissue region segmentation model and a dilated Hover-net model. The latter incorporated the dilated convolution and the atrous spatial pyramid pooling feature pyramids to expand the receptive field; therefore, more information about nuclei and their spacial locations can be captured. Our method achieved the state-of-the-art performance on four benchmark datasets of various cancer types and the in-house curated Breast Cancer dataset.},
  archive      = {J_NCA},
  author       = {Wang, Ji and Qin, Lulu and Chen, Dan and Wang, Juan and Han, Bo-Wei and Zhu, Zexuan and Qiao, Guangdong},
  doi          = {10.1007/s00521-023-08394-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14403-14417},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved hover-net for nuclear segmentation and classification in histopathology images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DoubleU-NetPlus: A novel attention and context-guided dual
u-net with multi-scale residual feature fusion network for semantic
segmentation of medical images. <em>NCA</em>, <em>35</em>(19),
14379–14401. (<a
href="https://doi.org/10.1007/s00521-023-08493-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of the region of interest in medical images can provide an essential pathway for devising effective treatment plans for life-threatening diseases. It is still challenging for U-Net, and its modern state-of-the-art variants to effectively model the higher-level output feature maps of the convolutional units of the network mostly due to the presence of various scales of the region of interest, the intricacy of context environments, ambiguous boundaries, and multiformity of textures in medical images. In this paper, we exploit multi-contextual features and several attention strategies to increase networks’ ability to model discriminative feature representation for more accurate medical image segmentation, and we present a novel dual-stacked U-Net-based architecture named DoubleU-NetPlus. The DoubleU-NetPlus incorporates several architectural modifications. In particular, we integrate EfficientNetB7 as the feature encoder module, a newly designed multi-kernel residual convolution module, and an adaptive feature re-calibrating attention-based atrous spatial pyramid pooling module to progressively and precisely accumulate discriminative multi-scale high-level contextual feature maps and emphasize the salient regions. In addition, we introduce a novel triple attention gate module and a hybrid triple attention module to encourage selective modeling of relevant medical image features. Moreover, to mitigate the gradient vanishing issue while incorporating high-resolution features with deeper spatial details, the standard convolution operation is replaced with the attention-guided residual convolution operations, which enables the model to achieve effective and relevant feature maps from a significantly increased network depth. Empirical results confirm that the proposed model accomplishes superior semantic segmentation performance compared to other state-of-the-art approaches on six publicly available benchmark datasets of diverse modalities. The proposed network achieves a Dice score of 85.17\%, 99.34\%, 94.30\%, 96.40\%, 95.76\%, and 97.10\% on DRIVE, LUNA, BUSI, CVCclinicDB, 2018 DSB, and ISBI 2012 datasets.},
  archive      = {J_NCA},
  author       = {Ahmed, Md. Rayhan and Ashrafi, Adnan Ferdous and Ahmed, Raihan Uddin and Shatabda, Swakkhar and Islam, A. K. M. Muzahidul and Islam, Salekul},
  doi          = {10.1007/s00521-023-08493-1},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14379-14401},
  shortjournal = {Neural Comput. Appl.},
  title        = {DoubleU-NetPlus: A novel attention and context-guided dual U-net with multi-scale residual feature fusion network for semantic segmentation of medical images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of the emerging metaheuristic algorithms
on solving complex optimization problems. <em>NCA</em>, <em>35</em>(19),
14275–14378. (<a
href="https://doi.org/10.1007/s00521-023-08481-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scientific field of optimization has witnessed an increasing trend in the development of metaheuristic algorithms within the current decade. The vast majority of the proposed algorithms have been proclaimed as superior and highly efficient compared to their contemporary counterparts by their own developers, which should be verified on a set of benchmark cases if it is to give conducive insights into their true capabilities. This study completes a comprehensive investigation of the general optimization capabilities of the recently developed nature-inspired metaheuristic algorithms, which have not been thoroughly discussed in past literature studies due to their new emergence. To overcome this deficiency in the existing literature, optimization benchmark problems with different functional characteristics will be solved by some of the widely used recent optimizers. Unconstrained standard test functions comprised of thirty-four unimodal scalable optimization problems with varying dimensionalities have been solved by these competitive algorithms, and respective estimated solutions have been evaluated relying on the performance metrics defined by the statistical analysis of the predictive results. Convergence curves of the algorithms have been construed to observe the evolution trends of objective function values. To further delve into comprehensive analysis on unconstrained test cases, CEC 2013 problems have been considered for comparison tools since their resemblances of the following features of real-world complex algorithms. The optimization capabilities of eleven metaheuristics algorithms have been comparatively analyzed on twenty-eight multidimensional problems. Finally, fourteen complex engineering problems have been optimized by the algorithms to scrutinize their effectiveness on handling the imposed design constraints.},
  archive      = {J_NCA},
  author       = {Turgut, Oguz Emrah and Turgut, Mert Sinan and Kırtepe, Erhan},
  doi          = {10.1007/s00521-023-08481-5},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14275-14378},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic review of the emerging metaheuristic algorithms on solving complex optimization problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stacked denoising autoencoder for missing traffic data
reconstruction via mobile edge computing. <em>NCA</em>, <em>35</em>(19),
14259–14274. (<a
href="https://doi.org/10.1007/s00521-023-08475-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sensing system requires to periodically collect spatial–temporal traffic data distributed among road networks, which results in overhigh bandwidth consumption and storage cost in a large-scale road network. Several compressive sensing-based algorithms are proposed to reconstruct missing traffic data with limited traffic observation. However, there still exist great challenges to be addressed. First, these existing algorithms are always iteration-based, whose time complexity will explosively increase with the growth of network scale. Furthermore, these algorithms have to be re-executed even if only a small fraction of data changes, which is not suitable for dynamic traffic environments. To overcome these issues, we investigate a novel service architecture of traffic sensing based on mobile edge computing where collected data is pre-processed at the edge node and reconstructed at cloud servers, respectively. On this basis, we formulate the problem of Missing Traffic Data reconstruction (MTDR), which aims at maximizing data reconstruction accuracy within limited observation data. Further, we develop a deep-learning-based algorithm called stacked denoising autoencoder for MTDR (SDAE-MTDR), where three denoising autoencoders are trained in order and then stacked together for parameter fine-tuning based on cross-entropy-based loss function. Finally, we conduct comprehensive performance evaluation based on realistic vehicular traces and the simulation results demonstrate the superiority of the proposed algorithm compared with competitive solutions.},
  archive      = {J_NCA},
  author       = {Dai, Penglin and Luo, Jingtao and Zhao, Kangli and Xing, Huanlai and Wu, Xiao},
  doi          = {10.1007/s00521-023-08475-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14259-14274},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stacked denoising autoencoder for missing traffic data reconstruction via mobile edge computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classifying breast cancer using transfer learning models
based on histopathological images. <em>NCA</em>, <em>35</em>(19),
14243–14257. (<a
href="https://doi.org/10.1007/s00521-023-08484-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning algorithms are designed to learn from the data, where these require large amount of training dataset for accurate prediction. Recent studies have depicted that transfer learning-based DL approaches perform accurately in a variety of applications to create Computer-Aided Design (CAD) systems. These systems are used for the early detection and analysis of diseases such as lung cancer, brain tumor, and breast cancer using various modalities. Instead of developing neural network models from the scratch, pre-trained models are frequently utilized for DL-based tasks in computer vision as they diminish time. The effectiveness of transfer learning models without applying augmentation and preprocessing techniques to automate the classification of tumors is explained in this work. Seven transfer learning models (LENET, VGG16, DarkNet53, DarkNet19, ResNet50, Inception, and Xception) are implemented on BreakHis dataset for the tumor classification, where Xception computed the best accuracy of 83.07\%. Further, to attain the accuracy with unbalanced dataset, a new parameter named Balanced Accuracy (BAC) is best computed by DarkNet53 (87.17\%). This study will facilitate the researchers and medical practitioners to choose an accurate model for the classification of tumor with unbalanced dataset. It will aid medical professionals to efficiently and precisely classify the disease.},
  archive      = {J_NCA},
  author       = {Rana, Meghavi and Bhushan, Megha},
  doi          = {10.1007/s00521-023-08484-2},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14243-14257},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classifying breast cancer using transfer learning models based on histopathological images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-guided spatial–temporal graph relation network for
video-based person re-identification. <em>NCA</em>, <em>35</em>(19),
14227–14241. (<a
href="https://doi.org/10.1007/s00521-023-08477-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based person Re-Identification (Re-ID) is to re-identify video tracklets belonging to a specific person when reviewing this person from cross-view cameras. The key of this task is to effectively learn robust sequential feature representation under illumination changes, complicated backgrounds and viewpoint changes. Most existing methods could not explore the dynamic spatial–temporal relations of video sequences, making it impossible for them to efficiently utilize abundant spatial–temporal cues in videos. In this paper, we propose a spatial–temporal attention-guided graph relation network (STAGNet) for video-based person Re-ID. The STAGNet method has a spatial attention-guided graph relation (SAGR) module and a temporal attention-guided graph relation (TAGR) module sequentially. Specifically, in the SAGR module, we first design a multi-granularity spatial attention module to localize the parts of the pedestrian in each frame. Based on the obtained spatial attention masks, SAGR is used to capture the structured information of pedestrians. In the TAGR module, the self-attention module is used to rank images at first, and then a multi-granularity temporal graph network based on the sorted sequence is developed to mine discriminative sequence information. After optimizing these modules, our model is expected to finally obtain discriminative sequence-level features. Experiments have been conducted on three benchmarks (i.e., MARS, iLIDS-VID and PRID2011) to validate the effectiveness of the proposed method. The results indicate that the proposed method achieves state-of-the-art results.},
  archive      = {J_NCA},
  author       = {Qi, Yu and Ge, Hongwei and Pei, Wenbin and Liu, Yuxuan and Hou, Yaqing and Sun, Liang},
  doi          = {10.1007/s00521-023-08477-1},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14227-14241},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention-guided spatial–temporal graph relation network for video-based person re-identification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient framework for outfit compatibility prediction
towards occasion. <em>NCA</em>, <em>35</em>(19), 14213–14226. (<a
href="https://doi.org/10.1007/s00521-023-08431-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, in a communicating society, fashion is an integral part of a human life, and it is more comfortable and confident when people dress well. Outfit compatibility is not only a combination of different items but also regarding various aspects, such as style, user preferences, and specific occasions. Most of the existing works lead to address the outfit compatibility concerning only style or user preferences, and have no regard for occasions. In this paper, we propose an efficient method for both outfit compatibility and the fill-in-the-blank tasks according to specific occasions. To this end, we utilized an auxiliary classification branch to learn the significantly important features regarding specific occasions. Besides, a sequence to sequence approach is also applied to learn the relationship of different items along with a visual semantic space, which is able to learn the connection between visual features and their semantic presentation. To demonstrate the effectiveness of the proposed method, we conduct experiments on our newly collected Shoplook-Occasion dataset. The experimental results indicate that our proposed method improved the AUC metric from 0.02 to 0.15\% and from 0.5 to 4\% on accuracy, compared with other approaches for outfit compatibility problem conditioning on specific occasions.},
  archive      = {J_NCA},
  author       = {Vo, Anh H. and Le, Tung B. T. and Pham, Huy V. and Nguyen, Bao T.},
  doi          = {10.1007/s00521-023-08431-1},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14213-14226},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient framework for outfit compatibility prediction towards occasion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dependency-enhanced graph convolutional networks for
aspect-based sentiment analysis. <em>NCA</em>, <em>35</em>(19),
14195–14211. (<a
href="https://doi.org/10.1007/s00521-023-08384-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis aims to extract aspect and opinion terms, and identify the sentiment polarities for such terms. The majority of research has proposed effective methods in individual subtasks, and some multi-task learning models have been designed to deal with combining two subtasks, such as extracting aspect terms and opinions in pairs. Recently, there have been some studies on triple extraction tasks that attempt to simultaneously extract target terms (aspects, opinions) and sentiment polarities from a sentence. However, these studies ignore the directional dependency relations between terms and context, and the intrinsic dependence between these terms has not been well exploited. In this paper, we propose a novel dependency-enhanced graph convolutional network (DE-GCN) for multi-variate extraction tasks. We re-integrate the directional dependency relations in the graph convolution to reconstruct the time-series information representation. In addition, we construct a dependency aggregator to enhance dependency relations between contexts. We conduct experiments on extensive experiments and comparisons on these subtasks. Experimental results on four datasets show the effectiveness of our proposed model.},
  archive      = {J_NCA},
  author       = {Zhao, Meng and Yang, Jing and Shang, Fanshu},
  doi          = {10.1007/s00521-023-08384-5},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14195-14211},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dependency-enhanced graph convolutional networks for aspect-based sentiment analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Road surface classification using accelerometer and speed
data: Evaluation of a convolutional neural network model. <em>NCA</em>,
<em>35</em>(19), 14183–14194. (<a
href="https://doi.org/10.1007/s00521-023-08479-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the quality of road surfaces for maintenance has typically been an expensive exercise for local government agencies. This paper evaluates the feasibility of using accelerometer and speed data collected from on-board diagnostic (OBD-II) devices and labelled using the PASER system of road classification to classify road quality and identify poor stretches. An ordinal logistic model and a support vector machine (SVM) classifier were first trained on features created from raw data. The SVM and an artificial neural network (ANN) were then trained separately on the raw data parameters followed by a convolutional neural network (CNN) model. All models have comparable results in terms of overall classification accuracy on validation datasets (around 67\%) but the ANN and CNN models were superior in their ability to correctly identify ‘Poor’ and ‘Good’ stretches. The CNN model had the best performance among all models evaluated. The approach presented offers a low-cost method to map poor roads and identify stretches that require more attention as an alternative to more expensive traditional methods.},
  archive      = {J_NCA},
  author       = {Sabapathy, Ashwin and Biswas, Avik},
  doi          = {10.1007/s00521-023-08479-z},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14183-14194},
  shortjournal = {Neural Comput. Appl.},
  title        = {Road surface classification using accelerometer and speed data: Evaluation of a convolutional neural network model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). State-of-health estimation of lithium-ion battery based on
back-propagation neural network with adaptive hidden layer.
<em>NCA</em>, <em>35</em>(19), 14169–14182. (<a
href="https://doi.org/10.1007/s00521-023-08471-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reliability and safety of lithium-ion batteries (LIBs) are key issues in battery applications. Accurate prediction of the state-of-health (SOH) of LIBs can reduce or even avoid battery-related accidents. In this paper, a new back-propagation neural network (BPNN) is proposed to predict the SOH of LIBs. The BPNN uses as input the LIB voltage, current and temperature, as well as the charging time, since it is strongly correlated with the SOH. The number of hidden layer nodes is adaptively set based on the training data in order to improve the generalization capability of the BPNN. The effectiveness and robustness of the proposed scheme is verified using four distinct battery datasets and different training data. Experimental results show that the new BPNN is able to accurately predict the SOH of LIBs, revealing superiority when compared to other alternatives.},
  archive      = {J_NCA},
  author       = {Chen, Liping and Xu, Changcheng and Bao, Xinyuan and Lopes, António and Li, Penghua and Zhang, Chaolong},
  doi          = {10.1007/s00521-023-08471-7},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14169-14182},
  shortjournal = {Neural Comput. Appl.},
  title        = {State-of-health estimation of lithium-ion battery based on back-propagation neural network with adaptive hidden layer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Runtime analysis of some hybrid algorithms. <em>NCA</em>,
<em>35</em>(19), 14153–14167. (<a
href="https://doi.org/10.1007/s00521-023-08388-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid algorithm combines two or more individual algorithms in order to integrate the advantages of these individual algorithms. In recent years, a huge number of hybrid algorithms have been proposed, and their efficiencies have been demonstrated by experimental studies. However, few theoretical results that support the experimental conclusions are available. In this paper, we focus on theoretical investigation about the efficiency of hybrid algorithms for combinatorial optimization problems. We first analyze the runtime of three specific hybrid algorithms and their component algorithms on two instances. One is a well-known pseudo-Boolean function, and the other is an instance of a classical combinatorial optimization problem. We then theoretically investigate the relationship between the upper bounds of the expected runtime of three kinds of general hybrid algorithms and their component algorithms.},
  archive      = {J_NCA},
  author       = {Lai, Xinsheng and Zhou, Yuren},
  doi          = {10.1007/s00521-023-08388-1},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14153-14167},
  shortjournal = {Neural Comput. Appl.},
  title        = {Runtime analysis of some hybrid algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel extended li zeroing neural network for matrix
inversion. <em>NCA</em>, <em>35</em>(19), 14129–14152. (<a
href="https://doi.org/10.1007/s00521-023-08460-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improved activation function, termed extended sign-bi-power (Esbp), is proposed. An extension of the Li zeroing neural network (ELi-ZNN) based on the Esbp activation is derived to obtain the online solution of the time-varying inversion problem. A detailed theoretical analysis confirms that the new activation function accomplishes fast convergence in calculating the time-varying matrix inversion. At the same time, illustrative numerical experiments substantiate the excellent performance of the proposed activation function over the Li and tunable activation functions. Convergence properties and numerical behaviors of the proposed ELi-ZNN model are examined.},
  archive      = {J_NCA},
  author       = {Gerontitis, Dimitrios and Mo, Changxin and Stanimirović, Predrag S. and Tzekis, Panagiotis and Katsikis, Vasilios N.},
  doi          = {10.1007/s00521-023-08460-w},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14129-14152},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel extended li zeroing neural network for matrix inversion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new MPPT design using PV-BES system using modified sparrow
search algorithm based ANFIS under partially shaded conditions.
<em>NCA</em>, <em>35</em>(19), 14109–14128. (<a
href="https://doi.org/10.1007/s00521-023-08453-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, due to the increasing interest in renewable energy, modeling and practical research on Photovoltaic (PV) have been given much attention. Currently, the challenge of using PV systems is to reach the maximum power point (MPP) in order to increase their efficiency. Hence, extensive research has been done all over the world to develop the productivity of the PV system by properly tracking the MPP. In this regard, in this article, a new maximum power point tracking (MPPT) technique based on Modified Sparrow Search Algorithm and adaptive neuro-fuzzy inference system (ANFIS) is suggested. To implement the suggested MPPT method, two important steps must be taken into account. Firstly, in different conditions of radiation and temperature, the optimal voltage is obtained by mSSA algorithm. Then, the optimal voltage is achieved by the proposed ANFIS method based on different radiation conditions to find the MPP. In order to evaluate the proposed MPPT technique, simulations are done in MATLAB in different weather conditions and scenarios. The results indicate the suitable performance of the recommended mSSA-ANFIS-based MPPT controller in tracking the MPP and achieving the global optimum in different weather conditions by attaining 99.3\% efficiency.},
  archive      = {J_NCA},
  author       = {Alaas, Zuhair and Eltayeb, Galal eldin A. and Al-Dhaifallah, Mujahed and Latifi, Mohsen},
  doi          = {10.1007/s00521-023-08453-9},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14109-14128},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new MPPT design using PV-BES system using modified sparrow search algorithm based ANFIS under partially shaded conditions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental learning without looking back: A neural
connection relocation approach. <em>NCA</em>, <em>35</em>(19),
14093–14107. (<a
href="https://doi.org/10.1007/s00521-023-08448-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, artificial intelligence methods need to face more and more open application scenarios. They need to have the ability to continuously develop new skills and knowledge to respond to changes over time. However, how the learning system learns new tasks without affecting performance on old tasks remains a big challenge. In this work, we develop a learning system based on convolutional neural network (CNN) to implement the incremental learning mode for image classification tasks. Inspired by the way human learns, which includes abstracting learning experiences, keeping only key information in mind and forgetting trivial details, our proposed method contains a neural connection relocation mechanism to remove unimportant information from learned memory. And a mechanism composed of knowledge distillation and fine-tuning is also included to consolidate the learned knowledge using associations with the new task. To demonstrate the performance of our method, two pairs of image classification tasks are conducted with different CNN architectures. The experimental results show that our method performs better than the state of the art incremental learning methods.},
  archive      = {J_NCA},
  author       = {Liu, Yi and Wu, Xiang and Bo, Yuming and Zheng, Zejia and Yin, Mingfeng},
  doi          = {10.1007/s00521-023-08448-6},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14093-14107},
  shortjournal = {Neural Comput. Appl.},
  title        = {Incremental learning without looking back: A neural connection relocation approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural group recommendation based on a probabilistic
semantic aggregation. <em>NCA</em>, <em>35</em>(19), 14081–14092. (<a
href="https://doi.org/10.1007/s00521-023-08410-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation to groups of users is a challenging subfield of recommendation systems. Its key concept is how and where to make the aggregation of each set of user information into an individual entity, such as a ranked recommendation list, a virtual user, or a multi-hot input vector encoding. This paper proposes an innovative strategy where aggregation is made in the multi-hot vector that feeds the neural network model. The aggregation provides a probabilistic semantic, and the resulting input vectors feed a model that is able to conveniently generalize the group recommendation from the individual predictions. Furthermore, using the proposed architecture, group recommendations can be obtained by simply feedforwarding the pre-trained model with individual ratings; that is, without the need to obtain datasets containing group of user information, and without the need of running two separate trainings (individual and group). This approach also avoids maintaining two different models to support both individual and group learning. Experiments have tested the proposed architecture using three representative collaborative filtering datasets and a series of baselines; results show suitable accuracy improvements compared to the state of the art.},
  archive      = {J_NCA},
  author       = {Dueñas-Lerín, Jorge and Lara-Cabrera, Raúl and Ortega, Fernando and Bobadilla, Jesús},
  doi          = {10.1007/s00521-023-08410-6},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14081-14092},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural group recommendation based on a probabilistic semantic aggregation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boosting capuchin search with stochastic learning strategy
for feature selection. <em>NCA</em>, <em>35</em>(19), 14061–14080. (<a
href="https://doi.org/10.1007/s00521-023-08400-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technological revolution has made available a large amount of data with many irrelevant and noisy features that alter the analysis process and increase time processing. Therefore, feature selection (FS) approaches are used to select the smallest subset of relevant features. Feature selection is viewed as an optimization process for which meta-heuristics have been successfully applied. Thus, in this paper, a new feature selection approach is proposed based on an enhanced version of the Capuchin search algorithm (CapSA). In the developed FS approach, named ECapSA, three modifications have been introduced to avoid a lack of diversity, and premature convergence of the basic CapSA: (1) The inertia weight is adjusted using the logistic map, (2) sine cosine acceleration coefficients are added to improve convergence, and (3) a stochastic learning strategy is used to add more diversity to the movement of Capuchin and a levy random walk. To demonstrate the performance of ECapSA, different datasets are used, and it is compared with other well-known FS methods. The results provide evidence of the superiority of ECapSA among the tested datasets and competitive methods in terms of performance metrics.},
  archive      = {J_NCA},
  author       = {Abd Elaziz, Mohamed and Ouadfel, Salima and Ibrahim, Rehab Ali},
  doi          = {10.1007/s00521-023-08400-8},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14061-14080},
  shortjournal = {Neural Comput. Appl.},
  title        = {Boosting capuchin search with stochastic learning strategy for feature selection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective domain awareness and adaptation approach via mask
substructure for multi-domain neural machine translation. <em>NCA</em>,
<em>35</em>(19), 14047–14060. (<a
href="https://doi.org/10.1007/s00521-023-08377-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-domain adaptation of neural machine translation (NMT) aims to learn a unified seq2seq framework based on multi-domain data. Domain corpus data mixing is one of the most important ways for multi-domain NMT, which has been widely explored in many recent works. However, due to the limitation of data mixing strategy, it often suffers from catastrophic forgetting problem or domain shift problem. To this end, we propose a domain-aware NMT with mask substructure. The mask substructure is employed in both Transformer-encoder and Transformer-decoder to capture domain-specific representations for each domain, then a domain fusion strategy is adopted to obtain a multi-domain adaptive NMT model. Our domain fusion framework could share domain-invariant knowledge and maintain domain-specific knowledge. We conduct extensive experiments on multi-domain NMT dataset, and the experimental results show significant improvements over the state-of-the-art (SOTA) approaches by up to 1.1 BLEU points on 8 domains and up to 4.5 BLEU points on an unseen domain. Moreover, the in-depth analysis shows that our model can also effectively alleviate both catastrophic forgetting and domain shift problems.},
  archive      = {J_NCA},
  author       = {Huang, Shuanghong and Guo, Junjun and Yu, Zhengtao and Wen, Yonghua},
  doi          = {10.1007/s00521-023-08377-4},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14047-14060},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effective domain awareness and adaptation approach via mask substructure for multi-domain neural machine translation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New unified score functions and similarity measures for
non-standard fuzzy numbers: An extended TOPSIS method addressing risk
attitudes. <em>NCA</em>, <em>35</em>(19), 14029–14046. (<a
href="https://doi.org/10.1007/s00521-023-08467-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a new form of score function for both intuitionistic and picture fuzzy sets, which we term the weighted average membership function. By inserting both refusal and neutrality degrees for picture fuzzy sets, we extend the idea of modifying memberships by including hesitancy for intuitionistic fuzzy sets. This new representative membership function can be used to rank and defuzzify fuzzy numbers. Using this idea of updating the membership function allows us to consider all the knowledge that both fuzzy set generalizations can offer, similar to ordinary fuzzy concepts. Moreover, any method of handling uncertainty for standard fuzzy sets can be mimicked. The proposed convex combination type of score function is a generalization that produces special cases for some proper values of the function parameters and collects some linear score functions from the literature under one roof. Also, it provides an extended approach by incorporating decision behaviors into a more general scope. This paper addresses the applications of both assigning a single value to a non-standard fuzzy number and an extended TOPSIS method that considers decision makers’ optimism degrees with the aid of a newly defined similarity measure. To demonstrate its effectiveness, illustrative examples and simulation studies are presented.},
  archive      = {J_NCA},
  author       = {Akdemir, Hande Günay and Kocken, Hale Gonce},
  doi          = {10.1007/s00521-023-08467-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14029-14046},
  shortjournal = {Neural Comput. Appl.},
  title        = {New unified score functions and similarity measures for non-standard fuzzy numbers: An extended TOPSIS method addressing risk attitudes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Group learning algorithm: A new metaheuristic algorithm.
<em>NCA</em>, <em>35</em>(19), 14013–14028. (<a
href="https://doi.org/10.1007/s00521-023-08465-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are intelligent optimization techniques that lead the searching procedure through utilizing exploitation and exploration. Increasing the number of hard problems with big data sets has encouraged researchers to implement novel metaheuristics and hybrid the existing ones to improve their performance. Hence, in this work, a novel metaheuristic called group learning algorithm is proposed. The main inspiration of the algorithm emerged from the way individuals inside a group affect each other, and the effect of group leader on group members. The two main steps of optimization, exploration and exploitation are outlined through integrating the behaviors of group members and the group leader to complete the assigned task. The proposed work is evaluated against a number of benchmarks. The produced results of classical benchmarks are compared against PSO, GWO, TLBO, BA, ALO, and SSA. In general, compared to other participated algorithms, out of 19 classical benchmarks, the proposed work showed better results in 11. However, the second best algorithm which is SSA performed better in 4 out of 19 benchmarks. To further evaluate the ability of the algorithm to optimize large scale optimization problems CEC-C06 2019 benchmarks are utilized. In comparison to other participated algorithms, the proposed work produced better results in most of the cases. Additionally, the statistical tests confirmed the significance of the produced results. The results are evidence that the proposed algorithm has the ability to optimize various types of problems including large scale optimization problems.},
  archive      = {J_NCA},
  author       = {Rahman, Chnoor M.},
  doi          = {10.1007/s00521-023-08465-5},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {14013-14028},
  shortjournal = {Neural Comput. Appl.},
  title        = {Group learning algorithm: A new metaheuristic algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Response surface methodology-based multi-objective grey
relation optimization for impinging jet cooling with Al2O3/water
nanofluid on a curved surface. <em>NCA</em>, <em>35</em>(19),
13999–14012. (<a
href="https://doi.org/10.1007/s00521-023-08357-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a modelling procedure is followed to simultaneously optimize the heat transfer and entropy generation performance in the impinging jet flow on a convex surface. For this optimization study, numerical results of laminar nanofluid flow (Al2O3/water) having two different particle shape (blade and cylindrical) were used as inputs and optimum Nusselt number and total entropy generation parameters were obtained by using RSM-based multi-objective grey relation analysis. Different nanofluid volume fractions, target distance/nozzle diameter ratio (H/B) and Reynolds numbers were evaluated for the analysis. Each control variable has three levels except for the particle shape (blade and cylindrical). In total, forty CFD analyses have been performed based on these variables and the findings obtained by the RSM-based multi-objective grey relation analysis reveal that geometric differences and nanofluid properties have a considerable impact on the performance of jet impingement cooling. The results show that the H/B ratio has the greatest impact on heat transfer enhancement and entropy generation improvement on convex surface at laminar flow conditions. As a result of the optimization, the highest Nu number and the lowest entropy generation obtained by grey relation analysis were found to be 4.383 and 9.06 × 10–4 kj/kg K, respectively, for blade-shaped alumina nanofluid at H/B = 2.},
  archive      = {J_NCA},
  author       = {Akgül, Volkan and Kurşuncu, Bilal and Kaya, Hüseyin},
  doi          = {10.1007/s00521-023-08357-8},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13999-14012},
  shortjournal = {Neural Comput. Appl.},
  title        = {Response surface methodology-based multi-objective grey relation optimization for impinging jet cooling with Al2O3/water nanofluid on a curved surface},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterization of electrical 1-phase transformer
parameters with guaranteed hotspot temperature and aging using an
improved dwarf mongoose optimizer. <em>NCA</em>, <em>35</em>(19),
13983–13998. (<a
href="https://doi.org/10.1007/s00521-023-08449-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameters identification of Electric Power Transformer (EPT) models is significant for the steady and consistent operation of the power systems. The nonlinear and multimodal natures of EPT models make it challenging to optimally estimate the EPT’s parameters. Therefore, this work presents an improved Dwarf Mongoose Optimization Algorithm (IDMOA) to identify unknown parameters of the EPT model (1-phase transformer) and to appraise transformer aging trend under hottest temperatures. The IDMOA employs a population of solutions to get as much information as possible within the search space through generating different solution’ vectors. Furthermore, the Nelder–Mead Simplex method is incorporated to efficiently promote the neighborhood searching with the aim to find a high-quality solution during the iterative process. At initial stage, power transformer electrical equivalent extraction parameters are expressed in terms of the fitness function and its corresponding operating inequality restrictions. In this sense, the sum of absolute errors (SAEs) among numerous factors from nameplate data of transformers is to be minimized. The proposed IDMOA is demonstrated on two transformer ratings as 4 kVA and 15 kVA, respectively. Moreover, the outcomes of the IDMOA are compared with other recent challenging optimization methods. It can be realized that the lowest minimum values of SAEs compared to the others which are 3.3512e−2 and 1.1200e−5 for 15 kVA and 4 kVA cases, respectively. For more assessment for the proposed optimizer, the extracted parameters are utilized to evaluate the transformer aging considering the transformer hottest temperature compared with effect of the actual parameters following the IEEE Std C57.91 procedures. It is proved that the results are guaranteed, and the transformer per unit nominal life is 1.00 at less than 110 °C as per the later-mentioned standard.},
  archive      = {J_NCA},
  author       = {Rizk-Allah, Rizk M. and El-Fergany, Attia A. and Gouda, Eid A. and Kotb, Mohamed F.},
  doi          = {10.1007/s00521-023-08449-5},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13983-13998},
  shortjournal = {Neural Comput. Appl.},
  title        = {Characterization of electrical 1-phase transformer parameters with guaranteed hotspot temperature and aging using an improved dwarf mongoose optimizer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing a strategy based on weighted mean of vectors
(INFO) optimizer for optimal power flow considering uncertainty of
renewable energy generation. <em>NCA</em>, <em>35</em>(19), 13955–13981.
(<a href="https://doi.org/10.1007/s00521-023-08427-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, more efforts have been exerted to increase the level of renewable energy sources (RESs) in the energy mix in many countries to mitigate the dangerous effects of greenhouse gases emissions. However, because of their stochastic nature, most RESs pose some operational and planning challenges to power systems. One of these challenges is the complexity of solving the optimal power flow (OPF) problem in existing RESs. This study proposes an OPF model that has three different sources of renewable energy: wind, solar, and combined solar and small-hydro sources in addition to the conventional thermal power. Three probability density functions (PDF), namely lognormal, Weibull, and Gumbel, are employed to determine available solar, wind, and small-hydro output powers, respectively. Many meta-heuristic optimization algorithms have been applied for solving OPF problem in the presence of RESs. In this work, a new meta-heuristic algorithm, weighted mean of vectors (INFO), is employed for solving the OPF problem in two adjusted standard IEEE power systems (30 and 57 buses). It is simulated by MATLAB software in different theoretical and practical cases to test its validity in solving the OPF problem of the adjusted power systems. The results of the applied simulation cases in this work show that INFO has better performance results in minimizing total generation cost and reducing convergence time among other algorithms.},
  archive      = {J_NCA},
  author       = {Farhat, Mohamed and Kamel, Salah and Atallah, Ahmed M. and Abdelaziz, Almoataz Y. and Tostado-Véliz, Marcos},
  doi          = {10.1007/s00521-023-08427-x},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13955-13981},
  shortjournal = {Neural Comput. Appl.},
  title        = {Developing a strategy based on weighted mean of vectors (INFO) optimizer for optimal power flow considering uncertainty of renewable energy generation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Siamese neural networks in recommendation. <em>NCA</em>,
<em>35</em>(19), 13941–13953. (<a
href="https://doi.org/10.1007/s00521-023-08610-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are widely adopted as an increasing research and development area, since they provide users with diverse and useful information tailored to their needs. Several strategies have been proposed, and in most of them some concept of similarity is used as a core part of the approach, either between items or between users. At the same time, Siamese Neural Networks are being used to capture the similarity of items in the image domain, as they are defined as a subtype of Artificial Neural Networks built with (at least two) identical networks that share their weights. In this review, we study the proposals done in the intersection of these two fields, that is, how Siamese Networks are being used for recommendation. We propose a classification that considers different recommendation problems and algorithmic approaches. Some research directions are pointed out to encourage future research. To the best of our knowledge, this paper is the first comprehensive survey that focuses on the usage of Siamese Neural Networks for Recommender Systems.},
  archive      = {J_NCA},
  author       = {Serrano, Nicolás and Bellogín, Alejandro},
  doi          = {10.1007/s00521-023-08610-0},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13941-13953},
  shortjournal = {Neural Comput. Appl.},
  title        = {Siamese neural networks in recommendation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linguistic methods in healthcare application and COVID-19
variants classification. <em>NCA</em>, <em>35</em>(19), 13935–13940. (<a
href="https://doi.org/10.1007/s00521-021-06286-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important goals of modern medicine is prevention against pandemic and civilization diseases. For such tasks, advanced IT infrastructures and intelligent AI systems are used, which allow supporting patients’ diagnosis and treatment. In our research, we also try to define efficient tools for coronavirus classification, especially using mathematical linguistic methods. This paper presents the ways of application of linguistics techniques in supporting effective management of medical data obtained during coronavirus treatments, and possibilities of application of such methods in classification of different variants of the coronaviruses detected for particular patients. Currently, several types of coronavirus are distinguished, which are characterized by differences in their RNA structure, which in turn causes an increase in the rate of mutation and infection with these viruses.},
  archive      = {J_NCA},
  author       = {Ogiela, Marek R. and Ogiela, Urszula},
  doi          = {10.1007/s00521-021-06286-y},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13935-13940},
  shortjournal = {Neural Comput. Appl.},
  title        = {Linguistic methods in healthcare application and COVID-19 variants classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward real-time and efficient cardiovascular monitoring for
COVID-19 patients by 5G-enabled wearable medical devices: A deep
learning approach. <em>NCA</em>, <em>35</em>(19), 13921–13934. (<a
href="https://doi.org/10.1007/s00521-021-06219-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients with deaths from COVID-19 often have co-morbid cardiovascular disease. Real-time cardiovascular disease monitoring based on wearable medical devices may effectively reduce COVID-19 mortality rates. However, due to technical limitations, there are three main issues. First, the traditional wireless communication technology for wearable medical devices is difficult to satisfy the real-time requirements fully. Second, current monitoring platforms lack efficient streaming data processing mechanisms to cope with the large amount of cardiovascular data generated in real time. Third, the diagnosis of the monitoring platform is usually manual, which is challenging to ensure that enough doctors online to provide a timely, efficient, and accurate diagnosis. To address these issues, this paper proposes a 5G-enabled real-time cardiovascular monitoring system for COVID-19 patients using deep learning. Firstly, we employ 5G to send and receive data from wearable medical devices. Secondly, Flink streaming data processing framework is applied to access electrocardiogram data. Finally, we use convolutional neural networks and long short-term memory networks model to obtain automatically predict the COVID-19 patient’s cardiovascular health. Theoretical analysis and experimental results show that our proposal can well solve the above issues and improve the prediction accuracy of cardiovascular disease to 99.29\%.},
  archive      = {J_NCA},
  author       = {Tan, Liang and Yu, Keping and Bashir, Ali Kashif and Cheng, Xiaofan and Ming, Fangpeng and Zhao, Liang and Zhou, Xiaokang},
  doi          = {10.1007/s00521-021-06219-9},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13921-13934},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward real-time and efficient cardiovascular monitoring for COVID-19 patients by 5G-enabled wearable medical devices: A deep learning approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Res-CovNet: An internet of medical health things driven
COVID-19 framework using transfer learning. <em>NCA</em>,
<em>35</em>(19), 13907–13920. (<a
href="https://doi.org/10.1007/s00521-021-06171-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Major countries are globally facing difficult situations due to this pandemic disease, COVID-19. There are high chances of getting false positives and false negatives identifying the COVID-19 symptoms through existing medical practices such as PCR (polymerase chain reaction) and RT-PCR (reverse transcription-polymerase chain reaction). It might lead to a community spread of the disease. The alternative of these tests can be CT (Computer Tomography) imaging or X-rays of the lungs to identify the patient with COVID-19 symptoms more accurately. Furthermore, by using feasible and usable technology to automate the identification of COVID-19, the facilities can be improved. This notion became the basic framework, Res-CovNet, of the implemented methodology, a hybrid methodology to bring different platforms into a single platform. This basic framework is incorporated into IoMT based framework, a web-based service to identify and classify various forms of pneumonia or COVID-19 utilizing chest X-ray images. For the front end, the.NET framework along with C# language was utilized, MongoDB was utilized for the storage aspect, Res-CovNet was utilized for the processing aspect. Deep learning combined with the notion forms a comprehensive implementation of the framework, Res-CovNet, to classify the COVID-19 affected patients from pneumonia-affected patients as both lung imaging looks similar to the naked eye. The implemented framework, Res-CovNet, developed with the technique, transfer learning in which ResNet-50 used as a pre-trained model and then extended with classification layers. The work implemented using the data of X-ray images collected from the various trustable sources that include cases such as normal, bacterial pneumonia, viral pneumonia, and COVID-19, with the overall size of the data is about 5856. The accuracy of the model implemented is about 98.4\% in identifying COVID-19 against the normal cases. The accuracy of the model is about 96.2\% in the case of identifying COVID-19 against all other cases, as mentioned.},
  archive      = {J_NCA},
  author       = {Madhavan, Mangena Venu and Khamparia, Aditya and Gupta, Deepak and Pande, Sagar and Tiwari, Prayag and Hossain, M. Shamim},
  doi          = {10.1007/s00521-021-06171-8},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13907-13920},
  shortjournal = {Neural Comput. Appl.},
  title        = {Res-CovNet: An internet of medical health things driven COVID-19 framework using transfer learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A detection algorithm for cherry fruits based on the
improved YOLO-v4 model. <em>NCA</em>, <em>35</em>(19), 13895–13906. (<a
href="https://doi.org/10.1007/s00521-021-06029-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {&quot;Digital&quot; agriculture is rapidly affecting the value of agricultural output. Robotic picking of the ripe agricultural product enables accurate and rapid picking, making agricultural harvesting intelligent. How to increase product output has also become a challenge for digital agriculture. During the cherry growth process, realizing the rapid and accurate detection of cherry fruits is the key to the development of cherry fruits in digital agriculture. Due to the inaccurate detection of cherry fruits, environmental problems such as shading have become the biggest challenge for cherry fruit detection. This paper proposes an improved YOLO-V4 deep learning algorithm to detect cherry fruits. This model is suitable for cherry fruits with a small volume. It is proposed to increase the network based on the YOLO-V4 backbone network CSPDarknet53 network, combined with DenseNet The density between layers, the a priori box in the YOLO-V4 model, is changed to a circular marker box that fits the shape of the cherry fruit. Based on the improved YOLO-V4 model, the feature extraction is enhanced, the network structure is deepened, and the detection speed is improved. To verify the effectiveness of this method, different deep learning algorithms of YOLO-V3, YOLO-V3-dense and YOLO-V4 are compared. The results show that the mAP (average accuracy) value obtained by using the improved YOLO-V4 model (YOLO-V4-dense) network in this paper is 0.15 higher than that of yolov4. In actual orchard applications, cherries with different ripeness of cherries in the same area can be detected, and the fruits with larger ripeness differences can be artificially intervened, and finally, the yield of cherry fruits can be increased.},
  archive      = {J_NCA},
  author       = {Gai, Rongli and Chen, Na and Yuan, Hai},
  doi          = {10.1007/s00521-021-06029-z},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13895-13906},
  shortjournal = {Neural Comput. Appl.},
  title        = {A detection algorithm for cherry fruits based on the improved YOLO-v4 model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and verification of secure communication scheme for
industrial IoT intelligent production line system with multi-path
redundancy and collaboration. <em>NCA</em>, <em>35</em>(19),
13879–13893. (<a
href="https://doi.org/10.1007/s00521-021-05990-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of diversified terminal structures is common in the Industrial Internet of Things (IIoT), and the information transmission methods between the terminals are more complicated. The wireless network transmission and the security of wireless data communication between various intelligent devices are a major challenge facing the IIoT. Aiming at the problem that the existing single-path communication method of the IIoT intelligent production line system cannot guarantee the confidentiality, integrity and authenticity of sensitive information transmission effectively, we establish a redundant collaboration secure communication scheme (TS-RCSCS) for IIoT intelligent production line system in this paper. This scheme constructs a redundant-synergy secure communication model based on threshold signature mechanism and proposes a redundant-synergy transmission method based on multiple auxiliary paths. This method can prevent state information transmission failure effectively caused by the failure of wireless communication nodes in IIoT intelligent production line system, which could reduce the probability of information packets being intercepted by malicious nodes. In addition, in view of the special situation that redundant-synergy secure communication model fails periodically, this scheme further proposes a method for predicting the communication missing data of intelligent production line system. This method can predict the missing communication information of continuous period effectively, which meets the integrity requirements of communication information for IIoT intelligent production line system. The test verification conclusion shows that the TS-RCSCS scheme can obtain higher communication accuracy and higher fitting prediction value in the IIoT environment. The conclusion further shows that the scheme is suitable for the wireless communication process between intelligent devices and intelligent terminals in the IIoT environment, and it can improve the security and integrity of data communication effectively.},
  archive      = {J_NCA},
  author       = {Li, Mingshi and Yin, Zhenyu and Ma, Yue and Wang, Chunxiao and Chai, Anying and Lian, Mengjia},
  doi          = {10.1007/s00521-021-05990-z},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13879-13893},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design and verification of secure communication scheme for industrial IoT intelligent production line system with multi-path redundancy and collaboration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing COVID-19 tracking apps with human activity
recognition using a deep convolutional neural network and HAR-images.
<em>NCA</em>, <em>35</em>(19), 13861–13877. (<a
href="https://doi.org/10.1007/s00521-021-05913-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of COVID-19, mobile health applications have increasingly become crucial in contact tracing, information dissemination, and pandemic control in general. Apps warn users if they have been close to an infected person for sufficient time, and therefore potentially at risk. The distance measurement accuracy heavily affects the probability estimation of being infected. Most of these applications make use of the electromagnetic field produced by Bluetooth Low Energy technology to estimate the distance. Nevertheless, radio interference derived from numerous factors, such as crowding, obstacles, and user activity can lead to wrong distance estimation, and, in turn, to wrong decisions. Besides, most of the social distance-keeping criteria recognized worldwide plan to keep a different distance based on the activity of the person and on the surrounding environment. In this study, in order to enhance the performance of the COVID-19 tracking apps, a human activity classifier based on Convolutional Deep Neural Network is provided. In particular, the raw data coming from the accelerometer sensor of a smartphone are arranged to form an image including several channels (HAR-Image), which is used as fingerprints of the in-progress activity that can be used as an additional input by tracking applications. Experimental results, obtained by analyzing real data, have shown that the HAR-Images are effective features for human activity recognition. Indeed, the results on the k-fold cross-validation and obtained by using a real dataset achieved an accuracy very close to 100\%.},
  archive      = {J_NCA},
  author       = {D’Angelo, Gianni and Palmieri, Francesco},
  doi          = {10.1007/s00521-021-05913-y},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13861-13877},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing COVID-19 tracking apps with human activity recognition using a deep convolutional neural network and HAR-images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Postpartum pelvic organ prolapse assessment via adversarial
feature complementation in heterogeneous data. <em>NCA</em>,
<em>35</em>(19), 13851–13860. (<a
href="https://doi.org/10.1007/s00521-021-06869-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical data processing and analysis using machine learning algorithms are a prominent research topic these days. To obtain high performances, most state-of-the-art models must be trained on a large number of labeled datasets. However, manually collecting a large-scale real-world medical data is expensive due to the issues like privacy, security, and reliability. Moreover, the collected samples may be incomplete, i.e., some important data items are missing, which has a significant impact on the performance of the machine learning algorithms, especially deep learning models. In this paper, we present a strategy that uses the idea of adversarial learning to augment the real-world medical samples with the incomplete issue to obtain better performance in predicting patient states. Rather than supplying the incomplete data sample with extra instance-level information as in existing data-complementation methods, our method aims to achieve the complementary effect in the feature level without consuming human effort. The method receives both high-quality data and low-quality data (with serious incomplete issue) to learn a comprehensive feature space where the incomplete samples can be complemented with the knowledge transferred from the high-quality samples by the adversarial learning scheme. From the perspective of feature representations, our method can alleviate the incomplete issue of the low-quality data, which enhances the model performance in the end task. Experiments show that our method works well on a real-world medical dataset, which collected for assessment of pelvic organ prolapse. When compared to machine learning approaches frequently employed in medical data analysis, our approach shows a significant improvement of up to 10\%.},
  archive      = {J_NCA},
  author       = {Luo, Mingxuan and Yang, Xiaoshan},
  doi          = {10.1007/s00521-021-06869-9},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13851-13860},
  shortjournal = {Neural Comput. Appl.},
  title        = {Postpartum pelvic organ prolapse assessment via adversarial feature complementation in heterogeneous data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gesture recognition based on sEMG using multi-attention
mechanism for remote control. <em>NCA</em>, <em>35</em>(19),
13839–13849. (<a
href="https://doi.org/10.1007/s00521-021-06729-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote controlling using surface electromyography (sEMG) plays a more and more important role in a human–robot interface, such as controlling prosthesis devices, and exoskeleton. Different gestures are controlled by the cooperation of muscle groups, and sEMG represent the energy of the activated muscle fibers. With the limit of the low performance of wearable device, this article proposed a remote hand gesture recognized system based on deep learning framework of multi-attention mechanism convolutional neural network using sEMG energy to decoding hand gestures with remote server host. In the first part, an adaptive channel weighted method is proposed on multi-channel data of sEMG for enhancing the related feature map of sEMG and reducing the feature map low contribution of sEMG. The second part is improving the shortcuts by adding adaptively weighted instead of a simple short concatenation of feature maps. A novel multi-attention deep learning framework with multi-view (MMDL) for hand gestures recognition is proposed in our study, using sEMG. We verify the MMDL framework on myo dataset, myoUp dataset, and ninapro DB5, with the average accuracy 99.27\%, 97.86\%, and 97.0\%, which is improved by 0.46\%, 18.88\%, 7\% compared with prior works. In addition, the framework can classify seven hand gestures with 99.92\% accuracy on ours datasets.},
  archive      = {J_NCA},
  author       = {Lv, Xiaodong and Dai, Chuankai and Liu, Haijie and Tian, Ye and Chen, Luyao and Lang, Yiran and Tang, Rongyu and He, Jiping},
  doi          = {10.1007/s00521-021-06729-6},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13839-13849},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gesture recognition based on sEMG using multi-attention mechanism for remote control},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cyber warfare perspective on risks related to health IoT
devices and contact tracing. <em>NCA</em>, <em>35</em>(19), 13823–13837.
(<a href="https://doi.org/10.1007/s00521-021-06720-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide use of IT resources to assess and manage the recent COVID-19 pandemic allows to increase the effectiveness of the countermeasures and the pervasiveness of monitoring and prevention. Unfortunately, the literature reports that IoT devices, a widely adopted technology for these applications, are characterized by security vulnerabilities that are difficult to manage at the state level. Comparable problems exist for related technologies that leverage smartphones, such as contact tracing applications, and non-medical health monitoring devices. In analogous situations, these vulnerabilities may be exploited in the cyber domain to overload the crisis management systems with false alarms and to interfere with the interests of target countries, with consequences on their economy and their political equilibria. In this paper we analyze the potential threat to an example subsystem to show how these influences may impact it and evaluate a possible consequence.},
  archive      = {J_NCA},
  author       = {Bobbio, Andrea and Campanile, Lelio and Gribaudo, Marco and Iacono, Mauro and Marulli, Fiammetta and Mastroianni, Michele},
  doi          = {10.1007/s00521-021-06720-1},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13823-13837},
  shortjournal = {Neural Comput. Appl.},
  title        = {A cyber warfare perspective on risks related to health IoT devices and contact tracing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time running workouts monitoring using cloud–edge
computing. <em>NCA</em>, <em>35</em>(19), 13803–13822. (<a
href="https://doi.org/10.1007/s00521-021-06675-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a world of ever-growing technology where smartwatches are becoming more and more widespread, we introduced an application that can attach a personal running coach on one’s wrist. We developed a highly scalable model that takes input from real coaches, conveys it into a running training on a watch, analyzes the running performance, and gives real-time text and haptic feedback based on it. Using cloud technologies, we came up with a solution that provides end-to-end connectivity between a smartwatch and a coach or user. We empower people to track down their workouts and physical profiles easily and to connect with their trainers using a standard, interactive dashboard. The solution is presented in this paper.},
  archive      = {J_NCA},
  author       = {Avram, Maria-Ruxandra and Pop, Florin},
  doi          = {10.1007/s00521-021-06675-3},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13803-13822},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time running workouts monitoring using Cloud–Edge computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Alleviating pseudo-touching in attention u-net-based
binarization approach for the historical tibetan document images.
<em>NCA</em>, <em>35</em>(19), 13791–13802. (<a
href="https://doi.org/10.1007/s00521-021-06512-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binarization, one of the most popular research directions in computer vision, is still facing challenges, especially for the degraded historical Tibetan document images. Quite a few U-Net-based binarization approaches might encounter a particular problem called pseudo-touching which hampers subsequent procedures including text line segmentation, character segmentation, and recognition. To avoid these undesired pseudo-touching strokes and obtain optimal binary images, the present work employs several easy-to-use techniques, such as rescaling the input and output of the attention U-Net. Furthermore, we provide insights into the accelerated construction of the training set and discuss the effects of various configurations. The quantitative experimental results on our dataset show that upsampling the input image by a factor of two during the inference phase can alleviate the pseudo-touching. It achieves an average P-FM of 97.73 which is two percentage points higher than the result of U-Net. The proposed approach can also accept common challenges including non-uniform illumination, stains, noise and delivers finer performance across several metrics.},
  archive      = {J_NCA},
  author       = {Zhao, Penghai and Wang, Weilan and Zhang, Guowei and Lu, Yuqi},
  doi          = {10.1007/s00521-021-06512-7},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13791-13802},
  shortjournal = {Neural Comput. Appl.},
  title        = {Alleviating pseudo-touching in attention U-net-based binarization approach for the historical tibetan document images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A smart healthcare framework for detection and monitoring of
COVID-19 using IoT and cloud computing. <em>NCA</em>, <em>35</em>(19),
13775–13789. (<a
href="https://doi.org/10.1007/s00521-021-06396-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus (COVID-19) is a very contagious infection that has drawn the world’s attention. Modeling such diseases can be extremely valuable in predicting their effects. Although classic statistical modeling may provide adequate models, it may also fail to understand the data’s intricacy. An automatic COVID-19 detection system based on computed tomography (CT) scan or X-ray images is effective, but a robust system design is challenging. In this study, we propose an intelligent healthcare system that integrates IoT-cloud technologies. This architecture uses smart connectivity sensors and deep learning (DL) for intelligent decision-making from the perspective of the smart city. The intelligent system tracks the status of patients in real time and delivers reliable, timely, and high-quality healthcare facilities at a low cost. COVID-19 detection experiments are performed using DL to test the viability of the proposed system. We use a sensor for recording, transferring, and tracking healthcare data. CT scan images from patients are sent to the cloud by IoT sensors, where the cognitive module is stored. The system decides the patient status by examining the images of the CT scan. The DL cognitive module makes the real-time decision on the possible course of action. When information is conveyed to a cognitive module, we use a state-of-the-art classification algorithm based on DL, i.e., ResNet50, to detect and classify whether the patients are normal or infected by COVID-19. We validate the proposed system’s robustness and effectiveness using two benchmark publicly available datasets (Covid-Chestxray dataset and Chex-Pert dataset). At first, a dataset of 6000 images is prepared from the above two datasets. The proposed system was trained on the collection of images from 80\% of the datasets and tested with 20\% of the data. Cross-validation is performed using a tenfold cross-validation technique for performance evaluation. The results indicate that the proposed system gives an accuracy of 98.6\%, a sensitivity of 97.3\%, a specificity of 98.2\%, and an F1-score of 97.87\%. Results clearly show that the accuracy, specificity, sensitivity, and F1-score of our proposed method are high. The comparison shows that the proposed system performs better than the existing state-of-the-art systems. The proposed system will be helpful in medical diagnosis research and healthcare systems. It will also support the medical experts for COVID-19 screening and lead to a precious second opinion.},
  archive      = {J_NCA},
  author       = {Nasser, Nidal and Emad-ul-Haq, Qazi and Imran, Muhammad and Ali, Asmaa and Razzak, Imran and Al-Helali, Abdulaziz},
  doi          = {10.1007/s00521-021-06396-7},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13775-13789},
  shortjournal = {Neural Comput. Appl.},
  title        = {A smart healthcare framework for detection and monitoring of COVID-19 using IoT and cloud computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning-based diffusion model for prediction of
coronavirus-19 outbreak. <em>NCA</em>, <em>35</em>(19), 13755–13774. (<a
href="https://doi.org/10.1007/s00521-021-06376-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus pandemic has been globally impacting the health and prosperity of people. A persistent increase in the number of positive cases has boost the stress among governments across the globe. There is a need of approach which gives more accurate predictions of outbreak. This paper presents a novel approach called diffusion prediction model for prediction of number of coronavirus cases in four countries: India, France, China and Nepal. Diffusion prediction model works on the diffusion process of the human contact. Model considers two forms of spread: when the spread takes time after infecting one person and when the spread is immediate after infecting one person. It makes the proposed model different over other state-of-the art models. It is giving more accurate results than other state-of-the art models. The proposed diffusion prediction model forecasts the number of new cases expected to occur in next 4 weeks. The model has predicted the number of confirmed cases, recovered cases, deaths and active cases. The model can facilitate government to be well prepared for any abrupt rise in this pandemic. The performance is evaluated in terms of accuracy and error rate and compared with the prediction results of support vector machine, logistic regression model and convolution neural network. The results prove the efficiency of the proposed model.},
  archive      = {J_NCA},
  author       = {Raheja, Supriya and Kasturia, Shreya and Cheng, Xiaochun and Kumar, Manoj},
  doi          = {10.1007/s00521-021-06376-x},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13755-13774},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning-based diffusion model for prediction of coronavirus-19 outbreak},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PA during the COVID-19 outbreak in china: A cross-sectional
study. <em>NCA</em>, <em>35</em>(19), 13739–13754. (<a
href="https://doi.org/10.1007/s00521-021-06538-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has undergone several mutations and is still spreading in most countries now. PA has positive benefits in the prevention of COVID-19 infection and counteracting the negative physical and mental effects caused by COVID-19. However, relevant evidence has indicated a high prevalence of physical inactivity among the general population, which has worsened due to the outbreak of the pandemic, and there is a severe lack of exercise guidance and mitigation strategies to advance the knowledge and role of PA to improve physical and mental health in most countries during the epidemic. This study surveyed the effects of COVID-19 on PA in Chinese residents during the pandemic and provided important reference and evidence to inform policymakers and formulate policies and planning for health promotion and strengthening residents’ PA during periods of public health emergencies. ANOVA, Kolmogorov–Smirnov, the chi-square test and Spearman correlation analysis were used for statistical analysis. A total of 14,715 participants were included. The results show that nearly 70\% of Chinese residents had inadequate PA (95\%CI 58.0\%–82.19\%) during the COVID-19 outbreak, which was more than double the global level (27.5\%, 95\%CI 25.0\%–32.2\%). The content, intensity, duration, and frequency of PA were all affected during the period of home isolation, and the types of PA may vary among different ages. The lack of physical facilities and cultural environment is the main factor affecting PA. However, there was no significant correlation between insufficient PA and the infection rate. During the period of home isolation and social distance of epidemic prevention, it is necessary to strengthen the scientific remote network monitoring and guidance for the process of PA in China.},
  archive      = {J_NCA},
  author       = {Nie, Yingjun and Ma, Yuanyan and Li, Xiaodong and Wu, Yankong and Liu, Weixin and Tan, Zhenke and Li, Jiahui and Zhang, Ce and Lv, Chennan and Liu, Ting},
  doi          = {10.1007/s00521-021-06538-x},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13739-13754},
  shortjournal = {Neural Comput. Appl.},
  title        = {PA during the COVID-19 outbreak in china: A cross-sectional study},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A privacy-preserving botnet detection approach in largescale
cooperative IoT environment. <em>NCA</em>, <em>35</em>(19), 13725–13737.
(<a href="https://doi.org/10.1007/s00521-022-06934-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Internet-of-Things (IoT), our modern life has been greatly facilitated, while an exponentially growing number of vulnerable devices also breed a wonderful ground for botnet controllers,. However, existing detection approaches developed for individual traditional network area neglect cross-area privacy issue and resource restraint nature of IoT network and therefore impede their effectiveness of mitigating IoT botnet. In this work, we present a lightweight and privacy-preserving system, namely PPBotHunter, to detect botnet across multiple network areas. PPBotHunter implements a fuzzy matrix algorithm to retrieve effective bot similarity computation while ensuring a high privacy degree. This algorithm is designed based on a privacy-preserving scalar product computation technique (PPSPC) which enables PPBotHunter to be lightweight yet efficient. We utilize only time series feature to build the fuzzy matrices, which further improve the compatibility, energy-efficacy and resistance against heterogeneity. The theoretical analysis and detailed simulations illustrate the efficacy and effectiveness of our proposed botnet detection system.},
  archive      = {J_NCA},
  author       = {Li, Yixin and Zhu, Muyijie and Luo, Xi and Yin, Lihua and Fu, Ye},
  doi          = {10.1007/s00521-022-06934-x},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13725-13737},
  shortjournal = {Neural Comput. Appl.},
  title        = {A privacy-preserving botnet detection approach in largescale cooperative IoT environment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of lower limb motor imagery based on
iterative EEG source localization and feature fusion. <em>NCA</em>,
<em>35</em>(19), 13711–13724. (<a
href="https://doi.org/10.1007/s00521-021-06761-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery (MI) brain–computer interface (BCI) systems have broad application prospects in rehabilitation and other fields. However, to achieve accurate and practical MI-BCI applications, there are still several critical issues, such as channel selection, electroencephalogram (EEG) feature extraction and EEG classification, needed to be better resolved. In this paper, these issues are studied for lower limb MI which is more difficult and less studied than upper limb MI. First, a novel iterative EEG source localization method is proposed for channel selection. Channels FC1, FC2, C1, C2 and Cz, instead of the commonly used traditional channel set (TCS) C3, C4 and Cz, are selected as the optimal channel set (OCS). Then, a multi-domain feature (MDF) extraction algorithm is presented to fuse single-domain features into multi-domain features. Finally, a particle swarm optimization based support vector machine (SVM) method is utilized to classify the EEG data collected by the lower limb MI experiment designed by us. The results show that the classification accuracy is 88.43\%, 3.35–5.41\% higher than those of using traditional SVM to classify single-domain features on the TCS, which proves that the combination of OCS and MDF can not only reduce the amount of data processing, but also retain more feature information to improve the accuracy of EEG classification.},
  archive      = {J_NCA},
  author       = {Peng, Xiaobo and Liu, Junhong and Huang, Ying and Mao, Yanhao and Li, Dong},
  doi          = {10.1007/s00521-021-06761-6},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13711-13724},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of lower limb motor imagery based on iterative EEG source localization and feature fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IoT-based health monitoring system to handle pandemic
diseases using estimated computing. <em>NCA</em>, <em>35</em>(19),
13709–13710. (<a
href="https://doi.org/10.1007/s00521-023-08625-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ogiela, Lidia and Castiglione, Arcangelo and Gupta, Brij B. and Agrawal, Dharma P.},
  doi          = {10.1007/s00521-023-08625-7},
  journal      = {Neural Computing and Applications},
  number       = {19},
  pages        = {13709-13710},
  shortjournal = {Neural Comput. Appl.},
  title        = {IoT-based health monitoring system to handle pandemic diseases using estimated computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fitness distance balance-based runge–kutta algorithm for
indirect rotor field-oriented vector control of three-phase induction
motor. <em>NCA</em>, <em>35</em>(18), 13685–13707. (<a
href="https://doi.org/10.1007/s00521-023-08408-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a study has been carried out to further develop the Runge–Kutta (RK) algorithm, which has a current and robust mathematical structure, using the fitness distance balance (FDB) method, and to test it for induction machine control. The RK algorithm was developed to avoid local optimum solutions, speed up convergence, and seek out the best possible solutions globally. Despite offering promising solutions, it is clear that this algorithm has its shortcomings, especially in solving high-dimensional problems like asynchronous motor control. In this study, the FDB method was used to build the guide selection process in the RK algorithm to reach the optimal solution. The developed FDB-based RK algorithm has been tested and verified on the CEC17 benchmark problems for 30-dimensional search spaces. The results of the proposed algorithm have been compared to the performance of the classical RK algorithm, and it shows that the changes in the design of the RK algorithm are successful. The proportional–integral–derivative (PID) parameters employed as a controller in the indirect rotor field-oriented control approach of a three-phase induction motor have then been optimized using the accuracy-proven algorithm. The FDB-RK, RK, genetic algorithm, particle swarm (PSO), differential evolution, artificial bee colony, and weighted average of vectors (INFO) algorithms have been used in this study with three different fitness functions and Wilcoxon and Freidman statistical analyses to find the best values for PID parameters. According to the data, FDB-RK-based PID controller has the best performance among the techniques.},
  archive      = {J_NCA},
  author       = {Dursun, Mustafa},
  doi          = {10.1007/s00521-023-08408-0},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13685-13707},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fitness distance balance-based Runge–Kutta algorithm for indirect rotor field-oriented vector control of three-phase induction motor},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid deep learning CNN-ELM approach for parking space
detection in smart cities. <em>NCA</em>, <em>35</em>(18), 13665–13683.
(<a href="https://doi.org/10.1007/s00521-023-08426-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With each passing day, the number of smart vehicles is increasing manifold, hence, automatic/automated parking lot detection is gaining a lot of importance among Smart City applications. A robust approach is desired to identify parking spaces effectively and efficiently. This work presents a deep learning classifier based on convolutional neural network (CNN) and extreme learning machine (ELM), i.e., CNN-ELM to classify the parking space as vacant or occupied. CNN is well-known for efficient image classification, but its training time is highly influenced by backpropagation of errors in the fully connected layer. Thus, ELM is plugged into CNN to replace the fully connected layer and perform classification whereas, feature extraction is performed using CNN. The performance of CNN-ELM is validated on the publicly available PKLot dataset, which contains approximately 700,000 images categorized into sunny, overcast, and rainy weather conditions. The experimental results indicate that CNN-ELM approach outperforms other hybrid CNN models using different classifiers such as support vector machine, Xgboost, and Extra Trees in terms of sensitivity, specificity, and accuracy. The comparison of results with other state-of-the-art approaches based on accuracy and Area under the curve (AUC) score further justifies the effectiveness of the proposed approach in real-time parking space detection.},
  archive      = {J_NCA},
  author       = {Kaur, Ravneet and Roul, Rajendra Kumar and Batra, Shalini},
  doi          = {10.1007/s00521-023-08426-y},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13665-13683},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid deep learning CNN-ELM approach for parking space detection in smart cities},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of o-6-methylguanine-DNA methyltransferase and
overall survival of the patients suffering from glioblastoma using
MRI-based hybrid radiomics signatures in machine and deep learning
framework. <em>NCA</em>, <em>35</em>(18), 13647–13663. (<a
href="https://doi.org/10.1007/s00521-023-08405-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {O-6-methylguanine-DNA methyltransferase (MGMT) is one of the most salient gene promoters that correlates with the effectiveness of standard therapy for patients suffering from glioblastoma (GBM). Non-invasive estimation of MGMT and overall survival (OS) in GBM patients could provide a particular direction to neuro-oncologists and surgeons for precise treatment and surgical planning. This study investigated hybrid radiomics signatures (HRS) for the prediction of (i) MGMT status (methylated/unmethylated) and (ii) OS (short survivors 12 months and long survivors &gt;  = 12 months) using both conventional and deep radiomic features derived from multi-parametric MRI (mp-MRI). Further, for the OS, Kaplan–Meier analysis was carried out to analyze the difference between two groups of survivors. Additionally, Cox-PH modeling was adapted to investigate the impact of clinical observation on OS. Two cohorts of 555 and 209 GBM patients have been used to analyze HRS for MGMT and OS, respectively. (i) For MGMT status prediction employing conventional machine learning radiomics features along with deep learning features using VGG16 and VGG19, the HRS obtained an AUC of 0.76 (95\% CI: 0.70–0.80). (ii) For OS prediction employing the log-rank test, the conventional radiomic signature showed an AUC of 0.78 (95\% CI: 0.75–0.83) with a p-value &lt; 0.001. Similarly, in assessing the impact of patient age on OS, the concordance index was 0.68 (95\% CI 0.6–0.72). The proposed study concludes with the diagnostics remark of efficient HRS for MGMT prediction and conventional radiomics for OS prediction.},
  archive      = {J_NCA},
  author       = {Saxena, Sanjay and Agrawal, Aaditya and Dash, Prasad and Jena, Biswajit and Khanna, Narendra N. and Paul, Sudip and Kalra, Mannudeep M. and Viskovic, Klaudija and Fouda, Mostafa M. and Saba, Luca and Suri, Jasjit S.},
  doi          = {10.1007/s00521-023-08405-3},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13647-13663},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of O-6-methylguanine-DNA methyltransferase and overall survival of the patients suffering from glioblastoma using MRI-based hybrid radiomics signatures in machine and deep learning framework},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimation of causality in economic growth and expansionary
policies using uplift modeling. <em>NCA</em>, <em>35</em>(18),
13631–13645. (<a
href="https://doi.org/10.1007/s00521-023-08397-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uplift modeling corresponds to an area of machine learning focused on capturing causal relationships on various observational and experimental data. Currently it has several applications, particularly in the marketing area, focused on customer segmentation and the establishment of advertising campaigns. This research proposes an novel economic uplift approach, using branching causal algorithms to estimate the individual treatment effect on real GDP growth and changes in expansionary economic policy on a quarterly basis from an OECD dataset. The developed framework reveals positive causal effects on economic growth driven by expansionary policies, generalized for all countries under study. In addition, lagged causal effects on these policies, exerted by the economic cycle, are captured. The results obtained not only show a performance similar to that of the literature, but also conform to the theoretical and actual macroeconomic behavior.},
  archive      = {J_NCA},
  author       = {Bermeo, Cristhian and Michell, Kevin and Kristjanpoller, Werner},
  doi          = {10.1007/s00521-023-08397-0},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13631-13645},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimation of causality in economic growth and expansionary policies using uplift modeling},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An improved many-objective artificial bee colony algorithm
for cascade reservoir operation. <em>NCA</em>, <em>35</em>(18),
13613–13629. (<a
href="https://doi.org/10.1007/s00521-023-08446-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial bee colony (ABC) has shown good performance on single-objective and ordinary multi-objective optimization problems. However, ABC faces some difficulties with increasing number of objectives. The selection pressure based on Pareto dominance degrades severely. The original ABC shows weak exploitation ability and slow convergence speed. To help ABC solve many-objective optimization problems (MaOPs), this paper proposes an improved many-objective ABC algorithm based on decomposition and dimension learning (called MaOABC-DDL). Firstly, an MaOP is converted to several sub-problems by the decomposition. The original fitness function is not available because of multiple objective values. Then, a new fitness function is defined based on the ranking of each objective. Solutions with good fitness values are selected to form an elite set. To improve the convergence, an elite set guided search strategy and dimension learning are designed for the employed bee and onlooker bee stages, respectively. Moreover, the scout bee stage is modified to dynamically allocate computing resources. To verify the performance of MaOABC-DDL, the DTLZ and MaF benchmark problems with 3, 5, 8, and 15 objectives are tested. Results show that MaOABC-DDL can obtain better performance when compared with seven other many-objective evolutionary algorithms. Finally, MaOABC-DDL is applied to cascade reservoir operation. Simulation results show that our approach still achieves promising performance.},
  archive      = {J_NCA},
  author       = {Wang, Hui and Wang, Shuai and Wei, Zichen and Zeng, Tao and Ye, Tingyu},
  doi          = {10.1007/s00521-023-08446-8},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13613-13629},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved many-objective artificial bee colony algorithm for cascade reservoir operation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection and classification of COVID-19 by using faster
r-CNN and mask r-CNN on CT images. <em>NCA</em>, <em>35</em>(18),
13597–13611. (<a
href="https://doi.org/10.1007/s00521-023-08450-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus (COVID-19) pandemic has a devastating impact on people’s daily lives and healthcare systems. The rapid spread of this virus should be stopped by early detection of infected patients through efficient screening. Artificial intelligence techniques are used for accurate disease detection in computed tomography (CT) images. This article aims to develop a process that can accurately diagnose COVID-19 using deep learning techniques on CT images. Using CT images collected from Yozgat Bozok University, the presented method begins with the creation of an original dataset, which includes 4000 CT images. The faster R-CNN and mask R-CNN methods are presented for this purpose in order to train and test the dataset to categorize patients with COVID-19 and pneumonia infections. In this study, the results are compared using VGG-16 for faster R-CNN model and ResNet-50 and ResNet-101 backbones for mask R-CNN. The faster R-CNN model used in the study has an accuracy rate of 93.86\%, and the ROI (region of interest) classification loss is 0.061 per ROI. At the conclusion of the final training, the mask R-CNN model generates mAP (mean average precision) values for ResNet-50 and ResNet-101, respectively, of 97.72\% and 95.65\%. The results for five folds are obtained by applying the cross-validation to the methods used. With training, our model performs better than the industry standard baselines and can help with automated COVID-19 severity quantification in CT images.},
  archive      = {J_NCA},
  author       = {Sahin, M. Emin and Ulutas, Hasan and Yuce, Esra and Erkoc, Mustafa Fatih},
  doi          = {10.1007/s00521-023-08450-y},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13597-13611},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection and classification of COVID-19 by using faster R-CNN and mask R-CNN on CT images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decomposing the deep: Finding class-specific filters in deep
CNNs. <em>NCA</em>, <em>35</em>(18), 13583–13596. (<a
href="https://doi.org/10.1007/s00521-023-08441-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability of Deep Neural Networks has become a major area of exploration. Although these networks have achieved state-of-the-art results in many tasks, it is extremely difficult to interpret and explain their decisions. In this work, we analyze the final and penultimate layers of Deep Convolutional Networks for image classification with respect to $$\ell _1$$ norm and develop an algorithm for identifying subsets of features that contribute most toward the network’s decision for each class. We also develop a novel decomposed softmax to efficiently re-train the network such that the class-specific decomposition is preserved. We provide a comparison with other methods for identifying class-specific filters and show, using Pairwise Mutual Information Score, that our technique provides better decomposition. The resulting decomposed final layer provides a low-dimensional embedding (decreased by around a factor of 10) per class, which is far more interpretable. Such a low-dimensional class-specific embedding makes diagnosing issues with misclassifications of a certain class in the data easier as fewer weights contribute to the decision for the data points of that class. It also enables the network toward easier diagnostics and pruning as an entire part of the final and pre-final layer can be excluded to remove predictions for data points belonging to a particular label. The resulting layer also achieves a modest computational cost gain as compared to the final layer of the full network. Our algorithm is unsupervised in nature and can be applied to any CNN.},
  archive      = {J_NCA},
  author       = {Badola, Akshay and Roy, Cherian and Padmanabhan, Vineet and Lal, Rajendra Prasad},
  doi          = {10.1007/s00521-023-08441-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13583-13596},
  shortjournal = {Neural Comput. Appl.},
  title        = {Decomposing the deep: Finding class-specific filters in deep CNNs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EmoDNN: Understanding emotions from short texts through a
deep neural network ensemble. <em>NCA</em>, <em>35</em>(18),
13565–13582. (<a
href="https://doi.org/10.1007/s00521-023-08435-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knowledge obtained from emotions via online communities is substantially valuable in various domains, including social management, resource planning, politics, and market predictions. Affective computing, as a multi-aspect realm, aims to exploit emotion-pertinent details from various contents via connecting artificial intelligence to cognitive science. The hidden personality cues in daily brief contents can reveal the cognitive aspect of authors and uncover both similarities and contrasts between them. However, the main challenge lies in devising a cognition-aware algorithm to trace emotional cues in brief contents. To solve the challenge, we develop a novel framework that infers the cognitive aspect of individuals. We propose a deep ensemble method, supplied with a novel dropout algorithm, that aggregates outcomes from various classifiers to extract emotions from short texts. We employ a new embedding approach to enrich emotion-relevant features, collectively assembled via lexicons and attention actuates, resulting in a preferable set of vectors. The experimental results show that our proposed framework can achieve better accuracy in recognizing emotions versus other trending competitors. We empirically observe that detecting emotion latent cues via relying on personality features can effectively distinguish short text authors. Furthermore, the deep learning models overcome conventional methods, including the SVM, categorization, and heuristic rules.},
  archive      = {J_NCA},
  author       = {Kamran, Sara and Zall, Raziyeh and Hosseini, Saeid and Kangavari, MohammadReza and Rahmani, Sana and Hua, Wen},
  doi          = {10.1007/s00521-023-08435-x},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13565-13582},
  shortjournal = {Neural Comput. Appl.},
  title        = {EmoDNN: Understanding emotions from short texts through a deep neural network ensemble},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepHAR: A deep feed-forward neural network algorithm for
smart insole-based human activity recognition. <em>NCA</em>,
<em>35</em>(18), 13547–13563. (<a
href="https://doi.org/10.1007/s00521-023-08363-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health monitoring, rehabilitation, and fitness are just a few domains where human activity recognition can be applied. In this study, a deep learning approach has been proposed to recognise ambulation and fitness activities from data collected by five participants using smart insoles. Smart insoles, consisting of pressure and inertial sensors, allowed for seamless data collection while minimising user discomfort, laying the baseline for the development of a monitoring and/or rehabilitation system for everyday life. The key objective has been to enhance the deep learning model performance through several techniques, including data segmentation with overlapping technique (2 s with 50\% overlap), signal down-sampling by averaging contiguous samples, and a cost-sensitive re-weighting strategy for the loss function for handling the imbalanced dataset. The proposed solution achieved an Accuracy and F1-Score of 98.56\% and 98.57\%, respectively. The Sitting activities obtained the highest degree of recognition, closely followed by the Spinning Bike class, but fitness activities were recognised at a higher rate than ambulation activities. A comparative analysis was carried out both to determine the impact that pre-processing had on the proposed core architecture and to compare the proposed solution with existing state-of-the-art solutions. The results, in addition to demonstrating how deep learning solutions outperformed those of shallow machine learning, showed that in our solution the use of data pre-processing increased performance by about 2\%, optimising the handling of the imbalanced dataset and allowing a relatively simple network to outperform more complex networks, reducing the computational impact required for such applications.},
  archive      = {J_NCA},
  author       = {D’Arco, Luigi and Wang, Haiying and Zheng, Huiru},
  doi          = {10.1007/s00521-023-08363-w},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13547-13563},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepHAR: A deep feed-forward neural network algorithm for smart insole-based human activity recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Squirrel search algorithm applied to effective estimation of
solar PV model parameters: A real-world practice. <em>NCA</em>,
<em>35</em>(18), 13529–13546. (<a
href="https://doi.org/10.1007/s00521-023-08451-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model parameters estimation of solar photovoltaic (PV) cells/modules using real current–voltage (I–V) data is a critical task for the performance of PV systems. Therefore, there is a necessity to procure optimal parameters of PV models using proper optimization techniques. For this aim, squirrel search algorithm (SSA) as the recent and powerful tool is employed to accomplish the mentioned task in the single-diode model (SDM) and double-diode model (DDM) of a PV unit. Of course, better parameter values can be obtained by reducing the error between the experimental and model-based estimated data. Analyses are performed under two case studies. The former considers a standard dataset of R.T.C. France silicon solar cell, whereas the latter uses an experimental dataset of a polycrystalline CS6P-220P solar module. The I-V data of this PV module were acquired when it worked under 30 °C and solar radiance of 1000W/m2 at the Engineering Faculty Campus of Düzce University, Turkey. The results of the first case study are compared with those of other prevalent approaches, which demonstrate the superiority of SSA over its competing peers. Moreover, SSA is found to handle the model parameters definition of an industrial PV module located at the university campus. Thus, the new method offers a practical tool beneficial to boost the effectiveness of PV systems.},
  archive      = {J_NCA},
  author       = {Maden, Dinçer and Çelik, Emre and Houssein, Essam H. and Sharma, Gulshan},
  doi          = {10.1007/s00521-023-08451-x},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13529-13546},
  shortjournal = {Neural Comput. Appl.},
  title        = {Squirrel search algorithm applied to effective estimation of solar PV model parameters: A real-world practice},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CovTiNet: Covid text identification network using
attention-based positional embedding feature fusion. <em>NCA</em>,
<em>35</em>(18), 13503–13527. (<a
href="https://doi.org/10.1007/s00521-023-08442-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covid text identification (CTI) is a crucial research concern in natural language processing (NLP). Social and electronic media are simultaneously adding a large volume of Covid-affiliated text on the World Wide Web due to the effortless access to the Internet, electronic gadgets and the Covid outbreak. Most of these texts are uninformative and contain misinformation, disinformation and malinformation that create an infodemic. Thus, Covid text identification is essential for controlling societal distrust and panic. Though very little Covid-related research (such as Covid disinformation, misinformation and fake news) has been reported in high-resource languages (e.g. English), CTI in low-resource languages (like Bengali) is in the preliminary stage to date. However, automatic CTI in Bengali text is challenging due to the deficit of benchmark corpora, complex linguistic constructs, immense verb inflexions and scarcity of NLP tools. On the other hand, the manual processing of Bengali Covid texts is arduous and costly due to their messy or unstructured forms. This research proposes a deep learning-based network (CovTiNet) to identify Covid text in Bengali. The CovTiNet incorporates an attention-based position embedding feature fusion for text-to-feature representation and attention-based CNN for Covid text identification. Experimental results show that the proposed CovTiNet achieved the highest accuracy of 96.61±.001\% on the developed dataset (BCovC) compared to the other methods and baselines (i.e. BERT-M, IndicBERT, ELECTRA-Bengali, DistilBERT-M, BiLSTM, DCNN, CNN, LSTM, VDCNN and ACNN).},
  archive      = {J_NCA},
  author       = {Hossain, Md. Rajib and Hoque, Mohammed Moshiul and Siddique, Nazmul and Sarker, Iqbal H.},
  doi          = {10.1007/s00521-023-08442-y},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13503-13527},
  shortjournal = {Neural Comput. Appl.},
  title        = {CovTiNet: Covid text identification network using attention-based positional embedding feature fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered fixed-time adaptive neural formation control
for underactuated ASVs with connectivity constraints and prescribed
performance. <em>NCA</em>, <em>35</em>(18), 13485–13501. (<a
href="https://doi.org/10.1007/s00521-023-08417-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an event-triggered fixed-time adaptive neural network formation control method is proposed for underactuated multiple autonomous surface vessels with model uncertainties and unknown external disturbances under communication distance constraints. First, a time-varying barrier Lyapunov function is developed to obtain prescribed performances, such as formation error constraints, and avoid collisions in the communication range with distance limitations. Second, combining backstepping technology with neural networks, a fixed-time adaptive minimum learning parameter (MLP) is proposed to improve robustness against external disturbances and model uncertainties, and an adaptive law is designed to compensate for the approximation error of MLP. Third, a relative threshold-based event-triggered strategy is developed to greatly save communication resources without degrading control performance. Subsequently, Theorem analysis shows that all signals in the closed-loop system are bounded and practical fixed-time stable. Finally, the effectiveness of the proposed method is demonstrated by numerical simulations.},
  archive      = {J_NCA},
  author       = {Liu, Haitao and Lin, Jianfei and Li, Ronghui and Tian, Xuehong and Mai, Qingqun},
  doi          = {10.1007/s00521-023-08417-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13485-13501},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-triggered fixed-time adaptive neural formation control for underactuated ASVs with connectivity constraints and prescribed performance},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of ANN and traditional ML algorithms in
modelling compost production under different climatic conditions.
<em>NCA</em>, <em>35</em>(18), 13465–13484. (<a
href="https://doi.org/10.1007/s00521-023-08404-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plentiful and diverse Organic wastes such as green, food, pruning and landscaping waste necessitate upon effective and efficient recycling strategies such as composting. In this article, for the first time, machine learning (ML) models have been applied to model compost generation rate as a function of climatic parameters and organic waste content. The data size contained approximately 864 sample points records of the meteorological parameters (Modern-Era Retrospective Analysis), organic waste (Central Pollution Control Board) and compost yields (Open Government Data) data for 2010–2021. The modelling efforts involved the consideration of MLP and traditional ML algorithms namely k-nearest neighbour (kNN), gradient boosting (GB) and random forest (RF) for prediction and autoregressive integrated moving average (ARIMA) model supplemented ML models for long-term forecasting of the compost generation rate. Model validation resulted in an RMSE of 0.757 and R2 of 0.99 for GB model, and a correlation index of 0.68 between observed and predicted values to thereby outperform all other models. However, forecasted data for ten years after the predicted outcomes resulted in the best performance of ARIMA–MLP model with a standard error of 21.1152 and a CP yield of 74,958 kg. Thereby, the findings affirm upon the evidence for the limitations of the broader application of the empirical approaches and the feasibility of ML algorithms as a potential reconstruction technique for developing robust and accurate region-specific compost prediction and forecasting models to assist integrated circular agricultural system development for a sustainable global future.},
  archive      = {J_NCA},
  author       = {Singh, Tinka and Uppaluri, Ramagopal V. S.},
  doi          = {10.1007/s00521-023-08404-4},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13465-13484},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of ANN and traditional ML algorithms in modelling compost production under different climatic conditions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bacteria phototaxis optimizer. <em>NCA</em>,
<em>35</em>(18), 13433–13464. (<a
href="https://doi.org/10.1007/s00521-023-08391-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new metaheuristic algorithm called bacteria phototaxis optimizer (BPO). It is designed to solving optimization issues. Inspired by the bacteria phototaxis under the control of photosensory proteins in nature, and based on the basic law of bacterial colony growth and evolution, we have designed the photosensory protein concentration, phototaxis motion and growth operators. These three operators exhibit a highly adaptive and information interaction mechanism. The goal is to simulate the phototaxis process of bacteria and form a complete model of BPO. At the same time, BPO is compared with eight most representative as well as newly generated metaheuristics. Its performance is verified by using 23 well-known benchmark functions with three different types. Additionally, we have conducted several evaluation processes, such as qualitative and quantitative analysis as well as parametric and nonparametric tests. Finally, five classical engineering design problems are used to further test the effectiveness of the algorithm in solving constrained problems. The aforementioned experimental results show that compared with other algorithms, BPO has better accuracy, convergence, and robustness and shows strong competitiveness and optimization performance.},
  archive      = {J_NCA},
  author       = {Pan, Qingtao and Tang, Jun and Zhan, Jianjun and Li, Hao},
  doi          = {10.1007/s00521-023-08391-6},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13433-13464},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bacteria phototaxis optimizer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SFSS-net: Shape-awared filter and sematic-ranked sampler for
voxel-based 3D object detection. <em>NCA</em>, <em>35</em>(18),
13417–13431. (<a
href="https://doi.org/10.1007/s00521-023-08382-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection has been used in many fields, such as virtual reality, automatic driving and target tracking. 3D object detection methods usually use point clouds as input, but point clouds are disordered and rotationally invariant. To solve this problem, voxel-based methods convert point clouds into voxels. However, the raw point clouds contain a large number of background points which are not relevant to the target or not helpful for subsequent detection, and voxel-based methods invariably feed them directly into the network for 3D object detection. Besides, the voxel-based approach is to model the point cloud data to generate a plenty of voxels with the same dimension. But random sampling during voxel partition will make voxel representation weaker and reduce the performance of classifier as well as box regressor. We, therefore, propose a plug-to-play module, which contains a shape-awared filter(SAF) and a semantic-ranked sampler(SRS). SAF can effectively remove some of the background points in the raw point clouds, to accelerate inference indirectly. And, SRS can enhance the expression of voxel feature by retaining the points of high confidence. Finally, we remove previous orientation classifier and propose a new loss method named ADIoU loss to improve the orientation estimation performance. Experiments on the KITTI car detection bench-mark demonstrate that our method shows faster inference speed and higher detection accuracy compared with SOTA methods.},
  archive      = {J_NCA},
  author       = {Zhu, Liping and Chen, Zhe and Wang, Bingyao and Tian, Gangyi and Ji, Laihu},
  doi          = {10.1007/s00521-023-08382-7},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13417-13431},
  shortjournal = {Neural Comput. Appl.},
  title        = {SFSS-net: Shape-awared filter and sematic-ranked sampler for voxel-based 3D object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Water cycle algorithm with adaptive sea and rivers and
enhanced position updating strategy for numerical optimization.
<em>NCA</em>, <em>35</em>(18), 13387–13416. (<a
href="https://doi.org/10.1007/s00521-023-08365-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel water cycle algorithm is presented by dynamically assigning sea and rivers and devising an enhanced position updating strategy. To effectively maintain the diversity of solutions and ensure the convergence of algorithm, an adaptive distance-based assignment mechanism is first developed to set sea, rivers and their corresponding streams. In this mechanism, the fitness values and position information of solutions are simultaneously considered, and the total number of sea and rivers is nonlinearly reduced during the search process. Meanwhile, an enhanced position updating strategy is designed to update the solutions by incorporating both the gravitational search and greedy strategy. Moreover, a modified evaporation operation is further proposed to dynamically refresh the search capability of algorithm by properly making full use of the promising information of solutions. Differing from the existing WCA variants, the proposed algorithm dynamically assigns sea, rivers and their streams, additionally incorporates the gravitational search and greedy strategy, and fully exploits the obtained promising information in the raining process. Then it could availably strengthen the search effectiveness and balance the exploration and exploitation. Finally, the performance of the proposed algorithm is evaluated by comparing with 12 typical algorithms on 30 CEC2017 benchmark functions. Numerical results show that the proposed algorithm has better performance.},
  archive      = {J_NCA},
  author       = {Tian, Mengnan and Gao, Xingbao and Yan, Xueqing},
  doi          = {10.1007/s00521-023-08365-8},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13387-13416},
  shortjournal = {Neural Comput. Appl.},
  title        = {Water cycle algorithm with adaptive sea and rivers and enhanced position updating strategy for numerical optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An enhanced multi-operator differential evolution algorithm
for tackling knapsack optimization problem. <em>NCA</em>,
<em>35</em>(18), 13359–13386. (<a
href="https://doi.org/10.1007/s00521-023-08358-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knapsack problem (KP) is a discrete combinatorial optimization problem that has different utilities in many fields. It is described as a non-polynomial time (NP) problem and has several applications in many fields. The differential evolution (DE) algorithm has been successful in solving continuous optimization problems, but it needs further work to solve discrete and binary optimization problems and avoid local optima. According to the literature, no DE search operator or algorithm is optimal for all optimization tasks. As a result, using more than one search operator in a single algorithm architecture, called multi-operator-based algorithms, is a solution to address this problem. These methods outperformed single-based methods for continuous optimization problems. Thus, in this paper, a binary multi-operator differential evolution (BMODE) approach is presented to tackle the 0–1 KP. The presented methodology utilizes multiple differential evolution (DE) mutation strategies with complementary characteristics, with the best mutation operator being asserted utilizing the produced solutions’ quality and the population’s diversity. In BMODE, two types of transfer functions (TFs) (S-shaped and V-shaped) are used to transfer the continuous solutions to binary ones to be able to calculate the fitness function value. To handle the capacity constraints, a feasibility rule is utilized and some of the infeasible solutions are repaired. The performance of BMODE is tested by solving 40 instances with multiple dimensions, i.e., low, medium, and high. Experimental results of the proposed BMODE are compared with well-known state-of-the-art 0–1 knapsack algorithms. Based on Wilcoxon’s nonparametric statistical test ( $$\alpha =0.05$$ ), the proposed BMODE can obtain the best results against the rival algorithms in most cases, and can work well on stability and computational accuracy.},
  archive      = {J_NCA},
  author       = {Sallam, Karam M. and Abohany, Amr A. and Rizk-Allah, Rizk M.},
  doi          = {10.1007/s00521-023-08358-7},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13359-13386},
  shortjournal = {Neural Comput. Appl.},
  title        = {An enhanced multi-operator differential evolution algorithm for tackling knapsack optimization problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Amperage prediction in mono-wire cutting operation using
multiple regression and artificial neural network models. <em>NCA</em>,
<em>35</em>(18), 13343–13358. (<a
href="https://doi.org/10.1007/s00521-023-08443-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operational parameters such as cutting speed and peripheral speed in diamond wire cutting operation greatly affect the efficiency of the machine. The cutting machine’s amperage draw measures how hard the machine must work to run, and it is an alternative way to understand the cutting performance of rocks. High amperage values in cutting indicate that the machine has difficulties in cutting process. The retreat rates of the quarry type cutting machines and downward rates for stationary diamond wire cutting machines change the cutting rates of natural stone blocks. In addition to operational parameters, rock properties such as strength, abrasivity also affect cutting performance. In this study, variations of amperage values during mono-wire cutting were investigated and the effects of cutting parameters and some rock properties on amperage values were examined. While analyzing the basic relationships between cutting parameters and amperage values, obtained experimental data were grouped depending on rock properties. In the final part of the study, amperage values were predicted using multiple regression and artificial neural network models. Produced models were compared by using R2, RMSE, VAF and MAPE performance indices. This comparison showed that the constructed ANN model is highly acceptable for prediction of amperage.},
  archive      = {J_NCA},
  author       = {Yilmazkaya, Emre},
  doi          = {10.1007/s00521-023-08443-x},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13343-13358},
  shortjournal = {Neural Comput. Appl.},
  title        = {Amperage prediction in mono-wire cutting operation using multiple regression and artificial neural network models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Micro-network-based deep convolutional neural network for
human activity recognition from realistic and multi-view visual data.
<em>NCA</em>, <em>35</em>(18), 13321–13341. (<a
href="https://doi.org/10.1007/s00521-023-08440-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent past, deep convolutional neural network (DCNN) has been used in majority of state-of-the-art methods due to its remarkable performance in number of computer vision applications. However, DCNN are computationally expensive and requires more resources as well as computational time. Also, deeper architectures are prone to overfitting problem, while small-size dataset is used. To address these limitations, we propose a simple and computationally efficient deep convolutional neural network (DCNN) architecture based on the concept multiscale processing for human activity recognition. We increased the width and depth of the network by carefully crafting the design of network, which results in improved utilization of computational resources. First, we designed a small micro-network with varying receptive field size convolutional kernels (1 $$\times$$ 1, 3 $$\times$$ 3, and 5 $$\times$$ 5) for extraction of unique discriminative information of human objects having variations in object size, pose, orientation, and view. Then, the proposed DCNN architecture is designed by stacking repeated building blocks of small micro-networks with same topology. Here, we factorize the larger convolutional operation in stack of smaller convolutional operations to make the network computationally efficient. The softmax classifier is used for activity classification. Advantage of the proposed architecture over standard deep architectures is its computational efficiency and flexibility to use with both small as well as large size datasets. To evaluate the effectiveness of the proposed architecture, several extensive experiments are conducted by using publically available datasets, namely UCF sports, IXMAS, YouTube, TV-HI, HMDB51, and UCF101 datasets. The activity recognition results have shown outperformance of the proposed method over other existing state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Kushwaha, Arati and Khare, Ashish and Prakash, Om},
  doi          = {10.1007/s00521-023-08440-0},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13321-13341},
  shortjournal = {Neural Comput. Appl.},
  title        = {Micro-network-based deep convolutional neural network for human activity recognition from realistic and multi-view visual data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial neural networks (ANN), MARS, and adaptive
network-based fuzzy inference system (ANFIS) to predict the stress at
the failure of concrete with waste steel slag coarse aggregate
replacement. <em>NCA</em>, <em>35</em>(18), 13293–13319. (<a
href="https://doi.org/10.1007/s00521-023-08439-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concrete is a very flexible composite material that is extensively employed in the building industry. Steel slag is a waste material produced during steelmaking. It is formed during the separation of molten steel from impurities in steelmaking furnaces. Slag starts as a molten liquid melt and cools to a solid state. It is a solution of silicates and oxides that is rather complicated. Steel slag recovery is environmentally friendly since it conserves natural resources and frees up landfill space. Steel slag has been extensively utilized in concrete as a partial substitute for normal and crushed coarse aggregate to improve the mechanical qualities of normal-strength concrete, such as compressive strength. The researchers and suppliers investigated that using steel slag instead of normal coarse aggregate could save the environment and natural resources. Three hundred thirty-eight (338) data sets were gathered and evaluated in total. During the modeling procedure, the most significant factors affecting the compressive strength of concrete with steel slag replacement were considered, including the curing time of 1–180 days, the cement content of 237.35–550 kg/m3, the water-to-cement ratio of 0.3–0.872, the fine aggregate content of 175.5–1285 kg/m3, the steel slag content of 0–1196 kg/m3, and the coarse aggregate content of 0–1253.75 kg/m3. A credible mathematical model is needed to investigate the influence of steel slag as a partial replacement on concrete compressive strength. Mathematical models will help engineers and concrete industries mix a proper concrete mix design, including steel slag, to achieve a desired compressive strength without doing any experimental work. As a result, an artificial neural network (ANN), an adaptive network-based fuzzy inference system (ANFIS), a multivariate adaptive regression splines (MARS), and an M5P-tree model were presented in this research to predict the compressive strength of concrete with steel slag aggregate replacement. According to previous research findings, all percentages of steel slag improve compressive strength. According to statistical studies, the adaptive network-based fuzzy inference system model outperformed the other models in forecasting steel slag replacement compressive strength for normal strength concrete (ANN, MARS, and M5P-tree). It has a higher coefficient of determination of 0.99, a smaller mean absolute error of 0.74 MPa, a smaller root mean square error of 1.12 MPa, a smaller scatter index of 0.029, and a smaller objective of 0.93 MPa.},
  archive      = {J_NCA},
  author       = {Piro, Nzar Shakr and Mohammed, Ahmed and Hamad, Samir M. and Kurda, Rawaz},
  doi          = {10.1007/s00521-023-08439-7},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13293-13319},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural networks (ANN), MARS, and adaptive network-based fuzzy inference system (ANFIS) to predict the stress at the failure of concrete with waste steel slag coarse aggregate replacement},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implementation of transformer-based deep learning
architecture for the development of surface roughness classifier using
sound and cutting force signals. <em>NCA</em>, <em>35</em>(18),
13275–13292. (<a
href="https://doi.org/10.1007/s00521-023-08425-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhanced machining quality, including the appropriate surface roughness of the machined parts, is the focus of many industries. This paper proposes and implements transformer-based deep learning (DL) architecture for machining roughness classification for the end-milling operation using cutting force and machining sound data. To increase the accuracy of the classification outcomes, audio feature extraction techniques—Mel-spectrogram and Mel-frequency cepstral coefficients (MFCCs)—were incorporated with the DL model. To measure and demonstrate the proposed model’s performance, a number of experiments were conducted by training the models on 0–30 s machining data, including end mill-workpiece impact at the beginning of the experiment and 10–40 s machining data. Based on the outcomes’ accuracies, four DL models were designed and the number of parameters, maximum epoch required for convergence, and training, validation and testing accuracies were compared for each model. DL models trained on 10–40 s machining data achieved over 90\% validation and test accuracies, suggesting that the cutting force and machining data after reaching steady-state performs better than data from the beginning of machining operation. Confusion matrices were plotted for the inference results of each model to observe the prediction accuracy visually. The proposed method will be able to predict machining surface quality with high accuracy saving time and cost for post-operations.},
  archive      = {J_NCA},
  author       = {Bhandari, Binayak and Park, Gijun and Shafiabady, Niusha},
  doi          = {10.1007/s00521-023-08425-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13275-13292},
  shortjournal = {Neural Comput. Appl.},
  title        = {Implementation of transformer-based deep learning architecture for the development of surface roughness classifier using sound and cutting force signals},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Outlier-resistant variance-constrained <span
class="math display"><em>H</em><sub>∞</sub></span> state estimation for
time-varying recurrent neural networks with randomly occurring deception
attacks. <em>NCA</em>, <em>35</em>(18), 13261–13273. (<a
href="https://doi.org/10.1007/s00521-023-08419-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the outlier-resistant variance-constrained $$H_{\infty }$$ state estimation problem for a class of discrete time-varying recurrent neural networks with randomly occurring deception attacks. The randomly occurring deception attacks are modeled by a series of random variables satisfying the Bernoulli distribution with known probability. In addition, the saturation function is introduced to reduce the negative impact from the measurement outliers onto the estimation performance. The objective of this paper is to propose an outlier-resistant finite-horizon state estimation scheme without utilizing the augmentation method such that, in the presence of measurement outliers and randomly occurring deception attacks, some sufficient criteria are obtained ensuring both the desired $$H_{\infty }$$ performance index and the error variance boundedness. Finally, a numerical example is used to illustrate the feasibility of the presented outlier-resistant variance-constrained $$H_{\infty }$$ state estimation algorithm.},
  archive      = {J_NCA},
  author       = {Gao, Yan and Hu, Jun and Yu, Hui and Du, Junhua and Jia, Chaoqing},
  doi          = {10.1007/s00521-023-08419-x},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13261-13273},
  shortjournal = {Neural Comput. Appl.},
  title        = {Outlier-resistant variance-constrained $$\mathit{H}_{\infty }$$ state estimation for time-varying recurrent neural networks with randomly occurring deception attacks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MCMSTClustering: Defining non-spherical clusters by using
minimum spanning tree over KD-tree-based micro-clusters. <em>NCA</em>,
<em>35</em>(18), 13239–13259. (<a
href="https://doi.org/10.1007/s00521-023-08386-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a technique for statistical data analysis and is widely used in many areas where class labels are not available. Major problems related to clustering algorithms are handling high-dimensional, imbalanced, and/or varying-density datasets, detecting outliers, and defining arbitrary-shaped clusters. In this study, we proposed a novel clustering algorithm named as MCMSTClustering (Defining Non-Spherical Clusters by using Minimum Spanning Tree over KD-Tree-based Micro-Clusters) to overcome mentioned issues simultaneously. Our algorithm consists of three parts. The first part is defining micro-clusters using the KD-Tree data structure with range search. The second part is constructing macro-clusters by using minimum spanning tree (MST) on defined micro-clusters, and the final part is regulating defined clusters to increase the accuracy of the algorithm. To state the efficiency of our algorithm, we performed some experimental studies on some state-of-the-art algorithms. The findings were presented in detail with tables and graphs. The success of the proposed algorithm using various performance evaluation criteria was confirmed. According to the experimental studies, MCMSTClustering outperformed competitor algorithms in aspects of clustering quality in acceptable run-time. Besides, the obtained results showed that the novel algorithm can be applied effectively in solving many different clustering problems in the literature.},
  archive      = {J_NCA},
  author       = {Şenol, Ali},
  doi          = {10.1007/s00521-023-08386-3},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13239-13259},
  shortjournal = {Neural Comput. Appl.},
  title        = {MCMSTClustering: Defining non-spherical clusters by using minimum spanning tree over KD-tree-based micro-clusters},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-stack RNN-based neural machine translation model for
english to pakistan sign language translation. <em>NCA</em>,
<em>35</em>(18), 13225–13238. (<a
href="https://doi.org/10.1007/s00521-023-08424-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign languages are gesture-based languages used by the deaf community of the world. Every country has a different sign language and there are more than 200 sign languages in the world. American Sign Language (ASL), British Sign Language (BSL), and German Sign Language (DGS) are well-studied sign languages. Due to their different grammatical structure and word order the deaf people feel difficulty in reading and understanding the written text in natural languages. In order to enhance the cognitive ability of the deaf subjects some translation models have been developed for these languages that translate natural language text into corresponding sign language gestures. Most of the earlier natural to sign language translation models rely on rule-based approaches. Recently, some neural machine translation models have been proposed for ASL, BSL, DGS, and Arabic sign language. However, most of these models have low accuracy scores. This research provides an improved and novel multi-stack RNN-based neural machine translation model for natural to sign language translation. The proposed model is based on encoder–decoder architecture and incorporates attention mechanism and embeddings to improve the quality of results. Rigorous experimentation has been performed to compare the proposed multi-stack RNN-based model with baseline models. The experiments have been conducted using a sizeable translation corpus comprising of nearly 50,000 sentences for Pakistan Sign Language (PSL). The performance of the proposed neural machine translation model for PSL has been evaluated with the help of well-established evaluation measures including Bilingual Evaluation Understudy Score (BLEU), and Word Error Rate (WER). The results show that multi-stacked gated recurrent unit-based RNN model that employs Bahdanau attention mechanism and GloVe embedding performed the best showing the BLEU score of 0.83 and WER 0.17, which outperform the existing translation models. The proposed model has been exposed through a software system that converts the translated sentences into PSL gestures using an avatar. The evaluation of the usability has also been performed to see how effectively the avatar-based output helps compensating the cognitive hearing deficit for the deaf people. The results show that it works well for different granularity levels.},
  archive      = {J_NCA},
  author       = {Farooq, Uzma and Mohd Rahim, Mohd Shafry and Abid, Adnan},
  doi          = {10.1007/s00521-023-08424-0},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13225-13238},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-stack RNN-based neural machine translation model for english to pakistan sign language translation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameter optimization of chaotic system using pareto-based
triple objective artificial bee colony algorithm. <em>NCA</em>,
<em>35</em>(18), 13207–13223. (<a
href="https://doi.org/10.1007/s00521-023-08434-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaotic map is a kind of discrete chaotic system. The existing chaotic maps suffer from optimal parameters in terms of chaos measurements. In this study, a novel approach of optimization of parametric chaotic map (PCM) using triple objective optimization is presented for the first time. A PCM with six parameters is first conceived and then optimized using Pareto-based triple objective artificial bee colony (PT-ABC) algorithm. Pareto optimality is employed to catch the trade-off among the objectives: Lyapunov exponent (LE), sample entropy (SE), and Kolmogorov entropy (KE). A global optimal design including the six parameters is selected for minimizing the reciprocal of the three objectives independently. The chaotic performance of PCM is verified through an evaluation with bifurcation diagram, attractor, LE, SE, KE, and correlation dimension. The results are also validated by comparison with those of which reported elsewhere. Furthermore, the applicability of PCM is examined over image encryption and the results are compared with existing chaos-based IEs. Therefore, the PCM manifests the best ergodicity and complexity thanks to its PT-ABC algorithm.},
  archive      = {J_NCA},
  author       = {Toktas, Abdurrahim and Erkan, Uğur and Ustun, Deniz and Wang, Xingyuan},
  doi          = {10.1007/s00521-023-08434-y},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13207-13223},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parameter optimization of chaotic system using pareto-based triple objective artificial bee colony algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A multimodal dialogue system for improving user
satisfaction via knowledge-enriched response and image recommendation.
<em>NCA</em>, <em>35</em>(18), 13187–13206. (<a
href="https://doi.org/10.1007/s00521-023-08409-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task-oriented multimodal dialogue systems have important application value and development prospects. Existing methods have made significant progress, but the following challenges still exist: (1) Most existing methods focus on improving the accuracy of dialogue state tracking and dialogue act prediction. However, the essential to leverage knowledge in the knowledge base to supplement textual responses in multi-turn dialogues is ignored. (2) One feature that distinguishes multimodal dialogue from plain text dialogue is the usage of visual information. However, existing methods ignore the importance of accurately providing visual information to improve user satisfaction. (3) For multimodal dialogue systems, most existing methods ignore the classification of response types to assign appropriate response generators automatically. To address the issues above, we present a user-satisfactory multimodal dialogue system, USMD for short. Specifically, USMD is designed as four modules. The general response generator is based on generative pre-training 2.0 (GPT-2) to generate dialogue acts and general textual responses. The knowledge-enriched response generator is designed to leverage a structured knowledge base under the guidance of a knowledge graph. The image recommender pays attention to both latent and explicit visual cues, a deep multimodal fusion model to obtain informative image representations. Finally, the response classifier automatically selects the appropriate generators to answer the user based on user and agent actions. Extensive experiments on the benchmark multimodal dialogue datasets show that the proposed USMD model achieves state-of-the-art performance.},
  archive      = {J_NCA},
  author       = {Wang, Jiangnan and Li, Haisheng and Wang, Leiquan and Wu, Chunlei},
  doi          = {10.1007/s00521-023-08409-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13187-13206},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multimodal dialogue system for improving user satisfaction via knowledge-enriched response and image recommendation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot learning via graph embeddings with convolutional
networks for low-data molecular property prediction. <em>NCA</em>,
<em>35</em>(18), 13167–13185. (<a
href="https://doi.org/10.1007/s00521-023-08403-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks and convolutional architectures have proven to be pivotal in improving the prediction of molecular properties in drug discovery. However, this is fundamentally a low data problem that is incompatible with regular deep learning approaches. Contemporary deep networks require large amounts of training data, which severely limits the prediction of new molecular entities from limited available data. In this paper, we address the challenge of low data in molecular property prediction by: (1) defining a set of deep learning architectures that accept compound chemical structures in the form of molecular graphs, (2) creating a few-shot learning strategy across graph neural networks and convolutional neural networks to leverage the rich information of graph embeddings, and (3) proposing a two-module meta-learning framework to learn from task-transferable knowledge and predict molecular properties on few-shot data. Furthermore, we conduct multiple experiments on two benchmark multiproperty datasets to demonstrate a superior performance over conventional graph-based baselines. ROC-AUC results for 10-shot experiments show an average improvement of $$+11.37\%$$ on Tox21 and $$+0.53\%$$ on SIDER, which are representative small-sized biological datasets for molecular property prediction.},
  archive      = {J_NCA},
  author       = {Torres, Luis and Arrais, Joel P. and Ribeiro, Bernardete},
  doi          = {10.1007/s00521-023-08403-5},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13167-13185},
  shortjournal = {Neural Comput. Appl.},
  title        = {Few-shot learning via graph embeddings with convolutional networks for low-data molecular property prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale discriminant representation for generic
palmprint recognition. <em>NCA</em>, <em>35</em>(18), 13147–13165. (<a
href="https://doi.org/10.1007/s00521-023-08355-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palmprint shows great potential in biometric-based security due to its advantages of great stability, easy collection, and high accuracy. However, with insufficient training samples, how to extract discriminative features applicable in various scenarios is still challenging. This paper proposes a general palmprint recognition framework. First, based on the integrated Gabor filter (IGF), a multi-scale integrated Gabor convolutional network (MS-IGCN) with large and small receptive fields is built. Compared with the existing DCNN, MS-IGCN applies fewer trainable parameters to targetable grasp principle lines and wrinkles features. Notably, our constructed IGF in MS-IGCN completes the feature extraction. The fixed Gabor filters in IGF extract spatial features of different orientations, and the learnable filters learn complementary features that cannot be extracted by the fixed Gabor filters. Then, the multi-scale discriminant representation (MSDR) of palmprint is learned through MS-IGCN. Finally, to make MSDR flexibly applicable to various scenarios, the ProCRC is implemented. A large number of experiments on public databases are conducted. The experimental results show that compared with various advanced palmprint recognition methods, MSDR has the best recognition effect. In addition, we complete the palmprint collection in an unconstrained environment and established an unconstrained palmprint dataset. The experimental results on the unconstrained palmprint dataset fully demonstrate that MSDR maintains the best performance in practical applications.},
  archive      = {J_NCA},
  author       = {Yu, Lingli and Yi, Qian and Zhou, Kaijun},
  doi          = {10.1007/s00521-023-08355-w},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13147-13165},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale discriminant representation for generic palmprint recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph convolutional network with multi-similarity attribute
matrices fusion for node classification. <em>NCA</em>, <em>35</em>(18),
13135–13145. (<a
href="https://doi.org/10.1007/s00521-021-06429-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolution networks (GCNs) have become one of the most popular deep neural network-based models in many real-world applications. GCNs can extract features take advantage of both graph structure and node attributes based on convolutional neural networks. Existing GCN models represent nodes by aggregating the graph structure and node attributes from their neighbors which usually disrupt the node similarities in the feature space. In this paper, we propose the MSF-GCN, a graph convolutional network with multi-similarity attributed matrices fusion for node classification. The key idea behind the MSF-GCN is that not only the topology but also the attributes similarities are taken into consideration for node presentation. Specifically, we first apply a GAT-based module to obtain a general representation of the original graph. Next, we construct two k-nearest neighbor graphs based on node attributes with cosine similarity and heat kernel similarity. To balance the disparity between the graph structure and node attributes for each similarity matrix, we develop a self-attention network to integrate the node attributes with topological features. Furthermore, we design a gated-fusion network to merge the cosine similarity vector and heat kernel vector. In our experiments on four real-world datasets, results show that our MSF-GCN model can extract more correlation information from the node attributes and graph structure, and outperform seven state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Wang, Youquan and Cao, Jie and Tao, Haicheng},
  doi          = {10.1007/s00521-021-06429-1},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13135-13145},
  shortjournal = {Neural Comput. Appl.},
  title        = {Graph convolutional network with multi-similarity attribute matrices fusion for node classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual temporal gated multi-graph convolution network for taxi
demand prediction. <em>NCA</em>, <em>35</em>(18), 13119–13134. (<a
href="https://doi.org/10.1007/s00521-021-06092-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taxi demand prediction is essential to build efficient traffic transportation systems for smart city. It helps to properly allocate vehicles, ease the traffic pressure and improve passengers’ experience. Traditional taxi demand prediction methods mostly rely on time-series forecasting techniques, which cannot model the nonlinearity embedded in data. Recent studies start to combine the Euclidean spatial features through grid-based methods. By considering the spatial correlations among different regions, we can capture how the temporal events have impacts on those with adjacent links or intersections and improve prediction precision. Some graph-based models are proposed to encode the non-Euclidean correlations as well. However, the temporal periodicity of data is often overlooked, and the study units are usually constructed as oversimplified grids. In this paper, we define places with specific semantic and humanistic experiences as study units, using a fuzzy set method based on adaptive kernel density estimation. Then, we introduce dual temporal gated multi-graph convolution network to predict the future taxi demand. Specifically, multi-graph convolution is used to model spatial correlations with graphs, including the neighborhood, functional similarities and landscape similarities based on street view images. As for the temporal dependencies modeling, we design the dual temporal gated branches to capture information hidden in both previous and periodic observations. Experiments on two real-world datasets show the effectiveness of our model over the baselines.},
  archive      = {J_NCA},
  author       = {Yang, Taoru and Tang, Xiaopei and Liu, Rong},
  doi          = {10.1007/s00521-021-06092-6},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13119-13134},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual temporal gated multi-graph convolution network for taxi demand prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parallel spatio-temporal attention-based TCN for
multivariate time series prediction. <em>NCA</em>, <em>35</em>(18),
13109–13118. (<a
href="https://doi.org/10.1007/s00521-021-05958-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As industrial systems become more complex and monitoring sensors for everything from surveillance to our health become more ubiquitous, multivariate time series prediction is taking an important place in the smooth-running of our society. A recurrent neural network with attention to help extend the prediction windows is the current-state-of-the-art for this task. However, we argue that their vanishing gradients, short memories, and serial architecture make RNNs fundamentally unsuited to long-horizon forecasting with complex data. Temporal convolutional networks (TCNs) do not suffer from gradient problems and they support parallel calculations, making them a more appropriate choice. Additionally, they have longer memories than RNNs, albeit with some instability and efficiency problems. Hence, we propose a framework, called PSTA-TCN, that combines a parallel spatio-temporal attention mechanism to extract dynamic internal correlations with stacked TCN backbones to extract features from different window sizes. The framework makes full use parallel calculations to dramatically reduce training times, while substantially increasing accuracy with stable prediction windows up to 13 times longer than the status quo.},
  archive      = {J_NCA},
  author       = {Fan, Jin and Zhang, Ke and Huang, Yipan and Zhu, Yifei and Chen, Baiping},
  doi          = {10.1007/s00521-021-05958-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13109-13118},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parallel spatio-temporal attention-based TCN for multivariate time series prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A supervised and distributed framework for cold-start author
disambiguation in large-scale publications. <em>NCA</em>,
<em>35</em>(18), 13093–13108. (<a
href="https://doi.org/10.1007/s00521-020-05684-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Names make up a large portion of queries in search engines, while the name ambiguity problem brings negative effect to the service quality of search engines. In digital academic systems, this problem refers to a large number of publications containing ambiguous author names. Name ambiguity derives from many people sharing identical names, or names may be abbreviated. Although some methods have been proposed in the decade, this problem is still not completely solved and there are many subproblems needing to be studied. Due to lack of information, it is a nontrivial task to distinguish ambiguous authors accurately relying on limited internal information only. In this paper, we focus on the cold-start disambiguation task with homonymous author names, i.e., distinguishing publications written by authors with identical names. We present a supervised framework named DND (abbreviation for Distributed Framework for Name Disambiguation) to solve the author disambiguation problem efficiently. DND utilizes accessible information and trains a robust function to measure similarities between publications, and then determines whether they belong to the same author. In traditional clustering-based approaches for author disambiguation, the number of clusters which is the amount of authors sharing the same name is hard to predict in advance, while DND transforms the clustering task to a linkage prediction task to avoid specifying the number of clusters. We validate the effectiveness of DND on two real-world datasets. The experimental results indicate that DND achieves a competitive performance compared with the baselines.},
  archive      = {J_NCA},
  author       = {Chen, Yibo and Jiang, Zhiyi and Gao, Jianliang and Du, Hongliang and Gao, Liping and Li, Zhao},
  doi          = {10.1007/s00521-020-05684-y},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13093-13108},
  shortjournal = {Neural Comput. Appl.},
  title        = {A supervised and distributed framework for cold-start author disambiguation in large-scale publications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Item trend learning for sequential recommendation system
using gated graph neural network. <em>NCA</em>, <em>35</em>(18),
13077–13092. (<a
href="https://doi.org/10.1007/s00521-021-05723-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation system, or recommender system, is widely used in online Web applications like e-commerce Web sites and movie review Web sites. Sequential recommender put more emphasis upon user’s short-term preference through exploiting information from its recent history. By incorporating the user short-term preference into the recommendation, the algorithm achieves a higher accuracy, which proves that a more accurate user portrait or representation boosts the performance to a great extent. Intuitionally, we seek to improve the current item representation modeling via incorporating the item trend information. Most of the recommendation models neglect the importance of the ever-changing item popularity. To this end, this paper introduces a novel sequential recommendation approach dubbed TRec. TRec learns the item trend information from the implicit user interaction history and incorporates the item trend information into the subsequent item recommendation tasks. After that, a self-attention mechanism is used for better representation. We also investigate alternative ways to model the proposed item trend representation; we evaluate two variant models which leverage the power of gated graph neural network upon the item trend representation modeling to boost the representation ability. We conduct extensive experiments with seven baseline methods on four benchmark datasets. The empirical results show that our proposed approach outperforms the state-of-the-art models as high as 18.2\%. The experiment result displays the effectiveness in item trend information learning while with low computational complexity as well. Our study demonstrates the importance of item trend information in recommendation system.},
  archive      = {J_NCA},
  author       = {Tao, Ye and Wang, Can and Yao, Lina and Li, Weimin and Yu, Yonghong},
  doi          = {10.1007/s00521-021-05723-2},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13077-13092},
  shortjournal = {Neural Comput. Appl.},
  title        = {Item trend learning for sequential recommendation system using gated graph neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial dual autoencoders for trust-aware
recommendation. <em>NCA</em>, <em>35</em>(18), 13065–13075. (<a
href="https://doi.org/10.1007/s00521-021-05722-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems face longstanding challenges in gaining users’ trust due to the unreliable information caused by profile injection or human misbehavior. Traditional solutions to those challenges focus on leveraging users’ social relationships for inferring the user preference, i.e., recommending items according to the preference by user’s trusted friends; or adding random noise to the input to improve the robustness of the recommender systems. However, such approaches cannot defend the real-world noises like fake ratings. The recommender model is generally built upon all the user-item interactions, which incorporates the information from fake ratings or spammer groups, that neglects the reliability of the ratings. To address the above challenges, we propose an adversarial training approach in this work. In details, our approach includes two components: a predictor that infers the user preference; and a discriminator that enforces cohort rating patterns. In particular, the predictor applies an encoder-decoder structure to learn the shared latent information from sparse users’ ratings and trust relationships; the discriminator enforces the predictor to provide ratings as coherent with the cohort rating patterns. Our extensive experiments on three real-world datasets show the advantages of our approach over several competitive baselines.},
  archive      = {J_NCA},
  author       = {Dong, Manqing and Yao, Lina and Wang, Xianzhi and Xu, Xiwei and Zhu, Liming},
  doi          = {10.1007/s00521-021-05722-3},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13065-13075},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adversarial dual autoencoders for trust-aware recommendation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HeteGraph: Graph learning in recommender systems via graph
convolutional networks. <em>NCA</em>, <em>35</em>(18), 13047–13063. (<a
href="https://doi.org/10.1007/s00521-020-05667-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of online information, many recommendation methods have been proposed. This research direction is boosted with deep learning architectures, especially the recently proposed graph convolutional networks (GCNs). GCNs have shown tremendous potential in graph embedding learning thanks to its inductive inference property. However, most of the existing GCN-based methods focus on solving tasks in the homogeneous graph settings, and none of them considers heterogeneous graph settings. In this paper, we bridge the gap by developing a novel framework called HeteGraph based on the GCN principles. HeteGraph can handle heterogeneous graphs in the recommender systems. Specifically, we propose a sampling technique and a graph convolutional operation to learn high-quality graph’s node embeddings, which differs from the traditional GCN approaches where a full graph adjacency matrix is needed for the embedding learning. We design two models based on the HeteGraph framework to evaluate two important recommendation tasks, namely item rating prediction and diversified item recommendations. Extensive experiments show the encouraging performance of HeteGraph on the first task and the state-of-the-art performance on the second task.},
  archive      = {J_NCA},
  author       = {Tran, Dai Hoang and Sheng, Quan Z. and Zhang, Wei Emma and Aljubairy, Abdulwahab and Zaib, Munazza and Hamad, Salma Abdalla and Tran, Nguyen H. and Khoa, Nguyen Lu Dang},
  doi          = {10.1007/s00521-020-05667-z},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13047-13063},
  shortjournal = {Neural Comput. Appl.},
  title        = {HeteGraph: Graph learning in recommender systems via graph convolutional networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development and external evaluation of predictions models
for mortality of COVID-19 patients using machine learning method.
<em>NCA</em>, <em>35</em>(18), 13037–13046. (<a
href="https://doi.org/10.1007/s00521-020-05592-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To predict the mortality of patients with coronavirus disease 2019 (COVID-19). We collected clinical data of COVID-19 patients between January 18 and March 29 2020 in Wuhan, China . Gradient boosting decision tree (GBDT), logistic regression (LR) model, and simplified LR were built to predict the mortality of COVID-19. We also evaluated different models by computing area under curve (AUC), accuracy, positive predictive value (PPV), and negative predictive value (NPV) under fivefold cross-validation. A total of 2924 patients were included in our evaluation, with 257 (8.8\%) died and 2667 (91.2\%) survived during hospitalization. Upon admission, there were 21 (0.7\%) mild cases, 2051 (70.1\%) moderate case, 779 (26.6\%) severe cases, and 73 (2.5\%) critically severe cases. The GBDT model exhibited the highest fivefold AUC, which was 0.941, followed by LR (0.928) and LR-5 (0.913). The diagnostic accuracies of GBDT, LR, and LR-5 were 0.889, 0.868, and 0.887, respectively. In particular, the GBDT model demonstrated the highest sensitivity (0.899) and specificity (0.889). The NPV of all three models exceeded 97\%, while their PPV values were relatively low, resulting in 0.381 for LR, 0.402 for LR-5, and 0.432 for GBDT. Regarding severe and critically severe cases, the GBDT model also performed the best with a fivefold AUC of 0.918. In the external validation test of the LR-5 model using 72 cases of COVID-19 from Brunei, leukomonocyte (\%) turned to show the highest fivefold AUC (0.917), followed by urea (0.867), age (0.826), and SPO2 (0.704). The findings confirm that the mortality prediction performance of the GBDT is better than the LR models in confirmed cases of COVID-19. The performance comparison seems independent of disease severity.},
  archive      = {J_NCA},
  author       = {Li, Simin and Lin, Yulan and Zhu, Tong and Fan, Mengjie and Xu, Shicheng and Qiu, Weihao and Chen, Can and Li, Linfeng and Wang, Yao and Yan, Jun and Wong, Justin and Naing, Lin and Xu, Shabei},
  doi          = {10.1007/s00521-020-05592-1},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13037-13046},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development and external evaluation of predictions models for mortality of COVID-19 patients using machine learning method},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transferring fashion to surveillance with weak labels.
<em>NCA</em>, <em>35</em>(18), 13021–13035. (<a
href="https://doi.org/10.1007/s00521-020-05528-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of automatic clothing parsing in surveillance images using the information from user-generated tags, such as “jeans” and “T-shirt.” Although clothing parsing has achieved great success in the fashion domain, it is quite challenging to parse target under practical surveillance conditions due to the presence of complex environmental interference, such as that from low resolution, viewpoint variations and lighting changes. Our method is developed to capture target information from the fashion domain and apply this information to a surveillance domain by weakly supervised transfer learning. Most target tags convey strong location information (e.g., “T-shirt” is always shown in the upper region), which can be used as weak labels for our transfer method. Both quantitative and qualitative experiments conducted on practical surveillance datasets demonstrate the effectiveness of the proposed surveillance data enhancing method.},
  archive      = {J_NCA},
  author       = {Zheng, Qi and He, Zheng and Liang, Chao and Chen, Jun and Lin, Chia-Wen and Tao, Dapeng},
  doi          = {10.1007/s00521-020-05528-9},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13021-13035},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transferring fashion to surveillance with weak labels},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selective information passing for MR/CT image segmentation.
<em>NCA</em>, <em>35</em>(18), 13007–13020. (<a
href="https://doi.org/10.1007/s00521-020-05407-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated medical image segmentation plays an important role in many clinical applications, which however is a very challenging task, due to complex background texture, lack of clear boundary and significant shape and texture variation between images. Many researchers proposed an encoder–decoder architecture with skip connections to combine low-level feature maps from the encoder path with high-level feature maps from the decoder path for automatically segmenting medical images. The skip connections have been shown to be effective in recovering fine-grained details of the target objects and may facilitate the gradient back-propagation. However, not all the feature maps transmitted by those connections contribute positively to the network performance. In this paper, to adaptively select useful information to pass through those skip connections, we propose a novel 3D network with self-supervised function, named selective information passing network. We evaluate our proposed model on the MICCAI Prostate MR Image Segmentation 2012 Grant Challenge dataset, TCIA Pancreas CT-82 and MICCAI 2017 Liver Tumor Segmentation Challenge dataset. The experimental results across these datasets show that our model achieved improved segmentation results and outperformed other state-of-the-art methods. The source code of this work is available at https://github.com/ahukui/SIPNet .},
  archive      = {J_NCA},
  author       = {Zhu, Qikui and Li, Liang and Hao, Jiangnan and Zha, Yunfei and Zhang, Yan and Cheng, Yanxiang and Liao, Fei and Li, Pingxiang},
  doi          = {10.1007/s00521-020-05407-3},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {13007-13020},
  shortjournal = {Neural Comput. Appl.},
  title        = {Selective information passing for MR/CT image segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep spatial–temporal structure learning for rumor detection
on twitter. <em>NCA</em>, <em>35</em>(18), 12995–13005. (<a
href="https://doi.org/10.1007/s00521-020-05236-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread of rumors on social media, carrying unreal or even malicious information, brings negative effects on society and individuals, which makes the automatic detection of rumors become particularly important. Most of the previous studies focused on text mining using supervised models based on feature engineering or deep learning models. In recent years, another parallel line of works, which focuses on the spatial structure of message propagation, provides an alternative and promising solution. However, these existing methods in this parallel line largely overlooked the temporal structure information associated with the spatial structure in message propagation. Actually the addition of temporal structure information can make the message propagations be classified from the perspective of spatial–temporal structure, a more fine-grained perspective. Under these observations, this paper proposes a spatial–temporal structure neural network for rumor detection, termed as STS-NN, which treats the spatial structure and the temporal structure as a whole to model the message propagation. All the STS-NN units are parameter shared and consist of three components, including spatial capturer, temporal capturer and integrator, to capture the spatial–temporal information for the message propagation. The results show that our approach obtains better performance than baselines in both rumor classification and early detection.},
  archive      = {J_NCA},
  author       = {Huang, Qi and Zhou, Chuan and Wu, Jia and Liu, Luchen and Wang, Bin},
  doi          = {10.1007/s00521-020-05236-4},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {12995-13005},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep spatial–temporal structure learning for rumor detection on twitter},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolution of cooperation in malicious social networks with
differential privacy mechanisms. <em>NCA</em>, <em>35</em>(18),
12979–12994. (<a
href="https://doi.org/10.1007/s00521-020-05243-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperation is an essential behavior in multi-agent systems. Existing mechanisms have two common drawbacks. The first drawback is that malicious agents are not taken into account. Due to the diverse roles in the evolution of cooperation, malicious agents can exist in multi-agent systems, and they can easily degrade the level of cooperation by interfering with agent’s actions. The second drawback is that most existing mechanisms have a limited ability to fit in different environments, such as different types of social networks. The performance of existing mechanisms heavily depends on some factors, such as network structures and the initial proportion of cooperators. To solve these two drawbacks, we propose a novel mechanism which adopts differential privacy mechanisms and reinforcement learning. Differential privacy mechanisms can be used to relieve the impact of malicious agents by exploiting the property of randomization. Reinforcement learning enables agents to learn how to make decisions in various social networks. In this way, the proposed mechanism can promote the evolution of cooperation in malicious social networks.},
  archive      = {J_NCA},
  author       = {Zhang, Tao and Ye, Dayong and Zhu, Tianqing and Liao, Tingting and Zhou, Wanlei},
  doi          = {10.1007/s00521-020-05243-5},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {12979-12994},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evolution of cooperation in malicious social networks with differential privacy mechanisms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based deep convolutional neural network for
spectral efficiency optimization in MIMO systems. <em>NCA</em>,
<em>35</em>(18), 12967–12978. (<a
href="https://doi.org/10.1007/s00521-020-05142-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral efficiency (SE) optimization in massive multiple input multiple output (MIMO) antenna cognitive systems is a challenge originated from the coexistence restrictions. Traditional power allocation can optimize the SE; however, involving deep learning can meet real-time and fairness processing requirements. In unfair allocation problem, all power is possibly assigned to one or few antennas of a particular user. In this paper, we build a mathematical optimization model considering the fairness problem such that SE is optimized for all users. To implement the model, we propose an attention-based convolutional neural network (Att-CNN), where $$h_0$$ and $$h_k$$ (i.e., cross-interference and direct channels) attention mechanisms are used to improve the SE. The convolutional neural network is applied to decrease the floating point operations (FLOPs) and number of network parameters. We conducted experiments from these aspects: Fair antenna power allocation, power allocation performance and computational performance. Heat maps with different interference thresholds show the fair allocation for all users. Analyses of SE validate the superiority of the Att-CNN compared with the equal power allocation and fully connected neural network (FNN) schemes. The analyses of the FLOPs and number of parameters show the superiority of the Att-CNN over the FNN.},
  archive      = {J_NCA},
  author       = {Sun, Danfeng and Yaqot, Abdullah and Qiu, Jiachen and Rauchhaupt, Lutz and Jumar, Ulrich and Wu, Huifeng},
  doi          = {10.1007/s00521-020-05142-9},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {12967-12978},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention-based deep convolutional neural network for spectral efficiency optimization in MIMO systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention deep residual networks for MR image analysis.
<em>NCA</em>, <em>35</em>(18), 12957–12966. (<a
href="https://doi.org/10.1007/s00521-020-05083-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate diseases often occur in men. For further clinical treatment and diagnosis, we need to do accurate segmentation on prostate. There are already many methods that concentrate on solving the problem of automatic prostate MR image segmentation. However, the design of some hyperparameters of these methods is migrated from the models that are used for nature images which do not consider the difference between medical image and nature image. Besides, there is trend that researchers are likely to use deeper and more complicated networks to achieve high accuracy. The improvement is limited with surging parameters, computations, training time, and inference time. In this paper, we propose an efficient attention residual U-Net to segment the prostate MR image. We analyze the property of prostate MR image and fine-tune the architecture of U-Net. To accelerate the convergence of our method, residual connection and channel attention are added to our network. A set of experiments suggest our method can achieve a similar accuracy of state of the art with less parameters, less computations, shorter training time, and shorter inference time.},
  archive      = {J_NCA},
  author       = {Mei, Mengqing and He, Fazhi and Xue, Shan},
  doi          = {10.1007/s00521-020-05083-3},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {12957-12966},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention deep residual networks for MR image analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new point-of-interest group recommendation method in
location-based social networks. <em>NCA</em>, <em>35</em>(18),
12945–12956. (<a
href="https://doi.org/10.1007/s00521-020-04979-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {POI group recommendation is one of the hottest research topics in location-based social networks, which recommends the most agreeable places for a group of users. However, traditional POI group recommendation methods only generate a consensus function to aggregate individual preference into group preference and they do not consider all the factors that can determine the results of POI group recommendation, which leads to a low recommendation accuracy. What’s more, these methods have a long running time. Therefore, in this paper, we propose a new POI group recommendation method with an extreme learning machine (ELM) called PGR-ELM. The PGR-ELM method regards POI group recommendation as a binary classification problem. First, three features are extracted from three factors: POI popularity, group members’ distance to POI, members’ interest preferences combined affinity between group members. These features simultaneously consider all the factors that can determine the results of recommendation and guarantee the effectiveness of POI group recommendation. Then, the extracted features are input to train an ELM classifier because of its fast learning speed, which guarantees the efficiency of POI group recommendation. Finally, extensive experiments verify the accuracy and efficiency of PGR-ELM method.},
  archive      = {J_NCA},
  author       = {Zhao, Xiangguo and Zhang, Zhen and Bi, Xin and Sun, Yongjiao},
  doi          = {10.1007/s00521-020-04979-4},
  journal      = {Neural Computing and Applications},
  number       = {18},
  pages        = {12945-12956},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new point-of-interest group recommendation method in location-based social networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strike off removal in indic scripts with transfer learning.
<em>NCA</em>, <em>35</em>(17), 12927–12943. (<a
href="https://doi.org/10.1007/s00521-023-08433-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strike-off text poses major challenges in handwritten text recognition as it changes the semantic and structural information of the image. Although significant results have been achieved in identifying and removing such strike-off data using deep learning methodologies, most have been done for Roman scripts only. Deep learning approaches require a large amount of data with a high cost of training for every script individually to derive effective performance. Due to its complex nature and non-availability of sufficient data, research in strike-off removal in Indic scripts is limited. To address this problem, we propose reducing the requirement of a huge amount of data and minimizing the training cost through transfer learning. With the objective of strike-off removal in multiple Indic scripts, we leverage the experiences of a pre-trained model (trained on the Roman script) for strike-off removal in different domains (Indic scripts). We consider handwritten text documents of $${\textbf {10}}$$ different Indic scripts and introduce $${\textbf {7}}$$ different strike-offs in these documents. We implement Few-Shot Learning (FSL) and Zero-Shot Learning (ZSL) to train various state-of-the-art deep generative models on a few samples of the mentioned Indic texts. An extensive analysis of the results for ZSL and FSL has been presented with the perspective of source hypothesis generalization capability and the strength of relatedness of source and target domains. The results show that the degree of adaptability of the source hypothesis is significant for the right amount of transfer to take place. The scripts with angular structure have performed better than the round structured scripts as there is a higher degree of relatedness of angular scripts with the Roman script (source script). FSL and ZSL approaches promise to reduce data requirements and training costs for strike-off removal.},
  archive      = {J_NCA},
  author       = {Nigam, Shivangi and Behera, Adarsh Prasad and Gogoi, Manas and Verma, Shekhar and Nagabhushan, P.},
  doi          = {10.1007/s00521-023-08433-z},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12927-12943},
  shortjournal = {Neural Comput. Appl.},
  title        = {Strike off removal in indic scripts with transfer learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparative approach to different convolutional neural
network (CNN) architectures applied to human behavior detection.
<em>NCA</em>, <em>35</em>(17), 12915–12925. (<a
href="https://doi.org/10.1007/s00521-023-08430-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical diagnostics, product classification, surveillance and detection of inappropriate behavior are becoming increasingly sophisticated due to the development of methods based on image analysis using neural networks. Considering this, in this work, we evaluate state-of-the-art convolutional neural network architectures proposed in recent years to classify the driving behavior and distractions of drivers. Our main goal is to measure the performance of such architectures using only free resources (i.e., free graphic processing unit, open source) and to evaluate how much of this technological evolution is available to regular users.},
  archive      = {J_NCA},
  author       = {Shirabayashi, Juliana Verga and Braga, Ana Silvia Moretto and da Silva, Jair},
  doi          = {10.1007/s00521-023-08430-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12915-12925},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparative approach to different convolutional neural network (CNN) architectures applied to human behavior detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparative study of three quantum-inspired optimization
algorithms for robust tuning of power system stabilizers. <em>NCA</em>,
<em>35</em>(17), 12905–12914. (<a
href="https://doi.org/10.1007/s00521-023-08429-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-frequency oscillations (LFO) are a significant problem for multi-machine electrical power system (EPS). These oscillations are undesirable as they reduce the power transfer capability of the transmission line and thus directly influence competitive electrical markets. The power system stabilizers (PSS) play a vital role in damping low-frequency oscillations to improve the dynamic stability of the power system. However, these controllers must be tuned in a coordinated and robust manner for effective performance. PSS tuning is characterized by a complex optimization problem that may involve hundreds of variables. The tuning procedure is modeled as an optimization problem which aims at maximizing the damping ratio coefficients of the closed-loop power system considering multiple operating points. In this context, this article employs and compares three metaheuristics with quantum characteristics, namely quantum particle swarm optimization (QPSO), quantum flower pollination algorithm (QFPA) and quantum gray wolf optimizer (QGWO). The aforementioned metaheuristics are used in PSS tuning in four test systems with 5 generators–7 buses, 10 generators–39 buses, 50 generators–616 buses and 170 generators–3584 buses. The results obtained by the quantum algorithms are compared through statistical indices and boxplot. The optimization results show that the QFPA and QGWO provide better system damping than the QPSO for the large electrical system.},
  archive      = {J_NCA},
  author       = {Costa Filho, Raimundo N. D.},
  doi          = {10.1007/s00521-023-08429-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12905-12914},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparative study of three quantum-inspired optimization algorithms for robust tuning of power system stabilizers},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic stress detection in car drivers based on
non-invasive physiological signals using machine learning techniques.
<em>NCA</em>, <em>35</em>(17), 12891–12904. (<a
href="https://doi.org/10.1007/s00521-023-08428-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stress is now thought to be a major cause to a wide range of human health issues. However, many people may ignore their stress feelings and disregard to take action before serious physiological and mental disorders take place. The heart rate (HR) and blood pressure (BP) are the most physiological markers used in various studies to detect mental stress for a human, and because they are captured non-invasively using wearable sensors, these markers are recommended to provide information on a person’s mental state. Most stress assessment studies have been undertaken in a laboratory-based controlled environment. This paper proposes an approach to identify the mental stress of automotive drivers based on selected biosignals, namely, ECG, EMG, GSR, and respiration rate. In this study, six different machine learning models (KNN, SVM, DT, LR, RF, and MLP) have been used to classify between the stressed and relaxation states. Such system can be integrated with a Driver Assistance System (DAS). The proposed stress detection technique (SDT) consists of three main phases: (1) Biosignal Pre-processing, in which the signal is segmented and filtered. (2) Feature Extraction, in which some discriminate features are extracted from each biosignal to describe the mental state of the driver. (3) Classification. The results show that the RF classifier outperforms other techniques with a classification accuracy of 98.2\%, sensitivity 97\%, and specificity 100\% using the drivedb dataset.},
  archive      = {J_NCA},
  author       = {Siam, Ali I. and Gamel, Samah A. and Talaat, Fatma M.},
  doi          = {10.1007/s00521-023-08428-w},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12891-12904},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic stress detection in car drivers based on non-invasive physiological signals using machine learning techniques},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Command filter-based adaptive fuzzy fixed-time tracking
control for strict-feedback nonlinear systems with nonaffine nonlinear
faults. <em>NCA</em>, <em>35</em>(17), 12875–12889. (<a
href="https://doi.org/10.1007/s00521-023-08418-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates adaptive fuzzy fixed-time fault-tolerant control for strict-feedback nonlinear systems with unknown nonaffine nonlinear faults. To address the nonaffine nonlinear fault, Butterworth filter signal is introduced into the adaptive backstepping control design procedures. The “explosion of complexity” is avoided by adopting command filter method, and the filter errors can be eliminated by introducing compensating signals. Fuzzy logic system as an approximator that is employed to estimate the unknown term in the system. Lyapunov stability analysis testifies that the closed loop system is semiglobally fixed-time stable, and the tracking error can converge to a small neighborhood of zero in a fixed time that the convergence time is not affected by the initial conditions of the system. The simulation consequences illustrate the effectiveness of the proposed control method.},
  archive      = {J_NCA},
  author       = {Wang, Jiayao and Cui, Yang},
  doi          = {10.1007/s00521-023-08418-y},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12875-12889},
  shortjournal = {Neural Comput. Appl.},
  title        = {Command filter-based adaptive fuzzy fixed-time tracking control for strict-feedback nonlinear systems with nonaffine nonlinear faults},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepPress: Guided press release topic-aware text generation
using ensemble transformers. <em>NCA</em>, <em>35</em>(17), 12847–12874.
(<a href="https://doi.org/10.1007/s00521-023-08393-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Guided text generation is one of the key issues when it comes to creating human-like artificial intelligence writing machines. Humans can use their writing skills depending on the topic of the text and the pieces of information they want to include. The context and style also play an important role in mediating the engagement level of the press release. However, current research does focus on conditional text continuation rather than a specific writing task. To address this problem, we propose DeepPress, a topic-aware approach that generates effective press release content when the keywords are situated in the context. We used a variety of public press datasets on specific topics to build and test our models. We show the proposed deep model achieves fine-grained control of attributes such as topics and sentiment while retaining fluency for the generated press release articles.},
  archive      = {J_NCA},
  author       = {Rahali, Abir and Akhloufi, Moulay A.},
  doi          = {10.1007/s00521-023-08393-4},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12847-12874},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepPress: Guided press release topic-aware text generation using ensemble transformers},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Q-learning-based sequential recovery of interdependent
power-communication network after cascading failures. <em>NCA</em>,
<em>35</em>(17), 12833–12845. (<a
href="https://doi.org/10.1007/s00521-023-08399-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing robustness of cyber-physical system under cascading failures still remains to be an important problem. In this paper, we propose a novel coupled model with the process of cascading failure, the DC power flow model and sequential bus/branch recovery in the interdependent power-communication network. Then, we adopt the Q-learning algorithm to search out the optimal recovery sequence with the minimal number of recovery times. By comparing the recovery costs of sequential bus recovery and sequential branch recovery, it is found that the strategy of branch recovery requires less recovery cost. Besides, we have also compared the performance of Q-learning-based branch recovery strategy with those of several other topology-related branch recovery strategies. Experimental results show that the Q-learning-based algorithm can effectively find the optimal sequence of branch recovery.},
  archive      = {J_NCA},
  author       = {Huang, Wei and Gao, Yuxin and Zhang, Tianyi and Gao, Hua},
  doi          = {10.1007/s00521-023-08399-y},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12833-12845},
  shortjournal = {Neural Comput. Appl.},
  title        = {Q-learning-based sequential recovery of interdependent power-communication network after cascading failures},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Comprehensive machine and deep learning analysis of
sensor-based human activity recognition. <em>NCA</em>, <em>35</em>(17),
12793–12831. (<a
href="https://doi.org/10.1007/s00521-023-08374-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) is a crucial research focus in the body area networks and pervasive computing domains. The goal of HAR is to examine activities from raw sensor data, video sequences, or even images. It aims to classify input data correctly into its underlying category. In the current study, machine and deep learning approaches along with different traditional dimensionality reduction and TDA feature extraction techniques are suggested to solve the HAR problem. Two public datasets (i.e., WISDM and UCI-HAR) are used to conduct the experiments. Different data balancing techniques are utilized to deal with the problem of imbalanced data. Additionally, a sampling mechanism with two overlapping percentages (i.e., 0\% and 50\%) is applied to each dataset to retrieve four balanced datasets. Five traditional dimensionality reduction techniques in addition to the Topological Data Analysis (TDA) are utilized. Seven machine learning (ML) algorithms are used to perform HAR where six of them are ensemble classifiers. In addition to that, 1D-CNN, BiLSTM, and GRU deep learning approaches are utilized. Three categories of experiments (i.e., ML with traditional features, ML with TDA, and DL) are applied. For the first category experiments, the best-reported scores concerning the WISDM dataset are accuracy and WSM of 99.10\% and 86.61\%, respectively. When concerning the UCI-HAR dataset, the best-reported scores are accuracy and WSM of 100\% and 100\%, respectively. For the second category experiments, the best-reported scores concerning the WISDM dataset are accuracy and WSM of 95.34\% and 89.62\%, respectively. When concerning the UCI-HAR dataset, the best-reported scores are accuracy and WSM of 96.70\% and 92.57\%, respectively. For the third category experiments, the best-reported scores concerning the WISDM dataset are accuracy and WSM of 99.90\% and 99.76\%, respectively. When concerning the UCI-HAR dataset, the best-reported scores are accuracy and WSM of 100\% and 100\%, respectively. After concluding the final results, the suggested approach is compared with 6 related studies utilizing the same dataset(s).},
  archive      = {J_NCA},
  author       = {Balaha, Hossam Magdy and Hassan, Asmaa El-Sayed},
  doi          = {10.1007/s00521-023-08374-7},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12793-12831},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comprehensive machine and deep learning analysis of sensor-based human activity recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning-based histopathology classifier for focal
cortical dysplasia. <em>NCA</em>, <em>35</em>(17), 12775–12792. (<a
href="https://doi.org/10.1007/s00521-023-08364-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A light microscopy-based histopathology diagnosis of human brain specimens obtained from epilepsy surgery remains the gold standard to confirm the underlying cause of a patient’s focal epilepsy and further inform postsurgical patient management. The differential diagnosis of neocortical specimens in the realm of epilepsy surgery remains, however, challenging. Herein, we developed an open access, deep learning-based classifier to histopathologically assess whole slide microscopy images (WSI) and to automatically recognize various subtypes of Focal Cortical Dysplasia (FCD), according to the ILAE consensus classification update of 2022. We trained a convolutional neuronal network (CNN) with fully digitalized WSI of hematoxylin–eosin stainings obtained from 125 patients covering the spectrum of mild malformation of cortical development (mMCD), mMCD with oligodendroglial hyperplasia in epilepsy (MOGHE), FCD ILAE Type 1a, 2a and 2b using 414 formalin-fixed and paraffin-embedded archival tissue blocks. An additional series of 198 postmortem tissue blocks from 59 patients without neurological disorders served as control to train the CNN for homotypic frontal, temporal and occipital areas and heterotypic Brodmann areas 4 and 17, entorhinal cortex and dentate gyrus. Special stains and immunohistochemical reactions were used to comprehensively annotate the region of interest. We then programmed a novel tile extraction pipeline and graphical dashboard to visualize all areas on the WSI recognized by the CNN. Our deep learning-based classifier is able to compute 1000 × 1000 µm large tiles and recognizes 25 anatomical regions and FCD categories with an accuracy of 98.8\% (F1 score = 0.82). Microscopic review of regions predicted by the network confirmed these results. This deep learning-based classifier will be made available as online web application to support the differential histopathology diagnosis in neocortical human brain specimens obtained from epilepsy surgery. It will also serve as blueprint to build a digital histopathology slide suite addressing all major brain diseases encountered in patients with surgically amenable focal epilepsy.},
  archive      = {J_NCA},
  author       = {Vorndran, Jörg and Neuner, Christoph and Coras, Roland and Hoffmann, Lucas and Geffers, Simon and Honke, Jonas and Herms, Jochen and Roeber, Sigrun and Hamer, Hajo and Brandner, Sebastian and Hartlieb, Till and Pieper, Tom and Kudernatsch, Manfred and Bien, Christian G. and Kalbhenn, Thilo and Simon, Matthias and Adle-Biassette, Homa and Cienfuegos, Jesús and Di Giacomo, Roberta and Garbelli, Rita and Miyata, Hajime and Mühlebner, Angelika and Raicevic, Savo and Rauramaa, Tuomas and Rogerio, Fabio and Blümcke, Ingmar and Jabari, Samir},
  doi          = {10.1007/s00521-023-08364-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12775-12792},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning-based histopathology classifier for focal cortical dysplasia},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature combination mixup: Novel mixup method using feature
combination for neural networks. <em>NCA</em>, <em>35</em>(17),
12763–12774. (<a
href="https://doi.org/10.1007/s00521-023-08421-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixup is a data augmentation method that generates a new sample by calculating the linear interpolation of two samples. Manifold mixup is an improved version of mixup, where samples are mixed in a randomly selected neural network layer. These mixups can easily be applied to various data types and are practically significant because most data augmentation methods focus on only image data. In this study, we propose a feature combination mixup (FC-mixup) as a versatile and powerful data augmentation method. The proposed method is based on the similarity between feature sets, whereas conventional mixups are based on geometric distances in feature space. We conducted experiments on several datasets. The experimental results showed that the proposed FC-mixup generally outperformed conventional mixups. We also verified the high performance of hybrid methods that combine FC-mixup and manifold mixup.},
  archive      = {J_NCA},
  author       = {Takase, Tomoumi},
  doi          = {10.1007/s00521-023-08421-3},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12763-12774},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feature combination mixup: Novel mixup method using feature combination for neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance analysis and comparison of machine learning and
LoRa-based healthcare model. <em>NCA</em>, <em>35</em>(17), 12751–12761.
(<a href="https://doi.org/10.1007/s00521-023-08411-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes Mellitus (DM) is a widespread condition that is one of the main causes of health disasters around the world, and health monitoring is one of the sustainable development topics. Currently, the Internet of Things (IoT) and Machine Learning (ML) technologies work together to provide a reliable method of monitoring and predicting Diabetes Mellitus. In this paper, we present the performance of a model for patient real-time data collection that employs the Hybrid Enhanced Adaptive Data Rate (HEADR) algorithm for the Long-Range (LoRa) protocol of the IoT. On the Contiki Cooja simulator, the LoRa protocol&#39;s performance is measured in terms of high dissemination and dynamic data transmission range allocation. Furthermore, by employing classification methods for the detection of diabetes severity levels on acquired data via the LoRa (HEADR) protocol, Machine Learning prediction takes place. For prediction, a variety of Machine Learning classifiers are employed, and the final results are compared with the already existing models where the Random Forest and Decision Tree classifiers outperform the others in terms of precision, recall, F-measure, and receiver operating curve (ROC) in the Python programming language. We also discovered that using k-fold cross-validation on k-neighbors, Logistic regression (LR), and Gaussian Nave Bayes (GNB) classifiers boosted the accuracy.},
  archive      = {J_NCA},
  author       = {Verma, Navneet and Singh, Sukhdip and Prasad, Devendra},
  doi          = {10.1007/s00521-023-08411-5},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12751-12761},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance analysis and comparison of machine learning and LoRa-based healthcare model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel deeper AWRDNet: Adverse weather-affected night scene
restorator cum detector net for accurate object detection. <em>NCA</em>,
<em>35</em>(17), 12729–12750. (<a
href="https://doi.org/10.1007/s00521-023-08390-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in adversarial atmospheric attacks, such as fog, rain, low light, and dust conditions, is a challenging task with regards to computer vision. Moreover, the applicability of convolutional neural network-based object detection architectures in various weather-affected night-time thermal scenes has not been extensively reported in recent and past literatures. The extraction of region of interest through anchors from each multi-resolution feature map (FM), either shallow or deep, suffers from several issues in adverse weather-degraded scenarios. Our proposed architecture, namely adverse weather-affected night scene restorator cum detector net (AWRDNet), focuses on the process of recovering such adverse weather-degraded video frames to restored frames through deeper convolutional layers. Further, our network reduces the time-consuming generation of pre-defined anchors in each FM at a deeper de-convolution layer, which combines different scales and aspect ratios for anchor boxes from multiple sets to naturally handle objects of various sizes. Considering the multi-scale anchor boxes at multiple set, an anchor refinement strategy has been applied to reduce memory consumption. The performance of the AWRDNet architecture is evaluated using standard detection performance metrics over the Tripura University Video Dataset at Night Time (TU-VDN) dataset which contains objects with annotated bounding box of the image frame sequences, and the available PASCAL VOC 2007 2012 datasets, and ZUT thermal dataset.},
  archive      = {J_NCA},
  author       = {Singha, Anu and Bhowmik, Mrinal Kanti},
  doi          = {10.1007/s00521-023-08390-7},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12729-12750},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel deeper AWRDNet: Adverse weather-affected night scene restorator cum detector net for accurate object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Real-time facial emotion recognition system among children
with autism based on deep learning and IoT. <em>NCA</em>,
<em>35</em>(17), 12717–12728. (<a
href="https://doi.org/10.1007/s00521-023-08372-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosis of autism considers a challenging task for medical experts since the medical diagnosis mainly depends on the abnormalities in the brain functions that may not appear in the early stages of early onset of autism disorder. Facial expression can be an alternative and efficient solution for the early diagnosis of Autism. This is due to Autistic children usually having distinctive patterns which facilitate distinguishing them from normal children. Assistive technology has proven to be one of the most important innovations in helping people with autism improve their quality of life. A real-time emotion identification system for autistic youngsters was developed in this study. Face identification, facial feature extraction, and feature categorization are the three stages of emotion recognition. A total of six facial emotions are detected by the propound system: anger, fear, joy, natural, sadness, and surprise. This section proposes an enhanced deep learning (EDL) technique to classify the emotions using convolutional neural network. The proposed emotion detection framework takes the benefit from using fog and IoT to reduce the latency for real-time detection with fast response and to be a location awareness. From the results, EDL outperforms other techniques as it achieved 99.99\% accuracy. EDL used GA to select the optimal hyperparameters for the CNN.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M.},
  doi          = {10.1007/s00521-023-08372-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12717-12728},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time facial emotion recognition system among children with autism based on deep learning and IoT},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction to: TMHSCA: A novel hybrid two-stage mutation
with a sine cosine algorithm for discounted 0-1 knapsack problems.
<em>NCA</em>, <em>35</em>(17), 12715. (<a
href="https://doi.org/10.1007/s00521-023-08595-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Kang, Yan and Wang, Haining and Pu, Bin and Liu, Jiansong and Lee, Shin-Jye and Yang, Xuekun and Tao, Liu},
  doi          = {10.1007/s00521-023-08595-w},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12715},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: TMHSCA: a novel hybrid two-stage mutation with a sine cosine algorithm for discounted {0-1} knapsack problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). TMHSCA: A novel hybrid two-stage mutation with a sine
cosine algorithm for discounted 0-1 knapsack problems. <em>NCA</em>,
<em>35</em>(17), 12691–12713. (<a
href="https://doi.org/10.1007/s00521-023-08367-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discounted {0-1} knapsack problem (DKP) is an NP-hard problem that is more challenging than the classical knapsack problem. In this paper, an enhanced version of the sine-cosine algorithm (SCA) called TMHSCA is proposed to solve the DKP. The SCA is a novel metaheuristic algorithm based on sine-cosine theory. Three effective improvements are proposed for the SCA to enhance the convergence speed and exploitation capability of the algorithm. First, by dividing the initial population into three subpopulations using random, greedy and opposition-based learning (OBL) strategies, the diversity of the population can be effectively enhanced. Furthermore, a forward-inverse sine-cosine search that expands the search space by utilizing the worst solution as another target is proposed. The proposed forward-inverse sine-cosine search strategy facilitates the algorithm to explore the easily ignored solution space. The last improvement includes the use of an OBL mutation and the mutation operator of differential evolution at a two-stage mutation, which increases the algorithm’s convergence speed and fitness. In our proposed two-stage mutation, the number of mutations can be adaptively adjusted based on the optimization capabilities of the optimal individual. Additionally, a reshuffling repair strategy for repairing infeasible solutions by sorting items into groups to obtain the weight-to-value ratio is proposed. Extensive experiments are conducted on 40 publicly available datasets and are compared to the greedy algorithm, 3 SCAs and 8 competitive baseline methods. The experimental results demonstrate that our method achieves a state-of-the-art performance.},
  archive      = {J_NCA},
  author       = {Kang, Yan and Wang, Haining and Pu, Bin and Liu, Jiansong and Lee, Shin-Jye and Yang, Xuekun and Tao, Liu},
  doi          = {10.1007/s00521-023-08367-6},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12691-12713},
  shortjournal = {Neural Comput. Appl.},
  title        = {TMHSCA: A novel hybrid two-stage mutation with a sine cosine algorithm for discounted {0-1} knapsack problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wrapper-based optimized feature selection using
nature-inspired algorithms. <em>NCA</em>, <em>35</em>(17), 12675–12689.
(<a href="https://doi.org/10.1007/s00521-023-08383-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computations that mimic nature are known as nature-inspired computing. Nature presents a wealthy source of thoughts and ideas for computing. The use of natural galvanized techniques has been found to provide machine solutions to complex problems. One of the challenging issues among researchers is high-dimensional data which contains a large number of unwanted, redundant, and irrelevant features. These redundant or unwanted features reduce the accuracy of machine learning models. Therefore, to solve this problem nowadays metaheuristic techniques are being used. The paper presents both surveys as well as comparison of five metaheuristic algorithms for feature selection. A wrapper-based feature selection approach using five nature-inspired techniques for feature selection has been applied. The binary version of the five swarm-based nature-inspired algorithms (NIAs), namely particle swarm optimization, whale optimization algorithm (WOA), grey wolf optimization (GWO), firefly algorithm, and bat algorithm. WOA and GWO are recent algorithms used for finding optimal feature subsets when there is no empirical information. The S-shape transfer function has been used to convert the continuous value to binary form and K-nearest neighbor is used to calculate the classification accuracy of selected feature subsets. To validate the results of the selected NIAs eleven benchmark datasets from the UCI repository are used. The strength of each NIA has been verified using a nonparametric test called the Friedman rank and Holm test. p value obtained shows that WOA is statistically significant and performs better than other models.},
  archive      = {J_NCA},
  author       = {Karlupia, Namrata and Abrol, Pawanesh},
  doi          = {10.1007/s00521-023-08383-6},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12675-12689},
  shortjournal = {Neural Comput. Appl.},
  title        = {Wrapper-based optimized feature selection using nature-inspired algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end data-dependent routing in multi-path neural
networks. <em>NCA</em>, <em>35</em>(17), 12655–12674. (<a
href="https://doi.org/10.1007/s00521-023-08381-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are known to give better performance with increased depth due to their ability to learn more abstract features. Although the deepening of networks has been well established, there is still room for efficient feature extraction within a layer, which would reduce the need for mere parameter increment. The conventional widening of networks by having more filters in each layer introduces a quadratic increment of parameters. Having multiple parallel convolutional/dense operations in each layer solves this problem, but without any context-dependent allocation of input among these operations: The parallel computations tend to learn similar features making the widening process less effective. Therefore, we propose the use of multi-path neural networks with data-dependent resource allocation from parallel computations within layers, which also lets an input be routed end-to-end through these parallel paths. To do this, we first introduce a cross-prediction-based algorithm between parallel tensors of subsequent layers. Second, we further reduce the routing overhead by introducing feature-dependent cross-connections between parallel tensors of successive layers. Using image recognition tasks, we show that our multi-path networks show superior performance to existing widening and adaptive feature extraction, even ensembles and deeper networks at similar complexity.},
  archive      = {J_NCA},
  author       = {Tissera, Dumindu and Wijesinghe, Rukshan and Vithanage, Kasun and Xavier, Alex and Fernando, Subha and Rodrigo, Ranga},
  doi          = {10.1007/s00521-023-08381-8},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12655-12674},
  shortjournal = {Neural Comput. Appl.},
  title        = {End-to-end data-dependent routing in multi-path neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal PSS design using FDB-based social network search
algorithm in multi-machine power systems. <em>NCA</em>, <em>35</em>(17),
12627–12653. (<a
href="https://doi.org/10.1007/s00521-023-08356-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimal design of Power System Stabilizer (PSS) parameters is a significant optimization problem in power systems. Metaheuristic search (MHS) algorithms are among the most commonly used methods for optimizing PSS parameters. The preferred MHS algorithm must have strong exploration capability and an effective exploitation-exploration balance. The Fitness-Distance Balance (FDB) is a novel method for MHS algorithms, and it is featured by balanced search and effective diversity capabilities. In this paper, the exploration and balanced search capabilities of the Social Network Search (SNS) have been developed by using the FDB method. The FDB method guides the search process in the SNS and enables a more efficient selection of solution candidates in the search space. The performance of FDB-based SNS (FDBSNS) has been tested in the CEC-2014 and CEC-2017 benchmark test suits, and its superiority against SNS has been verified. Moreover, the effect of the FDBSNS was investigated in WSCC 3-machine 9-bus and 10-machine 39-bus New England test systems in the optimal PSS design problem. The obtained results and statistical analyses demonstrated that FDBSNS is a robust MHS algorithm compared to the algorithms in the literature for solving the CEC benchmark suits and optimal PSS design problem.},
  archive      = {J_NCA},
  author       = {Kaymaz, Enes and Güvenç, Uğur and Döşoğlu, M. Kenan},
  doi          = {10.1007/s00521-023-08356-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12627-12653},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal PSS design using FDB-based social network search algorithm in multi-machine power systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RHL-track: Visual object tracking based on recurrent
historical localization. <em>NCA</em>, <em>35</em>(17), 12611–12625. (<a
href="https://doi.org/10.1007/s00521-023-08422-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking (VOT) is a fundamental and complex problem in computer vision field. In the past few years, the research focus has been shifted from template matching to deep learning models. Especially, the Siamese networks dominate tracking domain in recent years, which take the first frame as the reference and perform object detection and localization in the following frames. However, most of them could not capture target changes due to the lack of strong feature representation abilities. To address these issue, we propose an advanced tracking network in this paper based on recurrent historical localization information. Unlike traditional symmetric structures, we utilize two convolution layers to perform target classification that predicts the initial target center. Then, we apply a gated recurrent unit that fuses multi-resolution features with historical localization information to yield the final optimized target position. Extensive experiments have been conducted on six mainstream datasets: OTB100, GOT-10k, TrackingNet, LaSOT, VOT2018 and NFS, where our tracker exhibits state-of-the-art performances.},
  archive      = {J_NCA},
  author       = {Meng, Feiyu and Gong, Xiaomei and Zhang, Yi},
  doi          = {10.1007/s00521-023-08422-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12611-12625},
  shortjournal = {Neural Comput. Appl.},
  title        = {RHL-track: Visual object tracking based on recurrent historical localization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining variable neighborhood with gradient ascent for
learning to rank problem. <em>NCA</em>, <em>35</em>(17), 12599–12610.
(<a href="https://doi.org/10.1007/s00521-023-08412-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic applications for information retrieval research are limited in spite of the importance of this problem domain. Ranking the retrieved documents based on their importance is a vital issue for the scientific and industrial communities. This paper proposes a novel variable neighborhood search (VNS) algorithm with adaptation based on an objective function for the learning to rank (LTR) problem. VNS is a global optimum metaheuristic algorithm that has been engaged to evolve the optimal solutions for heuristic problems based on exploring better neighbor solutions from the current one. The changes from the current to the next optimal solution are made during the perturbation stage to identify the global optimal solutions. The exploration procedure has been made through various mutation step sizes, whereas the exploitation process has been done by checking the quality of the evolved solutions using the fitness function. This research proposes a novel version of VNS based on four random probability distributions with gradient ascent. In addition to using the traditional random generator with gradient ascent for modifying the mutated genes of the neighborhood candidate solution in the following evolving iteration. This novel method in LTR is called gradient variable neighborhood (GVN). In the experiments, we utilized Microsoft Bing search (MSLR-WEB30K), Yahoo, and TREC Million Queries Competitions in 2008 and 2007 (LETOR 4) datasets. From the findings of the results, we can deduce that the GVN method outperformed recent studies on LTR methods.},
  archive      = {J_NCA},
  author       = {Ibrahim, Osman Ali Sadek and Younis, Eman M. G.},
  doi          = {10.1007/s00521-023-08412-4},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12599-12610},
  shortjournal = {Neural Comput. Appl.},
  title        = {Combining variable neighborhood with gradient ascent for learning to rank problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). YoDenBi-NET: YOLO + DenseNet + bi-LSTM-based hybrid deep
learning model for brain tumor classification. <em>NCA</em>,
<em>35</em>(17), 12583–12598. (<a
href="https://doi.org/10.1007/s00521-023-08395-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor, which is the deadliest disease in adults, grows rapidly and disrupts the functioning of organs. Brain tumors can be of different types, depending on their shape, texture, and location. The correct detection of these types helps the field specialist to make the correct diagnosis and thus save the patient&#39;s life. In this study, a three-stage hybrid new classification framework based on YOLO + DenseNet + Bi-LSTM is proposed to classify glioma, meningioma, and pituitary brain tumor types. In this framework, the brain region is detected first through the YOLO detection algorithm. In the second stage, deep features are extracted from this region via a pre-trained deep learning architecture, and in the final stage, brain tumor classification is performed by way of the Bi-LSTM network which is another deep learning model. The proposed model offers high test accuracies of 99.77\% and 99.67\%, respectively, for three brain tumor types using hold-out and tenfold cross-validation techniques on a dataset containing 3064 MRI images. With its high performance in validation and test sets, the proposed hybrid model is better than other previous studies and so it can be used as a useful decision support system for field specialists.},
  archive      = {J_NCA},
  author       = {Karacı, Abdulkadir and Akyol, Kemal},
  doi          = {10.1007/s00521-023-08395-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12583-12598},
  shortjournal = {Neural Comput. Appl.},
  title        = {YoDenBi-NET: YOLO + DenseNet + bi-LSTM-based hybrid deep learning model for brain tumor classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Determination of wheat types using optimized extreme
learning machine with metaheuristic algorithms. <em>NCA</em>,
<em>35</em>(17), 12565–12581. (<a
href="https://doi.org/10.1007/s00521-023-08354-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to increase the market value and quality of wheat, it is important to separate different types and determine the amount of foreign matter using the visual properties of durum and bread wheat. In this study, the extreme learning machine (ELM) algorithm, which is often preferred in real-time applications, was used to make classifications using features obtained from images containing the wheat kernel and foreign matter. The feature selection process was applied to remove the irrelevant ones from the obtained 236 features. In addition, the Harris hawks’ optimizer (HHO), a novel method in the literature, and the particle swarm optimizer (PSO), one of the well-known algorithms, were used to improve the ELM model. As part of this study, new models called HHO-ELM and PSO-ELM were created and compared with the original ELM model and other artificial neural networks (ANNs) studies published in the literature. As a result, in comparison with other models, the optimized ELM models demonstrated good stability and accuracy, having 99.32\% in binary classification and 95.95\% in multi-class classification.},
  archive      = {J_NCA},
  author       = {Dogan, Musa and Ozkan, Ilker Ali},
  doi          = {10.1007/s00521-023-08354-x},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12565-12581},
  shortjournal = {Neural Comput. Appl.},
  title        = {Determination of wheat types using optimized extreme learning machine with metaheuristic algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient intrusion detection using multi-player generative
adversarial networks (GANs): An ensemble-based deep learning
architecture. <em>NCA</em>, <em>35</em>(17), 12545–12563. (<a
href="https://doi.org/10.1007/s00521-023-08398-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems (IDSs) investigate various attacks, identify malicious patterns, and implement effective control strategies. With the recent advances in machine learning and deep learning, designing an efficient IDS has become feasible. Existing Deep learning (DL) methods predominantly suffer from data loss or overfitting while handling class-imbalanced data. Generative adversarial networks (GANs) efficiently solve the overfitting class and overlap problems. However, GANs suffer from “instability” in the training process. Another issue also arises in GANs when the input data does not accurately reflect the actual distribution of the data, such that the generator would produce samples of one or a very small number of classes rather than generating samples for all minor classes at the same time; this behavior is called &quot;mode collapse.&quot; To reduce the instability and mode collapse problems and improve the detection accuracy, we developed novel architectures for the generator and discriminator to improve the multi-attack detection problem with a stable training process using ensemble deep learning (EDL) models across various loss functions. To solve the mode collapse problem, we proposed multi-player GANs with teams of multiple generators and discriminators to optimize the learning process while minimizing the chance of mode collapsing. Experimental results over various benchmark datasets show that the developed ensemble-based multi-player GANs (EMP-GANs) outperform the existing methods in terms of quality while maintaining high training stability and minimal chances of mode collapse.},
  archive      = {J_NCA},
  author       = {Soleymanzadeh, Raha and Kashef, Rasha},
  doi          = {10.1007/s00521-023-08398-z},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12545-12563},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient intrusion detection using multi-player generative adversarial networks (GANs): An ensemble-based deep learning architecture},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new robust harris hawk optimization algorithm for large
quadratic assignment problems. <em>NCA</em>, <em>35</em>(17),
12531–12544. (<a
href="https://doi.org/10.1007/s00521-023-08387-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris Hawk optimization (HHO) is a new robust metaheuristic algorithm proposed for the solution of large intractable combinatorial optimization problems. The hawks are cooperative birds and use many intelligent hunting techniques. This study proposes new HHO algorithms for solving the well-known quadratic assignment problem (QAP). Large instances of the QAP have not been solved exactly yet. We implement HHO algorithms with robust tabu search (HHO-RTS) and introduce new operators that simulate the actions of hawks. We also developed an island parallel version of the HHO-RTS algorithm using the message passing interface. We verify the performance of our proposed algorithms on the QAPLIB benchmark library. One hundred and twenty-five of 135 problems are solved optimally, and the average deviation of all the problems is observed to be 0.020\%. The HHO-RTS algorithm is a robust algorithm compared to recent studies in the literature.},
  archive      = {J_NCA},
  author       = {Dokeroglu, Tansel and Ozdemir, Yavuz Selim},
  doi          = {10.1007/s00521-023-08387-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12531-12544},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new robust harris hawk optimization algorithm for large quadratic assignment problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimation of joint torques using an artificial neural
network model based on kinematic and anthropometric data. <em>NCA</em>,
<em>35</em>(17), 12513–12529. (<a
href="https://doi.org/10.1007/s00521-023-08379-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint torques are an important parameter in the mechanical study of human movements. People’s mass properties and movement patterns have different effects on joint torques. As for human segments, measuring joint torques directly limits movement. Therefore, it is a more common practice to determine joint torques indirectly. Mathematical methods have been successfully used to indirectly determine joint torques. However, mathematical techniques can be challenging. Another way to identify joint torques is to use artificial intelligence techniques. In recent years, it has been seen that joint torque estimation algorithms based on artificial neural networks (ANN) give successful results. Electromyography (EMG) is widely used as input data in estimating joint torque with ANN. Obtaining EMG data is a difficult process and requires sensitive sensors. Data variability is an important factor for the joint torque estimation based on the ANN method. It has been seen that some studies have a limited number of participants with similar physical characteristics. In this study, the analysis of sit-to-stand movement was performed on 20 participants with different physical properties. Then, joint torques were calculated with the simulation model. After that, a four-layer neural network was trained using the angular displacements of the joints, segment heights, and segment mass as input data. Here, different ANN model variations were tested in terms of performance, and the best one was selected. It has been seen that the proposed ANN model shows high accuracy in estimating joint torques using a non-complex method.},
  archive      = {J_NCA},
  author       = {Serbest, Kasim and Ozkan, Murat Tolga and Cilli, Murat},
  doi          = {10.1007/s00521-023-08379-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12513-12529},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimation of joint torques using an artificial neural network model based on kinematic and anthropometric data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retinal disease prediction through blood vessel segmentation
and classification using ensemble-based deep learning approaches.
<em>NCA</em>, <em>35</em>(17), 12495–12511. (<a
href="https://doi.org/10.1007/s00521-023-08402-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detection of retinal diseases is found to be more challenging and gaining considerable attention in the recent years. The visual impairments are emerging in different forms and hence effective retina screening system is required. The ophthalmologists utilize colour fundus images normally to diagnose the abnormalities and most of the experiments were conducted by the researchers in classifying the retinal diseases. However, the quality of fundus images gets deteriorated due to low contrast issues and illumination inhomogeneity that affects the overall classification accuracy. In most of the works, convergence rate is obtained to be less, over fitting issues may occur and classification errors are increased. On considering these issues, the proposed work attempts to analyse the performance of Ensemble based Deep learning approaches for retinal disease prediction. The proposed retinal disease prediction method is categorized in to various stages including Pre-processing, Adaptive Gaussian kernel PDF based matched filtering approach, Post processing for segmentation and classification. In pre-processing, the RGB image is transformed into a grayscale retinal image through Principle Component Analysis. The contrast of obtained greyscale retinal image is improved using CLAHE and the image is enhanced by Toggle Contrast operator. In the Adaptive Gaussian kernel, PDF is designed with matched filter kernel to generate the MFR (Matched filtered response) image. In Post processing, the MFR image is directed to ideal entropy based-thresholding to extract binary segmented retinal blood vessel image. This is followed by length filtering for artifact removal and masking is done to generate the accurate segmented blood vessel. The classification of segmented image is performed through three approaches called Efficient Net B0, VGG 16 and ResNet-152. The obtained feature vector is fused through ensemble approach and eleven forms of retinal diseases are classified precisely through softmax classifier. Through the implementation of proposed method, 99.71\% of accuracy, 98.63\% of precision, 98.25\% of recall, 99.22\% of F measure are obtained.},
  archive      = {J_NCA},
  author       = {Kumar, K. Susheel and Singh, Nagendra Pratap},
  doi          = {10.1007/s00521-023-08402-6},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12495-12511},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retinal disease prediction through blood vessel segmentation and classification using ensemble-based deep learning approaches},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sign language recognition via dimensional global–local shift
and cross-scale aggregation. <em>NCA</em>, <em>35</em>(17), 12481–12493.
(<a href="https://doi.org/10.1007/s00521-023-08380-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign languages generally consist of a sequence of upper body gestures and are cooperative processes among various parts such as the hands, arms, and face. Therefore, the dynamics of the parts as well as the holistic appearance of the upper body and individual parts are essential for robust recognition. In this paper, a global–local representation (GLR) module is proposed to boost the spatiotemporal feature modeling. The GLR module is composed of global shift and local shift along the height, width, and temporal dimensions. Specifically, the global shift is applied to the entire feature map for holistic representation, while the local shift restricts itself to local patches to capture detailed features. Furthermore, a novel cross-scale aggregation module is designed to combine the global and local information in different dimensions. Extensive experimental results on three large-scale benchmarks, including WLASL, INCLUDE and LSA64, demonstrate that the proposed method achieves state-of-the-art recognition performance.},
  archive      = {J_NCA},
  author       = {Guo, Zihui and Hou, Yonghong and Li, Wanqing},
  doi          = {10.1007/s00521-023-08380-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12481-12493},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sign language recognition via dimensional global–local shift and cross-scale aggregation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Innovative modeling techniques including MEP, ANN and FQ to
forecast the compressive strength of geopolymer concrete modified with
nanoparticles. <em>NCA</em>, <em>35</em>(17), 12453–12479. (<a
href="https://doi.org/10.1007/s00521-023-08378-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of nano-materials to improve the engineering properties of different types of concrete composites including geopolymer concrete (GPC) has recently gained popularity. Numerous programs have been executed to investigate the mechanical properties of GPC. In general, compressive strength (CS) is an essential mechanical indicator for judging the quality of concrete. Traditional test methods for determining the CS of GPC are expensive, time-consuming and limiting due to the complicated interplay of a wide variety of mixing proportions and curing regimes. Therefore, in this study, artificial neural network (ANN), multi-expression programming, full quadratic, linear regression and M5P-tree machine learning techniques were used to predict the CS of GPC. In this instance, around 207 tested CS values were extracted from the literature and studied to promote the models. During the process of modeling, eleven effective variables were utilized as input model parameters, and one variable was utilized as an output. Four statistical indicators were used to judge how well the models worked, and the sensitivity analysis was carried out. According to the results, the ANN model calculated the CS of GPC with greater precision than the other models. On the other hand, the ratio of alkaline solution to the binder, molarity, NaOH content, curing temperature and concrete age have substantial effects on the CS of GPC.},
  archive      = {J_NCA},
  author       = {Ahmed, Hemn Unis and Mohammed, Ahmed S. and Faraj, Rabar H. and Abdalla, Aso A. and Qaidi, Shaker M. A. and Sor, Nadhim Hamah and Mohammed, Azad A.},
  doi          = {10.1007/s00521-023-08378-3},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12453-12479},
  shortjournal = {Neural Comput. Appl.},
  title        = {Innovative modeling techniques including MEP, ANN and FQ to forecast the compressive strength of geopolymer concrete modified with nanoparticles},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of improved hybrid whale optimization algorithm
to optimization problems. <em>NCA</em>, <em>35</em>(17), 12433–12451.
(<a href="https://doi.org/10.1007/s00521-023-08370-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Whale Optimization Algorithm (WOA) is one of the recent meta-heuristic algorithms. WOA has advantages such as an exploration mechanism that leads towards the global optimum, a suitable balance between exploration and exploitation that avoids the local optimum, and a very good exploitation capability. In this study, five new hybrid algorithms are proposed to develop these advantages. Two of them are developed by combining WOA and Particle Swarm Optimization (PSO) algorithms, and three of them are developed by adding the Lévy flight algorithm to this combination in different ways. The proposed algorithms have been tested with 23 mathematical optimization problems, and in order to make a more accurate comparison, the average optimization results and corresponding standard deviation results are calculated by running these algorithms 30 times for each optimization problem. The proposed algorithms&#39; performances were evaluated among themselves, and the WOALFVWPSO algorithm performed better among these algorithms. This proposed algorithm has been first compared with WOA and PSO, then with other algorithms in the literature. According to WOA and PSO, the proposed algorithm performs better in 19 of 23 mathematical optimization problems, and according to other literature, it performs better in 15 of 23 problems. Also, the proposed algorithm has been applied to the pressure vessel design engineering problem and achieved the best result compared to other algorithms in the literature. It has been proven that the WOALFVWPSO algorithm provides competitive solutions for most optimization problems when compared to meta-heuristic algorithms in the literature.},
  archive      = {J_NCA},
  author       = {Uzer, Mustafa Serter and Inan, Onur},
  doi          = {10.1007/s00521-023-08370-x},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12433-12451},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of improved hybrid whale optimization algorithm to optimization problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CSI-based cross-scene human activity recognition with
incremental learning. <em>NCA</em>, <em>35</em>(17), 12415–12432. (<a
href="https://doi.org/10.1007/s00521-023-08389-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) based on Channel State Information (CSI) has important application prospects in various fields such as human–computer interactivity, medical health et al. Although the current CSI-based HAR researches have made great progress in the number of activity categories and recognition accuracy, they encounter two challenges. When recognizing new activities, a large number of new activity samples are required to retrain the original model or adjust the model parameters. Besides, the recognition accuracy of the model retrained in the new scene for the already recognized activities drops obviously. To address the two challenges, we propose a human activity recognition system CSI-ARIL based on incremental learning in this paper. CSI-ARIL saves partial representative samples for each learned activity, and adds distillation loss to the loss function as the regularization term to further strengthen the model’s memory for the learned activities. In order to enhance the feature difference among different activities, CSI-ARIL explicitly adds time information for CSI activity samples. In addition, pseudo-samples are generated through data enhancement to expand the new training set, which reduces the cost of obtaining labeled real samples. CSI-ARIL also adds the Convolutional Block Attention Module (CBAM) to the network, which helps the network extract the effective features of CSI activity samples. The experimental results show that, after continuously learning eight categories of activities in four scenes, the recognition accuracy of CSI-ARIL for new and already recognized activities reaches 92.8\% and 89.4\%, respectively.},
  archive      = {J_NCA},
  author       = {Zhang, Yong and He, Fei and Wang, Yujie and Wu, Dingchao and Yu, Guangwei},
  doi          = {10.1007/s00521-023-08389-0},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12415-12432},
  shortjournal = {Neural Comput. Appl.},
  title        = {CSI-based cross-scene human activity recognition with incremental learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Elite and dynamic opposite learning enhanced sine cosine
algorithm for application to plat-fin heat exchangers design problem.
<em>NCA</em>, <em>35</em>(17), 12401–12414. (<a
href="https://doi.org/10.1007/s00521-021-05963-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heat exchanger has been widely used in the energy and chemical industry and plays an irreplaceable role in the featured applications. The design of heat exchanger is a mixed integer complex optimization problem, where the efficient design significantly improves the efficiency and reduces the cost. Many intelligent methods have been developed for heat exchanger optimal design. In this paper, a novel variant of sine and cosine algorithm named EDOLSCA is proposed, enhanced by dynamic opposite learning algorithm and the elite strategy. The proposed method is tested in CEC2014 benchmark and proved to be of significant advantages over the original algorithm. The new algorithm is then validated in the plate-fin heat exchanger (PFHE) optimal design problem. The comparison results of the proposed algorithm and other algorithms prove that EDOLSCA also has demonstrated superiority in heat exchanger optimal design.},
  archive      = {J_NCA},
  author       = {Zhang, Lidong and Hu, Tianyu and Yang, Zhile and Yang, Dongsheng and Zhang, Jianhua},
  doi          = {10.1007/s00521-021-05963-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12401-12414},
  shortjournal = {Neural Comput. Appl.},
  title        = {Elite and dynamic opposite learning enhanced sine cosine algorithm for application to plat-fin heat exchangers design problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel framework for message dissemination with
consideration of destination prediction in VFC. <em>NCA</em>,
<em>35</em>(17), 12389–12399. (<a
href="https://doi.org/10.1007/s00521-021-05754-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of intelligent transportation systems (ITS) and the emergency of ever-growing vehicular applications pose significant challenges to the underlying communication system. Without the support of powerful communication, many vehicular services will just stay in conceptual phase and cannot be put into practice. Recently, vehicular fog computing (VFC) is introduced as a promising solution to provide low-latency services on roads, which utilizes enormous vehicles on roads as communication and computation resources and extends cloud computing service to an edge network. On the other hand, the publish/subscribe (pub/sub) paradigm provides a loosely coupled and scalable communication which can facilitate flexible and dynamic vehicular network services. Motivated by the merits of these two research fields, in this paper, we propose a novel joint design of pub/sub-communication model based on VFC architecture, which employs fog nodes as the data platform for messages aggregation. Specifically, we describe a method to predict the vehicle’s destination and construct a stable VFC on roads. Then, a message dissemination approach is designed based on our communication model. Finally, the experimental results confirm the efficiency of our proposed scheme in real-world urban scenarios.},
  archive      = {J_NCA},
  author       = {Liu, Bingyi and Wang, Ze and Qin, Jing and Jiang, Yi and Chen, Xinhai and Wang, Enshu and Xiong, Shengwu},
  doi          = {10.1007/s00521-021-05754-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12389-12399},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel framework for message dissemination with consideration of destination prediction in VFC},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). RtDS: Real-time distributed strategy for multi-period task
offloading in vehicular edge computing environment. <em>NCA</em>,
<em>35</em>(17), 12373–12387. (<a
href="https://doi.org/10.1007/s00521-021-05766-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With recent advances in sensing technologies and the emerging intelligent transportation system applications, smart vehicles impose huge requirements on processing computation-intensive tasks with strict time constraints, which cannot be satisfied solely relying on local computation resources. Vehicular edge computing is an efficient paradigm for enabling low-latency and high-quality service. In this paper, we consider a multi-period task offloading scenario in vehicular edge computing environment, where tasks can be offloaded in any period during their lifetime. Then, we formulate the multi-period offloading problem (MOP) to maximize the task completion ratio, by analyzing the mobility-aware communication model, resources-aware computation model and deadline-aware award model. Further, considering the high mobility of vehicles and dynamic wireless environments, we propose a real-time distributed strategy (RtDS) to solve MOP by exploiting the collaboration among edge nodes and client vehicles. Finally, we build the simulation model based on real vehicular trajectories and give a comprehensive performance evaluation, which demonstrates the superior performance of RtDS.},
  archive      = {J_NCA},
  author       = {Liu, Chunhui and Liu, Kai and Ren, Hualing and Xu, Xincao and Xie, Ruitao and Cao, Jingjing},
  doi          = {10.1007/s00521-021-05766-5},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12373-12387},
  shortjournal = {Neural Comput. Appl.},
  title        = {RtDS: Real-time distributed strategy for multi-period task offloading in vehicular edge computing environment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive neural network control for maglev vehicle systems
with time-varying mass and external disturbance. <em>NCA</em>,
<em>35</em>(17), 12361–12372. (<a
href="https://doi.org/10.1007/s00521-021-05874-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unexpected disturbance and ever-changing passengers are unfavorable factors that always accompany maglev trains. If not considered or handled properly, they would deteriorate the control system performance significantly and even cause instability. This paper proposes a neural network-based adaptive control approach to stabilize the airgap of the nonlinear maglev vehicle. Meanwhile, the time-varying mass and external disturbance can be estimated accurately. Specifically, to ensure the asymptotic stability of the maglev system, a nonlinear basic control law is developed first. To tackle the uncertainty, a radial basis function neural network is fused into the basic controller, which can recover the unknown mass and disturbance more quickly and accurately. Lyapunov stability techniques are utilized to prove the stability of the whole maglev control system without any linear approximation. The sufficient comparative simulation results are provided to demonstrate that the established control scheme can obtain better levitation performance and achieve a precise estimation of time-varying and disturbance simultaneously. Finally, we build a dSPACE-based single electromagnet suspension test bed to examine its efficacy and practical applicability as well.},
  archive      = {J_NCA},
  author       = {Sun, Yougang and Xu, Junqi and Lin, Guobin and Sun, Ning},
  doi          = {10.1007/s00521-021-05874-2},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12361-12372},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive neural network control for maglev vehicle systems with time-varying mass and external disturbance},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). L1-norm laplacian support vector machine for data reduction
in semi-supervised learning. <em>NCA</em>, <em>35</em>(17), 12343–12360.
(<a href="https://doi.org/10.1007/s00521-020-05609-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a semi-supervised learning method, Laplacian support vector machine (LapSVM) is popular. Unfortunately, the model generated by LapSVM has a poor sparsity. A sparse decision model has always been fascinating because it could implement data reduction and improve performance. To generate a sparse model of LapSVM, we propose an $$\ell _1$$ -norm Laplacian support vector machine ( $$\ell _1$$ -norm LapSVM), which replaces the $$\ell _2$$ -norm with the $$\ell _1$$ -norm in LapSVM. The $$\ell _1$$ -norm LapSVM has two techniques that can induce sparsity: the $$\ell _1$$ -norm regularization and the hinge loss function. We discuss two situations for the $$\ell _1$$ -norm LapSVM, linear and nonlinear ones. In the linear $$\ell _1$$ -norm LapSVM, the sparse decision model implies that features with nonzero coefficients are contributive. In other words, the linear $$\ell _1$$ -norm LapSVM can perform feature selection to achieve the goal of data reduction. Moreover, the nonlinear (kernel) $$\ell _1$$ -norm LapSVM can also implement data reduction in terms of sample selection. In addition, the optimization problem of the $$\ell _1$$ -norm LapSVM is a convex quadratic programming one. That is, the $$\ell _1$$ -norm LapSVM has a unique and global solution. Experimental results on semi-supervised classification tasks have shown a comparable performance of our $$\ell _1$$ -norm LapSVM.},
  archive      = {J_NCA},
  author       = {Zheng, Xiaohan and Zhang, Li and Xu, Zhiqiang},
  doi          = {10.1007/s00521-020-05609-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12343-12360},
  shortjournal = {Neural Comput. Appl.},
  title        = {L1-norm laplacian support vector machine for data reduction in semi-supervised learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Perception consistency ultrasound image super-resolution
via self-supervised CycleGAN. <em>NCA</em>, <em>35</em>(17),
12331–12341. (<a
href="https://doi.org/10.1007/s00521-020-05687-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the limitations of sensors, the transmission medium, and the intrinsic properties of ultrasound, the quality of ultrasound imaging is always not ideal, especially its low spatial resolution. To remedy this situation, deep learning networks have been recently developed for ultrasound image super-resolution (SR) because of the powerful approximation capability. However, most current supervised SR methods are not suitable for ultrasound medical images because the medical image samples are always rare, and usually, there are no low-resolution (LR) and high-resolution (HR) training pairs in reality. In this work, based on self-supervision and cycle generative adversarial network, we propose a new perception consistency ultrasound image SR method, which only requires the LR ultrasound data and can ensure the re-degenerated image of the generated SR one to be consistent with the original LR image, and vice versa. We first generate the HR fathers and the LR sons of the test ultrasound LR image through image enhancement, and then make full use of the cycle loss of LR–SR–LR and HR–LR–SR and the adversarial characteristics of the discriminator to promote the generator to produce better perceptually consistent SR results. The evaluation of PSNR/IFC/SSIM, inference efficiency and visual effects under the benchmark CCA-US and CCA-US datasets illustrate our proposed approach is effective and superior to other state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Liu, Heng and Liu, Jianyong and Hou, Shudong and Tao, Tao and Han, Jungong},
  doi          = {10.1007/s00521-020-05687-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12331-12341},
  shortjournal = {Neural Comput. Appl.},
  title        = {Perception consistency ultrasound image super-resolution via self-supervised CycleGAN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A discrete collaborative swarm optimizer for resource
scheduling problem in mobile cellular networks. <em>NCA</em>,
<em>35</em>(17), 12319–12329. (<a
href="https://doi.org/10.1007/s00521-021-05803-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a discrete collaborative swarm optimizer (DCCSO) for solving the resource scheduling problem in mobile cellular networks, which aims to employ minimum wireless bandwidth to meet various channel demands from each cell without violation of interference constraint. Many current algorithms can provide satisfactory solutions in dealing with simple problems, while some complex problems still need efficient scheduling schema, due to the limited resources. The proposed algorithm is inspired by the competitive swarm optimizer, whose superiority on continuous optimization problems has been proven by theory and verification. With the characteristics of the resource scheduling problem, the generalized order learning mechanism is designed, which updates the information of the loser particles by learning the sequential knowledge of the winners. Besides, plenty of invalid solutions will generate during the searching process in the original solution space degeneration of the exploration capability and coverage speed. To that end, an ensemble self-learning strategy is arisen by helping the neighborhood search by problem-specific information in the transformed solution space. The effectiveness of the proposed DCCSO is demonstrated on a set of real-world problems, and the experimental results show that the proposed algorithm exhibits better than or at least comparable performance to other state-of-the-art algorithms on most problems.},
  archive      = {J_NCA},
  author       = {Dong, Bei and Su, Yuping and Zhou, Yun and Cheng, Shi and Wu, Xiaojun},
  doi          = {10.1007/s00521-021-05803-3},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12319-12329},
  shortjournal = {Neural Comput. Appl.},
  title        = {A discrete collaborative swarm optimizer for resource scheduling problem in mobile cellular networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot classification with unseen prototype learning.
<em>NCA</em>, <em>35</em>(17), 12307–12317. (<a
href="https://doi.org/10.1007/s00521-021-05746-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning (ZSL) aims at recognizing instances from unseen classes via training a classification model with only seen data. Most existing approaches easily suffer from the classification bias from unseen to seen categories since the models are only trained with seen data. In this paper, we tackle the task of ZSL with a novel Unseen Prototype Learning (UPL) model, which is a simple yet effective framework to learn visual prototypes for unseen categories from the corresponding class-level semantic information, and the learned features are treated as latent classifiers directly. Two types of constraints are proposed to improve the performance of the learned prototypes. Firstly, we utilize an autoencoder framework to learn visual prototypes from the semantic prototypes and reconstruct the original semantic information by a decoder to ensure the prototypes have a strong correlation with the corresponding categories. Secondly, we employ a triplet loss to make the average of visual features per class supervise the learned visual prototypes. In this way, the visual prototypes are more discriminative and as a result, the classification bias problem can be alleviated well. Besides, based on the episodic training paradigm in meta-learning, the model can accumulate wealthy experiences in predicting unseen classes. Extensive experiments on four datasets under both traditional ZSL and generalized ZSL show the effectiveness of our proposed UPL method.},
  archive      = {J_NCA},
  author       = {Ji, Zhong and Cui, Biying and Yu, Yunlong and Pang, Yanwei and Zhang, Zhongfei},
  doi          = {10.1007/s00521-021-05746-9},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12307-12317},
  shortjournal = {Neural Comput. Appl.},
  title        = {Zero-shot classification with unseen prototype learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Identification of downhole conditions in geological
drilling processes based on quantitative trends and expert rules.
<em>NCA</em>, <em>35</em>(17), 12297–12306. (<a
href="https://doi.org/10.1007/s00521-021-05759-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In drilling processes, faulty downhole conditions often lead to drilling performance degradation and even serious accidents, such as the blowout, and well collapse. To improve the drilling efficiency and enhance the process safety, a new downhole condition identification method is proposed for geological drilling processes based on quantitative trends and expert rules. A knowledge base that associates the quantitative trends and downhole conditions is established based on variational trends extracted from the historical data and rules summarized from the drilling operation manual. When the new data arrive for online monitoring, the variational trends are extracted, and then, the downhole condition is identified by comparing such trends with each rule in the knowledge base. The effectiveness and practicality of the proposed method are demonstrated by industrial case studies with real drilling process data.},
  archive      = {J_NCA},
  author       = {Li, Yupeng and Cao, Weihua and Hu, Wenkai and Wu, Min},
  doi          = {10.1007/s00521-021-05759-4},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12297-12306},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification of downhole conditions in geological drilling processes based on quantitative trends and expert rules},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Face image set classification with self-weighted latent
sparse discriminative learning. <em>NCA</em>, <em>35</em>(17),
12283–12295. (<a
href="https://doi.org/10.1007/s00521-020-05479-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since image set classification has strong power to overcome various variations in illumination, expression, pose, and so on, it has drawn extensive attention in recent years. Noteworthily, the point-to-point distance-based methods have achieved the promising performance, which aim to compute the similarity between each gallery set and the probe set for classification purpose. Nevertheless, these existing methods have to face the following problems: (1) they do not take full advantage of the between-set discrimination information; (2) they ideally presume that the importance of different gallery sets is equal, whereas this always violates objective facts and may degenerate algorithm performance in practice; (3) they tend to have high computational cost and several parameters, though explicit sparsity can enhance discrimination. To address these problems, we propose a novel method for face image set classification, namely self-weighted latent sparse discriminative learning (SLSDL). Specifically, a novel self-weighted strategy guided discrimination term is proposed to largely boost the discrimination of different gallery sets, such that the effect of true sets can be boosted while the effect of false sets can be weakened or removed. Moreover, we propose a latent sparse normalization to reduce computational complexity as well as the number of trade-off parameters. In addition, we propose an efficient optimization algorithm to solve the final SLSDL. Comprehensive experiments on four public benchmark datasets demonstrate that SLSDL is superior to the state-of-the-art competitors.},
  archive      = {J_NCA},
  author       = {Sun, Yuan and Ren, Zhenwen and Yang, Chao and Sun, Quansen and Chen, Liwan and Ou, Yanglong},
  doi          = {10.1007/s00521-020-05479-1},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12283-12295},
  shortjournal = {Neural Comput. Appl.},
  title        = {Face image set classification with self-weighted latent sparse discriminative learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluate, explain, and explore the state more exactly: An
improved actor-critic algorithm for complex environment. <em>NCA</em>,
<em>35</em>(17), 12271–12282. (<a
href="https://doi.org/10.1007/s00521-020-05663-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an Advanced Actor-Critic algorithm, which is improved based on the conventional Actor-Critic algorithm, to train the agent to play the complex strategy game StarCraft II. A series of advanced features have been incorporated, including the distributional advantage estimation, information entropy-based uncertainty estimation, self-confidence-based exploration, and normal constraint-based update strategy. A case study including seven StarCraft II mini-games is investigated to identify the effectiveness of the proposed approach, where the famous A3C algorithm is adopted as the comparative baseline. The results verify the superiority of the improved algorithm in accuracy and training efficacy, in complex environment with high-dimensional and hybrid state and action space.},
  archive      = {J_NCA},
  author       = {Zha, ZhongYi and Wang, Bo and Tang, XueSong},
  doi          = {10.1007/s00521-020-05663-3},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12271-12282},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluate, explain, and explore the state more exactly: An improved actor-critic algorithm for complex environment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Competitive advantage assessment for container shipping
liners using a novel hybrid method with intuitionistic fuzzy linguistic
variables. <em>NCA</em>, <em>35</em>(17), 12261–12269. (<a
href="https://doi.org/10.1007/s00521-021-05718-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main purpose of this paper is to design a method for ranking the competitive advantages of container shipping liner companies. The major issue that arises in applying this method is capturing and dealing with qualitative and uncertain information in a complex decision-making environment. A novel hybrid scheme combining intuitionistic fuzzy linguistic variables with optimal determining weights is proposed to assess the competitive advantages of five representative shipping liner companies. Several experts in the related field are invited to adopt intuitionistic fuzzy sets into their group decision-making on the basis of four aspects of competitive advantage held by each shipping liner firm. The intuitionistic fuzzy linguistic variables are employed to evaluate data under each key attribute, which is extracted from the public reports issued by each company concerned. The result validates the effectiveness of the scheme with intuitionistic fuzzy linguistic variables, and it is found that the experts involved more easily grasp the classical intuitionistic fuzzy evaluation tool, benefiting the effectiveness of competitive advantage assessments of liner companies.},
  archive      = {J_NCA},
  author       = {Bao, Junzhong and Zhou, Yuanzi and Li, Ronghui},
  doi          = {10.1007/s00521-021-05718-z},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12261-12269},
  shortjournal = {Neural Comput. Appl.},
  title        = {Competitive advantage assessment for container shipping liners using a novel hybrid method with intuitionistic fuzzy linguistic variables},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Brain storm optimization algorithm for solving knowledge
spillover problems. <em>NCA</em>, <em>35</em>(17), 12247–12260. (<a
href="https://doi.org/10.1007/s00521-020-05674-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolutionary game theory aims to simulate different decision strategies in populations of individuals and to determine how the population evolves. Compared to strategies between two agents, such as cooperation or noncooperation, strategies on multiple agents are rather challenging and difficult to be simulated via traditional methods. Particularly, in a knowledge spillover problem (KSP), cooperation strategies among more than hundreds of individuals need to be simulated. At the same time, the brain storm optimization (BSO) algorithm, which is a data-driven and model-driven hybrid paradigm, has the potential to simulate the complex behaviors in a group of simple individuals. In this paper, a modified BSO algorithm has been used to solve KSP from the perspective of evolutionary game theory. Knowledge spillover (KS) is the sharing or exchanging of knowledge resources among individuals. Firstly, the KS and evolutionary game theory were introduced. Then, the KS model and KS optimization problems were built from the evolutionary game perspective. Lastly, the modified BSO algorithms were utilized to solve KS optimization problems. Based on the applications of BSO algorithms for KSP, the properties of different swarm optimization algorithms can be understood better. More efficient algorithms could be designed to solve different real-world evolutionary game problems.},
  archive      = {J_NCA},
  author       = {Cheng, Shi and Zhang, Mingming and Ma, Lianbo and Lu, Hui and Wang, Rui and Shi, Yuhui},
  doi          = {10.1007/s00521-020-05674-0},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12247-12260},
  shortjournal = {Neural Comput. Appl.},
  title        = {Brain storm optimization algorithm for solving knowledge spillover problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on neural computing and applications 2020.
<em>NCA</em>, <em>35</em>(17), 12243–12245. (<a
href="https://doi.org/10.1007/s00521-023-08594-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhao, Mingbo and Wu, Zhou and Zhang, Zhao and Hao, Tianyong and Meng, Zhiwei and Malekian, Reza},
  doi          = {10.1007/s00521-023-08594-x},
  journal      = {Neural Computing and Applications},
  number       = {17},
  pages        = {12243-12245},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on neural computing and applications 2020},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: Special issue on large-scale neural computing
and cybersecurity opportunities using artificial intelligence.
<em>NCA</em>, <em>35</em>(16), 12241. (<a
href="https://doi.org/10.1007/s00521-022-07887-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Tyagi, Sumarga Kumar Sah and Pimenidis, Elias and Jain, Sanjeev and Serrano, Will},
  doi          = {10.1007/s00521-022-07887-x},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12241},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Special issue on large-scale neural computing and cybersecurity opportunities using artificial intelligence},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction to: Human activity recognition from sensor data
using spatial attention-aided CNN with genetic algorithm. <em>NCA</em>,
<em>35</em>(16), 12239. (<a
href="https://doi.org/10.1007/s00521-022-08189-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sarkar, Apu and Hossain, S. K. Sabbir and Sarkar, Ram},
  doi          = {10.1007/s00521-022-08189-y},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12239},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Human activity recognition from sensor data using spatial attention-aided CNN with genetic algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction to: Maize crop disease detection using NPNet-19
convolutional neural network. <em>NCA</em>, <em>35</em>(16), 12237. (<a
href="https://doi.org/10.1007/s00521-022-08073-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Nagaraju, M. and Chawla, Priyanka},
  doi          = {10.1007/s00521-022-08073-9},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12237},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Maize crop disease detection using NPNet-19 convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: AM-ConvGRU: A spatio-temporal model for
typhoon path prediction. <em>NCA</em>, <em>35</em>(16), 12235. (<a
href="https://doi.org/10.1007/s00521-022-08032-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Xu, Guangning and Xian, Di and Fournier-Viger, Philippe and Li, Xutao and Ye, Yunming and Hu, Xiuqing},
  doi          = {10.1007/s00521-022-08032-4},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12235},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: AM-ConvGRU: a spatio-temporal model for typhoon path prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Correction to: Adaptive 1-dimensional time invariant
learning for inertial sensor-based gait authentication. <em>NCA</em>,
<em>35</em>(16), 12233. (<a
href="https://doi.org/10.1007/s00521-022-07907-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Permatasari, Jessica and Connie, Tee and Ong, Thian Song and Teoh, Andrew Beng Jin},
  doi          = {10.1007/s00521-022-07907-w},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12233},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Adaptive 1-dimensional time invariant learning for inertial sensor-based gait authentication},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method for mapping and monitoring of iron ore stopes based
on hyperspectral remote sensing-ground data and a 3D deep neural
network. <em>NCA</em>, <em>35</em>(16), 12221–12232. (<a
href="https://doi.org/10.1007/s00521-023-08353-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research explores a new hyperspectral remote sensing processing method that combines remote sensing and ground data, and builds a model based on a novel 3D convolutional neural network and fusion data. The method can monitor and map changes in iron ore stopes. First, we used an unmanned aerial vehicle-borne hyperspectral imager to take a hyperspectral image of the iron ore stope; second, collected iron ore samples and then used a ground-based spectrometer to measure the spectral data of these samples; third, combined the hyperspectral remote sensing data with the ground data and then proposed a data augmentation method. Fourth, based on the 3D convolutional neural network and deep residual network, an iron ore stope classification model is proposed. Finally, the model is applied to monitor and map iron ore stopes. The experimental results show that the proposed method is effective, and the overall accuracy is 99.62\% for the five-class classification problem. The method provides a quick, accurate, and low-cost way to monitor iron ore stopes.},
  archive      = {J_NCA},
  author       = {Xiao, Dong and Vu, Quoc Huy and Le, Ba Tuan and Ha, Thai Thuy Lam},
  doi          = {10.1007/s00521-023-08353-y},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12221-12232},
  shortjournal = {Neural Comput. Appl.},
  title        = {A method for mapping and monitoring of iron ore stopes based on hyperspectral remote sensing-ground data and a 3D deep neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature extraction and selection from electroencephalogram
signals for epileptic seizure diagnosis. <em>NCA</em>, <em>35</em>(16),
12195–12219. (<a
href="https://doi.org/10.1007/s00521-023-08350-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is one of the most common neurological diseases, affecting approximately 50 million people. This illness can be diagnosed by electroencephalogram (EEG), whose analysis depends on human interpretation, which may lead to divergent results and be imprecise and error-prone. Moreover, one estimates more than 80\% of the epilepsy examinations return no anomalies at all, wasting the effort of analysis. In this context, machine learning (ML) methods are used to aid in epilepsy detection. An essential task for classifier building is feature extraction, for which there are many measures that can be computed. However, part of these features can be irrelevant or hinder the performance of ML methods. This paper proposes an automatic way to classify EEG segments by using a reduced set of features. The proposed method combines multispectral analysis, feature selection, and classifier building approaches. As our main contribution, a methodology to minimize the number of features for classifier building is proposed. A total of 285 measures are extracted. Afterward, two attribute selection approaches are used: Pearson’s correlation coefficient filter and wrapper based on the genetic algorithm. Then, five well-known ML methods (k-nearest-neighbor, support vector machine, naive Bayes, artificial neural network, and random forest) were used to build 281 different classifiers. As a result, the proposed classifiers reached an accuracy between 87.2 and 90.99\% and considerably reduced the number of features from 285 to 30, keeping competitive scores. Additionally, statistical hypothesis tests prove that our proposed approach is as efficient as using the complete feature dataset for classifier building.},
  archive      = {J_NCA},
  author       = {de Vargas, Dionathan Luan and Oliva, Jefferson Tales and Teixeira, Marcelo and Casanova, Dalcimar and Rosa, João Luís Garcia},
  doi          = {10.1007/s00521-023-08350-1},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12195-12219},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feature extraction and selection from electroencephalogram signals for epileptic seizure diagnosis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Flow-based intrusion detection on software-defined
networks: A multivariate time series anomaly detection approach.
<em>NCA</em>, <em>35</em>(16), 12175–12193. (<a
href="https://doi.org/10.1007/s00521-023-08376-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present and implement the SAnDet (SDN anomaly detector) architecture, an anomaly-based intrusion detection system designed to take advantage of the capabilities offered by software-defined networking (SDN) architecture, as a controller application. The SAnDet system is composed of three modules: statistics collection, anomaly detection, and anomaly prevention. In particular, we utilize replicator neural networks (RNN), which is a specialized variant of the autoencoder, and the LSTM-based encoder–decoder (EncDecAD) method, which is a special type of long short-term memory (LSTM) network that has demonstrated a strong performance on data series particularly, to identify unknown attacks using flow features collected from OpenFlow switches. In our experiments, we utilize flow-based features extracted from network traffic data containing various types of attacks as input to our models in the form of time series. We evaluate the performance of our methods using the accuracy and area under the receiver operating characteristic curve (AUC) metrics. Our experimental results demonstrate that EncDecAD outperforms RNN and that our approach offers several benefits over previously conducted research.},
  archive      = {J_NCA},
  author       = {Zavrak, Sultan and Iskefiyeli, Murat},
  doi          = {10.1007/s00521-023-08376-5},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12175-12193},
  shortjournal = {Neural Comput. Appl.},
  title        = {Flow-based intrusion detection on software-defined networks: A multivariate time series anomaly detection approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-informed neural networks for predicting liquid dairy
manure temperature during storage. <em>NCA</em>, <em>35</em>(16),
12159–12174. (<a
href="https://doi.org/10.1007/s00521-023-08347-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a physics-informed neural networks (PINN) modeling approach we developed as a practical application of neural computing to predict manure temperature during storage at a dairy farm all year round. Manure temperature is a factor that impacts the microbial and chemical processes associated with releasing aerial pollutants. Therefore, knowing the dynamics and quantifying the manure temperature value during storage is critical for designing methods to mitigate its potential contribution to polluting the environment. Also, manure temperature is a pertinent input parameter for on-farm decision support tools and nutrient accounting models used to assess sustainable manure management practices. However, there is no standard method to estimate it. Currently, decision support tools use surrogates derived from various ambient air temperature averages instead of the manure temperature, which underestimates the contaminants lost to the atmosphere during the manure storage. In this study, we developed a PINN model as an alternative for predicting the stored manure temperature. We compared its performance to three other models (finite-elements heat transfer, classical data-driven neural network, and simulation-based neural network). We collected field data from three dairy farms with different manure management practices and storage structures to train, validate, and test the models. The manure temperatures predicted by the PINN model were the closest in magnitude to the measured temperatures at the three manure storages on the three dairy farms. In addition, the PINN model predictions were less biased and more data-efficient than the other models. The predictive ability of the models was comparable during validation (R2 &gt; 0.90); however, the PINN model had superior generalization accuracy. The R2 for the PINN model during the testing phase exceeded 0.70. In contrast, R2 ranged from − 0.03 and 0.66 for the finite-elements heat transfer, classical data-driven neural network, and simulation-based neural network models. These results suggest that using the PINN model to estimate manure temperature in decision support tools and nutrient cycling models would provide more realistic outcomes for assessing sustainable manure management practices. The outcomes of this study contribute to the field of precision agriculture, specifically designing suitable on-farm strategies to minimize nutrient loss and greenhouse gas emissions during the manure storage periods and improve the accuracy of metrics used to assess sustainable manure management practices.},
  archive      = {J_NCA},
  author       = {Genedy, Rana A. and Chung, Matthias and Ogejo, Jactone A.},
  doi          = {10.1007/s00521-023-08347-w},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12159-12174},
  shortjournal = {Neural Comput. Appl.},
  title        = {Physics-informed neural networks for predicting liquid dairy manure temperature during storage},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Circuit design completion using graph neural networks.
<em>NCA</em>, <em>35</em>(16), 12145–12157. (<a
href="https://doi.org/10.1007/s00521-023-08346-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic design automation tools are widely used in circuit design and greatly assist designers in handling the complexities and challenges of circuit design and evaluation. There have been numerous recent developments in using machine learning tools, particularly graph neural networks (GNNs), to address circuit design problems. These techniques take advantage of the natural representation of a circuit as a graph. In this study, we propose using state-of-the-art GNNs to solve a key circuit design issue. Specifically, we are interested in addressing the circuit completion problem (CCP), where the goal is to determine the missing components and their connections in a partially designed or evaluated circuit. We provide a novel two-step solution to this problem: First, we formulate missing component identification as a graph classification task in the graph-based representation of partial circuit, and second, we treat the placement and connectivity of the newly (predicted) component as a link completion problem. We propose a novel graph learning framework called feature-enhanced graph isomorphism network that combines both GNNs and graph descriptors in an end-to-end fashion to extract expressive graph representations. We also present three new circuit datasets to implement and test our solutions. Our extensive experiments demonstrate that the proposed framework is an effective and generalizable solution to the CCP problem.},
  archive      = {J_NCA},
  author       = {Said, Anwar and Shabbir, Mudassir and Broll, Brian and Abbas, Waseem and Völgyesi, Peter and Koutsoukos, Xenofon},
  doi          = {10.1007/s00521-023-08346-x},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12145-12157},
  shortjournal = {Neural Comput. Appl.},
  title        = {Circuit design completion using graph neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural architecture search for energy-efficient always-on
audio machine learning. <em>NCA</em>, <em>35</em>(16), 12133–12144. (<a
href="https://doi.org/10.1007/s00521-023-08345-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile and edge computing devices for always-on classification tasks require energy-efficient neural network architectures. In this paper we present several changes to neural architecture searches that improve the chance of success in practical situations. Our search simultaneously optimizes for network accuracy, energy efficiency and memory usage. We benchmark the performance of our search on real hardware, but since running thousands of tests with real hardware is difficult, we use a random forest model to roughly predict the energy usage of a candidate network. We present a search strategy that uses both Bayesian and regularized evolutionary search with particle swarms, and employs early stopping to reduce the computational burden. Our search, evaluated on a sound event classification dataset based upon AudioSet, results in an order of magnitude less energy per inference and a much smaller memory footprint than our baseline MobileNetV1/V2 implementations while slightly improving task accuracy. We also demonstrate how combining a 2D spectrogram with a convolution with many filters causes a computational bottleneck for audio classification and that alternative approaches reduce the computational burden but sacrifice task accuracy.},
  archive      = {J_NCA},
  author       = {Speckhard, Daniel T. and Misiunas, Karolis and Perel, Sagi and Zhu, Tenghui and Carlile, Simon and Slaney, Malcolm},
  doi          = {10.1007/s00521-023-08345-y},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12133-12144},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural architecture search for energy-efficient always-on audio machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of EfficientNet models for COVID-19 detection
using lung parenchyma. <em>NCA</em>, <em>35</em>(16), 12121–12132. (<a
href="https://doi.org/10.1007/s00521-023-08344-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the COVID-19 pandemic broke out in the beginning of 2020, it became crucial to enhance early diagnosis with efficient means to reduce dangers and future spread of the viruses as soon as possible. Finding effective treatments and lowering mortality rates is now more important than ever. Scanning with a computer tomography (CT) scanner is a helpful method for detecting COVID-19 in this regard. The present paper, as such, is an attempt to contribute to this process by generating an open-source, CT-based image dataset. This dataset contains the CT scans of lung parenchyma regions of 180 COVID-19-positive and 86 COVID-19-negative patients taken at the Bursa Yuksek Ihtisas Training and Research Hospital. The experimental studies show that the modified EfficientNet-ap-nish method uses this dataset effectively for diagnostic purposes. Firstly, a smart segmentation mechanism based on the k-means algorithm is applied to this dataset as a preprocessing stage. Then, performance pretrained models are analyzed using different CNN architectures and with our Nish activation function. The statistical rates are obtained by the various EfficientNet models and the highest detection score is obtained with the EfficientNet-B4-ap-nish version, which provides a 97.93\% accuracy rate and a 97.33\% F1-score. The implications of the proposed method are immense both for present-day applications and future developments.},
  archive      = {J_NCA},
  author       = {Kurt, Zuhal and Işık, Şahin and Kaya, Zeynep and Anagün, Yıldıray and Koca, Nizameddin and Çiçek, Sümeyye},
  doi          = {10.1007/s00521-023-08344-z},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12121-12132},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation of EfficientNet models for COVID-19 detection using lung parenchyma},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interdependent evolutionary machine learning model
applied to global horizontal irradiance modeling. <em>NCA</em>,
<em>35</em>(16), 12099–12120. (<a
href="https://doi.org/10.1007/s00521-023-08342-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most important input parameter in all solar power generation forecasting systems is solar radiation. Your estimation is necessary for the development of any photovoltaic system project. However, this estimate depends on expensive devices, namely pyranometers and pyrheliometers. Therefore, predicting such values through mathematical and computational models is an attractive approach where costs can be reduced. In particular, machine learning methods have been widely successfully applied to this task. The efficiency of a machine learning model depends on a suitable set of parameters. Evolutionary algorithms are helpful and widely used to optimize internal parameters and select the most relevant variables. In this context, machine learning models use evolutionary algorithms’ search capability to improve forecasting performance. This work presents a study incorporating different evolutionary algorithms for parameter adjustment in machine learning models applied to solar radiation prediction. Two years of observation data from the Dar es Salaam weather station in Tanzania were used. The results show the presented framework’s applicability to finding the best subset of variables, machine learning model and optimization algorithm combination. Although promising results have been obtained in the experiments, it should be clear that care must be taken to generalize the conclusions. The integration of machine learning model with optimization algorithms is limited to a defined data collection context, under specific local environmental conditions and only under data collection from a meteorological station.},
  archive      = {J_NCA},
  author       = {Basílio, Samuel da Costa Alves and Saporetti, Camila M. and Goliatt, Leonardo},
  doi          = {10.1007/s00521-023-08342-1},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12099-12120},
  shortjournal = {Neural Comput. Appl.},
  title        = {An interdependent evolutionary machine learning model applied to global horizontal irradiance modeling},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A framework for classifying breast cancer based on deep
features integration and selection. <em>NCA</em>, <em>35</em>(16),
12089–12097. (<a
href="https://doi.org/10.1007/s00521-023-08341-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (DCNNs) are one of the most advanced techniques for classifying images in a range of applications. One of the most prevalent cancers that cause death in women is breast cancer. For survival rates to increase, early detection and treatment of breast cancer is essential. Deep learning (DL) can help radiologists diagnose and classify breast cancer lesions. This paper proposes a computer-aided system based on DL techniques for automatically classify breast cancer tumors in histopathological images. There are nine DCNN architectures used in this work. Four schemes are performed in the proposed framework to find the best approach. The first scheme consists of pre-trained DCNNs based on the transfer learning concept. The second scheme performs feature extraction of the DCNN architectures and uses a support vector machine (SVM) classifier for evaluation. The third one performs feature integration to show how the integrated deep features may enhance the SVM classifiers&#39; accuracy. Finally, in the fourth scheme, the Chi-square (χ2) feature selection method is applied to reduce the large feature size in the feature integration step. The results of the proposed system present a promising performance for breast cancer classification with an accuracy of 99.24\%. The system performance shows that the proposed tool is suitable to assist radiologists in diagnosing breast cancer tumors.},
  archive      = {J_NCA},
  author       = {Hassan, Abdallah M. and Yahya, Ahmed and Aboshosha, Ashraf},
  doi          = {10.1007/s00521-023-08341-2},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12089-12097},
  shortjournal = {Neural Comput. Appl.},
  title        = {A framework for classifying breast cancer based on deep features integration and selection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of apple images using support vector machines
and deep residual networks. <em>NCA</em>, <em>35</em>(16), 12073–12087.
(<a href="https://doi.org/10.1007/s00521-023-08340-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important problems for farmers who produce large amounts of apples is the classification of the apples according to their types in a short time without handling them. Support vector machines (SVM) and deep residual networks (ResNet-50) are machine learning methods that are able to solve general classification situations. In this study, the classification of apple varieties according to their genus is made using machine learning algorithms. A database is created by capturing 120 images from six different apple species. Bag of visual words (BoVW) treat image features as words representing a sparse vector of occurrences over the vocabulary. BoVW features are classified using SVM. On the other hand, ResNet-50 is a convolutional neural network that is 50 layers deep with embedded feature extraction layers. The pre-trained ResNet-50 architecture is retrained for apple classification using transfer learning. In the experiments, our dataset is divided into three cases: Case 1: 40\% train, 60\% test; Case 2: 60\% train, 40\% test; and Case 3: 80\% train, 20\% test. As a result, the linear, Gaussian, and polynomial kernel functions used in the BoVW + SVM algorithm achieved 88\%, 92\%, and 96\% accuracy in Case 3, respectively. In the ResNet-50 classification, the root-mean-square propagation (rmsprop), adaptive moment estimation (adam), and stochastic gradient descent with momentum (sgdm) training algorithms achieved 86\%, 89\%, and 90\% accuracy, respectively, in the set of Case 3.},
  archive      = {J_NCA},
  author       = {Adige, Sevim and Kurban, Rifat and Durmuş, Ali and Karaköse, Ercan},
  doi          = {10.1007/s00521-023-08340-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12073-12087},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of apple images using support vector machines and deep residual networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coconut trees classification based on height, inclination,
and orientation using MIN-SVM algorithm. <em>NCA</em>, <em>35</em>(16),
12055–12071. (<a
href="https://doi.org/10.1007/s00521-023-08339-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A computerized coconut tree detection system can help dendrologists and laypersons in identifying coconut trees based on three morphological parameters including height, inclination, and orientation. These three parameters help to determine the health and the nature of growth of coconut trees which influences the design and use of robots for harvesting coconuts. Deep learning is a powerful tool used for feature extraction as it is better in extracting deeper details (features) in an image. In this research work, a new Modified Inception Net based Hyper Tuning Support Vector Machine classification method named MIN-SVM is proposed for coconut tree classification based on three morphological parameters including height, inclination and orientation. The features from the pre-processed coconut tree images were extracted using four distinct Convolutional Neural Network models including Visual Geometry Group, Inception Net, ResNet, and MIN-SVM. These extracted features were then classified using a Machine Learning model named Support Vector Machine (SVM). The MIN-SVM have achieved a remarkable accuracy of 95.35 percent as contrasted to Visual Geometry Group (91.90\%), Inception Net (81.66\%), and ResNet (71.95\%). The features extracted from Modified Inception Net fitted good with SVM classifier. Experimental results show that MIN-SVM can be powerful computerized automated system to identify coconut trees based on height, inclination, and orientation.},
  archive      = {J_NCA},
  author       = {Megalingam, Rajesh Kannan and Kuttankulangara Manoharan, Sakthiprasad and Babu, Dasari Hema Teja Anirudh and Sriram, Ghali and Lokesh, Karanam and Kariparambil Sudheesh, Sankardas},
  doi          = {10.1007/s00521-023-08339-w},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12055-12071},
  shortjournal = {Neural Comput. Appl.},
  title        = {Coconut trees classification based on height, inclination, and orientation using MIN-SVM algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SoftClusterMix: Learning soft boundaries for empirical risk
minimization. <em>NCA</em>, <em>35</em>(16), 12039–12053. (<a
href="https://doi.org/10.1007/s00521-023-08338-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional networks are data hungry learners and, to compensate for the limited amount of available data, various augmentation methods have been proposed. While the initial approaches aimed to fill the space around existing data points, more recent methods use the “mixing” procedure, which is a convex combination between points, being both holistic and local (from a spatial point of view). Although the mixing techniques improved the performance for standard benchmarks, we do notice that they are less effective for problems that exhibit poor class separation. For these scenarios, we propose a soft labeling technique based on distances to class prototypes, as extracted on an intermediate CNN layer. The mixing is performed between relative positions in the clustering space. The method, named SoftClusterMix, is shown to be competitive on standard image classification benchmarks and leads to significantly improved accuracy for problems where there is a poor class separation. We report better performance in three such categories: face expression recognition, aesthetic image classification and painting style classification. Ablation tests allow deep insights of the method.},
  archive      = {J_NCA},
  author       = {Florea, Corneliu and Vertan, Constantin and Florea, Laura},
  doi          = {10.1007/s00521-023-08338-x},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12039-12053},
  shortjournal = {Neural Comput. Appl.},
  title        = {SoftClusterMix: Learning soft boundaries for empirical risk minimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DL-DARE: Deep learning-based different activity recognition
for the human–robot interaction environment. <em>NCA</em>,
<em>35</em>(16), 12029–12037. (<a
href="https://doi.org/10.1007/s00521-023-08337-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a deep learning-based activity recognition for the Human–Robot Interaction environment. The observations of the object state are acquired from the vision sensor in the real-time scenario. The activity recognition system examined in this paper comprises activities labeled as classes (pour, rotate, drop objects, and open bottles). The image processing unit processes the images and predicts the activity performed by the robot using deep learning methods so that the robot will do the actions (sub-actions) according to the predicted activity.},
  archive      = {J_NCA},
  author       = {Kansal, Sachin and Jha, Sagar and Samal, Prathamesh},
  doi          = {10.1007/s00521-023-08337-y},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12029-12037},
  shortjournal = {Neural Comput. Appl.},
  title        = {DL-DARE: Deep learning-based different activity recognition for the human–robot interaction environment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-classification for EEG motor imagery signals using
data evaluation-based auto-selected regularized FBCSP and convolutional
neural network. <em>NCA</em>, <em>35</em>(16), 12001–12027. (<a
href="https://doi.org/10.1007/s00521-023-08336-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a renewal of interest in brain–computer interface (BCI). One of the BCI tasks is to classify the EEG motor imagery (MI). A great deal of effort has been made on MI classification. What seems to be lacking, however, is multiple MI classification. This paper develops a single-channel-based convolutional neural network to tackle multi-classification motor imagery tasks. For multi-classification, a single-channel learning strategy can extract effective information from each independent channel, making the information between adjacent channels not affect each other. A data evaluation method and a mutual information-based regularization parameters auto-selection algorithm are also proposed to generate effective spatial filters. The proposed method can be used to tackle the problem of an inaccurate mixed covariance matrix caused by fixed regularization parameters and invalid training data. To illustrate the merits of the proposed methods, we used the tenfold cross-validation accuracy and kappa as the evaluation measures to test two data sets. BCI4-2a and BCI3a data sets have four mental classes. For the BCI4-2a data set, the average accuracy is 79.01\%, and the kappa is 0.7202 using data evaluation-based auto-selected filter bank regularized common spatial pattern voting (D-ACSP-V) and single-channel series convolutional neural network (SCS-CNN). Compared to traditional FBRCSP, the proposed method improved accuracy by 7.14\% for the BCI4-2a data set. By using the BCI3a data set, the proposed method improved accuracy by 9.54\% compared with traditional FBRCSP, the average accuracy of the proposed method is 83.70\%, and the kappa is 0.7827.},
  archive      = {J_NCA},
  author       = {An, Yang and Lam, Hak Keung and Ling, Sai Ho},
  doi          = {10.1007/s00521-023-08336-z},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {12001-12027},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-classification for EEG motor imagery signals using data evaluation-based auto-selected regularized FBCSP and convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-centers SoftMax reciprocal average precision loss for
deep metric learning. <em>NCA</em>, <em>35</em>(16), 11989–11999. (<a
href="https://doi.org/10.1007/s00521-023-08334-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep metric learning (DML) aims to learn the semantic embeddings with deep convolutional neural networks (DCNNs) that the similar instances are closer than different ones. Despite the success in the past decades, one drawback of metric learning approaches is that they are mostly driven by minimizing distances. Thus they remain lacking in awareness of the importance of shifting ranking orders which is essential in rank-based metric tasks. Moreover, in real-world scenarios, images of the same class always have several local clusters rather than a single one, e.g., cars from different perspectives and birds of different postures. Therefore, this work proposes multi-centers SoftMax reciprocal average precision loss (mcSAP) to jointly supervise the learning of DCNNs by SoftMax with multi-centers and a ranking-based metric loss. Firstly, we reformulate SoftMax to learn multiple sub-centers for each class to capture more local centroids for modeling intra-class variance in real-world data. Then, we introduce mcSAP loss that enhances the capacity on improving the order of positive instances at high ranks rather than those only at low ranks. And it is meaningful for obtaining a more optimally structured feature space with higher purity around the center. Moreover, we created Cattle-2022 dataset, consisting of 10,076 images from 246 identities of Chinese Simmental and Holstein for supporting DML tasks and even cattle identification. To validate the proposed mcSAP loss, it is comprehensively compared with several well-known losses on the benchmark fine-grained datasets, as CUB-2011, Cars196, Stanford online products (SOP) and our proposed Cattle-2022 dataset. It is encouraging to find that our approach outperforms the state-of-the-art models in both image retrieval and clustering benchmarks.},
  archive      = {J_NCA},
  author       = {Zhao, Jian-Min and Lian, Qiu-Sheng},
  doi          = {10.1007/s00521-023-08334-1},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11989-11999},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-centers SoftMax reciprocal average precision loss for deep metric learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective fitness-dependent optimizer algorithm.
<em>NCA</em>, <em>35</em>(16), 11969–11987. (<a
href="https://doi.org/10.1007/s00521-023-08332-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the multi-objective variant of the recently-introduced fitness dependent optimizer (FDO). The algorithm is called a multi-objective fitness dependent optimizer (MOFDO) and is equipped with all five types of knowledge (situational, normative, topographical, domain, and historical knowledge) as in FDO. MOFDO is tested on two standard benchmarks for the performance-proof purpose: classical ZDT test functions, which is a widespread test suite that takes its name from its authors Zitzler, Deb, and Thiele, and on IEEE Congress of Evolutionary Computation benchmark (CEC-2019) multi-modal multi-objective functions. MOFDO results are compared to the latest variant of multi-objective particle swarm optimization, non-dominated sorting genetic algorithm third improvement (NSGA-III), and multi-objective dragonfly algorithm. The comparative study shows the superiority of MOFDO in most cases and comparative results in other cases. Moreover, MOFDO is used for optimizing real-world engineering problems (e.g., welded beam design problems). It is observed that the proposed algorithm successfully provides a wide variety of well-distributed feasible solutions, which enable the decision-makers to have more applicable-comfort choices to consider.},
  archive      = {J_NCA},
  author       = {Abdullah, Jaza M. and Rashid, Tarik A. and Maaroof, Bestan B. and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-023-08332-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11969-11987},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective fitness-dependent optimizer algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pedestrian gender classification on imbalanced and small
sample datasets using deep and traditional features. <em>NCA</em>,
<em>35</em>(16), 11937–11968. (<a
href="https://doi.org/10.1007/s00521-023-08331-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript, imbalanced and small sample space (IB-SSS) dataset problems for pedestrian gender classification using fusion of selected deep and traditional features (PGC-FSDTF) are considered. In this regard, data preparation is first done through data augmentation and preprocessing steps to handle imbalanced classification problem and environmental effects, respectively. The proposed approach follows different types of feature extraction schemes, for instance, pyramid histogram of oriented gradients, hue saturation value histogram, deep visual features of DenseNet201 and InceptionResNetV2-based convolutional neural network architectures. The parallel fusion method computes the maximum and average values-based features from the learned features of both deep networks. Features are selected through features selection methods such as entropy and principal component analysis (PCA). The subsets of features are serially fused and provided to multiple classifiers to perform gender classification on IB-SSS datasets. Resultantly, the proposed PGC-FSDTF method shows better results in terms of different accuracies (overall, mean, and balanced), and area under curve on selected datasets. Further, improved results are achieved on applied datasets using PCA-based selected features and medium Gaussian support vector machine (M-SVM) classifier. These results on different datasets confirm that the selected feature combination provides a way to handle IB-SSS issues for PGC effectively.},
  archive      = {J_NCA},
  author       = {Fayyaz, Muhammad and Yasmin, Mussarat and Sharif, Muhammad and Iqbal, Tasswar and Raza, Mudassar and Babar, Muhammad Imran},
  doi          = {10.1007/s00521-023-08331-4},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11937-11968},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pedestrian gender classification on imbalanced and small sample datasets using deep and traditional features},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive dual niching-based differential evolution with
resource reallocation for nonlinear equation systems. <em>NCA</em>,
<em>35</em>(16), 11917–11936. (<a
href="https://doi.org/10.1007/s00521-023-08330-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems (NESs) remains a challenging task in the numerical optimization community due to the multi-root nature of NESs. To locate multiple roots of NESs in a single run, an adaptive dual niching-based differential evolution with resource reallocation is developed. The novelty of the proposed algorithm mainly lies in: (i) two niching-based differential evolution (DE) including neighborhood-based crowding DE (NCDE) and neighborhood-based speciation DE (NSDE), are adaptively called through a population diversity dynamic capture mechanism; (ii) a novel resource reallocation strategy is proposed to release those found solutions; (iii) an efficient parameter adaptation approach is employed to alleviate the parameter setting pressure in NCDE and NSDE. Experimental results on thirty NESs and a new test set show that the proposed algorithm exhibits significant performance in terms of the root rate and success rate when compared with other well-established algorithms.},
  archive      = {J_NCA},
  author       = {Shuijia, Li and Wenyin, Gong and Qiong, Gu and Zuowen, Liao},
  doi          = {10.1007/s00521-023-08330-5},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11917-11936},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive dual niching-based differential evolution with resource reallocation for nonlinear equation systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel probabilistic and 3D column p300 stimulus
presentation paradigm for EEG-based spelling systems. <em>NCA</em>,
<em>35</em>(16), 11901–11915. (<a
href="https://doi.org/10.1007/s00521-023-08329-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–computer interfaces can allow users to select letters or other targets on a computer screen without any muscular activity. One of the most popular EEG-based spelling systems is employed with P300 potentials, eliciting the brain&#39;s positive electrical response to a flash-denoting gaze at a target character. A P300 spelling system generally uses the row-column paradigm, which displays letters in a matrix and alternately flashes the rows and columns in a randomized order. At the same time, the participant focuses on a target letter. Afterward, a classification algorithm determines the row and column that elicited the largest P300 amplitude and finds the intersection of the identified row and column that indicates the target letter. This paper proposes a probabilistic and 3D column P300 stimulus presentation paradigm for a high-performance spelling system. In contrast to the classical 2D row-column paradigm, we utilized a 3D column stimulus presentation in the proposed paradigm, and we adaptively determined the flashing numbers of columns according to the probability of the following letter in the dictionary between 4 and 13. While the subject-independent P300 speller model was trained with the EEG signals of the first 10 participants, it was independently tested with the second group, including 15 volunteers. The results showed that the proposed probabilistic and 3D column P300 stimulus presentation paradigm-based method achieved 92.69\% average classification accuracy, which is 9.94\% higher than that of the non-probabilistic 3D column paradigm. The obtained experimental results show the effectiveness and potential of the proposed method to achieve very high performance for brain–computer interface spelling systems.},
  archive      = {J_NCA},
  author       = {Korkmaz, Onur Erdem and Aydemir, Onder and Oral, Emin Argun and Ozbek, Ibrahim Yucel},
  doi          = {10.1007/s00521-023-08329-y},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11901-11915},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel probabilistic and 3D column p300 stimulus presentation paradigm for EEG-based spelling systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective optimal allocation of multiple capacitors
and distributed generators considering different load models using
lichtenberg and thermal exchange optimization techniques. <em>NCA</em>,
<em>35</em>(16), 11867–11899. (<a
href="https://doi.org/10.1007/s00521-023-08327-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating distributed generations (DGs) into the radial distribution system (RDS) are becoming more crucial to capture the benefits of these DGs. However, the non-optimal integration of renewable DGs and shunt capacitors may lead to several operational challenges in distribution systems, including high energy losses, poor voltage quality, reverse power flow, and lower voltage stability. Therefore, in this paper, the multi-objective optimization problem is expressed with precisely selected three conflicting goals, incorporating the reduction in both power loss and voltage deviation and improvement of voltage stability. A new index for voltage deviation called root mean square voltage is suggested. The proposed multi-objective problems are addressed using two freshly metaheuristic techniques for optimal sitting and sizing multiple SCs and renewable DGs with unity and optimally power factors into RDS, presuming several voltage-dependent load models. These optimization techniques are the multi-objective thermal exchange optimization (MOTEO) and the multi-objective Lichtenberg algorithm (MOLA), which are regarded as being physics-inspired techniques. The MOLA is inspired by the physical phenomena of lightning storms and Lichtenberg figures (LF), while the MOTEO is developed based on the concept of Newtonian cooling law. The MOLA as a hybrid algorithm differs from many in the literature since it combines the population and trajectory-based search approaches. Further, the developed methodology is implemented on the IEEE 69-bus distribution network during several optimization scenarios, such as bi- and tri-objective problems. The fetched simulation outcomes confirmed the superiority of the MOTEO algorithm in achieving accurate non-dominated solutions with fewer outliers and standard deviation among all studied metrics.},
  archive      = {J_NCA},
  author       = {Elseify, Mohamed A. and Kamel, Salah and Nasrat, Loai and Jurado, Francisco},
  doi          = {10.1007/s00521-023-08327-0},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11867-11899},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective optimal allocation of multiple capacitors and distributed generators considering different load models using lichtenberg and thermal exchange optimization techniques},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy rough digraph based on strength of connectedness with
application. <em>NCA</em>, <em>35</em>(16), 11847–11866. (<a
href="https://doi.org/10.1007/s00521-023-08325-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough digraph is an effective tool for dealing with uncertain data and has been widely used in network analysis. At present, a rough digraph considering reachability, namely path information-based rough digraph (PIRD), has been proposed by approximating a digraph with its minimum equivalent subgraph and transitive closure. However, PIRD cannot reflect the strength of links, which will lead to the loss of important information. As the generalization of rough digraph in fuzzy context, fuzzy rough digraph is more accurate and effective in dealing with uncertainty, as it quantifies the strength of links. However, the existing fuzzy rough digraphs lack the consideration of reachability in digraphs, so they are not suitable for situations considering the propagation paths. Therefore, this paper aims to combine PIRD with fuzzy set theory and propose a fuzzy rough digraph considering reachability. First, we extend minimum equivalent subgraph to minimum equivalent fuzzy subgraph and give a corresponding algorithm. Then, by approximating a fuzzy digraph with its minimum equivalent fuzzy subgraph and fuzzy transitive closure, the paper introduces fuzzy rough digraph based on strength of connectedness and discusses its properties and rough features. Finally, the practicability of the proposed fuzzy rough digraph is verified by comparing it with PIRD in the scene of discovering the most influential spreaders in social trust networks. The comparison result shows that the proposed fuzzy rough digraph is more effective. Also, it is analyzed that the existing fuzzy rough digraph is not applicable to this scene.},
  archive      = {J_NCA},
  author       = {Wang, Danyang and Zhu, Ping},
  doi          = {10.1007/s00521-023-08325-2},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11847-11866},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy rough digraph based on strength of connectedness with application},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a compressed FCN architecture for semantic
segmentation using particle swarm optimization. <em>NCA</em>,
<em>35</em>(16), 11833–11846. (<a
href="https://doi.org/10.1007/s00521-023-08324-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have adapted the conventional deep learning classification networks to generate Fully Conventional Networks (FCN) for carrying out accurate semantic segmentation. However, such models are expensive both in terms of storage and inference time and not readily employable on edge devices. In this paper, a compressed version of VGG16-based Fully Convolution Network (FCN) has been developed using Particle Swarm Optimization. It has been shown that the developed model can offer tremendous saving in storage space and also faster inference time, and can be implemented on edge devices. The efficacy of the proposed approach has been tested using potato late blight leaf images from publicly available PlantVillage dataset, street scene image dataset and lungs X-Ray dataset and it has been shown that it approaches the accuracies offered by standard FCN even after 851× compression.},
  archive      = {J_NCA},
  author       = {Agarwal, Mohit and Gupta, Suneet K. and Biswas, K. K.},
  doi          = {10.1007/s00521-023-08324-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11833-11846},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of a compressed FCN architecture for semantic segmentation using particle swarm optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-media correlation learning for web video event mining
with integrated text semantics and network structural information.
<em>NCA</em>, <em>35</em>(16), 11815–11831. (<a
href="https://doi.org/10.1007/s00521-023-08323-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, cross-media web video event mining based on heterogeneous information networks (HIN) has attracted extensive attention. However, each web video is described by only a few words, resulting in sparse semantic associations between textual and visual information. In this case, it is difficult to seek out videos belonging to the same event, which brings great challenges to web video event mining. Nevertheless, nodes with similar structural features in network tend to be highly correlated. It can be found that structural information could provide complementary clues for correlation learning, which has been widely ignored in previous studies. Thus, we propose a novel cross-media correlation learning method with integrated text semantics and network structural information for web video event mining. Firstly, a multi-modal HIN is constructed to describe the interactions among videos, near-duplicate keyframes (NDKs) and terms. Then, hidden semantic associations between nodes are learned by designing semantic paths for enriching the sparse text distribution information. Next, the first-order proximity and second-order proximity of each pair of nodes are fused to obtain structural correlations in network, which reflects local and global structural proximity between nodes. Finally, a semantic and structural association fusion model based on network embedding is proposed to learn distinguishable low-dimensional representation vectors for event mining. Experiments on web videos from YouTube show the superior performance of our proposed method compared with several state-of-the-art models, with an average F1 score improved by $$16\%$$ to $$57\%$$ .},
  archive      = {J_NCA},
  author       = {Zhang, Chengde and Liu, Guoying and Xiao, Xia},
  doi          = {10.1007/s00521-023-08323-4},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11815-11831},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-media correlation learning for web video event mining with integrated text semantics and network structural information},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Laplace’s rule of succession: A simple and efficient way to
compare metaheuristics. <em>NCA</em>, <em>35</em>(16), 11807–11814. (<a
href="https://doi.org/10.1007/s00521-023-08322-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are algorithms that are used to solve difficult optimization problems. They are typically stochastic approaches; hence, proper statistical tests are needed to compare them. However, choosing an appropriate statistical test is not trivial given that each test requires some assumptions to be true before the test can be used. Moreover, the p-values associated with a statistical test is usually difficult to interpret. In this paper, we propose the use of Laplace’s rule of succession to compare different metaheuristic approaches. The rule is simple, intuitive and easy to compute. It can be used alone or to complement a statistical test. The process of using the rule for comparison purposes is clearly explained and applied to a typical scenario encountered in the field of metaheuristics. In this scenario, an improved variant of an existing metaheuristic algorithm is proposed. To evaluate the performance of the two algorithms, Laplace’s rule and a traditional statistical test are used. Analysis of the results and how to interpret them are provided. The results show that Laplace’s rule is consistent with the used statistical test. Furthermore, the rule is easier to compute and interpret.},
  archive      = {J_NCA},
  author       = {Omran, Mahamed Ghasib Hussein and Clerc, Maurice},
  doi          = {10.1007/s00521-023-08322-5},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11807-11814},
  shortjournal = {Neural Comput. Appl.},
  title        = {Laplace’s rule of succession: A simple and efficient way to compare metaheuristics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MTED: Multiple teachers ensemble distillation for compact
semantic segmentation. <em>NCA</em>, <em>35</em>(16), 11789–11806. (<a
href="https://doi.org/10.1007/s00521-023-08321-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current state-of-the-art semantic segmentation models achieve great success. However, their vast model size and computational cost limit their applications in many real-time systems and mobile devices. Knowledge distillation is one promising solution to compress the segmentation models. However, the knowledge from a single teacher may be insufficient, and the student may also inherit bias from the teacher. This paper proposes a multi-teacher ensemble distillation framework named MTED for semantic segmentation. The key idea is to effectively transfer the comprehensive knowledge from multiple teachers to one student. We present one multi-teacher output-based distillation loss to effectively distill the valuable knowledge in output probabilities to the student. We construct one adaptive weight assignment module to dynamically assign different weights to different teachers at each pixel. In addition, we introduce one multi-teacher feature-based distillation loss to transfer the comprehensive knowledge in the feature maps efficiently. We conduct extensive experiments on three benchmark datasets, Cityscapes, CamVid, and Pascal VOC 2012. The results show that the proposed MTED performs much better than the single-teacher methods on three datasets, e.g., Cityscapes, CamVid, and Pascal VOC 2012.},
  archive      = {J_NCA},
  author       = {Wang, Chen and Zhong, Jiang and Dai, Qizhu and Yu, Qien and Qi, Yafei and Fang, Bin and Li, Xue},
  doi          = {10.1007/s00521-023-08321-6},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11789-11806},
  shortjournal = {Neural Comput. Appl.},
  title        = {MTED: Multiple teachers ensemble distillation for compact semantic segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating green cover and open spaces in informal
settlements of mumbai using deep learning. <em>NCA</em>,
<em>35</em>(16), 11773–11788. (<a
href="https://doi.org/10.1007/s00521-023-08320-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haphazard urbanization has resulted in development of unplanned informal settlements, also called slums. Citizens residing in these dense settlements are generally deprived of essential sustainable drivers, i.e., green cover and open spaces (GOS). Such limitations can have an adverse impact on various aspects such as physiological, economical, health, and quality of life. Much research has been done on applying Machine Learning (ML) techniques for identifying slums at the city scale. However, no study explicitly addressed the problem of GOS extraction inside the informal settlements. This paper aims to fill this gap by training three modified Convolution Neural Network (CNN) models, i.e., VGG16-UNet, MobileNetV2-UNet, DeepLabV3 + on manually labeled high-resolution satellite imagery for the city of Mumbai. All three models performed excellently and achieved the state-of-the art overall accuracy of around 95\%, for the considered classes. Out of the three models, VGG16-UNet performed the best and hence was applied to the whole city for developing green, open, and green and open indices. The indices were further used to establish a quantitative relation between various built-up typologies and GOS. It was found that informal settlements have significantly less green and open space than other built-up typologies. Stark GOS difference between slums and its neighborhood planned residential was observed, and hence, requires urgent attention of the city managers. The outcome presented in the paper can be used as input to various decision-making systems concerning better informal space planning to better plan the GOS, which eventually can lead to development of sustainable cities.},
  archive      = {J_NCA},
  author       = {Dabra, Ayush and Kumar, Vaibhav},
  doi          = {10.1007/s00521-023-08320-7},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11773-11788},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluating green cover and open spaces in informal settlements of mumbai using deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully distributed dynamic event-triggered output regulation
for heterogeneous linear multiagent systems under fixed and switching
topologies. <em>NCA</em>, <em>35</em>(16), 11753–11771. (<a
href="https://doi.org/10.1007/s00521-023-08318-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the cooperative output regulation issues of heterogeneous linear multiagent systems under fixed and arbitrary connected switching topologies, respectively. Firstly, the fully distributed node-based event-triggered compensator under fixed topology and edge-based event-triggered compensator under arbitrary connected switching topologies are proposed, where two novel dynamic event-triggered mechanisms to ensure discrete communication between agents, respectively. Note that the internal dynamic variables included in the triggering mechanisms play an important role in reducing the communication frequency among neighbors. In addition, under these triggering mechanisms, the interval of adjacent interaction events of each agent is strictly greater than zero. Then, based on the proposed compensators, the fully distributed state and measured output feedback control protocols are designed to solve the cooperative output regulation problem. Finally, several examples are performed to validate the main results of this paper.},
  archive      = {J_NCA},
  author       = {Tan, Zilong and Zhang, Juan and Yan, Yuqing and Sun, Jiayue and Zhang, Huaguang},
  doi          = {10.1007/s00521-023-08318-1},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11753-11771},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fully distributed dynamic event-triggered output regulation for heterogeneous linear multiagent systems under fixed and switching topologies},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interactive deep model combined with retinex for
low-light visible and infrared image fusion. <em>NCA</em>,
<em>35</em>(16), 11733–11751. (<a
href="https://doi.org/10.1007/s00521-023-08314-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directly fusing the low-light visible and infrared images is hard to obtain fusion results containing rich structural details and critical infrared targets, due to the limitations of extreme illumination. The generated fusion results are typically not accurate to describe the scene nor are suitable for machine perception. Consequently, a novel image fusion framework combined with Retinex theory, termed as LLVIFusion, is designed for the low-light visible and infrared image fusion. Specifically, the training of LLVIFusion is accomplished via a two-stage training strategy. First, a new interactive fusion network is trained to generate initial fusion results with more informative features. Within the interactive fusion network, features are continuously reused in the same branch network and feature information from different branches are constantly interacted through the designed fusion blocks, which allows the fusion network to not only avoid losing information but also strengthen the information for subsequent processing. Further, an adaptive weight-based loss function is proposed to guide the fusion network for training. Next, a refinement network incorporating Retinex theory is introduced to optimize the visibility of the initial fusion results for obtaining high visual quality fusion results. In contrast to the 14 state-of-the-art comparison methods, LLVIFusion achieves the best values for all six objective measures on the LLVIP and the MF-Net datasets, while obtaining two best values and two second-best values for the objective measures on the TNO dataset. Such experimental results show that LLVIFusion can successfully perform low-light visible and infrared image fusion and produce good fusion results under normal illumination. The codes of LLVIFusion are accessible on https://github.com/govenda/LLVIFusion .},
  archive      = {J_NCA},
  author       = {Wang, Changcheng and Zang, Yongsheng and Zhou, Dongming and Nie, Rencan and Mei, Jiatian},
  doi          = {10.1007/s00521-023-08314-5},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11733-11751},
  shortjournal = {Neural Comput. Appl.},
  title        = {An interactive deep model combined with retinex for low-light visible and infrared image fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical arbitrage in the stock markets by the means of
multiple time horizons clustering. <em>NCA</em>, <em>35</em>(16),
11713–11731. (<a
href="https://doi.org/10.1007/s00521-023-08313-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, statistical arbitrage is one of the most attractive fields of study for researchers, and its applications are widely used also in the financial industry. In this work, we propose a new approach for statistical arbitrage based on clustering stocks according to their exposition on common risk factors. A linear multifactor model is exploited as theoretical background. The risk factors of such a model are extracted via Principal Component Analysis by looking at different time granularity. Furthermore, they are standardized to be handled by a feature selection technique, namely the Adaptive Lasso, whose aim is to find the factors that strongly drive each stock’s return. The assets are then clustered by using the information provided by the feature selection, and their exposition on each factor is deleted to obtain the statistical arbitrage. Finally, the Sequential Least SQuares Programming is used to determine the optimal weights to construct the portfolio. The proposed methodology is tested on the Italian, German, American, Japanese, Brazilian, and Indian Stock Markets. Its performances, evaluated through a Cross-Validation approach, are compared with three benchmarks to assess the robustness of our strategy.},
  archive      = {J_NCA},
  author       = {Gatta, Federico and Iorio, Carmela and Chiaro, Diletta and Giampaolo, Fabio and Cuomo, Salvatore},
  doi          = {10.1007/s00521-023-08313-6},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11713-11731},
  shortjournal = {Neural Comput. Appl.},
  title        = {Statistical arbitrage in the stock markets by the means of multiple time horizons clustering},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement control with fuzzy-rules emulated network for
robust-optimal drug-dosing of cancer dynamics. <em>NCA</em>,
<em>35</em>(16), 11701–11711. (<a
href="https://doi.org/10.1007/s00521-023-08312-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a nonlinear mathematical model of the biological phenomena in chemotherapy cancer treatment is considered as a class of unknown discrete-time systems when the input data and the measured output are only available. The input data are the drug administration represented as the control effort and the output is the tumor cells population. As a result, the actor-critic architecture is constructed without the full-state observer. Two sets of IF-THEN rules are utilized for fuzzy rules emulated networks by human knowledge according to the pharmacokinetic and pharmacodynamic details. The learning laws are derived from the concept of the incoherent reward function. Thus, the convergence of the internal signals and the robustness are accomplished by the theoretical and numerical results. Furthermore, the comparative results are given to demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_NCA},
  author       = {Treesatayapun, Chidentree and Muñoz-Vázquez, Aldo Jonathan},
  doi          = {10.1007/s00521-023-08312-7},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11701-11711},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement control with fuzzy-rules emulated network for robust-optimal drug-dosing of cancer dynamics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An error correction system for sea surface temperature
prediction. <em>NCA</em>, <em>35</em>(16), 11681–11699. (<a
href="https://doi.org/10.1007/s00521-023-08311-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main indicators for detecting changes in climate and marine ecosystems around the world is the sea surface temperature (SST). Even with several models presented in the literature, it is still a challenging task when only a single model is considered for SST forecasting. In this context, hybrid approaches that combine statistical models (to estimate linear dependencies) and machine learning models (to estimate nonlinear dependencies from residuals) have attained highlighted accuracy in several time series forecasting problems. In this way, this paper proposes a hybrid system that combines the autoregressive integrated moving average (ARIMA) model with a deep morphological neural network model, which employs dilation-erosion operators to estimate ARIMA’s model residuals. In this context, the proposed hybrid system is composed of three stages: (1) time series forecast using the ARIMA model, (2) residuals forecast using the deep morphological neural network and (3) a linear combination of the stages (1) and (2). Three SST time series are used in the experimental analysis. Moreover, the achieved results are evaluated using three relevant statistical measures showing that the proposed hybrid system attains higher accuracy when compared to other hybrid models in the literature.},
  archive      = {J_NCA},
  author       = {Araújo, Ricardo de A. and de Mattos Neto, Paulo S. G. and Nedjah, Nadia and Soares, Sergio C. B.},
  doi          = {10.1007/s00521-023-08311-8},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11681-11699},
  shortjournal = {Neural Comput. Appl.},
  title        = {An error correction system for sea surface temperature prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel deep learning approach to predict subject arm
movements from EEG-based signals. <em>NCA</em>, <em>35</em>(16),
11669–11679. (<a
href="https://doi.org/10.1007/s00521-023-08310-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Around 3 million people worldwide have an arm amputation. These people face a lot of trouble in their everyday life whilst performing basic tasks. This paper proposes a novel deep learning-based approach for predicting arm movements using EEG-based signals. We plan to design and develop an active exoskeleton controlled by the same EEG-based signals to rehabilitate the amputees. The architecture design is intended to build an exoskeleton arm with at least 3 degrees of freedom that can perform complex movements and is sophisticated enough to substitute for a real arm. This prosthetic arm will be controlled using electroencephalogram (EEG) signals gathered by different devices/headsets and processed using deep learning models. The results show that our proposed approach gives excellent results.},
  archive      = {J_NCA},
  author       = {Kansal, Sachin and Garg, Dhruv and Upadhyay, Aditya and Mittal, Snehil and Talwar, Guneet Singh},
  doi          = {10.1007/s00521-023-08310-9},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11669-11679},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel deep learning approach to predict subject arm movements from EEG-based signals},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interval type-2 fuzzy neural network-based adaptive
compensation control for omni-directional mobile robot. <em>NCA</em>,
<em>35</em>(16), 11653–11667. (<a
href="https://doi.org/10.1007/s00521-023-08309-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to overcome the influence of model uncertainty and external disturbance on the trajectory tracking accuracy of four-wheel omnidirectional mobile robot (FM-OMR), a new adaptive trajectory tracking control scheme based on interval type 2 fuzzy neural network approximator (IT2FNNA) is proposed in this paper. Based on the kinematics and dynamics model of FM-OMR, a dual loop trajectory controller is constructed. To improve the adaptive ability of IT2FNNA, an adaptive adjustment method for the network output is proposed. In addition, to improve the approximation accuracy of the IT2FNNA, a bias strategy is proposed based on the FM-OMR model. Finally, the circle track and ”8” track are simulated and tested. The simulation and experimental results show that the bias strategy and adaptive factor really improve the approximation ability and accuracy of IT2FNNA, and the proposed adaptive control scheme has smaller fluctuations, higher accuracy and better steady-state performance.},
  archive      = {J_NCA},
  author       = {Qin, Peng and Zhao, Tao and Dian, Songyi},
  doi          = {10.1007/s00521-023-08309-2},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11653-11667},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interval type-2 fuzzy neural network-based adaptive compensation control for omni-directional mobile robot},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Influencing brain waves by evoked potentials as biometric
approach: Taking stock of the last six years of research. <em>NCA</em>,
<em>35</em>(16), 11625–11651. (<a
href="https://doi.org/10.1007/s00521-023-08539-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scientific advances of recent years have made available to anyone affordable hardware devices capable of doing something unthinkable until a few years ago, the reading of brain waves. It means that through small wearable devices it is possible to perform an electroencephalography (EEG), albeit with less potential than those offered by high-cost professional devices. Such devices make it possible for researchers a huge number of experiments that were once impossible in many areas due to the high costs of the necessary hardware. Many studies in the literature explore the use of EEG data as a biometric approach for people identification, but, unfortunately, it presents problems mainly related to the difficulty of extracting unique and stable patterns from users, despite the adoption of sophisticated techniques. An approach to face this problem is based on the evoked potentials (EPs), external stimuli applied during the EEG reading, a noninvasive technique used for many years in clinical routine, in combination with other diagnostic tests, to evaluate the electrical activity related to some areas of the brain and spinal cord to diagnose neurological disorders. In consideration of the growing number of works in the literature that combine the EEG and EP approaches for biometric purposes, this work aims to evaluate the practical feasibility of such approaches as reliable biometric instruments for user identification by surveying the state of the art of the last 6 years, also providing an overview of the elements and concepts related to this research area.},
  archive      = {J_NCA},
  author       = {Saia, Roberto and Carta, Salvatore and Fenu, Gianni and Pompianu, Livio},
  doi          = {10.1007/s00521-023-08539-4},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11625-11651},
  shortjournal = {Neural Comput. Appl.},
  title        = {Influencing brain waves by evoked potentials as biometric approach: Taking stock of the last six years of research},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven approaches and model-based methods for detecting
and locating leaks in water distribution systems: A literature review.
<em>NCA</em>, <em>35</em>(16), 11611–11623. (<a
href="https://doi.org/10.1007/s00521-023-08497-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water distribution systems are made up of interconnected components that should allow water systems to meet demand, but leaks can waste enough water to limit supply. To limit financial losses, water utilities must quickly determine that a leak is occurring and where it is referred to as the localization of the leak. Over the years, there have been various methods proposed to detect and locate leaks. This literature review summarizes many of the methodologies introduced, categorizes them into data-driven approaches and model-based methods, and reviews their performance. Data-driven approaches demand efficient exploitation and use of available data from pressure and flow devices, and model-based methods require finely calibrated hydraulic models to reach a verdict. Data-driven approaches can manage uncertainty better than model-based methods.},
  archive      = {J_NCA},
  author       = {Nimri, Waid and Wang, Yong and Zhang, Ziang and Deng, Chengbin and Sellstrom, Kristofor},
  doi          = {10.1007/s00521-023-08497-x},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11611-11623},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-driven approaches and model-based methods for detecting and locating leaks in water distribution systems: A literature review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new deep belief network-based multi-task learning for
diagnosis of alzheimer’s disease. <em>NCA</em>, <em>35</em>(16),
11599–11610. (<a
href="https://doi.org/10.1007/s00521-021-06149-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of Alzheimer’s disease (AD) and mild cognitive impairment (MCI), especially distinguishing the progressive MCI (pMCI) from stable MCI (sMCI), will be helpful in both reducing the risk of converting into AD and also releasing the burden on the family and even the society. In this study, a novel deep belief network (DBN) based multi-task learning algorithm is developed for the classification issue. In particular, the dropout technology and zero-masking strategy are exploited for getting over the overfitting problem and also enhancing the generalization ability and robustness of the model. Then, a new framework based on the DBN-based multi-task learning is established for accurate diagnosis of AD. After MRI preprocessing, not only the principal component analysis is utilized to reduce the feature dimension, but also multi-task feature selection approach is introduced to select the feature set related to all tasks as a result of taking the internal relevancy among multiple related tasks into consideration. Using data from the ADNI dataset, our method achieves satisfactory results in six tasks of health control (HC) vs. AD, HC vs. pMCI, HC vs. sMCI, pMCI vs. AD, sMCI vs. AD and sMCI vs. pMCI with the accuracies are 98.62\%, 96.67\%, 92.31\%, 91.89\%, 99.62\% and 87.78\%, respectively. Experimental results demonstrate that the DBN-based MTL algorithm developed in this study is an effective, superior and practical method of AD diagnosis.},
  archive      = {J_NCA},
  author       = {Zeng, Nianyin and Li, Han and Peng, Yonghong},
  doi          = {10.1007/s00521-021-06149-6},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11599-11610},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new deep belief network-based multi-task learning for diagnosis of alzheimer’s disease},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Rib segmentation algorithm for x-ray image based on
unpaired sample augmentation and multi-scale network. <em>NCA</em>,
<em>35</em>(16), 11583–11597. (<a
href="https://doi.org/10.1007/s00521-021-06546-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rib segmentation based on chest X-ray images is essential in the computer-aided diagnosis systems of lung cancer, which serves as an important step in the quantitative analysis of various types of lung diseases. However, the traditional methods are unable to segment ribs effectively due to the unclear edges and overlapping regions in X-ray images. A novel rib segmentation framework based on Unpaired Sample Augmentation and Multi-Scale Network is presented in this paper, aiming to improve the accuracy of ribs segmentation with limited labeled samples. First, the algorithm learns pneumonia-related texture changes via unpaired chest x-ray images and generates various augmented samples. Then, a multi-scale network attempts to learn hierarchical features using global supervision. Finally, the refined segmentation result of each organ is achieved by using a deep separation module and a comprehensive loss function. Specifically, the hierarchical features can greatly improve the robustness of multi-organ segmentation networks. The complex multi-organ segmentation task with limited labeled data is simplified with the designed deep separation module. We justify the proposed framework through extensive experiments. It achieves good performance with DSC, Precision, Recall, and Jaccard of 88.03, 88.25, 88.36, and 79.02\%, respectively. The DSC value increases nearly by 3\% compared to other popular methods. The experimental results show that our algorithm presents better segmentation performance for the overlapping region and fuzzy region of multiple organs, which holds research value and prospects for application.},
  archive      = {J_NCA},
  author       = {Wang, Hongyu and Zhang, Dandan and Ding, Songtao and Gao, Zhanyi and Feng, Jun and Wan, Shaohua},
  doi          = {10.1007/s00521-021-06546-x},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11583-11597},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rib segmentation algorithm for X-ray image based on unpaired sample augmentation and multi-scale network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tofee-tree: Automatic feature engineering framework for
modeling trend-cycle in time series forecasting. <em>NCA</em>,
<em>35</em>(16), 11563–11582. (<a
href="https://doi.org/10.1007/s00521-021-06438-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most time series forecasting tasks using Artificial Neural Networks (ANNs) relegate trend-cycle modeling to a simple preprocessing step. In this work, we propose an automatic feature engineering framework for modeling the trend-cycle (tofee-tree) in time series forecasting. The first stage of the framework automatically creates over 286 deterministic linear and nonlinear engineered features to model the trend-cycle. These features are based only on the time of observation and length of the time series, making them domain-agnostic. In the second stage of the framework, a SHapley Additive exPlanations (SHAP)—based feature selection procedure using Light Gradient Boosted Machine (LightGBM) selects the most relevant features. These relevant features can be used for forecasting with ANNs in addition to the auto-regressive lags. Two popular ANNs—Multi-Layer Perceptron (MLP) and Long Short Term Memory network (LSTM) are used to evaluate our proposed tofee-tree framework. Comparisons against two empirical studies using the M3 competition dataset show that the proposed framework improved the overall Symmetric Mean Absolute Percentage Error (SMAPE) in the one-step, medium- and long-term. The relative improvement in one-step SMAPE is 3\% for MLP and 23\% for LSTM. We also show that the residual seasonality left after deseasonalization can be modeled using the tofee-tree framework.},
  archive      = {J_NCA},
  author       = {Selvam, Santhosh Kumar and Rajendran, Chandrasekharan},
  doi          = {10.1007/s00521-021-06438-0},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11563-11582},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tofee-tree: Automatic feature engineering framework for modeling trend-cycle in time series forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel bio-inspired hybrid multi-filter wrapper gene
selection method with ensemble classifier for microarray data.
<em>NCA</em>, <em>35</em>(16), 11531–11561. (<a
href="https://doi.org/10.1007/s00521-021-06459-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microarray technology is known as one of the most important tools for collecting DNA expression data. This technology allows researchers to investigate and examine types of diseases and their origins. However, microarray data are often associated with a small sample size, a significant number of genes, imbalanced data, etc., making classification models inefficient. Thus, a new hybrid solution based on a multi-filter and adaptive chaotic multi-objective forest optimization algorithm (AC-MOFOA) is presented to solve the gene selection problem and construct the Ensemble Classifier. In the proposed solution, a multi-filter model (i.e., ensemble filter) is proposed as preprocessing step to reduce the dataset&#39;s dimensions, using a combination of five filter methods to remove redundant and irrelevant genes. Accordingly, the results of the five filter methods are combined using a voting-based function. Additionally, the results of the proposed multi-filter indicate that it has good capability in reducing the gene subset size and selecting relevant genes. Then, an AC-MOFOA based on the concepts of non-dominated sorting, crowding distance, chaos theory, and adaptive operators is presented. AC-MOFOA as a wrapper method aimed at reducing dataset dimensions, optimizing KELM, and increasing the accuracy of the classification, simultaneously. Next, in this method, an ensemble classifier model is presented using AC-MOFOA results to classify microarray data. The performance of the proposed algorithm was evaluated on nine public microarray datasets, and its results were compared in terms of the number of selected genes, classification efficiency, execution time, time complexity, hypervolume indicator, and spacing metric with five hybrid multi-objective methods, and three hybrid single-objective methods. According to the results, the proposed hybrid method could increase the accuracy of the KELM in most datasets by reducing the dataset&#39;s dimensions and achieve similar or superior performance compared to other multi-objective methods. Furthermore, the proposed Ensemble Classifier model could provide better classification accuracy and generalizability in the seven of nine microarray datasets compared to conventional ensemble methods. Moreover, the comparison results of the Ensemble Classifier model with three state-of-the-art ensemble generation methods indicate its competitive performance in which the proposed ensemble model achieved better results in the five of nine datasets.},
  archive      = {J_NCA},
  author       = {Nouri-Moghaddam, Babak and Ghazanfari, Mehdi and Fathian, Mohammad},
  doi          = {10.1007/s00521-021-06459-9},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11531-11561},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel bio-inspired hybrid multi-filter wrapper gene selection method with ensemble classifier for microarray data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A feature weighted support vector machine and artificial
neural network algorithm for academic course performance prediction.
<em>NCA</em>, <em>35</em>(16), 11517–11529. (<a
href="https://doi.org/10.1007/s00521-021-05962-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Academic performance, a globally understood metric, is utilized worldwide across disparate teaching and learning environments and is regarded as a quantifiable indicator of learning gain. The ability to reliably estimate student’s academic performance is important and can assist academic staff to improve the provision of support. However, it is recognized that academic performance estimation is non-trivial and affected by multiple factors, including a student’s engagement with learning activities and their social, geographic, and demographic characteristics. This paper investigates the opportunity to develop reliable models for predicting student performance using Artificial Intelligence. Specifically, we propose two-step academic performance prediction using feature weighted support vector machine and artificial neural network (ANN) learning. A feature weighted SVM, where the importance of different features to the outcome is calculated using information gain ratios, is employed to perform coarse-grained binary classification (pass, $$P1$$ , or fail, $$P0$$ ). Subsequently, detailed score levels are divided from D to A+, and ANN learning is employed for fine-grained, multi-class training of the $$P1$$ and $$P0$$ classes separately. The experiments and our subsequent ablation study, which are conducted on the student datasets from two Portuguese secondary schools, have proved the effectiveness of this hybridized method.},
  archive      = {J_NCA},
  author       = {Huang, Chenxi and Zhou, Junsheng and Chen, Jinling and Yang, Jane and Clawson, Kathy and Peng, Yonghong},
  doi          = {10.1007/s00521-021-05962-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11517-11529},
  shortjournal = {Neural Comput. Appl.},
  title        = {A feature weighted support vector machine and artificial neural network algorithm for academic course performance prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A neural network approach to optimising treatments for
depression using data from specialist and community psychiatric services
in australia, new zealand and japan. <em>NCA</em>, <em>35</em>(16),
11497–11516. (<a
href="https://doi.org/10.1007/s00521-021-06710-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigated the application of a recurrent neural network for optimising pharmacological treatment for depression. A clinical dataset of 458 participants from specialist and community psychiatric services in Australia, New Zealand and Japan were extracted from an existing custom-built, web-based tool called Psynary . This data, which included baseline and self-completed reviews, was used to train and refine a novel algorithm which was a fully connected network feature extractor and long short-term memory algorithm was firstly trained in isolation and then integrated and annealed using slow learning rates due to the low dimensionality of the data. The accuracy of predicting depression remission before processing patient review data was 49.8\%. After processing only 2 reviews, the accuracy was 76.5\%. When considering a change in medication, the precision of changing medications was 97.4\% and the recall was 71.4\% . The medications with predicted best results were antipsychotics (88\%) and selective serotonin reuptake inhibitors (87.9\%). This is the first study that has created an all-in-one algorithm for optimising treatments for all subtypes of depression. Reducing treatment optimisation time for patients suffering with depression may lead to earlier remission and hence reduce the high levels of disability associated with the condition. Furthermore, in a setting where mental health conditions are increasing strain on mental health services, the utilisation of web-based tools for remote monitoring and machine/deep learning algorithms may assist clinicians in both specialist and primary care in extending specialist mental healthcare to a larger patient community.},
  archive      = {J_NCA},
  author       = {Cousins, Aidan and Nakano, Lucas and Schofield, Emma and Kabaila, Rasa},
  doi          = {10.1007/s00521-021-06710-3},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11497-11516},
  shortjournal = {Neural Comput. Appl.},
  title        = {A neural network approach to optimising treatments for depression using data from specialist and community psychiatric services in australia, new zealand and japan},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). E-learningDJUST: E-learning dataset from jordan university
of science and technology toward investigating the impact of COVID-19
pandemic on education. <em>NCA</em>, <em>35</em>(16), 11481–11495. (<a
href="https://doi.org/10.1007/s00521-021-06712-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the COVID-19 pandemic has triggered different behaviors in education, especially during the lockdown, to contain the virus outbreak in the world. As a result, educational institutions worldwide are currently using online learning platforms to maintain their education presence. This research paper introduces and examines a dataset, E-LearningDJUST, that represents a sample of the student’s study progress during the pandemic at Jordan University of Science and Technology (JUST). The dataset depicts a sample of the university’s students as it includes 9,246 students from 11 faculties taking four courses in spring 2020, summer 2020, and fall 2021 semesters. To the best of our knowledge, it is the first collected dataset that reflects the students’ study progress within a Jordanian institute using e-learning system records. One of this work’s key findings is observing a high correlation between e-learning events and the final grades out of 100. Thus, the E-LearningDJUST dataset has been experimented with two robust machine learning models (Random Forest and XGBoost) and one simple deep learning model (Feed Forward Neural Network) to predict students’ performances. Using RMSE as the primary evaluation criteria, the RMSE values range between 7 and 17. Among the other main findings, the application of feature selection with the random forest leads to better prediction results for all courses as the RMSE difference ranges between (0–0.20). Finally, a comparison study examined students’ grades before and after the Coronavirus pandemic to understand how it impacted their grades. A high success rate has been observed during the pandemic compared to what it was before, and this is expected because the exams were online. However, the proportion of students with high marks remained similar to that of pre-pandemic courses.},
  archive      = {J_NCA},
  author       = {Abdullah, Malak and Al-Ayyoub, Mahmoud and AlRawashdeh, Saif and Shatnawi, Farah},
  doi          = {10.1007/s00521-021-06712-1},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11481-11495},
  shortjournal = {Neural Comput. Appl.},
  title        = {E-learningDJUST: E-learning dataset from jordan university of science and technology toward investigating the impact of COVID-19 pandemic on education},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Innovative feature-driven machine learning and deep learning
for finance, education, and healthcare. <em>NCA</em>, <em>35</em>(16),
11477–11480. (<a
href="https://doi.org/10.1007/s00521-023-08543-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Parisi, Luca and Manaog, Marianne Lyne},
  doi          = {10.1007/s00521-023-08543-8},
  journal      = {Neural Computing and Applications},
  number       = {16},
  pages        = {11477-11480},
  shortjournal = {Neural Comput. Appl.},
  title        = {Innovative feature-driven machine learning and deep learning for finance, education, and healthcare},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimized model for network intrusion detection systems
in industry 4.0 using XAI based bi-LSTM framework. <em>NCA</em>,
<em>35</em>(15), 11459–11475. (<a
href="https://doi.org/10.1007/s00521-023-08319-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industry 4.0 enable novel business cases, such as client-specific production, real-time monitoring of process condition and progress, independent decision making and remote maintenance, to name a few. However, they are more susceptible to a broad range of cyber threats because of limited resources and heterogeneous nature. Such risks cause financial and reputational damages for businesses, well as the theft of sensitive information. The higher level of diversity in industrial network prevents the attackers from such attacks. Therefore, to efficiently detect the intrusions, a novel intrusion detection system known as Bidirectional Long Short-Term Memory based Explainable Artificial Intelligence framework (BiLSTM-XAI) is developed. Initially, the preprocessing task using data cleaning and normalization is performed to enhance the data quality for detecting network intrusions. Subsequently, the significant features are selected from the databases using the Krill herd optimization (KHO) algorithm. The proposed BiLSTM-XAI approach provides better security and privacy inside the industry networking system by detecting intrusions very precisely. In this, we utilized SHAP and LIME explainable AI algorithms to improve interpretation of prediction results. The experimental setup is made by MATLAB 2016 software using Honeypot and NSL-KDD datasets as input. The analysis result reveals that the proposed method achieves superior performance in detecting intrusions with a classification accuracy of 98.2\%.},
  archive      = {J_NCA},
  author       = {Sivamohan, S. and Sridhar, S. S.},
  doi          = {10.1007/s00521-023-08319-0},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11459-11475},
  shortjournal = {Neural Comput. Appl.},
  title        = {An optimized model for network intrusion detection systems in industry 4.0 using XAI based bi-LSTM framework},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning metric space with distillation for large-scale
multi-label text classification. <em>NCA</em>, <em>35</em>(15),
11445–11458. (<a
href="https://doi.org/10.1007/s00521-023-08308-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network-based methods have achieved outstanding results in the task of text classification. However, the relationship of text–label and label–label has not been thoroughly investigated for most existing methods. Furthermore, these methods have excessive computational and memory overhead for large-scale classification. To address these challenges, we propose a novel framework with metric learning and knowledge distillation. We first project the texts and labels into the same embedding space by utilizing the symmetry metric learning on both text–centric and label–centric relationships. Then the distillation component is introduced to learn the text representation features with a deep module. Finally, we use this distilled module to encode new text and make predictions with label embeddings in the metric space. Experimental results on four real datasets show that our model achieves very competitive prediction accuracy while improving training and prediction efficiency.},
  archive      = {J_NCA},
  author       = {Qin, Shaowei and Wu, Hao and Zhou, Lihua and Li, Jiahui and Du, Guowang},
  doi          = {10.1007/s00521-023-08308-3},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11445-11458},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning metric space with distillation for large-scale multi-label text classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physiotherapy-based human activity recognition using deep
learning. <em>NCA</em>, <em>35</em>(15), 11431–11444. (<a
href="https://doi.org/10.1007/s00521-023-08307-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, continuous human activity recognition is being studied broadly by investigators for diverse applications. However, the studies based on physiotherapy action tracking from the physiotherapy video dataset are limited. Hence, the physiotherapy dataset has been considered in this present study. Moreover, deep learning-based (DL) neural networks have promoted the enhancement of activity detection study to become an essential technique. DL-based neural networks, such as long short-term memory, can automatically acquire the significant features from the physiotherapy video of sub-activity and main activity. Nevertheless, some physiotherapy videos are inappropriate and correspond to insignificant actions. Consequently, these insignificant actions can cause the recognition of continuous movements. Therefore, a novel strawberry-based recurrent neural framework is proposed to address this issue. Here, a physiotherapy video is taken as the input, and this dataset consists of several actions. Consequently, all the steps are done by one single person. So, the proposed design initially identifies all sub-activities based on that sub-activities, and the main physiotherapy actions were classified. After that, repeated action counts and their starting and ending times are evaluated. Finally, the present study&#39;s design is considered in terms of performance metrics. Three things are mentioned in this article. First the class determines whether the human body is static, dynamic, or transitional, which class indicates the position of action. To recognize the main activity, it is important to first identify all sub-activities in the physiotherapy video. Then, you should count the number of times each sub-activity was performed and how long it took overall. The proposed model was implemented using the Python platform, and the results were compared with the existing models. The proposed model shows higher recognition accuracy in comparison.},
  archive      = {J_NCA},
  author       = {Deotale, Disha and Verma, Madhushi and Suresh, P. and Kumar, Neeraj},
  doi          = {10.1007/s00521-023-08307-4},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11431-11444},
  shortjournal = {Neural Comput. Appl.},
  title        = {Physiotherapy-based human activity recognition using deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A lightweight relation network for few-shots classification
of hyperspectral images. <em>NCA</em>, <em>35</em>(15), 11417–11430. (<a
href="https://doi.org/10.1007/s00521-023-08306-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are data-hungry and require numerous labelled data for their training; as a result, these approaches are difficult to apply in a domain where very less training data is available. Although few-shots learning has emerged as a promising solution in domains where limited data is available. However, due to model complexity, these models still suffer when deployed on low-end devices. In this work, we propose a lightweight relation network, meta-learning, to classify hyperspectral images in the few-shots and one-shot settings. In this network, a CNN is used to utilize the spatial-spectral information present in the data. The proposed meta-learning-based network is trained episodically in an end-to-end manner to regress a relation score and perform the instance-label assignment. Experiments are performed on four benchmark datasets, namely, Indian Pines, Salinas, Pavia Center and Pavia University. Empirical results show that the proposed network achieves state-of-the-art results on the Indian Pines dataset; for all other datasets, its performance remains competitive with the approaches reported in the literature, even with more than a hundred times lesser parameters. Consequently, the proposed lightweight relation network can be deployed and fine-tuned even on devices with limited computation capabilities.},
  archive      = {J_NCA},
  author       = {Mishra, Anshul and Singh, Upendra Pratap and Singh, Krishna Pratap},
  doi          = {10.1007/s00521-023-08306-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11417-11430},
  shortjournal = {Neural Comput. Appl.},
  title        = {A lightweight relation network for few-shots classification of hyperspectral images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using neural-genetic hybrid systems for complex decision
support. <em>NCA</em>, <em>35</em>(15), 11403–11416. (<a
href="https://doi.org/10.1007/s00521-023-08305-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a hybrid system for supporting complex decisions through integrating neural networks (NNs) and genetic algorithms (GAs). We investigate the feasibility of leveraging the synergistic effect of integrating NNs and GAs to support stock market investment decisions. Utilizing 10-year daily US stock market data, we identified a set of effective attributes to predict stock market. The results suggest that our system is capable of exhibiting learning behavior and is a promising tool for stock market prediction. Though NNs have been successfully applied to a variety of pattern recognition applications, the connection weights generation process is highly computationally demanding. We apply GAs to search stochastically for connection weights. This alleviates an NN&#39;s lengthy training problem so that our hybrid system is more applicable to support complex decision making. Another contribution of our research is parameter setting for GAs. Parameter setting is a long-time thorny issue for GA implementation. We focus on one of the most difficult issues—the setting for the mutation rate. Using the stock market prediction as an application area, we have helped shed light on the role and importance of the mutation rate, as well as the complementary effect of mutation and crossover functions. Our findings favor “low-mutation-rates.”},
  archive      = {J_NCA},
  author       = {Deng, Pi-Sheng and Huang, Tzu-Man},
  doi          = {10.1007/s00521-023-08305-6},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11403-11416},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using neural-genetic hybrid systems for complex decision support},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ITabNet: An improved neural network for tabular data and its
application to predict socioeconomic and environmental attributes.
<em>NCA</em>, <em>35</em>(15), 11389–11402. (<a
href="https://doi.org/10.1007/s00521-023-08304-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing application of machine learning methods to predict socioeconomic and environmental attributes in computational social science, where big data are usually presented in tabular format. However, it is still a challenge to develop novel deep learning models to deal with tabular data, fill missing value, improve prediction accuracy, and enhance interpretability. In this study, we for the first time apply a tabular deep learning methodology (TabNet) to predict socioeconomic and environmental attributes (number of population and companies, volume of consumption, poker players’ behaviors, forest cover, etc.). Furthermore, we develop a new network architecture, referred to as improved TabNet (iTabNet), that can simultaneously learn local and global features in the tabular data to improve prediction accuracy. We also introduce a difference loss to constrain the feature selection process in iTabNet so that the model can use different features at different steps to enhance interpretability. To deal with missing values, we introduce a fusion strategy based on data mean and Auto-Encoder network to efficiently complete a more reasonable value filling. Experimental results demonstrate that the proposed iTabNet achieves competitive performances in the application to predict socioeconomic and environmental attributes based on tabular data, iTabNet using the proposed fusion strategy significantly outperforms other machine learning models when tabular data have missing values.},
  archive      = {J_NCA},
  author       = {Liu, Junmin and Tian, Tian and Liu, Yunxia and Hu, Sufeng and Li, Mengyao},
  doi          = {10.1007/s00521-023-08304-7},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11389-11402},
  shortjournal = {Neural Comput. Appl.},
  title        = {ITabNet: An improved neural network for tabular data and its application to predict socioeconomic and environmental attributes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RealMalSol: Real-time optimized model for android malware
detection using efficient neural networks and model quantization.
<em>NCA</em>, <em>35</em>(15), 11373–11388. (<a
href="https://doi.org/10.1007/s00521-023-08303-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Android is currently the most dominant platform in the market in comparison with all other operating systems (OS) such as iOS, Windows, and Blackberry. As the scope of Android value-added applications has grown, so also the increased risk of exploitation; thus, highlighting the dire need to protect user’s privacy and data through malware detection and prevention. Among the two options—static and dynamic android malware detection, static has the inherent advantages of being fast and the first line of defense before application installation/execution; thus, same has been the focus of our work. Static malware analysis has been previously targeted in a number of works, with approaches ranging from machine learning (ML)-based models to statistical analysis techniques; however, the former has been determined to be more promising thus leading to our proposed neural network (NN)-based Real-device Malware Solution (RealMalSol). Our proposed solution not only provides improved accuracy of 96.4\% with respect to the contemporary options but also ensures customized, scalable and optimized deployment for on-device analysis in contrast to emulator-based methods. To cater for limited computational capability of Android devices; we considered model optimization in two steps; as a first efficient Feature Reduction (FR) is applied to reduce the model complexity without adversely impacting the accuracy, and next optimized transformation of the model to a lightweight construct has been analyzed in TensorFlow Lite. The accuracy of RealMalSol improved from 95.2\% to 96.40\% using feature reduction in the full dataset. Moreover, the resultant model also performed proficiently on Android devices due to the careful selection of the best quantization-based optimization after rigorous analysis.},
  archive      = {J_NCA},
  author       = {Chaudhary, Maham and Masood, Ammar},
  doi          = {10.1007/s00521-023-08303-8},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11373-11388},
  shortjournal = {Neural Comput. Appl.},
  title        = {RealMalSol: Real-time optimized model for android malware detection using efficient neural networks and model quantization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Camera-aware progressive learning for unsupervised person
re-identification. <em>NCA</em>, <em>35</em>(15), 11359–11371. (<a
href="https://doi.org/10.1007/s00521-023-08301-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised person re-identification (Re-ID) is a challenging task due to the problems of the view-specific gap across different cameras and the missing of ground truth labels. The intra-class variance caused by the camera domain gap makes the model difficult to distinguish cross-view discriminative information. The noisy pseudo labels may be misguide the model toward deteriorated over-fitting. Improving the clustering accuracy of pseudo labels and alleviating the intra-class variance can improve the performance of unsupervised person Re-ID. Most methods improve clustering accuracy by optimizing the clustering distribution of instance features in the memory bank. However, the optimized distribution is still unbalanced and has a large intra-class gap. In order to address this problem, we propose a camera-aware progressive learning (CAPL) for unsupervised person re-identification. In CAPL, on the one hand, clustering edge features are explored and used to update all instance features belonging to the same pseudo label in the memory bank, which makes the instance feature distribution more balanced; on the other hand, camera-relevant features are explored to update all instance features with the same pseudo-labels in the memory bank as well as the corresponding camera class centroids, which makes the model effectively reduces the intra-class variance. This process is performed iteratively, and finally, the global clustering distribution can be achieved progressively. Extensive experiments on four person Re-ID benchmarks and a vehicle Re-ID benchmark demonstrate that our proposed approach outperforms the state-of-the-art methods in terms of mAP and CMC.},
  archive      = {J_NCA},
  author       = {Liu, Yuxuan and Ge, Hongwei and Sun, Liang and Hou, Yaqing},
  doi          = {10.1007/s00521-023-08301-w},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11359-11371},
  shortjournal = {Neural Comput. Appl.},
  title        = {Camera-aware progressive learning for unsupervised person re-identification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards automated check-worthy sentence detection using
gated recurrent unit. <em>NCA</em>, <em>35</em>(15), 11337–11357. (<a
href="https://doi.org/10.1007/s00521-023-08300-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People are exposed to a lot of information daily, which is a mix of facts, opinions, and false claims. The rate at which information is created and spread has necessitated an automated fact-checking mechanism. In this work, we focus on the first step of the fact-checking system, which is to identify whether a given sentence is factual. We propose a glove embedding-based gated recurrent unit pipeline for check-worthy sentence detection, referred to as G2CW framework. It detects whether a given sentence has check-worthy content in it or not; furthermore, if it has check-worthy content, whether it is important or not, from a fact-checking perspective. We evaluate our proposed framework on two datasets: a standard ClaimBuster dataset commonly used by the research community for this problem and a self-curated IndianClaim dataset. Our G2CW framework outperforms prior work with 0.92 as F1-score. Furthermore, our G2CW framework, when trained on the ClaimBuster dataset, performs the best on the IndianClaims dataset.},
  archive      = {J_NCA},
  author       = {Jha, Ria and Motwani, Ena and Singhal, Nivedita and Kaushal, Rishabh},
  doi          = {10.1007/s00521-023-08300-x},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11337-11357},
  shortjournal = {Neural Comput. Appl.},
  title        = {Towards automated check-worthy sentence detection using gated recurrent unit},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complex turing patterns in chaotic dynamics of autocatalytic
reactions with the caputo fractional derivative. <em>NCA</em>,
<em>35</em>(15), 11309–11335. (<a
href="https://doi.org/10.1007/s00521-023-08298-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many chemical systems exhibit a range of patterns, a noticeable and interesting class of numerical patterns that arise in autocatalytic reactions which changes with increasing spatial domains. In this paper, autocatalytic spatiotemporal patterns were demonstrated using the system of chemical species modeled with the time-fractional Caputo derivatives of subdiffusive orders. It is not new that a spectral algorithm with its entire nature is more accurate when compared with a finite-difference scheme to solve a range of integer and non-integer order time partial differential equations. This is because the Fourier spectral techniques have the upper hand on high-order spectral accuracy, and are computationally efficient. Hence, it is regarded as the best approach to existing lower-order methods for integrating the second-order partial derivatives in space. This motivates the present study to explore the usefulness of Fourier spectral methods in resolving and obtaining complex Turing patterns arising from nonlinear fractional autocatalytic reaction-diffusion problems in high dimensions. The autocatalysis model was examines for linear stability in an attempt to obtain the correct choice of parameters that are likely to lead to the formation of new complex turing-like patterns. Numerical experiments in the 2D lead to a striking range of patterns arising from catalytic reactions of fractional-order labyrinthine pattern-like structures. Analysis of pattern formation was also extended to 3D dynamics to obtain a new set of patterns like a star-, cyclic-, diamond-like, and the emergence of apple-shaped structures, which are greatly influenced by either the choice parameters that are involved or that of the initial conditions.},
  archive      = {J_NCA},
  author       = {Owolabi, Kolade M. and Agarwal, Ravi P. and Pindza, Edson and Bernstein, Swanhild and Osman, Mohamed S.},
  doi          = {10.1007/s00521-023-08298-2},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11309-11335},
  shortjournal = {Neural Comput. Appl.},
  title        = {Complex turing patterns in chaotic dynamics of autocatalytic reactions with the caputo fractional derivative},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new ensemble classification approach based on rotation
forest and LightGBM. <em>NCA</em>, <em>35</em>(15), 11287–11308. (<a
href="https://doi.org/10.1007/s00521-023-08297-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research shows that the Rotation Forest and its several variants can achieve better performance than other widely used ensemble methods in classification issues. However, it is a very time-consuming task to train a Rotation Forest on large-scale and high-dimensional data. To improve its classification accuracy and reduce the computational cost, a novel classification ensemble algorithm named RoF-GBM is presented in this paper. In the novel algorithm, singular value decomposition is employed to solve the rotation matrix, and then whitening is performed to reduce the computational complexity of PCA. And LightGBM is utilized to train the base classifier to reduce the number of PCA calculations of the whole model. The effectiveness of the proposed RoF-GBM is evaluated against twelve small and medium-scale datasets, three large-scale datasets, three high-dimensional datasets, two artificial datasets and five comparison algorithms. And the extensive experimentation demonstrates that RoF-GBM can observably improve the training speed of Rotation Forest and generate a higher classification accuracy than LightGBM and the variants of Rotation Forest, such as RotBoost and Rotation of Random Forest. Moreover, RoF-GBM also shows strong robustness on some datasets with noise and extreme outliers.},
  archive      = {J_NCA},
  author       = {Gu, Qinghua and Sun, Wenjing and Li, Xuexian and Jiang, Song and Tian, Jingni},
  doi          = {10.1007/s00521-023-08297-3},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11287-11308},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new ensemble classification approach based on rotation forest and LightGBM},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cascaded structure tensor for robust baggage threat
detection. <em>NCA</em>, <em>35</em>(15), 11269–11285. (<a
href="https://doi.org/10.1007/s00521-023-08296-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last two decades, baggage scanning has become one of the prime aviation security concerns worldwide. Manual screening of the baggage items is tedious and an error-prone process that also compromises privacy. Hence, many researchers have developed X-ray imagery-based autonomous systems to address these shortcomings. This paper presents a cascaded structure tensor framework that can automatically detect suspicious objects from the baggage X-ray scans under extreme class imbalance and irrespective of the baggage clutter. The proposed framework is unique as it intelligently extracts each object by iteratively picking its contour-based transitional information from different orientations and uses only a single feed-forward convolutional neural network for the recognition. The proposed framework has been rigorously evaluated on publicly available GDXray and SIXray datasets for detecting the highly cluttered and overlapping suspicious items, where it achieved the mean average precision score of 0.9343 and 0.9595, respectively, across both datasets, outperforming state-of-the-art works by 1.94\% on the GDXray, and 8.21\% on the SIXray. Furthermore, the proposed framework gives the best trade-off between detection performance and efficiency.},
  archive      = {J_NCA},
  author       = {Hassan, Taimur and Akcay, Samet and Hassan, Bilal and Bennamoun, Mohammed and Khan, Salman and Dias, Jorge and Werghi, Naoufel},
  doi          = {10.1007/s00521-023-08296-4},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11269-11285},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cascaded structure tensor for robust baggage threat detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hardware implementation of particle swarm optimization with
chaotic fractional-order. <em>NCA</em>, <em>35</em>(15), 11249–11268.
(<a href="https://doi.org/10.1007/s00521-023-08295-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engineering optimization methods based on meta-heuristic algorithms are computationally demanding and might present complex implementation issues for embedded devices with high constraints. One of the interesting meta-heuristic methods frequently utilized to address diverse optimization issues in the real world is particle swarm optimization (PSO). However, the most challenging constraints in real applications; having an optimal execution time for an optimal solution, added to avoid premature convergence and stagnation in the local optima. In this study, we propose the hardware implementation of an improved particle swarm optimization algorithm by using the fractional order concept and chaos theory named CF-PSO. The concept is to substitute a chaotic sequence generator for the values of random variables and to use fractional calculus in the velocity and position expressions. We provide a hardware design of the enhanced PSO on Field Programmable Gate Array (FPGA) to obtain substantially quicker execution speeds than those attainable in software implementation. A Xilinx Virtex-7 Pro Development Kit is used to implement the hardware-improved PSO design and evaluate its performance. To start, we put the suggested architecture to the test using a benchmark of four functions to demonstrate the effectiveness of this hardware implementation. Secondly, we contrasted it with three other PSO variations: the conventional PSO, the PSO using fractional order velocity (F-V-PSO), and the PSO using fractional order velocity and position (F-VP-PSO). The experimental results show that the hardware implementation of F-VP-PSO is between 1.082 and 21.25 times faster. CF-PSO algorithm can be implemented in the Virtex7 VC707 evaluation platform by utilizing less than 2\% of the slice 462 registers and 16\% of the slice LUT (Look up Table) resources.},
  archive      = {J_NCA},
  author       = {Zermani, Aymen and Manita, Ghaith and Feki, Elyes and Mami, Abdelkader},
  doi          = {10.1007/s00521-023-08295-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11249-11268},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hardware implementation of particle swarm optimization with chaotic fractional-order},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid deep learning approach for classification of music
genres using wavelet and spectrogram analysis. <em>NCA</em>,
<em>35</em>(15), 11223–11248. (<a
href="https://doi.org/10.1007/s00521-023-08294-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual classification of millions of songs of the same or different genres is a challenging task for human beings. Therefore, there should be a machine intelligent model that can classify the genres of the songs very accurately. In this paper, a deep learning-based hybrid model is proposed for the analysis and classification of different music genre files. The proposed hybrid model mainly uses a combination of multimodal and transfer learning-based models for classification. This model is analyzed using GTZAN and Ballroom datasets. The GTZAN dataset contains 1000 music files classified with 10 different kinds of music genres such as Metal, Classical, Rock, Reggae, Pop, Disco, Blues, Country, Hip-Hop and Jazz, and the duration of each music file is 30 s. The Ballroom dataset contains 698 music files classified into 8 different kinds of music genres such as Tango, ChaChaCha, Rumba, Viennese waltz, Jlive, Waltz, Quickstep and Samba, and the duration of each music file is 30 s. The performance of the model is evaluated using the Python tool. The macro-average and weighted average are taken for computing the percentage of accuracy of each model. From the results, it is found that the proposed hybrid model is able to perform better as compared to other deep learning models such as the convolution neural network model, transfer learning-based model, multimodal model, machine learning models and other existing models in terms of training accuracy, validation accuracy, training loss, validation loss, precision, recall, F1-score and support.},
  archive      = {J_NCA},
  author       = {Jena, Kalyan Kumar and Bhoi, Sourav Kumar and Mohapatra, Sonalisha and Bakshi, Sambit},
  doi          = {10.1007/s00521-023-08294-6},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11223-11248},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid deep learning approach for classification of music genres using wavelet and spectrogram analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of barely visible impact damage in composite
laminates using deep learning and pulsed thermographic inspection.
<em>NCA</em>, <em>35</em>(15), 11207–11221. (<a
href="https://doi.org/10.1007/s00521-023-08293-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasingly comprehensive utilisation of Carbon Fibre-Reinforced Polymers (CFRP) in modern industry, defects detection and characterisation of these materials have become very important and draw significant research attention. During the past 10 years, Artificial Intelligence (AI) technologies have been attractive in this area due to their outstanding ability in complex data analysis tasks. Most current AI-based studies on damage characterisation in this field focus on damage segmentation and depth measurement, which also faces the bottleneck of lacking adequate experimental data for model training. This paper proposes a new framework to understand the relationship between Barely Visible Impact Damage features occurring in typical CFRP laminates to their corresponding controlled drop-test impact energy using a Deep Learning approach. A parametric study consisting of one hundred CFRP laminates with known material specification and identical geometric dimensions were subjected to drop-impact tests using five different impact energy levels. Then Pulsed Thermography was adopted to reveal the subsurface impact damage in these specimens and recorded damage patterns in temporal sequences of thermal images. A convolutional neural network was then employed to train models that aim to classify captured thermal photos into different groups according to their corresponding impact energy levels. Testing results of models trained from different time windows and lengths were evaluated, and the best classification accuracy of 99.75\% was achieved. Finally, to increase the transparency of the proposed solution, a salience map is introduced to understand the learning source of the produced models.},
  archive      = {J_NCA},
  author       = {Deng, Kailun and Liu, Haochen and Yang, Lichao and Addepalli, Sri and Zhao, Yifan},
  doi          = {10.1007/s00521-023-08293-7},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11207-11221},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of barely visible impact damage in composite laminates using deep learning and pulsed thermographic inspection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of dependency of compression index on toughness
limit for fine-grained soils. <em>NCA</em>, <em>35</em>(15),
11183–11205. (<a
href="https://doi.org/10.1007/s00521-023-08292-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of the ultimate settlement is vital for the assessment of the service life of a structure, particularly when it is underlain by fine-grained soils. As known, this value is a function of the compression index (Cc) of soils, which can simply be found by performance of oedometer tests. For this purpose, more than 2000 test results from past studies were compiled to constitute a database. Then, multiple linear regression analyses were employed to predict the Cc parameter by use of toughness limit (TL) and a function of this parameter, namely the soil state index (SSI). It was noticed that SSI was a better predictor of Cc, in comparison with TL. Prediction ability of many equations from literature was questioned, and it was concluded that these equations were good predictors of their own data. Moving to a generalized behavior, data show a more scattered structure, which needs more sophisticated methods using above-mentioned parameters as inputs. In this regard, artificial neural networks were employed to estimate the Cc by use of single input parameters: TL or SSI. Additionally, a combination of Atterberg limits was also instructed as inputs for prediction of Cc. A comparative analysis of the effects of learning algorithm, input data, and number of neurons in hidden layer was given. It was concluded that the TL and SSI are reasonable predictors of compression index.},
  archive      = {J_NCA},
  author       = {Shimobe, Satoru and Karakan, Eyyüb and Sezer, Alper},
  doi          = {10.1007/s00521-023-08292-8},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11183-11205},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation of dependency of compression index on toughness limit for fine-grained soils},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive mutation strategy correction framework for
differential evolution. <em>NCA</em>, <em>35</em>(15), 11161–11182. (<a
href="https://doi.org/10.1007/s00521-023-08291-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is an efficient global optimization algorithm. However, due to its random properties, some individuals may mutate in the direction of deviating from the theoretical global optima, failing to evolve and wasting a lot of computing resources. Moreover, there is an imbalance between exploration and exploitation in mutation strategies. For these shortcomings, we propose an adaptive mutation strategy correction framework (AMSC) for DEs. In this framework, the population is firstly split into superior subpopulation and disadvantaged subpopulation. Two types of auxiliary mutant vectors based on the direction information are designed to respectively enhance the exploration ability and exploitation ability of these two subpopulations, so as to improve the search efficiency. Moreover, for achieving the proper balance between exploration and exploitation in DEs, we propose an adaptive cooperative rule for the above two auxiliary vectors based on the actual crossover rates. This rule controls the relative size of two subgroups to determine the proportion of two types of auxiliary vectors used in the whole population. To evaluate the performance of AMSC framework, we have introduced into eight original DEs and carried out comparative experiments on four practical problems and 59 test functions from CEC 2014 and CEC 2017 benchmark suites. The experiments demonstrate that the AMSC framework can increase DEs’ performance dramatically.},
  archive      = {J_NCA},
  author       = {Deng, Libao and Qin, Yifan and Li, Chunlei and Zhang, Lili},
  doi          = {10.1007/s00521-023-08291-9},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11161-11182},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive mutation strategy correction framework for differential evolution},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive multi-class imbalanced classification framework
based on ensemble methods and deep network. <em>NCA</em>,
<em>35</em>(15), 11141–11159. (<a
href="https://doi.org/10.1007/s00521-023-08290-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imbalance is one of the most difficult problems in machine learning. The improved ensemble learning model is a promising solution to mitigate this challenge. In this paper, an improved multi-class imbalanced data classification framework is proposed by combining the Focal Loss with Boosting model (FL-Boosting). By addressing the confusion of the second-order derivation of Focal Loss in the traditional ensemble learning model, the proposed model achieves a more efficient and accurate classification of the imbalanced data. More specifically, a Highly Adaptive Focal Loss (HAFL) is proposed to ensure that the model maintains lasting attention to the minority samples, which could be combined with boosting model to build HAFL-Boosting to achieve better performance. The framework has the scalability to adapt to different situations according to typical ensemble learning algorithms such as LightGBM, XGBoost and CatBoost. In addition, to implement the application of the proposed framework on deep models, a two-stage classification method combining ConvNeXt with the improved boosting model is proposed, which could improve the recognition ability to high-dimensional imbalanced data. We evaluate the HAFL-Boosting and the two-stage class imbalance classification method by ablation experiments and benchmark experiments, which demonstrated that the proposed methods obviously improved the scores on several evaluation indexes. The comparative experiments with the latest classification models show that the proposed methods could achieve leading performance from multiple perspectives.},
  archive      = {J_NCA},
  author       = {Jiang, Xuezheng and Wang, Junyi and Meng, Qinggang and Saada, Mohamad and Cai, Haibin},
  doi          = {10.1007/s00521-023-08290-w},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11141-11159},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive multi-class imbalanced classification framework based on ensemble methods and deep network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EOS-3D-DCNN: Ebola optimization search-based 3D-dense
convolutional neural network for corn leaf disease prediction.
<em>NCA</em>, <em>35</em>(15), 11125–11139. (<a
href="https://doi.org/10.1007/s00521-023-08289-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corn disease prediction is an essential part of agricultural productivity. This paper presents a novel 3D-dense convolutional neural network (3D-DCNN) optimized using the Ebola optimization search (EOS) algorithm to predict corn disease targeting the increased prediction accuracy than the conventional AI methods. Since the dataset samples are generally insufficient, the paper uses some preliminary pre-processing approaches to increase the sample set and improve the samples for corn disease. The Ebola optimization search (EOS) technique is used to reduce the classification errors of the 3D-CNN approach. As an outcome, the corn disease is predicted and classified accurately and more effectually. The accuracy of the proposed 3D-DCNN-EOS model is improved, and some necessary baseline tests are performed to project the efficacy of the anticipated model. The simulation is performed in the MATLAB 2020a environment, and the outcomes specify the significance of the proposed model over other approaches. The feature representation of the input data is learned effectually to trigger the model&#39;s performance. When the proposed method is compared to other existing techniques, it outperforms them in terms of precision, the area under receiver operating characteristics (AUC), f1 score, Kappa statistic error (KSE), accuracy, root mean square error value (RMSE), and recall.},
  archive      = {J_NCA},
  author       = {Ashwini, C. and Sellam, V.},
  doi          = {10.1007/s00521-023-08289-3},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11125-11139},
  shortjournal = {Neural Comput. Appl.},
  title        = {EOS-3D-DCNN: Ebola optimization search-based 3D-dense convolutional neural network for corn leaf disease prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weather forecasting based on hybrid decomposition methods
and adaptive deep learning strategy. <em>NCA</em>, <em>35</em>(15),
11109–11124. (<a
href="https://doi.org/10.1007/s00521-023-08288-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many global climate-affecting factors are combined to influence the weather and the most challenging ones are the wind speed and the air temperature. The objective of our study is to build a reliable model, capable of handling both data different behaviors for an efficient 12 hours-ahead prediction of each parameter separately. A hybrid strategy called OVMD-DWT-Attention-based-Adaptive-mLSTM was proposed for this purpose, based on a double decomposition method that combines the optimized variational mode decomposition (OVMD) algorithm with the discrete wavelet transform (DWT) technique, that proved its efficiency in extracting the appropriate features, and pre-processing both datasets, in order to reach the desired data denoised effect. The denoised high and low-frequency sub-sequences of each parameter resulted are then forecasted separately using the Adaptive-Multiplicative-LSTM (Adaptive-mLSTM) model to eliminate the inter-correlations between the sub-signals. Finally, each parameter predicted results are reconstructed and fitted independently to the Attention-based-Adaptive mLSTM proposed model for the final prediction. A benchmark of models was implemented for comparison purpose and evaluated over both wind speed and air temperature datasets characteristics, collected from three different stations, where the proposed strategy showed the best and the more consistent results.},
  archive      = {J_NCA},
  author       = {Zouaidia, Khouloud and Rais, Mohamed Saber and Ghanemi, Salim},
  doi          = {10.1007/s00521-023-08288-4},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11109-11124},
  shortjournal = {Neural Comput. Appl.},
  title        = {Weather forecasting based on hybrid decomposition methods and adaptive deep learning strategy},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimized deep learning approach to detect and classify
defective tiles in production line for efficient industrial quality
control. <em>NCA</em>, <em>35</em>(15), 11089–11108. (<a
href="https://doi.org/10.1007/s00521-023-08283-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a deep learning-based machine vision approach is proposed to automatically detect and classify defective tiles in the production assembly line of a tile manufacturing industry. The deep learning model used in this methodology is trained with 30,000 real-time images of cement/ceramic tiles, and the features of the image samples are extracted using the convolutional layers in the model. The defective tiles are identified and classified using an optimized activation function that acts as the decision-making layer or output layer of the deep learning model. The performance of this deep learning technique is evaluated using various metrics like accuracy, precision, recall and f1-score which is further compared with state-of-the-art activation functions like Relu, sigmoid, tanh and softmax. To further enhance the performance metrics, the feature extraction is done using various pre-trained models like VGG-16, Resnet50 and InceptionV3 and was further evaluated using metrics like K (Kappa statistic), OA (overall accuracy) and AA (average accuracy). The obtained experimental results with an accuracy of 99.96\% under a favorable learning rate prove the robustness and efficiency of the proposed methodology to enhance industrial quality control in any tile manufacturing industry.},
  archive      = {J_NCA},
  author       = {Kovilpillai, J. Judeson Antony and Jayanthy, S.},
  doi          = {10.1007/s00521-023-08283-9},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11089-11108},
  shortjournal = {Neural Comput. Appl.},
  title        = {An optimized deep learning approach to detect and classify defective tiles in production line for efficient industrial quality control},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KO: Modularity optimization in community detection.
<em>NCA</em>, <em>35</em>(15), 11073–11087. (<a
href="https://doi.org/10.1007/s00521-023-08284-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many algorithms have been developed to detect communities in networks. The success of these developed algorithms varies according to the types of networks. A community detection algorithm cannot always guarantee the best results on all networks. The most important reason for this is the approach algorithms follow when dividing any network into communities (sub-networks). The modularity of the network determines the quality of communities in networks. It is concluded that networks with high modularity values are divided into more successful communities (clusters, sub-networks). This study proposes a modularity optimization algorithm to increase clustering success in any network without being dependent on any community detection algorithm. The basic approach of the proposed algorithm is to transfer nodes at the community boundary to neighboring communities if they meet the specified conditions. The method called KO (Karcı–Oztemiz) optimization algorithm maximizes the modularity value of any community detection algorithm in the best case, while it does not change the modularity value in the worst case. For the KO algorithm’s test, in this study, Walktrap, Cluster Edge Betweenness, Label Propagation, Fast Greedy, and Leading Eigenvector community detection algorithms have been applied on three popular networks that were unweighted and undirected previously used in the literature. The community structures created by five community detection algorithms were optimized via the KO algorithm and the success of the proposed method was analyzed. When the results are examined, the modularity values of the community detection algorithms applied on the three different networks have increased at varying rates (0\%, …,14.73\%).},
  archive      = {J_NCA},
  author       = {Öztemiz, Furkan and Karcı, Ali},
  doi          = {10.1007/s00521-023-08284-8},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11073-11087},
  shortjournal = {Neural Comput. Appl.},
  title        = {KO: Modularity optimization in community detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting event-aware and role-aware with tree pruning for
document-level event extraction. <em>NCA</em>, <em>35</em>(15),
11061–11072. (<a
href="https://doi.org/10.1007/s00521-023-08282-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level event extraction aims to extract event information from a passage, which is more challenging than sentence-level event extraction. Despite some success, the existing document-level event extraction methods still face the following two shortcomings: (a) Insufficient Dependencies: the dependencies between event type and role type are not fully exploited in a document. (b) Redundancy: The redundant role features in document-level event extraction hinder the performance improvement. In this paper, we propose dual-channel Conditional Interaction with Tree Pruning (CITP) to solve the above two challenges simultaneously. For the insufficient dependencies issue, CITP constructs a dual-channel condition interaction module to simultaneously extract both event types and role types in a document, which improves the feature interaction between event types and role types. Also, it can effectively enhance candidate argument features and sentence features with event-aware and role-aware. For the redundancy issue, CITP expands the ordered tree and adopts the classified role types as guidance to prune unnecessary branches, which reduces the impact of redundant role features and improves event extraction performance. Experimental results on the widely used ChFinAnn dataset have proved that our model achieves state-of-the-art compared to other models, with higher effectiveness.},
  archive      = {J_NCA},
  author       = {Lv, Jianwei and Zhang, Zequn and Xu, Guangluan and Sun, Xian and Li, Shuchao and Liu, Qing and Dong, Pengcheng},
  doi          = {10.1007/s00521-023-08282-w},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11061-11072},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploiting event-aware and role-aware with tree pruning for document-level event extraction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel multi-class brain tumor classification method based
on unsupervised PCANet features. <em>NCA</em>, <em>35</em>(15),
11043–11059. (<a
href="https://doi.org/10.1007/s00521-023-08281-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors are one of the most severe tumors in the human body because of their nonlinear morphological and textural characteristics. The appropriate clinical practices selected by the surgeons for the patients can be improved by using automated brain tumor diagnosis systems based on magnetic resonance images (MRIs). Therefore, improving the efficiency of these systems plays an essential role in saving the lives of patients. In this paper, a novel multi-class brain tumor classification method is proposed. The proposed method comprises two modules: a simple unsupervised convolutional PCANet module is utilized for feature extraction and a supervised CNN module for feature classification. We modified the PCANet model by applying a nonlinear activation function on the convolutional feature maps. In addition, the learned convolutional PCA filters are computed across the 3D feature maps contrary to the traditional PCANet model, which apply PCA filters on the 2D maps. These modifications enhance the features’ expressive power compared with the traditional PCANet and the deep CNN models. The unsupervised features extracted from the modified PCANet module are followed by a simple CNN classification module. The unsupervised PCANet does not require a large number of training data compared with its competitive supervised CNN. We apply grid-search optimization to obtain the optimal hyper-parameters for the classification module. Four public benchmark datasets containing 9581 MRI brain images are utilized to evaluate the performance of the proposed method. The datasets contain different classification tasks, number of samples, image sizes, contrast, and planes. Our proposed method achieved the highest performance compared with other state-of-the-art methods. The proposed method encourages medical imaging diagnosis and can solve the size limitation problem in medical datasets.},
  archive      = {J_NCA},
  author       = {Shahin, Ahmed I. and Aly, Saleh and Aly, Walaa},
  doi          = {10.1007/s00521-023-08281-x},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11043-11059},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel multi-class brain tumor classification method based on unsupervised PCANet features},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neuromorphic processor-oriented hybrid q-format
multiplication with adaptive quantization for tiny YOLO3. <em>NCA</em>,
<em>35</em>(15), 11013–11041. (<a
href="https://doi.org/10.1007/s00521-023-08280-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have delivered unprecedented achievements in the modern Internet of Everything society, encompassing autonomous driving, expert diagnosis, unmanned supermarkets, etc. It continues to be challenging for researchers and engineers to develop a high-performance neuromorphic processor for deployment in edge devices or embedded hardware. DNNs’ superpower derives from their enormous and complex network architecture, which is computation-intensive, time-consuming, and energy-heavy. Due to the limited perceptual capacity of humans, accurate processing results from DNNs require a substantial amount of computing time, making them redundant in some applications. Utilizing adaptive quantization technology to compress the DNN model with sufficient accuracy is crucial for facilitating the deployment of neuromorphic processors in emerging edge applications. This study proposes a method to boost the development of neuromorphic processors by conducting fixed-point multiplication in a hybrid Q-format using an adaptive quantization technique on the convolution of tiny YOLO3. In particular, this work integrates the sign-bit check and bit roundoff techniques into the arithmetic of fixed-point multiplications to address overflow and roundoff issues within the convolution’s adding and multiplying operations. In addition, a hybrid Q-format multiplication module is developed to assess the proposed method from a hardware perspective. The experimental results prove that the hybrid multiplication with adaptive quantization on the tiny YOLO3’s weights and feature maps possesses a lower error rate than alternative fixed-point representation formats while sustaining the same object detection accuracy. Moreover, the fixed-point numbers represented by Q(6.9) have a suboptimal error rate, which can be utilized as an alternative representation form for the tiny YOLO3 algorithm-based neuromorphic processor design. In addition, the 8-bit hybrid Q-format multiplication module exhibits low power consumption and low latency in contrast to benchmark multipliers.},
  archive      = {J_NCA},
  author       = {Li, Tao and Ma, Yitao and Endoh, Tetsuo},
  doi          = {10.1007/s00521-023-08280-y},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {11013-11041},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neuromorphic processor-oriented hybrid Q-format multiplication with adaptive quantization for tiny YOLO3},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tensor-based multi-feature affinity graph learning for
natural image segmentation. <em>NCA</em>, <em>35</em>(15), 10997–11012.
(<a href="https://doi.org/10.1007/s00521-023-08279-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the previous image segmentation methods based on affinity graph learning, it is difficult to obtain clear contour boundaries in the process of image preprocessing, over-segmentation leads to the separation of local regions and most traditional affinity graph learning methods cluster and segment with a single feature of natural images, ignoring the associative characteristics of multiple types of features and cannot effectively utilize the useful information of multiple features of natural images. Aiming at such problems, this paper proposes a tensor-based multi-feature affinity graph learning method for natural image segmentation (TRMFAL). First, the adaptive morphological rebuilding watershed transform is applied to original natural image, the obtained superpixel image contains a lot of boundary contour information, and the fusion of local regions is relatively good; secondly, extract multi-class features from the superpixel blocks in the superpixel image, effectively utilize the features of different characteristics, and integrate them into a multi-feature data matrix according to the corresponding rules; Then, a tensor-based multi-feature affinity graph learning algorithm is proposed, in which tensor is introduced in the algorithm to effectively obtain the higher-order information of image data, and use the projection matrix to embed the original data in the low-dimensional space to decrease the dimension, while minimizing the residual error of each view feature and assign appropriate weights according to the importance of the feature information; finally, use spectral clustering performs clustering and segmentation on affinity graphs to obtain final clustering results and segmented images. In addition, an optimization iterative algorithm based on the alternating multiplier direction method is designed, which effectively solves the problem of solving the TRMFAL model. Sufficient experimental comparisons are carried out on multiple public datasets, and the results prove that the proposed method achieves the optimal clustering performance and segmentation effect.},
  archive      = {J_NCA},
  author       = {Wang, Xiao and Zhang, Xiaoqian and Li, Jinghao and Zhao, Shuai and Sun, Huaijiang},
  doi          = {10.1007/s00521-023-08279-5},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10997-11012},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tensor-based multi-feature affinity graph learning for natural image segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bearing capacity of ring footings in anisotropic clays: FELA
and ANN. <em>NCA</em>, <em>35</em>(15), 10975–10996. (<a
href="https://doi.org/10.1007/s00521-023-08278-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel investigation of the bearing capacity of ring footings embedded in undrained anisotropic clays using a new hybrid soft computation technique that cooperates between finite element limit analysis (FELA) and artificial neural networks (ANNs) is presented in this paper. The undrained shear strength of clays is considered to be anisotropic and linearly increased with depth. The anisotropic undrained shear strength (AUS) model is employed to demonstrate the anisotropic behaviour of the undrained clays. The FLEA solutions of this problem based on lower bound (LB) and upper bound (UB) solutions are presented. The variations of bearing capacity factor (N) and the failure patterns of ring footings are examined by considering the changes in the geometric ratio of the internal radius and external radius (ri/ro), the embedment ratio (D/ro), the rates of increase of undrained shear with depth (ρro/suTC0), and the ratio of anisotropic (re). The results of the paper are presented in the simple dimensionless design charts and tables that show the relationships between N and all investigated parameters which will be beneficial to practitioners. Furthermore, the application of artificial neural networks (ANNs) is adopted to do sensitivity analysis and build an empirical equation for the complex relationship between the input variables and output bearing capacity factor. As the results, the radius ratio ri/ro is the most important variable on bearing capacity factor and the lower importance parameters are D/ro, ρro/suTC0, and re with relative importance 37.01, 30.37; 21.59; 11.03\%, respectively. The proposed empirical equation is also proved to be an efficient method as evidenced by the high agreement between its predicted values and those from FELA with R2 of 99.95\%.},
  archive      = {J_NCA},
  author       = {Nguyen, Dang Khoa and Nguyen, Trong Phuoc and Ngamkhanong, Chayut and Keawsawasvong, Suraparb and Lai, Van Qui},
  doi          = {10.1007/s00521-023-08278-6},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10975-10996},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bearing capacity of ring footings in anisotropic clays: FELA and ANN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CrackViT: A unified CNN-transformer model for pixel-level
crack extraction. <em>NCA</em>, <em>35</em>(15), 10957–10973. (<a
href="https://doi.org/10.1007/s00521-023-08277-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pixel-level crack extraction (PCE) is challenging due to topology complexity, irregular edges, low contrast ratio, and complex background. Recently, Transformer architectures have shown great potential on many vision tasks and even outperform convolutional neural networks (CNNs). Benefiting from the self-attention mechanism, Transformers can invariably capture the global context information to establish long-range dependencies on the detected objects. However, there was little work on the Transformer architectures for PCE. In this paper, a systematic analysis of three well-designed Transformer architectures for PCE task in terms of network structures and parameters, feature fusion modes, training data and strategy, and generalization ability was developed for the first time. We proposed a Crack extraction network with Vision Transformer (CrackViT) that jointly captures the detailed structures and long-distance dependencies with a novel hybrid encoder with CNN and Transformer to keep the corresponding topologies. In order to be more suitable for PCE task, we explored three feature fusion modes between CNN and Transformer. In addition, a novel feature aggregation block was proposed to sharpen the edges of the decoder upsampling and reduce the noise effect of shallow features. Moreover, a multi-task supervised training strategy was adopted to further improve the details of crack edges. Results on four challenging datasets, including CrackForest, DeepCrack, CRKWH100, and CRACK500, show that CrackViT outperforms state-of-the-art CNN-based methods and the other two novel Transformer architectures. Our codes are available at: https://github.com/SmilQe/CrackViT .},
  archive      = {J_NCA},
  author       = {Quan, Jianing and Ge, Baozhen and Wang, Min},
  doi          = {10.1007/s00521-023-08277-7},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10957-10973},
  shortjournal = {Neural Comput. Appl.},
  title        = {CrackViT: A unified CNN-transformer model for pixel-level crack extraction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformer transfer learning emotion detection model:
Synchronizing socially agreed and self-reported emotions in big data.
<em>NCA</em>, <em>35</em>(15), 10945–10956. (<a
href="https://doi.org/10.1007/s00521-023-08276-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tactics to determine the emotions of authors of texts such as Twitter messages often rely on multiple annotators who label relatively small data sets of text passages. An alternative method gathers large text databases that contain the authors’ self-reported emotions, to which artificial intelligence, machine learning, and natural language processing tools can be applied. Both approaches have strength and weaknesses. Emotions evaluated by a few human annotators are susceptible to idiosyncratic biases that reflect the characteristics of the annotators. But models based on large, self-reported emotion data sets may overlook subtle, social emotions that human annotators can recognize. In seeking to establish a means to train emotion detection models so that they can achieve good performance in different contexts, the current study proposes a novel transformer transfer learning approach that parallels human development stages: (1) detect emotions reported by the texts’ authors and (2) synchronize the model with social emotions identified in annotator-rated emotion data sets. The analysis, based on a large, novel, self-reported emotion data set (n = 3,654,544) and applied to 10 previously published data sets, shows that the transfer learning emotion model achieves relatively strong performance.},
  archive      = {J_NCA},
  author       = {Lee, Sanghyub John and Lim, JongYoon and Paas, Leo and Ahn, Ho Seok},
  doi          = {10.1007/s00521-023-08276-8},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10945-10956},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transformer transfer learning emotion detection model: Synchronizing socially agreed and self-reported emotions in big data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A memristor-based associative memory neural network circuit
with emotion effect. <em>NCA</em>, <em>35</em>(15), 10929–10944. (<a
href="https://doi.org/10.1007/s00521-023-08275-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, people tend to learn or recall pleasant experiences during positive feelings. Similarly, people tend to learn or recall unpleasant things during negative feelings. The research in psychological field has demonstrated that human memory is closely related to emotion. On one hand, emotion helps store the memory that possesses the same emotion valence, which is known as the mood congruency memory (MCM). On the other hand, memory stored in a certain emotional state will be associated easily when the same emotion occurs, which is called mood-dependent memory (MDM). Inspired by the mechanisms of MCM and MDM, a memristor-based circuit of emotion-affected associative memory neural network is proposed in this work. The designed circuit mainly contains MCM module and MDM module. The functions, such as learning, forgetting, variable learning rate, MCM effect, MDM effect, and time interval, are implemented by the circuit. The simulation results in PSPICE show that the proposed memristive circuit can learn and associate the memory based on emotional effects like humans.},
  archive      = {J_NCA},
  author       = {Wang, Chunhua and Xu, Cong and Sun, Jingru and Deng, Quanli},
  doi          = {10.1007/s00521-023-08275-9},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10929-10944},
  shortjournal = {Neural Comput. Appl.},
  title        = {A memristor-based associative memory neural network circuit with emotion effect},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep adaptive hiding network for image hiding using
attentive frequency extraction and gradual depth extraction.
<em>NCA</em>, <em>35</em>(15), 10909–10927. (<a
href="https://doi.org/10.1007/s00521-023-08274-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hiding secures information security in multimedia communication. Existing deep image hiding methods usually process the secret and cover information at first, and then fuse such entire processed information. This complete and rough fusion pipeline, however, severely hinders the quality improvement of the stego and revealed secret images. This paper proposes a deep image hiding architecture, named Deep Adaptive Hiding Network (DAH-Net), to gradually extract and fuse the necessary secret and cover information at the frequency and the depth (layer) extents. Specifically, we propose the Attentive Frequency Extraction method for the DAH-Net to adaptively extract the necessary secret and cover information at the frequency level. The Gradual Depth Extraction method is further proposed for the DAH-Net to gradually extract and fuse the attentive frequency secret and cover information at the depth (layer) level of the deep image hiding network. Extensive experiment results demonstrate the proposed DAH-Net is more universal and achieves state-of-the-art performances in image hiding, watermarking, and photographic steganography.},
  archive      = {J_NCA},
  author       = {Zhang, Le and Lu, Yao and Li, Jinxing and Chen, Fanglin and Lu, Guangming and Zhang, David},
  doi          = {10.1007/s00521-023-08274-w},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10909-10927},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep adaptive hiding network for image hiding using attentive frequency extraction and gradual depth extraction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hash centroid construction method with swin transformer
for multi-label image retrieval. <em>NCA</em>, <em>35</em>(15),
10891–10907. (<a
href="https://doi.org/10.1007/s00521-023-08273-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantization-based hashing methods have become increasingly popular to adjust the global data distribution and accurately capture the data similarity compared with pairwise/triplet similarity-based methods. However, the existing image quantization hashing approaches adopt fixed hash centers, which consider neither the semantic information of each hash center nor the scale size of each object appearing in a multi-label image, resulting in that each hash code will deviate from its corresponding hash centroid. To address this issue, we propose HCCST, a hash centroid construction method with Swin transformer for multi-label image retrieval. HCCST consists of a hash code generation module, a hash centroid construction module and an interaction module between each hash code and its corresponding hash centroid. In the hash code generation module, we first adopt Swin transformer to extract the feature vector for each input multi-label image and then generate the initialized hash code of this image. In the hash centroid construction module, we first utilize the object semantic information to construct semantic hash centers and then consider the object scale size by learning the object weight coefficient to compute the hash centroid for each sample. After obtaining both the hash code and hash centroid of each sample, in the last interaction module, we constantly limit the distance between each hash code and its hash centroid to preserve the similarity between samples. Our model will be trained in an end-to-end manner to alternately update the net parameters of hash code generation module, hash centroid construction module and the object weight coefficient. We conduct extensive experiments on 3 multi-label image datasets including VOC2012, MS-COCO and NUS-WIDE. The experimental results demonstrate that HCCST can achieve better retrieval performance compared with the state-of-the-art image hashing methods. The open-source code of this project is released at: https://github.com/lzHZWZ/HCCST.git .},
  archive      = {J_NCA},
  author       = {Xie, Yanzhao and Wang, Yangtao and Wei, Rukai and Liu, Yu and Zhou, Ke and Fan, Lisheng},
  doi          = {10.1007/s00521-023-08273-x},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10891-10907},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hash centroid construction method with swin transformer for multi-label image retrieval},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Flexible few-shot class-incremental learning with prototype
container. <em>NCA</em>, <em>35</em>(15), 10875–10889. (<a
href="https://doi.org/10.1007/s00521-023-08272-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the few-shot class-incremental learning, new class samples are utilized to learn the characteristics of new classes, while old class exemplars are used to avoid old knowledge forgetting. The limited number of new class samples is more likely to cause overfitting during incremental training. Moreover, mass stored old exemplars mean large storage space consumption. To solve the above difficulties, in this paper we propose a novel flexible few-shot class-incremental framework to make the incremental process efficient and convenient. We enhance the expression ability of extracted features through multistage pre-training. Then, we set up a prototype container to store each class prototype to retain old knowledge. When new classes flow in, we calculate the new class prototypes and update the prototype container. Finally, we get the prediction result through similarity weighting. The entire framework only need to train the base class classifier and does not require further training during the incremental process. It avoids the overfitting of novel classes and saves time for further training. Besides, storing prototypes can save more storage space than original image data. Overall, the entire framework has the advantage of flexibility. We conduct extensive experiments on three standard few-shot class-incremental datasets and achieve state-of-the-art results. Especially, to verify the flexibility of the framework, we discuss the special federated few-shot class-incremental scenarios in addition. No further training and less storage consumption provide the possibility for applications in more complex scenarios.},
  archive      = {J_NCA},
  author       = {Xu, Xinlei and Wang, Zhe and Fu, Zhiling and Guo, Wei and Chi, Ziqiu and Li, Dongdong},
  doi          = {10.1007/s00521-023-08272-y},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10875-10889},
  shortjournal = {Neural Comput. Appl.},
  title        = {Flexible few-shot class-incremental learning with prototype container},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-grained deepfake detection based on cross-modality
attention. <em>NCA</em>, <em>35</em>(15), 10861–10874. (<a
href="https://doi.org/10.1007/s00521-023-08271-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a fine-grained deepfake detection network based on cross-modality attention. Specifically, it consists of three essential parts. The first is the feature extraction module, including learnable high-pass filters and Gabor convolutions. The former can adaptively extract different high-frequency components from original RGB images, while the latter can adaptively extract texture information at multiple directions and scales. The second is the shallow texture module, which is aimed to enhance texture and high-frequency features. The last is the cross-modality attention module that leverages the complementary information between the three modalities to promote feature learning and fusion. It can propagate the forgery patterns extracted from a specific modality to other modalities to learn previously undetected forgery traces. Moreover, we further introduce a novel diversity loss to penalize texture and frequency feature vectors for overlapping with each other. Our proposed method achieves the most advanced performance on multiple benchmark databases.},
  archive      = {J_NCA},
  author       = {Zhao, Lei and Zhang, Mingcheng and Ding, Hongwei and Cui, Xiaohui},
  doi          = {10.1007/s00521-023-08271-z},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10861-10874},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fine-grained deepfake detection based on cross-modality attention},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning cross-domain representations by vision transformer
for unsupervised domain adaptation. <em>NCA</em>, <em>35</em>(15),
10847–10860. (<a
href="https://doi.org/10.1007/s00521-023-08269-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) is a popular machine learning technique to reduce the distribution discrepancy among domains. Generally, most UDA methods utilize a deep Convolutional Neural Networks (CNNs) and a domain discriminator to learn a domain-invariant representation, but it does not equal to a discriminative domain-specific representation. Transformers (TRANS), which has been proved to be more robust to domain shift than CNNs, has gradually become a powerful alternative to CNNs in feature representation. On the other hand, the domain shift between the labeled source data and the unlabeled target data produces a significant amount of label noise, which needs a more robust connection between the source and target domain. This report proposes a simple yet effective UDA method for learning cross-domain representations by vision Transformers in a self-training manner. Unlike the conventional form of dividing an image into multiple non-overlapping patches, we proposed a novel method that aggregates both source domain labeled patches and target domain pseudo-labeled target patches. In addition, a cross-domain alignment loss is proposed to match the centroid of labeled source patches and pseudo-labeled target patches. Extensive experiments show that our proposed method achieves state-of-the-art (SOTA) results on several standard UDA benchmarks (90.5 $$\%$$ on ImageCLEF-DA, Office-31) by a transformers baseline model without any extra assistant networks.},
  archive      = {J_NCA},
  author       = {Ye, Yifan and Fu, Shuai and Chen, Jing},
  doi          = {10.1007/s00521-023-08269-7},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10847-10860},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning cross-domain representations by vision transformer for unsupervised domain adaptation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimal neural network design for fractional deep
learning of logistic growth. <em>NCA</em>, <em>35</em>(15), 10837–10846.
(<a href="https://doi.org/10.1007/s00521-023-08268-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper suggests a multi-layer neural network for deep learning based on fractional differential equations, and parallel computing is used to search an optimal structure. First, the Caputo derivative is approximated by $$L_1$$ numerical scheme and an unconstrained discretization minimization problem is presented. Then, parameters are adjusted by use of the Adam algorithm. Analytical approximate solutions of two fractional logistic equations (FLEs) are obtained which demonstrate the method’s efficiency. Furthermore, with real-life data, fractional order and other parameters of FLEs are estimated by the gradient descent algorithm meanwhile. The proposed optimal NN method is used in forecasting. Through the comparative study, FLEs have more parameter freedom degrees and perform better than the classical logistic model.},
  archive      = {J_NCA},
  author       = {Wei, Jia-Li and Wu, Guo-Cheng and Liu, Bao-Qing and Nieto, Juan J.},
  doi          = {10.1007/s00521-023-08268-8},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10837-10846},
  shortjournal = {Neural Comput. Appl.},
  title        = {An optimal neural network design for fractional deep learning of logistic growth},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient method to fool and enhance object tracking with
adversarial perturbations. <em>NCA</em>, <em>35</em>(15), 10821–10836.
(<a href="https://doi.org/10.1007/s00521-023-08266-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although current Siamese-based trackers have achieved impressive performance in visual object tracking by balancing accuracy and speed, their sensitivity to adversarial perturbation makes them face many risks in practical applications ( e.g., automatic drive). In this paper, we first propose a general attack method against Siamese-based trackers, and then carefully design an online augmentation strategy based on adversarial examples to improve the tracking accuracy. To ensure both attack and augmentation trackers simultaneously, two opposing losses are proposed to push and pull the gap between the template patch and search regions. Specifically, most Siamese-based trackers employ the cross-correlation module to associate features of two branches. The similarity between the template patch and the search region will be reflected on the cross-correlation map, which is the focus of our method. SiamCAR is the main research object of this paper; the tracking accuracy after deception and enhancement is reduced by 64.62\% and improved by 0.88\%, respectively. We also transfer our attack method to SiamRPN++, SiamBAN, SiamGAT, and TrDiMP. Extensive experiments on the popular benchmark datasets indicate the effectiveness and universality of our method.},
  archive      = {J_NCA},
  author       = {Pang, Haibo and Ma, Rongqi and Liu, Chengming and Su, Jie and Han, Linxuan},
  doi          = {10.1007/s00521-023-08266-w},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10821-10836},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient method to fool and enhance object tracking with adversarial perturbations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification of untrained class data using neuron
clusters. <em>NCA</em>, <em>35</em>(15), 10801–10819. (<a
href="https://doi.org/10.1007/s00521-023-08265-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs), a representative type of deep neural networks, are used in various fields. There are problems that should be solved to operate CNN in the real-world. In real-world operating environments, the CNN’s performance may be degraded due to data of untrained types, which limits its operability. In this study, we propose a method for identifying data of a type that the model has not trained on based on the neuron cluster, a set of neurons activated based on the type of input data. In experiments performed on the ResNet model with the MNIST, CIFAR-10, and STL-10 datasets, the proposed method identifies data of untrained and trained types with an accuracy of 85\% or higher. The more data used for neuron cluster identification, the higher the accuracy; conversely, the more complex the dataset&#39;s characteristics, the lower the accuracy. The proposed method uses only the information of activated neurons without any addition or modification of the model’s structure; hence, the computational cost is low without affecting the classification performance of the model.},
  archive      = {J_NCA},
  author       = {Lee, Young-Woo and Chae, Heung-Seok},
  doi          = {10.1007/s00521-023-08265-x},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10801-10819},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification of untrained class data using neuron clusters},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A semi-supervised neighborhood matching model for global
entity alignment. <em>NCA</em>, <em>35</em>(15), 10779–10799. (<a
href="https://doi.org/10.1007/s00521-023-08264-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important way to integrate knowledge graphs, entity alignment is widely used in the field of natural language processing. Entity alignment is to find entities that exist in different knowledge graphs but have the same real-world meaning. Recently, most entity alignment models consider only the one-hop neighborhood node information of candidate entity alignment pairs, without considering the relations connected to neighboring nodes. Relations are critical to determining whether two entities can be aligned when they have the same neighborhood structure. Therefore, besides using the structural information of entities, we also use relation semantics to enhance entity alignment. The larger the number of training seed set, the better the model performance. Based on the premise, we use the semi-supervised bidirectional nearest neighbor iteration strategy to expand the size of the training seed set without manual labeling. Furthermore, to ensure the stability of the entity alignment results, we consider the dependencies between alignment decisions and perform global entity alignment from a comprehensive perspective. We evaluate the performance of our model on three publicly available cross-lingual datasets, and the experimental results demonstrate the effectiveness of our model.},
  archive      = {J_NCA},
  author       = {Zhu, Beibei and Bao, Tie and Wang, Kerun and Liu, Lu and Han, Jiayu and Peng, Tao},
  doi          = {10.1007/s00521-023-08264-y},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10779-10799},
  shortjournal = {Neural Comput. Appl.},
  title        = {A semi-supervised neighborhood matching model for global entity alignment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging enhanced task embeddings for generalization in
multimodal meta-learning. <em>NCA</em>, <em>35</em>(15), 10765–10778.
(<a href="https://doi.org/10.1007/s00521-023-08263-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal meta-learning, previous works modulate the meta-learned network to adapt to tasks, based on task embeddings extracted by an task encoder. However, it is ignored that similarity exists in the tasks from the same mode, and the similarity cannot be utilized when generating the initialization and loss for the task-learner in previous methods. In this paper, we propose a new method to leverage the task similarity in multimodal meta-learning, which provides a better-suited initialization and loss for the task-learner with consideration of the task characteristics. In our proposed Task Embedding Adaptation (TEA), a Transformer is introduced to refine the task embeddings by encouraging information aggregation among similar tasks. The enhanced task embeddings can be utilized to infer the task mode more accurately and modulate the meta-learner to generate a better task-specific initialization. Furthermore, Modulated Adaptive Loss module is proposed to generate task-specific loss adaptively based on the loss network and enhanced task embeddings obtained by TEA. In addition, we present an efficient Mixed-Loop Learning strategy to ensure the training efficiency of the task encoder and loss network instead of the traditional two-loop learning strategy. Extensive experiments on multimodal few-shot classification demonstrate that our method achieves state-of-the-art performance, and our method also performs well in regression and reinforcement learning.},
  archive      = {J_NCA},
  author       = {Rao, Shuzhen and Huang, Jun},
  doi          = {10.1007/s00521-023-08263-z},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10765-10778},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging enhanced task embeddings for generalization in multimodal meta-learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot learning in realistic settings for text CAPTCHA
recognition. <em>NCA</em>, <em>35</em>(15), 10751–10764. (<a
href="https://doi.org/10.1007/s00521-023-08262-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based captcha is commonly used by many commercial websites. Most existing captcha recognition methods rely on deep learning and large-scale labeled data. Recently, few-shot learning has shown its effectiveness in various visual classification tasks in the case of insufficient data. However, the performance of current few-shot learning methods will deteriorate in realistic settings with class-imbalance and cross-domain. In this paper, we have proposed a novel captcha solver based on prototypical networks and model-agnostic meta-learning. Two major improvements, including multi-source domain data augmentation and intra-class variance distance weighting method, are proposed to alleviate the performance degradation problems caused by cross-domain and class imbalance. Our approaches achieve an average character accuracy of more than 90\% in 5-shot and 10-shot tasks and an astonishing attack rate of 88\% in one-shot tasks. The efficacy of this work may promote the application of few-shot learning in realistic settings.},
  archive      = {J_NCA},
  author       = {Wang, Yao and Wei, Yuliang and Zhang, Yifan and Jin, Chuhao and Xin, Guodong and Wang, Bailing},
  doi          = {10.1007/s00521-023-08262-0},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10751-10764},
  shortjournal = {Neural Comput. Appl.},
  title        = {Few-shot learning in realistic settings for text CAPTCHA recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chernobyl disaster optimizer (CDO): A novel meta-heuristic
method for global optimization. <em>NCA</em>, <em>35</em>(15),
10733–10749. (<a
href="https://doi.org/10.1007/s00521-023-08261-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel meta-heuristic optimization method, namely “Chernobyl Disaster Optimizer (CDO)”. The underlying concepts and principles behind the proposed approach is inspired by the nuclear reactor core explosion of Chernobyl. In CDO, radioactivity happened because of nuclear instability, which different types of radiations are emitted from nuclei. The most common kinds of these radiations are called gamma, beta, and alpha particles. These particles fly away from the explosion point (high pressure point) to the low pressure point (the human standing point), which are harmful to the humans. The CDO mimics the process of nuclear radiation while attaching human after the nuclear explosion. The main steps of nuclear explosion and attaching human are implemented in which gamma, beta, and alpha particles are involved in this process. The CDO is evaluated with optimizing “Congress on Evolutionary Computation (CEC 2017)” test bed suites. In addition, it is compared against well-known optimization methods, such as “Sperm Swarm Optimization” and “Gravitational Search Algorithm”. The experimental results prove its efficiency, which can be considered as viable alternative.},
  archive      = {J_NCA},
  author       = {Shehadeh, Hisham A.},
  doi          = {10.1007/s00521-023-08261-1},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10733-10749},
  shortjournal = {Neural Comput. Appl.},
  title        = {Chernobyl disaster optimizer (CDO): A novel meta-heuristic method for global optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Learning from pseudo-lesion: A self-supervised framework
for COVID-19 diagnosis. <em>NCA</em>, <em>35</em>(15), 10717–10731. (<a
href="https://doi.org/10.1007/s00521-023-08259-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Coronavirus disease 2019 (COVID-19) has rapidly spread all over the world since its first report in December 2019, and thoracic computed tomography (CT) has become one of the main tools for its diagnosis. In recent years, deep learning-based approaches have shown impressive performance in myriad image recognition tasks. However, they usually require a large number of annotated data for training. Inspired by ground glass opacity, a common finding in COIVD-19 patient’s CT scans, we proposed in this paper a novel self-supervised pretraining method based on pseudo-lesion generation and restoration for COVID-19 diagnosis. We used Perlin noise, a gradient noise based mathematical model, to generate lesion-like patterns, which were then randomly pasted to the lung regions of normal CT images to generate pseudo-COVID-19 images. The pairs of normal and pseudo-COVID-19 images were then used to train an encoder–decoder architecture-based U-Net for image restoration, which does not require any labeled data. The pretrained encoder was then fine-tuned using labeled data for COVID-19 diagnosis task. Two public COVID-19 diagnosis datasets made up of CT images were employed for evaluation. Comprehensive experimental results demonstrated that the proposed self-supervised learning approach could extract better feature representation for COVID-19 diagnosis, and the accuracy of the proposed method outperformed the supervised model pretrained on large-scale images by 6.57\% and 3.03\% on SARS-CoV-2 dataset and Jinan COVID-19 dataset, respectively.},
  archive      = {J_NCA},
  author       = {Li, Zhongliang and Li, Xuechen and Jin, Zhihao and Shen, Linlin},
  doi          = {10.1007/s00521-023-08259-9},
  journal      = {Neural Computing and Applications},
  number       = {15},
  pages        = {10717-10731},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning from pseudo-lesion: A self-supervised framework for COVID-19 diagnosis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient edge/cloud medical system for rapid detection
of level of consciousness in emergency medicine based on explainable
machine learning models. <em>NCA</em>, <em>35</em>(14), 10695–10716. (<a
href="https://doi.org/10.1007/s00521-023-08258-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency medicine (EM) is one of the attractive research fields in which researchers investigate their efforts to diagnose and treat unforeseen illnesses or injuries. There are many tests and observations are involved in EM. Detection of the level of consciousness is one of these observations, which can be detected using several methods. Among these methods, the automatic estimation of the Glasgow coma scale (GCS) is studied in this paper. The GCS is a medical score used to describe a patient’s level of consciousness. This type of scoring system requires medical examination that may not be available with the shortage of the medical expert. Therefore, the automatic medical calculation for a patient’s level of consciousness is highly needed. Artificial intelligence has been deployed in several applications and appears to have a high performance regarding providing automatic solutions. The main objective of this work is to introduce the edge/cloud system to improve the efficiency of the consciousness measurement through efficient local data processing. Moreover, an efficient machine learning (ML) model to predict the level of consciousness of a certain patient based on the patient’s demographic, vital signs, and laboratory tests is proposed, as well as maintaining the explainability issue using Shapley additive explanations (SHAP) that provides natural language explanation in a form that helps the medical expert to understand the final prediction. The developed ML model is validated using vital signs and laboratory tests extracted from the MIMIC III dataset, and it achieves superior performance (mean absolute error (MAE) = 0.269, mean square error (MSE) = 0.625, R2 score = 0.964). The resulting model is accurate, medically intuitive, and trustworthy.},
  archive      = {J_NCA},
  author       = {El-Rashidy, Nora and Sedik, Ahmed and Siam, Ali I. and Ali, Zainab H.},
  doi          = {10.1007/s00521-023-08258-w},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10695-10716},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient edge/cloud medical system for rapid detection of level of consciousness in emergency medicine based on explainable machine learning models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Employing evolutionary artificial neural network in
risk-adjusted monitoring of surgical performance. <em>NCA</em>,
<em>35</em>(14), 10677–10693. (<a
href="https://doi.org/10.1007/s00521-023-08257-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various applications of control charts in the field of health-care monitoring and surveillance can be found in the literature. As one of the major categories, monitoring binary outcomes of cardiac surgeries with the aim of logistic regression model for the patients’ death probability has been extended by different researchers. For this aim, statistical control charts, such as cumulative sum (CUSUM) chart, are applied as a risk-adjusted method to monitoring patients’ mortality rate. However, employing machine learning techniques such as artificial neural network (ANN) has not been paid attention. So, this paper proposes a novel ANN-based control chart with a heuristic training approach to monitor binary surgical outcomes by control charts. Performance of the proposed approach is investigated and compared with existing studies, based on the average run lengths (ARL) criterion and the results demonstrated a superior performance of the proposed approach. Nevertheless, to demonstrate the application of the proposed approach, some real-life applications are also provided in this paper. Furthermore, robustness of the proposed method is investigated by considering Beta distribution for the death rate in addition to the logistic model.},
  archive      = {J_NCA},
  author       = {Yeganeh, Ali and Shadman, Alireza and Shongwe, Sandile Charles and Abbasi, Saddam Akber},
  doi          = {10.1007/s00521-023-08257-x},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10677-10693},
  shortjournal = {Neural Comput. Appl.},
  title        = {Employing evolutionary artificial neural network in risk-adjusted monitoring of surgical performance},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A further study in the prediction of viscosity for iranian
crude oil reservoirs by utilizing a robust radial basis function (RBF)
neural network model. <em>NCA</em>, <em>35</em>(14), 10663–10676. (<a
href="https://doi.org/10.1007/s00521-023-08256-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a robust radial basis function neural network (RBF-NN) is developed for predicting Iranian crude oil viscosity in an extensive and precise way. Experimental data incorporate the PVT data of 720 samples gathered from Iranian central, southern, and offshore oil fields. The proposed RBF-NN model uses temperature, pressure, and parameters obtained by PVT analyses including oil and gas specific gravity, and solution gas–oil ratio as independent variables. The evaluation process was employed in three different regions; above, at, and below the bubble point pressure (Pb). The proposed RBF-NN model outputs were evaluated statistically using experimental data, and the results were compared side by side with the results of the previous studies including a multilayer perceptron neural network (MLP-NN) and the five well-established semiempirical equations. Sensitivity analyses were performed using the numeric sensitivity analyses (NSA) method and the results showed the highest and lowest impacts on the predicted crude oil viscosity between input parameters related to oil and gas specific gravity with 42 and 0\%, respectively. The results show the proposed RBF-NN model with the average absolute relative deviation (AARD\%) of 1.69, 4.56, and 2.04\% for above, at, and below the bubble point pressure (Pb) regions, respectively, is the most precise and consistent method for predicting crude oil viscosity compared with those published in the literature.},
  archive      = {J_NCA},
  author       = {Lashkenari, Mohammad Soleimani and Bagheri, Mohammad and Tatar, Afshin and Rezazadeh, Hadi and Inc, Mustafa},
  doi          = {10.1007/s00521-023-08256-y},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10663-10676},
  shortjournal = {Neural Comput. Appl.},
  title        = {A further study in the prediction of viscosity for iranian crude oil reservoirs by utilizing a robust radial basis function (RBF) neural network model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-domain reciprocal learning design for few-shot image
classification. <em>NCA</em>, <em>35</em>(14), 10649–10662. (<a
href="https://doi.org/10.1007/s00521-023-08255-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning is challenging in computer vision tasks, which aims to learn novel visual concepts from few labeled samples. Metric-based learning methods are widely used in few-shot learning due to their simplicity and effectiveness. However, comparing the similarity of support samples and query samples in a single metric space appears to be biased. In this work, we design a dual-domain reciprocal metric network (DRM-Net) structure for few-shot classification task which establishes a commutative learning relationship in two feature distributions from different metric domains. Specifically, our reciprocal metric network contains two metric domains, which employ graph neural network (GNN) and geometric algebra graph neural network (GA-GNN) as two metric functions to comprehensively measure the similarity between samples. This structure can help reduce the prediction bias by a single measure. We also construct the reciprocal learning loss between the metric feature distributions from the two branches to promote each other to improve the performance of the overall model. Our extensive experimental results demonstrate that the proposed reciprocal metric learning outperforms existing state-of-the-art few-shot learning methods on various benchmark datasets.},
  archive      = {J_NCA},
  author       = {Liu, Qifan and Chen, Yaozong and Cao, Wenming},
  doi          = {10.1007/s00521-023-08255-z},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10649-10662},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual-domain reciprocal learning design for few-shot image classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neonatal seizure detection using deep belief networks from
multichannel EEG data. <em>NCA</em>, <em>35</em>(14), 10637–10647. (<a
href="https://doi.org/10.1007/s00521-023-08254-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seizures in neonates happen to be one of the most difficult emergency circumstances to deal with. They are the first signs of significant neurological implications and should be precisely diagnosed for prompt medical intervention to avoid serious morbidities and occasional fatalities. In most cases, unlike adults, newborns show practically no physical indications of an epileptic fit. Hitherto, seizure diagnosis has relied solely on consistent laborious manual monitoring and interpretation of long-duration recordings of electroencephalograms (EEG). However, because the brains of the newborns remain nascent during the neonatal period, interpreting the EEG data necessitates the expertise of highly skilled experts. This study demonstrates a Deep Belief Network-based Machine Learning architecture for binary classification of seizure and seizure-free periods. The classifier was trained and its performance was assessed using a publicly available annotated dataset containing EEG recordings of 79 infants collected at Helsinki University Hospital. The proposed model was highly discriminative for seizure detection (AUC: 97.1\%). Our architecture establishes a high accuracy of 98.7 percentage, when applied to multichannel EEG recordings. The mean sensitivity and specificity rates were observed to be 96.1\% and 99.2\%, respectively, deeming the model comparable to recent advancements in machine learning classifiers on our dataset.},
  archive      = {J_NCA},
  author       = {Visalini, K. and Alagarsamy, Saravanan and Nagarajan, D.},
  doi          = {10.1007/s00521-023-08254-0},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10637-10647},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neonatal seizure detection using deep belief networks from multichannel EEG data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel neuroevolution model for emg-based hand gesture
classification. <em>NCA</em>, <em>35</em>(14), 10621–10635. (<a
href="https://doi.org/10.1007/s00521-023-08253-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of hand gestures from multichannel surface electromyography (sEMG) has been widely explored for the control of robotic prostheses. Several deep-learning algorithms have been utilized for this task with diverse levels of performance. A special type of genetic algorithm, Neuroevolution of Augmenting Topologies (NEAT), has favorable properties to be exploited for this task, especially the minimalistic initial structure and optimizing the topology along and weights of the evolved network. In this paper, we proposed a novel NEAT-based model that coherently evolves neural networks with Gated Recurrent Units and employed it for sEMG-based hand gesture classification. The algorithm was assessed in classifying 9 gestures from eight subjects (NinaPro Database 2) using eight independently trained networks using 150 ms non-overlapping decision windows. The trained networks yielded a mean classification accuracy of 88.76\% (3.85\%). Separate classification of gesture transition yielded an overall accuracy of 84\% and transition class recall of 93.3\%. The proposed algorithm was shown to utilize a small data set to evolve a classifier capable of expanding the number of independent control signals for real-time myoelectric control of powered upper limb prosthesis, translating the user’s intent into intuitive control of prosthesis with high degrees of freedom.},
  archive      = {J_NCA},
  author       = {Dweiri, Yazan and Hajjar, Yumna and Hatahet, Ola},
  doi          = {10.1007/s00521-023-08253-1},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10621-10635},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel neuroevolution model for emg-based hand gesture classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An unsupervised transfer learning model based on
convolutional auto encoder for non-alcoholic steatohepatitis activity
scoring and fibrosis staging of liver histopathological images.
<em>NCA</em>, <em>35</em>(14), 10605–10619. (<a
href="https://doi.org/10.1007/s00521-023-08252-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-alcoholic fatty liver disease (NAFLD) is one of the most frequent chronic liver diseases worldwide. Non-alcoholic steatohepatitis (NASH) is a progressive type of NAFLD that may cause cirrhosis, hepatocellular carcinoma, or almost mortality. Therefore, early diagnosis of the NASH is crucial. NASH is scored using the main histopathological features: ballooning, inflammation, steatosis, and fibrosis. The diagnosis of NASH by pathologists is time-consuming and can vary subjectively. On the other hand, several studies have reported deep learning approaches to enable fully automated NASH scoring. However, these studies suffer from limited labeled and imbalanced datasets. The purpose of this study to achieve fully automated NASH scoring with deep learning models that overcome data limitations. This study proposes an unsupervised transfer learning model for NASH scoring and fibrosis staging on a small-size dataset within two steps. In the first step, Convolutional Auto Encoder (CAE) is utilized as a deep feature extractor in an unsupervised manner during reconstruction. The second step is fine-tuning for classification consisting of the CAE encoder set as initial layers combined with fully connected layers and softmax. The proposed unsupervised transfer learning model is evaluated on a public NASH dataset. We compare the performance of the proposed network (CAE+classifier) with transfer learning models including Inception-v3, VGG16, ResNet-50. The proposed model has 94.87\% AUC for ballooning, 89.47\% AUC for inflammation, 96.15\% AUC for steatosis, and 93.18\% AUC for fibrosis. The proposed model is superior to transfer learning models (Inception-v3, VGG16, ResNet-50) with less parameter size and low computational complexity on a small NASH dataset.},
  archive      = {J_NCA},
  author       = {Karagoz, Meryem Altin and Akay, Bahriye and Basturk, Alper and Karaboga, Dervis and Nalbantoglu, O. Ufuk},
  doi          = {10.1007/s00521-023-08252-2},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10605-10619},
  shortjournal = {Neural Comput. Appl.},
  title        = {An unsupervised transfer learning model based on convolutional auto encoder for non-alcoholic steatohepatitis activity scoring and fibrosis staging of liver histopathological images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic speaker localization based on a novel lightweight
r–CNN model. <em>NCA</em>, <em>35</em>(14), 10589–10603. (<a
href="https://doi.org/10.1007/s00521-023-08251-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel sound localization approach is proposed that provides 3D coordinates of the real moving speaker. Sound recordings of a real user indoor environment were used for the proposed study. Four conventional microphones simultaneously recorded speech signals as the user moved between 14 predetermined locations. For extracting environment noise from recorded sound signals and accurately determining the origin of speech, z-score-based peak detection approach is used. The delays between acquired speech signals are calculated with the generalized cross-correlation phase transform approach. The determined delays are transformed into a special distance matrix, and each of these matrices is assigned to a particular speaker location in 3D space. A novel lightweight convolutional neural network-based deep regression network structure was constructed in order to learn the relationship between these distance matrices and real 3D location information. As a result, the sound localization problem has been transformed from an iterative solution to an innovative regression problem structure. With the low-cost traditional microphone structures and hardware used in this approach, the position of moving speaker is determined with high accuracy compared to the particle swarm optimization-based time difference of arrival approach. According to the performance comparison, the average localization deviation of 45.826 cm obtained in the time difference of arrival-based sound source localization approach was reduced to 16.298 cm in the proposed approach.},
  archive      = {J_NCA},
  author       = {Catalbas, Mehmet Cem and Dobrisek, Simon},
  doi          = {10.1007/s00521-023-08251-3},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10589-10603},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic speaker localization based on a novel lightweight R–CNN model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved sub-category exploration and attention hybrid
network for weakly supervised semantic segmentation. <em>NCA</em>,
<em>35</em>(14), 10573–10587. (<a
href="https://doi.org/10.1007/s00521-023-08250-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since image-wise supervised labels can be obtained effortlessly, weakly supervised semantic segmentation has made great achievements in recent years. Most advanced methods use the class activation maps (CAMs) to generate the initial localization map. However, the CAMs generated by the convolutional neural network only contain the discriminative parts of the object, and it is not sufficient for segmenting the image. In this paper, we propose an effective two-stage weakly supervised semantic segmentation method called SRANet with sub-category exploration network (SEN) and self-correlation module (SCM). It enriches the object information and adjusts the generated CAM by applying improved sub-category task and second-order self-supervision mechanism. Specifically, we perform clustering on features to obtain the sub-category pseudolabels, which are employed to generate high qualitative CAMs. Then, we design a self-attention module to further improve the quality of the response map. The extensive experiments results with some state-of-the-art methods show that the proposed SRANet model can achieve 71.5\% and 72.8\% mIoU on the PASCAL VOC 2012 training set and testing set, respectively. It also obtains 44.6\% mIoU on MS COCO 2014 dataset, which is the best performance in all comparable algorithms. All these verify the performance and superiority of the proposed model.},
  archive      = {J_NCA},
  author       = {Zhu, Hegui and Geng, Tian and Wang, Jiayi and Tang, Qingsong and Jiang, Wuming},
  doi          = {10.1007/s00521-023-08250-4},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10573-10587},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved sub-category exploration and attention hybrid network for weakly supervised semantic segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EyeDeep-net: A multi-class diagnosis of retinal diseases
using deep neural network. <em>NCA</em>, <em>35</em>(14), 10551–10571.
(<a href="https://doi.org/10.1007/s00521-023-08249-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal images are a key element for ophthalmologists in diagnosing a variety of eye illnesses. The retina is vulnerable to microvascular changes as a result of many retinal diseases and a variety of research have been done on early diagnosis of medical images to take proper treatment on time. This paper designs an automated deep learning-based non-invasive framework to diagnose multiple eye diseases using colour fundus images. A multi-class eye disease RFMiD dataset was used to develop an efficient diagnostic framework. Multi-class fundus images were extracted from a multi-label dataset and then various augmentation techniques were applied to make the framework robust in real-time. Images were processed according to the network for low computational demand. A multi-layer neural network EyeDeep-Net has been developed to train and test images for diagnosis of various eye problems in which the keystone convolutional neural network extracts relevant features from the input colour fundus image dataset and then processed features were used to make predictive diagnostic decisions. The strength of the EyeDeep-Net is evaluated using multiple statistical parameters and the performance of the proposed model is found to be significantly superior to multiple baseline state-of-the-art models. A comprehensive comparison of the proposed methodology to the most recent methods proves its efficacy in terms of classification and disease identification through digital fundus images.},
  archive      = {J_NCA},
  author       = {Sengar, Neha and Joshi, Rakesh Chandra and Dutta, Malay Kishore and Burget, Radim},
  doi          = {10.1007/s00521-023-08249-x},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10551-10571},
  shortjournal = {Neural Comput. Appl.},
  title        = {EyeDeep-net: A multi-class diagnosis of retinal diseases using deep neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-transfer learning for emotion recognition.
<em>NCA</em>, <em>35</em>(14), 10535–10549. (<a
href="https://doi.org/10.1007/s00521-023-08248-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been widely adopted in automatic emotion recognition and has lead to significant progress in the field. However, due to insufficient training data, pre-trained models are limited in their generalisation ability, leading to poor performance on novel test sets. To mitigate this challenge, transfer learning performed by fine-tuning pr-etrained models on novel domains has been applied. However, the fine-tuned knowledge may overwrite and/or discard important knowledge learnt in pre-trained models. In this paper, we address this issue by proposing a PathNet-based meta-transfer learning method that is able to (i) transfer emotional knowledge learnt from one visual/audio emotion domain to another domain and (ii) transfer emotional knowledge learnt from multiple audio emotion domains to one another to improve overall emotion recognition accuracy. To show the robustness of our proposed method, extensive experiments on facial expression-based emotion recognition and speech emotion recognition are carried out on three bench-marking data sets: SAVEE, EMODB, and eNTERFACE. Experimental results show that our proposed method achieves superior performance compared with existing transfer learning methods.},
  archive      = {J_NCA},
  author       = {Nguyen, Dung and Nguyen, Duc Thanh and Sridharan, Sridha and Denman, Simon and Nguyen, Thanh Thi and Dean, David and Fookes, Clinton},
  doi          = {10.1007/s00521-023-08248-y},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10535-10549},
  shortjournal = {Neural Comput. Appl.},
  title        = {Meta-transfer learning for emotion recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural architecture search based on packed samples for
identifying animals in camera trap images. <em>NCA</em>,
<em>35</em>(14), 10511–10533. (<a
href="https://doi.org/10.1007/s00521-023-08247-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biodiversity monitoring is valuable for reversing the global trend of biodiversity loss. The typical indicators in biodiversity monitoring are wild animals like vertebrates which can be effectively monitored via autonomously triggered cameras called camera traps. Since camera traps may produce numerous images due to uncontrollable monitoring conditions, it is relatively difficult to obtain reliable and timely animal records from camera trap images. Even though the neural networks may automate camera trap image classification, their applications are challenged by the limited transferability and operating costs. This challenge may be mounted by using neural architecture search with consideration of edge devices. Since the search is computationally expensive, the search cost is usually lowered by sacrificing resolutions of images in search. The objective of this study is to design a search method for classifying camera trap images on edge devices at acceptable search costs without sacrificing image resolutions of animal regions. The experiments show that the proposed method consumed about 95 h and 170 h to find networks, respectively, for camera trap image dataset NACTI-b and D3-a. The resulting networks achieve average accuracies 95.31 and 82.03\%, respectively, for NACTI-b and D3-a. The networks are also tested on the edge device NVIDIA Jetson TX2 and lead to average accuracies 95.35 and 81.86\%, respectively, for NACTI-b and D3-a.},
  archive      = {J_NCA},
  author       = {Jia, Liang and Tian, Ye and Zhang, Junguo},
  doi          = {10.1007/s00521-023-08247-z},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10511-10533},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural architecture search based on packed samples for identifying animals in camera trap images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MCGAN: Mask controlled generative adversarial network for
image retargeting. <em>NCA</em>, <em>35</em>(14), 10497–10509. (<a
href="https://doi.org/10.1007/s00521-023-08246-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image retargeting aims to resize a photograph without distorting its content. Recent solutions leverage generative adversarial networks (GANs) to learn an image’s internal distribution. Patches are then replicated and generated to fill the target aspect ratio to preserve the internal distribution. Although these approaches are somewhat successful, they do not have a sense of image semantics or the image’s contents, causing semantic errors during generation (e.g., a person with two heads). Our model addresses this by allowing user intervention. The users can preserve the objects they desire through user-defined masks. Our model enforces the masked object to appear at the user-defined location. It also utilizes a de-association regularizer to loosen the association of the selected object with its surroundings. Our method prevents object distortion and enables the user to remove or relocate the object from the input image while allowing the user to set its target size.},
  archive      = {J_NCA},
  author       = {Dy, Jilyan Bianca and Virtusio, John Jethro and Tan, Daniel Stanley and Lin, Yong-Xiang and Ilao, Joel and Chen, Yung-Yao and Hua, Kai-Lung},
  doi          = {10.1007/s00521-023-08246-0},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10497-10509},
  shortjournal = {Neural Comput. Appl.},
  title        = {MCGAN: Mask controlled generative adversarial network for image retargeting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble filters with harmonize PSO–SVM algorithm for
optimal hearing disorder prediction. <em>NCA</em>, <em>35</em>(14),
10473–10496. (<a
href="https://doi.org/10.1007/s00521-023-08244-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering a hearing disorder at an earlier intervention is critical for reducing the effects of hearing loss and the approaches to increase the remaining hearing ability can be implemented to achieve the successful development of human communication. Recently, the explosive dataset features have increased the complexity for audiologists to decide the proper treatment for the patient. In most cases, data with irrelevant features and improper classifier parameters causes a crucial influence on the audiometry system in terms of accuracy. This is due to the dependent processes of these two, where the classification accuracy performance could be worsened if both processes are conducted independently. Although the filter algorithm is capable of eliminating irrelevant features, it still lacks the ability to consider feature reliance and results in a poor selection of significant features. Improper kernel parameter settings may also contribute to poor accuracy performance. In this paper, an ensemble filters feature selection based on Information Gain (IG), Gain Ratio (GR), Chi-squared (CS), and Relief-F (RF) with harmonize optimization of Particle Swarm Optimization (PSO) and Support Vector Machine (SVM) is presented to mitigate these problems. Ensemble filters are utilized so that the initial top dominant features relevant for classification can be considered. Then, PSO and SVM are optimized simultaneously to achieve the optimal solution. The results on a standard Audiology dataset show that the proposed method produces 96.50\% accuracy with optimal solution compared to classical SVM, which signifies the proposed method is effective in handling high dimensional data for hearing disorder prediction.},
  archive      = {J_NCA},
  author       = {Hamid, Tengku Mazlin Tengku Ab and Sallehuddin, Roselina and Yunos, Zuriahati Mohd and Ali, Aida},
  doi          = {10.1007/s00521-023-08244-2},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10473-10496},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ensemble filters with harmonize PSO–SVM algorithm for optimal hearing disorder prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Exploring a q-learning-based chaotic naked mole rat
algorithm for s-box construction and optimization. <em>NCA</em>,
<em>35</em>(14), 10449–10471. (<a
href="https://doi.org/10.1007/s00521-023-08243-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new variant of the metaheuristic algorithm based on the naked mole rat (NMR) algorithm, called the Q-learning naked mole rat algorithm (QL-NMR), for substitution box construction and optimization. Unlike most competing works (which typically integrate a single chaotic map into a particular metaheuristic algorithm), QL-NMR assembles five chaotic maps (i.e., Chebyshev, logistic, circle, Singer, and sinusoidal) as part of the algorithm itself. Using a Q-learning table, QL-NMR remembers the historical performance of each chaotic map during the S-box construction process allowing just-in-time adaptive selection based on its current performance. Experimental results for 8 × 8 S-box generation demonstrate that the proposed QL-NMR gives competitive performance against other existing works, particularly in terms of nonlinearity and strict avalanche criteria. To further demonstrate the effectiveness of our proposed work, we have subjected the QL-NMR for image segmentation using multilevel thresholding. The results confirm that QL-NMR gives better performance than its predecessor NMR. Finally, QL-NMR S-box also outperformed NMR S-box in image encryption.},
  archive      = {J_NCA},
  author       = {Zamli, Kamal Z. and Din, Fakhrud and Alhadawi, Hussam S.},
  doi          = {10.1007/s00521-023-08243-3},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10449-10471},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring a Q-learning-based chaotic naked mole rat algorithm for S-box construction and optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modified arithmetic optimization algorithm for drones
measurements and tracks assignment problem. <em>NCA</em>,
<em>35</em>(14), 10421–10447. (<a
href="https://doi.org/10.1007/s00521-023-08242-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents efforts to solve the multi-track measurement assignment problem in drone detection and tracking. In many cases, several radars are collectively used to track drones efficiently, generating measurements and several tracks under different circumstances. In this work, several measurements are simulated during a time frame accompanied by the generation of several tracks using the Linear Kalman Filter. The focus is on finding an optimum measurements/track assignment for the simulated measurements and track values. The measurements and track generation are simulated using Stone Soup software. On the other hand, the optimization of the problem is implemented using several evolutionary-based metaheuristic algorithms. This optimization problem is known to be computationally explosive, especially if long time frames are considered. In particular, a new modified method based on the Arithmetic Optimization Algorithm is proposed. The optimization is applied to a formulated cost function that considers uncertainty, false alarms, and existing clutters. Simulations and comparisons show the ability of those evolutionary-based algorithms to solve this kind of problem efficiently. The proposed method obtained promising results compared to other comparative methods used to solve this drone’s measurements and track assignment problem.},
  archive      = {J_NCA},
  author       = {Zitar, Raed Abu and Abualigah, Laith and Barbaresco, Frederic and Seghrouchni, Amal ElFallah},
  doi          = {10.1007/s00521-023-08242-4},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10421-10447},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified arithmetic optimization algorithm for drones measurements and tracks assignment problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A simple multiple-fold correlation-based multi-view
multi-label learning. <em>NCA</em>, <em>35</em>(14), 10407–10420. (<a
href="https://doi.org/10.1007/s00521-023-08241-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correlations among different features and labels are ubiquitous in the present multi-view multi-label data sets and they are always described with within-view, cross-view, and consensus-view representations. While how to discover and measure these correlations effectively so as to enhance performances of a learning machine is an open problem, this problem cannot be solved by existing traditional learning machines. In this article, different from the current classical multi-view, multi-label, multi-view multi-label learning machines, we focus on the simultaneously measurement of multiple-fold correlations including within-view ones, cross-view ones, and consensus-view ones. Then, a simple multiple-fold correlation-based multi-view multi-label learning (MC-MVML) is developed. Extensive experiments on 36 classical data sets validate the superiority of MC-MVML in terms of classification performance, training time, convergence, statistical analysis, influence of parameters, etc., and the development of multi-view multi-label learning theory is expected to be promoted.},
  archive      = {J_NCA},
  author       = {Zhu, Changming and Zhao, Jiyun and Hu, Shizhe and Dong, Yilin and Cao, Lei and Zhou, Fan and Shi, Yuhu and Wei, Lai and Zhou, Rigui},
  doi          = {10.1007/s00521-023-08241-5},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10407-10420},
  shortjournal = {Neural Comput. Appl.},
  title        = {A simple multiple-fold correlation-based multi-view multi-label learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust training of dendritic neuron model neural network
for time series prediction. <em>NCA</em>, <em>35</em>(14), 10387–10406.
(<a href="https://doi.org/10.1007/s00521-023-08240-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many prediction methods proposed in the literature can be concerned under two main headings: probabilistic and non-probabilistic methods. In particular, as a kind of non-probabilistic model, artificial neural networks (ANNs), having different properties, have been commonly and effectively used in the literature. Some ANNs operate the additive aggregation function in the structure of their neuron models, while others employ the multiplicative aggregation function. Recently proposed dendritic neural networks also have both additional and multiplicative neuron models. The prediction performance of such an artificial neural network will inevitably be negatively affected by the outliers that the time series of interest may contain due to the neuron model in its structure. This study, for the training of a dendritic neural network, presents a robust learning algorithm. The presented robust algorithm is the first for the training of DNM in the literature as far as is known and uses Huber&#39;s loss function as the fitness function. The iterative process of the robust learning algorithm is carried out by particle swarm optimization. The productivity and efficiency of the suggested learning algorithm were evaluated by analysing different real-life time series. All analyses were performed with original and contaminated data sets under different scenarios. The R-DNM has the best performance for the original data sets with a value of 2.95\% in the ABC time series, while the FTSE showed the best performance in approximately 27\% and the second best in 33\% of all analyses. The proposed R-DNM has been the least affected by outliers in almost all scenarios for contaminated ABC data sets. Moreover, it has been the least affected model by outliers in approximately 71\% of the 90 analyses performed for the contaminated FTSE time series. The obtained results show that the dendritic artificial neural network trained by the proposed robust learning algorithm produces the satisfactory predictive results in the analysis of time series with and without outliers.},
  archive      = {J_NCA},
  author       = {Yilmaz, Ayşe and Yolcu, Ufuk},
  doi          = {10.1007/s00521-023-08240-6},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10387-10406},
  shortjournal = {Neural Comput. Appl.},
  title        = {A robust training of dendritic neuron model neural network for time series prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modality complementary information fusion for
multispectral pedestrian detection. <em>NCA</em>, <em>35</em>(14),
10361–10386. (<a
href="https://doi.org/10.1007/s00521-023-08239-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral pedestrian detection has received increasing attention in recent years as color and thermal modalities can provide complementary visual information, especially under insufficient illumination conditions. However, there is still a persistent crucial problem that how to design the cross-modality fusion mechanism to fully exploit the complementary characteristics between different modalities. In this paper, we propose a novel cross-modality complementary information fusion network (denoted as CCIFNet) to comprehensively capture the long-range interactions with precise positional information and meanwhile preserve the inter-spatial relationship between different modalities in the feature extraction stage. Further, we design an adaptive illumination-aware weight generation module to adaptively weight the final detection confidence of color and thermal modalities by taking various illumination conditions into consideration. Specifically, we comprehensively compare three different fusion strategies about this module to synthetically explore the best way for generating the final illumination-aware fusion weights. Finally, we present a simple but effective feature alignment module to alleviate the position shift problem caused by the weakly aligned color-thermal image pairs. Extensive experiments and ablation studies on KAIST, CVC-14, FLIR and LLVIP multispectral object detection datasets show that the proposed CCIFNet can achieve state-of-the-art performance under different illumination evaluation settings, while keeping a competitive speed-accuracy trade-off for real-time applications.},
  archive      = {J_NCA},
  author       = {Yan, Chaoqi and Zhang, Hong and Li, Xuliang and Yang, Yifan and Yuan, Ding},
  doi          = {10.1007/s00521-023-08239-z},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10361-10386},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-modality complementary information fusion for multispectral pedestrian detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning ensembles of deep neural networks for extreme
rainfall event detection. <em>NCA</em>, <em>35</em>(14), 10347–10360.
(<a href="https://doi.org/10.1007/s00521-023-08238-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate rainfall estimation is crucial to adequately assess the risk associated with extreme events capable of triggering floods and landslides. Data gathered from Rain Gauges (RGs), sensors devoted to measuring the intensity of the rain at individual points, are commonly used to feed interpolation methods (e.g., the Kriging geostatistical approach) and estimate the precipitation field over an area of interest. However, the information provided by RGs could be insufficient to model complex phenomena, and computationally expensive interpolation methods could not be used in real-time environments. Integrating additional data sources (e.g., radar and geostationary satellites) is an effective solution for improving the quality of the estimate, but it needs to cope with Big Data issues. To overcome all these issues, we propose a Rainfall Estimation Model (REM) based on an Ensemble of Deep Neural Networks (DeepEns-REM) that can automatically fuse heterogeneous data sources. The usage of Residual Blocks in the base models and the adoption of a Snapshot procedure to build the ensemble guarantees a fast convergence and scalability. Experimental results, conducted on a real dataset concerning a southern region in Italy, demonstrate the quality of the proposal in comparison with the Kriging interpolation technique and other machine learning techniques, especially in the case of exceptional rainfall events.},
  archive      = {J_NCA},
  author       = {Folino, Gianluigi and Guarascio, Massimo and Chiaravalloti, Francesco},
  doi          = {10.1007/s00521-023-08238-0},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10347-10360},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning ensembles of deep neural networks for extreme rainfall event detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing an ANN prediction model for compressive strength
of fly ash-based geopolymer concrete with experimental investigation.
<em>NCA</em>, <em>35</em>(14), 10329–10345. (<a
href="https://doi.org/10.1007/s00521-023-08237-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the research on geopolymer concrete (GPC) using fly ash was performed extensively, due to its comparable properties as similar to cement and its environmental benefits. However, due to the complexity and uncertainty of the design parameters like molarity, alkaline solution concentration and liquid to fly ash (L/F) ratio had made it hard to develop a systematic mix design for geopolymer concrete. These parameters along with the properties of fly ash, curing temperature and curing time have a significant effect on compressive strength of geopolymer concrete. This paper describes the use of artificial neural network (ANN) to predict the compressive strength of the geopolymer concrete using the data obtained experimentally. The ANN is modelled using the MATLAB and thus used to predict the compressive strength using the specified input parameter. The outcomes of this research shed light on influence of curing temperature and time on compressive strength of geopolymer concrete. The developed ANN model demonstrated to be efficient tool for predicting the compressive strength with $${R}^{2}$$ value of 0.85.},
  archive      = {J_NCA},
  author       = {Verma, Nikhil Kumar and Meesala, Chakradhara Rao and Kumar, Shailendra},
  doi          = {10.1007/s00521-023-08237-1},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10329-10345},
  shortjournal = {Neural Comput. Appl.},
  title        = {Developing an ANN prediction model for compressive strength of fly ash-based geopolymer concrete with experimental investigation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TSA-CNN-AOA: Twitter sentiment analysis using CNN optimized
via arithmetic optimization algorithm. <em>NCA</em>, <em>35</em>(14),
10311–10328. (<a
href="https://doi.org/10.1007/s00521-023-08236-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19, a novel virus from the coronavirus family, broke out in Wuhan city of China and spread all over the world, killing more than 5.5 million people. The speed of spreading is still critical as an infectious disease, and it causes more and more deaths each passing day. COVID-19 pandemic has resulted in many different psychological effects on people’s mental states, such as anxiety, fear, and similar complex feelings. Millions of people worldwide have shared their opinions on COVID-19 on several social media websites, particularly on Twitter. Therefore, it is likely to minimize the negative psychological impact of the disease on society by obtaining individuals’ views on COVID-19 from social media platforms, making deductions from their statements, and identifying negative statements about the disease. In this respect, Twitter sentiment analysis (TSA), a recently popular research topic, is used to perform data analysis on social media platforms such as Twitter and reach certain conclusions. The present study, too, proposes TSA using convolutional neural network optimized via arithmetic optimization algorithm (TSA-CNN-AOA) approach. Firstly, using a designed API, 173,638 tweets about COVID-19 were extracted from Twitter between July 25, 2020, and August 30, 2020 to create a database. Later, significant information was extracted from this database using FastText Skip-gram. The proposed approach benefits from a designed convolutional neural network (CNN) model as a feature extractor. Thanks to arithmetic optimization algorithm (AOA), a feature selection process was also applied to the features obtained from CNN. Later, K-nearest neighbors (KNN), support vector machine, and decision tree were used to classify tweets as positive, negative, and neutral. In order to measure the TSA performance of the proposed method, it was compared with different approaches. The results demonstrated that TSA-CNN-AOA (KNN) achieved the highest tweet classification performance with an accuracy rate of 95.098. It is evident from the experimental studies that the proposed approach displayed a much higher TSA performance compared to other similar approaches in the existing literature.},
  archive      = {J_NCA},
  author       = {Aslan, Serpil and Kızıloluk, Soner and Sert, Eser},
  doi          = {10.1007/s00521-023-08236-2},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10311-10328},
  shortjournal = {Neural Comput. Appl.},
  title        = {TSA-CNN-AOA: Twitter sentiment analysis using CNN optimized via arithmetic optimization algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MMPL-net: Multi-modal prototype learning for one-shot RGB-d
segmentation. <em>NCA</em>, <em>35</em>(14), 10297–10310. (<a
href="https://doi.org/10.1007/s00521-023-08235-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For one-shot segmentation, prototype learning is extensively used. However, using only one RGB prototype to represent all information in the support image may lead to ambiguities. To this end, we propose a one-shot segmentation network based on multi-modal prototype learning that uses depth information to complement RGB information. Specifically, we propose a multi-modal fusion and refinement block (MFRB) and multi-modal prototype learning block (MPLB). MFRB fuses RGB and depth features to generate multi-modal features and refined depth features, which are used by MPLB, to generate multi-modal information prototypes, depth information prototypes, and global information prototypes. Furthermore, we introduce self-attention to capture global context information in RGB and depth images. By integrating self-attention, MFRB, and MPLB, we propose the multi-modal prototype learning network (MMPL-Net), which adapts to the ambiguity of visual information in the scene. Finally, we construct a one-shot RGB-D segmentation dataset called OSS-RGB-D-5 $$^i$$ . Experiments using OSS-RGB-D-5 $$^i$$ show that our proposed method outperforms several state-of-the-art techniques with fewer labeled images and generalizes well to previously unseen objects.},
  archive      = {J_NCA},
  author       = {Shan, Dexing and Zhang, Yunzhou and Liu, Xiaozheng and Liu, Shitong and Coleman, Sonya A. and Kerr, Dermot},
  doi          = {10.1007/s00521-023-08235-3},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10297-10310},
  shortjournal = {Neural Comput. Appl.},
  title        = {MMPL-net: Multi-modal prototype learning for one-shot RGB-D segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised contrastive learning for heterogeneous graph
based on multi-pretext tasks. <em>NCA</em>, <em>35</em>(14),
10275–10296. (<a
href="https://doi.org/10.1007/s00521-023-08234-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With graph structure data becoming more common in practical problems, graph neural networks have shown their potential for processing graph structure data. Now, a heterogeneous graph containing different types of nodes and edges as a more complex type of graph structure is the hot research area. However, existing studies only focus on supervised methods/semi-supervised methods for heterogeneous graph, which require a lot of labeled data, demanding lots of money and time. In this paper, we propose a novel framework, i.e., the self-supervised contrastive learning for heterogeneous graph based on multi-pretext tasks (HGMT). In our proposed HGMT, considering the essential and inherent properties of heterogeneous graph, we utilize both metapath-based encoder and network schema-based encoder to get two different node representations to construct contrastive samples. And then, we design three complementary pretext tasks, i.e., local–local self-supervised contrastive learning task, local–context self-supervised contrastive learning task and local–global self-supervised contrastive learning task, which can make model have a deeper understanding of the interaction relationships on local, context and global structure information of heterogeneous graph. At last, we view it as multitask learning to train our proposed HGMT model by balancing these three pretext tasks. Empirical results validate the performance of our proposed HGMT compared with the existing state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Ma, Shuai and Liu, Jian-wei},
  doi          = {10.1007/s00521-023-08234-4},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10275-10296},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-supervised contrastive learning for heterogeneous graph based on multi-pretext tasks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning-based self-learning intrusion detection
system for in-vehicle networks. <em>NCA</em>, <em>35</em>(14),
10257–10273. (<a
href="https://doi.org/10.1007/s00521-023-08233-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controller area networks (CANs) are the de-facto standard for in-vehicle networks and enable real-time data communication between the electronic control units in a vehicle. However, owing to inadequate security mechanisms, CANs are vulnerable to cyberattacks. The sophistication of these attacks evolves constantly and new types of attacks emerge over time. Most existing intrusion detection systems (IDSs) can handle known attacks, but their ability to detect unknown attacks requires urgent improvements. Although IDSs can be updated via the Internet of Vehicles cloud to improve their detection performance, an unacceptable amount of time is required to collect enough labeled data and the updates are slow. Considering these problems, we propose a transfer learning-based self-learning IDS (TLSIDS) for CANs. The proposed TLSIDS uses a cascade detection approach that is capable of detecting both known and unknown attacks with high performance, and the self-learning function can solve the problem of slow updates, thus improving the speed and performance of the TLSIDS in detecting unknown attacks. The TLSIDS consists of four modules, namely the basic detection module (BDM), the advanced detection module (ADM), the unknown attacks classification module (UACM), and the self-learning module (SLM). The efficacy of the TLSIDS was evaluated using a public dataset provided by the Hacking and Countermeasure Research Lab (HCRL). The results revealed that our proposed TLSIDS has effectiveness and robustness in distinct scenarios.},
  archive      = {J_NCA},
  author       = {Wang, Yuhang and Lai, Yingxu and Chen, Ye and Wei, Jingwen and Zhang, Zhaoyi},
  doi          = {10.1007/s00521-023-08233-5},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10257-10273},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transfer learning-based self-learning intrusion detection system for in-vehicle networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Basic flight maneuver generation of fixed-wing plane based
on proximal policy optimization. <em>NCA</em>, <em>35</em>(14),
10239–10255. (<a
href="https://doi.org/10.1007/s00521-023-08232-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous agile flight control has been a challenging problem due to complex highly nonlinear dynamics, and generating feasible basic flight maneuvers off-line for subsequent online motion planning has become a solution. In this paper, we present a novel reinforcement learning-based basic flight maneuvers generation method for a 6 degrees of freedom aircraft model via Proximal Policy Optimization (PPO). Different from traditional control methods depending on model simplification or complex controller design, the proposed algorithm can automatically generate maneuvers by directly selecting different aircrafts and adding or subtracting reward components. First, we propose a new approach to ensure the continuity and avoid large oscillations of the control command by designing its time derivative as the output of policy network and then using the integral operator to obtain the final control action exerted to the plane, which is effective to achieve complex flight control tasks based on the aircraft model with high-fidelity. Second, the reward function used in PPO training is comprised of desired aims of which the weights can be adaptive according to the task type or conditional trigger during training. By this method, we successfully generate most of the basic flight maneuvers, including level flight, coordinated turn, climb/descent and horizontal roll. A series of simulation results show that our proposed algorithm can not only learn these maneuvers in a short time within 0.2–10 h but also has superior performance in settling time and robustness compared with the traditional PID control method while attaining similar accuracy.},
  archive      = {J_NCA},
  author       = {Li, Lun and Zhang, Xuebo and Qian, Chenxu and Wang, Runhua},
  doi          = {10.1007/s00521-023-08232-6},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10239-10255},
  shortjournal = {Neural Comput. Appl.},
  title        = {Basic flight maneuver generation of fixed-wing plane based on proximal policy optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sum-based event-triggered dynamic output feedback control
for synchronization of fuzzy neural networks with deception attacks.
<em>NCA</em>, <em>35</em>(14), 10221–10237. (<a
href="https://doi.org/10.1007/s00521-023-08231-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns with the event-based dynamic output feedback control for the synchronization of fuzzy neural networks under mixed delay and deception attacks. A weighted sum-based dynamic event-triggered mechanism (WSDETM) is developed to save the communication resources while preserving a satisfactory system performance. A dynamic output feedback controller (DOFC) is designed to achieve exponential synchronization of fuzzy neural networks. To reduce the data traffic, both communication channels from the sensor to DOFC and DOFC to Zero-Order Holder are subject to WSDETM. Different from the traditional deception attacks modeled by Bernoulli process, we adopt the more general Markov process modeling deception attacks. By using the cone-complimentarity linearization algorithm, the DOFC and WSDETM parameters are carried out. The effectiveness of the proposed method is demonstrated with two numerical cases.},
  archive      = {J_NCA},
  author       = {Zhang, Duo and Ouyang, Deqiang and Shu, Lan and Hu, Cheng and Shi, Kaibo and Wen, Shiping},
  doi          = {10.1007/s00521-023-08231-7},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10221-10237},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sum-based event-triggered dynamic output feedback control for synchronization of fuzzy neural networks with deception attacks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel parameter identification strategy based on COOT
optimizer applied to a three-diode model of triple cation perovskite
solar cells. <em>NCA</em>, <em>35</em>(14), 10197–10219. (<a
href="https://doi.org/10.1007/s00521-023-08230-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable optoelectronic characteristics of hybrid metal halide perovskite semiconductors, such as high defect tolerance, extended carrier lifetime and diffusion length, and adjustable optical bandgap, have garnered much interest in the last decade. Therefore, this paper considers the experimental and mathematical modeling of triple-cation perovskite solar cells (PSCs) with two different device structures. It is challenging to construct a reliable mathematical model of triple-cation perovskite solar cells based on the three-diode model due to its complex nature. This is related to the perovskite materials&#39; dynamics, nonlinearity, and sensitivity. This paper proposes a novel method incorporating a recent metaheuristic algorithm named COOT optimizer to estimate the optimal parameters of the three-diode equivalent circuit of triple-cation perovskite solar cells. The key idea is to use the swarm intelligence-based COOT to optimally achieve the PV panel&#39;s optimal parameters. The identification method benefits from the exploration and exploitation abilities of the COOT algorithm to obtain its parameters effortlessly and precisely. Two experiments are conducted in this work; the first is measured I–V datasets for a triple-cation perovskite (TC-per) solar cell at standard conditions. The second consists of the measured I–V datasets for a triple-cation modified perovskite (TCM-per) perovskite solar cell. During the optimization process, the nine unknown parameters of the three-diode model (TDM) are used as decision variables. The objective function to be minimized is the root-mean-square error (RMSE) between the measured and estimated data. An extensive comparative study is presented with other optimizers of the whale optimization algorithm (WOA), seagull optimization algorithm (SOA), sine cosine algorithm (SCA), ant lion optimization (ALO), and dragonfly algorithm (DA). Furthermore, statistical analysis of ANOVA is performed. The obtained results confirm the superiority of the proposed method in constructing a reliable model of the three-diode model of PSCs as it provides the least RMSE between the measured and estimated characteristics of 1.61E−05 in the first dataset. In contrast, the poorest algorithm (SCA) provides 1.03E−04. Similarly, in the second dataset of experiments, COOT achieves the least RMSE of 1.82E−05; meanwhile, the largest RMSE of 1.03E−04 using ALO. Based on the strong correlation between experimental and theoretical results using the COOT algorithm, we proposed a theoretical way (close to reality) to get the photovoltaic parameters of ideality factor and parasitic resistances in perovskite solar cell devices.},
  archive      = {J_NCA},
  author       = {Rezk, Hegazy and Elsenety, Mohamed M. and Ferahtia, Seydali and Falaras, Polycarpos and Zaky, Alaa A.},
  doi          = {10.1007/s00521-023-08230-8},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10197-10219},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel parameter identification strategy based on COOT optimizer applied to a three-diode model of triple cation perovskite solar cells},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel metaheuristic algorithm inspired by COVID-19 for
real-parameter optimization. <em>NCA</em>, <em>35</em>(14), 10147–10196.
(<a href="https://doi.org/10.1007/s00521-023-08229-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this modern world, we are encountered with numerous complex and emerging problems. The metaheuristic optimization science plays a key role in many fields from medicine to engineering, design, etc. Metaheuristic algorithms inspired by nature are among the most effective and fastest optimization methods utilized to optimize different objective functions to minimize or maximize one or more specific objectives. The use of metaheuristic algorithms and their modified versions is expanding every day. However, due to the abundance and complexity of various problems in the real world, it is always necessary to select the most proper metaheuristic method; hence, there is a strong need to create new algorithms to achieve our desired goal. In this paper, a new and powerful metaheuristic algorithm, called the coronavirus metamorphosis optimization algorithm (CMOA), is proposed based on metabolism and transformation under various conditions. The proposed CMOA algorithm has been tested and implemented on the comprehensive and complex CEC2014 benchmark functions, which are functions based on real-world problems. The results of the experiments in a comparative study under the same conditions show that the CMOA is superior to the newly-developed metaheuristic algorithms including AIDO, ITGO, RFOA, SCA, CSA, CS, SOS, GWO, WOA, MFO, PSO, Jaya, CMA-ES, GSA, RW-GWO, mTLBO, MG-SCA, TOGPEAe, m-SCA, EEO and OB-L-EO, indicating the effectiveness and robustness of the CMOA algorithm as a powerful algorithm. As it was observed from the results, the CMOA provides more suitable and optimized solutions than its competitors for the problems studied. The CMOA preserves the diversity of the population and prevents trapping in local optima. The CMOA is also applied to three engineering problems including optimal design of a welded beam, a three-bar truss and a pressure vessel, showing its high potential in solving such practical problems and effectiveness in finding global optima. According to the obtained results, the CMOA is superior to its counterparts in terms of providing a more acceptable solution. Several statistical indicators are also tested using the CMOA, which demonstrates its efficiency compared to the rest of the methods. This is also highlighted that the CMOA is a stable and reliable method when employed for expert systems.},
  archive      = {J_NCA},
  author       = {Kadkhoda Mohammadi, Soleiman and Nazarpour, Daryoush and Beiraghi, Mojtaba},
  doi          = {10.1007/s00521-023-08229-1},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10147-10196},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel metaheuristic algorithm inspired by COVID-19 for real-parameter optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data augmentation techniques in time series domain: A survey
and taxonomy. <em>NCA</em>, <em>35</em>(14), 10123–10145. (<a
href="https://doi.org/10.1007/s00521-023-08459-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the latest advances in deep learning-based generative models, it has not taken long to take advantage of their remarkable performance in the area of time series. Deep neural networks used to work with time series heavily depend on the size and consistency of the datasets used in training. These features are not usually abundant in the real world, where they are usually limited and often have constraints that must be guaranteed. Therefore, an effective way to increase the amount of data is by using data augmentation techniques, either by adding noise or permutations and by generating new synthetic data. This work systematically reviews the current state of the art in the area to provide an overview of all available algorithms and proposes a taxonomy of the most relevant research. The efficiency of the different variants will be evaluated as a central part of the process, as well as the different metrics to evaluate the performance and the main problems concerning each model will be analysed. The ultimate aim of this study is to provide a summary of the evolution and performance of areas that produce better results to guide future researchers in this field.},
  archive      = {J_NCA},
  author       = {Iglesias, Guillermo and Talavera, Edgar and González-Prieto, Ángel and Mozo, Alberto and Gómez-Canaval, Sandra},
  doi          = {10.1007/s00521-023-08459-3},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10123-10145},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data augmentation techniques in time series domain: A survey and taxonomy},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A lightweight fast human activity recognition method using
hybrid unsupervised-supervised feature. <em>NCA</em>, <em>35</em>(14),
10109–10121. (<a
href="https://doi.org/10.1007/s00521-023-08368-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the elderly population has become an important issue for today’s society. Ambient-assisted living is a new means that focuses on providing assistance to address the needs of elderly people. Mobile device-based human activity recognition (HAR) has drawn increasing attention in this field. However, there are still many issues in HAR that remain open. Most existing HAR methods have overlooked the fact that the resources (CPU and memory) of mobile devices are limited. In view of this, a lightweight fast learning method based on stochastic configuration networks (SCNs) and dynamic stepwise updating technology was presented in this paper, which contributed to the reduction of the computational complexity and memory consumption for modeling. Besides, a hybrid unsupervised-supervised feature selection approach was proposed to obtain a feature set with high separability and low redundancy. The experimental results demonstrated that the proposed HAR method achieved lower resource consumption compared to other methods for human activity recognition.},
  archive      = {J_NCA},
  author       = {Nan, Jing and Ning, Chuanfeng and Yu, Gang and Dai, Wei},
  doi          = {10.1007/s00521-023-08368-5},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10109-10121},
  shortjournal = {Neural Comput. Appl.},
  title        = {A lightweight fast human activity recognition method using hybrid unsupervised-supervised feature},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PointDet++: An object detection framework based on human
local features with transformer encoder. <em>NCA</em>, <em>35</em>(14),
10097–10108. (<a
href="https://doi.org/10.1007/s00521-022-06938-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection algorithm plays an important role in the field of chemical plant safety identification. In the field operation chemical plant scene, usually the targets to be detected are highly correlated with people, and most of them are small objects because of the long shooting distance. Conventional object detection algorithms use strong backbone module to obtain global features, which makes the algorithm module perform well in large targets. But these methods are difficult to be applied in small target detection scenes as they lack the use of local features. How to make better use of local features is the key to small target detection tasks. It is not only necessary to extract the local features from the original data, but also to consider the location relationship between them. To solve this problem, we propose a new object detection framework named PointDet++. The first step is to use the trained pose estimation model to obtain the local features of human body. Then, we reconstruct local features and global features, respectively, with transformer encoder and graph convolution. In the output layer, we integrate local features and global features according to the target to be detected, so as to improve the detection performance of our proposed model. Specifically, our framework significantly outperforms state of the art by 10.3 AP scores on field operation dataset in chemical plant.},
  archive      = {J_NCA},
  author       = {Tang, Yudi and Wang, Bing and He, Wangli and Qian, Feng},
  doi          = {10.1007/s00521-022-06938-7},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10097-10108},
  shortjournal = {Neural Comput. Appl.},
  title        = {PointDet++: An object detection framework based on human local features with transformer encoder},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New pythagorean fuzzy-based distance operators and their
applications in pattern classification and disease diagnostic analysis.
<em>NCA</em>, <em>35</em>(14), 10083–10095. (<a
href="https://doi.org/10.1007/s00521-022-07679-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pythagorean fuzzy set is a notion that takes a broader view at intuitionistic fuzzy set with a higher prospect of applications since it has a wider scope compared to IFS. On the other hand, distance measure is an efficient information measure for decision-making via deep learning approach, and thus, this paper proposes a new tri-parametric distance and its weighted version under Pythagorean fuzzy environment with improved performance indexes compared to the hitherto tri-parametric distance measures in the literature. The proposed Pythagorean fuzzy-based distance operators are new approaches because they take into account the three conventional number of parameters of PFSs against the existing practice, and as well incorporate the whole parameters to avoid error due to exclusion as witnessed in other distance operators. Some theorems are presented to validate the new Pythagorean fuzzy distance techniques with regards to its alignment with distance operator’s properties. We demonstrate the applications of the proposed Pythagorean fuzzy distance and its weighted version in cases involving pattern classification and disease diagnosis via deep learning approach where patterns, diseases and patients are presented as Pythagorean fuzzy values. Finally, some comparative analyses of the new tri-parametric Pythagorean fuzzy distance and its weighted version alongside some similar existing distances are presented in terms of the applications to showcase the superiority of the present Pythagorean fuzzy distance techniques.},
  archive      = {J_NCA},
  author       = {Ejegwa, Paul Augustine and Feng, Yuming and Tang, Shuyu and Agbetayo, Johnson Mobolaji and Dai, Xiangguang},
  doi          = {10.1007/s00521-022-07679-3},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10083-10095},
  shortjournal = {Neural Comput. Appl.},
  title        = {New pythagorean fuzzy-based distance operators and their applications in pattern classification and disease diagnostic analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A transfer-based few-shot classification approach via masked
manifold mixup and fuzzy memory contrastive learning. <em>NCA</em>,
<em>35</em>(14), 10069–10082. (<a
href="https://doi.org/10.1007/s00521-022-07607-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning studies the problem of classifying unseen images by learning only a small number of samples in these categories with the assistance of a large amount of data in other classes. In recent studies, the idea of transfer learning is an effective method to solve the problem of few-shot classification. However, the insufficient generalization ability of the model still restricts the performance of these transfer-based methods. This paper proposes a masked manifold mixup and fuzzy memory contrastive learning (M3FM) method for transfer-based few-shot learning to improve the generalization ability. We design a regularization technique that enhances the model’s learning of local features by masking and mixing the data manifold in the hidden states of neural networks. Then, a momentum updated fuzzy memory is adopted in contrastive learning with the masked mixup manifold to help the model learn the specific distinctions of different categories. Experimental results show that the proposed method outperforms previous baseline methods on miniImageNet, CUB-200, and CIFAR-FS benchmarks. Further adaptation research demonstrates that our method can be generalized to complex few-shot classification tasks and cross-domain scenarios. Ablation studies verify the effectiveness of masked manifold mixup and fuzzy memory contrastive learning.},
  archive      = {J_NCA},
  author       = {Tian, Runliang and Shi, Hongmei},
  doi          = {10.1007/s00521-022-07607-5},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10069-10082},
  shortjournal = {Neural Comput. Appl.},
  title        = {A transfer-based few-shot classification approach via masked manifold mixup and fuzzy memory contrastive learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). XAI4EEG: Spectral and spatio-temporal explanation of deep
learning-based seizure detection in EEG time series. <em>NCA</em>,
<em>35</em>(14), 10051–10068. (<a
href="https://doi.org/10.1007/s00521-022-07809-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clinical practice, algorithmic predictions may seriously jeopardise patients’ health and thus are required to be validated by medical experts before a final clinical decision is met. Towards that aim, there is need to incorporate explainable artificial intelligence techniques into medical research. In the specific field of epileptic seizure detection there are several machine learning algorithms but less methods on explaining them in an interpretable way. Therefore, we introduce XAI4EEG: an application-aware approach for an explainable and hybrid deep learning-based detection of seizures in multivariate EEG time series. In XAI4EEG, we combine deep learning models and domain knowledge on seizure detection, namely (a) frequency bands, (b) location of EEG leads and (c) temporal characteristics. XAI4EEG encompasses EEG data preparation, two deep learning models and our proposed explanation module visualizing feature contributions that are obtained by two SHAP explainers, each explaining the predictions of one of the two models. The resulting visual explanations provide an intuitive identification of decision-relevant regions in the spectral, spatial and temporal EEG dimensions. To evaluate XAI4EEG, we conducted a user study, where users were asked to assess the outputs of XAI4EEG, while working under time constraints, in order to emulate the fact that clinical diagnosis is done - more often than not - under time pressure. We found that the visualizations of our explanation module (1) lead to a substantially lower time for validating the predictions and (2) leverage an increase in interpretability, trust and confidence compared to selected SHAP feature contribution plots.},
  archive      = {J_NCA},
  author       = {Raab, Dominik and Theissler, Andreas and Spiliopoulou, Myra},
  doi          = {10.1007/s00521-022-07809-x},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10051-10068},
  shortjournal = {Neural Comput. Appl.},
  title        = {XAI4EEG: Spectral and spatio-temporal explanation of deep learning-based seizure detection in EEG time series},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable bayesian network abstraction for dimension
reduction. <em>NCA</em>, <em>35</em>(14), 10031–10049. (<a
href="https://doi.org/10.1007/s00521-022-07810-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimension reduction methods is effective for tackling the complexity of models learning from high-dimensional data. Usually, they are presented as a black box, where the reduction process is unknown to the practitioners. Yet, this process potentially transmits a reliable framework for understanding the regularities behind the data. Furthermore, in some applications contexts, the available datasets are presented with a huge lack of records. Therefore, the classical and the deep dimension reduction methods often fall in the over-fitting trap. We propose to tackle these challenges under the Bayesian network paradigm associated with the latent variables learning. We propose an interpretable framework for learning a reduced dimension while ensuring the effectiveness against the curse of dimensionality. Our exhaustive experimental results, over benchmark datasets, prove that our dimension reduction algorithm yields a user-friendly model that not only minimizes the information loss due to the reduction process, but also escapes data overfitting due to the lack of records.},
  archive      = {J_NCA},
  author       = {Njah, Hasna and Jamoussi, Salma and Mahdi, Walid},
  doi          = {10.1007/s00521-022-07810-4},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10031-10049},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interpretable bayesian network abstraction for dimension reduction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constructing adversarial examples to investigate the
plausibility of explanations in deep audio and image classifiers.
<em>NCA</em>, <em>35</em>(14), 10011–10029. (<a
href="https://doi.org/10.1007/s00521-022-07918-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the rise of deep learning and its inherent black-box nature, the desire to interpret these systems and explain their behaviour became increasingly more prominent. The main idea of so-called explainers is to identify which features of particular samples have the most influence on a classifier’s prediction, and present them as explanations. Evaluating explainers, however, is difficult, due to reasons such as a lack of ground truth. In this work, we construct adversarial examples to check the plausibility of explanations, perturbing input deliberately to change a classifier’s prediction. This allows us to investigate whether explainers are able to detect these perturbed regions as the parts of an input that strongly influence a particular classification. Our results from the audio and image domain suggest that the investigated explainers often fail to identify the input regions most relevant for a prediction; hence, it remains questionable whether explanations are useful or potentially misleading.},
  archive      = {J_NCA},
  author       = {Hoedt, Katharina and Praher, Verena and Flexer, Arthur and Widmer, Gerhard},
  doi          = {10.1007/s00521-022-07918-7},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {10011-10029},
  shortjournal = {Neural Comput. Appl.},
  title        = {Constructing adversarial examples to investigate the plausibility of explanations in deep audio and image classifiers},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph non-negative matrix factorization with alternative
smoothed <span class="math display"><em>L</em><sub>0</sub></span>
regularizations. <em>NCA</em>, <em>35</em>(14), 9995–10009. (<a
href="https://doi.org/10.1007/s00521-022-07200-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph non-negative matrix factorization (GNMF) can discover the data’s intrinsic low-dimensional structure embedded in the high-dimensional space. So, it has superior performance for data representation and clustering. Unfortunately, it is sensitive to noise and outliers. In this paper, to improve the robustness of GNMF, $$l_0$$ norm is introduced to enhance the sparsity of factorized matrices. As the discontinuity of $$l_0$$ norm and minimizing it is a NP-hard problem, five functions approximating $$l_0$$ norm are used to transform the problem of the sparse graph non-negative matrix factorization (SGNMF) to a global optimization problem. Finally, the multiplicative updating rules (MUR) are designed to solve the problem and the convergence of algorithm is proven. In the experiment, the accuracy and normalized mutual information of clustering results show the superior performance of SGNMF on five public datasets.},
  archive      = {J_NCA},
  author       = {Chen, Keyi and Che, Hangjun and Li, Xinqi and Leung, Man-Fai},
  doi          = {10.1007/s00521-022-07200-w},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {9995-10009},
  shortjournal = {Neural Comput. Appl.},
  title        = {Graph non-negative matrix factorization with alternative smoothed $$L_0$$ regularizations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Method for solving constrained 0-1 quadratic programming
problems based on pointer network and reinforcement learning.
<em>NCA</em>, <em>35</em>(14), 9973–9993. (<a
href="https://doi.org/10.1007/s00521-022-07604-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constrained 0-1 quadratic programming problem (CBQP) is an important problem of integer programming, and many combinatorial optimization problems can be converted to CBQP problem. Because BQP is NP-hard problem, the solving time and accuracy of traditional optimization algorithm are very dependent on the size of the problem, and the local optimal solution obtained by the heuristic algorithm is unstable. Deep learning algorithm has great advantages in solving such problems. In this paper, for the CBQP problem with linear constraints, we creatively apply two algorithms and models to solve it: the graph pointer network model (GPN) trained by hierarchical reinforcement learning (HRL), and the multi-head attention-based pointer network model trained by Advantage Actor-Critic (A2C), which greatly improves the solving speed, accuracy and constraint satisfaction rate of CBQP problems of different scales. At the same time, the bidirectional mask mechanism is innovatively introduced into the network so that the constraint satisfaction rate of the solution is very high. For the two algorithms, this paper solved the 0-1 knapsack (BKP) problem and the quadratic knapsack (QKP) problem, which are equivalent to the CBQP problem, and compared the results of the CBQP problem with different data distribution and scales. The experiment shows that no matter the objective function of the CBQP problem is linear or nonlinear, different data set distribution, or the scale, the pointer network trained by reinforcement learning in this paper has better results than traditional optimization algorithms in solving time, accuracy, stability and constraint satisfaction rate, and with the increase in the size of the problem, this advantage becomes more obvious.},
  archive      = {J_NCA},
  author       = {Gu, Shenshen and Zhuang, Yuxi},
  doi          = {10.1007/s00521-022-07604-8},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {9973-9993},
  shortjournal = {Neural Comput. Appl.},
  title        = {Method for solving constrained 0-1 quadratic programming problems based on pointer network and reinforcement learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A subgradient-based neural network to constrained
distributed convex optimization. <em>NCA</em>, <em>35</em>(14),
9961–9971. (<a
href="https://doi.org/10.1007/s00521-022-07003-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence and large data develop, distributed optimization shows the great potential in the research of machine learning, particularly deep learning. As an important distributed optimization problem, the nonsmooth distributed optimization problem over an undirected multi-agent system with inequality and equality constraints frequently appears in deep learning. To deal with this optimization problem cooperatively, a novel neural network with lower dimension of solution space is presented. It is demonstrated that the state solution of proposed approach can enter the feasible region. Also, it can also prove that the state solution achieves consensus and finally converges to the optimal solution set. Moreover, the proposed approach here does not depend on the boundedness of the feasible region, which is a necessary assumption in some simplified neural network. Finally, some simulation results and a practical application are given to reveal the efficacy and practicability.},
  archive      = {J_NCA},
  author       = {Wei, Zhe and Jia, Wenwen and Bian, Wei and Qin, Sitian},
  doi          = {10.1007/s00521-022-07003-z},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {9961-9971},
  shortjournal = {Neural Comput. Appl.},
  title        = {A subgradient-based neural network to constrained distributed convex optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPINet: Self-supervised point cloud frame interpolation
network. <em>NCA</em>, <em>35</em>(14), 9951–9960. (<a
href="https://doi.org/10.1007/s00521-022-06939-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For autonomous vehicles, the acquisition frequency difference between LiDAR (10–20 Hz) and camera (over 100 Hz) makes simultaneous update of two perceptive systems (2D/3D) less efficient. Nowadays, frame interpolation is in urgent need for increasing frame rate of point cloud sequences obtained by LiDAR. However, a major limitation of current full supervised methods is that high frame rate ground truth sequences are hard to access. We propose a novel Self-supervised Point Cloud Frame Interpolation Network (SPINet) accommodating with variable motion situation, retaining geometric consistency, but without the necessity of utilizing G.T. data. Extensive experiments show that our proposed SPINet outperforms the current full supervised methods.},
  archive      = {J_NCA},
  author       = {Xu, Jiawen and Le, Xinyi and Chen, Cailian and Guan, Xinping},
  doi          = {10.1007/s00521-022-06939-6},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {9951-9960},
  shortjournal = {Neural Comput. Appl.},
  title        = {SPINet: Self-supervised point cloud frame interpolation network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on deep interpretation of deep learning:
Prediction, representation, modeling and utilization. <em>NCA</em>,
<em>35</em>(14), 9947–9949. (<a
href="https://doi.org/10.1007/s00521-023-08472-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhang, Nian and Wang, Jian and Rutkowski, Leszek},
  doi          = {10.1007/s00521-023-08472-6},
  journal      = {Neural Computing and Applications},
  number       = {14},
  pages        = {9947-9949},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on deep interpretation of deep learning: Prediction, representation, modeling and utilization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot learning via self-organizing maps. <em>NCA</em>,
<em>35</em>(13), 9931–9945. (<a
href="https://doi.org/10.1007/s00521-023-08299-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting-labeled images from all possible classes related to the task at hand is highly impractical and may even be impossible. At this point, Zero-Shot Learning (ZSL) can enable the classification of new test classes for which there are no labeled images for training. The vast majority of existing ZSL methods aim to learn a projection from the feature space into the semantic space, where all classes are represented by a list of semantic attributes. To this end, they usually try to solve a complex optimization problem. Nevertheless, the semantic features (attributes) may not be suitable to represent the images because they are derived based on human knowledge and are, therefore, abstract. Alternatively, in this study, we introduce a novel ZSL method called SOMZSL, which has its roots in Self-Organizing Maps (SOM), a famous data visualization method. In particular, SOMZSL builds two SOMs of the same size and shape, one for the feature space and one for the attribute space, and then establishes a correspondence between them. Instead of considering a direct projection between the feature space and the attribute space, which is inherently different, SOMZSL connects them through comparable intermediate layers, i.e., SOMs. In terms of performance, SOMZSL can classify novel test classes as well or even better than existing ZSL methods without dealing with a complex optimization problem, thanks to the heuristic nature of SOM on which it is based. Finally, SOMZSL uses unlabeled test images in the construction of SOMs and can thus mitigate the domain shift problem inherent in ZSL.},
  archive      = {J_NCA},
  author       = {Ismailoglu, Firat},
  doi          = {10.1007/s00521-023-08299-1},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9931-9945},
  shortjournal = {Neural Comput. Appl.},
  title        = {Zero-shot learning via self-organizing maps},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HTN planning for dynamic vehicle scheduling with stochastic
trip times. <em>NCA</em>, <em>35</em>(13), 9917–9930. (<a
href="https://doi.org/10.1007/s00521-023-08228-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the stochastic nature of traffic flow and passenger demand at stops, bus service is constantly subject to delays and disruptions. Therefore, dynamic vehicle scheduling is essential to reduce the negative effects of service disturbance. This paper proposes a novel hierarchical task network (HTN) planning approach for dynamic vehicle scheduling with stochastic trip times. In the approach, a hybrid dynamic control strategy is devised to achieve headway adherence. Experimental results demonstrate that the proposed approach can flexibly handle a variety of abnormal operating conditions and maintain a stable headway. Due to the consideration of stochastic trip times, the HTN-based dynamic vehicle scheduling can simulate real bus operations. It can not only flexibly simulate different scenarios, such as inserting new trips or vehicle breakdown, but also easily test different control strategies. This will assist dispatchers handling disruption agilely and enhance the service quality of public transport.},
  archive      = {J_NCA},
  author       = {Shen, Yindong and Yan, Miaomiao},
  doi          = {10.1007/s00521-023-08228-2},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9917-9930},
  shortjournal = {Neural Comput. Appl.},
  title        = {HTN planning for dynamic vehicle scheduling with stochastic trip times},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of idiopathic normal pressure hydrocephalus on
head CT using a deep convolutional neural network. <em>NCA</em>,
<em>35</em>(13), 9907–9915. (<a
href="https://doi.org/10.1007/s00521-023-08225-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Idiopathic normal pressure hydrocephalus (iNPH) is an underrecognized cause of dementia, with reasons for underdiagnosis including symptomatic overlap with other neurologic disorders and difficulty in distinguishing the disproportionate ventriculomegaly of iNPH from generalized volume loss on cross-sectional imaging. In response to this problem of underdiagnosis, we developed a convolutional neural network (CNN) to detect iNPH on head CT. In this retrospective study of 358 patients with head CTs acquired between 1997 and 2020, a CNN was trained to identify iNPH. The iNPH cohort utilized a clinically derived ground truth based upon EMR metadata meeting Japanese Society of Normal Pressure Hydrocephalus 2nd Edition criteria for definite iNPH. The non-iNPH cohort included matched control patients. Statistical analysis included evaluation of AUROC for the test partitions. The cohort included 80 iNPH and 278 non-iNPH patients identified for inclusion. Test partition performance demonstrated 100\% sensitivity [95\% CI: 100\%, 100\%] and 89\% specificity [95\% CI:78\%,97\%], with four false positives, zero false negatives, and a 0.96 AUROC [95\% CI:0.89,0.99]. We therefore demonstrated that a CNN utilizing a clinically derived ground truth can identify iNPH on head CT. Our model has the potential to be used in clinical practice as a screening tool to assist in the detection of iNPH in settings in which a high volume of head CTs is performed, and for a variety of indications, such as within the emergency department, thus potentially identifying patients who may benefit from referral to neurology or neurosurgery for further evaluation.},
  archive      = {J_NCA},
  author       = {Haber, Matthew A. and Biondetti, Giorgio P. and Gauriau, Romane and Comeau, Donnella S. and Chin, John K. and Bizzo, Bernardo C. and Strout, Julia and Golby, Alexandra J. and Andriole, Katherine P.},
  doi          = {10.1007/s00521-023-08225-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9907-9915},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of idiopathic normal pressure hydrocephalus on head CT using a deep convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time adaptive fuzzy SOSM controller design with output
constraint. <em>NCA</em>, <em>35</em>(13), 9893–9905. (<a
href="https://doi.org/10.1007/s00521-023-08224-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fixed-time adaptive fuzzy second-order sliding mode (SOSM) approach has been designed to handle the problem of nonlinear systems with output constraints. According to the advantages of using fuzzy logic systems, the unknown bounds of uncertainties can be approached dynamically. The problem of output constraints has been well handled by constructing a barrier Lyapunov function. Next, with the help of adding a power integrator technique and adaptive fuzzy control, a fixed-time adaptive fuzzy SOSM controller is designed for the considered systems. In addition to the above, the controller can not only promote the sliding variables to converge to the origin in fixed time, but also stabilize the variables in the constrained range. In other words, under the proposed method, the systems can be stable in a specified time no matter how the initial value changes. Lastly, a numerical example is used to verify the performance of the proposed SOSM control tactic.},
  archive      = {J_NCA},
  author       = {Li, Xin and Ma, Li and Mei, Keqi and Ding, Shihong and Pan, Tianhong},
  doi          = {10.1007/s00521-023-08224-6},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9893-9905},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fixed-time adaptive fuzzy SOSM controller design with output constraint},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An experimental study: Using categorical or fuzzy inputs for
classification problems with dimensionality reduction. <em>NCA</em>,
<em>35</em>(13), 9883–9892. (<a
href="https://doi.org/10.1007/s00521-023-08223-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fuzzy control system is a mathematical framework that evaluates analog input data in terms of logical variables with continuous values ranging from 0 to 1. From the 1970s on, fuzzy notions have exploded in popularity across all fields. Fuzzy logic that contains fuzzy values, fuzzy variables, and fuzzy sets is frequently used by engineers, statisticians, and programmers to describe vague concepts mathematically. In recent years, researchers have begun to investigate fuzzy systems in deep neural networks. In our study, the use of fuzzy inputs and the use of categorical inputs in classification problems were compared with and without dimension reduction. For the combination of four different datasets and three different encoder pairs, the accuracy using fuzzy values was higher than the accuracy using categorical values, and a 4.54656\% average increase in accuracy value is maintained. For big-data analysis, in critical fields like the medical field, even a tiny gain in accuracy can make a big difference in people’s lives. I hope that the findings will guide researchers to consider the fuzzy representation of the data in the data pre-processing part.},
  archive      = {J_NCA},
  author       = {Dönmez, İlknur},
  doi          = {10.1007/s00521-023-08223-7},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9883-9892},
  shortjournal = {Neural Comput. Appl.},
  title        = {An experimental study: Using categorical or fuzzy inputs for classification problems with dimensionality reduction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Empirical mode decomposition-based multi-scale spectral
graph convolution network for abnormal electricity consumption
detection. <em>NCA</em>, <em>35</em>(13), 9865–9881. (<a
href="https://doi.org/10.1007/s00521-023-08222-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal electricity consumption detection is of great significance for maintaining the safe and stable operation of the power grids, or for reducing the irregular electricity consumption and economic losses. However, not enough attention has been paid to comprehensively explore the multi-scale characteristics of the consumption series, and to discover the intra-series relationships among different timestamps. To tackle such problems, this paper proposes an empirical mode decomposition-based multi-scale spectral graph convolution network for detecting the abnormal electricity consumptions. Firstly, the electricity consumption data are decomposed into subcomponents by the empirical mode decomposition to generate the multi-scale time characteristics, and then, the entropy feature vectors are extracted from such subcomponents and the original data. Furthermore, the feature fusion for the entropy feature vectors and the original data is realized by the multi-scale convolutional layers. Then, the spectral graph convolution network (SGCN) is employed to detect the abnormal electricity consumption and to output specific electricity consumption case. In this SGCN, both the inter-series and the intra-series relationships can be tackled by the graph Fourier transform and the graph convolution operator. Finally, detailed experiments and comparisons are done. Experimental results demonstrate that our proposed method has satisfactory accuracy and adaptability, and has much better detection performance than some popular deep and shallow methods, e.g., the CNN, LSTM, ELM and SVM.},
  archive      = {J_NCA},
  author       = {Meng, Songping and Li, Chengdong and Peng, Wei and Tian, Chenlu},
  doi          = {10.1007/s00521-023-08222-8},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9865-9881},
  shortjournal = {Neural Comput. Appl.},
  title        = {Empirical mode decomposition-based multi-scale spectral graph convolution network for abnormal electricity consumption detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Determining the gender wage gap through causal inference and
machine learning models: Evidence from chile. <em>NCA</em>,
<em>35</em>(13), 9841–9863. (<a
href="https://doi.org/10.1007/s00521-023-08221-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, there has been increasing awareness of the different types of inequalities that women experience. A very important inequality is the wage gap. Understanding the elements that affect this gap is crucial in order for governments to take the right actions to diminish the gap. It is also important to understand the broader context in which this inequality has evolved over time. In this paper, we develop a causal inference model based on the ideas of Potential Outcome (PO) and Metalearners (ML) to address this important issue. We include a time variable in the causal analysis which helps to determine how the effects have evolved over the last decades. We apply data from 1990 to 2017 from the official government social survey of Chile to fit the models. We then make a deep analysis of each variable using the SHAP framework to see the impact of each variable on the gender wage gap. Sadly, our results indicate that there has been a gap between the earnings of men and women over the last three decades, and the gap actually widened over time. We also find that variable decomposition helps to clarify the different effects as some variables clearly help to diminish this gap. Our results may assist the government of Chile and other organizations to endorse policies that may reduce the gap.},
  archive      = {J_NCA},
  author       = {Kristjanpoller, Werner and Michell, Kevin and Olson, Josephine E.},
  doi          = {10.1007/s00521-023-08221-9},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9841-9863},
  shortjournal = {Neural Comput. Appl.},
  title        = {Determining the gender wage gap through causal inference and machine learning models: Evidence from chile},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven koopman fractional order PID control of a MEMS
gyroscope using bat algorithm. <em>NCA</em>, <em>35</em>(13), 9831–9840.
(<a href="https://doi.org/10.1007/s00521-023-08220-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven control methods are strong tools due to their predictions for controlling the systems with a nonlinear dynamic model. In this paper, the Koopman operator is used to linearize the nonlinear dynamic model. Generating the Koopman operator is the most important part of using the Koopman theory. Dynamic mode decomposition (DMD) is used to obtain eigenfunction for producing the Koopman operator. Then, a fractional order PID (FOPID) controller is applied to control the linearized dynamic model. A swarm intelligence bat optimization algorithm is utilized to tune the FOPID controller’s parameters. Simulation results on micro-electromechanical systems (MEMS) gyroscope under conventional PID controller, FOPID, Koopman-based FOPID controller (Koopman-FOPID), and Koopman-FOPID control optimized by bat algorithm (Koopman-BAFOPID) show that the proposed Koopman-BAFOPID controller has better performance in comparison with three other controllers in terms of high tracking performance, low tracking error, and low control efforts.},
  archive      = {J_NCA},
  author       = {Rahmani, Mehran and Redkar, Sangram},
  doi          = {10.1007/s00521-023-08220-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9831-9840},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-driven koopman fractional order PID control of a MEMS gyroscope using bat algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating deep learning predictions for COVID-19 from x-ray
images using leave-one-out predictive densities. <em>NCA</em>,
<em>35</em>(13), 9819–9830. (<a
href="https://doi.org/10.1007/s00521-023-08219-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of the COVID-19 virus is an important task for controlling the spread of the pandemic. Imaging techniques such as chest X-ray are relatively inexpensive and accessible, but its interpretation requires expert knowledge to evaluate the disease severity. Several approaches for automatic COVID-19 detection using deep learning techniques have been proposed. While most approaches show high accuracy on the COVID-19 detection task, there is not enough evidence on external evaluation for this technique. Furthermore, data scarcity and sampling biases make difficult to properly evaluate model predictions. In this paper, we propose stochastic gradient Langevin dynamics (SGLD) to take into account the model uncertainty. Four different deep learning architectures are trained using SGLD and compared to their baselines using stochastic gradient descent. The model uncertainties are also evaluated according to their convergence properties and the leave-one-out predictive densities. The proposed approach is able to reduce overconfidence of the baseline estimators while also retaining predictive accuracy for the best-performing cases.},
  archive      = {J_NCA},
  author       = {Hernández, Sergio and López-Córtes, Xaviera},
  doi          = {10.1007/s00521-023-08219-3},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9819-9830},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluating deep learning predictions for COVID-19 from X-ray images using leave-one-out predictive densities},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autism spectrum disorder prediction using bidirectional
stacked gated recurrent unit with time-distributor wrapper: An EEG
study. <em>NCA</em>, <em>35</em>(13), 9803–9818. (<a
href="https://doi.org/10.1007/s00521-023-08218-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A nearly diagnosis and inference of Autism Spectrum Disorder (ASD) demands an automated intelligent system that can efficiently and accurately detect disorder from diverse dataset. The existing automated (machine/deep learning) state-of-the-art approaches have major limitation of being specific to the EEG dataset and have not been tested over EEG-datasets with varying metadata. Hence, this challenges how well the methods can be generalized. The present paper aims to propose and investigate a Bidirectional Stacked GRU network for ASD prediction considering diversity in EEG-signals recorded from different devices. The stacked layers in the proposed model structure performs complex mapping, nonlinear variation capturing, and temporal feature extraction for classifying individuals with ASD from Neurotypical individuals. To enhance the generalizability of the model and identify model robustness for practical implementation, the proposed framework is trained on three different EEG-dataset fed randomly to the system. The model in cross-validation framework showed an accuracy of 97\% compared to the state-of-the-art methods ranging from 82 to 96\% when applied on the same dataset. Furthermore, a receiver operating characteristic curve metric has quantified proposed model performance showing 0.998 as Area Under the Curve (AUC) compared to models with values in range 0.961 &lt; AUC &lt; 0.984.},
  archive      = {J_NCA},
  author       = {Wadhera, Tanu and Bedi, Jatin and Sharma, Saurabh},
  doi          = {10.1007/s00521-023-08218-4},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9803-9818},
  shortjournal = {Neural Comput. Appl.},
  title        = {Autism spectrum disorder prediction using bidirectional stacked gated recurrent unit with time-distributor wrapper: An EEG study},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A self-organizing incremental neural network for imbalance
learning. <em>NCA</em>, <em>35</em>(13), 9789–9802. (<a
href="https://doi.org/10.1007/s00521-023-08217-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance learning deals with data that have very skewed class distributions, and commonly exists in real-world applications. Incremental learning has the ability to train a model continually using new data, which requires the model to learn the new information without forgetting the old one. While these two issues have been independently discussed, their joint treatment has not been studied thoroughly. This paper studies the combined challenges and proposes a balanced self-organizing incremental neural network (Balanced SOINN). First, we introduce Balanced SOINN, which can be trained incrementally with the resampling method. Then, we compare Balanced SOINN with other methods with artificial and real-world data. Our proposed method is competitive in artificial datasets in non-incremental scenarios and achieves the best performance with real-world datasets in incremental scenarios.},
  archive      = {J_NCA},
  author       = {Shao, Yue and Xu, Baile and Shen, Furao and Zhao, Jian},
  doi          = {10.1007/s00521-023-08217-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9789-9802},
  shortjournal = {Neural Comput. Appl.},
  title        = {A self-organizing incremental neural network for imbalance learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A detector for page-level handwritten music object
recognition based on deep learning. <em>NCA</em>, <em>35</em>(13),
9773–9787. (<a
href="https://doi.org/10.1007/s00521-023-08216-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten music recognition (HMR) is the technology of transcribing the content of images of music scores. The accurate detection of music objects at the page level is one of the main challenges of HMR. Thus far, the existing methods suffer from the tiny and dense nature of handwritten music notations and realize positive detection accuracy only on snippets. In this paper, we propose a detector that consists of a staff line removal model and a handwritten music object detection model for page-level handwritten music object recognition. First, an end-to-end staff line removal model R_Staff_Net based on residual learning reduces the complexity of page-level detection. Second, we developed an improved YOLO-V4 model for handwritten music object detection. The improvements mainly concern the adoption of a de-coupled detection head and visual attention module in the YOLO-V4, and an adaptive multi-scale feature fusion module AMFFM is used to enhance the textures and features of tiny music symbols in the deep convolution layers, and the gradient harmonized mechanism is utilized to address the inherent imbalance between music objects. We verified the R_Staff_Net and the improved YOLO-V4 model on the ICDAR/GREC staff line removal dataset and the MUSCIMA++ dataset, respectively. The experiments highlight that R_Staff_Net presents outstanding performance with an F-M score of 98.64\%, and our improved YOLO-V4 model is superior to other handwritten music symbol detection methods with a mean average precision (mAP) of 91.8\% when addressing page-level input. Although the experimental results of the detector show that the R_Staff_Net helps little to the overall mAP, the network is beneficial for symbols that are similar to staff lines or heavily overlap staff lines.},
  archive      = {J_NCA},
  author       = {Zhang, Yusen and Huang, Zhiqing and Zhang, Yanxin and Ren, Keyan},
  doi          = {10.1007/s00521-023-08216-6},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9773-9787},
  shortjournal = {Neural Comput. Appl.},
  title        = {A detector for page-level handwritten music object recognition based on deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving knee osteoarthritis classification using
multimodal intermediate fusion of x-ray, MRI, and clinical information.
<em>NCA</em>, <em>35</em>(13), 9763–9772. (<a
href="https://doi.org/10.1007/s00521-023-08214-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most common form of arthritis is osteoarthritis (OA) which often affects the knee joint. Recent studies are utilizing convolution neural networks (CNNs) to automatically classify OA severity. These deep learning models are designed to analyze either X-ray images or sequences of images from magnetic resonance imaging (MRI). For the first time, we propose a fusion model that combines three different modalities (X-ray, MRI, and the patient’s clinical information) into one network to improve the accuracy over the models being used individually. First, we construct the fusion architecture using two models from a previous work that were trained on a small dataset (dataset 1). This includes a classic CNN for X-ray with an accuracy of 50\%, and a custom 3D model for MRI with an accuracy of 54\%. When combining these two models with the clinical information, our fusion architecture increased performance to 62\%. To further test the fusion architecture, we created a custom X-ray model and trained it on a larger dataset (dataset 2) which achieved an accuracy of 70\% on the testing set from dataset 1. When combining the MRI (54\%) model with the new X-ray model (70\%) and the clinical information, the fusion model increased performance to 76\%. In addition to the 5-category KL classification, the fusion model also improves the 2-category OA and non-OA classification to AUC of 0.964. The results show the proposed fusion architecture can be generalized to combine different individual models and a holistic multimodal approach can further boost OA classification performance.},
  archive      = {J_NCA},
  author       = {Guida, Carmine and Zhang, Ming and Shan, Juan},
  doi          = {10.1007/s00521-023-08214-8},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9763-9772},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving knee osteoarthritis classification using multimodal intermediate fusion of X-ray, MRI, and clinical information},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spacecraft anomaly detection with attention temporal
convolution networks. <em>NCA</em>, <em>35</em>(13), 9753–9761. (<a
href="https://doi.org/10.1007/s00521-023-08213-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spacecraft faces various situations when carrying out exploration missions in complex space, thus monitoring the anomaly status of spacecraft is crucial to the development of the aerospace industry. The time-series telemetry data generated by on-orbit spacecraft contains important information about the status of spacecraft. However, traditional domain knowledge-based spacecraft anomaly detection methods are not effective due to high dimensionality and complex correlation among variables. In this work, we propose an anomaly detection framework for spacecraft multivariate time-series data based on temporal convolution networks (TCNs). First, we employ dynamic graph attention to model the complex correlation among variables and time series. Second, temporal convolution networks with parallel processing ability are used to extract multidimensional features for the downstream prediction task. Finally, many potential anomalies are detected by the best threshold. Experiments on real NASA SMAP/MSL spacecraft datasets show the superiority of our proposed model with respect to state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Liu, Liang and Tian, Ling and Kang, Zhao and Wan, Tianqi},
  doi          = {10.1007/s00521-023-08213-9},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9753-9761},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spacecraft anomaly detection with attention temporal convolution networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tumor growth prediction and classification based on the KNN
algorithm and discrete-time markov chains (DTMC). <em>NCA</em>,
<em>35</em>(13), 9739–9751. (<a
href="https://doi.org/10.1007/s00521-023-08212-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, brain tumors have become one of the most common fatal diseases. Despite the existence of an important number of research studies on tumors, the proportion of research on predicting the growth of tumors remains insufficient due to the intricate nature of this research domain. Therefore, the presence of any application able to predict the growth of the tumor may have a role in eliminating the tumor by finding the appropriate treatment for it before it grows. This paper investigates tumor growth and presents a technique for tumor growth prediction based on the Discrete Time Markov Chain (DTMC) and K-Nearest Neighbor (KNN) algorithms. The design and development of this technique consists of a proposition of a stochastic model of tumor progression. This is followed by an extension of the mode to several cases that allow the derivation of new cases based on the study of predictive probabilities. The aim of this paper is to develop a model based on the KNN and DTMC algorithms that can classify tumors and predict the future state based on the current state of the tumor without the knowledge of the past state. In other words, all relevant information about the past and the present that would be useful in making predictions is available in the current state. In terms of performance evaluation metrics, the results show that the proposed method exceeds the existing methods with 97.65\% accuracy, 71.65\% specificity and 99.087\% sensitivity.},
  archive      = {J_NCA},
  author       = {El Fatimi, Lahcen and Boucheneb, Hanifa},
  doi          = {10.1007/s00521-023-08212-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9739-9751},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tumor growth prediction and classification based on the KNN algorithm and discrete-time markov chains (DTMC)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Spatiotemporal consistent selection-correction network for
deep interactive image segmentation. <em>NCA</em>, <em>35</em>(13),
9725–9738. (<a
href="https://doi.org/10.1007/s00521-023-08210-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive image segmentation can extract specific targets meeting users’ intention, and has received widespread attention in computer vision. The conventional interactive methods rely too much on the user interaction due to the limitation caused by the hand-crafted low-level features. Recently, deep interactive approaches have significantly improved the segmentation performance thanks to the semantic perception ability. However, in these approaches each interaction is generally treated independently by the same way, regardless of its own intention of each click and the potential relationships among the continuous interactions. The above defects still leads them restricted to the conflict between the interaction quantity and the interaction number. To overcome the above problem, this paper focuses on the click-based interactive segmentation task by explicitly mining the intention of each click and linking the relationships among all clicks. A selection-collection training framework is first established to impose the global object selection and the local error correction roles during the whole interaction process. Then a temporal network architecture is designed to continuously connect the entire click sequence. In this case, the respective role of each click can be played as much as possible, and the spatially varying segmentation cues can be propagated in time series. Experiments on the challenging SBD, GrabCut, DAVIS and Berkeley segmentation datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Li, Yang and Wang, Tao and Ji, Zexuan and Fu, Peng and Shen, Xiaobo and Sun, Quansen},
  doi          = {10.1007/s00521-023-08210-y},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9725-9738},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatiotemporal consistent selection-correction network for deep interactive image segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing metaheuristic based extractive text summarization
with fuzzy logic. <em>NCA</em>, <em>35</em>(13), 9711–9723. (<a
href="https://doi.org/10.1007/s00521-023-08209-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world as the data on the web is increasing it becomes a challenge to identify the relevant information. Automatic text summarization (ATS) provides a significant answer to it. In this paper, fuzzy logic and shark smell optimization (SSO) based algorithm for extractive text summarization is proposed. Shark Smell Optimization has been used to assign a weight to eight different features to identify the less and more important text features of text summarization. Then, the Fuzzy Logic’s inference system is utilized to generate fuzzy rules, and finally an automated summary is generated. The system generated summaries have been tested against the reference summaries from the DUC 2002, DUC 2003, DUC-2004 and TAC-11 dataset and ROUGE toolkit has been used for the evaluation of the proposed solution. Results of the proposed algorithm are compared against traditional methods and the rouge score suggested that the proposed algorithm generates better results than other methods.},
  archive      = {J_NCA},
  author       = {Tomer, Minakshi and Kumar, Manoj and Hashmi, Adeel and Sharma, Bharti and Tomer, Uma},
  doi          = {10.1007/s00521-023-08209-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9711-9723},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing metaheuristic based extractive text summarization with fuzzy logic},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A heuristic multi-objective task scheduling framework for
container-based clouds via actor-critic reinforcement learning.
<em>NCA</em>, <em>35</em>(13), 9687–9710. (<a
href="https://doi.org/10.1007/s00521-023-08208-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Container-based cloud technology has changed the delivery mode of traditional applications and brought a breakthrough development to the field of cloud computing. However, the uncertainty of cloud environment and variability of application requirements increase the scheduling cost of tasks in container cloud. In particular, how to balance the business performance and utilization efficiency of cloud resources in the peak stage of application access is the focus of future for container cluster technology. In this paper, we propose a heuristics multi-objective task scheduling framework based on reinforcement learning (AC-CCTS). The proposed framework not only solves the problems of single objective and local convergence in traditional task scheduling methods, but also reduces the cost of experiential learning with reinforcement learning methods. Firstly, we define container cloud environment, scheduling agent, scheduling actions and scheduling evaluation methods to establish a deep reinforcement learning-based dynamic scheduling model. Then, based on Actor-Critic algorithm, we design heuristic rules and prioritized experience replay method to speed up convergence of task scheduling and decrease learning costs. At the same time, we provide compensation mechanism for dynamic task scheduling to improve the robustness of the approach. Finally, we implement comparative experiments to simulate various scheduling scenarios and verify the effectiveness of AC-CCTS from different perspectives such as resource balance, resource utilization and QoS. Compared with traditional meta-heuristic scheduling methods such as FIMPSO, HWOA-MBA and other reinforcement learning algorithms such as DeepRM-Plus and RLSched, AC-CCTS shows better resource utilization efficiency and convergence stability in container-based cloud task scheduling.},
  archive      = {J_NCA},
  author       = {Zhu, Lilu and Wu, Feng and Hu, Yanfeng and Huang, Kai and Tian, Xinmei},
  doi          = {10.1007/s00521-023-08208-6},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9687-9710},
  shortjournal = {Neural Comput. Appl.},
  title        = {A heuristic multi-objective task scheduling framework for container-based clouds via actor-critic reinforcement learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linear iterative feature embedding: An ensemble framework
for an interpretable model. <em>NCA</em>, <em>35</em>(13), 9657–9685.
(<a href="https://doi.org/10.1007/s00521-023-08204-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new ensemble framework for an interpretable model called linear iterative feature embedding (LIFE) has been developed to achieve high prediction accuracy, easy interpretation, and efficient computation simultaneously. The LIFE algorithm is able to fit a wide single-hidden-layer neural network (NN) accurately with three steps: defining the subsets of a dataset by the linear projections of neural nodes, creating the features from multiple narrow single-hidden-layer NNs trained on the different subsets of the data, combining the features with a linear model. The theoretical rationale behind LIFE is also provided by the connection to the loss ambiguity decomposition of stack ensemble methods. Both simulation and empirical experiments confirm that LIFE consistently outperforms directly trained single-hidden-layer NNs and also outperforms many other benchmark models, including multilayers feed forward neural network (FFNN), Xgboost, and random forest (RF) in many experiments. As a wide single-hidden-layer NN, LIFE is intrinsically interpretable. Meanwhile, both variable importance and global main and interaction effects can be easily created and visualized. In addition, the parallel nature of the base learner building makes LIFE computationally efficient by leveraging parallel computing.},
  archive      = {J_NCA},
  author       = {Sudjianto, Agus and Qiu, Jinwen and Li, Miaoqi and Chen, Jie},
  doi          = {10.1007/s00521-023-08204-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9657-9685},
  shortjournal = {Neural Comput. Appl.},
  title        = {Linear iterative feature embedding: An ensemble framework for an interpretable model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight ResGRU: A deep learning-based prediction of
SARS-CoV-2 (COVID-19) and its severity classification using multimodal
chest radiography images. <em>NCA</em>, <em>35</em>(13), 9637–9655. (<a
href="https://doi.org/10.1007/s00521-023-08200-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The new COVID-19 emerged in a town in China named Wuhan in December 2019, and since then, this deadly virus has infected 324 million people worldwide and caused 5.53 million deaths by January 2022. Because of the rapid spread of this pandemic, different countries are facing the problem of a shortage of resources, such as medical test kits and ventilators, as the number of cases increased uncontrollably. Therefore, developing a readily available, low-priced, and automated approach for COVID-19 identification is the need of the hour. The proposed study uses chest radiography images (CRIs) such as X-rays and computed tomography (CTs) to detect chest infections, as these modalities contain important information about chest infections. This research introduces a novel hybrid deep learning model named Lightweight ResGRU that uses residual blocks and a bidirectional gated recurrent unit to diagnose non-COVID and COVID-19 infections using pre-processed CRIs. Lightweight ResGRU is used for multi-modal two-class classification (normal and COVID-19), three-class classification (normal, COVID-19, and viral pneumonia), four-class classification (normal, COVID-19, viral pneumonia, and bacterial pneumonia), and COVID-19 severity types’ classification (i.e., atypical appearance, indeterminate appearance, typical appearance, and negative for pneumonia). The proposed architecture achieved f-measure of 99.0\%, 98.4\%, 91.0\%, and 80.5\% for two-class, three-class, four-class, and COVID-19 severity level classifications, respectively, on unseen data. A large dataset is created by combining and changing different publicly available datasets. The results prove that radiologists can adopt this method to screen chest infections where test kits are limited.},
  archive      = {J_NCA},
  author       = {Ahmad, Mughees and Bajwa, Usama Ijaz and Mehmood, Yasar and Anwar, Muhammad Waqas},
  doi          = {10.1007/s00521-023-08200-0},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9637-9655},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lightweight ResGRU: A deep learning-based prediction of SARS-CoV-2 (COVID-19) and its severity classification using multimodal chest radiography images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TRCA-net: Stronger u structured network for human image
segmentation. <em>NCA</em>, <em>35</em>(13), 9627–9635. (<a
href="https://doi.org/10.1007/s00521-023-08199-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human image segmentation has been a practical and active research topic due to its wide range of potential application. There are some previous studies on manual, semi-automatic and automatic segmentation methods to investigate the semantic segmentation of human parts fully for real-world human analysis scenarios, but further research is still needed. This paper presents a novel semantic segmentation network, named TRCA-Net, for human image segmentation tasks. Having the TransUNet as the backbone, TRCA-Net incorporates Res2Net and Coordinate Attention to improve the performance. Res2Net blocks and Transformer can obtain better feature maps by encoding the input images. The Coordinate Attention in the decoder aggregates and upsamples the encoded feature maps, and connects to the high-resolution CNN feature maps for gaining accurate segmentation. The TRCA-Net can enhance finer details by recovering local spatial information. We compare the TRCA-Net with state-of-the-art (SOAT) semantic segmentation networks: the original U-Net, DeepLabv3+, and TransUNet. The experiment results have demonstrated that our proposed TRCA-Net outperforms these networks.},
  archive      = {J_NCA},
  author       = {Hao, Li-Ying and Yang, Zhengkai and Liu, Yun-Peng and Shen, Chao},
  doi          = {10.1007/s00521-023-08199-4},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9627-9635},
  shortjournal = {Neural Comput. Appl.},
  title        = {TRCA-net: Stronger u structured network for human image segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When attention is not enough to unveil a text’s author
profile: Enhancing a transformer with a wide branch. <em>NCA</em>,
<em>35</em>(13), 9607–9626. (<a
href="https://doi.org/10.1007/s00521-023-08198-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Author profiling (AP) is a highly relevant natural language processing (NLP) problem; it deals with predicting features of authors such as gender, age and personality traits. It is done by analyzing texts written by the authors themselves; take for instance documents such as books, articles, and more recently posts in social media platforms. In the present study, we focus in the latter, which is an scenario with a number of applications in marketing, security, health and others. Surprisingly, given the achievements of deep learning (DL) strategies on other NLP tasks, for AP DL architectures regularly underperform, left behind by classical machine learning (ML) approaches. In this study we show how a deep learning architecture based on transformers offers competitive results by exploiting a joint-intermediate fusion strategy called the Wide &amp; Deep Transformer (WD-T). Our methodology implements a fusion of contextualized word vector representations and handcrafted features, by using a self-attention mechanism and a novel encoding technique that incorporates stylistic, topic, and personal information from authors. This allows for the creation of more accurate, fine-grained predictions. Our approach attained competitive performance against top-quartile results from the 2017–2019 editions at the Plagiarism analysis, Authorship identification, and Near-duplicate detection forum (PAN) in English and Spanish languages for gender and language variety predictions, and the Kaggle Myers–Briggs-type indicator (MBTI) dataset for personality forecasting. Our proposal consistently surpasses all other deep learning methods in PAN collections by as much as 2.4\%, and up to 3.4\% in the MBTI dataset. These results suggest that this DL strategy effectively addresses and improves upon the limitations of previous techniques and paves the way for new avenues of inquiry.},
  archive      = {J_NCA},
  author       = {López-Santillán, Roberto and González, Luis C. and Montes-y-Gómez, Manuel and López-Monroy, A. Pastor},
  doi          = {10.1007/s00521-023-08198-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9607-9626},
  shortjournal = {Neural Comput. Appl.},
  title        = {When attention is not enough to unveil a text’s author profile: Enhancing a transformer with a wide branch},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive receptive field u-shaped temporal convolutional
network for vulgar action segmentation. <em>NCA</em>, <em>35</em>(13),
9593–9606. (<a
href="https://doi.org/10.1007/s00521-022-08190-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporally detecting and classifying action segments in untrimmed videos are significant for many applications, especially for the detection of vulgar actions such as sucking and caressing in video platform supervision and surveillance applications. At present, vulgar action segmentation has problems such as fuzzy spatial features and complex temporal features of the video, which affect the detection accuracy. Therefore, this paper proposed an effective Adaptive receptive field U-shaped Temporal Convolutional Network (AU-TCN) for the automatic and accurate detection of vulgar actions in the video. Firstly, considering that the current temporal convolutional network has a significant effect on temporal feature extraction, AU-TCN uses the adaptive receptive field convolution kernel to solve the problem of large differences in the average duration between different types of actions in the Internet videos and then realize the temporal attention mechanism. Secondly, the U-shaped structure based on the temporal convolutional network is introduced to effectively analyze both high-level and low-level temporal features of the model, to solve the problem that the spatial features of vulgar actions are not obvious. Finally, extensive experiments on multiple data sets, including public datasets and a self-built vulgar dataset, verify the effectiveness of the proposed model. Our method achieves state-of-the-art results on the vulgar action dataset. This is of great significance to the purification of the Internet environment.},
  archive      = {J_NCA},
  author       = {Cao, Jin and Xu, Ran and Lin, Xinnan and Qin, Feiwei and Peng, Yong and Shao, Yanli},
  doi          = {10.1007/s00521-022-08190-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9593-9606},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive receptive field U-shaped temporal convolutional network for vulgar action segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TA-GAN: Transformer-driven addiction-perception generative
adversarial network. <em>NCA</em>, <em>35</em>(13), 9579–9591. (<a
href="https://doi.org/10.1007/s00521-022-08187-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of addiction-related brain connections using functional magnetic resonance imaging (fMRI) is essential for comprehending the mechanisms of addiction. However, it is a challenge to effectively identify addiction-related brain connections using fMRI for traditional methods. In this work, the transformer-driven addiction-perception generative adversarial network (TA-GAN) is proposed to identify brain connectivity associated with nicotine addiction. In particular, the generator of TA-GAN takes into account that the convolutional neural network (CNN) can capture the local spatial features between brain regions, while the transformer specializes in extracting global brain connectivity information. Specifically, the external encoder-decoder structure aims to extract and reconstruct representations of brain region features. The transformer structure is implemented to extract global dependencies between brain region features. The discriminator is frequently overfitting when Generative Adversarial Networks (GANs) are trained with insufficient data. We proposed an adaptive discriminator enhancement mechanism that allows the discriminator to acquire addiction-related brain connections with limited data volume efficiently. Validation results on rat nicotine addiction data show that our proposed method achieves promising results in both qualitative and quantitative measurements.},
  archive      = {J_NCA},
  author       = {Jing, Changhong and Gong, Changwei and Chen, Zuxin and Lei, Baiying and Wang, Shuqiang},
  doi          = {10.1007/s00521-022-08187-0},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9579-9591},
  shortjournal = {Neural Comput. Appl.},
  title        = {TA-GAN: Transformer-driven addiction-perception generative adversarial network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emotion classification of indonesian tweets using
bidirectional LSTM. <em>NCA</em>, <em>35</em>(13), 9567–9578. (<a
href="https://doi.org/10.1007/s00521-022-08186-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion classification can be a powerful tool to derive narratives from social media data. Traditional machine learning models that perform emotion classification on Indonesian Twitter data exist but rely on closed-source features. Recurrent neural networks can meet or exceed the performance of state-of-the-art traditional machine learning techniques using exclusively open-source data and models. Specifically, these results show that recurrent neural network variants can produce more than an 8\% gain in accuracy in comparison with logistic regression and SVM techniques and a 15\% gain over random forest when using FastText embeddings. This research found a statistical significance in the performance of a single-layer bidirectional long short-term memory model over a two-layer stacked bidirectional long short-term memory model. This research also found that a single-layer bidirectional long short-term memory recurrent neural network met the performance of a state-of-the-art logistic regression model with supplemental closed-source features from a study by Saputri et al. [8] when classifying the emotion of Indonesian tweets.},
  archive      = {J_NCA},
  author       = {Glenn, Aaron and LaCasse, Phillip and Cox, Bruce},
  doi          = {10.1007/s00521-022-08186-1},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9567-9578},
  shortjournal = {Neural Comput. Appl.},
  title        = {Emotion classification of indonesian tweets using bidirectional LSTM},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Skeleton-based tai chi action segmentation using trajectory
primitives and content. <em>NCA</em>, <em>35</em>(13), 9549–9566. (<a
href="https://doi.org/10.1007/s00521-022-08185-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing and analyzing human action is an important problem in many applications. Most studies focus on single motions, but human activity usually appears as a complex action sequence. The attendant problem is that segmenting and labeling action data manually is expensive and time-consuming, especially motions in professional fields. In this paper, we introduce Tai Chi as the background of action segmentation and propose a supervised method for Tai Chi action sequence segmentation based on trajectory primitives and geometric features. The concept of trajectory primitives is inspired by how humans recognize actions based on action fragments. They can be learned by unsupervised clustering through the self-organizing feature map. Also, we extract geometric features based on the content of motion. The work contains an experimental analysis of the proposed method on the Tai Chi dataset. In the experiment, we argued various parameters and considered the abnormal sequences. Experimental results demonstrate that our method achieves state-of-the-art performance. To allow future use by interested researchers, we release the Tai Chi dataset used in this paper.},
  archive      = {J_NCA},
  author       = {Xu, Leiyang and Wang, Qiang and Lin, Xiaotian and Yuan, Lin and Ma, Xiang},
  doi          = {10.1007/s00521-022-08185-2},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9549-9566},
  shortjournal = {Neural Comput. Appl.},
  title        = {Skeleton-based tai chi action segmentation using trajectory primitives and content},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based image analysis method for estimation of
macroscopic spray parameters. <em>NCA</em>, <em>35</em>(13), 9535–9548.
(<a href="https://doi.org/10.1007/s00521-022-08184-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spray strategies contribute to the overall engine efficiency, combustion process, and reduction of pollutant formation in internal combustion engines with direct rail injection systems. Spray shape is determined by several parameters such as nozzle diameter, injection pressure, injector geometry, and cylinder type, which influence spray macroscopic parameters. The spray macroscopic parameters are commonly used to describe the input parameters of numerical simulations. Three main spray macroscopic parameters are spray cone angle, penetration length, and spray area. In this paper, we propose a method for spray macroscopic parameter estimation that achieves the state-of-the-art results. To obtain these results, image segmentation was performed to separate the spray from the rest of the image. Then the spray macroscopic parameters are estimated from the segmented image. To perform image segmentation Min U-Net is used. Min U-Net is a novel lightweight deep learning neural network based on U-Net. Min U-Net achieves the state-of-the-art segmentation results while having more than 500 times fewer parameters and being at least twice as fast as other learning-based methods. To evaluate the proposed method, an available dataset containing a variety of images with various spray shapes and orientations. The experiments performed on the dataset showed that Min U-Net achieved a mean dice coefficient of 0.95 with an inference time of 11.94 ms/image. The spray macroscopic parameters estimation is also highly accurate, with spray cone angle having an error of 1.08 $$^{\circ }$$ , spray penetration length having a relative error of 5.95\%, and spray area having a relative error of 4.05\%.},
  archive      = {J_NCA},
  author       = {Huzjan, Fran and Jurić, Filip and Lončarić, Sven and Vujanović, Milan},
  doi          = {10.1007/s00521-022-08184-3},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9535-9548},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based image analysis method for estimation of macroscopic spray parameters},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). State-of-the-art session key generation on priority-based
adaptive neural machine (PANM) in telemedicine. <em>NCA</em>,
<em>35</em>(13), 9517–9533. (<a
href="https://doi.org/10.1007/s00521-022-08169-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telemedicine is one of the safest methods to provide healthcare facilities to the remote patients with the help of digitization. In this paper, state-of-the-art session key has been proposed based on the priority oriented neural machines followed by its validation. State-of-the-art technique can be mentioned as newer scientific method. Soft computing has been extensively used and modified here under the ANN domain. Telemedicine facilitates secure data communication between the patients and the doctors regarding their treatments. The best fitted hidden neuron can contribute only in the formation of the neural output. Minimum correlation was taken into consideration under this study. Hebbian learning rule was applied on both the patient’s neural machine and the doctor’s neural machine. Lesser iterations were needed in the patient’s machine and the doctor’s machine for the synchronization. Thus, the key generation time has been shortened here which were 4.011 ms, 4.324 ms, 5.338 ms, 5.691 ms, and 6.105 ms for 56 bits, 128 bits, 256 bits, 512 bits, and 1024 bits of state-of-the-art session keys, respectively. Statistically, different key sizes of the state-of-the-art session keys were tested and accepted. Derived value-based function had yielded successful outcomes too. Partial validations with different mathematical hardness had been imposed here too. Thus, the proposed technique is suitable for the session key generation and authentication in the telemedicine in order to preserve the patients’ data privacy. This proposed method has been highly protective against numerous data attacks inside the public networks. Partial transmission of the state-of-the-art session key disables the intruders to decode the same bit patterns of the proposed set of keys.},
  archive      = {J_NCA},
  author       = {Dey, Joydeep},
  doi          = {10.1007/s00521-022-08169-2},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9517-9533},
  shortjournal = {Neural Comput. Appl.},
  title        = {State-of-the-art session key generation on priority-based adaptive neural machine (PANM) in telemedicine},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurodynamic approaches with derivative feedback for sparse
signal reconstruction. <em>NCA</em>, <em>35</em>(13), 9501–9515. (<a
href="https://doi.org/10.1007/s00521-022-08166-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the reconstruction issue of sparse signal by developing centralized and distributed neurodynamic approaches. An $$ l_{1} $$ -minimization problem can be employed for reconstructing sparse signal, and for solving this problem, a centralized neurodynamic approach with derivative feedback is designed. Considering the fact that the distributed approaches decompose the large-scale problem into small-scale one without central processing node in centralized ones, it effectively reduces the computational complexity of a single node. According to the distributed consensus and graph theory, the original $$ l_{1} $$ -minimization problem can be equivalently transformed as a distributed optimization problem. Then, based on our proposed centralized approach, a distributed neurodynamic approach with derivative feedback is further proposed. Through the convex optimization theory and Lyapunov method, we indicate that the optimal solution of $$ l_{1} $$ -minimization problem is equivalent to the equilibrium point of centralized or distributed approach, and that each neurodynamic approach globally converges to its equilibrium point. Furthermore, by comparing with several state-of-the-art neurodynamic approaches, our proposed approaches demonstrate their effectiveness and superiority by simulation results in reconstructing sparse signals and images.},
  archive      = {J_NCA},
  author       = {Zhou, Xian and Zhao, You and Zheng, Hongying and Liao, Xiaofeng},
  doi          = {10.1007/s00521-022-08166-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9501-9515},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neurodynamic approaches with derivative feedback for sparse signal reconstruction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Spatial-aware topic-driven-based image chinese caption for
disaster news. <em>NCA</em>, <em>35</em>(13), 9481–9500. (<a
href="https://doi.org/10.1007/s00521-022-08072-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically generating descriptions for disaster news images could effectively accelerate the spread of disaster message and lighten the burden of news editors from tedious news materials. Image caption algorithms are remarkable for generating captions directly from the content of the image. However, current image caption algorithms trained on existing image caption datasets fail to describe the disaster images with fundamental news elements. In this paper, we developed a large-scale disaster news image Chinese caption dataset (DNICC19k), which collected and annotated enormous news images related to disaster. Furthermore, we proposed a spatial-aware topic driven caption network (STCNet) to encode the interrelationships between these news objects and generate descriptive sentences related to news topics. STCNet firstly constructs a graph representation based on objects feature similarity. The graph reasoning module uses the spatial information to infer the weights of aggregated adjacent nodes according to a learnable Gaussian kernel function. Finally, the generation of news sentences are driven by the spatial-aware graph representations and the news topics distribution. Experimental results demonstrate that STCNet trained on DNICC19k could not only automatically creates descriptive sentences related to news topics for disaster news images, but also outperforms benchmark models such as Bottom-up, NIC, Show attend and AoANet on multiple evaluation metrics, achieving CIDEr/BLEU-4 scores of 60.26 and 17.01, respectively.},
  archive      = {J_NCA},
  author       = {Zhou, Jinfei and Zhu, Yaping and Zhang, Yana and Yang, Cheng and Pan, Hong},
  doi          = {10.1007/s00521-022-08072-w},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9481-9500},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatial-aware topic-driven-based image chinese caption for disaster news},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Class-guided human motion prediction via
multi-spatial-temporal supervision. <em>NCA</em>, <em>35</em>(13),
9463–9479. (<a
href="https://doi.org/10.1007/s00521-023-08362-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important and challenging task in computer vision, human motion prediction aims to predict the future human motion sequence from a given historical sequence. Though the existing works can perform well with a well-designed network, they fail to exploit the semantic information within the input sequences. Inspired by the observation that the human motion sequence strongly correlates with the semantic class, we propose a class-guided network to predict future human poses. Specifically, the semantic class of the historical motion sequence is integrated as an elaborate class-guided loss function, which guides the network to predict the semantic-specific poses. Furthermore, we devise two extra spatial-temporal supervision signals to improve the stability and smoothness of the predicted motion sequence: the spatial multi-scale loss can promote the stability by minimizing the difference between the predictions and the groundtruth at multiple scales; and the multi-temporal loss can enhance the smoothness by narrowing the kinetics difference of human motion sequences. The experimental results on two benchmark datasets (i.e., Human3.6M and CMU Mocap) demonstrate that the proposed supervisions can effectively improve the prediction accuracy, and our method leads to a new state-of-the-art performance. Our code is available at https://github.com/cobblestones/CGHMP .},
  archive      = {J_NCA},
  author       = {Li, Jinkai and Pan, Honghu and Wu, Lian and Huang, Chao and Luo, Xiaoling and Xu, Yong},
  doi          = {10.1007/s00521-023-08362-x},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9463-9479},
  shortjournal = {Neural Comput. Appl.},
  title        = {Class-guided human motion prediction via multi-spatial-temporal supervision},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of sentiment analysis from film critics based on
machine learning, lexicon and hybridization. <em>NCA</em>,
<em>35</em>(13), 9437–9461. (<a
href="https://doi.org/10.1007/s00521-023-08359-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research and developments in the field of Sentiment Analysis (SA) have made it possible to simplify the detection and classification of sentiments from the textual content. This type of analysis classifies the text according to its positive, negative, or neutral polarity. Recently, researchers have focused on film reviews and aim to extract personal information about text reviews that can, for example, be used to determine the listener’s position on a number of different topics. The main contributions, proposed in the literature, focused on three categories of approaches: (i) a first category based on the lexicon, (ii) a second category based on machine learning, and (iii) a third based on a hybridization of the two previous categories. To our knowledge, and until the elaboration of this study, no previous study has examined the approaches and levels of sentiment in the field of film reviews. In this article, we propose to review and analyze the main works in this field. We begin by giving a methodological review of our study. Then, we present a taxonomy on the domain of sentiment analysis and a generic view of the main families of sentiment classification techniques. As a next step, we describe the different levels of sentiment analysis considered in the literature, then we expose the process of pre-processing, extracting, and selecting the characteristics necessary for the sentiment analysis. We then propose an analysis and a discussion of the results of the main works studied on sentiment analysis. This presentation will then be followed by a discussion of some research questions and a proposal for a number of future directions in this area that we believe are essential to contribute to solving the problem addressed in this article.},
  archive      = {J_NCA},
  author       = {Jassim, Mustafa Abdalrassual and Abd, Dhafar Hamed and Omri, Mohamed Nazih},
  doi          = {10.1007/s00521-023-08359-6},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9437-9461},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey of sentiment analysis from film critics based on machine learning, lexicon and hybridization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive resource allocation in 5G CP-OFDM systems using
markovian model-based reinforcement learning algorithm. <em>NCA</em>,
<em>35</em>(13), 9421–9435. (<a
href="https://doi.org/10.1007/s00521-023-08406-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an adaptive resource allocation algorithm based on reinforcement learning is proposed for multicarrier communication systems that consider multiple users and multipath channel characteristics assuming propagation of millimeter waves. An adaptive Markovian model represented by the queueing states in buffers and the channel states is proposed to describe the Cyclic Prefix—Orthogonal Frequency Division Multiplexing (CP-OFDM) communication system. Novel utility functions for the Markovian model-based Q-learning algorithm are introduced and evaluated. The performance of the proposed adaptive resource allocation scheme based on Markovian model reinforcement learning is verified via computational simulations considering real traffic traces. The simulation results show that the application of the proposed resource scheduling algorithm provides general improvements in the communication system performance parameters such as increased throughput and decreased packet loss when using the reward function proposals and increased energy efficiency for one of the proposed reward functions when compared to some algorithms present in the literature. Simulation results confirm that the proposed reward functions in conjunction with the Markov model make the scheduling of users and the sharing of resources more efficient for millimeter-wave-based CP-OFDM networks than traditional Q-learning-based algorithms.},
  archive      = {J_NCA},
  author       = {Carneiro, Daniel P. Q. and Cardoso, Alisson A. and Vieira, Flávio H. T.},
  doi          = {10.1007/s00521-023-08406-2},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9421-9435},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive resource allocation in 5G CP-OFDM systems using markovian model-based reinforcement learning algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An embedding-based non-stationary fuzzy time series method
for multiple output high-dimensional multivariate time series
forecasting in IoT applications. <em>NCA</em>, <em>35</em>(13),
9407–9420. (<a
href="https://doi.org/10.1007/s00521-022-08120-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the internet of things (IoT), high-dimensional time series data are generated continuously and recorded from different data sources; moreover, these time series are characterized by intrinsic changes known as concept drifts. Beside, decision-making in IoT applications may often involve multiple factors and criteria. Therefore, methods capable of handling high-dimensional non-stationary time series and many outputs are of great value in IoT applications. An important gap in the literature is the absence of fuzzy time series (FTS) multiple-input multiple-output (MIMO) methods. To fill this gap, we present a new methodology for forecasting high-dimensional non-stationary time series called MO-ENSFTS (multiple output embedding non-stationary fuzzy time series). MO-ENSFTS is a first-order MIMO multivariate model. We apply a combination of data embedding transformation and a non-stationary FTS model. We tested the proposed methodology on four real-world high-dimensional IoT time-series data sets. The proposed approach is a data-driven method, which is flexible and adaptable for many IoT applications. The computational results show that the proposed method outperforms recurrent neural networks, random forests and support vector regression methods, and is more parsimonious than deep learning methods.},
  archive      = {J_NCA},
  author       = {Bitencourt, Hugo Vinicius and Orang, Omid and de Souza, Luiz Augusto Facury and Silva, Petrônio C. L. and Guimarães, Frederico Gadelha},
  doi          = {10.1007/s00521-022-08120-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9407-9420},
  shortjournal = {Neural Comput. Appl.},
  title        = {An embedding-based non-stationary fuzzy time series method for multiple output high-dimensional multivariate time series forecasting in IoT applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Embedding generation for text classification of brazilian
portuguese user reviews: From bag-of-words to transformers.
<em>NCA</em>, <em>35</em>(13), 9393–9406. (<a
href="https://doi.org/10.1007/s00521-022-08068-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is a natural language processing (NLP) task relevant to many commercial applications, like e-commerce and customer service. Naturally, classifying such excerpts accurately often represents a challenge, due to intrinsic language aspects, like irony and nuance. To accomplish this task, one must provide a robust numerical representation for documents, a process known as embedding. Embedding represents a key NLP field nowadays, having faced a significant advance in the last decade, especially after the introduction of the word-to-vector concept and the popularization of Deep Learning models for solving NLP tasks, including Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformer-based Language Models (TLMs). Despite the impressive achievements in this field, the literature coverage regarding generating embeddings for Brazilian Portuguese texts is scarce, especially when considering commercial user reviews. Therefore, this work aims to provide a comprehensive experimental study of embedding approaches targeting a binary sentiment classification of user reviews in Brazilian Portuguese. This study includes from classical (Bag-of-Words) to state-of-the-art (Transformer-based) NLP models. The methods are evaluated with five open-source databases with pre-defined data partitions made available in an open digital repository to encourage reproducibility. The Fine-tuned TLMs achieved the best results for all cases, being followed by the Feature-based TLM, LSTM, and CNN, with alternate ranks, depending on the database under analysis.},
  archive      = {J_NCA},
  author       = {Souza, Frederico Dias and Filho, João Baptista de Oliveira e Souza},
  doi          = {10.1007/s00521-022-08068-6},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9393-9406},
  shortjournal = {Neural Comput. Appl.},
  title        = {Embedding generation for text classification of brazilian portuguese user reviews: From bag-of-words to transformers},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised learning for MALDI–TOF mass spectrometry
data classification: An application in the salmon industry.
<em>NCA</em>, <em>35</em>(13), 9381–9391. (<a
href="https://doi.org/10.1007/s00521-023-08333-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MALDI–TOF mass spectrometry (Matrix-Assisted Laser Desorption-Ionization (MALDI) and a Time-of-Flight detector (TOF) is a promising strategy for identifying patterns in data, establishing a relevant methodology for rapid and accurate microorganisms identification. However, this type of data is challenging to analyze due to its high complexity, and sometimes it is impossible to make a correct labeling. To address this problem, advanced data analysis techniques such as machine learning methods can be applied. In this work, we propose a novel approach using the semi-supervised paradigm for classifying MALDI–TOF mass spectrometry data. In addition, our study considers the use of labeled and unlabeled data to alleviate the issue of data labeling. Specifically, mass spectrometry data of healthy and infected salmon with the Piscirickettsia salmonis pathogen was analyzed. Our proposed algorithm based on self-training showed superior performance compared to traditional ML methods (NB, RF, SVM). Even considering a small percentage of labeled instances (25\%), semi-supervised learning attains equilibrated performance across all metrics. Experimental results showed that self-training with a random forest classifier reached an accuracy of 0.9, sensitivity of 0.75, and specificity of 1. Furthermore, the feature selection allowed the identification of 15 potential biomarkers that define healthy and infected salmon profiles accurately. From a more general perspective, these results demonstrate the potential of the proposed semi-supervised learning methodology for classifying MALDI–TOF mass spectrometry data.},
  archive      = {J_NCA},
  author       = {González, Camila and Astudillo, César A. and López-Cortés, Xaviera A. and Maldonado, Sebastián},
  doi          = {10.1007/s00521-023-08333-2},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9381-9391},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semi-supervised learning for MALDI–TOF mass spectrometry data classification: An application in the salmon industry},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hierarchical feature selection strategy for deepfake video
detection. <em>NCA</em>, <em>35</em>(13), 9363–9380. (<a
href="https://doi.org/10.1007/s00521-023-08201-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital face manipulation has become a concern in the last few years due to its harmful impacts on society. It is especially concerning for high-profile celebrities because their identities can be easily manipulated using mobile or web applications such as FaceSwap and FaceApp. These manipulated faces are so close to real ones that it becomes really hard to detect them, even with bare eyes. Though deep learning-based models are predominantly used by researchers, they hardly check for the presence of irrelevant or redundant features produced by those models. To this end, we have proposed a hierarchical feature selection (HFS)-based method to detect deepfake images or videos. First, we have extracted both handcrafted and deep learning features from the inputs. Next, the HFS is applied to select a near optimal set of features. In each stage of it, a hybrid feature selection method is employed that integrates a population-based meta-heuristic model, called Grey Wolf Optimization, and a single solution-based meta-heuristic model, called the Vortex Search algorithm. We have evaluated our model on three publicly available datasets, namely Celeb-DF (V2), FaceForensics++, and Deepfake Detection Challenge (DFDC). The model provides 99.35\%, 99.16\%, and 85.67\% AUC scores on the Celeb-DF (V2), FaceForensics++, and DFDC datasets, respectively, while using only 11.50\%, 12.65\%, and 10.22\% of actual features. Besides, our model outperforms most of the state-of-the-art methods found in our literature review and evaluated on these three datasets.},
  archive      = {J_NCA},
  author       = {Mohiuddin, Sk and Sheikh, Khalid Hassan and Malakar, Samir and Velásquez, Juan D. and Sarkar, Ram},
  doi          = {10.1007/s00521-023-08201-z},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9363-9380},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hierarchical feature selection strategy for deepfake video detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid method for fire detection based on spatial and
temporal patterns. <em>NCA</em>, <em>35</em>(13), 9349–9361. (<a
href="https://doi.org/10.1007/s00521-023-08260-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire detection is a vital task for social, economic and environmental reasons. Early identification of fire outbreaks is crucial in order to limit the damage that will be sustained. In open areas, this task is typically performed by humans, e.g., security guards, who are responsible for watching out for possible occurrences. However, people may get distracted, or may not have enough eyesight, which can result in considerable delays in identifying a fire, after much damage has occurred. Thus, the idea of having machines to automatically detect fires has long been considered an interesting possibility. Over the years, different approaches for fire detection have been developed using computer vision. Currently, the most promising ones are based on convolutional neural networks (CNNs). However, smoke and fire, the main visual indicators of wildfires, present additional difficulties for the vast majority of such learning systems. Both smoke and fire have a high intra-class variance, assuming different shapes, colors and textures, which makes the learning process more complicated than for well-defined objects. This work proposes an automatic fire detection method based on both spatial (visual) and temporal patterns. This hybrid method works in two stages: (i) detection of probable fire events by a CNN based on visual patterns (spatial processing) and (ii) analysis of the dynamics of these events over time (temporal processing). Experiments performed on our surveillance video database show that cascading these two stages can reduce the false positive rate with no significant impact either on the true positive rate or the processing time.},
  archive      = {J_NCA},
  author       = {de Venâncio, Pedro Vinícius A. B. and Campos, Roger J. and Rezende, Tamires M. and Lisboa, Adriano C. and Barbosa, Adriano V.},
  doi          = {10.1007/s00521-023-08260-2},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9349-9361},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid method for fire detection based on spatial and temporal patterns},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust handcrafted features for music genre classification.
<em>NCA</em>, <em>35</em>(13), 9335–9348. (<a
href="https://doi.org/10.1007/s00521-022-08069-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When it comes to offering song suggestions to a user, the music genre is one of the most used tags considered by music streaming services. Motivated by the growing number of songs available, automatic music genre classification systems have become a valuable tool for the creation of user-personalised playlists. Considering that feature engineering represents a major task to be addressed when one develops such systems, this work discusses the generation of new handcrafted features over songs, originally exploring high-order features’ moments combined with their derivatives. Additionally, this paper proposes a new wrapper-based selection procedure rigorously based on statistical tests to identify a subset of features that maximise the performance of these systems, irrespective of the classification approach adopted, named Robust Selector of Basis Feature Sets. Based on a synergistic combination of both strategies, a compact subset with 81 features is derived over the GTZAN Dataset. When compared with alternative solutions, this feature set boosted the classification accuracy in datasets containing a wide range of music genres, such as ISMIR2004, BALLROOM, HOMBURG, and FMA Datasets.},
  archive      = {J_NCA},
  author       = {da Silva Muniz, Victor Hugo and de Oliveira e Souza Filho, João Baptista},
  doi          = {10.1007/s00521-022-08069-5},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9335-9348},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust handcrafted features for music genre classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contextual word embeddings for tabular data search and
integration. <em>NCA</em>, <em>35</em>(13), 9319–9333. (<a
href="https://doi.org/10.1007/s00521-022-08066-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach to retrieve and further integrate tabular datasets (collections of rows and columns) using union and join operations. In this work, both processes were carried out using a similarity measure based on contextual word embeddings, which allows finding semantically similar tables and overcome the recall problem of lexical approaches based on string similarity. This work is the first attempt to use contextual word embeddings in the whole pipeline of table search and integration, including for the first time their use in the join operation. A comprehensive analysis of their performance was carried out on both retrieving and integrating tabular datasets, comparing them with context-free models. Column headings and cell values were used as contextual information and their impact on each task was evaluated. The results revealed that contextual models significantly outperform context-free models and a traditional weighting schema in ad hoc table retrieval. In the data integration task, contextual models also improved the results on union operation compared to context-free approaches.},
  archive      = {J_NCA},
  author       = {Pilaluisa, José and Tomás, David and Navarro-Colorado, Borja and Mazón, Jose-Norberto},
  doi          = {10.1007/s00521-022-08066-8},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9319-9333},
  shortjournal = {Neural Comput. Appl.},
  title        = {Contextual word embeddings for tabular data search and integration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A kaizen programming algorithm for multi-output regression
based on a heterogeneous island model. <em>NCA</em>, <em>35</em>(13),
9299–9317. (<a
href="https://doi.org/10.1007/s00521-023-08335-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes an algorithm to construct multi-output symbolic regression models in a single execution. The algorithm extends the single-output Kaizen programming (KP) to a multi-output KP. KP is a hybrid evolutionary algorithm used to solve symbolic regression problems, without making any prior assumptions on the structure of the models. The extension to multi-output KP is made through an island model (MOKP $$_\mathrm{{IM}}$$ ). The idea behind MOKP $$_\mathrm{{IM}}$$ is to find common terms among the outputs by balancing the solution obtained by each island working independently on a different output, with their cooperation due to the periodic exchange of migrants. In a previous effort, we followed a different approach for extending KP to multi-output scenarios based on using a multi-output linear regression in the linear regression step of the algorithm (MOKP $$_\mathrm{{MLR}}$$ ). A comparative analysis of the performance of MOKP $$_\mathrm{{IM}}$$ with the classical single-output KP, our previous multi-output approach for KP, a multi-output Gaussian Process, and a multi-output decision tree regressor was conducted. The evaluation of algorithms used four different schemes of term sharing; five classical benchmark functions and a chemical process case study were considered for each scheme. The numerical results show that MOKP $$_\mathrm{{IM}}$$ is the best-performing algorithm regarding both the independent analysis of each output and the global analysis of all the outputs together. The proposed algorithm MOKP $$_\mathrm{{IM}}$$ outperformed the other multi-output symbolic regression methods tested in this work. It also obtained competitive results with state-of-the-art methods when the outputs were considered independently.},
  archive      = {J_NCA},
  author       = {Ferreira, Jimena and Torres, Ana Inés and Pedemonte, Martín},
  doi          = {10.1007/s00521-023-08335-0},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9299-9317},
  shortjournal = {Neural Comput. Appl.},
  title        = {A kaizen programming algorithm for multi-output regression based on a heterogeneous island model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature-ranked self-growing forest: A tree ensemble based on
structure diversity for classification and regression. <em>NCA</em>,
<em>35</em>(13), 9285–9298. (<a
href="https://doi.org/10.1007/s00521-023-08202-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree ensemble algorithms, such as random forest (RF), are some of the most widely applied methods in machine learning. However, an important hyperparameter, the number of classification or regression trees within the ensemble must be specified in these algorithms. The number of trees within the ensemble can adversely affect bias or computational cost and should ideally be adapted for each task. For this reason, a novel tree ensemble is described, the feature-ranked self-growing forest (FSF), that allows the automatic growth of a tree ensemble based on the structural diversity of the first two levels of trees’ nodes. The algorithm’s performance was tested with 30 classification and 30 regression datasets and compared with RF. The computational complexity was also theoretically and experimentally analyzed. FSF had a significant higher performance for 57\%, and an equivalent performance for 27\% of classification datasets compared to RF. FSF had a higher performance for 70\% and an equivalent performance for 7\% of regression datasets compared to RF. Computational complexity of FSF was competitive compared to that of other tree ensembles, being mainly dependent on the number of observations within the dataset. Therefore, it can be implied that FSF is a suitable out-of-the-box approach with potential as a tool for feature ranking and dataset’s complexity analysis using the number of trees computed for a particular task. A MATLAB and Python implementation of the algorithm and a working example for classification and regression are provided for academic use.},
  archive      = {J_NCA},
  author       = {Carino-Escobar, Ruben I. and Alonso-Silverio, Gustavo A. and Alarcón-Paredes, Antonio and Cantillo-Negrete, Jessica},
  doi          = {10.1007/s00521-023-08202-y},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9285-9298},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feature-ranked self-growing forest: A tree ensemble based on structure diversity for classification and regression},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Opposite scoring: Focusing the tuning process of
evolutionary calibrator. <em>NCA</em>, <em>35</em>(13), 9269–9283. (<a
href="https://doi.org/10.1007/s00521-023-08203-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics have been successfully applied to solve complex real-world problems in many application domains. Their performance strongly depends on the values of their parameters. Many tuning algorithms have already been proposed to find a set of suitable values. However, the amount of computational time required to obtain these values is usually high. Our objective is to propose a collaborative strategy to: (1) improve the quality of configurations obtained by tuner algorithms and (2) reduce the time consumed in the tuning process. Here, we introduce a novel opposite scoring (OS) strategy that learns from configurations that produce a positive and a negative effect in the target algorithm. However, OS guides its trajectory by choosing parameter configurations that decrease the performance of the target algorithm. For the learning process, OS stores the quality of all the evaluated configurations and computes a score for each value in the visited parameter configurations. Then, OS generates the initial set of configurations for a tuner, where values that obtain a better score will have a higher probability of being part of this set. We evaluate our proposal using the well-known Evolutionary Calibrator (Evoca). Also, we tune three different algorithms: an Ant Colony Optimization algorithm for solving the Multidimensional Knapsack Problem, a Genetic Algorithm for solving landscapes that follow the NK model (N components and degree K), and a Particle Swarm Optimization algorithm for solving continuous optimization problems. Results show that OS-Evoca obtains better quality configurations than Evoca, consuming less computational resources.},
  archive      = {J_NCA},
  author       = {Rojas-Morales, Nicolás and Riff, María-Cristina},
  doi          = {10.1007/s00521-023-08203-x},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9269-9283},
  shortjournal = {Neural Comput. Appl.},
  title        = {Opposite scoring: Focusing the tuning process of evolutionary calibrator},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on latin–american computational intelligence.
<em>NCA</em>, <em>35</em>(13), 9267–9268. (<a
href="https://doi.org/10.1007/s00521-023-08437-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Estevez, Pablo A. and Sbarbaro, Daniel and Curilem, Millaray},
  doi          = {10.1007/s00521-023-08437-9},
  journal      = {Neural Computing and Applications},
  number       = {13},
  pages        = {9267-9268},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on Latin–American computational intelligence},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interactive possibilistic programming approach for green
capacitated vehicle routing problem. <em>NCA</em>, <em>35</em>(12),
9253–9265. (<a
href="https://doi.org/10.1007/s00521-022-08180-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The green capacitated vehicle routing problem (GCVRP) has attracted the attention of many researchers recently, due to the increasing global climate issues. This study presents an interactive fuzzy approach for solving green capacitated vehicle routing problem with imprecise travel time for each vehicle and supplier demands. Triangular fuzzy numbers are proposed for modeling uncertainty, and optimization problem is considered as a bi-objective possibilistic mixed-integer programming (PMIP) model. Possibilistic mixed-integer programming and a fuzzy analytical hierarchical process approach (FAHP) are combined to optimize two objective functions: (1) minimum total fuel consumption and (2) maximum total green score. In the first objective function, the fuel consumption ratio model is used. In this model, the fuel consumption is considered as function of travel time and total load of the vehicle. In the second objective function, suppliers are evaluated in terms of environmental factors with the fuzzy AHP method. The normalized weights are assigned to suppliers as a green score. A conciliating solution is obtained by solving this bi-objective mixed integer programming model. The proposed model and solution approach is applied for an automotive company in Turkey. According to the results obtained, a suggestion for a vehicle routing is proposed.},
  archive      = {J_NCA},
  author       = {Aydinalp Birecik, Zeynep and Özgen, Doğan},
  doi          = {10.1007/s00521-022-08180-7},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9253-9265},
  shortjournal = {Neural Comput. Appl.},
  title        = {An interactive possibilistic programming approach for green capacitated vehicle routing problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New models developed for detection of misconceptions in
physics with artificial intelligence. <em>NCA</em>, <em>35</em>(12),
9225–9251. (<a
href="https://doi.org/10.1007/s00521-023-08414-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Students’ misconceptions of various topics in physics have been investigated by many researchers. The detection of misconceptions is very difficult and takes a long time as a human being. Our aim in the study carried out is to determine the misconceptions of the students regarding the concept of the atom by machine instead of humans. This study proposes two novel methods: the Transformers model and the fastText algorithm, to classify the students’ answers. Since there is currently no Turkish language model for physics-related questions or the physics domain, we trained a transformer model from scratch for this domain using transfer learning and domain adaptation techniques. In the second part of this research, we proposed an unsupervised learning approach to accurately understand and identify the reasons behind the misconceptions. For this purpose, we utilized sentence transformers to obtain vector representation of the sentences with transformer-based denoising autoencoder training. We then used two clustering algorithms: an agglomerative one and a density-based one, to group similar sentences in a high-dimensional vector space. Again, for the first time, the unsupervised transformer-based denoising autoencoder training of the sentence transformers was employed for the Turkish language to provide domain adaptation for sentence transformers. Finally, we compared the human performance (experts’ opinions) and the proposed method results for both the classification and the clustering tasks according to the kappa metric. According to our results, we managed to distinguish misconceptions with a high accuracy of between 0.97 and 1.00 with our proposed methodology.},
  archive      = {J_NCA},
  author       = {Demirezen, Mustafa Umut and Yilmaz, Ozgur and Ince, Elif},
  doi          = {10.1007/s00521-023-08414-2},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9225-9251},
  shortjournal = {Neural Comput. Appl.},
  title        = {New models developed for detection of misconceptions in physics with artificial intelligence},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Velocity pausing particle swarm optimization: A novel
variant for global optimization. <em>NCA</em>, <em>35</em>(12),
9193–9223. (<a
href="https://doi.org/10.1007/s00521-022-08179-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is one of the most well-regard metaheuristics with remarkable performance when solving diverse optimization problems. However, PSO faces two main problems that degrade its performance: slow convergence and local optima entrapment. In addition, the performance of this algorithm substantially degrades on high-dimensional problems. In the classical PSO, particles can move in each iteration with either slower or faster speed. This work proposes a novel idea called velocity pausing where particles in the proposed velocity pausing PSO (VPPSO) variant are supported by a third movement option that allows them to move with the same velocity as they did in the previous iteration. As a result, VPPSO has a higher potential to balance exploration and exploitation. To avoid the PSO premature convergence, VPPSO modifies the first term of the PSO velocity equation. In addition, the population of VPPSO is divided into two swarms to maintain diversity. The performance of VPPSO is validated on forty three benchmark functions and four real-world engineering problems. According to the Wilcoxon rank-sum and Friedman tests, VPPSO can significantly outperform seven prominent algorithms on most of the tested functions on both low- and high-dimensional cases. Due to its superior performance in solving complex high-dimensional problems, VPPSO can be applied to solve diverse real-world optimization problems. Moreover, the velocity pausing concept can be easily integrated with new or existing metaheuristic algorithms to enhance their performances. The Matlab code of VPPSO is available at: https://uk.mathworks.com/matlabcentral/fileexchange/119633-vppso .},
  archive      = {J_NCA},
  author       = {Shami, Tareq M. and Mirjalili, Seyedali and Al-Eryani, Yasser and Daoudi, Khadija and Izadi, Saadat and Abualigah, Laith},
  doi          = {10.1007/s00521-022-08179-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9193-9223},
  shortjournal = {Neural Comput. Appl.},
  title        = {Velocity pausing particle swarm optimization: A novel variant for global optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NeuroGAN: Image reconstruction from EEG signals via an
attention-based GAN. <em>NCA</em>, <em>35</em>(12), 9181–9192. (<a
href="https://doi.org/10.1007/s00521-022-08178-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose an approach to process electroencephalogram (EEG) for a visual perception task for synthesizing the visual stimulus that was shown during the acquisition of EEG (images of objects, digits, and characters). We demonstrate that a cross-modality-based encoder–decoder network shows good performance for image synthesis tasks on simplistic images like digits and characters but fails on complex natural object images. To address this issue, we propose a novel attention &amp; auxiliary classifier-based GAN architecture where the generator itself is a cross-modality-based encoder–decoder network. It generates images along with producing class-specific EEG encoding as a latent representation. In addition to the traditional adversarial loss, we also propose to use perceptual loss and attention modules to generate good-quality images. The performance of the proposed network is measured using two metrics— diversity score and inception score, which quantify the relevance and quality of the reconstructed images, respectively. Experimentation results show that our approach performs better compared to the state-of-the-art for both metrics.},
  archive      = {J_NCA},
  author       = {Mishra, Rahul and Sharma, Krishan and Jha, R. R. and Bhavsar, Arnav},
  doi          = {10.1007/s00521-022-08178-1},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9181-9192},
  shortjournal = {Neural Comput. Appl.},
  title        = {NeuroGAN: Image reconstruction from EEG signals via an attention-based GAN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mapping of water bodies from sentinel-2 images using deep
learning-based feature fusion approach. <em>NCA</em>, <em>35</em>(12),
9167–9179. (<a
href="https://doi.org/10.1007/s00521-022-08177-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As water is considered one of the essential assets of nature, the recognition of the availability of water at a specific location can help government bodies to take necessary action toward water conservation. Monitoring water from satellite images is considered one of the most difficult areas of pattern recognition. In this manner, a novel multi-level feature fusion approach is proposed to predict the pattern of water concerning a specific location to analyze the scale and availability. The proposed framework can access the spatial features from sentinel-2 images by utilizing the concept of structural learning. For evaluating the prediction performance, the calculated outcomes are compared with the traditional and modern pattern recognition approaches. It has been observed that the proposed approach is more robust in terms of pattern analysis as compared to the state-of-the-art approaches. Moreover, the performance of the proposed approach is evaluated on different training and testing ratios such as 70:30, 75:25, and 80:20. In this manner, the calculated outcomes define the pattern recognition efficiency of the proposed approach over the state-of-the-art approaches by achieving 94.51\% of accuracy.},
  archive      = {J_NCA},
  author       = {Manocha, Ankush and Afaq, Yasir and Bhatia, Munish},
  doi          = {10.1007/s00521-022-08177-2},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9167-9179},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mapping of water bodies from sentinel-2 images using deep learning-based feature fusion approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SedimentNet — a 1D-CNN machine learning model for prediction
of hydrodynamic forces in rapidly varied flows. <em>NCA</em>,
<em>35</em>(12), 9145–9166. (<a
href="https://doi.org/10.1007/s00521-022-08176-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In natural free surface flows, sediment particles in the surface layer of a sediment bed are moved and entrained by the fluctuating hydrodynamic forces, such as lift and drag, exerted by the overlying flow. Accurate prediction of near-bed hydrodynamic forces in rapidly varied flows is vital for coastal sediment transport and morphodynamics. Directly measured hydrodynamic forces within the rapidly varied flows over rough bed layer have been limited by previous spatial averaging shear force studies. Therefore, the direct measurements were designed and adapted to estimate tidal bore forces, including longitudinal (drag) and vertical (lift) force on near-bed sediment particle. Specially designed experiments were conducted to measure the instantaneous forces using a highly sensitive force sensor assembled with a target sphere. A novel 1D-CNN model (i.e. SedimentNet) has been developed for the prediction of hydrodynamic forces and compared with existing machine learning models (i.e. Decision Tree (DT), Random Forest (RF), Multilayer Perceptron (MLP), Support Vector Regressor (SVR), XGBoost, $$k$$ -Nearest Neighbour ( $$k$$ -NN)). The parameters affecting near-bed hydrodynamic forces are also analysed. In the context of machine learning, both conventional dataset split and fivefold cross-validation approaches were implemented. The results indicated that the proposed SedimentNet was able to achieve marginally better cross-validation performance (i.e. $${R}^{2}$$ score of 0.77 for drag force, $${R}^{2}$$ score of 0.96 for lift force) for the prediction of drag and lift forces. RF and XGBoost were the second best models with $${R}^{2}$$ score of 0.73 and 0.95 for drag and lift force prediction, respectively. Results also showed the potential of machine learning models for the efficient prediction of complex hydrodynamic forces in a coastal environment. A use-case edge computing solution for the reported machine learning-based prediction of hydrodynamic forces has also been proposed and discussed to demonstrate the practical implementability of the presented research.},
  archive      = {J_NCA},
  author       = {Riaz, Muhammad Zain Bin and Iqbal, Umair and Yang, Shu-Qing and Sivakumar, Muttucumaru and Enever, Keith and Khalil, Usman and Ji, Rong and Miguntanna, Nadeeka Sajeewani},
  doi          = {10.1007/s00521-022-08176-3},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9145-9166},
  shortjournal = {Neural Comput. Appl.},
  title        = {SedimentNet — a 1D-CNN machine learning model for prediction of hydrodynamic forces in rapidly varied flows},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level self-adaptive prototypical networks for few-shot
node classification on attributed networks. <em>NCA</em>,
<em>35</em>(12), 9131–9144. (<a
href="https://doi.org/10.1007/s00521-022-08175-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed networks, such as social networks, citation networks, and traffic networks, are ubiquitous nowadays. Node classification is an essential analysis task on attributed networks that has attracted increasing research attention. However, the conventional node classification methods usually require a large number of labeled training instances, which is labor-consuming and cannot be applied to real-world attributed networks. Thus, various meta-learning methods have been proposed to tackle the problem of insufficient labeled instances. However, few-shot learning for graph-structured data is still under-explored due to two reasons: (1) In the few-shot scenario, equally treating each node makes the model vulnerable to noisy instances; (2) The adjacency matrix and attributed features suffer from the data sparsity and not all dimensions in the feature space are discriminative to support final classification. To solve the above problems, we propose a novel graph meta-learning framework: Multi-Level Self-Adaptive Prototypical Networks (MSPN). The proposed MSPN leverages multi-level adaptive learning to highlight the most expressive nodes and features and rectify the prototype to obtain a more accurate one. The episodic training strategy mimics the real testing scenario and transfers knowledge from previous tasks to unseen target tasks. Extensive experimental results demonstrate that the MSPN is superior to the other methods on few-shot node classification.},
  archive      = {J_NCA},
  author       = {Xu, Xin and Du, Junping and Xue, Zhe},
  doi          = {10.1007/s00521-022-08175-4},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9131-9144},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-level self-adaptive prototypical networks for few-shot node classification on attributed networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust amplitude-limited interval type-3 neuro-fuzzy
controller for robot manipulators with prescribed performance by output
feedback. <em>NCA</em>, <em>35</em>(12), 9115–9130. (<a
href="https://doi.org/10.1007/s00521-022-08174-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new observer-based bounded adaptive fuzzy controller for robotic manipulators with a prescribed performance subjected to uncertainties. To this end, interval type-3 fuzzy logic systems are introduced, and the system uncertainties are roughly modeled by an interval type-3 fuzzy neural network. The proposed controller is designed based on a robust adaptive command-filtered backstepping control scheme. Projection-type adaptive laws and saturation functions are effectively utilized to guarantee that actuator limitations are not violated by calculating the maximum required control signals a priori. The actuator disturbances and external perturbations are compensated by the designed robust control scheme. Furthermore, a high-gain observer is applied to estimate unmeasurable states. To improve the transient performance and to achieve better steady-state tracking errors, the prescribed performance control is suggested. The stability of the suggested closed-loop control system is studied by the Lyapunov theorem, and system signals are proved to be uniformly ultimately bounded. Lastly, simulation results show the potency of the proposed control method.},
  archive      = {J_NCA},
  author       = {Elhaki, Omid and Shojaei, Khoshnam and Mohammadzadeh, Ardashir and Rathinasamy, Sakthivel},
  doi          = {10.1007/s00521-022-08174-5},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9115-9130},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust amplitude-limited interval type-3 neuro-fuzzy controller for robot manipulators with prescribed performance by output feedback},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of pleasant and unpleasant odor imagery EEG
signals. <em>NCA</em>, <em>35</em>(12), 9105–9114. (<a
href="https://doi.org/10.1007/s00521-022-08171-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is a widely used technique that allows researchers to measure neural activity that demonstrates how the human brain reacts to various environmental stimuli or imaginations. In this study, EEG was used to determine the brain’s reactions during the imagination of the most pleasant and unpleasant odors among four kinds of odors, including orange, clove, thyme, and mint. The distinguishability of brain responses to these odors was tested using the Hilbert transform, Fast Walsh–Hadamard transform, band power, and spectrogram image features. The results showed that the Hilbert Transform-based features have great potential to classify the EEG signals recorded during the imagination of the most pleasant and unpleasant odors. The proposed method achieved an average classification accuracy of 87.75\% for the test data with a k-nearest neighbor classifier.},
  archive      = {J_NCA},
  author       = {Naser, Amir and Aydemir, Onder},
  doi          = {10.1007/s00521-022-08171-8},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9105-9114},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of pleasant and unpleasant odor imagery EEG signals},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Severity estimation of brainstem in dementia MR images using
moth flame optimized segmentation and fused deep feature selection.
<em>NCA</em>, <em>35</em>(12), 9093–9104. (<a
href="https://doi.org/10.1007/s00521-022-08167-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dementia is an irreversible chronic neuro-disorder. Prediction of preclinical stages variation in dementia disorder helps to delay the progression. This study attempts to differentiate the brainstem (BS) structures for normal and different demented stages. BS structure is interconnected with many brain cortical structures that help to provide valuable pathological information about atrophy. This work is carried out using ADNI public database. Initially, skull-stripped MR images are used to perform BS segmentation using moth flame optimization-based multilevel Tsallis entropy method. Architecture such as AlexNet, GoogleNet and SqueezeNet is considered to extract features. The fusion of these features provides optimal information about BS structures for preclinical stages. The performance of fused deep features is evaluated using heat map and occlusion sensitivity map. Further, combined feature selection is carried out to extract the most distinct feature set using mutual information, minimum redundancy maximal relevance and recursive feature elimination methods. Finally, the analysis of variance is used to evaluate inter and intra-class variation of the subject. Results indicate that the suggested approach could segment the BS prominently. The correlation value was found to be &gt; 0.97 in all the considered stages. The heatmap and occlusion sensitivity show the fused deep features provide highly discriminative features. The statistical performance of this fused feature set of Normal (CN)/EMCI, CN/EMCI, CN/LMCI, CN/MCI, CN/AD, EMCI/MCI, EMCI/AD, MCI/LMCI, MCI/AD and LMCI/AD shows high significant variation (p &lt; 0.0001). Consequently, this approach captures the complex preclinical stage variation effectively and suitable to reduce the misdiagnosis rates.},
  archive      = {J_NCA},
  author       = {Priyanka, Ahana and Ganesan, Kavitha},
  doi          = {10.1007/s00521-022-08167-4},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9093-9104},
  shortjournal = {Neural Comput. Appl.},
  title        = {Severity estimation of brainstem in dementia MR images using moth flame optimized segmentation and fused deep feature selection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Long-term missing value imputation for time series data
using deep neural networks. <em>NCA</em>, <em>35</em>(12), 9071–9091.
(<a href="https://doi.org/10.1007/s00521-022-08165-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach that uses a deep learning model, in particular, a MultiLayer Perceptron, for estimating the missing values of a variable in multivariate time series data. We focus on filling a long continuous gap (e.g., multiple months of missing daily observations) rather than on individual randomly missing observations. Our proposed gap filling algorithm uses an automated method for determining the optimal MLP model architecture, thus allowing for optimal prediction performance for the given time series. We tested our approach by filling gaps of various lengths (three months to three years) in three environmental datasets with different time series characteristics, namely daily groundwater levels, daily soil moisture, and hourly Net Ecosystem Exchange. We compared the accuracy of the gap-filled values obtained with our approach to the widely used R-based time series gap filling methods ImputeTS and mtsdi. The results indicate that using an MLP for filling a large gap leads to better results, especially when the data behave nonlinearly. Thus, our approach enables the use of datasets that have a large gap in one variable, which is common in many long-term environmental monitoring observations.},
  archive      = {J_NCA},
  author       = {Park, Jangho and Müller, Juliane and Arora, Bhavna and Faybishenko, Boris and Pastorello, Gilberto and Varadharajan, Charuleka and Sahu, Reetik and Agarwal, Deborah},
  doi          = {10.1007/s00521-022-08165-6},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9071-9091},
  shortjournal = {Neural Comput. Appl.},
  title        = {Long-term missing value imputation for time series data using deep neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Streamflow prediction in mountainous region using new
machine learning and data preprocessing methods: A case study.
<em>NCA</em>, <em>35</em>(12), 9053–9070. (<a
href="https://doi.org/10.1007/s00521-022-08163-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate streamflow estimation is crucial for proper water management for irrigation, hydropower, drinking and industrial purposes. The main aim of this study to adopt new data preprocessing techniques (e.g., EMD, EEMD and EWT) to capture the data noise and to enhance the prediction accuracy of machine learning methods for streamflow estimation which is a challenging task in high-altitude basins due to the influence of many external climatic and geographical parameters. The prediction accuracy of support vector regression (SVR), twin support vector machine (T), extreme learning machine (ELM), asymmetric Huber loss function-based ELM (AHELM) and ε-insensitive Huber loss function-based ELM (ε-AHELM) methods are investigated in monthly streamflow prediction. Among the standalone methods, the ε-AHELM performs superior to the SVR, TSVR, ELM, and AHELM in streamflow prediction; improvements in root mean square error are 6.9\%, 4.9\%, 6\% and 4.2\%, respectively. The study outcomes reveal that the preprocessing methods considerably improve the prediction accuracy of the implemented standalone models. Among the data preprocessing techniques, it is found that the EWT outperforms the EMD and EEMD techniques by reducing the prediction errors in the best ε-AHELM, EMD-ε-AHELM and EEMD-ε-AHELM models by 68–61.3\%, 64.7–63.4\% and 59.4–58.6\%, respectively. The overall results of the study recommend the use of EWT-ε-AHELM in streamflow estimation.},
  archive      = {J_NCA},
  author       = {Ikram, Rana Muhammad Adnan and Hazarika, Barenya Bikash and Gupta, Deepak and Heddam, Salim and Kisi, Ozgur},
  doi          = {10.1007/s00521-022-08163-8},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9053-9070},
  shortjournal = {Neural Comput. Appl.},
  title        = {Streamflow prediction in mountainous region using new machine learning and data preprocessing methods: A case study},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spiking neural p system with weight model of majority voting
technique for reliable interactive image segmentation. <em>NCA</em>,
<em>35</em>(12), 9035–9051. (<a
href="https://doi.org/10.1007/s00521-022-08162-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive image segmentation is a method for precisely segmenting of the object from background using information entered by the user. However, most interactive segmentation techniques are sensitive to the location and the number of seed points. To obtain a satisfactory result, the user should repeat the segmentation process over and over, and also based on employed technique, it may work well in some limited conditions and applications. To overcome these limitations and enhance the robustness of interactive image segmentation algorithm, this paper proposes a parallel fusion model using the majority voting technique, which not only is more reliable than existing methods, but also requires less user interaction. To this end, at first the input image is segmented by several segmentation methods independently. Then the obtained results are combined using majority voting technique to extract final segmentation result. To reduce the computational overhead of the proposed scheme, a spiking neural-like P system model for parallel implementation of majority voting technique is also proposed. The proposed model has been evaluated and compared with state-of-the-art methods using different metrics, and the obtained results show its efficiency compared to other methods.},
  archive      = {J_NCA},
  author       = {Dalvand, Mehran and Fathi, Abdolhossein and Kamran, Arezoo},
  doi          = {10.1007/s00521-022-08162-9},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9035-9051},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spiking neural p system with weight model of majority voting technique for reliable interactive image segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OQCNN: Optimal quantum convolutional neural network for
classification of facial expression. <em>NCA</em>, <em>35</em>(12),
9017–9033. (<a
href="https://doi.org/10.1007/s00521-022-08161-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotions play a vital role in developing social interaction as well as interpersonal relationships. It is because humans express and convey their thoughts and feelings visually rather than using verbal communication. Recently, facial expression recognition is greatly adopted in the emerging human–computer interaction and human–robot interaction technologies. Although humans can identify facial emotions virtually, the reliable automated recognition of facial expressions becomes a complicated task. The main intention of this paper is to develop an automated facial expression recognition system. To attain the goal, in this work, an improved particle swarm optimization bat tracking search algorithm optimized quantum convolutional neural network (IPSOBSA-QCNN) approach is proposed to accurately identify and classify facial expressions such as fear, happy, disgust, sad, surprise, negative, positive, and dominated. Although classification performance is limited by hyperparameter tuning concerns, the QCNN system efficiently recognizes face expressions at a high processing speed. Therefore, the hyperparameters of the quantum convolutional neural network (QCNN) are optimized to enhance the classification accuracy using the improved particle swarm optimization backtracking search algorithm (IPSOBSA). The proposed IPSOBSA-QCNN approach is evaluated using three diverse datasets namely the real-world affective faces dataset, the Emotic dataset, and the facial expression comparison dataset. The effectiveness of the proposed approach is determined by comparing the proposed IPSOBSA-QCNN approach with other existing methods using different evaluation metrics. The experimental results display that the proposed IPSOBSA-QCNN approach achieves higher classification accuracy of about 98\% for the real-world affective faces dataset, 97.5\% for the Emotic dataset, and 97\% for the facial expression comparison dataset.},
  archive      = {J_NCA},
  author       = {Sathya, T. and Sudha, S.},
  doi          = {10.1007/s00521-022-08161-w},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9017-9033},
  shortjournal = {Neural Comput. Appl.},
  title        = {OQCNN: Optimal quantum convolutional neural network for classification of facial expression},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How visual chirality affects the performance of image
hashing. <em>NCA</em>, <em>35</em>(12), 9003–9016. (<a
href="https://doi.org/10.1007/s00521-022-08141-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual chirality reveals the phenomenon that chiral data will present different semantics after flipping. Although image flipping is widely used in image hashing learning as a data augmentation technique, the effect of learning chiral image data on hashing performance has not been fully discussed. To explore this issue, this paper first designs an approach to recognize images with chiral cues, then constructs the chiral datasets including different proportions of images with chiral cues, and finally analyzes and discusses the performance change via testing three representative image hashing methods with different hash code lengths on constructed chiral datasets. In addition, to understand the effect of visual chirality from an internal perspective, we illustrate visual results of activated regions between some original images with chiral cues and their flipped ones. We conduct the above experiments on three public image datasets including VOC2007, MS-COCO, and NUS-WIDE. Experimental results reveal that different proportions of chiral data will greatly affect the performance of image hashing and the best performance appears when the proportion of images with chiral cues accounts for 15\% $$\sim$$ 25\% or 75\% $$\sim$$ 85\%. The code of this work is released at: https://github.com/lzHZWZ/Visual_Chirality_Hashing .},
  archive      = {J_NCA},
  author       = {Xie, Yanzhao and Hu, Guangxing and Liu, Yu and Lin, Zhiqiu and Zhou, Ke and Zhao, Yuhong},
  doi          = {10.1007/s00521-022-08141-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {9003-9016},
  shortjournal = {Neural Comput. Appl.},
  title        = {How visual chirality affects the performance of image hashing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reinforced CenterNet scheme on position detection of
acoustic levitated objects. <em>NCA</em>, <em>35</em>(12), 8987–9002.
(<a href="https://doi.org/10.1007/s00521-022-08140-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Position detection is essential for precise contactless manipulation as it can play an important role in analyzing the behavior patterns and motion regularities of levitated objects. However, traditional detection methods have several limitations, such as finite feature representation, low detection accuracy, and poor adaptability, notably for small targets. To address these issues, this paper proposes an effective detector called RFRM-CenterNet, which is the first attempt to detect the location of levitated objects based on a convolutional neural network. First, a receptive field refinement module consisting of multi-stage parallel dilated convolutional layers is designed to detect small levitated objects. Then, to increase the feature representation capability, a feature fusion network is designed, which employs a parallel fusion of ResNet50 and a receptive field refinement module. In addition, an experimental system is constructed, and a dataset is established to train the model and verify the performance of the proposed method. The experimental results show that RFRM-CenterNet has better performance in detecting levitated objects than other detection methods.},
  archive      = {J_NCA},
  author       = {Li, Xinbo and Wang, Yingwei and Jiang, Liangxu and Chen, Ziyi and Fan, Shuyuan},
  doi          = {10.1007/s00521-022-08140-1},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8987-9002},
  shortjournal = {Neural Comput. Appl.},
  title        = {A reinforced CenterNet scheme on position detection of acoustic levitated objects},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-cohort whale optimization with search space tightening
for engineering optimization problems. <em>NCA</em>, <em>35</em>(12),
8967–8986. (<a
href="https://doi.org/10.1007/s00521-022-08139-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms have been widely studied and shown to be suitable for solving various engineering optimization problems. This paper presents a novel variant of the whale optimization algorithm known as multi-cohort whale optimization algorithm to solve engineering optimization problems. The new algorithm improves the existing whale optimization by dividing the population in to cohorts and introduces a separate exploration procedure for each cohort. Also, a new boundary update procedure for the search space is introduced. In addition to this, opposition-based initialization and elitism are employed to aid quick convergence of the algorithm. The proposed algorithm is compared with whale optimization algorithm variants and other metaheuristic algorithms for different numerical optimization problems. Statistical analysis is performed to ensure the significance of the proposed algorithm. In addition to this, the proposed and existing algorithms are studied based on three engineering optimization problems. The analyses show that the proposed algorithm achieves 53.75\% improvement in average fitness when compared to the original whale optimization algorithm.},
  archive      = {J_NCA},
  author       = {Rajmohan, Shathanaa and Elakkiya, E. and Sreeja, S. R.},
  doi          = {10.1007/s00521-022-08139-8},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8967-8986},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-cohort whale optimization with search space tightening for engineering optimization problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clustering unknown network traffic with dual-path
autoencoder. <em>NCA</em>, <em>35</em>(12), 8955–8966. (<a
href="https://doi.org/10.1007/s00521-022-08138-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the proportion of unknown traffic in networks continues to increase. This poses great challenges to the management and security of cyberspace. The unknown traffic refers to network traffic generated by previously unknown protocols in a preconstructed traffic identification system. Measures to address this challenge can be developed by grouping the mixed unknown traffic into multiple clusters, where, ideally, each cluster contains just one traffic class. In this paper, we propose a novel scheme for clustering unknown traffic, named dual-path autoencoder-based clustering, to discover protocol-based traffic classes. The dual-path autoencoder model refers to the combination of convolutional autoencoder and deep autoencoder, which realizes the extraction and aggregation of payload features and statistical features. Then, the fusion feature is clustered by the correlation-adjusted clustering module, and the unknown traffic flows are divided into multiple high-purity clusters. To evaluate our scheme, experiments are conducted on two public network traffic datasets and one campus network dataset. Using seven common application layer protocols to simulate unknown traffic, the evaluation results show that our scheme can achieve above 98\% on each dataset when the preset number of clusters is 60. This establishes the effectiveness of the proposed scheme for clustering unknown network protocols.},
  archive      = {J_NCA},
  author       = {Fu, Yating and Li, Xuan and Li, Xiaofan and Zhao, Shuyuan and Wang, Fengyu},
  doi          = {10.1007/s00521-022-08138-9},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8955-8966},
  shortjournal = {Neural Comput. Appl.},
  title        = {Clustering unknown network traffic with dual-path autoencoder},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network with absent minority class samples and
boundary shifting for imbalanced data classification. <em>NCA</em>,
<em>35</em>(12), 8937–8953. (<a
href="https://doi.org/10.1007/s00521-022-08135-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks handling data imbalance heavily rely on resampling or reweighting strategies. However, existing resampling and reweighting approaches mainly focus on rebalancing known data, which ignore the essence of the data imbalance problem, namely, the problem of insufficient empirical representation of the minority class caused by the small number of samples. Therefore, we propose a new solution for neural networks classifying imbalanced data by sampling absent minority class samples. Specifically, an improved Metropolis Hasting (IMH) algorithm is developed to sample absent minority class samples by collecting samples rejected by the majority class approximation process. The sampled absent minority samples are then provided to neural networks to address the data imbalance problem. For IMH, in order to accelerate the sampling process and reduce the vague class definition of the sampled minority class samples, line segment transition kernel and class probability constraint are proposed. For neural networks, two boundary shifting strategies are supported to operate on different application modes of sampled absent minority class samples. In experiments, the proposed method is validated on 34 imbalanced datasets. Comparable AUC, G-MEAN, and MACC results are achieved. These results demonstrate the effectiveness of sampling absent minority class samples for neural networks solving the imbalanced data problem.},
  archive      = {J_NCA},
  author       = {Huang, Zhan ao and Sang, Yongsheng and Sun, Yanan and Lv, Jiancheng},
  doi          = {10.1007/s00521-022-08135-y},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8937-8953},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network with absent minority class samples and boundary shifting for imbalanced data classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MedGraph: Malicious edge detection in temporal reciprocal
graph via multi-head attention-based GNN. <em>NCA</em>, <em>35</em>(12),
8919–8935. (<a
href="https://doi.org/10.1007/s00521-022-08065-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of various online dating applications, it has become a crucial task to detect anomalous or malicious users from a large number of reciprocal users. Essentially, this task could be converted to a malicious edge detection problem, which is an important yet challenging task due to the following difficulties. First, malicious users may fake their profiles to avoid being detected by the service platform. Second, malicious behaviors, i.e., malicious edges, might vary from time to time which greatly challenges most existing approaches. To address the aforementioned issues, this paper proposes the multi-head attention-based GNN approach to detect malicious edges from a temporal reciprocal graph, called MedGraph. Particularly, the proposed MedGraph approach employs a transformer component to first capture both long-term and short-term behavior characteristics of malicious users from their historical interaction data. Then, a co-attention component is designed to differentiate important features that account for the prediction of malicious edges. We evaluate the proposed approach on two public datasets and one real-world dataset collected by ourselves. The promising results demonstrate that our approach could achieve state-of-the-art performance against a number of both baseline and SOTA approaches with respect to the widely adopted evaluation criteria.},
  archive      = {J_NCA},
  author       = {Chen, Kai and Wang, Ziao and Liu, Kai and Zhang, Xiaofeng and Luo, Linhao},
  doi          = {10.1007/s00521-022-08065-9},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8919-8935},
  shortjournal = {Neural Comput. Appl.},
  title        = {MedGraph: Malicious edge detection in temporal reciprocal graph via multi-head attention-based GNN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social media bot detection with deep learning methods: A
systematic review. <em>NCA</em>, <em>35</em>(12), 8903–8918. (<a
href="https://doi.org/10.1007/s00521-023-08352-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social bots are automated social media accounts governed by software and controlled by humans at the backend. Some bots have good purposes, such as automatically posting information about news and even to provide help during emergencies. Nevertheless, bots have also been used for malicious purposes, such as for posting fake news or rumour spreading or manipulating political campaigns. There are existing mechanisms that allow for detection and removal of malicious bots automatically. However, the bot landscape changes as the bot creators use more sophisticated methods to avoid being detected. Therefore, new mechanisms for discerning between legitimate and bot accounts are much needed. Over the past few years, a few review studies contributed to the social media bot detection research by presenting a comprehensive survey on various detection methods including cutting-edge solutions like machine learning (ML)/deep learning (DL) techniques. This paper, to the best of our knowledge, is the first one to only highlight the DL techniques and compare the motivation/effectiveness of these techniques among themselves and over other methods, especially the traditional ML ones. We present here a refined taxonomy of the features used in DL studies and details about the associated pre-processing strategies required to make suitable training data for a DL model. We summarize the gaps addressed by the review papers that mentioned about DL/ML studies to provide future directions in this field. Overall, DL techniques turn out to be computation and time efficient techniques for social bot detection with better or compatible performance as traditional ML techniques.},
  archive      = {J_NCA},
  author       = {Hayawi, Kadhim and Saha, Susmita and Masud, Mohammad Mehedy and Mathew, Sujith Samuel and Kaosar, Mohammed},
  doi          = {10.1007/s00521-023-08352-z},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8903-8918},
  shortjournal = {Neural Comput. Appl.},
  title        = {Social media bot detection with deep learning methods: A systematic review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analyzing the impact of driving tasks when detecting
emotions through brain–computer interfaces. <em>NCA</em>,
<em>35</em>(12), 8883–8901. (<a
href="https://doi.org/10.1007/s00521-023-08343-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accidents are the leading cause of death among young people, a problem that today costs an enormous number of victims. Several technologies have been proposed to prevent accidents, being brain–computer interfaces (BCIs) one of the most promising. In this context, BCIs have been used to detect emotional states, concentration issues, or stressful situations, which could play a fundamental role in the road since they are directly related to the drivers’ decisions. However, there is no extensive literature applying BCIs to detect subjects’ emotions in driving scenarios. In such a context, there are some challenges to be solved, such as (i) the impact of performing a driving task on the emotion detection and (ii) which emotions are more detectable in driving scenarios. To improve these challenges, this work proposes a framework focused on detecting emotions using electroencephalography with machine learning and deep learning algorithms. In addition, a use case has been designed where two scenarios are presented. The first scenario consists in listening to sounds as the primary task to perform, while in the second scenario listening to sound becomes a secondary task, being the primary task using a driving simulator. In this way, it is intended to demonstrate whether BCIs are useful in this driving scenario. The results improve those existing in the literature, achieving 99\% accuracy for the detection of two emotions (non-stimuli and angry), 93\% for three emotions (non-stimuli, angry and neutral) and 75\% for four emotions (non-stimuli, angry, neutral and joy).},
  archive      = {J_NCA},
  author       = {Quiles Pérez, Mario and Martínez Beltrán, Enrique Tomás and López Bernal, Sergio and Martínez Pérez, Gregorio and Huertas Celdrán, Alberto},
  doi          = {10.1007/s00521-023-08343-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8883-8901},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analyzing the impact of driving tasks when detecting emotions through brain–computer interfaces},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization algorithm of an artificial neural network-based
controller and simulation method for animated virtual idol characters.
<em>NCA</em>, <em>35</em>(12), 8873–8882. (<a
href="https://doi.org/10.1007/s00521-022-07697-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the movement naturalness and coordination of computer animation virtual idol characters, a virtual character interaction control method in virtual rehearsal is analyzed and proposed. Then, an artificial neural network motion controller based on motion capture data is proposed. The motion data are used as a priori information to guide the learning of the virtual character motion controller, and the whole learning process uses a progressive return function. Finally, an artificial neural network motion controller based on motion capture data uses the motion capture data as prior information and constrains the original motion capture data as part of the reward function, thereby limiting the motion pose of the virtual character. The virtual character produces a motion effect consistent with the posture of the original motion data, and the original motion data of different postures are used for experimental analysis. The experimental results show that adding spatiotemporal constraints to the return function can effectively prevent the bad motion posture of virtual characters (half cheetah and hopper) and make their motion more natural. The integration of motion data not only ensures the consistency between synthetic motion and original motion but also accelerates the learning process of network parameters.},
  archive      = {J_NCA},
  author       = {Shi, Yujie and Wang, Baoqing},
  doi          = {10.1007/s00521-022-07697-1},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8873-8882},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization algorithm of an artificial neural network-based controller and simulation method for animated virtual idol characters},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fusion of forehead EEG with machine vision for real-time
fatigue detection in an automatic processing pipeline. <em>NCA</em>,
<em>35</em>(12), 8859–8872. (<a
href="https://doi.org/10.1007/s00521-022-07466-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving fatigue is a leading contributor to traffic accidents and fatalities. For automatic detection of fatigue, multimodal data fusion is a potential key technique, especially the merging of electroencephalogram (EEG) and eye movement. Although EEG can produce objective measures of fatigue with very high temporal resolution, an unfriendly multichannel system limits its practical application while portable wearables and machine vision receive much attention since they are pervasive and user friendly. Hence, this study aims to construct a novel pipeline by using machine vision technique to improve the quality of driver fatigue detection based on forehead EEG. By coupling the Karolinska Sleepiness Scale (KSS) and percentage of eyelid closure (PERCLOS), the precise and reliable dataset for reflecting drivers’ fatigue levels were obtained. Moreover, major artifact contamination related to blink activity for frontal-channel EEG was removed by a synchronous video-based eyeblink event marker. In addition, the scale-invariant feature transform (SIFT) features of eyelid keypoints was applied to fuse with the EEG-driven features. Sixteen subjects participated in a realistic driving simulation experiment. Both machine and deep learning methods were used to implement the intra-subject and inter-subject cross validation. It demonstrated that our proposed method can achieve a significant performance. The present work showed the usefulness of forehead EEG and eye images that was originally merged for detecting fatigue. It provides a new strategy of using forehead EEG combined with machine vision to design a potential and automatic pipeline for driver fatigue detection.},
  archive      = {J_NCA},
  author       = {Min, Jianliang and Cai, Ming and Gou, Chao and Xiong, Chen and Yao, Xuejiao},
  doi          = {10.1007/s00521-022-07466-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8859-8872},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fusion of forehead EEG with machine vision for real-time fatigue detection in an automatic processing pipeline},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection and simulation of quasi random frequency hopping
signal based on interference analysis algorithm. <em>NCA</em>,
<em>35</em>(12), 8847–8858. (<a
href="https://doi.org/10.1007/s00521-022-07802-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information technology, information war is becoming more and more intense. Signal processing plays an increasingly important role in information war, and the application of this technology is becoming more and more extensive. The information signal processed by the traditional frequency hopping communication system is relatively single. When there are a variety of electromagnetic signals, the communication channel environment is complex and there will be signal interference. Therefore, this paper studies the detection, identification, and experimental simulation of quasi-frequency hopping signal under multi-fixed frequency interference. Firstly, this paper uses the short-time Fourier transform and Wigner–Ville time–frequency analysis method to identify and simulate the interference signal of multi-fixed frequency interference. Then, according to the working principle of genetic algorithm, the design steps of radio high frequency (RHF) signal are designed, the signal model is constructed, and the narrowband interference suppression strategy is proposed to suppress the fixed frequency interference signal. According to the simulation of this model in this paper, the suppression effect of time–frequency domain and joint method is more obvious than that of traditional time–frequency domain. If the fixed frequency interference signal only covers a small part or does not cover the quasi random frequency hopping signal, the signal suppression effect of using time–frequency domain to filter the interference signal is better than using non-decimation wavelet packet transform algorithm, and there will be no error impact on the original signal when completely using time–frequency domain to filter the signal. Finally, this paper combines the interference analysis algorithm in time domain and time frequency domain and carries on the simulation analysis. Through the application simulation of multi-target scene, the results show that the complementary code modulation method can estimate the distance and velocity parameters in multi-target scene. Although the velocity measurement range is narrow, this method has the advantages of high velocity measurement accuracy, higher output signal-to-noise ratio and lower computational complexity.},
  archive      = {J_NCA},
  author       = {Nie, Ruirui and Li, Bo},
  doi          = {10.1007/s00521-022-07802-4},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8847-8858},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection and simulation of quasi random frequency hopping signal based on interference analysis algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparative analysis of rail transit braking digital command
control strategies based on neural network. <em>NCA</em>,
<em>35</em>(12), 8833–8845. (<a
href="https://doi.org/10.1007/s00521-022-07552-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An urban subway network system is a complex public transportation system. To compare rail transit braking digital command control strategies based on neural network, this article analyzes and studies the characteristics of subway vehicle driver controllers and their design methods from three aspects: mechanical, electrical and software-assisted design. The learning rule of the BP neural network is called the mentor system learning rule, which is a kind of error-correcting algorithm. In the learning and training process, the expected output value needs to be given. The weights and thresholds of the BP neural network are optimized by selecting the parameters of the SA algorithm. The search method of SA is heuristic, and it has the following advantages: The selection of the initial solution does not affect the optimal solution. The simplified model extracts the core data processing individual analysis. In this paper, the physical data are extracted from the physical entity operation process for analysis, and the twin model is established to extract the twin data for analysis. This paper uses the characteristics of physical data to test the modeling effect and utilizes the twin data to carry out algorithm experiments on physical data. The ultimate goal is to use twin data to predict the state information of physical entities. The network error in the scheme designed by the article is 6\%. The smooth implementation of this research constitutes an important reference for the design of subway train network control systems in other cities in China. Therefore, this research has great application value.},
  archive      = {J_NCA},
  author       = {Fan, Zheyuan and Huang, Darong and Xu, Keqin and Tan, Jin},
  doi          = {10.1007/s00521-022-07552-3},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8833-8845},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparative analysis of rail transit braking digital command control strategies based on neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep q networks-based optimization of emergency resource
scheduling for urban public health events. <em>NCA</em>,
<em>35</em>(12), 8823–8832. (<a
href="https://doi.org/10.1007/s00521-022-07696-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s severe situation of the global new crown virus raging, there are still efficiency problems in emergency resource scheduling, and there are still deficiencies in rescue standards. For the happiness and well-being of people&#39;s lives, adhering to the principle of a community with a shared future for mankind, the emergency resource scheduling system for urban public health emergencies needs to be improved and perfected. This paper mainly studies the optimization model of urban emergency resource scheduling, which uses the deep reinforcement learning algorithm to build the emergency resource distribution system framework, and uses the Deep Q Network path planning algorithm to optimize the system, to achieve the purpose of optimizing and upgrading the efficient scheduling of emergency resources in the city. Finally, through simulation experiments, it is concluded that the deep learning algorithm studied is helpful to the emergency resource scheduling optimization system. However, with the gradual development of deep learning, some of its disadvantages are becoming increasingly obvious. An obvious flaw is that building a deep learning-based model generally requires a lot of CPU computing resources, making the cost too high.},
  archive      = {J_NCA},
  author       = {Zhao, Xianli and Wang, Guixin},
  doi          = {10.1007/s00521-022-07696-2},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8823-8832},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep q networks-based optimization of emergency resource scheduling for urban public health events},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on personalized learning path planning model based
on knowledge network. <em>NCA</em>, <em>35</em>(12), 8809–8821. (<a
href="https://doi.org/10.1007/s00521-022-07658-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing a personalized learning path is a critical way to solve the problem of cognitive difference and learning disorientation effectively. The construction process of the learning path is closely related to the internal relationship between knowledge and needs to meet different learning scenarios and learning needs. Because of the above requirements, a personalized learning path model based on a knowledge network is proposed in this paper. The algorithm begins by building a knowledge network with learning resource nodes and knowledge points. Following that, the order of the knowledge points was determined using their sequential link. A sequence of learning materials that adhere to user characteristics was eventually acquired by evaluating the learning time limit of various learning contexts. The proposed approach was tested on the data sets of open MOOPer and Python learning platforms. Compared with traditional learning path construction algorithms, the proposed algorithm improves the accuracy and relevance.},
  archive      = {J_NCA},
  author       = {Li, Hui and Gong, Rongrong and Zhong, Zhaoman and Xing, Libao and Li, Xing and Li, Haining},
  doi          = {10.1007/s00521-022-07658-8},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8809-8821},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on personalized learning path planning model based on knowledge network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Expression dynamic capture and 3D animation generation
method based on deep learning. <em>NCA</em>, <em>35</em>(12), 8797–8808.
(<a href="https://doi.org/10.1007/s00521-022-07644-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computer technology and artificial intelligence today, human–computer interaction based solely on computer software operations is far from being able to meet human requirements for computer use. People are looking forward to a more convenient and fast human–computer interface. This paper studies the expression dynamic capture and 3D animation generation methods based on deep learning. For facial expression dynamic capture, this paper proposes a facial feature extraction algorithm based on deep learning and uses SVM technology for feature classification. For 3D animation, C++ and OpenGL are used for rendering simulation. The experimental results show that the face detection algorithm proposed in this paper has good performance in both accuracy and speed. It can realize real-time detection of face regions in video images.},
  archive      = {J_NCA},
  author       = {Wang, Baoqing and Shi, Yujie},
  doi          = {10.1007/s00521-022-07644-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8797-8808},
  shortjournal = {Neural Comput. Appl.},
  title        = {Expression dynamic capture and 3D animation generation method based on deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The design of a neural network-based adaptive control method
for robotic arm trajectory tracking. <em>NCA</em>, <em>35</em>(12),
8785–8795. (<a
href="https://doi.org/10.1007/s00521-022-07646-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the in-depth development of high-tech industries, especially in the fields of production, manufacturing, aviation, and medical care, most of the work needs to be accomplished with the help of machines. As a high-tech product, a robotic arm plays an irreplaceable role in high-risk and high-precision engineering, such as arc welding, spraying, and assembly. At the same time, with the increasing requirements of scientific and technological production processes, robotic arm tasks are becoming increasingly complicated. Robotic arm trajectory tracking control in industry also has increasingly higher standards. Furthermore, external interference sources invariably affect the robotic arm control system when it is in operation. Therefore, existing manipulator control systems can no longer meet the requirements of industrial production. This paper aims to realize the tracking control of the trajectory of a robotic arm through a neural network algorithm. This research offers an adaptive neural network control method to solve the manipulator trajectory tracking control problem. To increase the control effect and overall performance of the manipulator, a neural network is employed to address the uncertainty in the control system as well as the interference of external elements. Experiments reveal that a neural network-based manipulator trajectory control and tracking system can effectively regulate the manipulator&#39;s operation and improve its overall performance.},
  archive      = {J_NCA},
  author       = {Xu, Kun and Wang, Zhiliang},
  doi          = {10.1007/s00521-022-07646-y},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8785-8795},
  shortjournal = {Neural Comput. Appl.},
  title        = {The design of a neural network-based adaptive control method for robotic arm trajectory tracking},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method of forecasting trade export volume based on
back-propagation neural network. <em>NCA</em>, <em>35</em>(12),
8775–8784. (<a
href="https://doi.org/10.1007/s00521-022-07693-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial forecasting has been greatly improved in recent years, but at long horizons, forecast accuracy may be low. Foreign trade plays an important role in introducing advanced technology and equipment, expanding employment opportunities, increasing government revenue and promoting economic growth. The main purpose of this paper is to predict the export volume of foreign trade through a back-propagation neural network (BPNN). To shed light on the characteristics of foreign trade and the export volume calculation method, this paper uses BPNN for forecasting. This method has a unique and advanced advantage in solving nonlinear problems and is very suitable for solving forecasting and decision-making problems related to nonlinear financial systems. By establishing multifactor and single-factor export forecasting models, the export volume of a single Chinese city in recent years is forecasted and compared with the actual export volume. The forecasting accuracy of our model is more than 30\% higher than that of the traditional forecasting method, and the application is also approximately 15\% more accurate than the traditional method, indicating that the method used in this paper is more in line with the growth trend of the actual export data. As a key part of the economic system, foreign trade is an important force driving economic growth. Therefore, developing foreign trade is a suitable path to pursue growth.},
  archive      = {J_NCA},
  author       = {Dai, Chenglin},
  doi          = {10.1007/s00521-022-07693-5},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8775-8784},
  shortjournal = {Neural Comput. Appl.},
  title        = {A method of forecasting trade export volume based on back-propagation neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Arbitrary surface data patching method based on geometric
convolutional neural network. <em>NCA</em>, <em>35</em>(12), 8763–8774.
(<a href="https://doi.org/10.1007/s00521-022-07759-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In free-form surface reconstruction technology, the ultimate goal is to obtain a computer model of a free-form surface. This study discusses the inpainting method of arbitrary surface data based on geometric convolutional neural networks. Reverse engineering is a process of product design technology reproduction, that is, reverse analysis and research of a target product, to deduce and obtain design elements such as the processing flow, organizational structure, functional characteristics and technical specifications of the product to produce functional similar but not identical products. This paper realizes the noise point elimination of point cloud data by studying reconstruction technology of free-form surfaces using a geometric convolutional neural network model. Point cloud data without gross errors are provided for later reconstruction. High-precision arbitrary surface data are realized for surface reconstruction. The repair of arbitrary surface data is completed based on BP and RBF neural networks, and a certain degree of data supplementing for the incomplete point cloud data measured is realized. Finally, free-form surface reconstruction is realized. In reverse engineering, a flexible surface is converted into a rigid surface, and the data points are collected using contact measuring equipment. The influencing factors of reverse engineering are work efficiency, technical ability and the influencing factors of innovative design. The data points obtained in this study are processed by denoising, streamlining and filtering. The sorted data points are used to obtain an optimized mathematical model after curve and surface fitting and smoothing. The research in this study proves that the data points obtained using the reverse engineering method can be very well applied in subsequent work. Therefore, this data collection method can be applied to other instances. In the experiment, the maximum error between the output of the RBF network and the test data is 0.0086 when surface 2 is repaired. When the hybrid learning algorithm is trained with different sample sets, the average width is 0.24, and the number of iterations is 1000. The experimental results of repairing various surface defect data show that the data repairing method has good versatility, fast data repairing speed and high precision, so it has high practical value.},
  archive      = {J_NCA},
  author       = {Fan, Linyuan and Ji, Dandan and Lin, Peng},
  doi          = {10.1007/s00521-022-07759-4},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8763-8774},
  shortjournal = {Neural Comput. Appl.},
  title        = {Arbitrary surface data patching method based on geometric convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bidirectional feedback of optimized gaussian mixture model
and kernel correlation filter for enhancing simple detection of small
pixel vehicles. <em>NCA</em>, <em>35</em>(12), 8747–8761. (<a
href="https://doi.org/10.1007/s00521-022-07570-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-precision detection of vehicle position and contour from unmanned aerial vehicles (UAV) provides critical information for vehicle behavior and traffic flow studies. Vehicles in UAV videos present unique features of small target pixels, which pose challenges in accurate detection. In addition, shaking of UAV camera, shadow of vehicle, and ground sign/marking also lead to difficulties in precise vehicle contour detection. The study proposes a novel approach that designs a bidirectional feedback framework (GKB) between optimized Gaussian mixture model and Kernel correlation filter to enhance vehicle detection. The framework predicts vehicle position based on information of continuous and correlated previous frames to achieve improved performance. We also improve the detection of closely spaced and dark vehicles with morphological algorithms and data processing. The approach is tested on two UAV videos with different shooting heights, illumination conditions, and traffic states. The results show that the proposed method significantly improves vehicle detection. The total accuracy of our model is 98\%, which is a 11\% improvement over the traditional single detect model and a 4\% improvement over the track-after-detect method. Our model’s detection rate of closely spaced and dark vehicles is improved by 15–25\% compared to previous methods. Our model’s vehicle contour detection accuracy is over 94\%, which is about a 15\% improvement over previous methods.},
  archive      = {J_NCA},
  author       = {Shan, Xiaofeng and Wu, Qifan and Li, Zhibin and Wang, Chishe},
  doi          = {10.1007/s00521-022-07570-1},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8747-8761},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bidirectional feedback of optimized gaussian mixture model and kernel correlation filter for enhancing simple detection of small pixel vehicles},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognition of abnormal human behavior in dual-channel
convolutional 3D construction site based on deep learning. <em>NCA</em>,
<em>35</em>(12), 8733–8745. (<a
href="https://doi.org/10.1007/s00521-022-07881-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human behavior recognition has widespread applications in real life, especially in the infrastructure field. Modern engineering projects involve many construction units and engineering documents, many personnel, large scales, and large amounts of information. The traditional engineering management information system also has some defects. To strictly control the construction order and work efficiency of the infrastructure site, deal with emergencies in a timely manner, and reduce the burden on staff, we design a human abnormal behavior recognition system based on deep learning and dual-channel C3D. Our main aim is to conduct an in-depth study of human behavior recognition and apply it to the safety management of existing residential construction sites. In the methods section, we first introduce the convolutional neural network in deep learning, explain the principle of neural networks and two-channel convolution, and use the C3D model as the recognition model of the algorithm. The improved model combines the convolutional neural network to obtain our improved model. In the experimental section, the working process, experimental environment, and objects of our designed human abnormal behavior recognition system are classified. The analysis comprehensively analyzes the influence of system identification, the recall rate and accuracy rate of different algorithms, the misrecognition rate of different angles, dual-channel fusion, and the influence of duration on the prediction results. We chose three different angles for behavior recognition, and the results show that from a specific angle, our anomaly recognition rate is 98.01\%; from a lateral point of view, our anomaly recognition rate is 97.27\%; and from a top-down point of view, the recognition rate is 95.68\%. Under three different video surveillance angles, the anomaly recognition rate of our proposed dual-channel 3D convolution algorithm reaches over 95\%.},
  archive      = {J_NCA},
  author       = {Jiang, Lingzi and Zou, Beiji and Liu, Shu and Yang, Wenjun and Wang, Min and Huang, Enquan},
  doi          = {10.1007/s00521-022-07881-3},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8733-8745},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recognition of abnormal human behavior in dual-channel convolutional 3D construction site based on deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognition method for stone carved calligraphy characters
based on a convolutional neural network. <em>NCA</em>, <em>35</em>(12),
8723–8732. (<a
href="https://doi.org/10.1007/s00521-022-08049-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese calligraphy is an important part of Chinese national culture and art and part of the essence of Chinese national culture. Stone calligraphy is one of the important elements of Chinese calligraphy art. Stone carved calligraphy characters have high cultural and artistic value. Therefore, accurately recognizing stone carved calligraphy characters are of great importance. Stone carved calligraphy can identify hard-to-preserve stone calligraphy paper materials in electronic data that can be preserved for a long time, thereby offering important reference materials for the study of the historical development of Chinese calligraphy art. Moreover, with the development of science and technology and the investment of China in cultural and artistic undertakings, computer-aided calligraphy character recognition technology is also constantly improving, and its application in calligraphy recognition is becoming increasingly extensive. This article aims to study a method of stone inscription calligraphy recognition based on convolutional neural networks. In this paper, we use an image recognition and optimization method consisting of a convolutional neural network to carry out an experiment with stone inscription calligraphy characters. It was concluded that the recognition accuracy of stone calligraphy characters by the convolutional neural network reached 99.2\%, indicating that this stone calligraphy character recognition method based on a convolutional neural network has a good ability to recognize stone calligraphy characters.},
  archive      = {J_NCA},
  author       = {Huang, Ji-dan and Cheng, Guanjie and Zhang, Jinghan and Miao, Wei},
  doi          = {10.1007/s00521-022-08049-9},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8723-8732},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recognition method for stone carved calligraphy characters based on a convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time motion removal based on point correlations for
RGB-d SLAM in indoor dynamic environments. <em>NCA</em>,
<em>35</em>(12), 8707–8722. (<a
href="https://doi.org/10.1007/s00521-022-07879-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional visual simultaneous localization and mapping (SLAM) systems have a high dependence on static world assumption, which makes them easy to fail to track in dynamic environments. In this paper, we propose a real-time dynamic visual SLAM system (RTDSLAM) based on ORB-SLAM3 to realize accurate pose estimation of the camera in indoor dynamic environments. We regard the static objects in the environments as a complete virtual rigid body and add two motion removal modules to handle the dynamic feature points without the aid of the camera’s ego motion. The geometry-based motion removal module utilizes the point correlations and the structural invariance of rigid body to detect sparse dynamic feature points between two keyframes, and the clustering of depth images helps find the complete dynamic regions. Meanwhile, the template-based motion removal module uses template matching to fast track the known moving objects between ordinary frames. The dynamic feature points located on moving objects are removed and only static feature points are reserved for pose estimation. We evaluate our system on public TUM and Bonn datasets, and the comparison with state-of-the-art dynamic visual SLAM systems shows our advantages both in runtime and the accuracy of pose estimation. Besides, the test in real-world scenes shows the effectiveness of our system in dynamic environments.},
  archive      = {J_NCA},
  author       = {Wang, Kesai and Yao, Xifan and Ma, Nanfeng and Jing, Xuan},
  doi          = {10.1007/s00521-022-07879-x},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8707-8722},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time motion removal based on point correlations for RGB-D SLAM in indoor dynamic environments},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal deep collaborative filtering recommendation based
on dual attention. <em>NCA</em>, <em>35</em>(12), 8693–8706. (<a
href="https://doi.org/10.1007/s00521-022-07756-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current collaborative filtering algorithm is difficult to quantify the interaction between user and item features, which makes it difficult to accurately identify user preferences. Therefore, a multimodal deep collaborative filtering recommendation model based on dual attention for crowdfunding platforms is proposed. The model first uses the dual attention mechanism to quantify investor preferences, then uses deep neural networks to learn the nonlinear interaction of item features, and then combines the collaborative filtering mechanism to model investor preferences and item features to predict the recommendation list. Meanwhile, in terms of features, a large amount of auxiliary information is used to construct a richer feature system through multimodal fusion as a way to alleviate the cold start problem and improve the prediction accuracy. The effect of hyper-parameters on the experimental performance of the real crowdfunding dataset Indiegogo is explored and baseline experiments are designed for comparison. The experimental results show that the proposed model achieves the best recommendation results on the Indiegogo dataset compared to other baseline models.},
  archive      = {J_NCA},
  author       = {Yin, Pei and Ji, Dandan and Yan, Han and Gan, Hongcheng and Zhang, Jinxian},
  doi          = {10.1007/s00521-022-07756-7},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8693-8706},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal deep collaborative filtering recommendation based on dual attention},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cleaning of object surfaces based on deep learning: A method
for generating manipulator trajectories using RGB-d semantic
segmentation. <em>NCA</em>, <em>35</em>(12), 8677–8692. (<a
href="https://doi.org/10.1007/s00521-022-07930-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A mobile robot with a robotic arm needs to be able to autonomously perceive the operating environment and plan the trajectory of the object’s surface in order to perform surface cleaning tasks in a complex, unstructured environment. This study suggests an autonomous trajectory planning technique for cleaning an object’s surface based on RGB-D semantic segmentation, which enables the robotic arm to move the cleaning mechanism on the object’s surface smoothly and steadily and finish the cleaning process. More particularly, it contains the following: (1) A Double Attention Fusion Net (DAFNet) RGB-D semantic segmentation network is proposed, which successfully integrates color texture features and spatial structure features and enhances the semantic segmentation performance of indoor objects. This network is based on the dual attention mechanism (channel attention and spatial attention). (2) The trajectory planning algorithm for the robot arm is created, and the semantically segmented data is clustered using DBCSCAN. In order to achieve autonomous planning of the cleaning trajectory, the target subject is first extracted, and then the working trajectory of the robot arm is generated via the processes of edge detection, slicing, sampling, fitting, etc. We also compare the accuracy of DAFNet semantic segmentation and other algorithms on SUNRGBD and self-built datasets, experiment with trajectory generation for various objects, and evaluate the online surface cleaning procedure. According to the experimental findings, the DAFNet semantic segmentation model is more accurate than the current models. According to the online test, the trajectory generated has a good degree of smoothness and continuity, and the robotic arm is capable of completing the surface cleaning operation effectively.},
  archive      = {J_NCA},
  author       = {Qi, Lizhe and Gan, Zhongxue and Hua, Zhongwei and Du, Daming and Jiang, Wenxuan and Sun, Yunquan},
  doi          = {10.1007/s00521-022-07930-x},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8677-8692},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cleaning of object surfaces based on deep learning: A method for generating manipulator trajectories using RGB-D semantic segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HRNet- and PSPNet-based multiband semantic segmentation of
remote sensing images. <em>NCA</em>, <em>35</em>(12), 8667–8675. (<a
href="https://doi.org/10.1007/s00521-022-07737-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution remote sensing images have become mainstream remote sensing data, but there is an obvious &quot;salt and pepper phenomenon&quot; in the existing semantic segmentation methods of high-resolution remote sensing images. The purpose of this paper is to propose an improved deep convolutional neural network based on HRNet and PSPNet to segment and realize deep scene analysis and improve the pixel-level semantic segmentation representation of high-resolution remote sensing images. Based on hierarchical multiscale segmentation technology research, the main method is multiband segmentation; the vegetation, buildings, roads, waters and bare land rule sets in the experimental area are established, the classification is extracted, and the category is labeled at each pixel in the image. Using the image classification network structure, different levels of feature vectors can be used to meet the judgment requirements. The HRNet and PSPNet algorithms are used to analyze the scene and obtain the category labels of all pixels in an image. Experiments have shown that artificial intelligence uses the pyramid pooling module in the classification and recognition of CCF satellite images. In the context of integrating different regions, PSPNet affects the region segmentation accuracy. FCN, DeepLab and PSPNet are now the best methods and achieve 98\% accuracy. However, the PSPNet object recognition algorithm has better advantages in specific areas. Experiments show that this method has high segmentation accuracy and good generalization ability and can be used in practical engineering.},
  archive      = {J_NCA},
  author       = {Sun, Yan and Zheng, Wenxi},
  doi          = {10.1007/s00521-022-07737-w},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8667-8675},
  shortjournal = {Neural Comput. Appl.},
  title        = {HRNet- and PSPNet-based multiband semantic segmentation of remote sensing images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Air infrared small target local dehazing based on
multiple-factor fusion cascade network. <em>NCA</em>, <em>35</em>(12),
8657–8665. (<a
href="https://doi.org/10.1007/s00521-022-07553-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared (IR) imaging, an import method of target monitoring, suffers great imaging quality degradation in poor weather conditions such as haze, fog, and smog. This will greatly affect the ability of detecting and identifying for targets with far distance. For visible-light imaging, an image processing technique named dehazing has been developed in the past several years. However, these dehazing methods for visible light can hardly be used to IR picture dehazing directly, due to the natural difference between IR and visible-light images. In this paper, an IR image dehazing algorithm based on multiple-factor fusion cascade network (MFFCN) is proposed, which includes multi-patch image encoder, multi-channel feature enhancement module and multi-level feature fusion module to directly remove the haze. Specifically, a multi-patch image encoder aggregating features from multiple patches of image to improve the response for different levels of haze in different regions and a multi-channel feature enhancement module can provide interactions of cross-feature and enrich the diversity of learned representations. A multi-level feature fusion module is integrated to calculate the importance weights of different network levels, and then, the calculated weights are utilized to fuse the corresponding feature. The experimental results showed that our MFFCN achieves the highest performance with both visual perception and evaluation metric, when compared with previous state-of-the-art methods. Particularly, for thick hazing scene, a greatly contrast enhancement for the local area around target has been achieved. In addition, the effectiveness for ground background image hazing and halation removing is demonstrated, which can also obtain superior performance.},
  archive      = {J_NCA},
  author       = {Gao, Xiaoli and Tang, Peiren and Cheng, Qi and Li, Jie},
  doi          = {10.1007/s00521-022-07553-2},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8657-8665},
  shortjournal = {Neural Comput. Appl.},
  title        = {Air infrared small target local dehazing based on multiple-factor fusion cascade network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A maximum-entropy-attention-based convolutional neural
network for image perception. <em>NCA</em>, <em>35</em>(12), 8647–8655.
(<a href="https://doi.org/10.1007/s00521-022-07564-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, image perception such as enhancement, classification and object detection with deep learning has achieved significant successes. However, in real world under extreme conditions, the training of a deep learning model often yields low accuracy, low efficiency in feature extraction and generalizability, due to the inner uncourteous and uninterpretable characteristics. In this paper, a maximal-entropy-attention-based convolutional neural network (MEA-CNN) framework is proposed. A maximum entropy algorithm is first used for image feature pre-extraction. An attention mechanism is then proposed by combining the extracted features on original images. By applying the mechanism, the key areas of an image are enhanced, and noised area can be ignored. Afterward, the processed images are transferred into region convolutional neural network, which is a well-known pre-trained CNN model, for further feature learning and extraction. Finally, two real-world experiments on traffic sign recognition and road surface condition monitoring are designed. The results show that the proposed framework has high testing accuracy, with improvements of 17\% and 2.9\%, compared with some other existing methods. In addition, the features extracted by the model are more easily interpretable.},
  archive      = {J_NCA},
  author       = {Chen, Qili and Zhang, Ancai and Pan, Guangyuan},
  doi          = {10.1007/s00521-022-07564-z},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8647-8655},
  shortjournal = {Neural Comput. Appl.},
  title        = {A maximum-entropy-attention-based convolutional neural network for image perception},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Multifeature video modularized arm movement algorithm
evaluation and simulation. <em>NCA</em>, <em>35</em>(12), 8637–8646. (<a
href="https://doi.org/10.1007/s00521-022-08060-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence applications, the practical value of robotic arms is becoming increasingly important. Traditional robotic arms can only grab objects along a preplanned route, and it is difficult to obtain external information. If the surrounding environment is unknown or has changed, the robotic arm needs to be redesigned. Otherwise, grabbing will be difficult. To ensure the coordination ability of the automatic control system of a robotic arm and for the robot to be able to independently recognize the surrounding environment, robotic arm control systems based on multifeature video have gradually become popular. These systems also help to address the problem of independent grasping under unknown conditions. In this study, a multifeature video-based modular robotic arm motion device was built, and the relevant performance of the robotic arm was verified by experiments. The experimental results show that the relative error between the multifeature video vision system and the laser rangefinder is 1.16\% at minimum and 3.12\% at maximum. The grasping success rate reached 88.9\%, and the robotic arm motion device could meet the expected requirements.},
  archive      = {J_NCA},
  author       = {Zhao, Xiaofang},
  doi          = {10.1007/s00521-022-08060-0},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8637-8646},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multifeature video modularized arm movement algorithm evaluation and simulation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on artificial intelligence-based techniques
and applications for intelligent IoT systems. <em>NCA</em>,
<em>35</em>(12), 8635–8636. (<a
href="https://doi.org/10.1007/s00521-023-08436-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ye, Jun and Loyola-González, Octavio},
  doi          = {10.1007/s00521-023-08436-w},
  journal      = {Neural Computing and Applications},
  number       = {12},
  pages        = {8635-8636},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on artificial intelligence-based techniques and applications for intelligent IoT systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-based solar energy forecasting for smart grid
integration. <em>NCA</em>, <em>35</em>(11), 8625–8634. (<a
href="https://doi.org/10.1007/s00521-022-08160-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating solar energy power into the existing grid system is a challenging task due to the volatile and intermittent nature of this power. Robust energy forecasting has been considered a reliable solution to the mentioned problem. Since the first success of Deep Learning models, it has been more and more employed for solving problems related to time series forecasting and excellent results were achieved. In this work, we propose a hybrid method based on the combination of an LSTM neural network and an autoencoder. The LSTM neural network extracted temporal features of the historical time series of solar energy production. The spatial features were extracted by the autoencoder, and predictions have been generated. To demonstrate the robustness of the proposed approach, four error metrics were used. The proposed method was compared to the state-of-the-art models, and superior results were achieved. A low SDE of 0.62 and an RMSE of 0.60 were achieved. Experimental results have proved the efficiency of the proposed approach and proved that extracting the temporal features before the spatial features is better than extracting spatial features than extracting temporal features.},
  archive      = {J_NCA},
  author       = {Said, Yahia and Alanazi, Abdulaziz},
  doi          = {10.1007/s00521-022-08160-x},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8625-8634},
  shortjournal = {Neural Comput. Appl.},
  title        = {AI-based solar energy forecasting for smart grid integration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust semi-supervised discriminant embedding method with
soft label in kernel space. <em>NCA</em>, <em>35</em>(11), 8601–8623.
(<a href="https://doi.org/10.1007/s00521-022-08134-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering some problems of local linear embedding methods in semi-supervised scenarios, a robust scheme for generating soft labels is designed and a semi-supervised discrimination embedding method combined with soft labels in the kernel space is proposed in this paper. The method uses the kernel trick to perform the following related operations in the regenerative kernel Hilbert space. Firstly, in order to deal with the different distribution of labeled data, the confidence of generating soft labels is introduced in the label propagation process, and then the label density of data within the hypersphere whose unlabeled data is the center of the sphere is used to generate final soft labels. The scheme is experimentally demonstrated to generate more reliable soft labels even with lower labeling ratios. In order to make full use of the prior information provided by soft labels and the confidence of soft labels, a distance distortion function is used in feature learning to introduce the soft label prior information, and a penalty term about the global information is added to the optimization objective function, so that a more suitable low-dimensional representation for data classification can be obtained. Finally, the method is experimentally compared with various feature learning methods and visualized on handwritten digit dataset. The experiments show that this method performs well on various datasets of the UCI database and is successfully applied in image recognition, especially when the ratio of labeled data is in a low range.},
  archive      = {J_NCA},
  author       = {Peng, Pei and Zhao, Yong-Ping},
  doi          = {10.1007/s00521-022-08134-z},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8601-8623},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust semi-supervised discriminant embedding method with soft label in kernel space},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pixel attention convolutional network for image
super-resolution. <em>NCA</em>, <em>35</em>(11), 8589–8599. (<a
href="https://doi.org/10.1007/s00521-022-08132-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an image super-resolution method (SR) using a deeply-recursive convolutional network (DRCN). Single-image super-resolution reconstruction technology is to reconstruct fuzzy low-resolution images into clearer high-resolution images. It is a research hotspot in the field of computer vision and image processing. In recent years, the attention mechanism has been successfully applied in image super-resolution reconstruction. However, the existing methods use the channel attention mechanism and the spatial attention mechanism separately, or simply superimpose them, which cannot effectively unify the adjustment effects of both, and the performance is limited. This paper proposes a method that can merge channel attention and spatial attention into pixel attention, which achieves more precise adjustment of feature map information. The pixel attention convolutional neural network method built on this basis can improve the quality of image texture detail reconstruction. We have been tested on five widely used standard datasets, the experimental results show that the method is superior to most current representative reconstruction methods, especially in terms of high-definition picture texture restoration.},
  archive      = {J_NCA},
  author       = {Wang, Xin and Zhang, Shufen and Lin, Yuanyuan and Lyu, Yanxia and Zhang, Jiale},
  doi          = {10.1007/s00521-022-08132-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8589-8599},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pixel attention convolutional network for image super-resolution},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite-time average consensus of directed second-order
multi-agent systems with markovian switching topology and impulsive
disturbance. <em>NCA</em>, <em>35</em>(11), 8575–8588. (<a
href="https://doi.org/10.1007/s00521-022-08131-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates finite-time mean square average consensus of second-order multi-agent systems, where connected typologies are directed and subject to Markovian switching, agents dynamics are nonlinear and interrupt by impulses. In order to eliminate the chattering phenomenon in finite-time control, we propose a protocol without sign function, that contains neighborhood and self state feedbacks. Also, by employing graph theory, some graph-related matrices are formed to analyze directed switching topologies. Then, expectations of multi-agent systems energy evolution are bounded in both continuous and discontinuous time by using stochastic and discontinuous stability theories. In this basis, sufficient finite-time mean square consensus criteria are established and their settling times are obtained. Simulation examples prove the theoretical results are correct and the finite-time protocol is valid.},
  archive      = {J_NCA},
  author       = {Tian, Yuan and Li, Huaqing and Han, Qi},
  doi          = {10.1007/s00521-022-08131-2},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8575-8588},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finite-time average consensus of directed second-order multi-agent systems with markovian switching topology and impulsive disturbance},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated learning for interpretable short-term residential
load forecasting in edge computing network. <em>NCA</em>,
<em>35</em>(11), 8561–8574. (<a
href="https://doi.org/10.1007/s00521-022-08130-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term residential load forecasting is of great significance to smart grid applications. Deep learning techniques, especially recurrent neural networks, can greatly improve the performance of prediction models. However, deep neural networks usually have low interpretability, which creates obstacles for customers to deeply understand the prediction results and make quick responses. In addition, the existing deep learning prediction methods rely heavily on the centralized training of massive data. However, the transmission of data from the client to the server poses a threat to the data security of customers. In this work, we propose an interpretable deep learning framework with federated learning for short-term residential load forecasting. Specifically, we propose a new automatic relevance determination network for feature interpretation, combined with the encoder–decoder architecture to achieve interpretable multi-step load prediction. In the edge computing network, the training scheme based on federated learning does not share the original data, which can effectively protect data privacy. The introduction of iterative federated clustering algorithm can alleviate the problem of non-independent and identical distribution of data in different households. We use two real-world datasets to verify the feasibility and performance of the proposed method. Finally, we discuss in detail the feature interpretation of these two datasets.},
  archive      = {J_NCA},
  author       = {Xu, Chongchong and Chen, Guo and Li, Chaojie},
  doi          = {10.1007/s00521-022-08130-3},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8561-8574},
  shortjournal = {Neural Comput. Appl.},
  title        = {Federated learning for interpretable short-term residential load forecasting in edge computing network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A self-training automatic infant-cry detector. <em>NCA</em>,
<em>35</em>(11), 8543–8559. (<a
href="https://doi.org/10.1007/s00521-022-08129-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infant cry is one of the first distinctive and informative life signals observed after birth. Neonatologists and automatic assistive systems can analyse infant cry to early-detect pathologies. These analyses extensively use reference expert-curated databases containing annotated infant-cry audio samples. However, these databases are not publicly accessible because of their sensitive data. Moreover, the recorded data can under-represent specific phenomena or the operational conditions required by other medical teams. Additionally, building these databases requires significant investments that few hospitals can afford. This paper describes an open-source workflow for infant-cry detection, which identifies audio segments containing high-quality infant-cry samples with no other overlapping audio events (e.g. machine noise or adult speech). It requires minimal training because it trains an LSTM-with-self-attention model on infant-cry samples automatically detected from the recorded audio through cluster analysis and HMM classification. The audio signal processing uses energy and intonation acoustic features from 100-ms segments to improve spectral robustness to noise. The workflow annotates the input audio with intervals containing infant-cry samples suited for populating a database for neonatological and early diagnosis studies. On 16 min of hospital phone-audio recordings, it reached sufficient infant-cry detection accuracy in 3 neonatal care environments (nursery—69\%, sub-intensive—82\%, intensive—77\%) involving 20 infants subject to heterogeneous cry stimuli, and had substantial agreement with an expert’s annotation. Our workflow is a cost-effective solution, particularly suited for a sub-intensive care environment, scalable to monitor from one to many infants. It allows a hospital to build and populate an extensive high-quality infant-cry database with a minimal investment.},
  archive      = {J_NCA},
  author       = {Coro, Gianpaolo and Bardelli, Serena and Cuttano, Armando and Scaramuzzo, Rosa T. and Ciantelli, Massimiliano},
  doi          = {10.1007/s00521-022-08129-w},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8543-8559},
  shortjournal = {Neural Comput. Appl.},
  title        = {A self-training automatic infant-cry detector},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid multiscale filter along with an improved adaptive
SVR technique for fault diagnosis and machine learning modeling:
Forecasting the octane number of gasoline in isomerization reactor.
<em>NCA</em>, <em>35</em>(11), 8517–8541. (<a
href="https://doi.org/10.1007/s00521-022-08128-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using a reliable predictive model is important for modeling, controlling, and optimization of the isomerization process. This process has a significant impact on the gasoline quality, which can reduce greenhouse gases by improving the octane number. On the other hand, the accuracy of the predicted results of a data-driven model depends on the quality of input data; this is while the measured variables of industrial units are inevitably contaminated by various errors. Hence, the present work proposes an improved adaptive machine learning model and a new hybrid multiscale filter to predict the gasoline research octane number reliably from error-contaminated data of a light naphtha isomerization reactor. The proposed machine learning model is based on the integration of the feature selection algorithm of the double-level similarity with the support vector regression model (named DLS-SVR model) for adaptive prediction. The new hybrid filter is based on a combination of the wavelet transform and median absolute deviation, named multiscale median absolute deviation (MSMAD). MSMAD filter is proposed with the aim to establish an accurate method to identify and eliminate outliers and gross errors from the measured process variables. A pilot-scale reactor is employed to provide the required experimental validating dataset to evaluate the predictive performance of the proposed filter–model combination. Inputs of the DLS-SVR model are operating conditions (temperature: 115–150 °C, pressure: 28–42 bar, space velocity: 0.38–3 h−1) and feed composition (benzene: 0–3.5 wt\%, cyclohexane: 0.8–23.2 wt\%, methylcyclopentane: 1–29 wt\%, H2/naphtha ratio: 0.03–0.3). The performance of the DLS-SVR model is compared with the response surface methodology, support vector regression, and double-level locally weighted extreme learning machine through the fivefold cross-validation technique. The particle swarm optimization–sequential quadratic programming algorithm is used to optimize the hyper-parameters of these models. The results prove that the generalized DLS-SVR model outperforms the other generalized models. Furthermore, the performance of the MSMAD filter is compared with the multiscale median, finite impulse response–median hybrid, median, and median absolute deviation filters by rectifying the error-contaminated temperature signal. Findings reveal that the DLS-SVR model utilizing the rectified signal by the MSMAD filter has a maximum coefficient of determination, R2 = 0.91, and minimum root mean square error, RMSE = 0.0562, among the other filter&#39;s rectified temperature signals. These values for error-free data are R2 = 0.945 and RMSE = 0.0439.},
  archive      = {J_NCA},
  author       = {Abdolkarimi, Vahid and Sari, Ataallah and Shokri, Saeid},
  doi          = {10.1007/s00521-022-08128-x},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8517-8541},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid multiscale filter along with an improved adaptive SVR technique for fault diagnosis and machine learning modeling: Forecasting the octane number of gasoline in isomerization reactor},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A residual network-based framework for COVID-19 detection
from CXR images. <em>NCA</em>, <em>35</em>(11), 8505–8516. (<a
href="https://doi.org/10.1007/s00521-022-08127-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In late 2019, a new Coronavirus disease (COVID-19) appeared in Wuhan, Hubei Province, China. The virus began to spread throughout many countries, affecting a large population. Polymerase chain reaction is currently being utilized to diagnose COVID-19 in suspected patients; however, its sensitivity is quite low. The researchers also developed automated approaches for reliably and timely identifying COVID-19 from X-ray images. However, traditional machine learning-based image classification algorithms necessitate manual image segmentation and feature extraction, which is a time-consuming task. Due to promising results and robust performance, Convolutional Neural Network (CNN)-based techniques are being used widely to classify COVID-19 from Chest X-rays (CXR). This study explores CNN-based COVID-19 classification methods. A series of experiments aimed at COVID-19 detection and classification validates the viability of our proposed framework. Initially, the dataset is preprocessed and then fed into two Residual Network (ResNet) architectures for deep feature extraction, such as ResNet18 and ResNet50, whereas support vector machines with its multiple kernels, including Quadratic, Linear, Gaussian and Cubic, are used to classify these features. The experimental results suggest that the proposed framework efficiently detects COVID-19 from CXR images. The proposed framework obtained the best accuracy of 97.3\% using ResNet50.},
  archive      = {J_NCA},
  author       = {Kibriya, Hareem and Amin, Rashid},
  doi          = {10.1007/s00521-022-08127-y},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8505-8516},
  shortjournal = {Neural Comput. Appl.},
  title        = {A residual network-based framework for COVID-19 detection from CXR images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predictive model for shear strength estimation in reinforced
concrete beams with recycled aggregates using gaussian process
regression. <em>NCA</em>, <em>35</em>(11), 8487–8503. (<a
href="https://doi.org/10.1007/s00521-022-08126-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to attain sustainable development, recycled concrete aggregates (RCAs) are increasingly utilized in civil engineering projects. Therefore, it is vital to study the performance of structural elements made with RCA. Shear strength is one of the main aspects in examining the structural performance of concrete beams. Shear strength is usually obtained using code calculation methods, and its exact value is obtained by experimental studies. The development of intelligent systems has provided the conditions for faster and easier calculation of this parameter. Shear strength prediction of recycled concrete beams has rarely been investigated. Therefore, in this research, the shear strength of these beams has been investigated and predicted. To achieve this goal, several methods including linear regression, regression tree, ensemble bagged trees, ensemble boosted trees, and Gaussian process regression were employed. The database used in this paper was included of 128 sets of data obtained from experimental studies. Parameters used as model inputs included percentage of recycled aggregates used in beam construction (RCA), compressive strength of concrete ( $$f_{c}^{{\prime}}$$ ), longitudinal reinforcement ratio ( $${\uprho }_{l}$$ ), transvers reinforcement ratio ( $${\uprho }_{t}$$ ), yield strength of longitudinal reinforcement ( $$f_{dy}$$ ), yield strength of transvers reinforcement ( $$f_{ty}$$ ), width of beam (b), effective depth of beam (d), length-to–effective-depth ratio (L/d), shear span-to-effective depth ratio (a/d), and shear strength of beam ( $$v_{U}$$ ) was output of model. Comparison of the results of the aforementioned models showed that the Gaussian process regression model had a better performance in predicting the output parameter, with a coefficient of R2, 0.91, and also had the lowest error, which indicates better performance of this proposed model, in comparison with other models.},
  archive      = {J_NCA},
  author       = {Omidinasab, Fereydoon and Sahraei Moghadam, Amirhosein and Dowlatshahi, Mohammad Bagher},
  doi          = {10.1007/s00521-022-08126-z},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8487-8503},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predictive model for shear strength estimation in reinforced concrete beams with recycled aggregates using gaussian process regression},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TINYCD: A (not so) deep learning model for change detection.
<em>NCA</em>, <em>35</em>(11), 8471–8486. (<a
href="https://doi.org/10.1007/s00521-022-08122-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a lightweight and effective change detection model, called TinyCD. This model has been designed to be faster and smaller than current state-of-the-art change detection models due to industrial needs. Despite being from 13 to 140 times smaller than the compared change detection models, and exposing at least a third of the computational complexity, our model outperforms the current state-of-the-art models by at least $$1\%$$ on both F1-score and IoU on the LEVIR-CD dataset, and more than $$8\%$$ on the WHU-CD dataset. To reach these results, TinyCD uses a Siamese U-Net architecture exploiting low-level features in a globally temporal and locally spatial way. In addition, it adopts a new strategy to mix features in the space-time domain both to merge the embeddings obtained from the Siamese backbones, and, coupled with an MLP block, it forms a novel space-semantic attention mechanism, the Mix and Attention Mask Block (MAMB).},
  archive      = {J_NCA},
  author       = {Codegoni, Andrea and Lombardi, Gabriele and Ferrari, Alessandro},
  doi          = {10.1007/s00521-022-08122-3},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8471-8486},
  shortjournal = {Neural Comput. Appl.},
  title        = {TINYCD: A (not so) deep learning model for change detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dummy trajectory generation scheme based on generative
adversarial networks. <em>NCA</em>, <em>35</em>(11), 8453–8469. (<a
href="https://doi.org/10.1007/s00521-022-08121-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dummy trajectory is widely used to protect the privacy of mobile users’ locations. However, two main challenges remain: (1) Map background information has not been modeled by machine learning methods in existing schemes, and (2) it is difficult to generate a good quality dummy trajectory that is similar to the real one. Focused on these two challenges, in this paper, we propose a dummy trajectory generation scheme with conditional generative adversary network (GAN), where the map features are extracted using convolutional neural network, which is regarded as a prior restriction of conditional GAN. Then, the movement pattern of the real trajectory is deduced by an auto-encoder and is involved in the dummy trajectory generation. Our model is trained and evaluated with two real-world datasets. Experimental results demonstrate that our scheme addresses these challenges well and defends against various attacks effectively.},
  archive      = {J_NCA},
  author       = {Yang, Jingkang and Yu, Xiaobo and Meng, Weizhi and Liu, Yining},
  doi          = {10.1007/s00521-022-08121-4},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8453-8469},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dummy trajectory generation scheme based on generative adversarial networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Underwater bubble plumes multi-scale morphological feature
extraction and state recognition method. <em>NCA</em>, <em>35</em>(11),
8437–8451. (<a
href="https://doi.org/10.1007/s00521-022-08116-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large amount of information can be derived from the motion form of underwater bubble plumes. As a result of the inadequate light, mutual adhesion, and absence of a background for the bubble plumes, it is difficult to extract features from the images of bubble plumes, and the recognition accuracy is low. Using a combination of nonsubsampled contourlet transform (NSCT) and quantum neural network (QNN), we present a method for extracting bubble plumes features and recognizing their states. To obtain the multi-scale sub-band images, the underwater bubble plumes image is transformed by NSCT. In the case of low-frequency images, the fuzzy set binarization method is used to extract bright spots, after which morphological features are calculated. The differential box counting (DBC) method is used to calculate the fractal dimension for the high-frequency images, which is used as a directional detail feature. In order to achieve accurate state recognition of the underwater bubble plumes, the quantum gate set convolution neural network (QCSCNN) was designed, taking into account the advantages of the quantum gate and the convolution neural network (CNN). In conclusion, the proposed method is implemented and the experimental results indicate that it achieves the promising and satisfactory results. According to the proposed method, it has been confirmed that it is able to achieve a good effect on convergence speed as well as the recognition accuracy of underwater bubble plumes.},
  archive      = {J_NCA},
  author       = {Yang, Xue and Chen, Wei},
  doi          = {10.1007/s00521-022-08116-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8437-8451},
  shortjournal = {Neural Comput. Appl.},
  title        = {Underwater bubble plumes multi-scale morphological feature extraction and state recognition method},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel transfer learning schemes based on siamese networks
and synthetic data. <em>NCA</em>, <em>35</em>(11), 8423–8436. (<a
href="https://doi.org/10.1007/s00521-022-08115-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning schemes based on deep networks which have been trained on huge image corpora offer state-of-the-art technologies in computer vision. Here, supervised and semi-supervised approaches constitute efficient technologies which work well with comparably small data sets. Yet, such applications are currently restricted to application domains where suitable deep network models are readily available. In this contribution, we address an important application area in the domain of biotechnology, the automatic analysis of CHO-K1 suspension growth in microfluidic single-cell cultivation, where data characteristics are very dissimilar to existing domains and trained deep networks cannot easily be adapted by classical transfer learning. We propose a novel transfer learning scheme which expands a recently introduced Twin-VAE architecture, which is trained on realistic and synthetic data, and we modify its specialized training procedure to the transfer learning domain. In the specific domain, often only few to no labels exist and annotations are costly. We investigate a novel transfer learning strategy, which incorporates a simultaneous retraining on natural and synthetic data using an invariant shared representation as well as suitable target variables, while it learns to handle unseen data from a different microscopy technology. We show the superiority of the variation of our Twin-VAE architecture over the state-of-the-art transfer learning methodology in image processing as well as classical image processing technologies, which persists, even with strongly shortened training times and leads to satisfactory results in this domain. The source code is available at https://github.com/dstallmann/transfer_learning_twinvae , works cross-platform, is open-source and free (MIT licensed) software. We make the data sets available at https://pub.uni-bielefeld.de/record/2960030 .},
  archive      = {J_NCA},
  author       = {Kenneweg, Philip and Stallmann, Dominik and Hammer, Barbara},
  doi          = {10.1007/s00521-022-08115-2},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8423-8436},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel transfer learning schemes based on siamese networks and synthetic data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine intelligence-driven classification of cancer
patients-derived extracellular vesicles using fluorescence correlation
spectroscopy: Results from a pilot study. <em>NCA</em>, <em>35</em>(11),
8407–8422. (<a
href="https://doi.org/10.1007/s00521-022-08113-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patient-derived extracellular vesicles (EVs) that contains a complex biological cargo is a valuable source of liquid-biopsy diagnostics to aid in early detection, cancer screening, and precision nanotherapeutics. In this study, we predicted that coupling cancer patient blood-derived EVs to time-resolved spectroscopy and artificial intelligence (AI) could provide a robust cancer screening and follow-up tools. In our pilot study, fluorescence correlation spectroscopy (FCS) measurements were taken on 24 blood samples-derived EVs. Blood samples were obtained from 15 cancer patients (presenting five different types of cancers), and nine healthy controls (including patients with benign lesions). EVs samples were labeled with PKH67 dye. The obtained FCS autocorrelation spectra were processed into power spectra using the fast Fourier transform algorithm. The processed power spectra were subjected to various machine learning algorithms to distinguish cancer spectra from healthy control spectra. The performance of AdaBoost Random Forest (RF) classifier, support vector machine, and multilayer perceptron were tested on selected frequencies in the N = 118 power spectra. The RF classifier exhibited the highest classification accuracy and performance metrics in distinguishing the FCS power spectra of cancer patients from those of healthy controls. Further, neural computing via an image convolutional neural network (CNN), ResNet network, and a quantum CNN were assessed on the power spectral images as additional validation tools. All image-based CNNs exhibited a nearly equal classification performance and reasonably high sensitivity and specificity scores. Our pilot study demonstrates that AI-algorithms coupled to time-resolved FCS power spectra can accurately and differentially classify the complex patient-derived EVs from different cancer samples of distinct tissue subtypes. As such, our findings hold promise in the diagnostic and prognostic screening in clinical medicine.},
  archive      = {J_NCA},
  author       = {Uthamacumaran, Abicumaran and Abdouh, Mohamed and Sengupta, Kinshuk and Gao, Zu-hua and Forte, Stefano and Tsering, Thupten and Burnier, Julia V. and Arena, Goffredo},
  doi          = {10.1007/s00521-022-08113-4},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8407-8422},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine intelligence-driven classification of cancer patients-derived extracellular vesicles using fluorescence correlation spectroscopy: Results from a pilot study},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated steel surface defect detection and classification
using a new deep learning-based approach. <em>NCA</em>, <em>35</em>(11),
8389–8406. (<a
href="https://doi.org/10.1007/s00521-022-08112-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a new deep learning-based approach has been developed that detects and classifies surface defects that occur in the steel production process. The proposed methodology was created in four steps. In the first step, a deep learning model is designed that trains the residual and attention structures in parallel, thus increasing the classification performance. In the second step, deep features were extracted from the Parallel Attention Residual-Convolutional Neural Network model. The extracted features in the third step were selected by a new and simple algorithm (NCA-ReliefF Matched Index) based on matching the indexes obtained from the Neighborhood Component Analysis and Relief algorithms. In the last process, classification was done with the support vector machine algorithm. The proposed methodology was used for dual and multi-class classification tasks and evaluated on a dataset in the Kaggle database named Severstal: Steel Defect Detection.},
  archive      = {J_NCA},
  author       = {Demir, Kursat and Ay, Mustafa and Cavas, Mehmet and Demir, Fatih},
  doi          = {10.1007/s00521-022-08112-5},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8389-8406},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated steel surface defect detection and classification using a new deep learning-based approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MLMRS-net: Electroencephalography (EEG) motion artifacts
removal using a multi-layer multi-resolution spatially pooled 1D signal
reconstruction network. <em>NCA</em>, <em>35</em>(11), 8371–8388. (<a
href="https://doi.org/10.1007/s00521-022-08111-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) signals suffer substantially from motion artifacts when recorded in ambulatory settings utilizing wearable sensors. Because the diagnosis of many neurological diseases is heavily reliant on clean EEG data, it is critical to eliminate motion artifacts from motion-corrupted EEG signals using reliable and robust algorithms. Although a few deep learning-based models have been proposed for the removal of ocular, muscle, and cardiac artifacts from EEG data to the best of our knowledge, there is no attempt has been made in removing motion artifacts from motion-corrupted EEG signals: In this paper, a novel 1D convolutional neural network (CNN) called multi-layer multi-resolution spatially pooled (MLMRS) network for signal reconstruction is proposed for EEG motion artifact removal. The performance of the proposed model was compared with ten other 1D CNN models: FPN, LinkNet, UNet, UNet+, UNetPP, UNet3+, AttentionUNet, MultiResUNet, DenseInceptionUNet, and AttentionUNet++ in removing motion artifacts from motion-contaminated single-channel EEG signal. All the eleven deep CNN models are trained and tested using a single-channel benchmark EEG dataset containing 23 sets of motion-corrupted and reference ground truth EEG signals from PhysioNet. Leave-one-out cross-validation method was used in this work. The performance of the deep learning models is measured using three well-known performance matrices viz. mean absolute error (MAE)-based construction error, the difference in the signal-to-noise ratio (ΔSNR), and percentage reduction in motion artifacts (η). The proposed MLMRS-Net model has shown the best denoising performance, producing an average ΔSNR, η, and MAE values of 26.64 dB, 90.52\%, and 0.056, respectively, for all 23 sets of EEG recordings. The results reported using the proposed model outperformed all the existing state-of-the-art techniques in terms of average η improvement.},
  archive      = {J_NCA},
  author       = {Mahmud, Sakib and Hossain, Md Shafayet and Chowdhury, Muhammad E. H. and Reaz, Mamun Bin Ibne},
  doi          = {10.1007/s00521-022-08111-6},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8371-8388},
  shortjournal = {Neural Comput. Appl.},
  title        = {MLMRS-net: Electroencephalography (EEG) motion artifacts removal using a multi-layer multi-resolution spatially pooled 1D signal reconstruction network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel automatic reading method of pointer meters based on
deep learning. <em>NCA</em>, <em>35</em>(11), 8357–8370. (<a
href="https://doi.org/10.1007/s00521-022-08110-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic reading of pointer meters is significantly important to data monitoring and efficient measurement in the industrial field. However, the existing automatic reading method can not obtain accurate performance in natural scenarios and present no satisfactory application effects in industrial fields (such as power stations and gas stations). In this paper, a novel automatic reading method for pointer meters based on deep learning is proposed, which contains five stages. Stage-1: the object detection algorithm Yolov4 and the feature optimization module IFF are used to locate the target meter. Stage-2: Semantic segmentation model is applied to extract the pointer area based on Anam-Net. Stage-3: the character detection algorithm CRAFT and the text recognition algorithm E2E-MLT are combined and used to recognize the scale text and unit on the meter. Stage-4: the scale area of the meter is converted to the polar coordinate system, and a lightweight convolutional neural network is designed to locate the main scale line. And finally in Stage-5: the reading data are calculated according to the outputs of the above-mentioned deep learning models. The experiment results show that the reading method proposed in this paper has higher accuracy and robustness than those of the existing approaches and obtains satisfactory application effects in the industrial field.},
  archive      = {J_NCA},
  author       = {Sun, Junjiao and Huang, Zhiqing and Zhang, Yanxin},
  doi          = {10.1007/s00521-022-08110-7},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8357-8370},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel automatic reading method of pointer meters based on deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RIECN: Learning relation-based interactive embedding
convolutional network for knowledge graph. <em>NCA</em>,
<em>35</em>(11), 8343–8356. (<a
href="https://doi.org/10.1007/s00521-022-08109-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most knowledge graphs(KGs) are large and incomplete graph-structure database, which can be completed by predicting miss links according to the existing knowledge. The mainstream method is knowledge graph embedding (KGE) which is designed to learn low dimensional embedding of entities and relations. However, knowledge graph embedding still faces two major issues: (1) How to generate more expressive embeddings? (2) How to solve semantic polysemy of entities in different relations? In this paper, we propose a novel KG embedding model, RIECN (Relation-based Interactive Embedding Convolutional Network), which achieves high-quality performance and shows some advancements in modeling complex relations. In RIECN, FIR (Feature Interaction Reshaping) method is introduced to increase the feature interactions between entity and relation embeddings to generate more expressive feature maps. In addition, a new method of generating relation-based dynamic convolution filters, RDCF, is proposed. RDCF generates specific relation and hybird-size convolution filters, which enriches the feature maps of each entity improving the accuracy of link prediction task especially in complex relations scenario. We tested the performance of our model on five benchmark datasets. The experimental results show that the RIECN model significantly outperforms recent state-of-the-art models by 0.1–3.2\% and 1.1–3.7\%, in terms of MMR metric and Hit@1 metric, respectively.},
  archive      = {J_NCA},
  author       = {Wang, Wei and Shen, Xiaoxuan and Zhang, Huanyu and Li, Zhifei and Yi, Baolin},
  doi          = {10.1007/s00521-022-08109-0},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8343-8356},
  shortjournal = {Neural Comput. Appl.},
  title        = {RIECN: Learning relation-based interactive embedding convolutional network for knowledge graph},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing the distributed generators integration in
electrical distribution networks: Efficient modified forensic-based
investigation. <em>NCA</em>, <em>35</em>(11), 8307–8342. (<a
href="https://doi.org/10.1007/s00521-022-08103-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a result of various loads, including critical installations (industries, nuclear facilities, etc.), electrical distribution networks (EDNs) must operate safely and sustainably in order to overcome problems such as high power losses and voltage drops, which must be addressed with the most efficient location and capacity of distributed generators (DGs). In order to address this purpose, the proposed research introduces a robust modified forensic-based investigation (mFBI) optimization method that is demonstrated first time to produce the optimum allocation of DGs in EDNs for minimizing power losses and voltage deviations. Moreover, the analytical hierarchy process approach is employed to generate the most applicable weighting factors of the multi-objective function (MOF). Validation and demonstration of the newly developed mFBI technique is conducted by studying the impact of DG integration on 118 IEEE EDN nodes and real Delta-Egypt EDNs. Additionally, an in-depth comprehensive analysis has been carried out between the novel mFBI and 7 recent proposed optimizers, considering the Wilcoxon sign rank test that is used to verify the significant nature of the results. The numeric results best demonstrate the advantage and utility of incorporating the MOF approach and the superior mFBI technique in the EDN to derive an efficient optimum solution.},
  archive      = {J_NCA},
  author       = {Tolba, Mohamed A. and Houssein, Essam H. and Eisa, Ayman A. and Hashim, Fatma A.},
  doi          = {10.1007/s00521-022-08103-6},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8307-8342},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing the distributed generators integration in electrical distribution networks: Efficient modified forensic-based investigation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight deep learning methods for panoramic dental x-ray
image segmentation. <em>NCA</em>, <em>35</em>(11), 8295–8306. (<a
href="https://doi.org/10.1007/s00521-022-08102-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dental X-ray image segmentation is helpful for assisting clinicians to examine tooth conditions and identify dental diseases. Fast and lightweight segmentation algorithms without using cloud computing may be required to be implemented in X-ray imaging systems. This paper aims to investigate lightweight deep learning methods for dental X-ray image segmentation for the purpose of deployment on edge devices, such as dental X-ray imaging systems. A novel lightweight neural network scheme using knowledge distillation is proposed in this paper. The proposed lightweight method and a number of existing lightweight deep learning methods were trained on a panoramic dental X-ray image data set. These lightweight methods were evaluated and compared by using several accuracy metrics. The proposed lightweight method only requires 0.33 million parameters ( $$\sim 7.5$$ megabytes) for the trained model, while it achieved the best performance in terms of IoU (0.804) and Dice (0.89) comparing to other lightweight methods. This work shows that the proposed method for dental X-ray image segmentation requires small memory storage, while it achieved comparative performance. The method could be deployed on edge devices and could potentially assist clinicians to alleviate their daily workflow and improve the quality of their analysis.},
  archive      = {J_NCA},
  author       = {Lin, Songyue and Hao, Xuejiang and Liu, Yan and Yan, Dong and Liu, Jianwei and Zhong, Mingjun},
  doi          = {10.1007/s00521-022-08102-7},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8295-8306},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lightweight deep learning methods for panoramic dental X-ray image segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). From depth-aware haze generation to real-world haze
removal. <em>NCA</em>, <em>35</em>(11), 8281–8293. (<a
href="https://doi.org/10.1007/s00521-022-08101-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For deep learning-based single image dehazing works, their performances seriously depend on the designed models and training dataset. Existing state-of-the-art methods focus on the design of novel dehazing models or the improvement of training strategies to obtain better dehazing results. In this work, instead of designing a new deep dehazing model, we attempt to further improve the dehazing performance from the perspective of enriching training datasets by exploring an intuitive yet efficient way to synthesize photo-realistic hazy images. It is well known that for a natural hazy image, its perceived haze density increases with scene depth. Motivated by this, we develop a depth-aware haze generation network, namely HazeGAN, by incorporating the Generative Adversarial Network (GAN), depth estimation network, and physical atmospheric scattering to progressively synthesize hazy images. Specifically, a separate depth estimation network is embedded to obtain multi-scale depth features, which are exploited by the atmospheric scattering model to generate multi-scale hazy features. The hazy features are fused into the GAN generator to output synthetic hazy images with depth-aware haze effects. Extensive experimental results demonstrate that the proposed HazeGAN can generate diverse training pairs of depth-aware hazy images and clear images, which effectively enrich the existing benchmark datasets, and improve the generalization capabilities of existing deep image dehazing models.},
  archive      = {J_NCA},
  author       = {Chen, Jiyou and Yang, Gaobo and Xia, Ming and Zhang, Dengyong},
  doi          = {10.1007/s00521-022-08101-8},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8281-8293},
  shortjournal = {Neural Comput. Appl.},
  title        = {From depth-aware haze generation to real-world haze removal},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stacked ensemble learning based on deep convolutional neural
networks for pediatric pneumonia diagnosis using chest x-ray images.
<em>NCA</em>, <em>35</em>(11), 8259–8279. (<a
href="https://doi.org/10.1007/s00521-022-08099-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pneumonia is an acute respiratory infection caused by bacteria, viruses, or fungi and has become very common in children ranging from 1 to 5 years of age. Common symptoms of pneumonia include difficulty breathing due to inflamed or pus and fluid-filled alveoli. The United Nations Children’s Fund reports nearly 800,000 deaths in children due to pneumonia. Delayed diagnosis and overpriced tests are the prime reason for the high mortality rate, especially in underdeveloped countries. A time and cost-efficient diagnosis tool: Chest X-rays, was thus accepted as the standard diagnostic test for pediatric pneumonia. However, the lower radiation levels for diagnosis in children make the task much more onerous and time-consuming. The mentioned challenges initiate the need for a computer-aided detection model that is instantaneous and accurate. Our work proposes a stacked ensemble learning of deep learning-based features for pediatric pneumonia classification. The extracted features from the global average pooling layer of the fine-tuned Xception model pretrained on ImageNet weights are sent to the Kernel Principal Component Analysis for dimensionality reduction. The dimensionally reduced features are further trained and validated on the stacking classifier. The stacking classifier consists of two stages; the first stage uses the Random-Forest classifier, K-Nearest Neighbors, Logistic Regression, XGB classifier, Support Vector Classifier (SVC), Nu-SVC, and MLP classifier. The second stage operates on Logistic Regression using the first stage predictions for the final classification with Stratified K-fold cross-validation to prevent overfitting. The model was tested on the publicly available pediatric pneumonia dataset, achieving an accuracy of 98.3\%, precision of 99.29\%, recall of 98.36\%, F1-score of 98.83\%, and an AUC score of 98.24\%. The performance shows its reliability for real-time deployment in assisting radiologists and physicians.},
  archive      = {J_NCA},
  author       = {Prakash, J. Arun and Ravi, Vinayakumar and Sowmya, V. and Soman, K. P.},
  doi          = {10.1007/s00521-022-08099-z},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8259-8279},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stacked ensemble learning based on deep convolutional neural networks for pediatric pneumonia diagnosis using chest X-ray images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Facial mask attention network for identity-aware face
super-resolution. <em>NCA</em>, <em>35</em>(11), 8243–8257. (<a
href="https://doi.org/10.1007/s00521-022-08098-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Super-Resolution (FSR) is a crucial research topic in image restoration field, which is a fundamental task for subsequent face applications, such as cross- and low-resolution face recognition. Recently, supported by deep convolutional neural networks, the previous FSR methods have achieved great success in generating high quality face images. However, they mainly focus on improving the visual effects of the images while retaining a challenge of restoring identity information from low-resolution faces. Specifically, some face structure information is discarded, such as the position and the shape of the face components, containing useful identity-related details. To solve this issue, we propose the Facial Mask Attention Network utilizing this information to generate faces of both high resolution and identity fidelity. Furthermore, we present an efficient pixel loss function, MaskPix loss, which selectively emphasizes those significant pixels to focus the model on the face regions with dense identity features. Extensive experiments on popular datasets demonstrate that our restored face images not only have more natural textures and facial details, but also preserve higher identity fidelity compared to the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Sun, Zhengzheng and Tian, Lianfang and Du, Qiliang and Bhutto, Jameel A. and Wang, Zhaolin},
  doi          = {10.1007/s00521-022-08098-0},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8243-8257},
  shortjournal = {Neural Comput. Appl.},
  title        = {Facial mask attention network for identity-aware face super-resolution},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CDZoom: A human-like sequential zoom agent for efficient
change detection in large scenes. <em>NCA</em>, <em>35</em>(11),
8227–8241. (<a
href="https://doi.org/10.1007/s00521-022-08096-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution (HR) remote sensing images provide rich information for human activities. However, processing entire HR images is time-consuming, and many computations are meaningless for change detection tasks since objects often cluster in local regions. To alleviate the pressure of downstream detectors, previous studies introduce a regional attention process to roughly sample candidate patches, but most solutions are tailored to particular tasks and datasets. Motivated by these, we develop a novel reinforcement learning sampling framework, and train a human-like agent, named CDZoom, to locate regions of interest by simulating human zooming behaviors. To be specific, the proposed network consists of an encoder block, multiple context blocks and a decision block. It speeds up sequential sampling operations by gradually focusing the scope of observed scene and increasing the resolution. To avoid the sparse reward problem when learning complex sampling tasks, we introduce a novel training paradigm based on curriculum learning and policy distillation. The proposed CDZoom can sample multi-size patches from multi-scale scenes, and thus generalizes well to different requirements. Experiments on public change detection datasets demonstrate the effectiveness of our method. CDZoom can reduce the computational cost by over 50\%, while maintaining similar detection accuracy to models which use full HR images.},
  archive      = {J_NCA},
  author       = {Lin, Yijun and Wu, Fengge and Zhao, Junsuo},
  doi          = {10.1007/s00521-022-08096-2},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8227-8241},
  shortjournal = {Neural Comput. Appl.},
  title        = {CDZoom: A human-like sequential zoom agent for efficient change detection in large scenes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-objective genetic algorithm for the hot mix asphalt
problem. <em>NCA</em>, <em>35</em>(11), 8197–8225. (<a
href="https://doi.org/10.1007/s00521-022-08095-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is desirable for the work done in any construction process to be both cost-effective and durable. A thorough consideration of the matter reveals that the optimization of real-world problems involves multiple objectives. Bituminous hot mixtures, which are widely used in motorway construction, consist of aggregate and bitumen. The ratio between the different types of aggregate and bitumen forms the input to the real-world problem defined in this article, and the results of a test of the obtained asphalt in three different fields form the output. Our aim is to optimize these three outputs simultaneously to obtain a solution space with the most appropriate inputs. To optimize this problem, a new multi-objective optimization approach is proposed and tested in various ways and is finally adapted to the hot mix asphalt problem. Since the mathematical model of the objective function for this problem is fairly difficult, a fuzzy logic expert system is developed to act as the objective function. We believe that our approach to solving complex problems such as these forms a significant contribution to the literature.},
  archive      = {J_NCA},
  author       = {Altiok, Mustafa and Alakara, Erdinç Halis and Gündüz, Mesut and Ağaoğlu, Melih Naci},
  doi          = {10.1007/s00521-022-08095-3},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8197-8225},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-objective genetic algorithm for the hot mix asphalt problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of underground metro train-induced ground
vibration using hybrid PSO-ANN approach. <em>NCA</em>, <em>35</em>(11),
8171–8195. (<a
href="https://doi.org/10.1007/s00521-022-08093-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The soil conditions substantially influence the intensity of underground metro train-induced ground vibration. However, assessing the influence of metro train-induced vibration on nearby structures is difficult due to problems in acquiring soil characteristics’ field data. An optimized artificial neural network (ANN)-based hybrid prediction model is proposed to predict the underground metro train-induced ground vibration to address this issue. Particle swarm optimization (PSO) and genetic algorithm (GA) are used in the hybrid model to optimize the neural network’s weights and biases. The datasets obtained by the validated numerical model are used to train the neural network. An explicit time domain, two-dimensional (2D) numerical model is developed using the finite element method (FEM) based on a two-step methodology and validated with experimental results of Delhi metro sites. Good agreement is observed between the numerical and experimental results in both time and frequency domains. The proposed hybrid PSO-ANN and GA-ANN model considered several soil properties such as density, Poisson’s ratio, damping, Young’s modulus and wave speed while predicting train-induced ground vibration. The PSO-ANN model predicted the outcome with an average error of 0.86\%. Moreover, the proposed PSO-ANN model is also compared with the Federal Transit Administration’s (FTA) semi-empirical approach of vibration assessment, linear support vector machine (SVM) and classification and regression tree (CART). The hybrid PSO-ANN model predicted the outcomes with greater accuracy than the basic ANN model, linear SVM, CART, GA-ANN and FTA’s approach. Additionally, the hybrid model can consider the effect of parameters such as vehicle characteristics, suspension system, speed and tunnel depth.},
  archive      = {J_NCA},
  author       = {Kedia, Naveen Kumar and Kumar, Anil and Singh, Yogendra},
  doi          = {10.1007/s00521-022-08093-5},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8171-8195},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of underground metro train-induced ground vibration using hybrid PSO-ANN approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive fuzzy command filtered control for incommensurate
fractional-order MIMO nonlinear systems with input saturation.
<em>NCA</em>, <em>35</em>(11), 8157–8170. (<a
href="https://doi.org/10.1007/s00521-022-08091-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive fuzzy control approach for incommensurate fractional-order multi-input multi-output (MIMO) systems with unknown nonlinearities and input saturation is presented. First, the nonlinear terms of MIMO systems are identified by introducing the fuzzy logic systems, and an adaptive compensating control term is provided to estimate the approximation errors. Then, the drawback of “explosion of complexity” in the typical backstepping is effectively figured out via an improved command filter, and the influence of filtered error is avoided by constructing the error compensation laws. Meanwhile, the input saturation issue is addressed by utilizing the fractional-order auxiliary equations. Derived from the fractional-order Lyapunov stability theory, it is proved that all signals of the closed-loop system are guaranteed to be bounded. Finally, the availability of the investigated control scheme is verified by simulation examples.},
  archive      = {J_NCA},
  author       = {Lu, Senkui and Li, Xiang and Lu, Ke and Wang, Zhengzhong and Ma, Yujie},
  doi          = {10.1007/s00521-022-08091-7},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8157-8170},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive fuzzy command filtered control for incommensurate fractional-order MIMO nonlinear systems with input saturation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Real-time automated detection of older adults’ hand
gestures in home and clinical settings. <em>NCA</em>, <em>35</em>(11),
8143–8156. (<a
href="https://doi.org/10.1007/s00521-022-08090-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an urgent need, accelerated by the COVID-19 pandemic, for methods that allow clinicians and neuroscientists to remotely evaluate hand movements. This would help detect and monitor degenerative brain disorders that are particularly prevalent in older adults. With the wide accessibility of computer cameras, a vision-based real-time hand gesture detection method would facilitate online assessments in home and clinical settings. However, motion blur is one of the most challenging problems in the fast-moving hands data collection. The objective of this study was to develop a computer vision-based method that accurately detects older adults’ hand gestures using video data collected in real-life settings. We invited adults over 50 years old to complete validated hand movement tests (fast finger tapping and hand opening–closing) at home or in clinic. Data were collected without researcher supervision via a website programme using standard laptop and desktop cameras. We processed and labelled images, split the data into training, validation and testing, respectively, and then analysed how well different network structures detected hand gestures. We recruited 1,900 adults (age range 50–90 years) as part of the TAS Test project and developed UTAS7k—a new dataset of 7071 hand gesture images, split 4:1 into clear: motion-blurred images. Our new network, RGRNet, achieved 0.782 mean average precision (mAP) on clear images, outperforming the state-of-the-art network structure (YOLOV5-P6, mAP 0.776), and mAP 0.771 on blurred images. A new robust real-time automated network that detects static gestures from a single camera, RGRNet, and a new database comprising the largest range of individual hands, UTAS7k, both show strong potential for medical and research applications.},
  archive      = {J_NCA},
  author       = {Huang, Guan and Tran, Son N. and Bai, Quan and Alty, Jane},
  doi          = {10.1007/s00521-022-08090-8},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8143-8156},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time automated detection of older adults&#39; hand gestures in home and clinical settings},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Siamese transformer network-based similarity metric learning
for cross-source remote sensing image retrieval. <em>NCA</em>,
<em>35</em>(11), 8125–8142. (<a
href="https://doi.org/10.1007/s00521-022-08092-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fundamental technique for mining and analysis of remote sensing (RS) big data, content-based remote sensing image retrieval (CBRSIR) has received a lot of attention. Recently, cross-source CBRSIR (CS-CBRSIR) has become one of the most challenging tasks in the RS community. Due to the data drift issue, it is hard to find a proper similarity metric function to accurately measure similarities between the RS images from different sources. To address this issue, instead of directly using the manually designed similarity metrics, we propose an end-to-end similarity metric learning network, i.e., Siamese Transformer Network (STN) for CS-CBRSIR. Specifically, the proposed STN consists of three modules: (1) feature extraction module, which is a network combining Vision Transformer (ViT) with convolution layers, named as ConViT, (2) similarity metric function, which is a fully connected neural network (FCNN) aiming to compute the similarity between the output features from different sources, and (3) smooth average-precision (Smooth-AP) loss function, which measures the surrogate loss of standard AP metric to optimize the similarity metric function through backpropagation. Afterward, the learned similarity metric function can be adopted to implement the CS-CBRSIR accurately. Extensive experiments and ablation studies demonstrate that the proposed approach achieves promising performance in the CS-CBRSIR task.},
  archive      = {J_NCA},
  author       = {Ding, Chun and Wang, Meimin and Zhou, Zhili and Huang, Teng and Wang, Xiaoliang and Li, Jin},
  doi          = {10.1007/s00521-022-08092-6},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8125-8142},
  shortjournal = {Neural Comput. Appl.},
  title        = {Siamese transformer network-based similarity metric learning for cross-source remote sensing image retrieval},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy masking distributed saddle-point algorithm for
dynamic economic dispatch. <em>NCA</em>, <em>35</em>(11), 8109–8123. (<a
href="https://doi.org/10.1007/s00521-022-08089-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smart grids, the goal of the dynamic economic dispatch problem (DEDP) is to obtain the optimal dispatch schedule for each generating unit in a set of periods under certain constraints. A major challenge is that privacy disclosures possibly occur during the exchange and updating of communications. To address the issue, we propose a fully distributed saddle-point algorithm while preserving the privacy of participants by injecting the decaying Laplace noise. Based on the properties of the multi-Lyapunov function, we prove that the algorithm has an asymptotic convergence in the sense of expectation. Using the mechanism of differential privacy, we prove that the algorithm can guarantee $$\varepsilon$$ -differential privacy. In addition, we characterize the trade-off between levels of differential privacy and algorithmic accuracy. Finally, numerical simulations on IEEE 30-bus and IEEE 118-bus are used to validate the theoretical results.},
  archive      = {J_NCA},
  author       = {Xu, Kaihui and Li, Jueyou and Chen, Guo},
  doi          = {10.1007/s00521-022-08089-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8109-8123},
  shortjournal = {Neural Comput. Appl.},
  title        = {Privacy masking distributed saddle-point algorithm for dynamic economic dispatch},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification and spatio-temporal analysis of earthquake
clusters using SOM–DBSCAN model. <em>NCA</em>, <em>35</em>(11),
8081–8108. (<a
href="https://doi.org/10.1007/s00521-022-08085-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seismic catalogs are vital to understanding and analyzing the progress of active fault systems. The background seismicity rate in a seismic catalog, strongly associated with stressing rate, is the critical parameter in seismic hazard analysis. Estimating background seismicity is a complex task due to the high correlation with aftershock sequences which may dominate the background seismicity rate. In this paper, identification of the significant earthquake aftershocks and independent background events is performed using a two-stage clustering approach. It works in two phases: Self-Organized Map and Density-based Temporal Clustering. The event’s location and depth information in the earthquake catalog is used to identify the major hot spots (SOM prototypes) in the region (Spatial domain). Later, density-based temporal clustering is applied to decipher the neighborhood events of each SOM prototype. The proposed two-level clustering approach performs effective spatio-temporal analysis and identifies the aftershock clusters and background. The experimental study is carried out on the prominent earthquake catalogs of Taiwan, Afghanistan, California, the Himalayas, Indonesia, Chile, and Japan. The statistical parameters: Coefficient of Variation (time-domain) and m-Morisita index (spatial domain) justify and validate the accuracy of the presented approach. The proposed model is compared with benchmark de-clustering algorithms for mainshock and background detection.},
  archive      = {J_NCA},
  author       = {Sharma, Ashish and Vijay, Rahul Kumar and Nanda, Satyasai Jagannath},
  doi          = {10.1007/s00521-022-08085-5},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8081-8108},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification and spatio-temporal analysis of earthquake clusters using SOM–DBSCAN model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient sheep flock optimization-based hybrid deep RaNN
for secure and enhanced video transmission quality. <em>NCA</em>,
<em>35</em>(11), 8065–8080. (<a
href="https://doi.org/10.1007/s00521-022-08083-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video communication gained wide popularity since it offers a more real-time mode of face-to-face interaction. This paper mainly aims to enhance the video transmission quality of multimedia applications via communication network security improvement and an adaptive resource allocation strategy. The main aim of the resource allocation strategy is to achieve efficient usage of spectrum resources since video communication utilizes the orthogonal subcarriers for data transmission and the need for conversion of non-flat channels to flat. An optimized Hybrid Deep Random Neural Network (HDRaNN) architecture is used to overcome the adaptive spectrum resource allocation problem in the single-frequency network transmission by taking into account the different time–frequency resources and regions for overlapping areas and the same time–frequency for non-overlapping areas. The Sheep Flock Optimization algorithm is used to minimize the network error rate of the HDRaNN architecture by optimizing the weights and biases. The basic purpose of communication network security in this paper is to ensure that data communicated over a network connection are safe and secure. The network security protocol offers protection from unauthorized data retrieval and attempts to obtain data. The protocols utilized for secure communication in the proposed technique are Secure Hypertext Transfer Protocol, Secure Socket Layer, Simple Network Management Protocol, and Secure File Transfer Protocol. This protocol also assures that unauthorized users, devices, or services do not have access to your network data and works on all network mediums and data types. The extensive experiments conducted using the proposed methodology show improvements in the video transmission quality in terms of high diversity gain, security, increased throughput, and minimized bit error rate.},
  archive      = {J_NCA},
  author       = {Benisha, R. B.},
  doi          = {10.1007/s00521-022-08083-7},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8065-8080},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient sheep flock optimization-based hybrid deep RaNN for secure and enhanced video transmission quality},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SAdaBoundNc: An adaptive subgradient online learning
algorithm with logarithmic regret bounds. <em>NCA</em>, <em>35</em>(11),
8051–8063. (<a
href="https://doi.org/10.1007/s00521-022-08082-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive (sub)gradient methods have received wide applications such as the training of deep networks. The square-root regret bounds are achieved in convex settings. However, how to exploit strong convexity for improving convergence rate and improve the generalization performance of adaptive (sub)gradient methods remain an open problem. For this reason, we devise an adaptive subgradient online learning algorithm called SAdaBoundNc in strong convexity settings. Moreover, we rigorously prove that the logarithmic regret bound can be achieved by choosing a faster diminishing learning rate. Further, we conduct various experiments to evaluate the performance of SAdaBoundNc on four real-world datasets. The results demonstrate that the training speed of SAdaBoundNc outperforms stochastic gradient descent and several adaptive gradient methods in the initial training process. Moreover, the generalization performance of SAdaBou-ndNc is also better than the current state-of-the-art methods on different datasets.},
  archive      = {J_NCA},
  author       = {Wang, Lin and Wang, Xin and Li, Tao and Zheng, Ruijuan and Zhu, Junlong and Zhang, Mingchuan},
  doi          = {10.1007/s00521-022-08082-8},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8051-8063},
  shortjournal = {Neural Comput. Appl.},
  title        = {SAdaBoundNc: An adaptive subgradient online learning algorithm with logarithmic regret bounds},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MDVA-GAN: Multi-domain visual attribution generative
adversarial networks. <em>NCA</em>, <em>35</em>(11), 8035–8050. (<a
href="https://doi.org/10.1007/s00521-022-06969-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some pixels of an input image have thick information and give insights about a particular category during classification decisions. Visualization of these pixels is a well-studied problem in computer vision, called visual attribution (VA), which helps radiologists to recognize abnormalities and identify a particular disease in the medical image. In recent years, several classification-based techniques for domain-specific attribute visualization have been proposed, but these techniques can only highlight a small subset of most discriminative features. Therefore, their generated VA maps are inadequate to visualize all effects in an input image. Due to recent advancements in generative models, generative model-based VA techniques are introduced which generate efficient VA maps and visualize all affected regions. To deal the issue, generative adversarial network-based VA techniques are recently proposed, where the researchers leverage the advances in domain adaption techniques to learn a map for abnormal-to-normal medical image translation. As these approaches rely on a two-domain translation model, it would require training as many models as number of diseases in a medical dataset, which is a tedious and compute-intensive task. In this work, we introduce a unified multi-domain VA model that generates a VA map of more than one disease at a time. The proposed unified model gets images from a particular domain and its domain label as input to generate VA map and visualize all the affected regions by that particular disease. Experiments on the CheXpert dataset, which is a publicly available multi-disease chest radiograph dataset, and the TBX11K dataset show that the proposed model generates identical results.},
  archive      = {J_NCA},
  author       = {Nawaz, Muhammad and Al-Obeidat, Feras and Tubaishat, Abdallah and Zia, Tehseen and Maqbool, Fahad and Rocha, Alvaro},
  doi          = {10.1007/s00521-022-06969-0},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8035-8050},
  shortjournal = {Neural Comput. Appl.},
  title        = {MDVA-GAN: Multi-domain visual attribution generative adversarial networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterfactual explanation of bayesian model uncertainty.
<em>NCA</em>, <em>35</em>(11), 8027–8034. (<a
href="https://doi.org/10.1007/s00521-021-06528-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence systems are becoming ubiquitous in everyday life as well as in high-risk environments, such as autonomous driving, medical treatment, and medicine. The opaque nature of the deep neural network raises concerns about its adoption in high-risk environments. It is important for researchers to explain how these models reach their decisions. Most of the existing methods rely on softmax to explain model decisions. However, softmax is shown to be often misleading, particularly giving unjustified high confidence even for samples far from the training data. To overcome this shortcoming, we propose Bayesian model uncertainty for producing counterfactual explanations. In this paper, we compare the counterfactual explanation of models based on Bayesian uncertainty and softmax score. This work predictively produces minimal important features, which maximally change classifier output to explain the decision-making process of the Bayesian model. We used MNIST and Caltech Bird 2011 datasets for experiments. The results show that the Bayesian model outperforms the softmax model and produces more concise and human-understandable counterfactuals.},
  archive      = {J_NCA},
  author       = {Ali, Gohar and Al-Obeidat, Feras and Tubaishat, Abdallah and Zia, Tehseen and Ilyas, Muhammad and Rocha, Alvaro},
  doi          = {10.1007/s00521-021-06528-z},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8027-8034},
  shortjournal = {Neural Comput. Appl.},
  title        = {Counterfactual explanation of bayesian model uncertainty},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepClassRooms: A deep learning based digital twin framework
for on-campus class rooms. <em>NCA</em>, <em>35</em>(11), 8017–8026. (<a
href="https://doi.org/10.1007/s00521-021-06754-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A lot of different methods are being opted for improving the educational standards through monitoring of the classrooms. The developed world uses Smart classrooms to enhance faculty efficiency based on accumulated learning outcomes and interests. Smart classroom boards, audio-visual aids, and multimedia are directly related to the Smart classroom environment. Along with these facilities, more effort is required to monitor and analyze students’ outcomes, teachers’ performance, attendance records, and contents delivery in on-campus classrooms. One can achieve more improvement in quality teaching and learning outcomes by developing digital twins in on-campus classrooms. In this article, we have proposed DeepClass-Rooms, a digital twin framework for attendance and course contents monitoring for the public sector schools of Punjab, Pakistan. DeepClassRooms is cost-effective and requires RFID readers and high-edge computing devices at the Fog layer for attendance monitoring and content matching, using convolution neural network for on-campus and online classes.},
  archive      = {J_NCA},
  author       = {Razzaq, Saad and Shah, Babar and Iqbal, Farkhund and Ilyas, Muhammad and Maqbool, Fahad and Rocha, Alvaro},
  doi          = {10.1007/s00521-021-06754-5},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {8017-8026},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepClassRooms: A deep learning based digital twin framework for on-campus class rooms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comparative study of fourteen deep learning networks for
multi skin lesion classification (MSLC) on unbalanced data.
<em>NCA</em>, <em>35</em>(11), 7989–8015. (<a
href="https://doi.org/10.1007/s00521-022-06922-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among various types of skin diseases, skin cancer is the deadliest form of the disease. This paper classifies seven types of skin diseases: Actinic keratosis and intraepithelial carcinoma, Basal cell carcinoma, Benign keratosis, Dermatofibroma, Melanoma, Melanocytic type, and Vascular lesions. The primary objective of this paper is to evaluate the performance of these deep learning networks on skin lesion images. The lesion classification is implemented through transfer learning on fourteen deep learning networks: AlexNet, GoogleNet, ResNet50, VGG16, VGG19, ResNet101, InceptionV3, InceptionResNetV2, SqueezeNet, DenseNet201, ResNet18, MobileNetV2, ShuffleNet and NasNetMobile. The dataset used for these experiments are from ISIC 2018 of about 10,154 images. The results show that DenseNet201 performs best with 0.825 accuracy and improves skin lesion classification under multiple diseases. The proposed work shows the various parameters, including the accuracy of all fourteen deep learning networks, which helped build an efficient automated classification model for multiple skin lesions.},
  archive      = {J_NCA},
  author       = {Arora, Ginni and Dubey, Ashwani Kumar and Jaffery, Zainul Abdin and Rocha, Alvaro},
  doi          = {10.1007/s00521-022-06922-1},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {7989-8015},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comparative study of fourteen deep learning networks for multi skin lesion classification (MSLC) on unbalanced data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discriminator-based adversarial networks for knowledge graph
completion. <em>NCA</em>, <em>35</em>(11), 7975–7987. (<a
href="https://doi.org/10.1007/s00521-022-07680-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) inherently lack reasoning ability which limits their effectiveness for tasks such as question–answering and query expansion. KG embedding (KGE) is a predominant approach where proximity between relations and entities in the embedding space is used for reasoning over KGs. Most existing KGE approaches use structural information of triplets and disregard contextual information which could be crucial to learning long-term relations between entities. Moreover, KGE approaches mostly use discriminative models which require both positive and negative samples to learn a decision boundary. KGs, by contrast, contain only positive samples, necessitating that negative samples are generated by replacing the head/tail of predicates with randomly chosen entities. They are thus usually irrational and easily discriminable from positive samples, which can prevent the learning of sufficiently robust classifiers. To address the shortcomings, we propose to learn contextualized KGE using pre-trained adversarial networks. We assume multi-hop relational paths(mh-RPs) as textual sequences for competitively learning discriminator-based KGE against the negative mh-RP generator. We use a pre-trained ELECTRA model and feed it with relational paths. We employ a generator to corrupt randomly chosen entities with plausible alternatives and a discriminator to predict whether an entity is corrupted or not. We perform experiments on multiple benchmark knowledge graphs, and the results show that our proposed KG-ELECTRA model outperforms BERT in link prediction.},
  archive      = {J_NCA},
  author       = {Tubaishat, Abdallah and Zia, Tehseen and Faiz, Rehana and Al Obediat, Feras and shah, Babar and Windridge, David},
  doi          = {10.1007/s00521-022-07680-w},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {7975-7987},
  shortjournal = {Neural Comput. Appl.},
  title        = {Discriminator-based adversarial networks for knowledge graph completion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning for histopathology images: An empirical
study. <em>NCA</em>, <em>35</em>(11), 7963–7974. (<a
href="https://doi.org/10.1007/s00521-022-07516-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Histopathology imaging is one of the key methods used to determine the presence of cancerous cells. However, determining the results from such medical images is a tedious task because of their size, which may cause a delay in results for days. Even though CNNs are widely used to analyze medical images, they can only learn short-term dependency and ignore long-term dependency, which could be crucial in processing higher dimensional histology images. Transformers, however, make use of a self-attention mechanism, which might be helpful to learn dependencies across an entire set of features. To process histology images, deep learning models require a large number of images, which is usually not available. Transfer learning, which is often used to deal with this issue, involves fine-tuning a trained model for use with medical images by adding features. In context, it is essential to analyze which CNNs or transformers are more conducive to transfer learning. In this study, we performed an empirical study to evaluate the performance of different pre-trained deep learning models for the classification of lung and colon cancer on histology images. Vision transformer and CNN models pre-trained on image-net are analyzed for the classification of histopathology images. We performed an experiment on the LC25000 dataset for the evaluation of models. The dataset consists of five classes, two belong to colon and three belong to lung cancer. The insights and observations obtained from an ablation study performed on different pre-trained models show vision transformers perform better than CNN based models for histopathology image classification using transfer learning. Moreover, the vision transformer with more layers of ViT-L32 performs better than ViTB32 with fewer layers.},
  archive      = {J_NCA},
  author       = {Aitazaz, Tayyab and Tubaishat, Abdullah and Al-Obeidat, Feras and Shah, Babar and Zia, Tehseen and Tariq, Ali},
  doi          = {10.1007/s00521-022-07516-7},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {7963-7974},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transfer learning for histopathology images: An empirical study},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective flower pollination algorithm: A new
technique for EEG signal denoising. <em>NCA</em>, <em>35</em>(11),
7943–7962. (<a
href="https://doi.org/10.1007/s00521-021-06757-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electroencephalogram (EEG) signal denoising problem has been considered a challenging task because of several artifact noises, such as eye blinking, eye movement, muscle activity, and power line interference, which can corrupt the original EEG signal during the recording time. Therefore, to remove these noises, the EEG signals must be processed to obtain efficient EEG features. Accordingly, several techniques have been proposed to reduce EEG noises, such as EEG signal denoising using wavelet transform (WT). The success of WT depends on the best configuration of its control parameters, which are often experimentally set. In this study, a multi-objective flower pollination algorithm (MOFPA) with WT (MOFPA-WT) is proposed to solve the EEG signal denoising problem. The novelty of this study is to find optimal EEG signal denoising parameters using MOFPA based on two measurement criteria for the denoised signals, namely minimum mean squared error (MSE) and maximum signal-to-noise ratio (SNR). The MOFPA-WT is tested using a standard EEG signal processing dataset, namely the EEG motor movement/imagery dataset. The performance of MOFPA-WT is evaluated using five criteria, namely SNR, SNR improvement, MSE, root mean squared error (RMSE), and percentage root mean square difference (PRD). Experiments are conducted using FPA with MSE, SNR, and MSE and SNR to show the effect of the multi-objective aspects on the performance of the proposed MOFPA-WT. Results show that FPA with MSE and SNR exhibits more subjective results than FPA with MSE and FPA with SNR. The convergence rate and Pareto front are also studied for the proposed MOFPA-WT.},
  archive      = {J_NCA},
  author       = {Alyasseri, Zaid Abdi Alkareem and Khader, Ahamad Tajudin and Al-Betar, Mohammed Azmi and Yang, Xin-She and Mohammed, Mazin Abed and Abdulkareem, Karrar Hameed and Kadry, Seifedine and Razzak, Imran},
  doi          = {10.1007/s00521-021-06757-2},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {7943-7962},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective flower pollination algorithm: A new technique for EEG signal denoising},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural correlates of affective content: Application to
perceptual tagging of video. <em>NCA</em>, <em>35</em>(11), 7925–7941.
(<a href="https://doi.org/10.1007/s00521-021-06591-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past years, a digital multimedia uprising has been experienced in every walk of life, due to which the un-annotated or unstructured multimedia content has always been a key issue for research. The multimedia content is usually created with some intended emotions, which the creator wants to induce in viewers. The affectiveness of the multimedia content can be measured by analyzing elicited emotions of its viewers. In this paper, we present a rigorous study of human cognition using EEG signals while watching a video, to analyze the affectiveness of video content. The analysis presented in this paper is done to establish an effective relationship between video content and the human emotional state. For this, the most effective scalp location and frequency ranges are identified for two categories of videos, i.e., excited and sad. Furthermore, a common affective response (CAR) is extracted for finding the distinguishable features for aforementioned categories of videos. The CAR is calculated and tested on the publicly available dataset “AMIGOS,” and the results presented here show the utility of cognitive features on extracted scalp locations and frequency ranges for automatic tagging of video content. The current research explores the innovative applicability of neuro-signals for a mouse-free video tagging based on human excitement level to augment a range of brain–computer interface (BCI)-based devices. It can further aid to automatically retrieve the video content which is exciting and interesting to human viewers. With this analysis, we aimed to provide a thorough analysis which can be used to customize a low-cost and mobile EEG system for automatic analysis and retrieval of videos.},
  archive      = {J_NCA},
  author       = {Sharma, Shanu and Dubey, Ashwani Kumar and Ranjan, Priya and Rocha, Alvaro},
  doi          = {10.1007/s00521-021-06591-6},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {7925-7941},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural correlates of affective content: Application to perceptual tagging of video},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emo-mirror: A proposal to support emotion recognition in
children with autism spectrum disorders. <em>NCA</em>, <em>35</em>(11),
7913–7924. (<a
href="https://doi.org/10.1007/s00521-021-06592-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a neurodevelopmental disorder defined as persistent difficulty in maturing the socialization process. Health professionals have used traditional methods in the therapies performed on patients with the aim of improving the expression of emotions by patients. However, they have not been sufficient to detect the different emotions expressed in the face of people according to different sensations. Therefore, different artificial intelligence techniques have been applied to improve the results obtained in these therapies. In this article, we propose the construction of an intelligent mirror to recognize five basic emotions: angry, scared, sad, happy and neutral. This mirror uses convolutional neural networks to analyze the images that are captured by a camera and compare it with the one that the patient should perform, thus supporting the therapies performed by health professionals in children with ASD. The proposal presents the platform and computer architecture, as well as the evaluation by specialists under the technology acceptance model.},
  archive      = {J_NCA},
  author       = {Pavez, Rodolfo and Diaz, Jaime and Arango-Lopez, Jeferson and Ahumada, Danay and Mendez-Sandoval, Carolina and Moreira, Fernando},
  doi          = {10.1007/s00521-021-06592-5},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {7913-7924},
  shortjournal = {Neural Comput. Appl.},
  title        = {Emo-mirror: A proposal to support emotion recognition in children with autism spectrum disorders},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on towards advancements in machine learning
for exploiting large-scale and heterogeneous repositories. <em>NCA</em>,
<em>35</em>(11), 7909–7911. (<a
href="https://doi.org/10.1007/s00521-022-08182-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Anwar, Sajid and Rocha, Álvaro},
  doi          = {10.1007/s00521-022-08182-5},
  journal      = {Neural Computing and Applications},
  number       = {11},
  pages        = {7909-7911},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on towards advancements in machine learning for exploiting large-scale and heterogeneous repositories},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An algorithm of nonnegative matrix factorization under
structure constraints for image clustering. <em>NCA</em>,
<em>35</em>(10), 7891–7907. (<a
href="https://doi.org/10.1007/s00521-022-08136-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) is a crucial method for image clustering. However, NMF may obtain low accurate clustering results because the factorization results contain no data structure information. In this paper, we propose an algorithm of nonnegative matrix factorization under structure constraints (SNMF). The factorization results of SNMF could maintain data global and local structure information simultaneously. In SNMF, the global structure information is captured by the cosine measure under the $$\ell _2$$ norm constraints. Meanwhile, $$\ell _2$$ norm constraints are utilized to get more discriminant data representations. A graph regularization term is employed to maintain the local structure. Effective updating rules are given in this paper. Moreover, the effects of different normalizations on similarities are investigated through experiments. On real datasets, the numerical results confirm the effectiveness of the SNMF.},
  archive      = {J_NCA},
  author       = {Jia, Mengxue and Li, Xiangli and Zhang, Ying},
  doi          = {10.1007/s00521-022-08136-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7891-7907},
  shortjournal = {Neural Comput. Appl.},
  title        = {An algorithm of nonnegative matrix factorization under structure constraints for image clustering},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust multi-view low-rank embedding clustering.
<em>NCA</em>, <em>35</em>(10), 7877–7890. (<a
href="https://doi.org/10.1007/s00521-022-08137-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant improvements of multi-view subspace clustering have emerged in recent years. However, multi-view data are often lying on high-dimensional space and inevitably corrupted by noise and even outliers, which pose challenges for fully exploiting the intrinsic underlying relevance of multi-view data, as the redundant and corrupted features are highly deceptive. To address the above problems, this paper proposes a robust multi-view low-rank embedding (RMLE) method for clustering. Specifically, RMLE projects each high-dimensional view onto a clean low-rank embedding space without energy loss, such that multiple high-quality candidate affinity graphs are yielded by using self-expressiveness subspace learning. Meanwhile, it integrates the clean complimentary information of multi-view data in semantic space to learn a shared consensus affinity graph. Further, an efficient alternating optimization algorithm is designed to solve our RMLE by the alternating direction method of multipliers. Extensive experiments on four benchmark multi-view datasets demonstrate the performance superiority and advantages of RMLE against many state-of-the-art clustering methods.},
  archive      = {J_NCA},
  author       = {Dai, Jian and Song, Hong and Luo, Yunzhi and Ren, Zhenwen and Yang, Jian},
  doi          = {10.1007/s00521-022-08137-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7877-7890},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust multi-view low-rank embedding clustering},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid artificial intelligence model for design of
reinforced concrete columns. <em>NCA</em>, <em>35</em>(10), 7867–7875.
(<a href="https://doi.org/10.1007/s00521-022-08164-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the optimum design of structures, the optimization process is an iterative one and it may last a long time. If the structural plan is updated, the optimization process is needed to be redone since dimensions and internal forces change. Also, the local market prices may show differences and the proposed design may not be the optimum anymore. To skip the optimization process, intelligence methods can be used to predict the optimum values. In the study, a model is proposed for cost optimum results of reinforced concrete columns. A hybrid method is presented that uses harmony search as a metaheuristic method in the optimum design and multi-layer perceptions as a type of artificial neural networks in machine learning to generate a model. The prediction results were evaluated for several error metrics, and the model is feasible in proposing optimum solutions.},
  archive      = {J_NCA},
  author       = {Nigdeli , Sinan Melih and Yücel, Melda and Bekdaş, Gebrail},
  doi          = {10.1007/s00521-022-08164-7},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7867-7875},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid artificial intelligence model for design of reinforced concrete columns},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved YOLOv5 network for real-time multi-scale traffic
sign detection. <em>NCA</em>, <em>35</em>(10), 7853–7865. (<a
href="https://doi.org/10.1007/s00521-022-08077-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sign detection is a challenging task for the unmanned driving system, especially for the detection of multi-scale targets and the real-time problem of detection. In the traffic sign detection process, the scale of the targets changes greatly, which will have a certain impact on the detection accuracy. Feature pyramid is widely used to solve this problem, but due to the diversity of traffic sign sizes, it cannot accurately extract multi-size feature maps, thus destroying the feature consistency between traffic signs. Moreover, in practical application, it is difficult for common methods to improve the detection accuracy of multi-scale traffic signs while ensuring real-time detection. In this paper, we propose an improved feature pyramid model, named AF-FPN, which utilizes the adaptive attention module (AAM) and feature enhancement module (FEM) to reduce the information loss in the process of feature map generation and enhance the representation ability of the feature pyramid. We replaced the original feature pyramid network in YOLOv5 with AF-FPN, which improves the detection performance for multi-scale targets of the YOLOv5 network under the premise of ensuring real-time detection. Furthermore, a new automatic learning data augmentation method is proposed to enrich the dataset and improve the robustness of the model to make it more suitable for practical scenarios. Extensive experimental results on the Tsinghua-Tencent 100 K (TT100K) dataset demonstrate that compared with several state-of-the-art methods, our method is more universal and superior.},
  archive      = {J_NCA},
  author       = {Wang, Junfan and Chen, Yi and Dong, Zhekang and Gao, Mingyu},
  doi          = {10.1007/s00521-022-08077-5},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7853-7865},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved YOLOv5 network for real-time multi-scale traffic sign detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Passive ship detection and classification using hybrid
cepstrums and deep compound autoencoders. <em>NCA</em>, <em>35</em>(10),
7833–7851. (<a
href="https://doi.org/10.1007/s00521-022-08075-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acoustic noise radiated from various ships in the same class is varying due to the changing machinery regimes, the multi-path propagation effect, time-varying underwater channels, and fluctuating ambient noise. The complex underwater propagation environment causes random fluctuations in the frequency, amplitude, and phase of the signal at the receiver point. Hence, in order to overcome the aforementioned problems, this study proposes a novel deep convolutional-recurrent autoencoder, evolving by a compound cepstral lifter. In this approach, the compound autoencoders automatically extract the features without information loss and human intervention, and hybrid cepstral lifters reduce the multi-path distortion and time-varying shallow underwater channel effects. In order to evaluate the performance of the proposed model, three underwater acoustic datasets, including synthetic, ShipsEar, and real experimental datasets, are exploited. For the sake of having a comprehensive comparison, the performance of the designed model is compared with ten recently proposed benchmark models. The results approve that the designed model with an average accuracy of 96.11\% and average giga-multiplier–accumulators equal to 0.019 reports the best accuracy and complexity than other benchmark models. Furthermore, the proposed model is less sensitive to SNR level compared to other benchmark models.},
  archive      = {J_NCA},
  author       = {Kamalipour, Maryam and Agahi, Hamed and Khishe, Mohammad and Mahmoodzadeh, Azar},
  doi          = {10.1007/s00521-022-08075-7},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7833-7851},
  shortjournal = {Neural Comput. Appl.},
  title        = {Passive ship detection and classification using hybrid cepstrums and deep compound autoencoders},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep variational models for collaborative filtering-based
recommender systems. <em>NCA</em>, <em>35</em>(10), 7817–7831. (<a
href="https://doi.org/10.1007/s00521-022-08088-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning provides accurate collaborative filtering models to improve recommender system results. Deep matrix factorization and their related collaborative neural networks are the state of the art in the field; nevertheless, both models lack the necessary stochasticity to create the robust, continuous, and structured latent spaces that variational autoencoders exhibit. On the other hand, data augmentation through variational autoencoder does not provide accurate results in the collaborative filtering field due to the high sparsity of recommender systems. Our proposed models apply the variational concept to inject stochasticity in the latent space of the deep architecture, introducing the variational technique in the neural collaborative filtering field. This method does not depend on the particular model used to generate the latent representation. In this way, this approach can be applied as a plugin to any current and future specific models. The proposed models have been tested using four representative open datasets, three different quality measures, and state-of-the-art baselines. The results show the superiority of the proposed approach in scenarios where the variational enrichment exceeds the injected noise effect. Additionally, a framework is provided to enable the reproducibility of the conducted experiments.},
  archive      = {J_NCA},
  author       = {Bobadilla, Jesús and Ortega, Fernando and Gutiérrez, Abraham and González-Prieto, Ángel},
  doi          = {10.1007/s00521-022-08088-2},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7817-7831},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep variational models for collaborative filtering-based recommender systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quasi-bipartite synchronization of heterogeneous memristive
neural networks via pinning control. <em>NCA</em>, <em>35</em>(10),
7801–7815. (<a
href="https://doi.org/10.1007/s00521-022-08087-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on quasi-bipartite synchronization of heterogeneous memristive neural networks (MNNs) with cooperative–competitive interactions. Firstly, MNNs with nonidentical uncertain parameters are investigated. A pinning control is adopted to study robust quasi-bipartite synchronization of uncertain MNNs over the signed graph. A sufficient condition is derived for robust quasi-bipartite synchronization. Secondly, a more general heterogeneous MNNs is further discussed over the signed graph. Due to the heterogeneities of the MNNs, quasi-bipartite synchronization is studied and the corresponding sufficient condition is obtained. Additionally, the upper bounds of quasi-bipartite synchronization for two kinds of MNNs are given. Finally, two examples are given to illustrate theoretical results.},
  archive      = {J_NCA},
  author       = {Yang, Jiuyu and Wang, Zhengxin and Feng, Yuanzhen and Lu, Yanling and Xiao, Min and Zheng, Cong},
  doi          = {10.1007/s00521-022-08087-3},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7801-7815},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quasi-bipartite synchronization of heterogeneous memristive neural networks via pinning control},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-view clustering algorithm for attributed weighted
multi-edge directed networks. <em>NCA</em>, <em>35</em>(10), 7779–7800.
(<a href="https://doi.org/10.1007/s00521-022-08086-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering acts as a critical topic for solving decision situations in networks. Different node clustering methods for undirected and directed graphs have been proposed in the literature, but less attention has been paid to the case of attributed weighted multi-edge digraphs (AWMEDiG). Nowadays, multi-source and multi-attributed data are used increasingly in decision sciences; however, traditional methods usually consider single-attributed and single-view data as the input. This type of directed network, whose nodes are described by a list of attributes and directed links are viewed as directed multi-edge, is a new challenge to graph clustering. This paper proposes a new approach to detecting and evaluating clusters of AWMEDiG based on the maximum clique method. Our algorithm first converts the given AWMEDiG into a new weighted graph. This transformation is carried out through a new structural-attributed similarity measurement, an improved version of our previous model. Then, the concept of the maximum clique is adopted to complete the clustering task. The main objective of this new approach is to improve the clustering quality by grouping the highly cohesive and homogeneous vertices. So, the entropy strongly tends to be zero. Moreover, since the number of clusters is not predefined, it has the ability to find out the natural number of clusters within a graph. The performance of the proposed algorithm is tested on a synthetic, provided for a three-view attributed weighted directed network including 50 nodes, and two real-world datasets: UK faculty and Seventh graders. The clustering results are analyzed based on the clusters’ entropy and density, meanwhile the precision and F-score indexes measure the accuracy of them.},
  archive      = {J_NCA},
  author       = {Khameneh, Azadeh Zahedi and Kilicman, Adem and Mahad, Zahari},
  doi          = {10.1007/s00521-022-08086-4},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7779-7800},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-view clustering algorithm for attributed weighted multi-edge directed networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning task-specific discriminative representations for
multiple object tracking. <em>NCA</em>, <em>35</em>(10), 7761–7777. (<a
href="https://doi.org/10.1007/s00521-022-08079-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-shot multiple object tracking (MOT), which learns object detection and identity embedding in a unified network, has attracted increasing attention due to its low complexity and high tracking speed. However, most one-shot trackers ignore that detection and re-identification (ReID) require different representations of features. The inherent difference between these two subtasks leads to optimization contradictions in the training procedure. This issue would result in suboptimal tracking performance. To alleviate this contradiction, we propose a novel dual-path transformation network (DTN) that decouples the shared features into detection-specific and ReID-specific representations. By learning task-specific features, this module satisfies the different requirements of both subtasks. Moreover, we observe that previous trackers generally utilize local information to distinguish targets and ignore global semantic relations, which are crucial for tracking. Therefore, we design a pyramid non-local network (PNN) that allows our network to explore pixel-to-pixel relations with a global receptive field. Meanwhile, PNN considers the scale information to enhance the robustness to scale variations. Extensive experiments conducted on three benchmarks, i.e., MOT16, MOT17, and MOT20, demonstrate the superiority of our tracker, namely DPTrack. The experimental results reveal that DPTrack achieves state-of-the-art performance, e.g., MOTA of 77.1 $$\%$$ and IDF1 of 74.9 $$\%$$ on MOT17. Moreover, DPTrack runs at 14.9FPS, and our lightweight version runs at 26.6FPS with only a slight performance decay.},
  archive      = {J_NCA},
  author       = {Wu, Han and Nie, Jiahao and Zhu, Ziming and He, Zhiwei and Gao, Mingyu},
  doi          = {10.1007/s00521-022-08079-3},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7761-7777},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning task-specific discriminative representations for multiple object tracking},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EmulART: Emulating radiative transfer—a pilot study on
autoencoder-based dimensionality reduction for radiative transfer
models. <em>NCA</em>, <em>35</em>(10), 7719–7760. (<a
href="https://doi.org/10.1007/s00521-022-08071-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dust is a major component of the interstellar medium. Through scattering, absorption and thermal re-emission, it can profoundly alter astrophysical observations. Models for dust composition and distribution are necessary to better understand and curb their impact on observations. A new approach for serial and computationally inexpensive production of such models is here presented. Traditionally these models are studied with the help of radiative transfer modelling, a critical tool to understand the impact of dust attenuation and reddening on the observed properties of galaxies and active galactic nuclei. Such simulations present, however, an approximately linear computational cost increase with the desired information resolution. Our new efficient model generator proposes a denoising variational autoencoder (or alternatively PCA), for spectral compression, combined with an approximate Bayesian method for spatial inference, to emulate high information radiative transfer models from low information models. For a simple spherical dust shell model with anisotropic illumination, our proposed approach successfully emulates the reference simulation starting from less than 1\% of the information. Our emulations of the model at different viewing angles present median residuals below 15\% across the spectral dimension and below 48\% across spatial and spectral dimensions. EmulART infers estimates for $$\sim $$ 85\% of information missing from the input, all within a total running time of around 20 minutes, estimated to be 6 $$\times $$ faster than the present target high information resolution simulations, and up to 50 $$\times $$ faster when applied to more complicated simulations.},
  archive      = {J_NCA},
  author       = {Rino-Silvestre, João and González-Gaitán, Santiago and Stalevski, Marko and Smole, Majda and Guilherme-Garcia, Pedro and Carvalho, Joao Paulo and Mourão, Ana Maria},
  doi          = {10.1007/s00521-022-08071-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7719-7760},
  shortjournal = {Neural Comput. Appl.},
  title        = {EmulART: Emulating radiative transfer—a pilot study on autoencoder-based dimensionality reduction for radiative transfer models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TransMCGC: A recast vision transformer for small-scale image
classification tasks. <em>NCA</em>, <em>35</em>(10), 7697–7718. (<a
href="https://doi.org/10.1007/s00521-022-08067-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-stage hierarchical structure is a basic and effective design pattern in convolution neural networks (CNNs). Recently, Vision Transformers (ViTs) have achieved impressive performance as a new architecture for various vision tasks. However, many unknown properties of ViTs need to be further explored. In this paper, we empirically find that despite having no explicit multi-stage hierarchical design like CNNs, ViT models are able to automatically organize layers into stages (or blockgroups) to gradually extract different levels of feature information. Moreover, ViT models organize more highly similar Transformer blocks in the last stage, where the multi-head self-attention becomes less effective to learn useful concepts for feature learning and thus may limit the model to get the expected performance gain. To this end, we further recast a new ViT framework, named TransMCGC, replacing the inefficient Transformer blocks in the last stage of Vision Transformer with the proposed convolutional operation MCGC blocks. The MCGC block consists of two sub-modules in parallel: Multi-branch Convolution module to integrate local neighborhood features and multi-scale context information, and Global Context module to capture global dependencies with negligible parameters. In this way, the proposed MCGC block integrates collaboratively convolution locality and global dependencies to enhance the feature learning ability of the model. Finally, extensive experiments on six standard small-scale benchmark datasets, including CIFAR10, CIFAR100, Stanford Cars, Oxford102flowers, DTD and Food101, demonstrate the effectiveness of the proposed MCGC block and indicate that our TransMCGC models achieve better performance over baseline model ViT, while achieving competitive performance compared to state-of-the-art ViT variants.},
  archive      = {J_NCA},
  author       = {Xiang, Jian-Wen and Chen, Min-Rong and Li, Pei-Shan and Zou, Hao-Li and Li, Shi-Da and Huang, Jun-Jie},
  doi          = {10.1007/s00521-022-08067-7},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7697-7718},
  shortjournal = {Neural Comput. Appl.},
  title        = {TransMCGC: A recast vision transformer for small-scale image classification tasks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Dynamic adaptive generative adversarial networks with
multi-view temporal factorizations for hybrid recovery of missing
traffic data. <em>NCA</em>, <em>35</em>(10), 7677–7696. (<a
href="https://doi.org/10.1007/s00521-022-08064-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Making reliable recovery of missing traffic data facilitates diverse applications of data-driven intelligent transportation system. But faced with correlation and heterogeneity along spatial–temporal dimensions, most existing works lack sufficient capability to capture these complex properties, resulting in suboptimal imputation performance. By addressing this challenge, we propose a hybrid framework TFs-DGAN consisting of dynamic adaptive generative adversarial networks (DA-GAN) with multi-view temporal factorizations (TFs), which can efficiently repair missing data by modeling those spatial–temporal correlations. Of these, DA-GAN model can generate traffic data from noise distribution and keep iterating dynamically to extract the global consistency. To further exploit the local consistency, TFs model drives the continual reduction in local elements in residuals by a novel truncation mechanism. Unlike the single model computation, TFs-DGAN integrates all stage-optimized residuals by local feedback and finally outputs the best repair results. In fact, our intention for this strategy is that DA-GAN module produces data but inaccurately, while TFs module refines its imperfections by modeling multi-view temporal properties. From the numerical analysis, the empirical evaluation relying on two publicly available traffic datasets suggests that our TFs-DGAN significantly outperforms the state-of-the-art baseline models in terms of accuracy, stability and computational efficiency.},
  archive      = {J_NCA},
  author       = {Li, Jinlong and Li, Ruonan and Huang, Zilin and Wu, Pan and Xu, Lunhui},
  doi          = {10.1007/s00521-022-08064-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7677-7696},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic adaptive generative adversarial networks with multi-view temporal factorizations for hybrid recovery of missing traffic data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accompanying deep framework for faults in motor and gearbox
with disproportion vibrational samples. <em>NCA</em>, <em>35</em>(10),
7659–7676. (<a
href="https://doi.org/10.1007/s00521-022-08020-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important demand in the machinery environment is the frequent handling of variant faults occurring during active performance of motors and gearbox and through its vibrational signals. Accordingly, effective intelligent approaches detecting and treating causes of low productivity, reliability and higher maintenance cost have been introduced. A huge attention in recent years recommended deep learning and reports higher capabilities in this context. However, one limitation of using the deep learning is that its performance (in terms of evaluation matrices and/or over-fitting) is highly connected to the availability of large number of training samples as it learns by examples. This paper tackles this problem, proposing novel generative adversarial networks based augmentation method to balance the dataset and hence increase generalizability of the machine learning model. The generator of the generative adversarial networks method provides more samples with main objective of class balancing. Its discriminator recognizes the real and fake samples and assigns classes to the inputs as well. Accompanying deep framework based on the pervious augmentation method and a two subsequent unsupervised sparse autoencoders is also proposed to develop accurate intelligent identification model for motor and gearbox multi-faults with 10 classes. Precision, recall, and F1 measures proved the validity of the proposed augmentation when evaluated on the dataset of gear and motor signals and enhanced the class balancing. In addition, it enhances results of deep learning and reports identification accuracy of 93.7\%.},
  archive      = {J_NCA},
  author       = {Karamti, Hanen and Lashin, Maha M. A. and Alrowais, Fadwa and Mahmoud, Abeer M.},
  doi          = {10.1007/s00521-022-08020-8},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7659-7676},
  shortjournal = {Neural Comput. Appl.},
  title        = {Accompanying deep framework for faults in motor and gearbox with disproportion vibrational samples},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A penalty-based algorithm proposal for engineering
optimization problems. <em>NCA</em>, <em>35</em>(10), 7635–7658. (<a
href="https://doi.org/10.1007/s00521-022-08058-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a population-based evolutionary computation model for solving continuous constrained nonlinear optimization problems. The primary goal is achieving better solutions in a specific problem type, regardless of metaphors and similarities. The proposed algorithm assumes that candidate solutions interact with each other to have better fitness values. The interaction between candidate solutions is limited with the closest neighbors by considering the Euclidean distance. Furthermore, Tabu Search Algorithm and Elitism selection approach inspire the memory usage of the proposed algorithm. Besides, this algorithm is structured on the principle of the multiplicative penalty approach that considers satisfaction rates, the total deviations of constraints, and the objective function value to handle continuous constrained problems very well. The performance of the algorithm is evaluated with real-world engineering design optimization benchmark problems that belong to the most used cases by evolutionary optimization researchers. Experimental results show that the proposed algorithm produces satisfactory results compared to the other algorithms published in the literature. The primary purpose of this study is to provide an algorithm that reaches the best-known solution values rather than duplicating existing algorithms through a new metaphor. We constructed the proposed algorithm with the best combination of features to achieve better solutions. Different from similar algorithms, constrained engineering problems are handled in this study. Thus, it aims to prove that the proposed algorithm gives better results than similar algorithms and other algorithms developed in the literature.},
  archive      = {J_NCA},
  author       = {Oztas, Gulin Zeynep and Erdem, Sabri},
  doi          = {10.1007/s00521-022-08058-8},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7635-7658},
  shortjournal = {Neural Comput. Appl.},
  title        = {A penalty-based algorithm proposal for engineering optimization problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient hybrid-based charged system search algorithm
for active filter design. <em>NCA</em>, <em>35</em>(10), 7611–7633. (<a
href="https://doi.org/10.1007/s00521-022-08057-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active filter design is one of the complex real-world optimization problems for signal processing applications. Active filters contain essential parameters such as transistors, resistors, coils, and capacitors to calculate the output signal of the filter. These parameters can be estimated using optimization algorithms. Numerous algorithms are developed in the literature to solve optimization problems related to active filter design. Some well-known optimization algorithms are charged system search (CSS), local search (LS), and levy flight (LF) algorithms. Even though these optimization algorithms have their strengths, they still have weaknesses in stacking local minima, leading to less efficient results. Therefore, more efficient, and robust learning methods that get the most benefit from these optimization algorithms&#39; strongest sides are required to improve the convergence ability of the optimization algorithms. This research implements LS, LF, and a Hybrid optimization method containing both LS and LF onto CSS algorithm to estimate active filter parameters. These optimization algorithms are applied to 20 different benchmark functions to compare and validate the significance of the methods. Some other common approaches such as Genetic Algorithm (GA) and particle swarm optimization (PSO) are also included in the performance analysis to enhance the comparison of the methods. According to these 20 test functions&#39; results, CSS-hybrid is the winner by overperforming in 12 functions, whereas CSS-LS and CSS-LF is the winner by overperforming in 7 and 1 function, respectively. In addition, GA and PSO couldn’t be winner in any of the 20 benchmark functions. The proposed and common algorithms are applied to the low-pass (LP) and high-pass (HP) active filter components, which are a real-world problem for improving their exploitation and exploration balance. The obtained results demonstrate that the proposed methods have a remarkable improvement in predicting active filters parameters.},
  archive      = {J_NCA},
  author       = {Beşkirli, Mehmet and Egi, Yunus},
  doi          = {10.1007/s00521-022-08057-9},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7611-7633},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient hybrid-based charged system search algorithm for active filter design},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-head attention with CNN and wavelet for classification
of hyperspectral image. <em>NCA</em>, <em>35</em>(10), 7595–7609. (<a
href="https://doi.org/10.1007/s00521-022-08056-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral Image (HSI) is characterized by large number of bands with a high spectral resolution where continuous spectrum is measured for each pixel. This high volume therefore leads to challenges in processing the dataset. Objective of Dimensionality Reduction (DR) algorithms is to identify and eliminate statistical redundancies of hyperspectral data while keeping as much spectral information as possible. Combining spectral and spatial information offers a more comprehensive classification approach. Convolutional neural network (CNN) has the potential to extract complex spatial and spectral features embedded in Hyperspectral data. Wavelet transform belongs to the family of multi-scale transformation where the input signal is analyzed at different levels of granularity. Attention mechanism is a method in neural networks to guide the algorithm to focus on the important information in the data. In this paper, we use Multi-head Transformer-based Attention (Vaswani et al. in Attention is all you Need, http://arxiv.org/abs/1706.03762 2017) technique for Channel attention which captures the long-range spectral dependencies. The experimental results show that the proposed algorithm MT-CW Band Selection-based multi-head transformer for dimensionality reduction and Wavelet CNN-based algorithm for feature extraction yields impressive results in terms of information conservation and class separability.},
  archive      = {J_NCA},
  author       = {Tulapurkar, Harshula and Banerjee, Biplab and Buddhiraju, Krishna Mohan},
  doi          = {10.1007/s00521-022-08056-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7595-7609},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-head attention with CNN and wavelet for classification of hyperspectral image},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Tongue size and shape classification fusing segmentation
features for traditional chinese medicine diagnosis. <em>NCA</em>,
<em>35</em>(10), 7581–7594. (<a
href="https://doi.org/10.1007/s00521-022-08054-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The size and shape of the tongue can reflect different pathological changes of the human body in Traditional Chinese Medicine (TCM). Recently, convolutional neural networks (CNNs) have been widely used for the classification of the color, thickness and teeth marks of the tongue. However, only a few works have been devoted to tongue size and shape classification, which is also key evidence for tongue diagnosis. In this work, we proposed an efficient deep network, TSC-WNet, for tongue size and shape classification. The proposed TSC-WNet consists of two subnetworks, i.e. TSC-Net and TSC-UNet. While TSC-Net is a straightforward and effective classification backbone, TSC-UNet is built for tongue segmentation and offers complementary beneficial features to enhance the classification performance of the networks. Our classification backbone requires fewer parameters than classic CNNs like AlexNet, VGG16 and ResNet18, and achieves better classification performance. Employing TSC-Net as the encoder, the TSC-UNet was used to provide the segmentation information for helping better tongue size and shape classification. Two different datasets, i.e. FJTCM/SZU and BioHit, were employed for performance evaluation. The experimental results show that TSC-Net achieves at least 2\% higher accuracy and $$F_{1}$$ score than the baseline networks. Ablation studies show that the fusion of TSC-Net and TSC-UNet at both input and feature levels can further improve the accuracy and $$F_{1}$$ score by about 2\%. The code is available at: https://github.com/Yating-Huang/TSC-WNet .},
  archive      = {J_NCA},
  author       = {Huang, Yating and Li, Xuechen and Zheng, Siting and Li, Zhongliang and Li, Sihan and Shen, Linlin and Zhou, Changen and Lai, Zhihui},
  doi          = {10.1007/s00521-022-08054-y},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7581-7594},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tongue size and shape classification fusing segmentation features for traditional chinese medicine diagnosis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid arithmetic optimization algorithm for a new
multi-warehouse joint replenishment and delivery problem under trade
credit. <em>NCA</em>, <em>35</em>(10), 7561–7580. (<a
href="https://doi.org/10.1007/s00521-022-08052-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trade credit is a significant form of short-term financing in the real business situation. This study proposes a practical multi-warehouse joint replenishment and delivery (MJRD) problem under trade credit in accordance with the realistic situation. The goal of the MJRD is to find the reasonable basic replenishment cycle time, the joint replenishment frequency, the delivery frequency, and the assignment information of suppliers to minimize the total cost. Five intelligent algorithms, which include a differential evolution algorithm, genetic algorithm, adaptive hybrid differential evolution algorithm, arithmetic optimization algorithm (AOA), and hybrid arithmetic optimization algorithm (HAOA), are designed to find a solution to this MJRD problem under trade credit. The results of several experiments show that HAOA is effective in solving the proposed MJRD. Compared with AOA, the best improvement is 46.66\%. HAOA is a satisfactory algorithm for the proposed MJRD under trade credit.},
  archive      = {J_NCA},
  author       = {Peng, Lu and Wang, Lin and Wang, Sirui},
  doi          = {10.1007/s00521-022-08052-0},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7561-7580},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid arithmetic optimization algorithm for a new multi-warehouse joint replenishment and delivery problem under trade credit},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving distant supervision relation extraction with
entity-guided enhancement feature. <em>NCA</em>, <em>35</em>(10),
7547–7560. (<a
href="https://doi.org/10.1007/s00521-022-08051-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selective attention in distant supervision extraction relation is advantageous to deal with incorrectly labeled sentences in a bag, but it does not help in cases where many sentence bags consist of only one sentence. To resolve the deficiencies, we propose an entity-guided enhancement feature neural network for distant supervision relation extraction. We discover that key relation features are typically found in both significant words and phrases, which can be captured by entity guidance. We first develop an entity-directed attention that measures the relevance between entities and two levels of semantic units from word and phrase to capture reliable relation features, which are used to enhance the entity representations. Furthermore, two multi-level augmented entity representations are transformed to a relation representation via a linear layer. Then we adopt a semantic fusion layer to fuse multiple semantic representations such as the sentence representation encoded by piecewise convolutional neural network, two multi-level augmented entity representations, and the relation representation to get final enhanced sentence representation. Finally, with the guidance of the relation representations, we introduce a gate pooling strategy to generate a bag-level representation and address the one-sentence bag problem occurring in selective attention. Extensive experiments demonstrate that our method outperforms the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Wen, Haixu and Zhu, Xinhua and Zhang, Lanfang},
  doi          = {10.1007/s00521-022-08051-1},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7547-7560},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving distant supervision relation extraction with entity-guided enhancement feature},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic-aware multi-branch interaction network for deep
multimodal learning. <em>NCA</em>, <em>35</em>(10), 7529–7545. (<a
href="https://doi.org/10.1007/s00521-022-08048-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep multimodal learning has attracted increasing attention in artificial intelligence since it bridges vision and language. Most existing works only focus on specific multimodal tasks, which limits the ability to generalize to other tasks. Furthermore, these works only learn coarse-grained interactions at the object-level in images and the word-level in text, while ignoring to learn fine-grained interactions at relation-level and attribute-level. In this paper, to alleviate these issues, we propose a Semantic-aware Multi-Branch Interaction (SeMBI) network for various multimodal learning tasks. The SeMBI mainly consists of three modules, Multi-Branch Visual Semantics (MBVS) module, Multi-Branch Textual Semantics (MBTS) module and Multi-Branch Cross-modal Alignment (MBCA) module. The MBVS enhances the visual features and performs reasoning through three parallel branches, corresponding to the latent relationship branch, explicit relationship branch and attribute branch. The MBTS learns relation-level language context and attribute-level language context by textual relationship branch and textual attribute branch, respectively. The enhanced visual features then passed into MBCA to learn fine-grained cross-modal correspondence under the guidance of relation-level and attribute-level language context. We demonstrate the generalizability and effectiveness of the proposed SeMBI by applying it to three deep multimodal learning tasks, including Visual Question Answering (VQA), Referring Expression Comprehension (REC) and Cross-Modal Retrieval (CMR). Extensive experiments conducted on five common benchmark datasets indicate superior performance comparing with state-of-the-art works.},
  archive      = {J_NCA},
  author       = {Pan, Hao and Huang, Jun},
  doi          = {10.1007/s00521-022-08048-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7529-7545},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semantic-aware multi-branch interaction network for deep multimodal learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the performance analysis of various features and
classifiers for handwritten devanagari word recognition. <em>NCA</em>,
<em>35</em>(10), 7509–7527. (<a
href="https://doi.org/10.1007/s00521-022-08045-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Holistic-based or segmentation-free handwritten word recognition is one of a pattern recognition problem that aims to recognize the entire word image as a single entity. It is a new modality that recognizes handwritten words from its overall shape and performs better than its complement, i.e., analytic approach for given small lexicon size. Due to technological advancements, society is becoming paperless and prefers to use digital platform for various tasks. This paper deals with the use of holistic approach for the recognition of offline handwritten Devanagari words based on some statistical features. Feature vector sets have been generated to describe each word in the feature space by extracting unıform zoning-, diagonal- and centroid-based features from the database of handwritten word images (50-word classes). Various classifiers, namely K-nearest neighbor (KNN), decision tree and random forest, are employed for the recognition purpose. Furthermore to enhance the system performance, combination of above mentioned features along with gradient boosted decision tree algorithm is proposed. In this way, proposed system achieved maximum recognition accuracy of 94.53\% and the attained competent results are comparable with exiting state-of-the-art methods. Moreover, the proposed system has achieved F1-score of 94.56\%, FAR of 0.11\%, FRR of 5.46\%, MCC of 0.945 and AUC of 97.21\%.},
  archive      = {J_NCA},
  author       = {Singh, Sukhjinder and Garg, Naresh Kumar and Kumar, Munish},
  doi          = {10.1007/s00521-022-08045-z},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7509-7527},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the performance analysis of various features and classifiers for handwritten devanagari word recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sensitive deep learning application on sleep stage scoring
by using all PSG data. <em>NCA</em>, <em>35</em>(10), 7495–7508. (<a
href="https://doi.org/10.1007/s00521-022-08037-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polysomnography (PSG)-based sleep stage scoring is time-consuming and it suffers from variability in results. With the help of automated PSG scoring, which is based on deep learning techniques, it is possible to reduce labor costs and variability inherent to this task. Instead of using publicly available sleep databases, we created our database by using the Philips Alice clinic device, which employs 19 sensor channels connected to subjects. Since every sensor channel creates a huge amount of data, we limited our work to 50 patients and pre-processed this data. The deep learning sleep-based sleep stage classifier demonstrates excellent accuracy and agreement with the sleep expert’s scoring. Average accuracy, precision, recall, and F1-measure were defined as 91.6, 90.9, 91.6, and 90.7\% respectively. The proposed work has novelty when it is compared with similar deep learning-based automatic sleep staging studies by using 19 channels as input rather than employing only EEG, EOG, or EMG data. The proposed model is scientifically created for making job quite similar to the sleep doctors during sleep stage scoring automatically instead of manual steps used by them. Furthermore, as explained, our database is created by using a local hospital, which has a sleep clinic, rather than using publicly available databases. The proposed work will allow a fully automated PSG scoring system by having its own database and employing all PSG inputs.},
  archive      = {J_NCA},
  author       = {Arslan, Recep Sinan and Ulutas, Hasan and Köksal, Ahmet Sertol and Bakir, Mehmet and Çiftçi, Bülent},
  doi          = {10.1007/s00521-022-08037-z},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7495-7508},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sensitive deep learning application on sleep stage scoring by using all PSG data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-channel spatial–temporal difference graph neural
network for PM <span class="math display"><sub>2.5</sub></span>
forecasting. <em>NCA</em>, <em>35</em>(10), 7475–7494. (<a
href="https://doi.org/10.1007/s00521-022-08036-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate PM $$_{2.5}$$ forecasting is significant for improving quality of life and human health. However, it is very challenging to capture the high spatiotemporal correlations and the complex diffusion processes of PM $$_{2.5}$$ . Most existing PM $$_{2.5}$$ prediction methods only focus on spatiotemporal dependencies. In addition, the PM $$_{2.5}$$ diffusion process with domain knowledge in deep learning is rarely considered. Therefore, how to simultaneously capture comprehensive spatiotemporal dependencies and model the complicated diffusion process of PM $$_{2.5}$$ is still a challenge. To address this problem, we propose a dual-channel spatial–temporal difference graph neural network (DC-STDGN) to forecast future PM $$_{2.5}$$ concentrations. DC-STDGN first constructs a dual-channel structure to obtain distance-based local neighboring information and the global hidden spatial correlation of the data. Then, a temporal convolution layer is designed to handle the long-term dependency. Finally, the spatial difference with domain knowledge is introduced to model the complex diffusion process and capture more comprehensive spatiotemporal correlations. The extensive experiments with three real-world datasets demonstrate the improved prediction performance of DC-STDGN over state-of-the-art baselines. DC-STDGN outperforms the second-best model by up to 16.9\% improvement in mean absolute error, 8.9\% improvement in root mean square error and 18.2\% improvement in mean absolute scaled error.},
  archive      = {J_NCA},
  author       = {Ouyang, Xiaocao and Yang, Yan and Zhang, Yiling and Zhou, Wei and Guo, Dongyu},
  doi          = {10.1007/s00521-022-08036-0},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7475-7494},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual-channel spatial–temporal difference graph neural network for PM $$_{2.5}$$ forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ABOA-CNN: Auction-based optimization algorithm with
convolutional neural network for pulmonary disease prediction.
<em>NCA</em>, <em>35</em>(10), 7463–7474. (<a
href="https://doi.org/10.1007/s00521-022-08033-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, deep learning plays a vital role behind many of the emerging technologies. Few applications of deep learning include speech recognition, virtual assistant, healthcare, entertainment, and so on. In healthcare applications, deep learning can be used to predict diseases effectively. It is a type of computer model that learns in conducting classification tasks directly from text, sound, or images. It also provides better accuracy and sometimes outdoes human performance. We presented a novel approach that makes use of the deep learning method in our proposed work. The prediction of pulmonary disease can be performed with the aid of convolutional neural network (CNN) incorporated with auction-based optimization algorithm (ABOA) and DSC process. The traditional CNN ignores the dominant features from the X-ray images while performing the feature extraction process. This can be effectively circumvented by the adoption of ABOA, and the DSC is used to classify the pulmonary disease types such as fibrosis, pneumonia, cardiomegaly, and normal from the X-ray images. We have taken two datasets, namely the NIH Chest X-ray dataset and ChestX-ray8. The performances of the proposed approach are compared with deep learning-based state-of-art works such as BPD, DL, CSS-DL, and Grad-CAM. From the performance analyses, it is confirmed that the proposed approach effectively extracts the features from the X-ray images, and thus, the prediction of pulmonary diseases is more accurate than the state-of-art approaches.},
  archive      = {J_NCA},
  author       = {Annamalai, Balaji and Saravanan, Prabakeran and Varadharajan, Indumathi},
  doi          = {10.1007/s00521-022-08033-3},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7463-7474},
  shortjournal = {Neural Comput. Appl.},
  title        = {ABOA-CNN: Auction-based optimization algorithm with convolutional neural network for pulmonary disease prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DENA: Display name embedding method for chinese social
network alignment. <em>NCA</em>, <em>35</em>(10), 7443–7461. (<a
href="https://doi.org/10.1007/s00521-022-08014-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social network alignment, which aims at finding node correspondences between social networks, is the cornerstone of fusing big data from different social networks. Most of social network alignment solutions are based on English environment. Hence, the existing attribute-based solutions, which contain the unique features in English, are not suitable for Chinese social networks. Although structure-based methods are general, they suffer from the sparsity problem. To solve the Chinese social network alignment problem, in this paper, a novel display name embedding method is proposed, called DENA. It utilizes the morphological and phonetic information of Chinese characters to enhance the alignment accuracy. Specifically, in DENA, a hierarchical n-gram process framework is introduced to generate features from display names and their related morphological information (i.e., strokes) and phonetic information (i.e., pinyin). Then, an innovative graph called display name graph is proposed to transform them into an undirected and unweighted graph. By learning this graph, all features are embedded in to low-dimensional vectors. Therefore, the closeness between embedding vectors of display names represents the probability of the alignment between them. Experiments based on real-world datasets show that DENA outperforms traditional classification-based methods and the state-of-the-art word embedding methods in social network alignment.},
  archive      = {J_NCA},
  author       = {Li, Yao and Liu, Huilin},
  doi          = {10.1007/s00521-022-08014-6},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7443-7461},
  shortjournal = {Neural Comput. Appl.},
  title        = {DENA: Display name embedding method for chinese social network alignment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utilizing fog computing and explainable deep learning
techniques for gestational diabetes prediction. <em>NCA</em>,
<em>35</em>(10), 7423–7442. (<a
href="https://doi.org/10.1007/s00521-022-08007-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gestational diabetes mellitus (GDM) is one of the pregnancy complications that poses a significant risk on mothers and babies as well. GDM usually diagnosed at 22–26 of gestation. However, the early prediction is desirable as it may contribute to decrease the risk. The continuous monitoring for mother’s vital signs helps in predicting any deterioration during pregnancy. The originality of this paper is to provide comprehensive framework for pregnancy women monitoring. The proposed Data Replacement and Prediction Framework consists of three layers which are: (i) IoT Layer, (ii) Fog Layer, and (iii) Cloud Layer. The first layer used IOT sensors to aggregate vital sings from pregnancies using invasive and noninvasive sensors. Then the vital signs transmitted to fog nodes to processed and finally stored in the cloud layer. The main contribution in this paper is located in the fog layer producing GDM module to implement two influential tasks which are: (i) Data Finding Methodology (DFM), and (ii) Explainable Prediction Algorithm (EPM) using DNN. First, the DFM is used to replace the unused data to free the cache space for the new incoming data items. The cache replacement is very important in the case of healthcare system as the incoming vital signs are frequent and must be replaced continuously. Second, the EPM is used to predict the incidence of GDM that may occur in the second trimester of the pregnancy. To evaluate our model, we extract data of 16,354 pregnancy women from medical information mart for intensive care (MIMIC III) benchmark dataset. For each woman, vital signs, demographic data and laboratory tests was aggregated. The results of the prediction model superior the state of the art (ACC = 0.957, AUC = 0.942). Regarding to explainability, we utilized Shapley additive explanation framework to provide local and global explanation for the developed models. Overall, the proposed framework is medically intuitive, allow the early prediction of GDM with cost effective solution.},
  archive      = {J_NCA},
  author       = {El-Rashidy, Nora and ElSayed, Nesma E. and El-Ghamry, Amir and Talaat, Fatma M.},
  doi          = {10.1007/s00521-022-08007-5},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7423-7442},
  shortjournal = {Neural Comput. Appl.},
  title        = {Utilizing fog computing and explainable deep learning techniques for gestational diabetes prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognition of diseases of maize crop using deep learning
models. <em>NCA</em>, <em>35</em>(10), 7407–7421. (<a
href="https://doi.org/10.1007/s00521-022-08003-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disease attack on crops is one of the most serious threats to the global food supply chain. A proper, comprehensive and systematic solution is required for the early recognition of diseases and to reduce the overall crop loss. In this regard, deep learning techniques (especially convolutional neural networks (CNNs/ConvNets)) are being successfully applied for automatically recognizing the diseases of crops using digital images. This study proposes a novel 15-layer deep convolutional neural network (CNN) model for recognizing the diseases of maize crop. Around 3852 images of maize crop were collected from the PlantVillage data-repository. This dataset contains leaf images of three diseases viz. gray Leaf Spot (GLS), Common Rust (CR) and Northern Corn Leaf Blight (NCLB) as well as the healthy ones. The proposed model showed significant results for recognizing the unseen diseased images of the maize crop. We also employed a few popular pre-trained networks in the transfer learning approach for training on the maize dataset. We presented the comparative performance analysis between the proposed model and the pre-trained models in the result section of the manuscript. The experimental findings reported that our proposed model showed 3.2\% higher prediction performance with 3 × lesser trainable parameters than the best-performing pre-trained network (i.e., DenseNet121). The overall performance analysis reported that the proposed CNN model is very effective in identifying the images of maize diseases and also performs quite better than the popular pre-trained models.},
  archive      = {J_NCA},
  author       = {Haque, Md. Ashraful and Marwaha, Sudeep and Deb, Chandan Kumar and Nigam, Sapna and Arora, Alka},
  doi          = {10.1007/s00521-022-08003-9},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7407-7421},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recognition of diseases of maize crop using deep learning models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-target domain-based hierarchical dynamic instance
segmentation method for steel defects detection. <em>NCA</em>,
<em>35</em>(10), 7389–7406. (<a
href="https://doi.org/10.1007/s00521-022-07990-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s large-scale popularity of machinery manufacturing, people’s demand for the detection of steel plate surface defects has gradually increased over time. Nowadays, the production of steel plates in various fields has to be in line with the actual product application after multiple rounds of testing. However, due to material, machine, and processing technology problems, defects usually appear on the surface of the steel plate during the process of mass production of steel plates. These defects not only affect the beauty and the esthetics, but also they have an unfavorable impact on the performance of the steel plate, and can even lead to a series of safety problems. Thus, we need to improve the requirements for the detection of defects on the surface of the steel plate. With the improvement of computer computing power and automation technology, deep learning has taken advantage of this development. It is one of the most representative fields of artificial intelligence, excelling in image classification, target detection, segmentation, and tracking of targets. For defect detection tasks with a small number of labeled samples, a large number of unlabeled samples, and a wide range of data sources, the unsupervised domain adaptive method was adopted to realize knowledge transfer between data in different domains to solve the above problems. The unsupervised domain adaptive method can train the defect segmentation model effectively by using labeled source domain data and unlabeled target domain data. In this way, the model can obtain better segmentation results in the target domain without increasing other costs. From the point of view of scene setting, most of the unsupervised domain adaptive methods are focused on a single-source single-target domain. To adapt to the real factory environment, we extended the domain adaptive method of steel plate surface defect feature learning to multi-source single-target and multi-source multi-target domains. Hence, we realized the effective migration of defect features among data in different domains and provided corresponding solutions for segmentation detection of multi-source data sets with few samples and no labels. Multi-target domain technology stands out in the field of related technologies with its powerful memory capability, nonlinear mapping capability, self-learning capability, and robustness. For training, we fed a small group of sample data into the network of generative adversarial networks. In this training, the low-level network could automatically learn the detailed features of the data, and the high-level network could automatically learn the abstract features. To improve industrial automation for the effective detection of steel plate surface defects, a deep learning-based algorithm was proposed for the detection of steel plate surface defects. The method was based on multi-target domain instance segmentation, which could well retain the texture and background integrated features in the visual features of steel plates; the dynamic random operation of the final pooling layer eliminated the multi-scale problem of steel plate vision; the multi-dimensional feature fusion of hierarchy ensured the diversity of features; thus, the recognition accuracy of steel plate surface defects was improved. In the image dataset of the detection of steel plate surface defects, the proposed method achieved outstanding performance compared with the other methods, which proved the effectiveness of the method.},
  archive      = {J_NCA},
  author       = {Zhang, Chi and Zhang, Xi},
  doi          = {10.1007/s00521-022-07990-z},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7389-7406},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-target domain-based hierarchical dynamic instance segmentation method for steel defects detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparison of recent metaheuristic optimization algorithms
to solve the SHE optimization problem in MLI. <em>NCA</em>,
<em>35</em>(10), 7369–7388. (<a
href="https://doi.org/10.1007/s00521-022-07980-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilevel inverters (MLIs) are one of the most popular topics of power electronics. Selective harmonic elimination (SHE) method is used to eliminate low-order harmonics in the MLI output voltage by determining the optimum switching angles. It includes the solution of nonlinear sets of transcendental equations. The optimization becomes more difficult as the number of levels in MLIs increases. Therefore, various metaheuristic algorithms have emerged toward obtaining optimal solutions to find the switching angles in the SHE problem in the last decade. In this study, a number of recent metaheuristics, such as ant lion optimization (ALO), hummingbird algorithm (AHA), dragonfly algorithm (DA), harris hawk optimization, moth flame optimizer (MFO), sine cosine algorithm (SCA), flow direction algorithm (FDA), equilibrium optimizer (EO), atom search optimization, artificial electric field algorithm and arithmetic optimization algorithm (AOA), are employed as an attempt to find the best optimization framework to identify switching moments in 11-level MLI. Marine predator algorithm (MPA), whale optimization algorithm (WOA), grey wolf optimizer (GWO), particle swarm optimization (PSO), multiverse optimizer (MVO), teaching–learning-based optimization (TLBO), and genetic algorithm (GA), which are widely used in solving this problem, are selected for performance analysis. AHA, ALO, AOA, DA, EO, FDA, GA, GWO, MFO, MPA, MVO, PSO, SCA, SSA, TLBO and WOA methods meet maximum 8\% THD requirement specified in IEEE 519 standard in the range of 0.4–0.9 modulation index. Simulation results show that MFO is superior other algorithms in terms of THD minimization, convergence rate, a single iteration time and robustness.},
  archive      = {J_NCA},
  author       = {Yiğit, Halil and Ürgün, Satılmış and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-022-07980-1},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7369-7388},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparison of recent metaheuristic optimization algorithms to solve the SHE optimization problem in MLI},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supervised contrastive learning for robust text adversarial
training. <em>NCA</em>, <em>35</em>(10), 7357–7368. (<a
href="https://doi.org/10.1007/s00521-022-07871-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lack of robustness is a serious problem for deep neural networks (DNNs) and makes DNNs vulnerable to adversarial examples. A promising solution is applying adversarial training to alleviate this problem, which allows the model to learn the features from adversarial examples. However, adversarial training usually produces overfitted models and may not work when facing a new attack. We believe this is because the previous adversarial training using cross-entropy loss ignores the similarity between the adversarial examples and the original examples, which will result in a low margin. Accordingly, we propose a supervised adversarial contrastive learning (SACL) approach for adversarial training. SACL uses supervised adversarial contrastive loss which contains both the cross-entropy term and adversarial contrastive term. The cross-entropy term is used for guiding DNN inductive bias learning, and the adversarial contrastive term can help models learn example representations by maximizing feature consistency under different original examples, which fits well with the goal of solving low margins. In addition, SACL only uses adversarial examples which can successfully fool the model and their corresponding original examples for training. This process is more advantageous to provide the model with more accurate information about the decision boundary and obtain a model that fits the example distribution. Experiments show that SACL can reduce the attack success rate of multiple adversarial attack algorithms against different models on text classification tasks. The defensive performance is significantly better than other adversarial training approaches without reducing the generalization ability of the model. In addition, the DNN model trained by our approach has high transferability and robustness.},
  archive      = {J_NCA},
  author       = {Li, Weidong and Zhao, Bo and An, Yang and Shangguan, Chenhan and Ji, Minzi and Yuan, Anqi},
  doi          = {10.1007/s00521-022-07871-5},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7357-7368},
  shortjournal = {Neural Comput. Appl.},
  title        = {Supervised contrastive learning for robust text adversarial training},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Speech dereverberation and source separation using DNN-WPE
and LWPR-PCA. <em>NCA</em>, <em>35</em>(10), 7339–7356. (<a
href="https://doi.org/10.1007/s00521-022-07884-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech signals observed from distantly placed microphones may have some acoustic interference, such as noise and reverberation. These may lead to the degradation of the quality of blind speech. Hence, it is necessary to process the acquired speech signals to separate the blind source and eliminate the reverberation. Therefore, we proposed a novel speech separation and dereverberation method, which is based on the incorporation of Locally Weighted Projection Regression (LWPR)-based Principal Component Analysis (PCA) and Deep Neural Network (DNN)-based Weighted Prediction Error (WPE). The proposed method preprocesses the mixed reverberant signal prior to the application of Blind Source Separation (BSS) and Blind Dereverberation (BD). The preprocessing of the input sample signals is performed with the exploitation of fast Fourier transform (FFT) and whitening approaches to convert the time domain signal into frequency domain signal and to generate the transformation matrices. Besides, the utilization of LWPR-PCA can perform the BSS and the DNN-WPE can be used to conduct the BD. Moreover, the experimental analysis of our proposed method is compared with the existing RPCA-SNMF, CBF, BA-CNMF, AFMNMF, and ISC-LPKF approaches. The experimental outcomes depict that the proposed method effectively separates the original signal from the mixed reverberant signals.},
  archive      = {J_NCA},
  author       = {Sheeja, Jasmine J. C. and Sankaragomathi, B.},
  doi          = {10.1007/s00521-022-07884-0},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7339-7356},
  shortjournal = {Neural Comput. Appl.},
  title        = {Speech dereverberation and source separation using DNN-WPE and LWPR-PCA},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Brain tumor segmentation using extended weiner and laplacian
lion optimization algorithm with fuzzy weighted k-mean embedding linear
discriminant analysis. <em>NCA</em>, <em>35</em>(10), 7315–7338. (<a
href="https://doi.org/10.1007/s00521-021-06709-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an efficient skull stripping method to improve the decision-making process. Extended Weiner filtering (EWF) is used for removing the noise and enhancing the quality of images. Further, laplacian lion optimization algorithm (LXLOA) is implemented. LXLOA utilizes the Otsu’s and Tsallis entropy fitness function to determine an optimal solution. The implemented LXLOA provides a threshold value required for performing the segmentation on the brain MRI images. The extracted features are selected using fuzzy weighted k-means embedding LDA (linear discriminant analysis) method for improving training of the classification model. The proposed LXLOA is extensively tested on standard benchmark functions CEC 2017 and outperforms the existing state-of-the-art algorithm. Rigorous statistical analysis is conducted to determine the statistical significance. Three-fold performance comparison is performed by considering (a) the quality of the segmented image; (b) accuracy, sensitivity, and specificity; and (c) computational cost of convergence for finding an optimal solution. Result reveals that LXLOA gives promising results and demonstrate effective outcomes on the standard quality measures (a) accuracy (97.37\%); (b) sensitivity (85.8\%); (c) specificity (90\%); and (d) precision (91.92\%).},
  archive      = {J_NCA},
  author       = {Vijh, Surbhi and Pandey, Hari Mohan and Gaurav, Prashant},
  doi          = {10.1007/s00521-021-06709-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7315-7338},
  shortjournal = {Neural Comput. Appl.},
  title        = {Brain tumor segmentation using extended weiner and laplacian lion optimization algorithm with fuzzy weighted k-mean embedding linear discriminant analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning-based joint self-optimisation method
for the fuzzy logic handover algorithm in 5G HetNets. <em>NCA</em>,
<em>35</em>(10), 7297–7313. (<a
href="https://doi.org/10.1007/s00521-021-06673-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G heterogeneous networks (HetNets) can provide higher network coverage and system capacity to the user by deploying massive small base stations (BSs) within the 4G macrosystem. However, the large-scale deployment of small BSs significantly increases the complexity and workload of network maintenance and optimisation. The current handover (HO) triggering mechanism A3 event was designed only for mobility management in the macrosystem. Directly implementing A3 in 5G-HetNets may degrade the user mobility robustness. Motivated by the concept of self-organisation networks (SON), this study developed a self-optimisation triggering mechanism to enable automated network maintenance and enhance user mobility robustness in 5G-HetNets. The proposed method integrates the advantages of subtractive clustering and Q-learning frameworks into the conventional fuzzy logic-based HO algorithm (FLHA). Subtractive clustering is first adopted to generate a membership function (MF) for the FLHA to enable FLHA with the self-configuration feature. Subsequently, Q-learning is utilised to learn the optimal HO policy from the environment as fuzzy rules that empower the FLHA with a self-optimisation function. The FLHA with SON functionality also overcomes the limitations of the conventional FLHA that must rely heavily on professional experience to design. The simulation results show that the proposed self-optimisation FLHA can effectively generate MF and fuzzy rules for the FLHA. The proposed approach can minimise the HO, ping-pong HO, and HO failure ratios while improving network throughput and latency by comparing with conventional triggering mechanisms.},
  archive      = {J_NCA},
  author       = {Liu, Qianyu and Kwong, Chiew Foong and Wei, Sun and Zhou, Sijia and Li, Lincan and Kar, Pushpendu},
  doi          = {10.1007/s00521-021-06673-5},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7297-7313},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement learning-based joint self-optimisation method for the fuzzy logic handover algorithm in 5G HetNets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global stability of fuzzy cognitive maps. <em>NCA</em>,
<em>35</em>(10), 7283–7295. (<a
href="https://doi.org/10.1007/s00521-021-06742-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex systems can be effectively modelled by fuzzy cognitive maps. Fuzzy cognitive maps (FCMs) are network-based models, where the connections in the network represent causal relations. The conclusion about the system is based on the limit of the iteratively applied updating process. This iteration may or may not reach an equilibrium state (fixed point). Moreover, if the model is globally asymptotically stable, then this fixed point is unique and the iteration converges to this point from every initial state. There are some FCM models, where global stability is the required property, but in many FCM applications, the preferred scenario is not global stability, but multiple fixed points. Global stability bounds are useful in both cases: they may give a hint about which parameter set should be preferred or avoided. In this article, we present novel conditions for the global asymptotical stability of FCMs, i.e. conditions under which the iteration leads to the same point from every initial vector. Furthermore, we show that the results presented here outperform the results known from the current literature.},
  archive      = {J_NCA},
  author       = {Harmati, István Á. and Hatwágner, Miklós F. and Kóczy, László T.},
  doi          = {10.1007/s00521-021-06742-9},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7283-7295},
  shortjournal = {Neural Comput. Appl.},
  title        = {Global stability of fuzzy cognitive maps},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of incomplete data integrating neural
networks and evidential reasoning. <em>NCA</em>, <em>35</em>(10),
7267–7281. (<a
href="https://doi.org/10.1007/s00521-021-06267-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When missing data are imputed by any method, there is some uncertainty associated with the imputed value. Consequently, when such imputed data are classified, some uncertainty will be propagated to the classifier output. This leads to two issues to address. First, reducing the uncertainty in the imputed value. Second, modeling and processing of the uncertainty associated with the classifier output to arrive at a better decision. To deal with the first issue, we use a latent space representation, while for the second issue we use Dempster-Shafer evidence theory. First, we train a neural network using the data without any missing value to generate a latent space representation of the input. The complete data set is now extended by deleting every feature once. These missing values are estimated using a nearest neighbor-based scheme. The network is then refined using this extended dataset to obtain a better latent space. This mechanism is expected to reduce the effect of the missing data on the latent space representation. Using the latent space representation of the complete data, we train two classifiers, support vector machines and evidential t-nearest neighbors. To classify an input with a missing value, we make a rough estimate of the missing value using the nearest neighbor rule and generate its latent space representation for classification by the classifiers. Using each classifier output, we generate a basic probability assignment (BPA) and all BPAs are combined to get an overall BPA. Final classification is done using Pignistic probabilities computed on the overall BPA. We use three different ways to defining BPAs. To avoid some problems of Dempster’s rule of aggregation, we also use several alternative aggregations including some T-norm-based methods. Note that, T-norm has been used for combination of belief function in Pichon and Denœux (in: NAFIPS 2008: 2008 annual meeting of the North American fuzzy information processing society, pp 1–6, 2008). To demonstrate the superiority of the proposed method, we compare its performance with four state-of-the-art techniques using both artificial and real datasets.},
  archive      = {J_NCA},
  author       = {Choudhury, Suvra Jyoti and Pal, Nikhil R.},
  doi          = {10.1007/s00521-021-06267-1},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7267-7281},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of incomplete data integrating neural networks and evidential reasoning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An automatic heart disease prediction using cluster-based
bi-directional LSTM (c-BiLSTM) algorithm. <em>NCA</em>, <em>35</em>(10),
7253–7266. (<a
href="https://doi.org/10.1007/s00521-022-07064-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease involves many diseases like block blood vessels, heart attack, chest pain or stroke. Heart disease will affect the muscles, valves or heart rate, and bypass surgery or coronary artery surgery will be used to treat these problems. In this paper, UCI heart disease dataset and real time dataset are used to test the deep learning techniques which are compared with the traditional methods. To improve the accuracy of the traditional methods, cluster-based bi-directional long-short term memory (C-BiLSTM) has been proposed. The UCI and real time heart disease dataset are used for experimental results, and both the datasets are used as inputs through the K-Means clustering algorithm for the removal of duplicate data, and then, the heart disease has been predicted using C-BiLSTM approach. The conventional classifier methods such as Regression Tree, SVM, Logistic Regression, KNN, Gated Recurrent Unit and Ensemble are compared with C-BiLSTM, and the efficiency of the system is demonstrated in terms of accuracy, sensitivity and F1 score. The results show that the C-BiLSTM proves to be the best with 94.78\% accuracy of UCI dataset and 92.84\% of real time dataset compared to the six conventional methods for providing better prediction of heart disease.},
  archive      = {J_NCA},
  author       = {Dileep, P. and Rao, Kunjam Nageswara and Bodapati, Prajna and Gokuruboyina, Sitaratnam and Peddi, Revathy and Grover, Amit and Sheetal, Anu},
  doi          = {10.1007/s00521-022-07064-0},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7253-7266},
  shortjournal = {Neural Comput. Appl.},
  title        = {An automatic heart disease prediction using cluster-based bi-directional LSTM (C-BiLSTM) algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Building fuzzy time series model from unsupervised learning
technique and genetic algorithm. <em>NCA</em>, <em>35</em>(10),
7235–7252. (<a
href="https://doi.org/10.1007/s00521-021-06485-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new model to interpolate time series and forecast it effectively for the future. The important contribution of this study is the combination of optimal techniques for fuzzy clustering problem using genetic algorithm and forecasting model for fuzzy time series. Firstly, the proposed model finds the suitable number of clusters for a series and optimizes the clustering problem by the genetic algorithm using the improved Davies and Bouldin index as the objective function. Secondly, the study gives the method to establish the fuzzy relationship of each element to the established clusters. Finally, the developed model establishes the rule to forecast for the future. The steps of the proposed model are presented clearly and illustrated by the numerical example. Furthermore, it has been realized positively by the established MATLAB procedure. Performing for a lot of series (3007 series) with the differences about characteristics and areas, the new model has shown the significant performance in comparison with the existing models via some parameters to evaluate the built model. In addition, we also present an application of the proposed model in forecasting the COVID-19 victims in Vietnam that it can perform similarly for other countries. The numerical examples and application show potential in the forecasting area of this research.},
  archive      = {J_NCA},
  author       = {Phamtoan, Dinh and Vovan, Tai},
  doi          = {10.1007/s00521-021-06485-7},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7235-7252},
  shortjournal = {Neural Comput. Appl.},
  title        = {Building fuzzy time series model from unsupervised learning technique and genetic algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse data-based image super-resolution with ANFIS
interpolation. <em>NCA</em>, <em>35</em>(10), 7221–7233. (<a
href="https://doi.org/10.1007/s00521-021-06500-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing is a very broad field containing various areas, including image super-resolution (ISR) which re-represents a low-resolution image as a high-resolution one through a certain means of image transformation. The problem with most of the existing ISR methods is that they are devised for the condition in which sufficient training data is expected to be available. This article proposes a new approach for sparse data-based (rather than sufficient training data-based) ISR, by the use of an ANFIS (Adaptive Network-based Fuzzy Inference System) interpolation technique. Particularly, a set of given image training data is split into various subsets of sufficient and sparse training data subsets. Typical ANFIS training process is applied for those subsets involving sufficient data, and ANFIS interpolation is employed for the rest that contains sparse data only. Inadequate work is available in the current literature for the sparse data-based ISR. Consequently, the implementations of the proposed sparse data-based approach, for both training and testing processes, are compared with the state-of-the-art sufficient data-based ISR methods. This is of course very challenging, but the results of experimental evaluation demonstrate positively about the efficacy of the work presented herein.},
  archive      = {J_NCA},
  author       = {Ismail, Muhammad and Shang, Changjing and Yang, Jing and Shen, Qiang},
  doi          = {10.1007/s00521-021-06500-x},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7221-7233},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sparse data-based image super-resolution with ANFIS interpolation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ANFIS for prediction of epidemic peak and infected cases for
COVID-19 in india. <em>NCA</em>, <em>35</em>(10), 7207–7220. (<a
href="https://doi.org/10.1007/s00521-021-06412-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corona Virus Disease 2019 (COVID-19) is a continuing extensive incident globally affecting several million people&#39;s health and sometimes leading to death. The outbreak prediction and making cautious steps is the only way to prevent the spread of COVID-19. This paper presents an Adaptive Neuro-fuzzy Inference System (ANFIS)-based machine learning technique to predict the possible outbreak in India. The proposed ANFIS-based prediction system tracks the growth of epidemic based on the previous data sets fetched from cloud computing. The proposed ANFIS technique predicts the epidemic peak and COVID-19 infected cases through the cloud data sets. The ANFIS is chosen for this study as it has both numerical and linguistic knowledge, and also has ability to classify data and identify patterns. The proposed technique not only predicts the outbreak but also tracks the disease and suggests a measurable policy to manage the COVID-19 epidemic. The obtained prediction shows that the proposed technique very effectively tracks the growth of the COVID-19 epidemic. The result shows the growth of infection rate decreases at end of 2020 and also has delay epidemic peak by 40–60 days. The prediction result using the proposed ANFIS technique shows a low Mean Square Error (MSE) of 1.184 × 10–3 with an accuracy of 86\%. The study provides important information for public health providers and the government to control the COVID-19 epidemic.},
  archive      = {J_NCA},
  author       = {Kumar, Rajagopal and Al-Turjman, Fadi and Srinivas, L. N. B. and Braveen, M. and Ramakrishnan, Jothilakshmi},
  doi          = {10.1007/s00521-021-06412-w},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7207-7220},
  shortjournal = {Neural Comput. Appl.},
  title        = {ANFIS for prediction of epidemic peak and infected cases for COVID-19 in india},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge and data-driven hybrid system for modeling fuzzy
wastewater treatment process. <em>NCA</em>, <em>35</em>(10), 7185–7206.
(<a href="https://doi.org/10.1007/s00521-021-06499-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since wastewater treatment processes (WTP) are generally accompanied with intense coupling and fuzziness, conventional biochemical mechanisms-based methods cannot comprehensively express the WTP due to limited computational ability. In response to the challenge caused by fuzziness, this paper proposes a hybrid control and prediction system for modeling WTP with the fuse of Activated Sludge model, Convolutional neural network and Long short-term memory neural networks (AS-CL) with knowledge and data-driven characteristics. Moreover, the activated sludge model is employed to model the wastewater treatment process based on the perspective of knowledge. Besides, the hybrid neural network that combines convolutional neural network and long short-term memory model is adopted to model the WTP from the perspective of data. Then, a multi-layer perception model is set up to realize collaborative awareness of data and knowledge. Lastly, the proposed AS-CL has been evaluated by a real-world data-set collected from a real sewage treatment plant. The results show that compared with typical existing methods, the proposal improves modeling efficiency. With the collaborative modeling scheme, influence from fuzziness on WTP can be reduced to some extent. Compared with five benchmark methods of the two evaluation indexes, the results of AS-CL show that the average performance of this method exceeds 7\% of the baseline.},
  archive      = {J_NCA},
  author       = {Cheng, Xuhong and Guo, Zhiwei and Shen, Yu and Yu, Keping and Gao, Xu},
  doi          = {10.1007/s00521-021-06499-1},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7185-7206},
  shortjournal = {Neural Comput. Appl.},
  title        = {Knowledge and data-driven hybrid system for modeling fuzzy wastewater treatment process},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting tourist arrivals using dual decomposition
strategy and an improved fuzzy time series method. <em>NCA</em>,
<em>35</em>(10), 7161–7183. (<a
href="https://doi.org/10.1007/s00521-021-06671-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tourist arrivals forecasting has become an increasingly hot issue due to its important role in the tourism industry and hence the whole economy of a country. However, owing to the complex characteristics of tourist arrivals series, such as seasonality, randomness, and non-linearity, forecasting tourist arrivals remains a challenging task. In this paper, a hybrid model of dual decomposition and an improved fuzzy time series method is proposed for tourist arrivals forecasting. In the novel model, two stages are mainly involved, i.e., dual decomposition and integrated forecasting. In the first stage, a dual decomposition strategy, which can overcome the potential defects of individual decomposition approaches, is designed to fully extract the main features of the tourist arrivals series and reduce the data complexity. In the second stage, a fuzzy time series method with fuzzy C-means algorithm as the discretization method is developed for prediction. In the empirical study, the proposed model is implemented to predict the monthly tourist arrivals to Hong Kong from USA, UK, and Germany. The results show that our hybrid model can obtain more accurate and more robust prediction results than benchmark models. Relative to the benchmark fuzzy time series models, the hybrid models using traditional decomposition methods and strategies, as well as the traditional single prediction models, our proposed model shows a significant improvement, with the improvement percentages at about 80, 70, and 50\%, respectively. Therefore, we can conclude that the proposed model is a very promising tool for forecasting future tourist arrivals or other related fields with complex time series.},
  archive      = {J_NCA},
  author       = {Liang, Xiaozhen and Wu, Zhikun},
  doi          = {10.1007/s00521-021-06671-7},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7161-7183},
  shortjournal = {Neural Comput. Appl.},
  title        = {Forecasting tourist arrivals using dual decomposition strategy and an improved fuzzy time series method},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive fuzzy modeling of interval-valued stream data and
application in cryptocurrencies prediction. <em>NCA</em>,
<em>35</em>(10), 7149–7159. (<a
href="https://doi.org/10.1007/s00521-021-06263-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an adaptive interval fuzzy modeling method using participatory learning and interval-valued stream data. The model is a collection of fuzzy functional rules in which the rule base structure and the parameters of the rules evolve simultaneously as data are input. The evolving nature of the method allows continuous model adaptation using the stream interval input data. The method employs participatory learning to cluster the interval input data recursively, constructs a fuzzy rule for each cluster, uses the weighted recursive least squares to update the parameters of the rule consequent intervals, and returns an interval-valued output. The method is evaluated using actual data to model and forecast the daily lowest and highest prices of the four most traded cryptocurrencies, BitCoin, Ethereum, XRP, and LiteCoin. The performance of the adaptive interval fuzzy modeling is compared with the adaptive neuro-fuzzy inference system, long short-term memory neural network, autoregressive integrated moving average, exponential smoothing state model, and the naïve random walk methods. Results show that the suggested interval fuzzy model outperforms all these methods in predicting prices in the digital coin market, especially when considering directional accuracy measure.},
  archive      = {J_NCA},
  author       = {Maciel, Leandro and Ballini, Rosangela and Gomide, Fernando},
  doi          = {10.1007/s00521-021-06263-5},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7149-7159},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive fuzzy modeling of interval-valued stream data and application in cryptocurrencies prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on neuro, fuzzy and their hybridization.
<em>NCA</em>, <em>35</em>(10), 7147–7148. (<a
href="https://doi.org/10.1007/s00521-022-08181-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yang, Longzhi and Varadarajan, Vijayakumar and Qu, Yanpeng},
  doi          = {10.1007/s00521-022-08181-6},
  journal      = {Neural Computing and Applications},
  number       = {10},
  pages        = {7147-7148},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on neuro, fuzzy and their hybridization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy demand estimation in turkey according to modes of
transportation: Bezier search differential evolution and black widow
optimization algorithms-based model development and application.
<em>NCA</em>, <em>35</em>(9), 7125–7146. (<a
href="https://doi.org/10.1007/s00521-023-08245-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, Bezier search differential evolution (BeSD) and black widow optimization (BWO) algorithms-based estimation models in different forms have been developed to estimate the transportation energy consumption in Turkey. In order to examine the effect of demand distribution in modes of transportation on energy consumption, parameters in modes of transportation which are Passenger-km and Freight-km, Carbon dioxide emissions, Gross Domestic Product and Infrastructure Investment parameters are used as model parameters. Model performances are evaluated within different error criteria, and their performances are revealed. The BeSD algorithm performed better than the BWO algorithm and revealed that it is the most appropriate method for transportation energy demand (TED) estimation. Although each model developed using two different approaches is usable, BeSD-based quadratic model has shown the highest performance with a 0.95\% MAPE value, and TED&#39;s predictions for the future have been put forth based on this model. According to two different scenarios, TED projections until 2040 are presented for cases in which the current distribution of demand in modes of transportation and there is a demand shift from highway to other modes of transportation. The projections of the parameters have been determined by the least squares method. In the first scenario, it has been predicted that there will be 63 MTOE energy demand in 2040, and the projection values are consistent with the Ministry of Energy and Natural Resources values. In the second scenario, when demand shifts from the highway to other modes of transportation, it is predicted that energy consumption will decrease and there will be 42 MTOE in 2040.},
  archive      = {J_NCA},
  author       = {Korkmaz, Ersin},
  doi          = {10.1007/s00521-023-08245-1},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7125-7146},
  shortjournal = {Neural Comput. Appl.},
  title        = {Energy demand estimation in turkey according to modes of transportation: Bezier search differential evolution and black widow optimization algorithms-based model development and application},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid firefly and particle swarm optimization algorithm
with local search for the problem of municipal solid waste collection: A
real-life example. <em>NCA</em>, <em>35</em>(9), 7107–7124. (<a
href="https://doi.org/10.1007/s00521-022-08173-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of managing waste in rapidly growing urban areas has been a major problem for local administrations. One of the most critical issues in waste management is the collection and transportation of solid waste, which are both costly and difficult to address. The collection of the waste through the shortest route, at the lowest cost and in the fastest way is a major vehicle routing problem. This study addresses the problem of collecting waste in a district in the province of Şanlıurfa. To solve the problem in question, it proposes a hybrid firefly and particle swarm optimization algorithm developed using local search. The results revealed that the proposed algorithm provided 31\% better outcomes than those obtained in the real-life case, 10\% better than those of the geographic information system, and 5\% better than those of a linear programming model.},
  archive      = {J_NCA},
  author       = {KAYA, Serkan},
  doi          = {10.1007/s00521-022-08173-6},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7107-7124},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid firefly and particle swarm optimization algorithm with local search for the problem of municipal solid waste collection: A real-life example},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feasibility of a novel predictive model based on multilayer
perceptron optimized with harris hawk optimization for estimating of the
longitudinal dispersion coefficient in rivers. <em>NCA</em>,
<em>35</em>(9), 7081–7105. (<a
href="https://doi.org/10.1007/s00521-022-08074-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protecting water resources from pollution is one of the most important challenges facing water management researchers. The governing equation for river pollution is mostly the advection–dispersion equation, with considering the longitudinal dispersion coefficient as its most important effective parameter. The purpose of this paper is to develop a new framework for accurate prediction of the longitudinal dispersion coefficient of rivers based on artificial intelligence (AI) methods. To do this, we used a combination of multilayer perceptron (MLP), one of the most robust neural networks, and a novel metaheuristic algorithm, namely Harris hawk optimization (HHO). Besides, two optimized MLP models with particle swarm optimization (PSO) and imperialist competitive algorithm (ICA) were utilized to demonstrate the accuracy of the proposed model. To evaluate the developed models, 164 series of data collected from previous studies, including hydraulic and geometric parameters of rivers, were used. The indicated results proved the efficiency of the HHO to improve the optimum auto-selection of the AI models. Thus, the recorded results show very high accuracy of the newly developed model, MLP-HHO compared to others. Furthermore, to increase the prediction accuracy, a K-means clustering technique is coupled with MLP-HHO model during dividing the data to train and test categories. The proposed hybrid K-means-MLP-HHO model with coefficient of determination (R2) and root mean square error (RMSE), of 0.97 and 30.94 m2/s, respectively, significantly outperformed all existing and AI-based models. Furthermore, the sensitivity analysis showed that the flow width is the most influential factor in predicting the longitudinal dispersion coefficient.},
  archive      = {J_NCA},
  author       = {Ohadi, Sima and Hashemi Monfared, Seyed Arman and Azhdary Moghaddam, Mehdi and Givehchi, Mohammad},
  doi          = {10.1007/s00521-022-08074-8},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7081-7105},
  shortjournal = {Neural Comput. Appl.},
  title        = {Feasibility of a novel predictive model based on multilayer perceptron optimized with harris hawk optimization for estimating of the longitudinal dispersion coefficient in rivers},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-driven automatic detection of mucilage event
in the sea of marmara, turkey. <em>NCA</em>, <em>35</em>(9), 7063–7079.
(<a href="https://doi.org/10.1007/s00521-022-08097-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A slimy and sticky structure is formed in sea surface due to the excessive proliferation of plantlike organisms called phytoplankton, which is formed by the combination of many biological and chemical conditions, the increase in sea temperature and bacterial activities accordingly. The rapid detection of this structure called mucilage is very important in terms of early intervention and cost determination. Remote sensing methods have been used quite frequently in recent years for the automatic classification and localization of such events with the help of satellite images. Deep convolutional neural networks (DCNNs) trained on mucilage images are applied as a very successful method thanks to their ability to automatically extract superior features. The studies carried out for the target point detection obtained as a result of extracting the visual features from natural images with these networks have reached the goal. In this study, transfer learning methods are proposed to improve the detection of mucilage areas from the satellite images. The Sea of Marmara, which has been difficult times due to the mucilage events, was selected as the study area. The dataset was trained to classify mucilage images with the convolutional neural network (CNN) models and then reused to localize mucilage areas. Residual networks (ResNet)-50, visual geometry group (VGG)-16, VGG-19, and Inception-V3 were used for individual CNN models. Gradient-weighted class activation mapping (Grad-CAM) technique was used to visualize the learned behavior. A custom CNN model was created, and comparisons were made with the real mucilage areas with the intersection over union considering the most efficient convolutional layer to better localize the mucilage areas. It was concluded that the custom CNN model has showed superior localization performance compared to other models.},
  archive      = {J_NCA},
  author       = {Hacıefendioğlu, Kemal and Başağa, Hasan Basri and Baki, Osman Tuğrul and Bayram, Adem},
  doi          = {10.1007/s00521-022-08097-1},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7063-7079},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-driven automatic detection of mucilage event in the sea of marmara, turkey},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). NC <span class="math display"><sup>2</sup></span> e:
Boosting few-shot learning with novel class center estimation.
<em>NCA</em>, <em>35</em>(9), 7049–7062. (<a
href="https://doi.org/10.1007/s00521-022-08080-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate class distribution estimation is expected to solve the problem of the poor generalization ability that exists in few-shot learning models due to data shortages. However, the reliability of class distributions estimates based on limited samples and knowledge is questionable, especially for similar classes. We find that the distribution calibration method is inaccurate in estimating similar classes due to limited knowledge being reused through double-validation experiments. To address this issue, we propose a novel class center estimation (NC $$^2$$ E) method, which consists of a two-stage center estimation (TCE) algorithm and a class centroid estimation (CCE) algorithm. The class centers estimated by TCE in two stages are closer to the truth, and its superiority is demonstrated by error theory. CCE searches for the centroid of the base class iteratively and is used as the basis for the novel class calibration. Sufficient simulation samples are generated based on the estimated class distribution to augment the training data. The experimental results show that, compared with the distribution calibration method, the proposed method achieves an approximately 1\% performance improvement on the miniImageNet and CUB datasets; an approximately 1.45\% performance improvement for similar class classification; and an approximately 6.06\% performance improvement for non-similar class classification.},
  archive      = {J_NCA},
  author       = {Wu, Zheng and Shen, Changchun and Guo, Kehua and Luo, Entao and Wang, Liwei},
  doi          = {10.1007/s00521-022-08080-w},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7049-7062},
  shortjournal = {Neural Comput. Appl.},
  title        = {NC $$^2$$ e: Boosting few-shot learning with novel class center estimation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving node embedding by a compact neighborhood
representation. <em>NCA</em>, <em>35</em>(9), 7035–7048. (<a
href="https://doi.org/10.1007/s00521-022-08076-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Embedding, a learning paradigm that represents graph vertices, edges, and other semantic information about a graph into low-dimensional vectors, has found wide applications in different machine learning tasks. In the past few years, we have had a plethora of methods centered on graph embedding using different techniques, such as spectral classification, matrix factorization and learning. In this context, choosing the appropriate dimension of the obtained embedding remains a fundamental issue. In this paper, we propose a compact representation of a node’s neighborhood, including attributes and structure, that can be used as an additional dimension to enrich node embedding, to ensure accuracy. This compact representation ensures that both semantic and structural properties of a node’s neighboring-hood are properly captured in a single dimension. Consequently, we improve the learned embedding from state-of-the-art models by introducing the neighborhood compact representation for each node as an additional layer of dimensionality. We leverage on this neighborhood encoding technique and compare with embedding from state-of-the-art models on two learning tasks: node classification and link prediction. The performance evaluation shows that our approach gives a better prediction and classification accuracy in both tasks.},
  archive      = {J_NCA},
  author       = {Oluigbo, Ikenna Victor and Seba, Hamida and Haddad, Mohammed},
  doi          = {10.1007/s00521-022-08076-6},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7035-7048},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving node embedding by a compact neighborhood representation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-encoded multiplication-free spiking neural networks:
Application to data classification tasks. <em>NCA</em>, <em>35</em>(9),
7017–7033. (<a
href="https://doi.org/10.1007/s00521-022-07910-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are mimicking computationally powerful biologically inspired models in which neurons communicate through sequences of spikes, regarded here as sparse binary sequences of zeros and ones. In neuroscience it is conjectured that time encoding, where the information is carried by the temporal position of spikes, is playing a crucial role at least in some parts of the brain where estimation of the spiking rate with a large latency cannot take place. Motivated by the efficiency of temporal coding, compared with the widely used rate coding, the goal of this paper is to develop and train an energy-efficient time-coded deep spiking neural network system. To ensure that the similarity among input stimuli is translated into a correlation of the spike sequences, we introduce correlative temporal encoding and extended correlative temporal encoding techniques to map analog input information into input spike patterns. Importantly, we propose an implementation where all multiplications in the system are replaced with at most a few additions. As a more efficient alternative to both rate-coded SNNs and artificial neural networks, such system represents a preferable solution for the implementation of neuromorphic hardware. We consider data classification tasks where input spike patterns are presented to a feed-forward architecture with leaky-integrate-and-fire neurons. The SNN is trained by backpropagation through time with the objective to match sequences of output spikes with those of specifically designed target spike patterns, each corresponding to exactly one class. During inference the target spike pattern with the smallest van Rossum distance from the output spike pattern determines the class. Extensive simulations indicate that the proposed system achieves a classification accuracy at par with that of state-of-the-art machine learning models.},
  archive      = {J_NCA},
  author       = {Stanojevic, Ana and Cherubini, Giovanni and Woźniak, Stanisław and Eleftheriou, Evangelos},
  doi          = {10.1007/s00521-022-07910-1},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7017-7033},
  shortjournal = {Neural Comput. Appl.},
  title        = {Time-encoded multiplication-free spiking neural networks: Application to data classification tasks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low tensor-ring rank completion: Parallel matrix
factorization with smoothness on latent space. <em>NCA</em>,
<em>35</em>(9), 7003–7016. (<a
href="https://doi.org/10.1007/s00521-022-08023-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, tensor ring (TR) decomposition has drawn a lot of attention and was successfully applied to tensor completion problem, due to its more compact representation ability. As well known, both global and local structural information is important for tensor completion problem. Although the existing TR-based completion algorithms obtain the impressive performance in visual-data inpainting by using low-rank global structure information, most of them didn’t take into account local smooth property which is often exhibited in visual data. To further improve visual-data inpainting performance, both low-rank and piecewise smooth structures are incorporated in our model. Instead of directly applying local smooth constraint on the data surface, we impose the smoothness on its latent TR-space, which greatly reduces computational cost especially for large-scale data. Extensive experiments on real-world visual data show that our model not only obtains the state-of-the-art performance, but also is rather stable to the TR-ranks owing to the local smooth constraint.},
  archive      = {J_NCA},
  author       = {Yu, Jinshi and Zou, Tao and Zhou, Guoxu},
  doi          = {10.1007/s00521-022-08023-5},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {7003-7016},
  shortjournal = {Neural Comput. Appl.},
  title        = {Low tensor-ring rank completion: Parallel matrix factorization with smoothness on latent space},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Virtual sample generation method based on generative
adversarial fuzzy neural network. <em>NCA</em>, <em>35</em>(9),
6979–7001. (<a
href="https://doi.org/10.1007/s00521-022-08104-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key performance indicators of complex industrial process such as production quality and pollutant emissions concentration are difficult to be measured online due to limited detection technology and high economical cost. Their modeling samples have high dimension, strong uncertainty, and small sample, which cannot satisfy the needs of traditional machine learning algorithms. A virtual sample generation method based on generative adversarial fuzzy neural network (GAFNN) is proposed to address the abovementioned problems. First, an adaptive feature selection algorithm based on random forest is used to reduce input feature for the original real samples. Second, candidate virtual samples are generated by GAFNN to alleviate the problems of uncertainty and small sample. Third, the virtual samples are screened by a multi-constrained selection mechanism to improve the quality of virtual samples. Finally, a deep forest classification model is constructed on the basis of the mixed samples in terms of the original real and selected virtual samples. The effectiveness of the proposed method is verified on benchmark and real industrial data.},
  archive      = {J_NCA},
  author       = {Cui, Canlin and Tang, Jian and Xia, Heng and Qiao, Junfei and Yu, Wen},
  doi          = {10.1007/s00521-022-08104-5},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6979-7001},
  shortjournal = {Neural Comput. Appl.},
  title        = {Virtual sample generation method based on generative adversarial fuzzy neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ESMOTE: An overproduce-and-choose synthetic examples
generation strategy based on evolutionary computation. <em>NCA</em>,
<em>35</em>(9), 6891–6977. (<a
href="https://doi.org/10.1007/s00521-022-08004-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance learning problem is an important topic that has attracted considerable attention in machine learning and data mining. The most common method of addressing imbalanced datasets is the synthetic minority oversampling technique (SMOTE). However, the SMOTE and its variants suffer from the noise derived from the interpolation of synthetic examples. In this paper, an overproduce-and-choose strategy, which is divided into the overproduction and selection phases, is proposed to generate an appropriate set of synthetic examples for imbalance learning problems. In the overproduction phase, a new interpolation mechanism is developed to produce numerous synthetic examples, while in the selection phase, the synthetic examples that are beneficial to the classification task are selected by using instance selection based on evolutionary computation. Experiments are conducted on a large number of datasets selected from the real-world applications. The experimental results demonstrate that the proposed method is significantly better than SMOTE and its well-known variants in terms of several metrics, including G-mean (GM) and area under the curve.},
  archive      = {J_NCA},
  author       = {Zhang, Zhong-Liang and Peng, Rui-Rui and Ruan, Yuan-Peng and Wu, Jian and Luo, Xing-Gang},
  doi          = {10.1007/s00521-022-08004-8},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6891-6977},
  shortjournal = {Neural Comput. Appl.},
  title        = {ESMOTE: An overproduce-and-choose synthetic examples generation strategy based on evolutionary computation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ArcMask: A robust and fast image-based method for high-speed
railway pantograph-catenary arcing instance segmentation. <em>NCA</em>,
<em>35</em>(9), 6875–6890. (<a
href="https://doi.org/10.1007/s00521-022-08059-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pantograph-catenary arcing reflects the health of pantograph-catenary and current collection quality of high-speed railway, so the arc detection is of great significance. However, due to the scene complexity, intra-class polymorphism and inter-class similarity of arcing and the fast running speed of high-speed railway, it is still a huge challenge to achieve fine and robust arcing detection. To overcome these issues, a robust and fast image-based instance segmentation method called ArcMask is proposed to detect pantograph-catenary arcing, which designs a new attention-based multi-scale feature fusion module that combines both top-down and down-up modules to realize arcing pixel-level instance segmentation. The effective combination of instance-level information and bottom-level semantic information balances features representation ability of top-level and bottom-level features. Compared with other instance segmentation methods (e.g., BlendMask), it can effectively learn feature representation with tiny, irregular and complex arc features and speeds up the calculation. In addition, both deformable convolution and depth-wise separable convolution are introduced in ArcMask, which aims to improve the segmentation performance of irregular arcing and efficiency. The ArcMask can distinguish different arcing instances at pixel-level with fine granularity and distinguish inter-class and intra-class features of arcing, instead of just focusing on rectangular bounding box. Experiments on self-collected dataset IVAIS-PCA2021 verify the effectiveness and efficiencies of the ArcMask. Its AP, AP50 and AP75 are 56.61, 94.14 and 64.56, respectively, and the fastest reasoning speed based on MobileNet is 56 FPS. Compared with other state-of-the-art segmentation methods, the proposed ArcMask has better integrity in arcing edge detection.},
  archive      = {J_NCA},
  author       = {Quan, Wei and Guo, Shaopeng and Lu, Xuemin and Gu, Guoxin and Cheng, Wenjing and Zhou, Ning and Yu, Long},
  doi          = {10.1007/s00521-022-08059-7},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6875-6890},
  shortjournal = {Neural Comput. Appl.},
  title        = {ArcMask: A robust and fast image-based method for high-speed railway pantograph-catenary arcing instance segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Harris hawks optimization for COVID-19 diagnosis based on
multi-threshold image segmentation. <em>NCA</em>, <em>35</em>(9),
6855–6873. (<a
href="https://doi.org/10.1007/s00521-022-08078-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital image processing techniques and algorithms have become a great tool to support medical experts in identifying, studying, diagnosing certain diseases. Image segmentation methods are of the most widely used techniques in this area simplifying image representation and analysis. During the last few decades, many approaches have been proposed for image segmentation, among which multilevel thresholding methods have shown better results than most other methods. Traditional statistical approaches such as the Otsu and the Kapur methods are the standard benchmark algorithms for automatic image thresholding. Such algorithms provide optimal results, yet they suffer from high computational costs when multilevel thresholding is required, which is considered as an optimization matter. In this work, the Harris hawks optimization technique is combined with Otsu’s method to effectively reduce the required computational cost while maintaining optimal outcomes. The proposed approach is tested on a publicly available imaging datasets, including chest images with clinical and genomic correlates, and represents a rural COVID-19-positive (COVID-19-AR) population. According to various performance measures, the proposed approach can achieve a substantial decrease in the computational cost and the time to converge while maintaining a level of quality highly competitive with the Otsu method for the same threshold values.},
  archive      = {J_NCA},
  author       = {Ryalat, Mohammad Hashem and Dorgham, Osama and Tedmori, Sara and Al-Rahamneh, Zainab and Al-Najdawi, Nijad and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-022-08078-4},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6855-6873},
  shortjournal = {Neural Comput. Appl.},
  title        = {Harris hawks optimization for COVID-19 diagnosis based on multi-threshold image segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Insight into breast cancer detection: New hybrid feature
selection method. <em>NCA</em>, <em>35</em>(9), 6831–6853. (<a
href="https://doi.org/10.1007/s00521-022-08062-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer, which is also the leading cause of death among women, is one of the most common forms of the disease that affects females all over the world. The discovery of breast cancer at an early stage is extremely important because it allows selecting appropriate treatment protocol and thus, stops the development of cancer cells. In this paper, a new patients detection strategy has been presented to identify patients with the disease earlier. The proposed strategy composes of two parts which are data preprocessing phase and patient detection phase (PDP). The purpose of this study is to introduce a feature selection methodology for determining the most efficient and significant features for identifying breast cancer patients. This method is known as new hybrid feature selection method (NHFSM). NHFSM is made up of two modules which are quick selection module that uses information gain, and feature selection module that uses hybrid bat algorithm and particle swarm optimization. Consequently, NHFSM is a hybrid method that combines the advantages of bat algorithm and particle swarm optimization based on filter method to eliminate many drawbacks such as being stuck in a local optimal solution and having unbalanced exploitation. The preprocessed data are then used during PDP in order to enable a quick and accurate detection of patients. Based on experimental results, the proposed NHFSM improves the efficiency of patients’ classification in comparison with state-of-the-art feature selection approaches by roughly 0.97, 0.76, 0.75, and 0.716 in terms of accuracy, precision, sensitivity/recall, and F-measure. In contrast, it has the lowest error rate value of 0.03.},
  archive      = {J_NCA},
  author       = {Shaban, Warda M.},
  doi          = {10.1007/s00521-022-08062-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6831-6853},
  shortjournal = {Neural Comput. Appl.},
  title        = {Insight into breast cancer detection: New hybrid feature selection method},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel form-finding method via noise-tolerant neurodynamic
model for symmetric tensegrity structure. <em>NCA</em>, <em>35</em>(9),
6813–6830. (<a
href="https://doi.org/10.1007/s00521-022-08039-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the form-finding of symmetric tensegrity structure is discussed and investigated by means of force density method and neural network algorithm. An optimization model based on the rank deficiency maximization is established to solve feasible force density, and the nodal coordinates are determined by eigenvalue decomposition of force density matrix. Then, the Lagrangian multiplier method can transform constrained optimization problem into unconstrained optimization problem. To avoid high-dimensional Hessian matrix calculation, noise-tolerant neural algorithm (NTNA) is exploited to calculate the unconstrained optimization problem. Numerical results indicate that the proposed noise-tolerant neural-based quasi-Newton Broyden–Fletcher–Goldfarb–Shanno (NTN-QNBFGS) form-finding method enhances convergence speed. Furthermore, the consistency between the form-finding results and analytical solutions infers that the developed method can be effectively applied to the form-finding of tensegrity robot.},
  archive      = {J_NCA},
  author       = {Sun, Zhongbo and Heng, Taotao and Zhao, Liming and Liu, Keping and Jin, Long and Yu, Junzhi},
  doi          = {10.1007/s00521-022-08039-x},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6813-6830},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel form-finding method via noise-tolerant neurodynamic model for symmetric tensegrity structure},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sound source localization for auditory perception of a
humanoid robot using deep neural networks. <em>NCA</em>, <em>35</em>(9),
6801–6811. (<a
href="https://doi.org/10.1007/s00521-022-08047-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an estimation of the sound source location using deep neural networks in order to provide auditory perception of a humanoid robot. Estimation of a moving sound source is crucial for a humanoid robot to improve functionality in some environments where the robot’s camera cannot operate. It plays an important role, especially in a recovery scenario with no visual contact. In this study, the data of the sound source around the robot were recorded by four microphones placed on the humanoid robot’s head. A wheeled robot was used to obtain the sound source with odometry. Recorded sound dataset and collected odometry dataset were used as input data and target data, respectively. The discrete wavelet transform (DWT) was applied for pre-processing of the input data. After pre-processing, the obtained matrices were applied as inputs of the proposed convolutional neural network (CNN), long short-term memory (LSTM), bidirectional long-short-term memory (biLSTM), and multilayer perceptron (MLP) networks to estimate the sound source location around the humanoid robot. As a result of all tests for the estimation models created by proposed networks, the $$R^2$$ metrics of the biLSTM structure were obtained as approximately 0.97. This study showed experimentally that humanoid robots can sense the position of sound source in the environment with sufficient accuracy like many living creatures.},
  archive      = {J_NCA},
  author       = {Boztas, G.},
  doi          = {10.1007/s00521-022-08047-x},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6801-6811},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sound source localization for auditory perception of a humanoid robot using deep neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing artificial neural network models to predict
corrosion of reinforcement in mechanically stabilized earth walls.
<em>NCA</em>, <em>35</em>(9), 6787–6799. (<a
href="https://doi.org/10.1007/s00521-022-08043-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corrosion of reinforcement in mechanically stabilized earth (MSE) walls is mainly due to physical and chemical properties of back-fill materials, types of metal reinforcement, and environmental factors. Therefore, it is imperative to evaluate the corrosion levels of reinforcement in the design and construction of MSE walls. This study employed artificial neural networks (ANN) to build prediction models of corrosion of reinforcement (COR) based on collected corrosion factors from 489 in-situ boring samples of MSE walls on highways in France. The ANN models were built, trained and achieved the best performance at an ANN structure (12-20-18-1) with one input layer (12 neurons), two hidden layers (20 and 18 neurons) and one output layer (1 neuron). The results have shown that the proposed model can provide a high coefficient correlation (R = 0.878) and a low mean squared error (MSE = 0.00454 µm2). Furthermore, a sensitivity study has shown that the factors of sulfate ion (SO42−), humidity, and time were the most important variables which influenced COR values. The research work could contribute significantly to geotechnical engineering with an optimal ANN model to predict the COR values of reinforcement metal in MSE walls.},
  archive      = {J_NCA},
  author       = {Nguyen, Thu-Ha and Chau, Truong-Linh and Hoang, Tung and Nguyen, Teron},
  doi          = {10.1007/s00521-022-08043-1},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6787-6799},
  shortjournal = {Neural Comput. Appl.},
  title        = {Developing artificial neural network models to predict corrosion of reinforcement in mechanically stabilized earth walls},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSSIF-net: An efficient CNN automatic detection method for
freight train images. <em>NCA</em>, <em>35</em>(9), 6767–6785. (<a
href="https://doi.org/10.1007/s00521-022-08035-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freight trains are one of the most important modes of transportation. The fault detection of freight train parts is crucial to ensure the safety of train operation. Given the low detection efficiency and accuracy of traditional train fault detection methods, a novel one-stage object detection method called the multi-scale spatial information fusion CNN network (MSSIF-Net) based on YOLOv4 is proposed in this study. The adaptive spatial feature fusion method and multi-scale channel attention mechanism are used to construct the multi-scale feature sharing network and consequently realize feature information sharing at different levels and promote detection accuracy. The mean average precision values of MSSIF-Net on the train image test set, PASCAL VOC 2007 test set, and surface defect detection dataset are 94.73\%, 87.76\%, and 75.54\%, respectively, outperforming YOLOv4, Faster R-CNN, CenterNet, RetinaNet, and YOLOX-l. The detection speed of MSSIF-Net is 33.10 FPS, achieving a good balance between detection accuracy and speed. In addition, the MSSIF-Net performance is estimated after adding noise or rotating the train images at a slight angle to simulate a real scene. Experimental results indicate that MSSIF-Net has favorable anti-interference ability.},
  archive      = {J_NCA},
  author       = {Zhang, Longxin and Hu, Yang and Chen, Jingsheng and Li, Chuang and Li, Keqin},
  doi          = {10.1007/s00521-022-08035-1},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6767-6785},
  shortjournal = {Neural Comput. Appl.},
  title        = {MSSIF-net: An efficient CNN automatic detection method for freight train images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An approximate randomization-based neural network with
dedicated digital architecture for energy-constrained devices.
<em>NCA</em>, <em>35</em>(9), 6753–6766. (<a
href="https://doi.org/10.1007/s00521-022-08034-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable energy constraints affect the implementations of neural networks on battery-operated embedded systems. This paper describes a learning algorithm for randomization-based neural networks with hard-limit activation functions. The approach adopts a novel cost function that balances accuracy and network complexity during training. From an energy-specific perspective, the new learning strategy allows to adjust, dynamically and in real time, the number of operations during the network’s forward phase. The proposed learning scheme leads to efficient predictors supported by digital architectures. The resulting digital architecture can switch to approximate computing at run time, in compliance with the available energy budget. Experiments on 10 real-world prediction testbeds confirmed the effectiveness of the learning scheme. Additional tests on limited-resource devices supported the implementation efficiency of the overall design approach.},
  archive      = {J_NCA},
  author       = {Ragusa, Edoardo and Gianoglio, Christian and Zunino, Rodolfo and Gastaldo, Paolo},
  doi          = {10.1007/s00521-022-08034-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6753-6766},
  shortjournal = {Neural Comput. Appl.},
  title        = {An approximate randomization-based neural network with dedicated digital architecture for energy-constrained devices},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing self attention-based ResNet architecture for rice
leaf disease classification. <em>NCA</em>, <em>35</em>(9), 6737–6751.
(<a href="https://doi.org/10.1007/s00521-022-07793-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In India, rice crops are very significant. Rice cultivation comprises several phases, and it is crucial to keep an eye on the crop&#39;s development to avoid any leaf diseases and to provide a good yield. To avoid yield loss, crop diseases need to be determined at the initial stage. Deep learning-based pre-trained CNN architecture is used in this study to identify rice leaf diseases. This paper discusses four different CNN architectures to classify and identify healthy and diseased leaves such as Brown spot, Hispa, and Leaf Blast. Initially, to avoid vanishing gradient problems that degrade the performance of the Network, ResNet34 and ResNet50 are used. Even though the CNN model performs the feature extraction, Self-attention with ResNet18 and ResNet34 architecture is utilized to improve the feature selection process. As a result of enhanced feature extraction, the accuracy of rice leaf disease identification and classification has improved. Finally, high accuracy of 98.54\% is achieved with the proposed ResNet34 with self-attention architecture when compared to other CNN models used in this paper. In terms of multiclass classification, the proposed model offers improved outcomes when compared to state-of-the-art techniques.},
  archive      = {J_NCA},
  author       = {Stephen, Ancy and Punitha, A. and Chandrasekar, A.},
  doi          = {10.1007/s00521-022-07793-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6737-6751},
  shortjournal = {Neural Comput. Appl.},
  title        = {Designing self attention-based ResNet architecture for rice leaf disease classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting impact of land cover change on flood peak using
hybrid machine learning models. <em>NCA</em>, <em>35</em>(9), 6723–6736.
(<a href="https://doi.org/10.1007/s00521-022-08070-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study evaluates the performance of hybrid machine learning models to predict flood peak due to land cover changes. Performance of feed forward neural network (FNN) and adaptive neuro-fuzzy inference system (ANFIS) was compared and analyzed to select the best model in which different conventional training algorithms and evolutionary algorithms were applied in the training process. The inputs consist of stream flow in previous time step, rainfall and area of each land use class, and output of the model is stream flow in the current time step. The models were trained and tested based on the available data in a river basin located in the Australian tropical region. Based on the results in the case study, invasive weed optimization is the best method to train the machine learning system for simulating flood peak. In contrast, some optimization algorithms such as harmony search algorithm are very weak to train the machine learning model. Furthermore, results corroborated that the performance of FNN and NFIS is the same in terms of generality. The FNN model is more reliable to predict the flood peak in the case study. Moreover, ANFIS-based model is more complex than FNN. However, ANFIS is advantageous in terms of interpretability. The main weakness of ANFIS-based model is underestimation of flood peak in the major and minor floods. Two scenarios of changing land cover were tested which demonstrated reducing natural cover might increase the flood peak more than twice.},
  archive      = {J_NCA},
  author       = {Sedighkia, Mahdi and Datta, Bithin},
  doi          = {10.1007/s00521-022-08070-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6723-6736},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting impact of land cover change on flood peak using hybrid machine learning models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiclass skin lesion classification in dermoscopic images
using swin transformer model. <em>NCA</em>, <em>35</em>(9), 6713–6722.
(<a href="https://doi.org/10.1007/s00521-022-08053-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic skin lesion classification in dermoscopic images is a very challenging task due to the huge intraclass variation, the high degree of interclass visual similarity, low contrast between skin lesion and surrounding normal skin, and the existence of extraneous and intrinsic artifacts. However, existing algorithms for skin lesion classification are developed by leveraging convolutional neural networks (CNNs), and the effectiveness of these algorithms is mostly validated for binary classification of skin lesions. In addition, the relatively low diagnostic sensitivity achieved by these studies demonstrates the uncertainty involved in skin lesion classification. In order to overcome these difficulties, a swin transformer model for multiclass skin lesion classification is proposed by taking advantage of both transformer and CNNs that are based on end-to-end mapping and do not require prior knowledge. Furthermore, the problem of class imbalance is addressed through a weighted cross entropy loss. Moreover, key components of the proposed approach are explored in detail in order to ensure efficient and effective learning process with multiclass data in the skin lesion classification. The proposed method is extensively evaluated on International Skin Imaging Collaboration (ISIC) 2019 Skin Lesion Analysis Towards Melanoma Detection Challenge dataset and achieves a sensitivity, specificity, accuracy, and balanced accuracy value of $$82.3\%$$ , $$97.9\%$$ , $$97.2\%$$ , and $$82.3\%$$ , respectively. Experimental results demonstrate that the proposed method has the highest balanced accuracy value and outperforms most of the other state-of-the-art methods in multiclass skin lesion classification.},
  archive      = {J_NCA},
  author       = {Ayas, Selen},
  doi          = {10.1007/s00521-022-08053-z},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6713-6722},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multiclass skin lesion classification in dermoscopic images using swin transformer model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A novel original feature fusion network for joint diabetic
retinopathy and diabetic macular edema grading. <em>NCA</em>,
<em>35</em>(9), 6699–6712. (<a
href="https://doi.org/10.1007/s00521-022-08038-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) and its complication diabetic macular edema (DME) are the leading cause of permanent blindness in the working-age population worldwide. Automated grading of DR and DME enables ophthalmologists to carry out tailored treatments to patients in early stages of their diseases. However, most of the current works only focus on the grading of a single disease, ignoring the relationship between DR and DME, and the traditional convolutional architectures face the problem that they can not capture long-distance dependencies despite of the effectiveness of extracting image features. To this end, we propose an original feature fusion network (OFFNet) for joint DR and DME grading based on the idea of key-value query, which consists of a specific feature extraction module (SFEM) based on self-attention and an original feature fusion module (OFFM) based on cross-attention. The proposed OFFNet enjoys several merits. First, to the best of our knowledge, this is the first joint grading effort based on the idea of key-value query. Second, OFFNet only needs image-level supervision, which can facilitate the acquisition of training data, rather than patch-level or pixel-level supervision. Third, OFFNet has obvious advantages in capturing long-distance dependencies. Extensive experiments on two public datasets Messidor and 2018 IDRiD challenge show that our method outperforms other joint grading methods on joint grading accuracy and the ability of capturing long-distance dependencies.},
  archive      = {J_NCA},
  author       = {Zhang, Jia and Guo, Xiaoxin and Lin, Qifeng and Wang, Haoren and Hu, Xiaoying and Che, Songtian},
  doi          = {10.1007/s00521-022-08038-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6699-6712},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel original feature fusion network for joint diabetic retinopathy and diabetic macular edema grading},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compressive strength prediction of SLWC using RBFNN and
LSSVM approaches. <em>NCA</em>, <em>35</em>(9), 6685–6697. (<a
href="https://doi.org/10.1007/s00521-022-08026-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the important types of lightweight concrete is expanded polystyrene (EPS) concrete which can be constructed by substituting part of coarse aggregates of the concrete with EPS beads. The characteristics of EPS concrete is greatly dependent on the material which is used in its manufacturing. Present study aims to develop two soft computing approaches according to radial basis function neural network (RBFNN) and coupled simulated annealing-least square support vector machine (CSA-LSSVM) models and a regression model for approximation the compressive strength of various types of concrete with main focus of EPS concrete. The regression model was considered as the benchmark model and the outcomes of RBFNN and CSA-LSSVM models were compared with it. The results revealed that the developed CSA-LSSVM and RBFNN approaches can be efficiently utilized to estimate the compressive strength of various kinds of concrete. The outcomes of the regression model were not as accurate as those of the machine learning approaches. In addition, the CSA-LSSVM model developed by the use of radial basis kernel function was decided as a better model. The R2, AARD\%, RMSE, and MAPE for the benchmark model were 0.7555, 8.87\%, 25.49, and 0.00887; however, these values for CSA-LSSVM were obtained as 0.9970, 3.01\%, 1.08, and 0.0301 and for the RBFNN model were obtained to be 0.9953, 4.84\%, 1.23, and 0.0484, respectively.},
  archive      = {J_NCA},
  author       = {Holakoei, Hamid Reza and Sajedi, Fathollah},
  doi          = {10.1007/s00521-022-08026-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6685-6697},
  shortjournal = {Neural Comput. Appl.},
  title        = {Compressive strength prediction of SLWC using RBFNN and LSSVM approaches},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust supervised matrix factorization hashing with
application to cross-modal retrieval. <em>NCA</em>, <em>35</em>(9),
6665–6684. (<a
href="https://doi.org/10.1007/s00521-022-08006-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, hashing methods have received extensive attention in multimedia search due to their high computational and storage efficiency. However, most of them explore the common representation of multi-modality data and then use it to generate the hash codes but ignore the specific properties of each modality. To mitigate this problem, we propose a novel hashing method, called Robust Supervised Matrix Factorization Hashing (RSMFH), which keeps both the shared and the specific properties of multimodality data by decomposing each modality into a common representation and an inconsistent representation. Moreover, we impose sparse constraints on the inconsistent part of each modality and minimize the production of the consistent parts, simultaneously. In addition, the supervised label information among the data is embedded into the learned hash codes enhancing the discriminative ability of RSMFH. We employ an efficient discrete optimization strategy to solve the proposed model. Massive experiments on four benchmark databases show that our approach achieves promising results in cross-modal retrieval tasks.},
  archive      = {J_NCA},
  author       = {Shu, Zhenqiu and Yong, Kailing and Zhang, Donglin and Yu, Jun and Yu, Zhengtao and Wu, Xiao-Jun},
  doi          = {10.1007/s00521-022-08006-6},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6665-6684},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust supervised matrix factorization hashing with application to cross-modal retrieval},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interior search algorithm based on chaotic and crossover
strategies for parameter extraction of polyphase induction machines.
<em>NCA</em>, <em>35</em>(9), 6647–6664. (<a
href="https://doi.org/10.1007/s00521-022-08055-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of the extracted parameters is important for studying the polyphase induction motor performance and/or the motor control schemes. An investigated and improved interior search algorithm (IISA) is presented in this study for extracting the optimal values of estimated parameters of six-phase and three-phase induction motors. This investigation was carried out on two polyphase induction motors as experimental research cases, utilizing features of manufacturer&#39;s operation. The estimated parameters show the high capability regarding the performance of the desired IISA optimizer. The performance of the proposed IISA is compared with different modern optimization algorithms including the basic ISA, and other state-of-the-art approaches. Experimental verifications are validated on two polyphase induction motors, called six-phase and three-phase induction motors. The obtained results show that the proposed method is very competitive in extracting the unknown parameters of different induction motor models with a high degree of closeness to the experimental records. Moreover, various statistical tests, such as the Wilcoxon rank test, stability analysis, and convergence analysis, have been conducted to justify the performance of the proposed IISA. From all the analyses, it has been revealed that the proposed IISA is a competitive method compared to other popular state-of-the-art competitors and ISA variant with accurately identified parameters.},
  archive      = {J_NCA},
  author       = {Rizk-Allah, Rizk M. and Abdelwanis, Mohamed I. and El-Sehiemy, Ragab A. and Abd-Elrazek, Ahmed S.},
  doi          = {10.1007/s00521-022-08055-x},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6647-6664},
  shortjournal = {Neural Comput. Appl.},
  title        = {An interior search algorithm based on chaotic and crossover strategies for parameter extraction of polyphase induction machines},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Observer-based finite-time adaptive neural network control
for PMSM with state constraints. <em>NCA</em>, <em>35</em>(9),
6635–6645. (<a
href="https://doi.org/10.1007/s00521-022-08050-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the observer-based finite-time adaptive neural network control for the permanent magnet synchronous motor (PMSM) system. The addressed PMSM system includes unknown nonlinear dynamics and constraint immeasurable states. The neural networks are utilized to approximate the unknown nonlinear dynamics and an equivalent control design model is established, by which a neural network state observer is given to estimate the immeasurable states. By constructing barrier Lyapunov functions and under the framework of adaptive backstepping control design technique and finite-time stability theory, a finite-time adaptive neural network control scheme is developed. It is proved that the proposed control scheme ensures the closed-loop system stable and the angular velocity, stator current and other state variables not to exceed their predefined bounds in a finite time. Finally, the computer simulation and a comparison with the existing controller are provided to confirm the effectiveness of the presented controller.},
  archive      = {J_NCA},
  author       = {Zhou, Sihui and Sui, Shuai and Li, Yongming and Tong, Shaocheng},
  doi          = {10.1007/s00521-022-08050-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6635-6645},
  shortjournal = {Neural Comput. Appl.},
  title        = {Observer-based finite-time adaptive neural network control for PMSM with state constraints},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimized artificial intelligence based technique for
identifying motor imagery from EEGs for advanced brain computer
interface technology. <em>NCA</em>, <em>35</em>(9), 6623–6634. (<a
href="https://doi.org/10.1007/s00521-022-08027-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor disability affects a person&#39;s ability to move and maintain balance. To remove this pain from the society, brain computer interface (BCI) system with the assistance of motor imagery (MI) tasks classification plays an important role. BCI translates human intension by brain activity into control signals to communicate with their external environment without direct physical movement. The current BCI system works with massive data through electroencephalogram (EEG) signals. Traditional methods in BCI are limited in efficiency, accuracy, and speed. To overcome these limitations, this study aims to develop an optimized artificial Intelligence-based technique for identifying human intentions of physical movement through EEG data for an advanced BCI system. The proposed technique is designed involving Common Spatial Pattern (CSP) and Medium K Nearest Neighbour (MKNN) technique to achieve higher classifier accuracy, which was tested on a publicly available EEG dataset (IVa) of BCI Competition III. This study produces the highest accuracy score in the case of all subjects above 90\%, and the average score is above 97\% for our proposed model, which outperforms the existing methods. This study&#39;s findings will assist technologists in creating frontier medical science technology and significantly improve BCI systems in Australia and worldwide. This proposed technique will help to identify the intensions of motor disabled people rapidly, assisting patients’ rehabilitation and daily living.},
  archive      = {J_NCA},
  author       = {Khanam, Taslima and Siuly, Siuly and Wang, Hua},
  doi          = {10.1007/s00521-022-08027-1},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6623-6634},
  shortjournal = {Neural Comput. Appl.},
  title        = {An optimized artificial intelligence based technique for identifying motor imagery from EEGs for advanced brain computer interface technology},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bernstein-levy differential evolution algorithm for
numerical function optimization. <em>NCA</em>, <em>35</em>(9),
6603–6621. (<a
href="https://doi.org/10.1007/s00521-022-08013-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolutionary (DE) algorithm is one of the most frequently used evolutionary computation method for the solution of non-differentiable, complex and discontinuous real value numerical problems. The analytical structure of the mutation and crossover operators used by DE and the initial values of the parameters of the relevant operators affect the problem-solving ability of DE. Unfortunately, there is no analytical method for selecting and initializing the best artificial genetic operators that DE can use to solve a problem. Therefore, there is a need to develop new evolutionary search methods that are parameter-free and insensitive to the artificial genetic operators they use. In this paper, the Bernstein–Levy differential evolution (BDE) algorithm, which has a unique elitist-mutation operator and a Bernstein polynomials-based stochastic parameter-free crossover operator, is introduced. The numerical problem-solving success of BDE is statistically evaluated by using 30 benchmark problems of CEC2014 in the numerical experiments presented. BDE&#39;s success in solving the related benchmark problems is statistically compared with six state-of-the-art comparison algorithms. In this paper, three real-world optimization problems are also solved by using the proposed algorithm, BDE. According to statistics generated from the experimental results, BDE is statistically better than comparison methods in solving the related real-world problems.},
  archive      = {J_NCA},
  author       = {Civicioglu, Pinar and Besdok, Erkan},
  doi          = {10.1007/s00521-022-08013-7},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6603-6621},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bernstein-levy differential evolution algorithm for numerical function optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent deep reinforcement learning algorithm with trend
consistency regularization for portfolio management. <em>NCA</em>,
<em>35</em>(9), 6589–6601. (<a
href="https://doi.org/10.1007/s00521-022-08011-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial portfolio management is reallocating the asset into financial products, whose goal is to maximize the profit under a certain risk. Since AlphaGo debated human professional players, deep reinforcement learning (DRL) algorithm has been widely used in various fields, including quantitative trading. The multi-agent system is a relatively new research branch in DRL, and its performance is better than that of a single agent in most cases. In this paper, we propose a novel multi-agent deep reinforcement learning algorithm with trend consistency regularization (TC-MARL) to find the optimal portfolio. Here, we divide the trend of stocks of one portfolio into two categories and train two different agents to learn the optimal trading strategy under these two stock trends. First, we build a trend consistency (TC) factor to recognize the consistency of several stocks from one portfolio. When the trend of these stocks is consistent, the factor is defined as 1; the trend is inconsistent, the factor is defined as $$-$$ 1. Based on it, a novel regularization related to the weights is proposed and added to the reward function, named TC regularization. And the TC factor value is used as the sign of the regularization term. In this way, two agents with different reward functions are constructed, which have the same policy model and value model. Afterward, the proposed TC-MARL algorithm will dynamically switch between the two trained agents to find the optimal portfolio strategy according to the market status. Extensive experimental results on the Chinese Stock Market show the effectiveness of the proposed algorithm.},
  archive      = {J_NCA},
  author       = {Ma, Cong and Zhang, Jiangshe and Li, Zongxin and Xu, Shuang},
  doi          = {10.1007/s00521-022-08011-9},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6589-6601},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-agent deep reinforcement learning algorithm with trend consistency regularization for portfolio management},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comparative assessment of tree-based predictive models to
estimate geopolymer concrete compressive strength. <em>NCA</em>,
<em>35</em>(9), 6569–6588. (<a
href="https://doi.org/10.1007/s00521-022-08042-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fly ash-based geopolymer concrete (FA-GPC) is a material that might be utilized to build a more sustainable construction industry; therefore, this paper aims to develop a novel approach for its compressive strength (CS) prediction. To achieve this goal, three tree-based machine learning methods, namely, Radom Forest (RF), Decision Tree (DT), and Extreme Gradient Boosting (XGBoost), were developed based on experimental databases considering fourteen key factors of FA-GPC. The results indicated that XGBoost outperformed other methods, as proved by excellent prediction metrics. The sensitivity analysis of XGBoost models was then discussed utilizing feature importance, mean Shapley additive explanations (SHAP), and Beeswarm-SHAP values. The findings indicated that FA content had the most crucial impact on the CS, followed by SiO2 and NaOH contents, among the other variables examined. Finally, the SHAP dependence plots technique was utilized to quantitatively discuss feature interactions and contributions to the CS of FA-GPC.},
  archive      = {J_NCA},
  author       = {Nguyen, May Huu and Mai, Hai-Van Thi and Trinh, Son Hoang and Ly, Hai-Bang},
  doi          = {10.1007/s00521-022-08042-2},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6569-6588},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comparative assessment of tree-based predictive models to estimate geopolymer concrete compressive strength},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Multistate time series imputation using generative
adversarial network with applications to traffic data. <em>NCA</em>,
<em>35</em>(9), 6545–6567. (<a
href="https://doi.org/10.1007/s00521-022-07961-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series missing data is a pervasive problem in many fields, especially in intelligent transportation system, which hinders the application of timing analysis methods and the fine adjustment of control strategies. The prevalent imputation approaches reconstruct missing data with a high accuracy by exploiting a precise distribution model. But the multistate characteristic of time series data and the uncertainty of imputation process increase the difficulty of modeling temporal data distribution and reduce the imputation performance. In this paper, a novel time series generative adversarial imputation network (TGAIN) model is proposed to deal with time series data missing problem. The model combines the advantages of GAN&#39;s data distribution modeling and multiple imputation&#39;s uncertainty handling. Specifically, the TGAIN network is designed and adversarial trained to learn the multistate distribution of missing time series data. Through the conditional vector constraint and adversarial imputation process, the latent distribution for each missing position under different states can be effectively estimated based on implicit relationships with partial observation information. Then the corresponding multiple imputation strategy is proposed to deal with the uncertainty of imputation process and it can determine the best fill value from the learned distribution. Furthermore, sufficient experiments have been conducted in two real traffic flow datasets. The comparative results show the proposed TGAIN not only has better ability on time series data distribution modeling and imputation uncertainty handling, but also performs more robustly and stability even with the missing rate increases.},
  archive      = {J_NCA},
  author       = {Li, Haitao and Cao, Qian and Bai, Qiaowen and Li, Zhihui and Hu, Hongyu},
  doi          = {10.1007/s00521-022-07961-4},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6545-6567},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multistate time series imputation using generative adversarial network with applications to traffic data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MPCSAN: Multi-head parallel channel-spatial attention
network for facial expression recognition in the wild. <em>NCA</em>,
<em>35</em>(9), 6529–6543. (<a
href="https://doi.org/10.1007/s00521-022-08040-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) in the wild is an exceedingly challenging task in computer vision due to subtle differences, poses, occlusions, label bias, and other uncontrollable factors. CNN-based deep learning networks are susceptible to the above factors, resulting in the inability to obtain highly discriminative features on the key regions of expressions, and most methods of learning in a single feature space may not fully capture the core regions of interest. These will directly affect the solution to the problem of intra-class variability and inter-class similarity of expressions, which ultimately affects the recognition performance. Therefore, we propose an effective multi-head parallel channel-spatial attention network (MPCSAN) for FER in the wild, which consists of a feature aggregation network (FAN), a multi-head parallel attention network (MPAN), and an expression forecasting network (EFN). First, the lightweight FAN network extracts basic expression features while optimizing intra-class and inter-class distribution. Then, MPAN forms a multi-attention subspace by a multi-head parallel channel-space attention fusion design and focuses on more accurate and comprehensive expression regions of interest by minimizing duplicate attention during subspace fusion. Finally, EFN performs the final expression classification under the optimization of label softening, which further improves the robustness problem caused by label bias. Our proposed method is evaluated on the three most widely used wild expression datasets (RAF-DB, FERPlus, and AffectNet). The extensive experimental results demonstrate that our method outperforms several current state-of-the-art methods, achieving accuracies of 90.16\% on RAF-DB, 89.91\% on FERPlus, and 61.58\% on AffectNet, respectively. Occlusion and pose variation datasets evaluation and cross-dataset assessment further demonstrate the good comprehensive performance of our method.},
  archive      = {J_NCA},
  author       = {Gong, Weijun and Qian, Yurong and Fan, Yingying},
  doi          = {10.1007/s00521-022-08040-4},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6529-6543},
  shortjournal = {Neural Comput. Appl.},
  title        = {MPCSAN: Multi-head parallel channel-spatial attention network for facial expression recognition in the wild},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying human activities in megastores through postural
data to monitor shoplifting events. <em>NCA</em>, <em>35</em>(9),
6515–6528. (<a
href="https://doi.org/10.1007/s00521-022-08028-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, modeling activity patterns for understanding events and human behavior has drawn prominent attention in research. Multiple methods have been proposed for developing automated vision systems that are capable of inferring accurate semantics from the moving dynamics. The multi-disciplinary nature of Human Activity Recognition (HAR) methods and the expanding technologies in this field inspire continual updates in existing methods. However, a cost-effective solution is still needed to recognize human activities like shoplifting in an occluded environment. With this motivation, we present a novel approach to identify human stealing actions by analyzing the postural information of the human body. This approach involves extracting 2D postural body joints of a human being from the captured frame. Pose encoding and postural feature generation in parameter space are the foremost contributions of this work, which can handle the occluded actions too. The feature reduction is done to scale the features into a smaller dimension with an objective of the computationally efficient and real-time solution. Activity classification is done on the reduced feature sets to detect human shoplifting actions in real-time scenarios. Experiments are performed on the synthesized shoplifting dataset, where the results derived are found more promising compared to other state-of-the-art methods, with an accuracy of 96.87\%. Additionally, this method exhibits commendable real-time performance in processing actual store camera footage.},
  archive      = {J_NCA},
  author       = {Ansari, Mohd. Aquib and Singh, Dushyant Kumar},
  doi          = {10.1007/s00521-022-08028-0},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6515-6528},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identifying human activities in megastores through postural data to monitor shoplifting events},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep-learning-based facial expression recognition method
using textural features. <em>NCA</em>, <em>35</em>(9), 6499–6514. (<a
href="https://doi.org/10.1007/s00521-022-08005-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human facial expression and emotion play pivotal roles in our day-to-day communication, and detecting them are one of the formidable tasks in the field of human–computer interfaces (HCI). This paper presents a new facial expressions detection method by exploiting textural image features such as local binary patterns (LBP), local ternary patterns (LTP) and completed local binary pattern (CLBP). This paper utilizes the advantages of textural features which are highly correlated with the facial expression changes and thereby trains a convolution neural network (CNN) model to detect facial expressions. The CNN model is trained on the images from the extended Cohn-Kanade (CK +), JAFEE and FER2013 datasets that are converted into LBP, LTP and CLBP image features. The performance of our facial expression recognition system is validated on modified CK+, JAFEE and FER2013 dataset. The results reported here illustrates that the CNN model yields better efficiency when we train the model with textural images. Moreover, we have shown that the CNN model trained with CLBP outperforms than that of with LBP and LTP images. In case of CLBP images, accuracies are 91.0\%, 82.2\% and 64.5\% for CK+, JAFFE and FER2013 dataset, respectively. In case of LBP, accuracies are 79.5\%, 75\% and 58.45\% and in case of LTP images accuracies are 89.2\%, 77.3\% and 62.79\% for the datasets CK+, JAFFE and FER2013, respectively.},
  archive      = {J_NCA},
  author       = {Mukhopadhyay, Moutan and Dey, Aniruddha and Kahali, Sayan},
  doi          = {10.1007/s00521-022-08005-7},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6499-6514},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep-learning-based facial expression recognition method using textural features},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving automated latent fingerprint detection and
segmentation using deep convolutional neural network. <em>NCA</em>,
<em>35</em>(9), 6471–6497. (<a
href="https://doi.org/10.1007/s00521-022-07894-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent fingerprint segmentation is a complex process of separating relevant areas called fingerprints from an irrelevant background in the latent fingerprint image which is of poor quality. A breakthrough in the field can be used to segment fingerprints accurately from the background by using optimal resources. Processing of unwanted background of the entire image can lead to false and missed detection of fingerprints. An early fingerprint distinction technique based on colour and saliency masks is proposed to detect potentially relevant areas out of the entire image area for further processing, using a non-learning approach. Later, the patches of early detected fingermarks are fed to a stacked convolutional autoencoder for separating imposters of fingerprint(s) region from relevant fingerprint(s) regions, using a deep learning approach. The inspiration to use the convolutional neural network in this hybrid approach is to effectively capture feature distinction from potential features similar to that of object detection and classification. The inspiration to use autoencoder in a stack is to provide better feature engineering for CNN. The use of the pre-trained convolutional neural network with a stack of autoencoders for image classification and segmentation produces better results than a naive convolutional neural network. The experiments are conducted on the IIIT-D database. The efficiency and effectiveness of the model over good quality images is evaluated by experimenting over different patch sizes, with and without the use of dropout in CNN, with and without use of Autoencoder with CNN. The early detection of contours along with patch-based classification-cum-segmentation using SCAE on good quality images produces 98.45\% segmentation accuracy.},
  archive      = {J_NCA},
  author       = {Chhabra, Megha and Ravulakollu, Kiran Kumar and Kumar, Manoj and Sharma, Abhay and Nayyar, Anand},
  doi          = {10.1007/s00521-022-07894-y},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6471-6497},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving automated latent fingerprint detection and segmentation using deep convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human migration-based graph convolutional network for PM2.5
forecasting in post-COVID-19 pandemic age. <em>NCA</em>, <em>35</em>(9),
6457–6470. (<a
href="https://doi.org/10.1007/s00521-022-07876-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the coronavirus disease 2019 pandemic, local authorities always implanted non-pharmaceutical interventions, such as maintaining social distance to reduce human migration. Besides, previous studies have proved that human migration highly influenced air pollution concentration in an area. Therefore, this study aims to explore whether human migration can work as a significant factor in the post-pandemic age to help PM2.5 concentration forecasting. In this work, we first analyze the variations of PM2.5 in 11 cities of Hubei from 2015 to 2020 and further compare PM2.5 trends with the migration trends of Hubei province in 2020. Experimental results indicate that the human migration indirectly affected the urban PM2.5 concentration. Then, we established a graph data structure based on the migration network describing the migration flow size between any two areas in the Hubei province and proposed a migration attentive graph convolutional network (MAGCN) for forecasting PM2.5. Combined with the migration data. The proposed model can attentively aggregate the information of neighbor nodes through migration weights. Experimental results indicate that the proposed MAGCN can forecast PM2.5 concentration accurately.},
  archive      = {J_NCA},
  author       = {Zhan, Choujun and Jiang, Wei and Min, Hu and Gao, Ying and Tse, C. K.},
  doi          = {10.1007/s00521-022-07876-0},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6457-6470},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human migration-based graph convolutional network for PM2.5 forecasting in post-COVID-19 pandemic age},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An accurate flexible process planning using an adaptive
genetic algorithm. <em>NCA</em>, <em>35</em>(9), 6435–6456. (<a
href="https://doi.org/10.1007/s00521-022-07811-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for products and services due to globalization has quickly increased through the years. Under such circumstances, the improvement in manufacturing processes has taken the attention of several areas of engineering. Different schemas have been introduced in the context of distributed manufacturing, such as the flexible use of tools, machines, and tool access directions which become a complex task considering the difficult combinatory process and rigorous restrictions. To overcome such complications, flexible process planning (FPP) has been treated as an optimization problem. Moreover, the problem difficulty compromises the proper balance between performance and computational cost which generates the proposal of different optimization techniques, statistical criteria, and hybridizations. Despite the good results of different methods, there are still several possibilities for improvement. In this work, a genetic algorithm (GA) is employed for an accurate FPP process where the GA operators are adapted in order to join up the combinatory optimization process of FPP with the main structure of GA (aGA). To carry out the experimentation, different scenarios of FPP problems using AND/OR networks, production time, and production cost are considered. The adapted genetic algorithm for flexible process planning (aGA-FPP) problems has shown competitive results regarding similar approaches and hybridizations reported in the literature.},
  archive      = {J_NCA},
  author       = {Haro, Eduardo H. and Avalos, Omar and Camarena, Octavio and Cuevas, Erik},
  doi          = {10.1007/s00521-022-07811-3},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6435-6456},
  shortjournal = {Neural Comput. Appl.},
  title        = {An accurate flexible process planning using an adaptive genetic algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized complex kernel least-mean-square algorithm with
adaptive kernel widths. <em>NCA</em>, <em>35</em>(9), 6423–6434. (<a
href="https://doi.org/10.1007/s00521-022-08022-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel variable kernel width generalized complex-valued least mean-square (VKW-GCKLMS) algorithm aims to optimize kernel width in online way to tackle with the problem that the performance of nonlinear kernel algorithms with fixed values of kernel widths is degraded by inappropriate choice of kernel widths. The proposed VKW-GCKLMS algorithm is able to continuously optimize values of kernel widths by using stochastic gradient algorithm in the task of complex-valued nonlinear filtering. Numerical simulations illustrate that the VKW-GCKLMS algorithm is capable of guiding values of kernel widths of different kernels toward those that can achieve the optimal filtering performances. In addition, it is also shown that initial values of kernel widths do not have evident effect on the filtering performance of the VKW-GCKLMS algorithm, which demonstrates the high effectiveness of the VKW-GCKLMS algorithm.},
  archive      = {J_NCA},
  author       = {Huang, Wei and Huang, Zezhen and Gao, Hua},
  doi          = {10.1007/s00521-022-08022-6},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6423-6434},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generalized complex kernel least-mean-square algorithm with adaptive kernel widths},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A z-number based multi-attribute decision-making algorithm
for hydro-environmental system management. <em>NCA</em>, <em>35</em>(9),
6405–6421. (<a
href="https://doi.org/10.1007/s00521-022-08025-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Attribute Decision-Making (MADM) is still an open issue under uncertain circumstances. This research aimed to introduce a new MADM method for dealing with highly uncertain circumstances. Lake Urmia in Iran suffers from natural and human stimuli. For rapid and sustainable lake rehabilitation, a multidisciplinary and flexible approach is needed to address the divergent benefits and multiple goals. MADM can be accomplished using various techniques such as the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS), the Analytic Hierarchy Process (AHP), and others. According to the uncertainty, in recent years the hybrid of fuzzy logic with well-known MADM methods such as fuzzy AHP (FAHP) has been used frequently. The main problem of the traditional MADM methods (and fuzzy-based MADM methods) is their weakness in dealing with the ambiguous situations common in real-life scenarios, especially in water crisis problems. For example, the decision, which was accepted based on low-reliability data, tends to be useless or harmful. In contrast to the traditional MADM methods, which ignore the reliability of the information, Z-numbers, as a new generation of the fuzzy logic method, include both constraint and reliability of information and have great potential to explain human knowledge uncertainty. This study developed a new MADM approach based on the Z-numbers concept. In this regard, seven alternatives were proposed and evaluated using the economic, social, environmental, and technical criteria of sustainable development. The obtained results were then compared with the results of the AHP, FAHP, and TOPSIS methods. Improving irrigation efficiency was chosen as the best alternative based on the final ranking of the alternatives.},
  archive      = {J_NCA},
  author       = {Nourani, Vahid and Najafi, Hessam},
  doi          = {10.1007/s00521-022-08025-3},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6405-6421},
  shortjournal = {Neural Comput. Appl.},
  title        = {A Z-number based multi-attribute decision-making algorithm for hydro-environmental system management},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time guidance for powered landing of reusable rockets
via deep learning. <em>NCA</em>, <em>35</em>(9), 6383–6404. (<a
href="https://doi.org/10.1007/s00521-022-08024-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on improving the autonomy and efficiency of fuel-optimal powered landing guidance for reusable rockets considering aerodynamic forces. Deep-learning-based methods are developed to enable online and autonomous operation ability and to avoid the convergence problem encountered by classic indirect and direct optimal control methods. Considering the complex uncertainties of the preceding entry flight and potential unsettling hand-over conditions, a classification network is designed to classify the initial states of landing flights into different categories that correspond to bang–bang or non-bang–bang/singular thrust profiles. Thus, the subsequent online regression network can perform well for a large initial state distribution, and the algorithm adjusts to extensive landing situations. The combined application of classification and regression networks is one of the main contributions of the paper. The offline trained state-action regression networks generate guidance commands according to the real-time rocket state, obtaining a near-optimal landing trajectory. In addition, an online parallel trajectory simulation strategy is proposed to verify the trajectory quality, and an alternative trajectory optimization procedure is embedded into the proposed network-based framework to enhance the safety and accuracy of the guidance algorithm, representing another major contribution. Numerical experiments are presented to evaluate the effectiveness and accuracy of the proposed algorithm.},
  archive      = {J_NCA},
  author       = {Wang, Jinbo and Ma, Hongjun and Li, Huixu and Chen, Hongbo},
  doi          = {10.1007/s00521-022-08024-4},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6383-6404},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time guidance for powered landing of reusable rockets via deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Energy-efficient distributed heterogeneous blocking
flowshop scheduling problem using a knowledge-based iterated pareto
greedy algorithm. <em>NCA</em>, <em>35</em>(9), 6361–6381. (<a
href="https://doi.org/10.1007/s00521-022-08012-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, both distributed scheduling and energy-efficient scheduling have attracted great attention in production systems. This paper studies an energy-efficient distributed blocking flowshop scheduling problem where several heterogeneous factories cooperate to process jobs. A knowledge-based iterated Pareto greedy algorithm (KBIPG) is proposed to minimize simultaneously the makespan and total energy consumption. Based on a speed scaling framework that allows machines to process different jobs at different speed levels or remain in the standby mode, the KBIPG has two stages, where the difference lies in whether to adjust the processing speed. First, two multi-objective insertion procedures are proposed to form construction procedures. Second, we presented an efficient destruction procedure for each stage separately. Third, two local intensification methods are designed based on adjusting machine speeds, including the energy-saving procedure that optimizes the total energy consumption and the speedup-based local search procedure that optimizes the makespan. The KBIPG algorithm starts with generating solutions under various initial machine speed matrixes with different levels and then goes through a two-stage loop based on the proposed procedures. Computational experiments and comparisons with five algorithms demonstrate the effectiveness of the proposed KBIPG algorithm.},
  archive      = {J_NCA},
  author       = {Chen, Shuai and Pan, Quan-Ke and Gao, Liang and Miao, Zhong-Hua and Peng, Chen},
  doi          = {10.1007/s00521-022-08012-8},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6361-6381},
  shortjournal = {Neural Comput. Appl.},
  title        = {Energy-efficient distributed heterogeneous blocking flowshop scheduling problem using a knowledge-based iterated pareto greedy algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantitative extensions of reaction systems based on SOS
semantics. <em>NCA</em>, <em>35</em>(9), 6335–6359. (<a
href="https://doi.org/10.1007/s00521-022-07935-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reaction systems (RSs) are a successful natural computing framework inspired by chemical reaction networks. A RS consists of a set of entities and a set of reactions. Entities can enable or inhibit each reaction and are produced by reactions or provided by the environment. In this paper, we define two quantitative variants of RSs: the first one is along the time dimension, to specify delays for making available reactions products and durations to protract their permanency, while the second deals with the possibility to specify different concentration levels of a substance in order to enable or inhibit a reaction. Technically, both extensions are obtained by modifying in a modular way the Structural Operational Semantics (SOS) for RSs that was already defined in the literature. Our approach maintains several advantages of the original semantics definition that were: (1) providing a formal specification of the RS dynamics that enables the reuse of many formal analysis techniques and favours the implementation of tools, and (2) making the RS framework extensible, by adding or changing some of the SOS rules in a compositional way. We provide a prototype logic programming implementation and apply our tool to three different case studies: the tumour growth, the Th cell differentiation in the immune system and neural communication.},
  archive      = {J_NCA},
  author       = {Brodo, Linda and Bruni, Roberto and Falaschi, Moreno and Gori, Roberta and Levi, Francesca and Milazzo, Paolo},
  doi          = {10.1007/s00521-022-07935-6},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6335-6359},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quantitative extensions of reaction systems based on SOS semantics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Theory and practice of natural computing: Tenth edition.
<em>NCA</em>, <em>35</em>(9), 6333. (<a
href="https://doi.org/10.1007/s00521-022-07956-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Martín-Vide, Carlos and Vega-Rodríguez, Miguel A.},
  doi          = {10.1007/s00521-022-07956-1},
  journal      = {Neural Computing and Applications},
  number       = {9},
  pages        = {6333},
  shortjournal = {Neural Comput. Appl.},
  title        = {Theory and practice of natural computing: Tenth edition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Letter to the editor in reference to the article entitled
“4D-GWR: Geographically, altitudinal, and temporally weighted
regression.” <em>NCA</em>, <em>35</em>(8), 6331. (<a
href="https://doi.org/10.1007/s00521-022-08041-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Helbich, Marco and Hagenauer, Julian},
  doi          = {10.1007/s00521-022-08041-3},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6331},
  shortjournal = {Neural Comput. Appl.},
  title        = {Letter to the editor in reference to the article entitled ‘4D-GWR: Geographically, altitudinal, and temporally weighted regression’},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A genetic algorithm integrated with the initial solution
procedure and parameter tuning for capacitated p-median problem.
<em>NCA</em>, <em>35</em>(8), 6313–6330. (<a
href="https://doi.org/10.1007/s00521-022-08010-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacitated p-median problem is a well-known location-allocation problem that is NP-hard. We proposed an advanced Genetic Algorithm (GA) integrated with an Initial Solution Procedure for this problem to solve the medium and large-size instances. A 33 Full Factorial Design was performed where three levels were selected for the probability of mutation, population size, and the number of iterations. Parameter tuning was performed to reach better performance at each instance. MANOVA and Post-Hoc tests were performed to identify significant parameter levels, considering both computational time and optimality gap percentage. Real data of Lorena and Senne (2003) and the data set presented by Stefanello et al. (2015) were used to test the proposed algorithm, and the results were compared with those of the other heuristics existing in the literature. The proposed GA was able to reach the optimal solution for some of the instances in contrast to other metaheuristics and the Mat-heuristic, and it reached a solution better than the best known for the largest instance and found near-optimal solutions for the other cases. The results show that the proposed GA has the potential to enhance the solutions for large-scale instances. Besides, it was also shown that the parameter tuning process might improve the solution quality in terms of the objective function and the CPU time of the proposed GA, but the magnitude of improvement may vary among different instances.},
  archive      = {J_NCA},
  author       = {Oksuz, Mehmet Kursat and Buyukozkan, Kadir and Bal, Alperen and Satoglu, Sule Itir},
  doi          = {10.1007/s00521-022-08010-w},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6313-6330},
  shortjournal = {Neural Comput. Appl.},
  title        = {A genetic algorithm integrated with the initial solution procedure and parameter tuning for capacitated P-median problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On a dual proximity measure based on intuitionistic fuzzy
sets. <em>NCA</em>, <em>35</em>(8), 6293–6311. (<a
href="https://doi.org/10.1007/s00521-022-07946-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new approach for defining a dual proximity measure for intuitionistic fuzzy sets. The new approach utilizes an extended form of the restricted equivalence functions and receives their values as a two tuple. The two values in the two tuple are due to the dual character of the proximity measure under consideration. In fact, the computation of proximity between two intuitionistic fuzzy sets simultaneously provides the value of similarity as well as non-similarity between the intuitionistic fuzzy sets. So, the novel approach proposed in this paper provides a comprehensive information theoretic evaluation of intuitionistic fuzzy sets. Further, we investigate the application of the novel measure in pattern recognition and clustering analysis. We also contrast the performance of the proposed measure with the state-of-art in view of the structured linguistic variables, pattern classification and clustering analysis. The comparative analysis shows that the newly introduced two-valued proximity measure performs better in certain circumstances and encompasses the dualism of the human cognition.},
  archive      = {J_NCA},
  author       = {Singh, Koushal and Singh, Surender},
  doi          = {10.1007/s00521-022-07946-3},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6293-6311},
  shortjournal = {Neural Comput. Appl.},
  title        = {On a dual proximity measure based on intuitionistic fuzzy sets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of temperature separation of a nitrogen-driven
vortex tube with linear, kNN, SVM, and RF regression models.
<em>NCA</em>, <em>35</em>(8), 6281–6291. (<a
href="https://doi.org/10.1007/s00521-022-08030-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the performance of a counter-flow Ranque–Hilsch vortex tube (RHVT) was investigated experimentally using working fluid nitrogen, and the thermal performance was modeled using different modeling methods with these experimental results. Each method was compared with the others. The variation of ΔT, which is the measure of temperature separation in RHVT, was investigated by using nozzle number, the thermal conductivity of nozzle material, inlet pressure, specific heat, and density of working fluid. In the study, the prediction models of linear, k-nearest neighbor (kNN), random forest (RF), and support vector machine (SVM) regression were trained with measured thermal performance using a specific portion of the experimental data and tested with the remaining data. Two different train and test datasets were used with the ratio of experimental data as 90–10\% and 80–20\%, respectively. The highest accuracy ratio was determined at the end of the four methods with SVM regression as 96.01\% when using the train and test datasets as 90–10\%, respectively. The percent accuracy of the other models under the same conditions was calculated as 95.7, 90.87, and 78.36\% for RF, kNN, and linear, respectively.},
  archive      = {J_NCA},
  author       = {Kaya, Hüseyin and Guler, Evrim and Kırmacı, Volkan},
  doi          = {10.1007/s00521-022-08030-6},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6281-6291},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of temperature separation of a nitrogen-driven vortex tube with linear, kNN, SVM, and RF regression models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SimpLex: A lexical text simplification architecture.
<em>NCA</em>, <em>35</em>(8), 6265–6280. (<a
href="https://doi.org/10.1007/s00521-022-07905-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text simplification (TS) is the process of generating easy-to-understand sentences from a given sentence or piece of text. The aim of TS is to reduce both the lexical (which refers to vocabulary complexity and meaning) and syntactic (which refers to the sentence structure) complexity of a given text or sentence without the loss of meaning or nuance. In this paper, we present SimpLex, a novel simplification architecture for generating simplified English sentences. To generate a simplified sentence, the proposed architecture uses either word embeddings (i.e., Word2Vec) and perplexity, or sentence transformers (i.e., BERT, RoBERTa, and GPT2) and cosine similarity. The solution is incorporated into a user-friendly and simple-to-use software. We evaluate our system using two metrics, i.e., SARI and Perplexity Decrease. Experimentally, we observe that the transformer models outperform the other models in terms of the SARI score. However, in terms of perplexity, the word embedding-based models achieve the biggest decrease. Thus, the main contributions of this paper are: (1) We propose a new word embedding and transformer-based algorithm for text simplification; (2) we design SimpLex—a modular novel text simplification system—that can provide a baseline for further research; and (3) we perform an in-depth analysis of our solution and compare our results with two state-of-the-art models, i.e., LightLS as reported by Glavaš and Štajner (in: Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing, 2015) and NTS-w2v as reported by Nisioi et al. (in: Proceedings of the 55th annual meeting of the association for computational linguistics, 2017). We also make the code publicly available online.},
  archive      = {J_NCA},
  author       = {Truică, Ciprian-Octavian and Stan, Andrei-Ionuţ and Apostol, Elena-Simona},
  doi          = {10.1007/s00521-022-07905-y},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6265-6280},
  shortjournal = {Neural Comput. Appl.},
  title        = {SimpLex: A lexical text simplification architecture},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating cross-selling opportunities with recurrent neural
networks on retail marketing. <em>NCA</em>, <em>35</em>(8), 6247–6263.
(<a href="https://doi.org/10.1007/s00521-022-08019-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are considered to be capable of predicting what the next product a customer should purchase is. It is crucial to identify which customers are more suitable than others to target a product for cross-selling in the retail industry. Using recurrent neural networks with self-attention mechanisms, this study proposes a hybrid model. Furthermore, the proposed design is capable of handling both sequential and non-sequential features, which correspond to purchase behavior and non-behavioral customer specific information, respectively. This study represents an alternative solution to a well-known business problem: improving cross-selling effectiveness by estimating customers’ likelihood for which products or services to buy next time. A recommender system which works on additional data configurations is the core concept of the framework. With an online shopping data set, this study shows that concatenation of relevant features adds additional information to the model, and it is found that evaluation metrics are improved by approximately 12\%.},
  archive      = {J_NCA},
  author       = {Kalkan, İbrahim Erdem and Şahin, Cenk},
  doi          = {10.1007/s00521-022-08019-1},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6247-6263},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluating cross-selling opportunities with recurrent neural networks on retail marketing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Surface path tracking method of autonomous surface
underwater vehicle based on deep reinforcement learning. <em>NCA</em>,
<em>35</em>(8), 6225–6245. (<a
href="https://doi.org/10.1007/s00521-022-08009-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability of path tracking and obstacle avoidance in a complex ocean environment is the basis of the autonomous ocean vehicle voyage. In this paper, a hybrid sea surface path tracking guidance and controller for the autonomous surface underwater vehicle based on the carrot-chasing (CC) and deep reinforcement learning (DRL) is proposed. Firstly, the reference heading angle is provided by the CC algorithm, and then the DRL algorithm is used to combine it with the vehicle-borne sensor information for decision and control. The vehicle’s tracking capability is self-developed through a Markov decision process model that includes states, actions, and reward functions, so as to interact and train with the surrounding environment without prior knowledge. The simulation experiments are carried out in high-fidelity sea surface environments with wind, wave and current disturbances, and the experimental results show that the proposed method can converge effectively, has high tracking accuracy and flexible obstacle avoidance ability while avoiding the calculation of complex parameters.},
  archive      = {J_NCA},
  author       = {Song, Dalei and Gan, Wenhao and Yao, Peng and Zang, Wenchuan and Qu, Xiuqing},
  doi          = {10.1007/s00521-022-08009-3},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6225-6245},
  shortjournal = {Neural Comput. Appl.},
  title        = {Surface path tracking method of autonomous surface underwater vehicle based on deep reinforcement learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast unsupervised consistent and modality-specific hashing
for multimedia retrieval. <em>NCA</em>, <em>35</em>(8), 6207–6223. (<a
href="https://doi.org/10.1007/s00521-022-08008-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hashing is an effective technique to solve large-scale data storage problem and achieve efficient retrieval, and it is also a core technology to promote the intelligent development of the new infrastructure construction. In most practical situations, label information is unavailable, and creating manual annotations is a time-consuming and laborious process. Therefore, unsupervised cross-modal hashing technique has received extensive attention from the information retrieval community due to its fast retrieval speed and feasibility. However, the capabilities of existing unsupervised cross-modal hashing methods are not sufficient to comprehensively describe the complex relations among different modalities, such as the balance of complementary and consistency between different modalities. In this article, we propose a new-type of unsupervised cross-modal hashing method called Fast Unsupervised Consistent and Modality-Specific Hashing (FUCMSH). Specifically, FUCMSH consists of two main modules, i.e., shared matrix factorization module (SMFM) and individual auto-encoding module (IAEM). In the SMFM, FUCMSH dynamically assigns weights to different modalities to adaptively balance the contribution of different modalities. By doing so, the information completeness of the shared consistent representation can be guaranteed. In the IAEM, FUCMSH learns individual modality-specific latent representations of different modalities through modality-specific linear autoencoders. Moreover, FUCMSH makes use of the transfer learning to link the relationships between different individual modality-specific latent representations. Combined with the SMFM and the IAEM, the discriminative capability of the generated binary codes can be significantly improved. The relatively extensive experimental results manifest the superiority of the proposed FUCMSH.},
  archive      = {J_NCA},
  author       = {Yang, Zhan and Deng, Xiyin and Long, Jun},
  doi          = {10.1007/s00521-022-08008-4},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6207-6223},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fast unsupervised consistent and modality-specific hashing for multimedia retrieval},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative adversarial networks with adaptive learning
strategy for noise-to-image synthesis. <em>NCA</em>, <em>35</em>(8),
6197–6206. (<a
href="https://doi.org/10.1007/s00521-022-08002-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) directly learn from an unknown real distribution through adversarial training. However, training the generator only by the feedback of the discriminator cannot make GANs learn adaptively from the unknown complex real distribution, and for this reason the quality of generated images is unsatisfactory sometimes. To address this problem, we propose a framework for training GANs with an adaptive learning strategy from simpleness to complexity. First, we employ a pre-trained encoder and a generator to construct a simple task that looks like a real image. Second, an adaptive learning strategy is designed based on the mathematical expectation of the discriminating results of the real image and the simple task. The designed adaptive learning strategy is well compatible with various GANs architectures. Experimental results demonstrate the proposed method can improve the performance of existing GANs.},
  archive      = {J_NCA},
  author       = {Gan, Yan and Xiang, Tao and Liu, Hangcheng and Ye, Mao and Zhou, Mingliang},
  doi          = {10.1007/s00521-022-08002-w},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6197-6206},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generative adversarial networks with adaptive learning strategy for noise-to-image synthesis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hospital selection framework for remote MCD patients based
on fuzzy q-rung orthopair environment. <em>NCA</em>, <em>35</em>(8),
6185–6196. (<a
href="https://doi.org/10.1007/s00521-022-07998-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a novel mobile health-based hospital selection framework for remote patients with multi-chronic diseases based on wearable body medical sensors that use the Internet of Things. The proposed framework uses two powerful multi-criteria decision-making (MCDM) methods, namely fuzzy-weighted zero-inconsistency and fuzzy decision by opinion score method for criteria weighting and hospital ranking. The development of both methods is based on a Q-rung orthopair fuzzy environment to address the uncertainty issues associated with the case study in this research. The other MCDM issues of multiple criteria, various levels of significance and data variation are also addressed. The proposed framework comprises two main phases, namely identification and development. The first phase discusses the telemedicine architecture selected, patient dataset used and decision matrix integrated. The development phase discusses criteria weighting by q-ROFWZIC and hospital ranking by q-ROFDOSM and their sub-associated processes. Weighting results by q-ROFWZIC indicate that the time of arrival criterion is the most significant across all experimental scenarios with (0.1837, 0.183, 0.230, 0.276, 0.335) for (q = 1, 3, 5, 7, 10), respectively. Ranking results indicate that Hospital (H-4) is the best-ranked hospital in all experimental scenarios. Both methods were evaluated based on systematic ranking and sensitivity analysis, thereby confirming the validity of the proposed framework.},
  archive      = {J_NCA},
  author       = {Alamoodi, A.H. and Albahri, O.S. and Zaidan, A.A. and Alsattar, H.A. and Zaidan, B.B. and Albahri, A.S.},
  doi          = {10.1007/s00521-022-07998-5},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6185-6196},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hospital selection framework for remote MCD patients based on fuzzy q-rung orthopair environment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced ali baba and the forty thieves algorithm for
feature selection. <em>NCA</em>, <em>35</em>(8), 6153–6184. (<a
href="https://doi.org/10.1007/s00521-022-08015-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature Selection (FS) aims to ameliorate the classification rate of dataset models by selecting only a small set of appropriate features from the initial range of features. In consequence, a reliable optimization method is needed to deal with the matters involved in this problem. Often, traditional methods fail to optimally reduce the high dimensionality of the feature space of complex datasets, which lead to the elicitation of weak classification models. Meta-heuristics can offer a favorable classification rate for high-dimensional datasets. Here, a binary version of a new human-based algorithm named Ali Baba and the Forty Thieves (AFT) was applied to tackle a pool of FS problems. Although AFT is an efficient meta-heuristic for optimizing many problems, it sometimes exhibits premature convergence and low search performance. These issues were mitigated by proposing three enhanced versions of AFT, namely: (1) A Binary Multi-layered AFT called BMAFT which uses hierarchical and distributed frameworks, (2) Binary Elitist AFT (BEAFT) which uses an elitist learning strategy, and, (3) Binary Self-adaptive AFT (BSAFT) which uses an adapted tracking distance parameter. These versions along with the basic Binary AFT (BAFT) were expansively assessed on twenty-four problems gathered from different repositories. The results showed that the proposed algorithms substantially enhance the performance of BAFT in terms of convergence speed and solution accuracy. On top of that, the overall results showed that BMAFT is the most competitive, which provided the best results with excellent performance scores compared to other competing algorithms.},
  archive      = {J_NCA},
  author       = {Braik, Malik},
  doi          = {10.1007/s00521-022-08015-5},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6153-6184},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced ali baba and the forty thieves algorithm for feature selection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A modified multi-objective slime mould algorithm with
orthogonal learning for numerical association rules mining.
<em>NCA</em>, <em>35</em>(8), 6125–6151. (<a
href="https://doi.org/10.1007/s00521-022-07985-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Association rule mining (ARM) is defined by its crucial role in finding common pattern in data mining. It has different types such as fuzzy, binary, numerical. In this paper, we introduce a multi-objective orthogonal mould algorithm (MOOSMA) with numerical association rule mining (NARM) which is a different type of ARM. Existing algorithms that deal with the NARM problem can be classified into three categories: distribution, discretization and optimization. The proposed approach belongs to the optimization category which is considered as a better way to deal with the problem. Our main objective is based on four efficiency measures related to each association: Support, Confidence, Comprehensibility, Interestingness. To test the performance of our approach, we started by testing our method on widely known generalized dynamic benchmark tests called CEC’09. This benchmark is composed of 20 test functions: 10 functions without constraints and 10 functions with constraints. Secondly, we applied our algorithm to solve NARM problem using 10 frequently used real-world datasets. Experimental analysis shows that our algorithm MOOSMA has better results in terms of Average Support, Average Confidence, Average Lift, Average Certain factor and Average Netconf. Note that source code of the MOOSMA algorithm is publicly available at https://github.com/gaithmanita/MOOSMA .},
  archive      = {J_NCA},
  author       = {Yacoubi, Salma and Manita, Ghaith and Amdouni, Hamida and Mirjalili, Seyedali and Korbaa, Ouajdi},
  doi          = {10.1007/s00521-022-07985-w},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6125-6151},
  shortjournal = {Neural Comput. Appl.},
  title        = {A modified multi-objective slime mould algorithm with orthogonal learning for numerical association rules mining},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A transformer fine-tuning strategy for text dialect
identification. <em>NCA</em>, <em>35</em>(8), 6115–6124. (<a
href="https://doi.org/10.1007/s00521-022-07944-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online medical consultation can significantly improve the efficiency of primary health care. Recently, many online medical question–answer services have been developed that connect the patients with relevant medical consultants based on their questions. Considering the linguistic variety in their question, social background identification of patients can improve the referral system by selecting a medical consultant with a similar social origin for efficient communication. This paper has proposed a novel fine-tuning strategy for the pre-trained transformers to identify the social origin of text authors. When fused with the existing adapter model, the proposed methods achieve an overall accuracy of 53.96\% for the Arabic dialect identification task on the Nuanced Arabic Dialect Identification (NADI) dataset. The overall accuracy is 0.54\% higher than the previous best for the same dataset, which establishes the utility of custom fine-tuning strategies for pre-trained transformer models.},
  archive      = {J_NCA},
  author       = {Humayun, Mohammad Ali and Yassin, Hayati and Shuja, Junaid and Alourani, Abdullah and Abas, Pg Emeroylariffion},
  doi          = {10.1007/s00521-022-07944-5},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6115-6124},
  shortjournal = {Neural Comput. Appl.},
  title        = {A transformer fine-tuning strategy for text dialect identification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast conjugate functional gain sequential minimal
optimization training algorithm for LS-SVM model. <em>NCA</em>,
<em>35</em>(8), 6095–6113. (<a
href="https://doi.org/10.1007/s00521-022-07875-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The least squares support vector machine (LS-SVM) is an effective method to deal with classification and regression problems and has been widely studied and applied in the fields of machine learning and pattern recognition. The learning algorithms of the LS-SVM are usually conjugate gradient (CG) and sequential minimal optimization (SMO) algorithms. Based on this, we propose a conjugate functional gain SMO algorithm and theoretically prove its asymptotic convergence. This algorithm combines the conjugate direction method and the functional gain SMO algorithm with second-order information, which increases the functional gain of the plain SMO algorithm. In addition, we also provide a generalized SMO-type algorithm framework with a simple iterative format and easy implementation for other LS-SVM training algorithms. The numerical results show that the execution time of this algorithm is significantly shorter than that of the other plain SMO-type algorithms and CG-type algorithms.},
  archive      = {J_NCA},
  author       = {Yu, Lang and Ma, Xin and Li, Shengjie},
  doi          = {10.1007/s00521-022-07875-1},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6095-6113},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fast conjugate functional gain sequential minimal optimization training algorithm for LS-SVM model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AREP: An adaptive, machine learning-based algorithm for
real-time anomaly detection on network telemetry data. <em>NCA</em>,
<em>35</em>(8), 6079–6094. (<a
href="https://doi.org/10.1007/s00521-022-08000-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal behaviour detection is an essential task of real-time monitoring to secure the reliable operation of ICT infrastructures. This paper presents AREP, an adaptive, long short-term memory-based machine learning algorithm for real-time anomaly detection on network telemetry data. AREP is an improved version of Alter-Re $$^2$$ , the direct predecessor algorithm developed by our research team. AREP introduces automatic tuning of its two key parameters and includes an offset compensation component to increase accuracy. Unfortunately, AREP and its predecessors perform well only on time series showing specific patterns. Thus, we propose also a data type classification method to identify patterns on which AREP performs best. Moreover, we use an extended range of metrics in our performance evaluations, including area under the curve (AUC). AUC computation is based on receiver operating characteristic (ROC) curves. However, generating ROC curves is not straightforward due to the inherent adaptive threshold technique used by AREP and its predecessors, so we had to develop a novel ROC curve generation approach for these algorithms. We show through rigorous experiments that on network time series following specific data patterns AREP overperforms its predecessors and produces similar or even better performance than other state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Farkas, Karoly},
  doi          = {10.1007/s00521-022-08000-y},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6079-6094},
  shortjournal = {Neural Comput. Appl.},
  title        = {AREP: An adaptive, machine learning-based algorithm for real-time anomaly detection on network telemetry data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel favipiravir pattern-based learning model for automated
detection of specific language impairment disorder using vowels.
<em>NCA</em>, <em>35</em>(8), 6065–6077. (<a
href="https://doi.org/10.1007/s00521-022-07999-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific language impairment (SLI) is one of the most common diseases in children, and early diagnosis can help to obtain better timely therapy economically. It is difficult and time-consuming for clinicians to accurately detect SLI through standard clinical assessments. Hence, machine learning algorithms have been developed to assist in the accurate diagnosis of SLI. This work aims to investigate the graph of the favipiravir molecule-based feature extraction function and propose an accurate SLI detection model using vowels. We proposed a novel handcrafted machine learning framework. This architecture comprises the favipiravir molecular structure pattern, statistical feature extractor, wavelet packet decomposition (WPD), iterative neighborhood component analysis (INCA), and support vector machine (SVM) classifier. Two feature extraction models, statistical and textural, are employed in the handcrafted feature generation methodology. A new nature-inspired graph-based feature extractor that uses the chemical depiction of the favipiravir (favipiravir became popular with the COVID-19 pandemic) is employed for feature extraction. Finally, the proposed favipiravir pattern, statistical feature extractor, and wavelet packet decomposition are used to create a feature vector. Moreover, a statistical feature extractor is used in this work. The WPD generates multilevel features, and the most meaningful features are selected using the NCA feature selector. Finally, these chosen features are fed to SVM classifier for automated classification. Two validation methods, (i) leave one subject out (LOSO) and (ii) tenfold cross-validations (CV), are used to obtain robust classification results. Our proposed favipiravir pattern-based model developed using a vowel dataset can detect SLI children with an accuracy of 99.87\% and 98.86\% using tenfold and LOSO CV strategies, respectively. These results demonstrated the high vowel classification ability of the proposed favipiravir pattern-based model.},
  archive      = {J_NCA},
  author       = {Barua, Prabal Datta and Aydemir, Emrah and Dogan, Sengul and Erten, Mehmet and Kaysi, Feyzi and Tuncer, Turker and Fujita, Hamido and Palmer, Elizabeth and Acharya, U. Rajendra},
  doi          = {10.1007/s00521-022-07999-4},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6065-6077},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel favipiravir pattern-based learning model for automated detection of specific language impairment disorder using vowels},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward a prediction approach based on deep learning in big
data analytics. <em>NCA</em>, <em>35</em>(8), 6043–6063. (<a
href="https://doi.org/10.1007/s00521-022-07986-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, cloud computing plays an important role in the process of storing both structured and unstructured data. This contributed to a very large data growth on web servers, which has come to be called Big Data. Cloud computing technology is adopted in many applications, perhaps the most important of which are social networking applications, e-mail messages, and others, which represent an important source of data through the process of communication between web users. Thus, these data represent views and opinions on various topics, which can help businesses and other decision makers in making decisions based on future predictions. To achieve this goal, several methods have been proposed. Recently, it relies on the use of deep learning as a tool for processing large volumes of data due to its high performance in extracting predictions from the opinions of web users. This paper presents a new prediction approach based on Big Data analysis and deep learning for large-scale data, called PABIDDL. The infrastructure of the proposed approach is focused on three important stages, starting with the reduction of Big Data based on MapReduce using the Hadoop framework. In the second stage, we performed the initialization of these data using the GloVe technique. Finally, the text data were classified into advantages and disadvantages poles depending on CNN deep learning approach. Also, we conducted an empirical study of our proposed approach PABIDDL and related works models on two standard datasets IMDB and MR datasets. The results obtained showed that the best performance is given by our approach. We recorded 0.93\%, 0.90\%, and 0.92\% as an accuracy, a recall, and an F1-score, respectively. Furthermore, our approach reached the fastest response time.},
  archive      = {J_NCA},
  author       = {Haddad, Omar and Fkih, Fethi and Omri, Mohamed Nazih},
  doi          = {10.1007/s00521-022-07986-9},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6043-6063},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward a prediction approach based on deep learning in big data analytics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New fixed-time stability criterion and fixed-time
synchronization of neural networks via non-chattering control.
<em>NCA</em>, <em>35</em>(8), 6029–6041. (<a
href="https://doi.org/10.1007/s00521-022-07975-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the framework of Filippov solution, a non-chattering controller is presented to realize the fixed-time (FXT) stability for a nonlinear system with the discontinuous activation function. First, a novel FXT stability criterion is established through the reduction to absurdity, and the settling time is estimated. Then, by building two controllers without chattering, sufficient conditions are obtained to ensure the FXT synchronization of the drive-response system. Moreover, compared with the existing results, the FXT obtained here is less conservative and more accurate. Finally, the validity of the proposed methods is provided by two numerical examples.},
  archive      = {J_NCA},
  author       = {Tang, Qian and Qu, Shaocheng and Zheng, Wei and Du, Xiaona and Tu, Zhengwen},
  doi          = {10.1007/s00521-022-07975-y},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6029-6041},
  shortjournal = {Neural Comput. Appl.},
  title        = {New fixed-time stability criterion and fixed-time synchronization of neural networks via non-chattering control},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FinGAN: Chaotic generative adversarial network for
analytical customer relationship management in banking and insurance.
<em>NCA</em>, <em>35</em>(8), 6015–6028. (<a
href="https://doi.org/10.1007/s00521-022-07968-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit card churn prediction, insurance fraud detection, and loan default prediction are all critical analytical customer relationship management (ACRM) problems. Since these events occur infrequently, datasets for these problems are highly unbalanced. Consequently, when trained on such unbalanced datasets, all machine learning classifiers tend to produce high false positive rates. We propose two methods for data balancing. To oversample the minority class, we proposed an innovative GAN called chaoticGAN, where we employed chaotic noise as input for the generator. We also employed the traditional GAN (Goodfellow et al. in Adv Neural Inf Process Syst, 2014. https://doi.org/10.1145/3422622 ), Wasserstein GAN (Arjovsky et al. in Wasserstein GAN, 2017. https://arxiv.org/abs/1701.07875 ), and CTGAN (Xu et al. in Modeling Tabular Data using Conditional GAN. https://arxiv.org/pdf/1907.00503 ) independently for baseline comparison. On the data balanced by GANs, we employed a host of machine learning classifiers, including Random Forest, Decision Tree, Support Vector Machine (SVM), Logistic Regression (LR), multi-layer perceptron (MLP) and Light gradient boosting machine (LGBM) to demonstrate the efficacy of our approaches. In the second approach, we augment the oversampled synthetic minority class data obtained by GAN and its variants with the undersampled majority class data obtained by one class support vector machine (OCSVM) (Tax et al. in Mach Learn 54:45–66, 2014). We passed the entire modified dataset to build the classifiers. Our proposed approaches outperform earlier studies on the same datasets in terms of the area under the ROC curve (AUC). Further, our proposed chaoticGAN and its hybrid turned out to be statistically similar to the state-of-the-art CTGAN on all datasets while being significant over other methods w.r.t AUC over tenfold cross-validation.},
  archive      = {J_NCA},
  author       = {Kate, Prateek and Ravi, Vadlamani and Gangwar, Akhilesh},
  doi          = {10.1007/s00521-022-07968-x},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {6015-6028},
  shortjournal = {Neural Comput. Appl.},
  title        = {FinGAN: Chaotic generative adversarial network for analytical customer relationship management in banking and insurance},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Framework for detection of probable clues to predict
misleading information proliferated during COVID-19 outbreak.
<em>NCA</em>, <em>35</em>(8), 5999–6013. (<a
href="https://doi.org/10.1007/s00521-022-07938-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spreading of misleading information on social web platforms has fuelled huge panic and confusion among the public regarding the Corona disease, the detection of which is of paramount importance. To identify the credibility of the posted claim, we have analyzed possible evidence from the news articles in the google search results. This paper proposes an intelligent and expert strategy to gather important clues from the top 10 google search results related to the claim. The N-gram, Levenshtein Distance, and Word-Similarity-based features are used to identify the clues from the news article that can automatically warn users against spreading false news if no significant supportive clues are identified concerning that claim. The complete process is done in four steps, wherein the first step we build a query from the posted claim received in the form of text or text additive images which further goes as an input to the search query phase, where the top 10 google results are processed. In the third step, the important clues are extracted from titles of the top 10 news articles. Lastly, useful pieces of evidence are extracted from the content of each news article. All the useful clues with respect to N-gram, Levenshtein Distance, and Word Similarity are finally fed into the machine learning model for classification and to evaluate its performances. It has been observed that our proposed intelligent strategy gives promising experimental results and is quite effective in predicting misleading information. The proposed work provides practical implications for the policymakers and health practitioners that could be useful in protecting the world from misleading information proliferation during this pandemic.},
  archive      = {J_NCA},
  author       = {Varshney, Deepika and Vishwakarma, Dinesh Kumar},
  doi          = {10.1007/s00521-022-07938-3},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5999-6013},
  shortjournal = {Neural Comput. Appl.},
  title        = {Framework for detection of probable clues to predict misleading information proliferated during COVID-19 outbreak},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Employing deep learning for sex estimation of adult
individuals using 2D images of the humerus. <em>NCA</em>,
<em>35</em>(8), 5987–5998. (<a
href="https://doi.org/10.1007/s00521-022-07981-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological profile estimation, of which sex estimation is a fundamental first stage, is a really important task in forensic human identification. Although there are a large number of methods that address this problem from different bone structures, mainly using the pelvis and the skull, it has been shown that the humerus presents significant sexual dimorphisms that can be used to estimate sex in their absence. However, these methods are often too subjective or costly, and the development of new methods that avoid these problems is one of the priorities in forensic anthropology research. In this respect, the use of artificial intelligence may allow to automate and reduce the subjectivity of biological profile estimation methods. In fact, artificial intelligence has been successfully applied in sex estimation tasks, but most of the previous work focuses on the analysis of the pelvis and the skull. More importantly, the humerus, which can be useful in some situations due to its resistance, has never been used in the development of an automatic sex estimation method. Therefore, this paper addresses the use of machine learning techniques to the task of image classification, focusing on the use of images of the distal epiphysis of the humerus to classify whether it belongs to a male or female individual. To address this, we have used a set of humerus photographs of 417 adult individuals of Mediterranean origin to validate and compare different approaches, using both deep learning and traditional feature extraction techniques. Our best model obtains an accuracy of 91.03\% in test, correctly estimating the sex of 92.68\% of the males and 89.19\% of the females. These results are superior to the ones obtained by the state of the art and by a human expert, who has achieved an accuracy of 83.33\% using a state-of-the-art method on the same data. In addition, the visualization of activation maps allows us to confirm not only that the neural network observes the sexual dimorphisms that have been proposed by the forensic anthropology literature, but also that it has been capable of finding a new region of interest.},
  archive      = {J_NCA},
  author       = {Venema, Javier and Peula, David and Irurita, Javier and Mesejo, Pablo},
  doi          = {10.1007/s00521-022-07981-0},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5987-5998},
  shortjournal = {Neural Comput. Appl.},
  title        = {Employing deep learning for sex estimation of adult individuals using 2D images of the humerus},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A machine learning approach for cross-domain plant
identification using herbarium specimens. <em>NCA</em>, <em>35</em>(8),
5963–5985. (<a
href="https://doi.org/10.1007/s00521-022-07951-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preservation of plant specimens in herbaria has been carried out for centuries in efforts to study and confirm plant taxa. With the increasing collection of herbaria made available digitally, it is practical to use herbarium specimens for the automation of plant identification. They are also substantially more accessible and less expensive to obtain compared to field images. In fact, in remote and inaccessible habitats, field images of rare plant species are still immensely lacking. As a result, rare plant species identification is challenging due to the deficiency of training data. To address this problem, we investigate a cross-domain adaptation approach that allows knowledge transfer from a model learned from herbarium specimens to field images. We propose a model called Herbarium–Field Triplet Loss Network (HFTL network) to learn the mapping between herbarium and field domains. Specifically, the model is trained to maximize the embedding distance of different plant species and minimize the embedding distance of the same plant species given herbarium–field pairs. This paper presents the implementation and performance of the HFTL network to assess the herbarium–field similarity of plants. It corresponds to the cross-domain plant identification challenge in PlantCLEF 2020 and PlantCLEF 2021. Despite the lack of field images, our results show that the network can generalize and identify rare species. Our proposed HFTL network achieved a mean reciprocal rank score of 0.108 and 0.158 on the test set related to the species with few training field photographs in PlantCLEF 2020 and PlantCLEF 2021, respectively.},
  archive      = {J_NCA},
  author       = {Chulif, Sophia and Lee, Sue Han and Chang, Yang Loong and Chai, Kok Chin},
  doi          = {10.1007/s00521-022-07951-6},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5963-5985},
  shortjournal = {Neural Comput. Appl.},
  title        = {A machine learning approach for cross-domain plant identification using herbarium specimens},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A complete ranking of trapezoidal-valued intuitionistic
fuzzy number: An application in evaluating social sustainability.
<em>NCA</em>, <em>35</em>(8), 5939–5962. (<a
href="https://doi.org/10.1007/s00521-022-07983-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional trapezoidal intuitionistic fuzzy numbers (CTrIFNs) are used in the literature to handle many real-life problems with imprecise information. However, the CTrIFNs are not the real generalization of interval-valued intuitionistic fuzzy numbers (IVIFNs) and triangular intuitionistic fuzzy numbers (TIFNs). This study discusses the non-conventional trapezoidal intuitionistic fuzzy numbers called trapezoidal-valued intuitionistic fuzzy numbers (TrVIFNs) that generalize (contain) all real-valued intuitionistic fuzzy numbers, IVIFNs and TIFNs. Various researchers worldwide are looking for a complete ranking principle on the set of TrVIFNs. However, none of them yields a complete ranking. The paper’s main aim is to propose a new complete ranking principle on the class of TrVIFNs. The complete ranking principle on the set of TrVIFNs makes the decision-making algorithm more robust. To achieve the main aim, firstly, we introduce eight different score functions on the set of TrVIFNs and study their mathematical properties. Secondly, we present a new ranking principle by considering all eight score functions in a linear order. Further, we prove (mathematically) that the introduced ranking principle defines complete ranking on the set of TrVIFNs. Thirdly, we show the significance of the proposed method compared with the existing methods on various classes of fuzzy and intuitionistic fuzzy numbers. Finally, we implement a case application of the proposed complete ranking principle for evaluating the social sustainability performance of Indian firms.},
  archive      = {J_NCA},
  author       = {Jeevaraj, S. and Rajesh, R. and Lakshmana Gomathi Nayagam, V.},
  doi          = {10.1007/s00521-022-07983-y},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5939-5962},
  shortjournal = {Neural Comput. Appl.},
  title        = {A complete ranking of trapezoidal-valued intuitionistic fuzzy number: An application in evaluating social sustainability},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-sensor feature fusion network model for bearings
grease life assessment in accelerated experiments. <em>NCA</em>,
<em>35</em>(8), 5923–5937. (<a
href="https://doi.org/10.1007/s00521-022-07982-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a multi-sensor feature fusion (MSFF) neural network comprised of two inception layer-type multiple channel feature fusion (MCFF) networks for both inner-sensor and cross-sensor feature fusion in conjunction with a deep residual neural network (ResNet) for accurate grease life assessment and bearings health monitoring. The single MCFF network is designed for low-level feature extraction and fusion of either vibration or acoustic emission signals at multi-scales. The concatenation of MCFF networks serves as a cross-sensor feature fusion layer to combine extracted features from both vibration and acoustic emission sources. A ResNet is developed for high-level feature extraction from the fused feature maps and prediction. Besides, to handle the large volume of collected data, original time-series data are transformed to the frequency domain with different sampling intervals and targeted ranges. The proposed MSFF network outperforms other models based on different fusion methods, fully connected network predictors and/or a single sensor source.},
  archive      = {J_NCA},
  author       = {Jiang, Zhuocheng and Hong, Seong Hyeon and Albia, Benjamin and Hood, Adrian A. and Hall, Asha J. and Cornelius, Jackson and Wang, Yi},
  doi          = {10.1007/s00521-022-07982-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5923-5937},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-sensor feature fusion network model for bearings grease life assessment in accelerated experiments},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep hashing method of likelihood function adaptive
mapping. <em>NCA</em>, <em>35</em>(8), 5903–5921. (<a
href="https://doi.org/10.1007/s00521-022-07962-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image retrieval, deep-learning-based models combing deep hashing and Bayesian learning have become one of the mainstream approaches. The choice of likelihood functions can significantly affect the performance of existing image retrieval methods that combine deep hashing and Bayesian learning, resulting in issues such as misclassification in single-label datasets and biased label association in multi-label ones. However, it remains to further explore how image retrieval performance can be reliably enhanced through proper likelihood function design. In this paper, we propose a deep adaptive-mapping-based hashing (DAMH) method that enhances image retrieval performance via adjustable likelihood function design. Through strategically re-mapping image samples with low-gradient to high-gradient regions of the likelihood functions, our method both effectively expands the ranges over which inner products used in single-label image retrieval are trained and properly delimits the likelihood functions to prevent multi-label images from being excessively mapped into Hamming sphere(s) of any single class. Furthermore, we design a batch-by-batch optimization method that treats easy and hard samples differently, preventing the gradients of hard samples from being submerged by those of the easy ones during the training process. Our experiments on general-purpose image datasets, including CIFAR10, NUSWIDE and ImageNet100, show that DAMH excels existing peer methods in overall image retrieval performance.},
  archive      = {J_NCA},
  author       = {Su, Hai and Fang, Jianwei and Liu, Weixing and Yu, Songsen and Yang, Huan},
  doi          = {10.1007/s00521-022-07962-3},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5903-5921},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep hashing method of likelihood function adaptive mapping},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual attention composition network for fashion image
retrieval with attribute manipulation. <em>NCA</em>, <em>35</em>(8),
5889–5902. (<a
href="https://doi.org/10.1007/s00521-022-07994-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to practical demands and substantial potential benefits, there is growing interest in fashion image retrieval with attribute manipulation. For example, if a user wants a product similar to a query image and has the attribute “3/4 sleeves” instead of “short sleeves” he can modify the query image by entering text. Unlike general items, fashion items are rich in categories and attributes, and some items with different attributes have only very subtle differences in vision. Moreover, the visual appearance of fashion items changes dramatically under different conditions, such as lighting, viewing angle, and occlusion. These pose challenges to the fashion retrieval task. Therefore, we consider learning an attribute-specific space for each attribute to obtain discriminative features. In this paper, we propose a dual attention composition network for image retrieval with manipulation, which addresses two important issues, where to focus and how to modify. The dual attention module aims to capture fine-grained image-text alignment through corresponding spatial and channel attention and then satisfy multi-modal composition through corresponding affine transformation. The TIRG-based semantic composition module combines the query image’s attention features and the manipulation text’s embedding features to obtain a synthetic representation close to the target image. Meanwhile, we investigate the semantic hierarchy of attributes and propose a hierarchical encoding method, which can preserve the associations between attributes for efficient feature learning. Extensive experiments conducted on three multi-modal fashion-related retrieval datasets demonstrate the superiority of our network.},
  archive      = {J_NCA},
  author       = {Wan, Yongquan and Zou, Guobing and Yan, Cairong and Zhang, Bofeng},
  doi          = {10.1007/s00521-022-07994-9},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5889-5902},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual attention composition network for fashion image retrieval with attribute manipulation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seismic data IO and sorting optimization in HPC through ANNs
prediction based auto-tuning for ExSeisDat. <em>NCA</em>,
<em>35</em>(8), 5855–5888. (<a
href="https://doi.org/10.1007/s00521-022-07991-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ExSeisDat is designed using standard message passing interface (MPI) library for seismic data processing on high-performance super-computing clusters. These clusters are generally designed for efficient execution of complex tasks including large size IO. The IO performance degradation issues arise when multiple processes try accessing data from parallel networked storage. These complications are caused by restrictive protocols running by a parallel file system (PFS) controlling the disks and due to less advancement in storage hardware itself as well. This requires and leads to the tuning of specific configuration parameters to optimize the IO performance, commonly not considered by users focused on writing parallel application. Despite its consideration, the changes in configuration parameters are required from case to case. It adds up to further degradation in IO performance for a large SEG-Y format seismic data file scaling to petabytes. The SEG-Y IO and file sorting operations are the two of the main features of ExSeisDat. This research paper proposes technique to optimize these SEG-Y operations based on artificial neural networks (ANNs). The optimization involves auto-tuning of the related configuration parameters, using IO bandwidth prediction by the trained ANN models through machine learning (ML) process. Furthermore, we discuss the impact on prediction accuracy and statistical analysis of auto-tuning bandwidth results, by the variation in hidden layers nodes configuration of the ANNs. The results have shown the overall improvement in bandwidth performance up to 108.8\% and 237.4\% in the combined SEG-Y IO and file sorting operations test cases, respectively. Therefore, this paper has demonstrated the significant gain in SEG-Y seismic data bandwidth performance by auto-tuning the parameters settings on runtime by using an ML approach.},
  archive      = {J_NCA},
  author       = {Tipu, Abdul Jabbar Saeed and Conbhuí, Pádraig Ó and Howley, Enda},
  doi          = {10.1007/s00521-022-07991-y},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5855-5888},
  shortjournal = {Neural Comput. Appl.},
  title        = {Seismic data IO and sorting optimization in HPC through ANNs prediction based auto-tuning for ExSeisDat},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Region-based feature enhancement using channel-wise
attention for classification of breast histopathological images.
<em>NCA</em>, <em>35</em>(8), 5839–5854. (<a
href="https://doi.org/10.1007/s00521-022-07966-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast histopathological image analysis at 400x magnification is essential for the determination of malignant breast tumours. But manual analysis of these images is tedious, subjective, error-prone and requires domain knowledge. To this end, computer-aided tools are gaining much attention in the recent past as it aids pathologists and save time. Furthermore, advances in computational power have leveraged the usage of computer tools. Yet, usage of computer-aided tools to analyse these images is challenging due to various reasons such as heterogeneity of malignant tumours, colour variations and presence of artefacts. Moreover, these images are captured at high resolutions which pose a major challenge to designing deep learning models as it demands high computational requirements. In this context, the present work proposes a new approach to efficiently and effectively extract features from these high-resolution images. In addition, at 400x magnification, the characteristics and structure of nuclei play a prominent role in the decision of malignancy. In this regard, the study introduces a novel CNN architecture called as CWA-Net that uses a colour channel attention module to enhance the features of the potential regions of interest such as nuclei. The developed model is qualitatively and quantitatively evaluated on private and public datasets and achieved an accuracy of 0.95\% and 0.96\%, respectively. The experimental evaluation demonstrates that the proposed method outperforms state-of-the-art methods on both datasets.},
  archive      = {J_NCA},
  author       = {Rashmi, R. and Prasad, Keerthana and Udupa, Chethana Babu K.},
  doi          = {10.1007/s00521-022-07966-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5839-5854},
  shortjournal = {Neural Comput. Appl.},
  title        = {Region-based feature enhancement using channel-wise attention for classification of breast histopathological images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Academic performance warning system based on data driven for
higher education. <em>NCA</em>, <em>35</em>(8), 5819–5837. (<a
href="https://doi.org/10.1007/s00521-022-07997-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Academic probation at universities has become a matter of pressing concern in recent years, as many students face severe consequences of academic probation. We carried out research to find solutions to decrease the situation mentioned above. Our research used the power of massive data sources from the education sector and the modernity of machine learning techniques to build an academic warning system. Our system is based on academic performance that directly reflects students’ academic probation status at the university. Through the research process, we provided a dataset that has been extracted and developed from raw data sources, including a wealth of information about students, subjects, and scores. We build a dataset with many features that are extremely useful in predicting students’ academic warning status via feature generation techniques and feature selection strategies. Remarkably, the dataset contributed is flexible and scalable because we provided detailed calculation formulas that its materials are found in any university or college in Vietnam. That allows any university to reuse or reconstruct another similar dataset based on their raw academic database. Moreover, we variously combined data, unbalanced data handling techniques, model selection techniques, and research to propose suitable machine learning algorithms to build the best possible warning system. As a result, a two-stage academic performance warning system for higher education was proposed, with the F2-score measure of more than 74\% at the beginning of the semester using the algorithm Support Vector Machine and more than 92\% before the final examination using the algorithm LightGBM.},
  archive      = {J_NCA},
  author       = {Duong, Hanh Thi-Hong and Tran, Linh Thi-My and To, Huy Quoc and Van Nguyen, Kiet},
  doi          = {10.1007/s00521-022-07997-6},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5819-5837},
  shortjournal = {Neural Comput. Appl.},
  title        = {Academic performance warning system based on data driven for higher education},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Will a tropical cyclone make landfall? <em>NCA</em>,
<em>35</em>(8), 5807–5818. (<a
href="https://doi.org/10.1007/s00521-022-07996-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the different development phases of a tropical cyclone, the most exciting and complex phase is its landfall, which is when a tropical cyclone moves over to the land after crossing the ocean’s coast. The location, time, and intensity at landfall of a tropical cyclone determine the extent of the disaster caused by it. In this work, we investigate a fundamental question: will a tropical cyclone make a landfall? Knowing the answer to this question with high accuracy will have huge benefits as the preparedness for a potential landfall involves mobilizing substantial human and economic resources. To answer this fundamental question, we have used high-resolution reanalysis data ERA5 (ECMWF reanalysis $$5^{th}$$ generation) and best track data IBTrACS (International Best Track Archive for Climate Stewardship) to develop a deep learning model that can predict the landfall event in the early phase of a tropical cyclone—in particular, using any 12 hours or 24 hours of data from the first 72 hours of its inception with very high accuracy. We tested the model for six ocean basins of the world and achieved a fivefold accuracy in the range of $$97.6\%$$ to $$99.2\%$$ across all basins. The model can be trained within 05 to 20 minutes depending on the ocean basin and can predict the above-stated problem within seconds, making it suitable for real-time application.},
  archive      = {J_NCA},
  author       = {Kumar, Sandeep and Biswas, Koushik and Pandey, Ashish Kumar},
  doi          = {10.1007/s00521-022-07996-7},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5807-5818},
  shortjournal = {Neural Comput. Appl.},
  title        = {Will a tropical cyclone make landfall?},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical temporal slot interactions for dialogue state
tracking. <em>NCA</em>, <em>35</em>(8), 5791–5805. (<a
href="https://doi.org/10.1007/s00521-022-07959-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue state tracking (DST), as an essential component of task-oriented dialogue systems, refers to keeping track of the user’s intentions as a conversation progresses. Typical methods formulate it as a classification task with fixed pre-defined slot-value pairs, or generate slot-value candidates given the dialogue history. Most of them have limitations on considering interactions of slots with utterance sentences and other slots progressively. To tackle this problem, we propose a Dialogue State Tracker with Hierarchical Temporal Slot Interactions (DST-HTSI) to capture slot-related semantic information from utterance sentences and slots. It firstly captures interactive information among slots within a turn and across turns by applying hierarchical slot interactions. Then a temporal slot interaction module is employed to establish slot dependencies along the time. Finally, a GRU is applied as the decoder to generate values for each slot correspondingly. Furthermore, we also leverage pre-trained language models as the backbone of our model. Experiments show that DST-HTSI outperforms previous state-of-the-art on MultiWOZ 2.2 and WOZ 2.0, and achieves competitive results on MultiWOZ 2.1.},
  archive      = {J_NCA},
  author       = {Qiu, Junyan and Lin, Ziqi and Zhang, Haidong and Yang, Yiping},
  doi          = {10.1007/s00521-022-07959-y},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5791-5805},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical temporal slot interactions for dialogue state tracking},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On finite-/fixed-time synchronization of multi-weighted
dynamical networks: A new unified control approach. <em>NCA</em>,
<em>35</em>(8), 5769–5790. (<a
href="https://doi.org/10.1007/s00521-022-07979-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a unified control strategy is proposed to explore the issues of finite-time (FTT) synchronization and fixed-time (FXT) one for multi-weighted dynamical networks (MWDNs) simultaneously. A new unified finite-/fixed-time (FTT/FXT) stability result is firstly derived for nonlinear dynamical systems, wherein the settling time is more precisely estimated. Then, by designing a novel feedback controller, unified sufficient conditions are established for FTT/FXT synchronization of the MWDNs under study. It is indicated that the conversion between FTT synchronization and FXT one can be realized through simply adjusting one control parameter, exhibiting the flexibility of the control scheme in real-world applications. Moreover, the designed unified control protocol does not contain signum function, which can avoid the occurrence of chattering phenomena during the synchronization process. In particular, a detailed analysis about the relationships between the settling time and the main control parameters is given, which facilitates the selection of control parameters in practice. Lastly, numerical simulations are presented to validate the correctness of the theoretical results.},
  archive      = {J_NCA},
  author       = {Shi, Jinyao and Zhou, Peipei and Cai, Shuiming and Jia, Qiang},
  doi          = {10.1007/s00521-022-07979-8},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5769-5790},
  shortjournal = {Neural Comput. Appl.},
  title        = {On finite-/fixed-time synchronization of multi-weighted dynamical networks: A new unified control approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network models for simulating adsorptive eviction of
metal contaminants from effluent streams using natural materials (NMs).
<em>NCA</em>, <em>35</em>(8), 5751–5767. (<a
href="https://doi.org/10.1007/s00521-023-08315-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise in environmental-conscious research, natural materials (NMs) have drawn attention as eco-sustainable solution for removing hazardous pollutants via adsorption. Although adsorption processes are renowned for their simple implementation, the mechanisms involved in the adsorption of toxins can be complex due to the number of variables involved and their nonlinear interaction. Literature unveils numerous modelling procedures to optimize process variables for the successful metal ions adsorption; however, artificial neural networks’ (ANN) algorithmic approach has accelerated the adsorption propensity of adsorbents for metals ions in water. This review evaluates the ANN approaches (i.e., feedforward neural networks (FFNNs) and neural networks coupled with global optimizers) to simulate the adsorption of different metal ions ranging from heavy metals to highly toxic contaminants (e.g., Ur, Th, As, Cd, Cr, Co, etc.) on NMs. Further, the relative influence of process parameters (such as contact time, pH, initial metal concentration, and dose of NMs) on adsorption has also been outlined. An outlook for future development in the field is provided.},
  archive      = {J_NCA},
  author       = {Nighojkar, Amrita and Plappally, Anand and Soboyejo, Winston},
  doi          = {10.1007/s00521-023-08315-4},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5751-5767},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network models for simulating adsorptive eviction of metal contaminants from effluent streams using natural materials (NMs)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification of spatial patterns with maximum association
between power of resting state neural oscillations and trait anxiety.
<em>NCA</em>, <em>35</em>(8), 5737–5749. (<a
href="https://doi.org/10.1007/s00521-022-07847-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anxiety affects approximately 5–10\% of the adult population worldwide, placing a large burden on the health systems. Despite its omnipresence and impact on mental and physical health, most of the individuals affected by anxiety do not receive appropriate treatment. Current research in the field of psychiatry emphasizes the need to identify and validate biological markers relevant to this condition. Neurophysiological preclinical studies are a prominent approach to determine brain rhythms that can be reliable markers of key features of anxiety. However, while neuroimaging research consistently implicated prefrontal cortex and subcortical structures, such as amygdala and hippocampus, in anxiety, there is still a lack of consensus on the underlying neurophysiological processes contributing to this condition. Methods allowing non-invasive recording and assessment of cortical processing may provide an opportunity to help identify anxiety signatures that could be used as intervention targets. In this study, we apply Source-Power Comodulation (SPoC) to electroencephalography (EEG) recordings in a sample of participants with different levels of trait anxiety. SPoC was developed to find spatial filters and patterns whose power comodulates with an external variable in individual participants. The obtained patterns can be interpreted neurophysiologically. Here, we extend the use of SPoC to a multi-subject setting and test its validity using simulated data with a realistic head model. Next, we apply our SPoC framework to resting state EEG of 43 human participants for whom trait anxiety scores were available. SPoC inter-subject analysis of narrow frequency band data reveals neurophysiologically meaningful spatial patterns in the theta band (4–7 Hz) that are negatively correlated with anxiety. The outcome is specific to the theta band and not observed in the alpha (8–12 Hz) or beta (13–30 Hz) frequency range. The theta-band spatial pattern is primarily localised to the superior frontal gyrus. We discuss the relevance of our spatial pattern results for the search of biomarkers for anxiety and their application in neurofeedback studies.},
  archive      = {J_NCA},
  author       = {Vidaurre, Carmen and Nikulin, Vadim V. and Herrojo Ruiz, Maria},
  doi          = {10.1007/s00521-022-07847-5},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5737-5749},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification of spatial patterns with maximum association between power of resting state neural oscillations and trait anxiety},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EmotiphAI: A biocybernetic engine for real-time biosignals
acquisition in a collective setting. <em>NCA</em>, <em>35</em>(8),
5721–5736. (<a
href="https://doi.org/10.1007/s00521-022-07191-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the latter years, we have been observing a growth in wearable technology for personal use. However, an analysis of the state of the art for wearable technology shows that most devices perform data acquisition from individual subjects only, relying on communication technologies with drawbacks that prevent their use in collective real-world scenarios (e.g. a cinema, a theatre, and related use cases). When analysing the emotional response in groups, two types of emotions appear: individual (influenced by the group) and group-based emotions (towards the group as an identity). To fill the existing gap, we propose a biocybernetic engine for real-time data acquisition of multimodal physiological data in real-world scenarios. Our system extends the state of the art with: (1) real-time data acquisition for the signals being acquired (20 devices at 25 Hz; 10 devices at 60 Hz); (2) creation of a standalone local infrastructure with end-user interface for monitoring the data acquisition; (3) local and cloud-based data storage. We foresee that this platform could be the basis for the creation of large databases in diverse real-world scenarios, namely health and wellbeing, marketing, art performances, and others. As a result, this work will greatly contribute to simplify widespread biosignals data collection from unobtrusive wearables. To evaluate the system, we report a comprehensive assessment based on a set of criteria for data quality analysis.},
  archive      = {J_NCA},
  author       = {Bota, Patrícia and Flety, Emmanuel and Silva, Hugo Plácido da and Fred, Ana},
  doi          = {10.1007/s00521-022-07191-8},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5721-5736},
  shortjournal = {Neural Comput. Appl.},
  title        = {EmotiphAI: A biocybernetic engine for real-time biosignals acquisition in a collective setting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ranking the effect of chronodisruption-based biomarkers in
reproductive health. <em>NCA</em>, <em>35</em>(8), 5697–5720. (<a
href="https://doi.org/10.1007/s00521-022-07563-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronodisruption alters circadian rhythms, which has negative consequences on different pathologies and mental disorders. This work studies whether factors related to chronodisruption of circadian rhythms motivated by shift works influence on reproductive health or not. In particular, this influence is studied on four particular aspects related to reproductive health: reproductive health disease, first pregnancy attempt, problems during pregnancy and gestation period. Some explainable machine learning models based on trees have been employed. These methods provided information about the importance of each predictor. The most important variables provided by each method were aggregated using a ranking aggregation function in order to reach a consensus ranking of variables that made possible to understand whether the chronodisruption factors had an effect on each of the aspects studied. The data have been obtained from 697 health professionals. Information about classical biomarkers, sleep quality indices and also other new variables related to eating jet lag, sleep hygiene and how the sleep is affected by shift works were considered as input data. Experiments have shown how some of these novel biomarkers are ranked in the top positions of the issues studied in relation to reproductive health. In particular, the light level and the use of electronic devices, which are features related to chronodisruption, are highlighted as biomarkers.},
  archive      = {J_NCA},
  author       = {Rúa, Ana G. and Rico, Noelia and Alonso, Ana and Díaz, Elena and Díaz, Irene},
  doi          = {10.1007/s00521-022-07563-0},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5697-5720},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ranking the effect of chronodisruption-based biomarkers in reproductive health},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic detection of the mental state in responses towards
relaxation. <em>NCA</em>, <em>35</em>(8), 5679–5696. (<a
href="https://doi.org/10.1007/s00521-022-07435-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, considering society’s highly demanding lifestyles, it is important to consider the usefulness of relaxation from the perspective of both psychology and clinical practice. The response towards relaxation (RResp) is a mind-body interaction that relaxes the organism or compensates for the physiological effects caused by stress. This work aims to automatically detect the different mental states (relaxation, rest and stress) in which RResps may occur so that complete feedback about the quality of the relaxation can be given to the subject itself, the psychologist or the doctor. To this end, an experiment was conducted to induce both states of stress and relaxation in a sample of 20 university students (average age of $$25.76\pm 3.7$$ years old). The electrocardiographic and electrodermal activity signals collected from the participants produced a dataset with 1641 episodes or instances in which the previously mentioned mental states take place. This data was used to extract up to 50 features and train several supervised learning algorithms (rule-based, trees, probabilistic, ensemble classifiers, etc.) using and not using feature selection techniques. Besides, the authors synthesised the cardiac activity information into a single new feature and discretised it down to three levels. The experimentation revealed which features were most discriminating, reaching a classification average accuracy of up to $$94.01\pm 1.73$$\% with the 6 most relevant features for the own-collected dataset. Finally, being restrictive, the same solution/subspace was tested with a dataset referenced in the bibliography (WESAD) and scored an average accuracy of $$90.36\pm 1.62$$\%.},
  archive      = {J_NCA},
  author       = {Sagastibeltza, Nagore and Salazar-Ramirez, Asier and Martinez, Raquel and Jodra, Jose Luis and Muguerza, Javier},
  doi          = {10.1007/s00521-022-07435-7},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5679-5696},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic detection of the mental state in responses towards relaxation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Impact of sampling rate and interpolation on
photoplethysmography and electrodermal activity signals’ waveform
morphology and feature extraction. <em>NCA</em>, <em>35</em>(8),
5661–5677. (<a
href="https://doi.org/10.1007/s00521-022-07212-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of low-cost biomedical devices has driven a growing interest in the use of physiological signals for mental and emotional health research. Due to their potential for integration in discrete wearable form factors, Photoplethysmography (PPG) and Electrodermal Activity (EDA) are particularly popular, especially in out-of-the-lab experiments. Although high-resolution data acquisition should be a priority, the sampling rate can greatly affect the power consumption and memory storage of the devices in long-term recordings. Moreover, systems with shared computational resources that simultaneously monitor different signals, can also have communication channel bandwidth constraints that limit the sampling rate. This work seeks to evaluate how the sampling rate and interpolation affect the signal quality of PPG and EDA signals, in terms of waveform morphology and feature extraction capabilities. We study the minimum sampling rate requirements for each signal, as well as the impact of interpolation methods on signal waveform reconstruction. Using a previously recorded dataset with signals originally recorded at 1 kHz, we simulate multiple lower sampling rates. Results show that for PPG a 50 Hz sampling rate with quadratic or cubic interpolation can achieve a temporal resolution identical to that of a 1 kHz acquisition, while for EDA the same can be said but with a 10 Hz sampling rate. Other recommendations are also proposed depending on the signal application.},
  archive      = {J_NCA},
  author       = {Silva, Rafael and Salvador, Gonçalo and Bota, Patrícia and Fred, Ana and Plácido da Silva, Hugo},
  doi          = {10.1007/s00521-022-07212-6},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5661-5677},
  shortjournal = {Neural Comput. Appl.},
  title        = {Impact of sampling rate and interpolation on photoplethysmography and electrodermal activity signals’ waveform morphology and feature extraction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Virtual reality and machine learning in the automatic
photoparoxysmal response detection. <em>NCA</em>, <em>35</em>(8),
5643–5659. (<a
href="https://doi.org/10.1007/s00521-022-06940-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photosensitivity, in relation to epilepsy, is a genetically determined condition in which patients have epileptic seizures of different severity provoked by visual stimuli. It can be diagnosed by detecting epileptiform discharges in their electroencephalogram (EEG), known as photoparoxysmal responses (PPR). The most accepted PPR detection method—a manual method—considered as the standard one, consists in submitting the subject to intermittent photic stimulation (IPS), i.e. a flashing light stimulation at increasing and decreasing flickering frequencies in a hospital room under controlled ambient conditions, while at the same time recording her/his brain response by means of EEG signals. This research focuses on introducing virtual reality (VR) in this context, adding, to the conventional infrastructure a more flexible one that can be programmed and that will allow developing a much wider and richer set of experiments in order to detect neurological illnesses, and to study subjects’ behaviours automatically. The loop includes the subject, the VR device, the EEG infrastructure and a computer to analyse and monitor the EEG signal and, in some cases, provide feedback to the VR. As will be shown, AI modelling will be needed in the automatic detection of PPR, but it would also be used in extending the functionality of this system with more advanced features. This system is currently in study with subjects at Burgos University Hospital, Spain.},
  archive      = {J_NCA},
  author       = {Moncada, Fernando and Martín, Sofía and González, Víctor M. and Álvarez, Víctor M. and García-López, Beatriz and Gómez-Menéndez, Ana Isabel and Villar, José R.},
  doi          = {10.1007/s00521-022-06940-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5643-5659},
  shortjournal = {Neural Comput. Appl.},
  title        = {Virtual reality and machine learning in the automatic photoparoxysmal response detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Black hole algorithm with convolutional neural networks for
the creation of brain-computer interface based in visual perception and
visual imagery. <em>NCA</em>, <em>35</em>(8), 5631–5641. (<a
href="https://doi.org/10.1007/s00521-022-07542-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-invasive brain-computer interfaces can be implemented through different paradigms, the most used one being motor imagery and evoked potentials, although recently there has been an interest in paradigms based on perception and visual imagery. Following this approach, this work demonstrates the classification of visual imagery, visual perception and also the possibility of knowledge transfer between these two domains from EEG signals using convolutional neural networks. Also, we propose an adequate framework for such classification, which uses convolutional neural networks and the black hole heuristic algorithm for the search for optimal neural network structures.},
  archive      = {J_NCA},
  author       = {Llorella, Fabio R. and Azorín, José M. and Patow, Gustavo},
  doi          = {10.1007/s00521-022-07542-5},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5631-5641},
  shortjournal = {Neural Comput. Appl.},
  title        = {Black hole algorithm with convolutional neural networks for the creation of brain-computer interface based in visual perception and visual imagery},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of schizophrenia from activity data using hidden
markov model parameters. <em>NCA</em>, <em>35</em>(8), 5619–5630. (<a
href="https://doi.org/10.1007/s00521-022-07845-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of predicting schizophrenia based on a persons measured motor activity over time. A key challenge to achieve this is how to extract features from the activity data that can efficiently separate schizophrenia patients from healthy subjects. To achieve this, we suggest to fit time dependent hidden Markov models with and without integrated covariates and letting the estimated model parameters represent our features. To further evaluate the efficiency of these features, we suggest to use them as features in a classification method (logistic regression) to separate schizophrenia patients from healthy subjects. The results show that the estimated hidden Markov model parameters are well-performing in predicting schizophrenia, and outperform features derived from other methods in the literature in terms of goodness-of-fit and classification performance.},
  archive      = {J_NCA},
  author       = {Boeker, Matthias and Hammer, Hugo L. and Riegler, Michael A. and Halvorsen, Pål and Jakobsen, Petter},
  doi          = {10.1007/s00521-022-07845-7},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5619-5630},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of schizophrenia from activity data using hidden markov model parameters},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnostic classification of parkinson’s disease based on
non-motor manifestations and machine learning strategies. <em>NCA</em>,
<em>35</em>(8), 5603–5617. (<a
href="https://doi.org/10.1007/s00521-022-07256-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-motor manifestations of Parkinson’s disease (PD) appear early and have a significant impact on the quality of life of patients, but few studies have evaluated their predictive potential with machine learning algorithms. We evaluated 9 algorithms for discriminating PD patients from controls using a wide collection of non-motor clinical PD features from two databases: Biocruces (96 subjects) and PPMI (687 subjects). In addition, we evaluated whether the combination of both databases could improve the individual results. For each database 2 versions with different granularity were created and a feature selection process was performed. We observed that most of the algorithms were able to detect PD patients with high accuracy (&gt;80\%). Support Vector Machine and Multi-Layer Perceptron obtained the best performance, with an accuracy of 86.3\% and 84.7\%, respectively. Likewise, feature selection led to a significant reduction in the number of variables and to better performance. Besides, the enrichment of Biocruces database with data from PPMI moderately benefited the performance of the classification algorithms, especially the recall and to a lesser extent the accuracy, while the precision worsened slightly. The use of interpretable rules obtained by the RIPPER algorithm showed that simply using two variables (autonomic manifestations and olfactory dysfunction), it was possible to achieve an accuracy of 84.4\%. Our study demonstrates that the analysis of non-motor parameters of PD through machine learning techniques can detect PD patients with high accuracy and recall, and allows us to select the most discriminative non-motor variables to create potential tools for PD screening.},
  archive      = {J_NCA},
  author       = {Martinez-Eguiluz, Maitane and Arbelaitz, Olatz and Gurrutxaga, Ibai and Muguerza, Javier and Perona, Iñigo and Murueta-Goyena, Ane and Acera, Marian and Del Pino, Rocío and Tijero, Beatriz and Gomez-Esteban, Juan Carlos and Gabilondo, Iñigo},
  doi          = {10.1007/s00521-022-07256-8},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5603-5617},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diagnostic classification of parkinson’s disease based on non-motor manifestations and machine learning strategies},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computational-based biomarkers for mental and emotional
health. <em>NCA</em>, <em>35</em>(8), 5601–5602. (<a
href="https://doi.org/10.1007/s00521-022-07920-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Villar, José Ramón and Yera, Ainhoa and López, Beatriz},
  doi          = {10.1007/s00521-022-07920-z},
  journal      = {Neural Computing and Applications},
  number       = {8},
  pages        = {5601-5602},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computational-based biomarkers for mental and emotional health},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Tolerance rough set firefly-based quick
reduct. <em>NCA</em>, <em>35</em>(7), 5599. (<a
href="https://doi.org/10.1007/s00521-022-08197-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ganesan, Jothi and Inbarani, Hannah H. and Azar, Ahmad Taher and Polat, Kemal},
  doi          = {10.1007/s00521-022-08197-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5599},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Tolerance rough set firefly-based quick reduct},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Decision response of subway evacuation
signs based on brain component features. <em>NCA</em>, <em>35</em>(7),
5597. (<a href="https://doi.org/10.1007/s00521-022-08193-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Huang, Yixin and Cao, Dongmei},
  doi          = {10.1007/s00521-022-08193-2},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5597},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Decision response of subway evacuation signs based on brain component features},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RETRACTED ARTICLE: IoT-based real-time patients vital
physiological parameters monitoring system using smart wearable sensors.
<em>NCA</em>, <em>35</em>(7), 5595. (<a
href="https://doi.org/10.1007/s00521-022-07090-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ahmed, Ajan and Khan, Mohammad Monirujjaman and Singh, Parminder and Batth, Ranbir Singh and Masud, Mehedi},
  doi          = {10.1007/s00521-022-07090-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5595},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: IoT-based real-time patients vital physiological parameters monitoring system using smart wearable sensors},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: Multiclass feature selection with
metaheuristic optimization algorithms: A review. <em>NCA</em>,
<em>35</em>(7), 5593. (<a
href="https://doi.org/10.1007/s00521-022-07784-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Akinola, Olatunji O. and Ezugwu, Absalom E. and Agushaka, Jeffrey O. and Zitar, Raed Abu and Abualigah, Laith},
  doi          = {10.1007/s00521-022-07784-3},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5593},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: multiclass feature selection with metaheuristic optimization algorithms: a review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: A review of machine learning-based human
activity recognition for diverse applications. <em>NCA</em>,
<em>35</em>(7), 5591. (<a
href="https://doi.org/10.1007/s00521-022-07731-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Kulsoom, Farzana and Narejo, Sanam and Mehmood, Zahid and Chaudhry, Hassan Nazeer and Butt, Ayesha and Bashir, Ali Kashif},
  doi          = {10.1007/s00521-022-07731-2},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5591},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: A review of machine learning-based human activity recognition for diverse applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correction to: Research on simulation of 3D human animation
vision technology based on an enhanced machine learning algorithm.
<em>NCA</em>, <em>35</em>(7), 5589. (<a
href="https://doi.org/10.1007/s00521-022-07267-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yuan, Zhenning and Lee, Jong Han and Zhang, Sai},
  doi          = {10.1007/s00521-022-07267-5},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5589},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Research on simulation of 3D human animation vision technology based on an enhanced machine learning algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Correction to: Classifying MOOC forum posts using corpora
semantic similarities: A study on transferability across different
courses. <em>NCA</em>, <em>35</em>(7), 5587. (<a
href="https://doi.org/10.1007/s00521-021-05904-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s00521-021-05904-z},
  archive      = {J_NCA},
  author       = {Ntourmas, Anastasios and Daskalaki, Sophia and Dimitriadis, Yannis and Avouris, Nikolaos},
  doi          = {10.1007/s00521-021-05904-z},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5587},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: classifying MOOC forum posts using corpora semantic similarities: a study on transferability across different courses},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reflection of people’s professions on social media
platforms. <em>NCA</em>, <em>35</em>(7), 5575–5586. (<a
href="https://doi.org/10.1007/s00521-022-07987-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {John Holland asserts that most people are one of the six personality types such as realistic, social, investigative, entrepreneurial, traditional, and artistic. Moreover, he claims that personality is an important factor in career choice, career success, and satisfaction. According to his theory of career choice, people’s careers are determined by the interaction between their personality and their environment. The theory points out that people prefer jobs surrounded by others who are like them. It also states that people seek environments that allow them not only to use their skills and abilities but also to express their attitudes and values. On the other hand, people from different professions express their thoughts through Online Social Networks (OSNs). They use social media to express themselves, discuss their interests, connect with friends, and grow their careers. Every day we witness the same person criticizing events in different expertise, such as political events, economic events, etc. Moreover, OSNs connect individuals with like-minded interests and let them share their thoughts, feelings, insights, and emotions. Herein, the reflection of people’s profession on OSNs was examined. Inspired by John Holland’s theory of career choice, the consistency of personality and work environment would be determined from which an individual’s personality can be inferred. In the study, tweets from four different professions: businessman, politician, sportsman, and actor were used to examine whether they are related to the profession. We developed two models using Long Short-Term Memory Neural Networks and Gated Recurrent Unit Neural Networks. The former received macro average accuracy of 94.025\% while the latter received 93.025\%. According to the simulation results, the proposed models sound and are promising.},
  archive      = {J_NCA},
  author       = {Dağıstanlı, Ömer and Erbay, Hasan and Kör, Hakan and Yurttakal, Ahmet Haşim},
  doi          = {10.1007/s00521-022-07987-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5575-5586},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reflection of people’s professions on social media platforms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward efficient neural architecture search with dynamic
mapping-adaptive sampling for resource-limited edge device.
<em>NCA</em>, <em>35</em>(7), 5553–5573. (<a
href="https://doi.org/10.1007/s00521-022-07984-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To account for both network accuracy and deployment efficiency, multi-objective NAS has been proposed. However, these methods are still inefficient. As a result of the previous coarse-grained performance descriptions, the acquisition of feasible networks is limited, reducing the effectiveness and efficiency of search direction updates. As a consequence, a large number of ineffective network structures that do not meet the application requirements are sampled and trained, significantly reducing search efficiency. To address the two issues, this paper uses adaptive dataflow mapping to describe the inference latency of the sampled network structures in a fine-grained manner, thereby expanding the search space of available networks. The sampling behavior is dynamically adjusted in accordance with the system latency requirement and the allocable latency for each layer. The sampled network structure’s latency will approach the system requirement. Finally, by reducing the number of infeasible networks, search efficiency is improved. Experiments show that comparing state-of-the-art methods, the accuracy of the networks searched by our framework can be improved by up to 7.93 $$\%$$ while meeting specific inference latency requirements. However, search efficiency can be improved up to 2.35 $$\times $$ .},
  archive      = {J_NCA},
  author       = {Yang, Zhao and Sun, Qingshuang},
  doi          = {10.1007/s00521-022-07984-x},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5553-5573},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward efficient neural architecture search with dynamic mapping-adaptive sampling for resource-limited edge device},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). STTG-TTE: Spatial–temporal gated multi-modality approach for
travel time estimation based on temporal convolutional networks.
<em>NCA</em>, <em>35</em>(7), 5535–5551. (<a
href="https://doi.org/10.1007/s00521-022-07977-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Travel time forecasting has become a core component of smart transportation systems, which assists both travelers and traffic organizers with route planning, travel schedule adjustments, ride-sharing, navigation applications, and efficient traffic management. However, timely and accurate travel time forecasting still remains a critical challenge owing to the complex nonlinear and dynamic fluctuations of spatial–temporal dependencies. Also, spatial sparseness is a big issue in traffic forecasting, since adopting the implicit interactions between the close traffic regions leads to superficial characterization of spatio-temporal dependences. In this paper, we propose a new deep learning-based framework (STTG-TTE) that addresses these drawbacks and improves the travel time estimation. First, we build a geo-hashing algorithm for the data sparsity issue that incorporates fluctuations of nearby and distant traffic situations in terms of spatio-temporal dependencies. Second, a new spatio-temporal correlation modeling method is proposed to fully leverage large-scale spatial and temporal traffic patterns using temporal convolutional networks integrated with a gated multi-modality mechanism. Then, for external factors’ representation, a new dual-gated Res-Net multi-modality-based module is proposed. Finally, we fuse these representations of multi-components dynamically and utilize the transformer model, which is conducive to learning intersections among these multiple factors for obtaining accurate prediction results. Experiments on two large-scale real-world traffic datasets from two different urban regions (Chengdu taxi-datsets and NYC-Bike datasets) demonstrate that the proposed model is superior to state-of-the-art baseline models.},
  archive      = {J_NCA},
  author       = {Tag Elsir, Alfateh M. and Khaled, Alkilane and Shen, Yanming},
  doi          = {10.1007/s00521-022-07977-w},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5535-5551},
  shortjournal = {Neural Comput. Appl.},
  title        = {STTG-TTE: Spatial–temporal gated multi-modality approach for travel time estimation based on temporal convolutional networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving and evaluating complex question answering over
knowledge bases by constructing strongly supervised data. <em>NCA</em>,
<em>35</em>(7), 5513–5533. (<a
href="https://doi.org/10.1007/s00521-022-07965-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex question answering (CQA) is widely used in real-world tasks such as search engines and intelligent customer service. With the development of large-scale knowledge bases, CQA over knowledge bases has attracted considerable attention in recent years. However, there are many types of complex questions, and few works deeply focus on the performance analysis of models for different types of questions. Another major challenge is the lack of complete supervised labels due to the expense of manual labelling, decreasing model interpretability and increasing the difficulty of model training. In this paper, we constructed a dataset, named CoSuQue, which includes multiple types of complex questions and complete supervised labels that are easily obtained. Our work provides an in-depth analysis of the model’s ability to answer different types of questions, contributing a comprehensive evaluation of the performance of CQA models. Based on the ability of the model to handle different types of questions, the model structure can be improved in a more targeted manner. The different types of complex questions and the complete supervised labels allow the inference process of the model to be investigated. Furthermore, we propose a novel training method that leverages the proposed dataset to improve the performance of the model on other publicly available datasets. Experiments on the Complex WebQuestions and WebQuestionsSP datasets demonstrate the effectiveness of our approach on the CQA task.},
  archive      = {J_NCA},
  author       = {Cao, Xing and Zhao, Yingsi and Shen, Bo},
  doi          = {10.1007/s00521-022-07965-0},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5513-5533},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving and evaluating complex question answering over knowledge bases by constructing strongly supervised data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybridization of butterfly optimization algorithm and
harmony search for fuzzy modelling in phishing attack detection.
<em>NCA</em>, <em>35</em>(7), 5501–5512. (<a
href="https://doi.org/10.1007/s00521-022-07957-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy system is one of the most used systems in the decision-making and classification method as it is easy to understand because the way this system works is closer to how humans think. It is a system that uses human experts to hold the membership values to make decisions. However, it is hard to determine the fuzzy parameter manually in a complex problem, and the process of generating the parameter is called fuzzy modelling. Therefore, an optimization method is needed to solve this issue, and one of the best methods to be applied is Butterfly Optimization Algorithm. In this paper, BOA was improvised by combining this algorithm with Harmony Search (HS) in order to achieve optimal results in fuzzy modelling. The advantages of both algorithms are used to balance the exploration and exploitation in the searching process. Two datasets from UCI machine learning were used: Website Phishing Dataset and Phishing Websites Dataset. As a result, the average accuracy for WPD and PWD was 98.69\% and 98.80\%, respectively. In conclusion, the proposed method shows promising and effective results compared to other methods.},
  archive      = {J_NCA},
  author       = {Nordin, Noor Syahirah and Ismail, Mohd Arfian},
  doi          = {10.1007/s00521-022-07957-0},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5501-5512},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybridization of butterfly optimization algorithm and harmony search for fuzzy modelling in phishing attack detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep feature selection using local search embedded social
ski-driver optimization algorithm for breast cancer detection in
mammograms. <em>NCA</em>, <em>35</em>(7), 5479–5499. (<a
href="https://doi.org/10.1007/s00521-022-07895-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer has become a common malignancy in women. However, early detection and identification of this disease can save many lives. As computer-aided detection helps radiologists in detecting abnormalities efficiently, researchers across the world are striving to develop reliable models to deal with. One of the common approaches to identifying breast cancer is through breast mammograms. However, the identification of malignant breasts from mass lesions is a challenging research problem. In the current work, we propose a method for the classification of breast mass using mammograms which consists of two main stages. At first, we extract deep features from the input mammograms using the well-known VGG16 model while incorporating an attention mechanism into this model. Next, we apply a meta-heuristic called Social Ski-Driver (SSD) algorithm embedded with Adaptive Beta Hill Climbing based local search to obtain an optimal features subset. The optimal features subset is fed to the K-nearest neighbors (KNN) classifier for the classification. The proposed model is demonstrated to be very useful for identifying and differentiating malignant and healthy breasts successfully. For experimentation, we evaluate our model on the digital database for screening mammography (DDSM) database and achieve 96.07\% accuracy using only 25\% of features extracted by the attention-aided VGG16 model. The Python code of our research work is publicly available at: https://github.com/Ppayel/BreastLocalSearchSSD .},
  archive      = {J_NCA},
  author       = {Pramanik, Payel and Mukhopadhyay, Souradeep and Mirjalili, Seyedali and Sarkar, Ram},
  doi          = {10.1007/s00521-022-07895-x},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5479-5499},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep feature selection using local search embedded social ski-driver optimization algorithm for breast cancer detection in mammograms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Study and comparison of different machine learning-based
approaches to solve the inverse problem in electrical impedance
tomographies. <em>NCA</em>, <em>35</em>(7), 5465–5477. (<a
href="https://doi.org/10.1007/s00521-022-07988-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrical Impedance Tomography (EIT) is a non-invasive technique used to obtain the electrical internal conductivity distribution from the interior of bodies. This is a promising method from the manufacturing viewpoint, since it could be used to estimate different physical inner body properties during the production of goods. Nevertheless, this technique requires dealing with an inverse problem that makes its usage in real-time processes challenging. Recently, Machine Learning techniques have been proposed to solve the inverse problem accurately. However, the majority of prior research is focused on qualitative results, and they typically lack a systematic methodology to determine the optimal hyperparameters appropriately. This work presents a systematic comparison of six popular Machine Learning algorithms: Artificial Neural Network, Random Forest, K-Nearest Neighbors, Elastic Net, Ada Boost, and Gradient Boosting. Particularly, the last two algorithms were based on decision tree learners. Furthermore, we studied the relationship between model performance and different EIT configurations. Specifically, we analyzed whether the measurement pattern and the number of used electrodes could increase the model performance. Experiments revealed that tree-based models present high performance, even better than Neural Networks, the most widely-used Machine Learning model to deal with EIT. Experiments also showed a model performance improvement when the EIT configuration was optimized. Most favorable metrics were attained using the tree-based Gradient Boosting model with a combination of both adjacent and mono measurement patterns as well as with 32 electrodes deployed during the tomographic process. With this particular setting, we achieved an accuracy of 99.14\% detecting internal artifacts and a Root Mean Square Error of 4.75 predicting internal conductivity distributions.},
  archive      = {J_NCA},
  author       = {Aller, Martín and Mera, David and Cotos, José Manuel. and Villaroya, Sebastián},
  doi          = {10.1007/s00521-022-07988-7},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5465-5477},
  shortjournal = {Neural Comput. Appl.},
  title        = {Study and comparison of different machine learning-based approaches to solve the inverse problem in electrical impedance tomographies},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable tourism volume forecasting with multivariate
time series under the impact of COVID-19. <em>NCA</em>, <em>35</em>(7),
5437–5463. (<a
href="https://doi.org/10.1007/s00521-022-07967-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel interpretable framework to forecast the daily tourism volume of Jiuzhaigou Valley, Huangshan Mountain, and Siguniang Mountain in China under the impact of COVID-19 by using multivariate time-series data, particularly historical tourism volume data, COVID-19 data, the Baidu index, and weather data. For the first time, epidemic-related search engine data is introduced for tourism demand forecasting. A new method named the composition leading search index–variational mode decomposition is proposed to process search engine data. Meanwhile, to overcome the problem of insufficient interpretability of existing tourism demand forecasting, a new model of DE-TFT interpretable tourism demand forecasting is proposed in this study, in which the hyperparameters of temporal fusion transformers (TFT) are optimized intelligently and efficiently based on the differential evolution algorithm. TFT is an attention-based deep learning model that combines high-performance forecasting with interpretable analysis of temporal dynamics, displaying excellent performance in forecasting research. The TFT model produces an interpretable tourism demand forecast output, including the importance ranking of different input variables and attention analysis at different time steps. Besides, the validity of the proposed forecasting framework is verified based on three cases. Interpretable experimental results show that the epidemic-related search engine data can well reflect the concerns of tourists about tourism during the COVID-19 epidemic.},
  archive      = {J_NCA},
  author       = {Wu, Binrong and Wang, Lin and Tao, Rui and Zeng, Yu-Rong},
  doi          = {10.1007/s00521-022-07967-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5437-5463},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interpretable tourism volume forecasting with multivariate time series under the impact of COVID-19},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerated computation of the genetic algorithm for
energy-efficient virtual machine placement in data centers.
<em>NCA</em>, <em>35</em>(7), 5421–5436. (<a
href="https://doi.org/10.1007/s00521-022-07941-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy efficiency is a critical issue in the management and operation of cloud data centers, which form the backbone of cloud computing. Virtual machine (VM) placement has a significant impact on energy-efficiency improvement for virtualized data centers. Among various methods to solve the VM-placement problem, the genetic algorithm (GA) has been well accepted for the quality of its solution. However, GA is also computationally demanding, particularly in the computation of its fitness function. This limits its application in large-scale systems or specific scenarios where a fast VM-placement solution of good quality is required. Our analysis in this paper reveals that the execution time of the standard GA is mostly consumed in the computation of its fitness function. Therefore, this paper designs a data structure extended from a previous study to reduce the complexity of the fitness computation from quadratic to linear one with respect to the input size of the VM-placement problem. Incorporating with this data structure, an alternative fitness function is proposed to reduce the number of instructions significantly, further improving the execution-time performance of GA. Experimental studies show that our approach achieves 11 times acceleration of GA computation for energy-efficient VM placement in large-scale data centers with about 1500 physical machines in size.},
  archive      = {J_NCA},
  author       = {Ding, Zhe and Tian, Yu-Chu and Wang, You-Gan and Zhang, Wei-Zhe and Yu, Zu-Guo},
  doi          = {10.1007/s00521-022-07941-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5421-5436},
  shortjournal = {Neural Comput. Appl.},
  title        = {Accelerated computation of the genetic algorithm for energy-efficient virtual machine placement in data centers},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MLaR: Machine-learning-assisted centralized link-state
routing in software-defined-based wireless networks. <em>NCA</em>,
<em>35</em>(7), 5409–5420. (<a
href="https://doi.org/10.1007/s00521-022-07993-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-defined networking (SDN) is a flexible networking paradigm that provides isolation of control and data planes from each other, proposes control mechanisms, network programmability and autonomy, and new tools for developing solutions to traditional network infrastructure problems such as latency, throughput, and packet loss losses. One of the most important critical issues that evaluated by SDN offers is the hardware and vendor-independent software for routing protocols in wireless communication. Therefore, using the SDN approach to run, manage and optimize routing algorithms efficiently has become one of the important topics. The SDN also makes it possible to use machine learning techniques for routing. In this study, a new machine learning-assisted routing (MLaR) algorithm is proposed for software-defined wireless networks. Through the trained model, this algorithm can make the most appropriate routing decision in real-time by using the historical network parameters of mobile nodes (latency, bandwidth, SNR, distance). This way, a learning the proposed routing algorithm that can adjust itself according to dynamic network conditions has been developed. The proposed MLaR algorithm is compared with the traditional Dijkstra algorithm in terms of delay and throughput ratio, and the MLaR gives more successful results. According to the simulation results, the proposed approach achieved 3.1 and 1.3 times improvement in delay and throughput, respectively, compared to the traditional Dijkstra.},
  archive      = {J_NCA},
  author       = {Cicioğlu, Murtaza and Çalhan, Ali},
  doi          = {10.1007/s00521-022-07993-w},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5409-5420},
  shortjournal = {Neural Comput. Appl.},
  title        = {MLaR: Machine-learning-assisted centralized link-state routing in software-defined-based wireless networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SBIR-BYOL: A self-supervised sketch-based image retrieval
model. <em>NCA</em>, <em>35</em>(7), 5395–5408. (<a
href="https://doi.org/10.1007/s00521-022-07978-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketch-based image retrieval is demanding interest in the computer vision community due to its relevance in the visual perception system and its potential application in a wide diversity of industries. In the literature, we observe significant advances when the models are evaluated in public datasets. However, when assessed in real environments, the performance drops drastically. The big problem is that the SOTA SBIR models follow a supervised regimen, strongly depending on a considerable amount of labeled sketch-photo pairs, which is unfeasible in real contexts. Therefore, we propose SBIR-BYOL, an extension of the well-known BYOL, to work in a bimodal scenario for sketch-based image retrieval. To this end, we also propose a two-stage self-supervised training methodology, exploiting existing sketch-photo pairs and contour-photo pairs generated from photographs of a target catalog. We demonstrate the benefits of our model for the eCommerce environments, where searching is a critical component. Here, our self-supervised SBIR model shows an increase of over $$60\%$$ of mAP.},
  archive      = {J_NCA},
  author       = {Saavedra, Jose M. and Morales, Javier and Murrugarra-Llerena, Nils},
  doi          = {10.1007/s00521-022-07978-9},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5395-5408},
  shortjournal = {Neural Comput. Appl.},
  title        = {SBIR-BYOL: A self-supervised sketch-based image retrieval model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy enhancement of routing protocol with hidden markov
model in wireless sensor networks. <em>NCA</em>, <em>35</em>(7),
5381–5393. (<a
href="https://doi.org/10.1007/s00521-022-07970-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy enhancement is a crucial factor while designing routing models in wireless sensor networks (WSNs). Many energy efficiency routing schemes are implemented to exchange various forms of gathered data by sensors in an optimal routing path through the network to increase its lifespan and maintain high scalability of the WSN. In this paper, a stochastic energy enhancement routing model is proposed to reduce the resource usage by nodes during the routing process. We aim to adapt the stochastic formalism based on the hidden Markov models (HMM) to learn from existing sensor networks, and design a new optimal routing mechanism that significantly exploits the available resources. Meanwhile, the proposed stochastic routing algorithm performs overall energy reduction in the network and permits optimal data transmission. The experimental results show that the proposed technique is efficient in terms of energy consumption, overall resource enhancement, and permits to increase network lifetime at least 19.05\% compared to other existing methods.},
  archive      = {J_NCA},
  author       = {Affane, Anselme R. and Satori, Hassan and Sanhaji, Farah and Boutazart, Yousssef and Satori, Khalid},
  doi          = {10.1007/s00521-022-07970-3},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5381-5393},
  shortjournal = {Neural Comput. Appl.},
  title        = {Energy enhancement of routing protocol with hidden markov model in wireless sensor networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complex scene video frames alignment and multi-frame fusion
deraining with deep neural network. <em>NCA</em>, <em>35</em>(7),
5369–5380. (<a
href="https://doi.org/10.1007/s00521-022-07963-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rainy is one of the most common weather. It is difficult to get clear and accurate background information when shooting outdoors in the rain. At the same time, these videos often have complex background depth and highly dynamic scenes. To address this problem, we propose a two-stage method for video deraining through adjacent frames alignment and multi-frame fusion. For adjacent frames, especially for large complex dynamic scenes, we combine optical flow and superpixel matching to achieve fine-grained alignment of scene content at the pixel level and semantic level. Optical flow is used to preprocess global frame alignment. Meanwhile, considering that the image scene depth range is large, we segment the target deraining image into smaller perceptual units superpixel (SP). It can better align the scene content of adjacent frames and the content details are well preserved. Aligned adjacent frames serve as input for subsequent fusion deraining. In the multi-frame fusion stage, a deep multi-frame fusion deraining neural network is designed, which uses the temporal and spatial information of multiple frames to compensate and restore the details of the target deraining images, and outputs clean images. Experiments show that our method can achieve good rain removal results. Visual inspection showed that rain was better eliminated. Extensive experiments on a series of synthetic and real videos with rain streaks verify the superiority of the proposed method over previous state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Su, Rui and Zhang, Lupeng and Zhang, Yuming and Xu, Fengqiang and Lu, Kun and Tong, Ning and Li, Fengqi},
  doi          = {10.1007/s00521-022-07963-2},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5369-5380},
  shortjournal = {Neural Comput. Appl.},
  title        = {Complex scene video frames alignment and multi-frame fusion deraining with deep neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty-guided joint unbalanced optimal transport for
unsupervised domain adaptation. <em>NCA</em>, <em>35</em>(7), 5351–5367.
(<a href="https://doi.org/10.1007/s00521-022-07976-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation aims to improve the performance of model generalization on unlabeled target domain by utilizing given labeled training samples from source domain. The optimal transport theory has been widely used to reduce domain discrepancy. However, most existing optimal transport-based approaches inevitably have the pair-wise mismatching problem during alignment of feature distributions. Besides, most current studies tend to focus on the improvement of prediction accuracy while ignoring the uncertainty estimation of noisy training samples, which is particularly important for the learning of transferrable model. To alleviate these issues, we propose a framework, Uncertainty-guided Joint Unbalanced Optimal Transport (UJUOT), which employs a feature uncertainty estimation (FUE) mechanism and an unbalanced optimal transport strategy. FUE encodes uncertainty by modeling each image embedding as a Gaussian distribution, improving representation space with better inter-class separability and intra-class compactness. It not only makes it easier for the domain alignment, but also lets the model more robust to noisy data. In addition, to reduce negative transfer, we design a novel unbalanced optimal transport (UOT) strategy to achieve precise pair-wise matching, which fully utilizes discriminative class-aware information to learn mass adaptively in order to determine best transport plan. To our best knowledge, this is a pioneering work of introducing data uncertainty to unsupervised domain adaptation. Extensive experiments on various standard datasets prove that our proposal can significantly improve transfer performance, outperforming state-of-the-art methods in many aspects.},
  archive      = {J_NCA},
  author       = {Dan, Jun and Jin, Tao and Chi, Hao and Dong, Shunjie and Shen, Yixuan},
  doi          = {10.1007/s00521-022-07976-x},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5351-5367},
  shortjournal = {Neural Comput. Appl.},
  title        = {Uncertainty-guided joint unbalanced optimal transport for unsupervised domain adaptation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised instance selection via conjectural
hyperrectangles. <em>NCA</em>, <em>35</em>(7), 5335–5349. (<a
href="https://doi.org/10.1007/s00521-022-07974-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms spend a lot of time processing data because they are not fast enough to commit huge data sets. Instance selection algorithms especially aim to tackle this trouble. However, even instance selection algorithms can suffer from it. We propose a new unsupervised instance selection algorithm based on conjectural hyper-rectangles. In this study, the proposed algorithm is compared with one conventional and four state-of-the-art instance selection algorithms by using fifty-five data sets from different domains. The experimental results demonstrate the supremacy of the proposed algorithm in terms of classification accuracy, reduction rate, and running time. The time and space complexities of the proposed algorithm are log-linear and linear, respectively. Furthermore, the proposed algorithm can obtain better results with an accuracy-reduction trade-off without decreasing reduction rates extremely. The source code of the proposed algorithm and the data sets are available at https://github.com/fatihaydin1/NIS for computational reproducibility.},
  archive      = {J_NCA},
  author       = {Aydin, Fatih},
  doi          = {10.1007/s00521-022-07974-z},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5335-5349},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsupervised instance selection via conjectural hyperrectangles},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal 3-dimension trajectory-tracking guidance for
reusable launch vehicle based on back-stepping adaptive dynamic
programming. <em>NCA</em>, <em>35</em>(7), 5319–5334. (<a
href="https://doi.org/10.1007/s00521-022-07972-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An optimal 3-dimension trajectory-tracking guidance method for Reusable Launch Vehicle (RLV) is proposed based on back-stepping Adaptive Dynamic Programming (ADP). The reference trajectory is generated based on the Gaussian pseudo-spectral method with sufficient saturation constraints on inputs. The reentry dynamics are normalized and modeled as position and velocity subsystems, based on which back-stepping approach is applied to derive the velocity virtual command which effectively reduces the position errors. A single-critic ADP structure is designed to achieve the optimal feedback control with an innovative weight iteration algorithm which reduces training computation, accelerates weights convergence and improves guidance accuracy. The proposed RLV guidance method is validated through the Monte Carlo simulations with initial errors, aerodynamic uncertainty and external disturbances. Comparable results with conventional guidance method based on Linear Quadratic Regulator (LQR) and weight iteration algorithm based on gradient decent demonstrate the advantages of the proposed guidance method.},
  archive      = {J_NCA},
  author       = {Wang, Xueyun and Quan, Zhiyuan and Zhang, Jingjuan},
  doi          = {10.1007/s00521-022-07972-1},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5319-5334},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal 3-dimension trajectory-tracking guidance for reusable launch vehicle based on back-stepping adaptive dynamic programming},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid PSO feature selection-based association
classification approach for breast cancer detection. <em>NCA</em>,
<em>35</em>(7), 5291–5317. (<a
href="https://doi.org/10.1007/s00521-022-07950-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the leading causes of death among women worldwide. Many methods have been proposed for automatic breast cancer diagnosis. One popular technique utilizes a classification-based association called Association Classification (AC). However, most AC algorithms suffer from considerable numbers of generated rules. In addition, irrelevant and redundant features may affect the measures used in the rule evaluation process. As such, they could severely affect the accuracy rates in rule mining. Feature selection identifies the optimal subset of features representing a problem in almost the same context as the original features. Feature selection is a critical preprocessing step for data mining as it tends to increase the prediction speed and accuracy of the classification model and thereby increase performance. In this research, an ensemble filter feature selection method and a wrapper feature selection algorithm in conjunction with the AC approach are proposed for undertaking breast cancer classification. The proposed approach employs optimal discriminative feature subsets for breast cancer prediction. Specifically, it first utilizes a new bootstrapping search strategy that effectively selects the most optimal feature subset that considers the overall weighted average of the relative frequency-based evaluation criteria function. We employ a Weighted Average of Relative Frequency (WARF)-based filter method to compute discriminative features from the ensemble results. The adopted filter algorithms utilize the prioritization ranking technique for selecting a subset of informative features that are used for subsequent AC-based disease classification. Another wrapper feature selection method, namely a hybrid Particle Swarm Optimization (PSO)-WARF filter-based wrapper method, is also proposed for feature selection. Two classification models, i.e., WARF-Predictive Classification Based on Associations (PCBA) and hybrid PSO-WARF-PCBA, are subsequently constructed based on the above filter and wrapper-based feature selection methods for breast cancer prediction. The proposed approach of the two models is evaluated using UCI breast cancer datasets. The empirical results indicate that our models achieve impressive performance and outperform a variety of well-known benchmark AC algorithms consistently for breast cancer diagnosis.},
  archive      = {J_NCA},
  author       = {Sowan, Bilal and Eshtay, Mohammed and Dahal, Keshav and Qattous, Hazem and Zhang, Li},
  doi          = {10.1007/s00521-022-07950-7},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5291-5317},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid PSO feature selection-based association classification approach for breast cancer detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Toward visual quality enhancement of dehazing effect with
improved cycle-GAN. <em>NCA</em>, <em>35</em>(7), 5277–5290. (<a
href="https://doi.org/10.1007/s00521-022-07964-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image dehazing is a fundamental problem in computer vision. However, GT images for supervised dehazing network training are virtually impossible to obtain in the real world. Therefore, unsupervised image dehazing is of great significance. In this paper, a Cycle Generative Adversarial Network (Cycle-GAN) based on the Homology Isomerism Discriminator (HID)-assisted Detail Generation Module (DGM) is proposed to achieve image dehazing under unsupervised training. In order to enable the generator to recover the details of the entire image, especially in images with complex structures, DGM is developed to boost the details performance of the output dehazing results. Then, HID is proposed to boost dehazing performance based on heterogeneous features and Channel-Spatial Attention (CSA) and complement DGM by varied guidance to the generator. Next, the loss functions are updated according to the image dehazing task based on Cycle-GAN under unsupervised learning. Finally, the experimental results under ablation study and comparison to state-of-the-art demonstrate that the proposed method has attractive results in both visual experience and quantitative metrics under various datasets.},
  archive      = {J_NCA},
  author       = {Liu, Xiaochen and Zhang, Tao and Zhang, Jiawei},
  doi          = {10.1007/s00521-022-07964-1},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5277-5290},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward visual quality enhancement of dehazing effect with improved cycle-GAN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy-based hunger games search algorithm for global
optimization and feature selection using medical data. <em>NCA</em>,
<em>35</em>(7), 5251–5275. (<a
href="https://doi.org/10.1007/s00521-022-07916-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is one of the basic data preprocessing steps in data mining and machine learning. It is used to reduce feature size and increase model generalization. In addition to minimizing feature dimensionality, it also enhances classification accuracy and reduces model complexity, which are essential in several applications. Traditional methods for feature selection often fail in the optimal global solution due to the large search space. Many hybrid techniques have been proposed depending on merging several search strategies which have been used individually as a solution to the FS problem. This study proposes a modified hunger games search algorithm (mHGS), for solving optimization and FS problems. The main advantages of the proposed mHGS are to resolve the following drawbacks that have been raised in the original HGS; (1) avoiding the local search, (2) solving the problem of premature convergence, and (3) balancing between the exploitation and exploration phases. The mHGS has been evaluated by using the IEEE Congress on Evolutionary Computation 2020 (CEC’20) for optimization test and ten medical and chemical datasets. The data have dimensions up to 20000 features or more. The results of the proposed algorithm have been compared to a variety of well-known optimization methods, including improved multi-operator differential evolution algorithm (IMODE), gravitational search algorithm, grey wolf optimization, Harris Hawks optimization, whale optimization algorithm, slime mould algorithm and hunger search games search. The experimental results suggest that the proposed mHGS can generate effective search results without increasing the computational cost and improving the convergence speed. It has also improved the SVM classification performance.},
  archive      = {J_NCA},
  author       = {Houssein, Essam H. and Hosney, Mosa E. and Mohamed, Waleed M. and Ali, Abdelmgeid A. and Younis, Eman M. G.},
  doi          = {10.1007/s00521-022-07916-9},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5251-5275},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy-based hunger games search algorithm for global optimization and feature selection using medical data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sustainability-based optimization of dissimilar friction
stir welding parameters in terms of energy saving, product quality, and
cost-effectiveness. <em>NCA</em>, <em>35</em>(7), 5221–5249. (<a
href="https://doi.org/10.1007/s00521-022-07898-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The friction stir welding (FSW) process is a prominent approach to fabricate high-quality welds for materials having low melting temperatures. Welding quality criteria have been extensively considered in former publications. The purpose of the current work is to optimize process parameters, including the tool rotational speed (N), travel speed (V), plunging depth (P), and tilting angle (A) for decreasing the energy consumption in the welding time (EW) and improving the ultimate tensile strength (UTS) as well as and percent elongation (PEL) for the FSW operation of dissimilar aluminum alloys. The adaptive neuro-based fuzzy inference system (ANFIS) approach is utilized to develop the FSW responses in terms of optimizing inputs, while a novel model is developed to compute the production cost (PC). The grey relational analysis (GRA) is applied to calculate the weight of each response. The vibration and communication particle swarm optimization (VCPSO) algorithm and combined compromise solution (CCS) are applied to produce feasible solutions and determine the best optimal point. The obtained outcomes presented that the optimum outcomes of the N, V, P, and A are 1500 RPM, 56 mm/min, 0.98 mm, and 2 deg., respectively, while the EW, UTS, and PEL are enhanced by 13.3\%, 7.4\%, and 55.7\% at the optimal solution. The optimal ANFIS models were trustworthy and ensure accurate predictions. The developed method using the ANFIS, VCPSO, and CCS could be effectively utilized to determine the optimal outcomes instead of the trial–error and/or human experience. The observed findings provided efficient information, which could help operators to select the optimal FSW parameters and enhance the welding responses.},
  archive      = {J_NCA},
  author       = {Nguyen, Trung-Thanh and Nguyen, Chung-Thai and Van, An-Le},
  doi          = {10.1007/s00521-022-07898-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5221-5249},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sustainability-based optimization of dissimilar friction stir welding parameters in terms of energy saving, product quality, and cost-effectiveness},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep spatiotemporal network for forecasting the risk of
traffic accidents in low-risk regions. <em>NCA</em>, <em>35</em>(7),
5207–5220. (<a
href="https://doi.org/10.1007/s00521-022-07971-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is admirably significant to forecast real-time traffic risks in the future, which protects people’s lives and improves the safety of the road. Most previous work uses the grid method to divide the entire city, which destroys the city’s inherent geospatial attributes and may lead to invalid prediction results. On the issue of sparse accidents, although previous studies have considered the imbalance in the number of accidents and normal events, the imbalance in the number of accidents between different regions caused by inner-city heterogeneity is ignored, resulting in unsatisfactory predictions for low-risk regions. Moreover, such a model is not suitable for citywide traffic accident prediction. To solve the above problems, firstly, we combine taxi division map, census track partition map and road network to divide the entire city, which retains the geographical spatial attributes, makes the regional division more reasonable and interpretable, and avoids the possible invalid prediction caused by grid method. Secondly, we propose the concept of double imbalance in traffic accident data, which is addressed by an improved cost-sensitive loss function, enabling the model to better predict accidents in low-risk regions. Finally, a deep spatiotemporal network that fuses local and global features (DSTFLG) based on a self-attention mechanism is proposed to forecast traffic accident risk. Extensive experiments on two real-world datasets demonstrate that the proposed framework improves the prediction accuracy over baseline approaches.},
  archive      = {J_NCA},
  author       = {Zheng, Junjie and Wang, Jing and Lai, Zhilin and Wang, Cheng and Zhang, Huizhen},
  doi          = {10.1007/s00521-022-07971-2},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5207-5220},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep spatiotemporal network for forecasting the risk of traffic accidents in low-risk regions},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of object boundary from point cloud by using
multi-population based differential evolution algorithm. <em>NCA</em>,
<em>35</em>(7), 5193–5206. (<a
href="https://doi.org/10.1007/s00521-022-07969-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem-solving success of an Evolutionary Computing algorithm is too sensitive to the structures of mutation and crossover operators it uses. The mutation operator generates the trial vectors necessary for the relevant Evolutionary Computing method to perform efficient global and local search in the search space. Partial elitist mutation operators can produce more efficient trial vectors than isotropic mutation strategies. Another numerical genetic operator that affects the process of producing efficient trial vectors is crossover. Due to the dominant effect of the Evolutionary Computing algorithms of mutation and crossover operators on problem solving capacity, new numerical-genetic operators are constantly being developed. When solving a problem with the Differential Evolution Algorithm determining the ideal mutation operator and setting the initial values of the internal parameters of the crossover operator is quite time-consuming and difficult. In this paper, the Multi-population Based Differential Evolution Algorithm (MDE) has been proposed to solve real-valued numerical optimization problems with its convergence proof. The mutation operator of MDE is partial—elitist and its crossover operator is parameter-free, in practice. In this paper, 28 benchmark problems of CEC2013 with Dim = 20 and one real-world geometric optimization problem have been used in the experiments performed to examine the numerical problem-solving success of MDE. MDE&#39;s success in solving related benchmark problems has been statistically compared with ABC, CK, SOS and GWO. Statistical analysis of the results obtained from the experiments exposed that MDE is statistically more successful than comparison methods in solving numerical optimization problems used.},
  archive      = {J_NCA},
  author       = {Karkinli, Ahmet Emin},
  doi          = {10.1007/s00521-022-07969-w},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5193-5206},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of object boundary from point cloud by using multi-population based differential evolution algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Human activity recognition from sensor data using spatial
attention-aided CNN with genetic algorithm. <em>NCA</em>,
<em>35</em>(7), 5165–5191. (<a
href="https://doi.org/10.1007/s00521-022-07911-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing time and frequency relationships of time series signals offers an inherent barrier for automatic human activity recognition (HAR) from wearable sensor data. Extracting spatiotemporal context from the feature space of the sensor reading sequence is challenging for the current recurrent, convolutional, or hybrid activity recognition models. The overall classification accuracy also gets affected by large size feature maps that these models generate. To this end, in this work, we have put forth a hybrid architecture for wearable sensor data-based HAR. We initially use Continuous Wavelet Transform to encode the time series of sensor data as multi-channel images. Then, we utilize a Spatial Attention-aided Convolutional Neural Network (CNN) to extract higher-dimensional features. To find the most essential features for recognizing human activities, we develop a novel feature selection (FS) method. In order to identify the fitness of the features for the FS, we first employ three filter-based methods: Mutual Information (MI), Relief-F, and minimum redundancy maximum relevance (mRMR). The best set of features is then chosen by removing the lower-ranked features using a modified version of the Genetic Algorithm (GA). The K-Nearest Neighbors (KNN) classifier is then used to categorize human activities. We conduct comprehensive experiments on five well-known, publicly accessible HAR datasets, namely UCI-HAR, WISDM, MHEALTH, PAMAP2, and HHAR. Our model significantly outperforms the state-of-the-art models in terms of classification performance. We also observe an improvement in overall recognition accuracy with the use of GA-based FS technique with a lower number of features. The source code of the paper is publicly available here https://github.com/apusarkar2195/HAR_WaveletTransform_SpatialAttention_FeatureSelection .},
  archive      = {J_NCA},
  author       = {Sarkar, Apu and Hossain, S. K. Sabbir and Sarkar, Ram},
  doi          = {10.1007/s00521-022-07911-0},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5165-5191},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human activity recognition from sensor data using spatial attention-aided CNN with genetic algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Research on diversity and accuracy of the recommendation
system based on multi-objective optimization. <em>NCA</em>,
<em>35</em>(7), 5155–5163. (<a
href="https://doi.org/10.1007/s00521-020-05438-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the information industry and the Internet develop rapidly, the use of big data enters people&#39;s vision and attracts attention. It makes the recommendation system come into being how to quickly extract the desired information from the excessive information. In the recommendation system, user-based collaborative filtering algorithm has become a research hotspot. Existing researches focus on improving collaborative filtering recommendation algorithm by using the kernel method, but still face the cold start problem, the diversity problem, the data sparsity problem, the concept drift problem and more others. To solve these problems, this paper proposes the user-based collaborative filtering based on kernel method and multi-objective optimization (MO-KUCF) which introduces kernel density estimation and multi-objective optimization. It can be increasing diversity of the recommendation systems, improving concept drift in dynamic data and the accuracy and diversity of the recommendation system. The dataset used in this article is the Netflix dataset. It analyzes the MO-KUCF algorithm with the user-based collaborative filtering (UCF) and user-based collaborative filtering based on kernel method (KUCF) by the mean absolute error (MAE). The MAE is compared with the internal user diversity $$I_{{\text{u}}}$$ index, and the pre-processed data set is divided into the training set and the test set, which are provided to the recommendation system for recommendation and evaluation. The results show that the accuracy of MO-KUCF improves by 5.6\%, and the diversity also increases with decreasing values. Combining multi-objective optimization techniques with kernel density estimation methods can improve the diversity of recommendation systems effectively and solve the concept drift problem to achieve the purpose of improving system accuracy.},
  archive      = {J_NCA},
  author       = {Ma, Tie-min and Wang, Xue and Zhou, Fu-cai and Wang, Shuang},
  doi          = {10.1007/s00521-020-05438-w},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5155-5163},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on diversity and accuracy of the recommendation system based on multi-objective optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced balancing GAN: Minority-class image generation.
<em>NCA</em>, <em>35</em>(7), 5145–5154. (<a
href="https://doi.org/10.1007/s00521-021-06163-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) are one of the most powerful generative models, but always require a large and balanced dataset to train. Traditional GANs are not applicable to generate minority-class images in a highly imbalanced dataset. Balancing GAN (BAGAN) is proposed to mitigate this problem, but it is unstable when images in different classes look similar, e.g., flowers and cells. In this work, we propose a supervised autoencoder with an intermediate embedding model to disperse the labeled latent vectors. With the enhanced autoencoder initialization, we also build an architecture of BAGAN with gradient penalty (BAGAN-GP). Our proposed model overcomes the unstable issue in original BAGAN and converges faster to high-quality generations. Our model achieves high performance on the imbalanced scale-down version of MNIST Fashion, CIFAR-10, and one small-scale medical image dataset. https://github.com/GH920/improved-bagan-gp.},
  archive      = {J_NCA},
  author       = {Huang, Gaofeng and Jafari, Amir Hossein},
  doi          = {10.1007/s00521-021-06163-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5145-5154},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced balancing GAN: Minority-class image generation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic review of machine learning techniques for
stance detection and its applications. <em>NCA</em>, <em>35</em>(7),
5113–5144. (<a
href="https://doi.org/10.1007/s00521-023-08285-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stance detection is an evolving opinion mining research area motivated by the vast increase in the variety and volume of user-generated content. In this regard, considerable research has been recently carried out in the area of stance detection. In this study, we review the different techniques proposed in the literature for stance detection as well as other applications such as rumor veracity detection. Particularly, we conducted a systematic literature review of empirical research on the machine learning (ML) models for stance detection that were published from January 2015 to October 2022. We analyzed 96 primary studies, which spanned eight categories of ML techniques. In this paper, we categorize the analyzed studies according to a taxonomy of six dimensions: approaches, target dependency, applications, modeling, language, and resources. We further classify and analyze the corresponding techniques from each dimension’s perspective and highlight their strengths and weaknesses. The analysis reveals that deep learning models that adopt a mechanism of self-attention have been used more frequently than the other approaches. It is worth noting that emerging ML techniques such as few-shot learning and multitask learning have been used extensively for stance detection. A major conclusion of our analysis is that despite that ML models have shown to be promising in this field, the application of these models in the real world is still limited. Our analysis lists challenges and gaps to be addressed in future research. Furthermore, the taxonomy presented can assist researchers in developing and positioning new techniques for stance detection-related applications.},
  archive      = {J_NCA},
  author       = {Alturayeif, Nora and Luqman, Hamzah and Ahmed, Moataz},
  doi          = {10.1007/s00521-023-08285-7},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5113-5144},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic review of machine learning techniques for stance detection and its applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy min–max neural networks: A bibliometric and social
network analysis. <em>NCA</em>, <em>35</em>(7), 5081–5111. (<a
href="https://doi.org/10.1007/s00521-023-08267-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The amount of digital data in the universe is growing at an exponential rate with the rapid development of digital information, and this reveals new machine learning methods. Learning algorithms using hyperboxes are a subsection of machine learning methods. Fuzzy min–max neural network (FMNN) are one of the most common and advanced methods using hyperboxes. FMNN is a special type of NeuroFuzzy system that combines the artificial neural network and fuzzy set into a common framework. This paper conducts an extensive bibliometric and network analysis of FMNN literature. Two hundred and sixty-two publications are analysed from the period of 1992–2022. Several analyses are realized in order to identify trends, challenges and key points in a more scientific and objective way that affect the development of knowledge in the FMNN domain. It can be seen from bibliometric analysis that there is rapid development in the last 10 years. Social network analysis results show that Chee Peng Lim is the most active author in the network. Besides, the modifications of FMNN are generally developed for classification. However, there are still potential future research opportunities for clustering.},
  archive      = {J_NCA},
  author       = {Kenger, Ömer Nedim and Özceylan, Eren},
  doi          = {10.1007/s00521-023-08267-9},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5081-5111},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy min–max neural networks: A bibliometric and social network analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning and smart card based two-factor
authentication scheme for preserving anonymity in telecare medical
information system (TMIS). <em>NCA</em>, <em>35</em>(7), 5055–5080. (<a
href="https://doi.org/10.1007/s00521-021-06152-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telecare medical information system (TMIS) is used to connect patients and doctors who are at a different location from each other. The authentication of the user and system is very crucial as the medical data of the user is stored on the server. Many systems have been developed in order to achieve this goal. We show some vulnerabilities of existing systems in this paper. We then propose a secure authentication mechanism to achieve the same goal. Machine learning and the nonce-based system is used for authentication of the entity and to prove the freshness of transmitted messages. Smart card blocking mechanisms have been included in each phase of the proposed system to prevent unauthorized access of data. The proposed system has been evaluated formally with the AVISPA tool. Then the proposed model has also been checked against different attacks and evaluated for different functionalities. We provide relative analysis with some recently proposed models and show our proposed system is relatively more efficient and secure.},
  archive      = {J_NCA},
  author       = {Gupta, B. B. and Prajapati, Varun and Nedjah, Nadia and Vijayakumar, P. and El-Latif, Ahmed A. Abd and Chang, Xiaojun},
  doi          = {10.1007/s00521-021-06152-x},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5055-5080},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning and smart card based two-factor authentication scheme for preserving anonymity in telecare medical information system (TMIS)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A conceptual framework for blockchain smart contract
adoption to manage real estate deals in smart cities. <em>NCA</em>,
<em>35</em>(7), 5033–5054. (<a
href="https://doi.org/10.1007/s00521-021-05800-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchains-based smart contracts are disrupting the smart real estate sector of the smart cities. The current study explores the literature focused on blockchain smart contracts in smart real estate and proposes a conceptual framework for its adoption in smart cities. Based on a systematic review method, the literature published between 2000 and 2020 is explored and analyzed. From the literature, ten key aspects of the blockchain smart contracts are highlighted that are grouped into six layers for adopting the smart contracts in smart real estate. The decentralized application and its interactions with Ethereum Virtual Machine (EVM) are presented to show the development of a smart contract that can be used for blockchain smart contracts in real estate. Further, a detailed design and interaction mechanism are highlighted for the real estate owners and users as parties to a smart contract. A list of functions for initiating, creating, modifying, or terminating a smart contract is presented along with a stepwise procedure for establishing and terminating smart contracts. The current study can help the users enjoy a more immersive, user-friendly, and visualized contracting process, whereas the owners, property technologies (Proptech) companies, and real estate agents can enjoy more business and sales. This can help disrupt traditional real estate and transform it into smart real estate in line with industry 4.0 requirements.},
  archive      = {J_NCA},
  author       = {Ullah, Fahim and Al-Turjman, Fadi},
  doi          = {10.1007/s00521-021-05800-6},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5033-5054},
  shortjournal = {Neural Comput. Appl.},
  title        = {A conceptual framework for blockchain smart contract adoption to manage real estate deals in smart cities},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DCU-net: A dual-channel u-shaped network for image splicing
forgery detection. <em>NCA</em>, <em>35</em>(7), 5015–5031. (<a
href="https://doi.org/10.1007/s00521-021-06329-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and location of image splicing forgery are a challenging task in the field of image forensics. It is to study whether an image contains a suspicious tampered area pasted from another image. In this paper, we propose a new image tamper location method based on dual-channel U-Net, that is, DCU-Net. The detection framework based on DCU-Net is mainly divided into three parts: encoder, feature fusion, and decoder. Firstly, high-pass filters are used to extract the residual of the tampered image and generate the residual image, which contains the edge information of the tampered area. Secondly, a dual-channel encoding network model is constructed. The input of the model is the original tampered image and the tampered residual image. Then, the deep features extracted from the dual-channel encoding network are fused for the first time, and then the tampered features with different granularity are extracted by dilation convolution, and then, the secondary fusion is carried out. Finally, the fused feature map is input into the decoder, and the predicted image is decoded layer by layer. The experimental results on Casia2.0 and Columbia datasets show that DCU-Net performs better than the latest algorithm and can accurately locate tampered areas. In addition, the attack experiments show that DCU-Net model has good robustness and can resist noise and JPEG recompression attacks.},
  archive      = {J_NCA},
  author       = {Ding, Hongwei and Chen, Leiyang and Tao, Qi and Fu, Zhongwang and Dong, Liang and Cui, Xiaohui},
  doi          = {10.1007/s00521-021-06329-4},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {5015-5031},
  shortjournal = {Neural Comput. Appl.},
  title        = {DCU-net: A dual-channel U-shaped network for image splicing forgery detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective NIDS framework based on a comprehensive survey
of feature optimization and classification techniques. <em>NCA</em>,
<em>35</em>(7), 4993–5013. (<a
href="https://doi.org/10.1007/s00521-021-06093-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technological advancement leads to an increase in the usage of the Internet with many applications and connected devices. This increased network size causes increased complexity and creating rooms for the attackers to explore and exploit vulnerabilities to carry out various attacks. As a result upsurge of network attacks can be realized in recent years and is diversified, which can be affirmed by the admittance of various organizations. Varieties of intrusion detection systems (IDSs) have been designed and proposed to tackle such issues based on the misuse-based, anomaly based, and sometimes hybrid techniques. The high rate of network data generation and its enormous volume makes it challenging for IDSs to maintain their efficacy and reliability. This paper discusses a comprehensive understanding of IDS types, six benchmark network datasets, high distributed dimensionality reduction techniques, and classification approaches based on machine learning and deep learning for intrusion detection with their importance to ascertain the efficacy and reliability of IDSs. Furthermore, based on the literature review, a general framework for NIDS has been proposed. At last model for network IDS (NIDS) is designed by following the proposed framework. Achieved accuracy and detection rate of the proposed NIDS model on the UNSW-NB15 dataset are 98.11\% and 97.81\%, respectively, and achieving better performance than other approaches comparatively.},
  archive      = {J_NCA},
  author       = {Keserwani, Pankaj Kumar and Govil, Mahesh Chandra and Pilli, Emmanuel S.},
  doi          = {10.1007/s00521-021-06093-5},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4993-5013},
  shortjournal = {Neural Comput. Appl.},
  title        = {An effective NIDS framework based on a comprehensive survey of feature optimization and classification techniques},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DSmishSMS-a system to detect smishing SMS. <em>NCA</em>,
<em>35</em>(7), 4975–4992. (<a
href="https://doi.org/10.1007/s00521-021-06305-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the origin of smart homes, smart cities, and smart everything, smart phones came up as an area of magnificent growth and development. These devices became a part of daily activities of human life. This impact and growth have made these devices more vulnerable to attacks than other devices such as desktops or laptops. Text messages or SMS (Short Text Messages) are a part of smartphones through which attackers target the users. Smishing (SMS Phishing) is an attack targeting smartphone users through the medium of text messages. Though smishing is a type of phishing, it is different from phishing in many aspects like the amount of information available in the SMS, the strategy of attack, etc. Thus, detection of smishing is a challenge in the context of the minimum amount of information shared by the attacker. In the case of smishing, we have short text messages which are often in short forms or in symbolic forms. A single text message contains very few smishing-related features, and it consists of abbreviations and idioms which makes smishing detection more difficult. Detection of smishing is a challenge not only because of features constraint but also due to the scarcity of real smishing datasets. To differentiate spam messages from smishing messages, we are evaluating the legitimacy of the URL (Uniform Resource Locator) in the message. We have extracted the five most efficient features from the text messages to enable the machine learning classification using a limited number of features. In this paper, we have presented a smishing detection model comprising of two phases, Domain Checking Phase and SMS Classification Phase. We have examined the authenticity of the URL in the SMS which is a crucial part of SMS phishing detection. In our system, Domain Checking Phase scrutinizes the authenticity of the URL. SMS Classification Phase examines the text contents of the messages and extracts some efficient features. Finally, the system classifies the messages using Backpropagation Algorithm and compares results with three traditional classifiers. A prototype of the system has been developed and evaluated using SMS datasets. The results of the evaluation achieved an accuracy of 97.93\% which shows the proposed method is very efficient for the detection of smishing messages.},
  archive      = {J_NCA},
  author       = {Mishra, Sandhya and Soni, Devpriya},
  doi          = {10.1007/s00521-021-06305-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4975-4992},
  shortjournal = {Neural Comput. Appl.},
  title        = {DSmishSMS-A system to detect smishing SMS},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid DNN–LSTM model for detecting phishing URLs.
<em>NCA</em>, <em>35</em>(7), 4957–4973. (<a
href="https://doi.org/10.1007/s00521-021-06401-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phishing is an attack targeting to imitate the official websites of corporations such as banks, e-commerce, financial institutions, and governmental institutions. Phishing websites aim to access and retrieve users’ important information such as personal identification, social security number, password, e-mail, credit card, and other account information. Several anti-phishing techniques have been developed to cope with the increasing number of phishing attacks so far. Machine learning and particularly, deep learning algorithms are nowadays the most crucial techniques used to detect and prevent phishing attacks because of their strong learning abilities on massive datasets and their state-of-the-art results in many classification problems. Previously, two types of feature extraction techniques [i.e., character embedding-based and manual natural language processing (NLP) feature extraction] were used in isolation. However, researchers did not consolidate these features and therefore, the performance was not remarkable. Unlike previous works, our study presented an approach that utilizes both feature extraction techniques. We discussed how to combine these feature extraction techniques to fully utilize from the available data. This paper proposes hybrid deep learning models based on long short-term memory and deep neural network algorithms for detecting phishing uniform resource locator and evaluates the performance of the models on phishing datasets. The proposed hybrid deep learning models utilize both character embedding and NLP features, thereby simultaneously exploiting deep connections between characters and revealing NLP-based high-level connections. Experimental results showed that the proposed models achieve superior performance than the other phishing detection models in terms of accuracy metric.},
  archive      = {J_NCA},
  author       = {Ozcan, Alper and Catal, Cagatay and Donmez, Emrah and Senturk, Behcet},
  doi          = {10.1007/s00521-021-06401-z},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4957-4973},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid DNN–LSTM model for detecting phishing URLs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Off-line signature verification using elementary
combinations of directional codes from boundary pixels. <em>NCA</em>,
<em>35</em>(7), 4939–4956. (<a
href="https://doi.org/10.1007/s00521-021-05854-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Verifying the genuineness of official documents, such as bank checks, certificates, contract forms, bonds, etc., remains a challenging task when it comes to accuracy and robustness. Here, the genuineness is related to the degree of match of the signature contained in the documents relating to the original signatures of the authorized person. Signatures of authorized persons are considered known in advance. In this paper, a novel feature set is introduced based on quasi-straightness of boundary pixel runs for signature verification. We extract the quasi-straight line segments using elementary combinations of the directional codes from the signature boundary pixels and subsequently we obtain the feature set from various quasi-straight line classes. The quasi-straight line segments provide a blending of straightness and small curvatures resulting in a robust feature set for the verification of signatures. We have used Support Vector Machine (SVM) for classification and have shown results on standard signature datasets like CEDAR (Center of Excellence for Document Analysis and Recognition) and GPDS-100 (Grupo de Procesado Digital de la Senal). The results establish how the proposed method outperforms the existing state of the art.},
  archive      = {J_NCA},
  author       = {Ajij, Md and Pratihar, Sanjoy and Nayak, Soumya Ranjan and Hanne, Thomas and Roy, Diptendu Sinha},
  doi          = {10.1007/s00521-021-05854-6},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4939-4956},
  shortjournal = {Neural Comput. Appl.},
  title        = {Off-line signature verification using elementary combinations of directional codes from boundary pixels},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A secure and robust color image watermarking using
nature-inspired intelligence. <em>NCA</em>, <em>35</em>(7), 4919–4937.
(<a href="https://doi.org/10.1007/s00521-020-05634-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The security of multimedia information is a prime concern in the present digital world. As a remedy, a robust color image watermarking in the transform domain using artificial intelligence is reported in this article. A color host image is secured by embedding a color watermark by utilizing the singular value decomposition and discrete wavelet transform. The color watermark information is scrambled with a chaotic map to give an additional stage of protection to overcome the problem of illegal copying and alteration of digital data by unauthorized users. All three RGB color channels of host singular values are modified with principal components of respective RGB information of scrambled watermark image. Ownership of data is provided by extracting the watermark in the presence of a secret key used while embedding process. To overcome the trade-off between the imperceptibility and robustness of the proposed algorithm artificial bee colony is used to optimize the scaling factor. The implementation of the proposed algorithm is performed on the MATLAB tool to compute the performance against the intentional and non-intentional image processing attacks. Comparative analysis with other related watermarking algorithms proves the robust, secure, and invisible nature of the proposed watermarking scheme.},
  archive      = {J_NCA},
  author       = {Sharma, Sourabh and Sharma, Harish and Sharma, Janki Ballabh and Poonia, Ramesh Chandra},
  doi          = {10.1007/s00521-020-05634-8},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4919-4937},
  shortjournal = {Neural Comput. Appl.},
  title        = {A secure and robust color image watermarking using nature-inspired intelligence},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel permission-based android malware detection system
using feature selection based on linear regression. <em>NCA</em>,
<em>35</em>(7), 4903–4918. (<a
href="https://doi.org/10.1007/s00521-021-05875-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the developments in mobile and wireless technology, mobile devices have become an important part of our lives. While Android is the leading operating system in market share, it is the platform most targeted by attackers. Although many solutions have been proposed in the literature for the detection of Android malware, there is still a need for attribute selection methods to be used in Android malware detection systems. In this study, a machine learning-based malware detection system is proposed to distinguish Android malware from benign applications. At the feature selection stage of the proposed malware detection system, it is aimed to remove unnecessary features by using a linear regression-based feature selection approach. In this way, the dimension of the feature vector is reduced, the training time is decreased, and the classification model can be used in real-time malware detection systems. When the results of the study are examined, the highest 0.961 is obtained according to the F-measure metric by using at least 27 features.},
  archive      = {J_NCA},
  author       = {Şahin, Durmuş Özkan and Kural, Oğuz Emre and Akleylek, Sedat and Kılıç, Erdal},
  doi          = {10.1007/s00521-021-05875-1},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4903-4918},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel permission-based android malware detection system using feature selection based on linear regression},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Key moment extraction for designing an agglomerative
clustering algorithm-based video summarization framework. <em>NCA</em>,
<em>35</em>(7), 4881–4902. (<a
href="https://doi.org/10.1007/s00521-021-06132-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video summarization is the process of refining the original video into a more concise form without losing valuable information. Both efficient storage and extraction of valuable information from a video are the challenging tasks in video analysis. Intelligent video surveillance system has an essential role for ensuring safety and security to the public. Recent intelligent technologies are extensively using the surveillance systems in all areas starting from border security application to street monitoring systems. Now the surveillance camera or motion sensitivity-based cameras produce large volume of data when employed for recording videos. As analysis of videos by humans demands immense manpower, automatic video summarization is an important and growing research topic. Hence, it is necessary to summarize the activities in the scene and eliminate unusual and redundant events recorded in videos. The proposed work has developed a video summarization framework using key moment-based frame selection and clustering of frames to identify only informative frames. The key moment is a simple yet effective characteristic for summarizing a long video shot and motion is the most salient feature in presenting actions or events in video which is used here to extract the key moments of the video frames. The motion is the scene of a video frame which has the most acceleration and deceleration in case of the key moments. Based on the extracted key moments, the frames of the video are partitioned into different groups using a novel similarity-based agglomerative clustering algorithm. The algorithm determines at most K clusters of frames based on Jaccard similarity among the clusters, where K is the user defined parameter set as the 5\% to 15\% of the size of the video to be summarized. From each cluster, few representative frames are identified based on the centroids of the clusters and arranged according to their original video sequence to generate the summary of the video. The proposed clustering algorithm and the summarization method are evaluated using state-of-the-art video datasets and compared with some related methodologies to demonstrate their effectiveness.},
  archive      = {J_NCA},
  author       = {Yasmin, Ghazaala and Chowdhury, Sujit and Nayak, Janmenjoy and Das, Priyanka and Das, Asit Kumar},
  doi          = {10.1007/s00521-021-06132-1},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4881-4902},
  shortjournal = {Neural Comput. Appl.},
  title        = {Key moment extraction for designing an agglomerative clustering algorithm-based video summarization framework},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Secure and efficient image retrieval through invariant
features selection in insecure cloud environments. <em>NCA</em>,
<em>35</em>(7), 4855–4880. (<a
href="https://doi.org/10.1007/s00521-021-06054-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in computer vision technologies lead to a renewed focus on content-based image retrieval (CBIR) in computer multimedia content analysis applications. CBIR is a technique for image retrieval using automatically derived features. As the size of image repositories grew, supported by increased cloud storage adoption, security concern around trust in cloud service provider (CSP) witnessed a resurgence of interest in user privacy. Hence, unlike in traditional CBIR, cloud-based image retrieval is based on the encrypted feature vector. This may reduce the overall retrieval performance of the system. Consequently, mechanisms are needed to protect the feature vector and the actual images during transmission. Second, to provide image content security, images are often encrypted by users before uploading to the cloud. This article addresses the challenges of retrieving images securely from an untrusted cloud environment. Images are represented in terms of their local invariant features to form an image feature vector. Later, an asymmetric scalar-product-preserving encryption (ASPE) is applied to secure the feature vector. Then, images are encrypted before they are uploaded to a cloud server. The proposed method has been tested on various Corel image datasets and the medical image repository. Performance evaluation shows that the proposed method outperforms its best secure CBIR systems in the literature.},
  archive      = {J_NCA},
  author       = {Kumar, Sumit and Pal, Arup Kumar and Islam, SK Hafizul and Hammoudeh, Mohammad},
  doi          = {10.1007/s00521-021-06054-y},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4855-4880},
  shortjournal = {Neural Comput. Appl.},
  title        = {Secure and efficient image retrieval through invariant features selection in insecure cloud environments},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep-learning-based data-manipulation attack resilient
supervisory backup protection of transmission lines. <em>NCA</em>,
<em>35</em>(7), 4835–4854. (<a
href="https://doi.org/10.1007/s00521-021-06106-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-attacks on smart-grid systems have become increasingly more complicated, and there is a need for taking detection and mitigation measures to combat their adverse effects on the smart-grid infrastructure. Wide area measurement system (WAMS) infrastructure comprising of phasor measurement units (PMUs) has recently shown remarkable progress in solving complex power system problems and avoiding blackouts. However, WAMS is vulnerable to cyber-attacks. This paper presents a novel cyber-attack resilient WAMS framework incorporating both attack detection and mitigation modules that ensure the resiliency of PMU data-based supervisory protection applications. It includes deep learning-based Long Short Term Memory (LSTM) model for real-time detection of anomalies in time-series PMU measurements and isolating the compromised PMUs followed by Generative Adversarial Imputation Nets (GAIN) for the reconstruction of the compromised PMU’s data. The corrected PDC data-stream is then forwarded to the decision-making end application, making it resilient against attacks. A Random Forrest classifier is used in the end application to distinguish fault events from other disturbances and supervise the third zone of distance relay for backup protection of transmission lines. The efficacy of the proposed framework for different attack scenarios has been verified on the WSCC 9-Bus System modeled on a developed real-time digital simulator (RTDS)-based integrated cyber-physical WAMS testbed. Experimental analysis shows that the proposed model successfully detects and mitigates attacks’ adverse effects on the end application.},
  archive      = {J_NCA},
  author       = {Chawla, Astha and Agrawal, Prakhar and Panigrahi, Bijaya Ketan and Paul, Kolin},
  doi          = {10.1007/s00521-021-06106-3},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4835-4854},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep-learning-based data-manipulation attack resilient supervisory backup protection of transmission lines},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). APAE: An IoT intrusion detection system using asymmetric
parallel auto-encoder. <em>NCA</em>, <em>35</em>(7), 4813–4833. (<a
href="https://doi.org/10.1007/s00521-021-06011-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the world has dramatically moved toward using the internet of things (IoT), and the IoT has become a hot research field. Among various aspects of IoT, real-time cyber-threat protection is one of the most crucial elements due to the increasing number of cyber-attacks. However, current IoT devices often offer minimal security features and are vulnerable to cyber-attacks. Therefore, it is crucial to develop tools to detect such attacks in real time. This paper presents a new and intelligent network intrusion detection system named APAE that is based on an asymmetric parallel auto-encoder and is able to detect various attacks in IoT networks. The encoder part of APAE has a lightweight architecture that contains two encoders in parallel, each one having three successive layers of convolutional filters. The first encoder is for extracting local features using standard convolutional layers and a positional attention module. The second encoder also extracts the long-range information using dilated convolutional layers and a channel attention module. The decoder part of APAE is different from its encoder and has eight successive transposed convolution layers. The proposed APAE approach has a lightweight and suitable architecture for real-time attack detection and provides very good generalization performance even after training using very limited training records. The efficacy of the APAE has been evaluated using three popular public datasets named UNSW-NB15, CICIDS2017, and KDDCup99, and the results showed the superiority of the proposed model over the state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Basati, Amir and Faghih, Mohammad Mehdi},
  doi          = {10.1007/s00521-021-06011-9},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4813-4833},
  shortjournal = {Neural Comput. Appl.},
  title        = {APAE: An IoT intrusion detection system using asymmetric parallel auto-encoder},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on machine learning for security and privacy:
Advancing the state-of-the-art applications. <em>NCA</em>,
<em>35</em>(7), 4809–4812. (<a
href="https://doi.org/10.1007/s00521-022-08183-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Nayak, Janmenjoy and Al-Dabass, David and Pelusi, Danilo and Mishra, Manohar},
  doi          = {10.1007/s00521-022-08183-4},
  journal      = {Neural Computing and Applications},
  number       = {7},
  pages        = {4809-4812},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on machine learning for security and privacy: Advancing the state-of-the-art applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Product modeling design based on genetic
algorithm and BP neural network. <em>NCA</em>, <em>35</em>(6), 4807. (<a
href="https://doi.org/10.1007/s00521-022-08196-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Han, Jia-Xuan and Ma, Min-Yuan and Wang, Kun},
  doi          = {10.1007/s00521-022-08196-z},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4807},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Product modeling design based on genetic algorithm and BP neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: 5G network-oriented machine learning and
national forest park ecotourism management. <em>NCA</em>,
<em>35</em>(6), 4805. (<a
href="https://doi.org/10.1007/s00521-022-08195-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yue, Yin},
  doi          = {10.1007/s00521-022-08195-0},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4805},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: 5G network-oriented machine learning and national forest park ecotourism management},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Design and implementation of bank CRM
system based on decision tree algorithm. <em>NCA</em>, <em>35</em>(6),
4803. (<a href="https://doi.org/10.1007/s00521-022-08194-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Chen, Caixia and Geng, Liwei and Zhou, Sheng},
  doi          = {10.1007/s00521-022-08194-1},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4803},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Design and implementation of bank CRM system based on decision tree algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Analyzing genetic diseases using multimedia
processing techniques associative decision tree-based learning and
hopfield dynamic neural networks from medical images. <em>NCA</em>,
<em>35</em>(6), 4801. (<a
href="https://doi.org/10.1007/s00521-022-08192-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Al-Maitah, Mohammed},
  doi          = {10.1007/s00521-022-08192-3},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4801},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Analyzing genetic diseases using multimedia processing techniques associative decision tree-based learning and hopfield dynamic neural networks from medical images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Research on control strategy and policy
optimal scheduling based on an improved genetic algorithm. <em>NCA</em>,
<em>35</em>(6), 4799. (<a
href="https://doi.org/10.1007/s00521-022-08191-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Xia, Jing and Yan, Yongcai and Ji, Lei},
  doi          = {10.1007/s00521-022-08191-4},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4799},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Research on control strategy and policy optimal scheduling based on an improved genetic algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Enrichment of accurate software effort
estimation using fuzzy-based function point analysis in business data
analytics. <em>NCA</em>, <em>35</em>(6), 4797. (<a
href="https://doi.org/10.1007/s00521-022-08159-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Vijay, J. Frank},
  doi          = {10.1007/s00521-022-08159-4},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4797},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Enrichment of accurate software effort estimation using fuzzy-based function point analysis in business data analytics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Comparative analysis of time series model
and machine testing systems for crime forecasting. <em>NCA</em>,
<em>35</em>(6), 4795. (<a
href="https://doi.org/10.1007/s00521-022-08158-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Jha, Sudan and Yang, Eunmok and Almagrabi, Alaa Omran and Bashir, Ali Kashif and Joshi, Gyanendra Prasad},
  doi          = {10.1007/s00521-022-08158-5},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4795},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Comparative analysis of time series model and machine testing systems for crime forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: A QoS optimization system for complex data
cross-domain request based on neural blockchain structure. <em>NCA</em>,
<em>35</em>(6), 4793. (<a
href="https://doi.org/10.1007/s00521-022-08157-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Deng, Lianbing and Li, Daming and Cai, Zhiming and Yao, Xiang},
  doi          = {10.1007/s00521-022-08157-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4793},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A QoS optimization system for complex data cross-domain request based on neural blockchain structure},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heuristic optimisation of multi-task dynamic architecture
neural network (DAN2). <em>NCA</em>, <em>35</em>(6), 4775–4791. (<a
href="https://doi.org/10.1007/s00521-022-07851-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel method to optimise the Dynamic Architecture Neural Network (DAN2) adapted for a multi-task learning problem. The multi-task learning neural network adopts a multi-head and serial architecture with DAN2 layers acting as the basic subroutine. Adopting a dynamic architecture, the layers are added consecutively starting from a minimal initial structure. The optimisation method adopts an iterative heuristic scheme that sequentially optimises the shared layers and the task-specific layers until the solver converges to a small tolerance. Application of the method has demonstrated the applicability of the algorithm to simulated datasets. Comparable results to Artificial Neural Networks (ANNs) have been obtained in terms of accuracy and speed.},
  archive      = {J_NCA},
  author       = {Zhang, Sushen and Vassiliadis, Vassilios S. and Hao, Zhimian and Cao, Liwei and Lapkin, Alexei A.},
  doi          = {10.1007/s00521-022-07851-9},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4775-4791},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heuristic optimisation of multi-task dynamic architecture neural network (DAN2)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EnsembleNet: A hybrid approach for vehicle detection and
estimation of traffic density based on faster r-CNN and YOLO models.
<em>NCA</em>, <em>35</em>(6), 4755–4774. (<a
href="https://doi.org/10.1007/s00521-022-07940-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to static traffic management regulations on roadways, traffic flow may become congested as it has been growing on roads. Estimating traffic density impacts intelligent transportation systems as it helps build efficient traffic management. Vehicle recognition and counting are two main steps to estimate traffic density. Vehicle identification systems can use motion, handcrafted features, and convolutional neural network (CNN)-based methods. The utilization of deep learning technologies is increasing daily with the popularity of CNN. Different classification and detection models have been developed using transfer learning. In this study, data are collected from several open-source libraries, including MB7500, KITTI, and FLIR. Image annotation has been done to classify vehicles into different categories. Various data augmentation methods are implemented to increase the dataset size and to reduce class imbalance problem. Image quality has been enhanced by performing the sharpening process. Then, a hybrid model of Faster R-CNN and YOLO using majority voting classifier has been trained on processed data. The proposed model’s findings have been compared with its base estimators on the collected datasets. The proposed model has demonstrated detection accuracy of up to 98\%, whereas YOLO and Faster R-CNN provide 95.8 and 97.5\%, respectively. Additionally, compared to YOLO and Faster R-CNN, experimental results show that the proposed model performs better at estimating traffic density. Hence, the proposed approach can effectively enhance road traffic management.},
  archive      = {J_NCA},
  author       = {Mittal, Usha and Chawla, Priyanka and Tiwari, Rajeev},
  doi          = {10.1007/s00521-022-07940-9},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4755-4774},
  shortjournal = {Neural Comput. Appl.},
  title        = {EnsembleNet: A hybrid approach for vehicle detection and estimation of traffic density based on faster R-CNN and YOLO models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Brain tumor segmentation and classification using hybrid
deep CNN with LuNetClassifier. <em>NCA</em>, <em>35</em>(6), 4739–4753.
(<a href="https://doi.org/10.1007/s00521-022-07934-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumour detection is essential for improving patient survival and prospects. This research work necessitates a physical examination with magnetic resonance imaging (MRI). As a result, computational algorithms are required for more accurate tumour diagnosis. Moreover, evaluating shape, boundaries, volume, size, segmentation, tumour detection, and classification remains difficult. To resolve these problems, hybrid deep convolutional neural network (DCNN) with enhanced LuNet classifier algorithm has been proposed for brain tumour detection. The main intention of the proposed approach is to locate the tumor and classify brain tumors as Glioma or Meningioma. For preprocessing, a Laplacian Gaussian filter (LOG) is used. A Fuzzy C Means with Gaussian mixture model (FCM-GMM) algorithm has been proposed for segmentation. To begin, use the extended LuNet algorithm to divide the data. A VGG16 extraction feature yields thirteen categorical features. Overall, the proposed method attempts to improve the performance of classifiers. The proposed LuNet classifiers are an excellent deep learning technique because it has low computational complexity, are inexpensive, and are simple to use even for those with little training experience. The simulated outcomes of the proposed algorithm compared to other conventional algorithms like SVM, Decision tree, Random forest, Alexnet, Resnet-50 and Googlenet classifier algorithm. The introduced hybrid approach achieves 99.7\% accuracy. When compared to other existing algorithms, the proposed method outperforms them.},
  archive      = {J_NCA},
  author       = {Balamurugan, T. and Gnanamanoharan, E.},
  doi          = {10.1007/s00521-022-07934-7},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4739-4753},
  shortjournal = {Neural Comput. Appl.},
  title        = {Brain tumor segmentation and classification using hybrid deep CNN with LuNetClassifier},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mastering construction heuristics with self-play deep
reinforcement learning. <em>NCA</em>, <em>35</em>(6), 4723–4738. (<a
href="https://doi.org/10.1007/s00521-022-07989-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning heuristics without expert experience to construct solutions automatically has always been a critical challenge of combinatorial optimization. It is also the pursuit of artificial intelligence to construct an agent with the planning ability to solve multiple problems simultaneously. Nonetheless, most current learning-based methods for combinatorial optimization still rely on artificially designed heuristics. In real-world problems, the environment’s dynamics are often unknown and complex, making it challenging to generalize and implement current methods. Inspired by AlphaGo Zero, we propose a novel self-play reinforcement learning algorithm (CH-Zero) based on the Monte Carlo tree search (MCTS) for routing optimization problems in this paper. Like AlphaGo Zero, CH-Zero does not require expert experience but some necessary rules. However, unlike other self-play algorithms based on MCTS, we have designed offline training and online reasoning. Specifically, we apply self-play reinforcement learning without MCTS to train offline policy and value networks. Then, we apply the learned heuristics and neural network combined with an MCTS to make inferences on unknown instances. Since we did not incorporate MCTS during training, this is equivalent to training a lightweight self-playing framework whose learning efficiency is much higher than the existing self-play-based methods for combinatorial optimization. We can employ the learned heuristics to guide MCTS to improve policies and take better actions at runtime.},
  archive      = {J_NCA},
  author       = {Wang, Qi and He, Yuqing and Tang, Chunlei},
  doi          = {10.1007/s00521-022-07989-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4723-4738},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mastering construction heuristics with self-play deep reinforcement learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Customer decision-making analysis based on big social data
using machine learning: A case study of hotels in mecca. <em>NCA</em>,
<em>35</em>(6), 4701–4722. (<a
href="https://doi.org/10.1007/s00521-022-07992-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big social data and user-generated content have emerged as important sources of timely and rich knowledge to detect customers’ behavioral patterns. Revealing customer satisfaction through the use of user-generated content has been a significant issue in business, especially in the tourism and hospitality context. There have been many studies on customer satisfaction that take quantitative survey approaches. However, revealing customer satisfaction using big social data in the form of eWOM (electronic word of mouth) can be an effective way to better understand customers’ demands. In this study, we aim to develop a hybrid methodology based on supervised learning, text mining, and segmentation machine learning approaches to analyze big social data on travelers’ decision-making regarding hotels in Mecca, Saudi Arabia. To do so, we use support vector regression with sequential minimal optimization (SMO), latent Dirichlet allocation (LDA), and k-means approaches to develop the hybrid method. We collect data from travelers’ online reviews of Mecca hotels on TripAdvisor. The data are segmented, and travelers’ satisfaction is revealed for each segment based on their online reviews of hotels. The results show that the method is effective for big social data analysis and traveler segmentation in Mecca hotels. The results are discussed, and several recommendations and strategies for hotel managers are provided to enhance their service quality and improve customer satisfaction.},
  archive      = {J_NCA},
  author       = {Alsayat, Ahmed},
  doi          = {10.1007/s00521-022-07992-x},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4701-4722},
  shortjournal = {Neural Comput. Appl.},
  title        = {Customer decision-making analysis based on big social data using machine learning: A case study of hotels in mecca},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial neural network-based pore size prediction of
alginate gel scaffold for targeted drug delivery. <em>NCA</em>,
<em>35</em>(6), 4683–4699. (<a
href="https://doi.org/10.1007/s00521-022-07958-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pore size distribution of polymeric gel scaffold and the corresponding porosity are key elements influencing their drug release profile in several targeted drug delivery applications. This research aimed to build a network model that can successfully determine the pore size distribution of the alginate gel scaffold fabricated using microfluidic techniques. Scaffold properties controlling the average pore diameter, porosity, and yield stress identified as sodium alginate concentration and surface activity were computed by measuring the viscosity, surface tension, and contact angle, respectively. A mathematical model was established using an artificial neural network (ANN) comprising alginate concentration, viscosity, surface tension, and contact angle as input and average pore diameter, porosity, and yield stress as output. The proposed model successfully determined the pore size distribution of gel scaffold covering a range of 70–400 mm, fabricated by various combinations of sodium alginate and pluronic F-127 and compared with random forest (RF), support vector regression (SVR) and k-nearest neighbor (kNN) models. The surface activity of gel scaffold was estimated to have an utmost impact on pore size followed by viscosity and finally contact angle. The results of this work efficaciously emphasized the scaffold properties affecting pore size distribution and established the efficacy of ANN in predicting the average pore diameter, porosity, and yield stress of polymeric gel scaffolds.},
  archive      = {J_NCA},
  author       = {Das, Raja and Bhasarkar, Jaykumar and Rastogi, Amol and Saxena, Raghav and Bal, Dharmendra Kumar},
  doi          = {10.1007/s00521-022-07958-z},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4683-4699},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural network-based pore size prediction of alginate gel scaffold for targeted drug delivery},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cell phone usage detection in roadway images: From plate
recognition to violation classification. <em>NCA</em>, <em>35</em>(6),
4667–4682. (<a
href="https://doi.org/10.1007/s00521-022-07943-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distracted driving plays a significant role in road accidents worldwide. Detecting distracted driving in real time is a significant challenge faced by law enforcement officers. Although efforts are continuing to identify this type of infraction in an automated manner, most of the techniques proposed for this problem use images obtained internally from vehicles. Few studies have looked into using roadway images collected in naturalistic situations. We propose in this research a complete and fully automated deep-learning approach that locates vehicles in roadway images, detects and extracts license plate numbers, detects the windshield region, and classifies images into predefined violations. The proposed approach is complete in that it does not rely on roadway license plate systems to localize the vehicle of interest and extract the license plate numbers. The model performance-both overall and in each stage-was evaluated, achieving $$90\%$$ overall classification accuracy. The model is trained and tested on a real-world local dataset of 10,000 images. The dataset used in this study is the first dataset acquired from roadway license plate cameras in the Middle Eastern region showing unique variations of plate forms, driving habits, regional attire, and weather conditions.},
  archive      = {J_NCA},
  author       = {Balabid, Amal and Altaban, Areej and Albsisi, Maram and Alhothali, Areej},
  doi          = {10.1007/s00521-022-07943-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4667-4682},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cell phone usage detection in roadway images: From plate recognition to violation classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward embedding-based multi-label feature selection with
label and feature collaboration. <em>NCA</em>, <em>35</em>(6),
4643–4665. (<a
href="https://doi.org/10.1007/s00521-022-07924-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similar to single-label learning, multi-label learning employs feature selection technique to alleviate the curse of dimensionality. Many multi-label methods, which utilize label correlation or instance correlation to select meaningful features, were proposed in recent years. However, these multi-label feature selection methods explored the label correlation or instance correlation via similarity measures, which may not perform well in revealing complex relationships between labels and instances. Furthermore, label correlation and instance correlation are employed as independent strategy to select the discriminative features, and no general framework can currently be considered the two together as to their effect. In this paper, we propose a new multi-label feature selection method named CMFSS, which explicitly explores the label correlation and instance correlation in a collaborative manner. Firstly, CMFSS learns the label correlation and the instance correlation via the ADMM technique. Secondly, the learned label correlation and instance correlation are seamlessly incorporated into the multi-label feature selection model. Finally, CMFSS utilizes $$\ell _{2,1}$$ -norm as sparsity regularization to control the model complexity. Extensive empirical evaluations conducted on multiple benchmark datasets clearly show the superiority of the proposed multi-label feature selection method.},
  archive      = {J_NCA},
  author       = {Dai, Liang and Zhang, Jia and Du, Guodong and Li, Candong and Wei, Rong and Li, Shaozi},
  doi          = {10.1007/s00521-022-07924-9},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4643-4665},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward embedding-based multi-label feature selection with label and feature collaboration},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GPU-based cooperative coevolution for large-scale global
optimization. <em>NCA</em>, <em>35</em>(6), 4621–4642. (<a
href="https://doi.org/10.1007/s00521-022-07931-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To resolve the issue of the curse of dimensionality in continuous large-scale optimization problems, the cooperative coevolution divide-and-conquer framework was proposed by dividing the problem into several subcomponents either randomly or based on the interaction between variables, each of which can be optimized separately using metaheuristic suboptimizers. The goal of researchers is to optimize the performance of algorithms in terms of both quality of solution and computational speed, seeing that large-scale optimization can be a computationally expensive process. This work proposes a parallel implementation to the cooperative coevolution framework for solving large-scale global optimization problems using the Graphics Processing Unit (GPU) and CUDA platform. A distributed variant of the cooperative coevolution framework is outlined to expose a degree of parallelism. Features of the GPU parallel technology and CUDA platform such as shared and global memories are used to optimize the subcomponents of the problem in parallel, speeding up the optimization process while attempting to maintain comparable search quality to works in the literature. The CEC 2010 large-scale global optimization benchmark functions are used for conducting experiments and comparing results in terms of improvements in search quality and search efficiency. Results of proposed parallel implementation show that a speedup of up to x13.01 is possible on large-scale global optimization benchmarks using the GPUs.},
  archive      = {J_NCA},
  author       = {Kelkawi, Ali and El-Abd, Mohammed and Ahmad, Imtiaz},
  doi          = {10.1007/s00521-022-07931-w},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4621-4642},
  shortjournal = {Neural Comput. Appl.},
  title        = {GPU-based cooperative coevolution for large-scale global optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reviving autoencoder pretraining. <em>NCA</em>,
<em>35</em>(6), 4587–4619. (<a
href="https://doi.org/10.1007/s00521-022-07892-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pressing need for pretraining algorithms has been diminished by numerous advances in terms of regularization, architectures, and optimizers. Despite this trend, we re-visit the classic idea of unsupervised autoencoder pretraining and propose a modified variant that relies on a full reverse pass trained in conjunction with a given training task. This yields networks that are as-invertible-as-possible and share mutual information across all constrained layers. We additionally establish links between singular value decomposition and pretraining and show how it can be leveraged for gaining insights about the learned structures. Most importantly, we demonstrate that our approach yields an improved performance for a wide variety of relevant learning and transfer tasks ranging from fully connected networks over residual neural networks to generative adversarial networks. Our results demonstrate that unsupervised pretraining has not lost its practical relevance in today’s deep learning environment.},
  archive      = {J_NCA},
  author       = {Xie, You and Thuerey, Nils},
  doi          = {10.1007/s00521-022-07892-0},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4587-4619},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reviving autoencoder pretraining},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shrink–swell index prediction through deep learning.
<em>NCA</em>, <em>35</em>(6), 4569–4586. (<a
href="https://doi.org/10.1007/s00521-022-07764-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growing application of artificial intelligence in geotechnical engineering has been observed; however, its ability to predict the properties and nonlinear behaviour of reactive soil is currently not well considered. Although previous studies provided linear correlations between shrink–swell index and Atterberg limits, obtained model accuracy values were found unsatisfactory results. Artificial intelligence, specifically deep learning, has the potential to give improved accuracy. This research employed deep learning to predict more accurate values of shrink–swell indices, which explored two scenarios; Scenario 1 used the features liquid limit, plastic limit, plasticity index, and linear shrinkage, whilst Scenario 2 added the input feature, fines percentage passing through a 0.075-mm sieve (\%fines). Findings indicated that the implementation of deep learning neural networks resulted in increased model measurement accuracy in Scenarios 1 and 2. The values of accuracy measured in this study were suggestively higher and have wider variance than most previous studies. Global sensitivity analyses were also conducted to investigate the influence of each input feature. These sensitivity analyses resulted in a range of predicted values within the variance of data in Scenario 2, with the\%fines having the highest contribution to the variance of the shrink–swell index and a relevant interaction between linear shrinkage and\%fines. The proposed model Scenario 2 was around 10–65\% more accurate than the preceding models considered in this study, which can then be used to expeditiously estimate more accurate values of shrink–swell indices.},
  archive      = {J_NCA},
  author       = {Teodosio, B. and Wasantha, P. L. P. and Yaghoubi, E. and Guerrieri, M. and C. van Staden, R. and Fragomeni, S.},
  doi          = {10.1007/s00521-022-07764-7},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4569-4586},
  shortjournal = {Neural Comput. Appl.},
  title        = {Shrink–swell index prediction through deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Road safety assessment and risks prioritization using an
integrated SWARA and MARCOS approach under spherical fuzzy environment.
<em>NCA</em>, <em>35</em>(6), 4549–4567. (<a
href="https://doi.org/10.1007/s00521-022-07929-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are a lot of elements that make road safety assessment situations unpredictable and hard to understand. This could put people&#39;s lives in danger, hurt the mental health of a society, and cause permanent financial and human losses. Due to the ambiguity and uncertainty of the risk assessment process, a multi-criteria decision-making technique for dealing with complex systems that involves choosing one of many options is an important strategy of assessing road safety. In this study, an integrated stepwise weight assessment ratio analysis (SWARA) with measurement of alternatives and ranking according to compromise solution (MARCOS) approach under a spherical fuzzy (SF) set was considered. Then, the proposed methodology was applied to develop the approach of failure mode and effect analysis (FMEA) for rural roads in Cosenza, southern Italy. Also, the results of modified FMEA by SF-SWARA-MARCOS were compared with the results of conventional FMEA. The risk score results demonstrated that the source of risk (human) plays a significant role in crashes compared to other sources of risk. The two risks, including landslides and floods, had the lowest values among the factors affecting rural road safety in Calabria, respectively. The correlation between scenario outcomes and main ranking orders in weight values was also investigated. This study was done in line with the goals of sustainable development and the goal of sustainable mobility, which was to find risks and lower the number of accidents on the road. As a result, it is thus essential to reconsider laws and measures necessary to reduce human risks on the regional road network of Calabria to improve road safety.},
  archive      = {J_NCA},
  author       = {Jafarzadeh Ghoushchi, Saeid and Shaffiee Haghshenas, Sina and Memarpour Ghiaci, Ali and Guido, Giuseppe and Vitale, Alessandro},
  doi          = {10.1007/s00521-022-07929-4},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4549-4567},
  shortjournal = {Neural Comput. Appl.},
  title        = {Road safety assessment and risks prioritization using an integrated SWARA and MARCOS approach under spherical fuzzy environment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new co-learning method in spatial complex fuzzy inference
systems for change detection from satellite images. <em>NCA</em>,
<em>35</em>(6), 4519–4548. (<a
href="https://doi.org/10.1007/s00521-022-07928-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of spatial and temporal changes (or change detection) in remote sensing images is essential in any decision support system about natural phenomena such as extreme weather conditions, climate change, and floods. In this paper, a new method is proposed to determine the inference process parameters of boundary point, rule coefficient, defuzzification coefficient, and dependency coefficient and present a new FWADAM+ method to train that set of parameters simultaneously. The initial data are clustered simultaneously according to each data group. This result will be the basis for determining a suitable set of parameters by using the FWADAM+ concurrent training algorithm. Eventually, these results will be inherited in the following data groups to build other complex fuzzy rule systems in a shorter time while still ensuring the model’s efficiency. The weather imagery database of the United States Navy (US Navy) is used to evaluate and compare with some related methods using the root-mean-squared error (RMSE), R-squared (R2) measures, and the analysis of variance (ANOVA) model. The experimental results show that the proposed method is up to 30\% better than the SeriesNet method, and the processing time is 10\% less than that of the SeriesNet method.},
  archive      = {J_NCA},
  author       = {Giang, Le Truong and Son, Le Hoang and Giang, Nguyen Long and Tuan, Tran Manh and Luong, Nguyen Van and Sinh, Mai Dinh and Selvachandran, Ganeshsree and Gerogiannis, Vassilis C.},
  doi          = {10.1007/s00521-022-07928-5},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4519-4548},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new co-learning method in spatial complex fuzzy inference systems for change detection from satellite images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a multi-stage fuzzy cognitive map for an
uncertainty environment: Methods and introduction. <em>NCA</em>,
<em>35</em>(6), 4499–4517. (<a
href="https://doi.org/10.1007/s00521-022-07778-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, hospital failures become a challenging issue regarding their occasional irreparable consequences. Many patients lose their lives each year due to medical failures, with their costs estimated at millions of dollars. Therefore, paying attention to them and correct management of these failures can save the patients’ life. In this regard, various methods have been introduced for evaluating and ranking them. Failure Mode and Effects Analysis (FMEA) in combination with the Gray Relational Analysis (GRA) is among the most effective methods for evaluating these failures. The present study aims to evaluate patient operating failures by considering such failures in an uncertain environment and considering causal relations between these failures. For this purpose, a new method is proposed, which is an extension of the fuzzy cognitive map. This method, called multi-stage fuzzy gray cognitive map, evaluates the operating room failures more accurately by considering the values obtained from FMEA as input, as well as the causal relationship between the failures identified by the medical expert team. The proposed cognitive map was trained by two network training methods including delta rule extended for the multi-stage fuzzy gray cognitive map and Nonlinear Hebbian learning (NHL) algorithm. One of the most important limitations of the present study was the lack of sufficient research on the subject under study and also the difficulty of selecting the appropriate case to validate the proposed model. The results obtained from ranking with the proposed approach and comparing it with previous methods showed more accurate ranking and elimination of duplicates at one level of ranking. These results can be a strong reference for management team decisions in future for better management of hospital failures.},
  archive      = {J_NCA},
  author       = {Abdollahzadeh, Sohrab and Hayati, Jamileh},
  doi          = {10.1007/s00521-022-07778-1},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4499-4517},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of a multi-stage fuzzy cognitive map for an uncertainty environment: Methods and introduction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D residual spatial–spectral convolution network for
hyperspectral remote sensing image classification. <em>NCA</em>,
<em>35</em>(6), 4479–4497. (<a
href="https://doi.org/10.1007/s00521-022-07933-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral remote sensing images (HRSI) are 3D image cubes that contain hundreds of spectral bands and have two spatial dimensions and one spectral dimension. HRSI analysis are commonly used in a wide variety of applications such as object detection, precision agriculture and mining. HRSI classification purposes to assign each pixel in HRSI to a unique class. Deep learning is seen as an effective method to improve HRSI classification. In particular, convolutional neural networks (CNNs) are increasingly used in remote sensing field. In this study, a hybrid 3D residual spatial–spectral convolution network (3D-RSSCN) is proposed to extract deep spatiospectral features using 3D CNN and ResNet18 architecture. Simultaneously spatiospectral features extraction is provided using 3D CNN. In deeper CNNs, ResNet architecture is used to achieve higher classification performance as the number of layers increases. In addition, thanks to the ResNet architecture, problems such as degradation and vanishing gradient that may occur in deep networks are overcome. The high dimensionality of the HRSIs increases the computational complexity. Thus, most of studies apply dimension reduction as preprocessing. In the proposed study, principal component analysis (PCA) is used as the preprocessing step for optimum spectral band extraction. The proposed 3D-RSSCN method is tested with Indian pines, Pavia University and Salinas datasets and compared against various deep learning-based methods (SAE, RPNet, 2D CNN, 3D CNN, M3D CNN, HybridSN, FC3D CNN, SSRN, FuSENet, S3EResBoF). As a result of the applications, the best classification accuracy among these methods compared in all datasets is obtained with the proposed 3D-RSSCN. The proposed 3D-RSSCN method has the best accuracy and time performance in classifying.},
  archive      = {J_NCA},
  author       = {Firat, Hüseyin and Asker, Mehmet Emin and Bayindir, Mehmet İlyas and Hanbay, Davut},
  doi          = {10.1007/s00521-022-07933-8},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4479-4497},
  shortjournal = {Neural Comput. Appl.},
  title        = {3D residual spatial–spectral convolution network for hyperspectral remote sensing image classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Brain MRI tumour classification using quantum classical
convolutional neural net architecture. <em>NCA</em>, <em>35</em>(6),
4467–4478. (<a
href="https://doi.org/10.1007/s00521-022-07939-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of quantum machines leverages the performance of classical machines in many aspects of solving real-world problems. Classification of a brain MR image for detection of tumour regions is a widely performed diagnostic step when it comes to working with brain images. Classical machine learning methods and/or conventional deep learning architectures including convolutional nets are commonly used for the classification of images. With larger network size, training the model becomes a challenging task to undertake. Quantum algorithms are beneficial in optimizing the performance of classical algorithms by incorporating intrinsic properties of quantum bits. In this paper, a novel Quantum Classical ConvNet architecture (QCCNN) is proposed for a binary class classification of brain MR images for detection of tumour regions in the human brain. The underlying idea is to encode data into quantum states enabling a faster extraction of information followed by using the information to distinguish the class of data. The reliability and the robustness of the proposed architecture are highlighted by the results obtained by the classifier. With technological advancements in quantum computers in the future (more qubits and less noise), the performance of the approach can be further improved. The presented model is tested on various datasets (Brats 2013, Harvard Med School, private dataset) and on quantitative evaluation with standard metrics, and the robustness of the classifier is verified. The proposed QCCNN model achieves accuracies in the range of 97.5–98.72\% on different datasets which defend the ability of the presented architecture in detecting and classifying brain tumours.},
  archive      = {J_NCA},
  author       = {Choudhuri, Rudrajit and Halder, Amiya},
  doi          = {10.1007/s00521-022-07939-2},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4467-4478},
  shortjournal = {Neural Comput. Appl.},
  title        = {Brain MRI tumour classification using quantum classical convolutional neural net architecture},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rao algorithms based on elite local search method.
<em>NCA</em>, <em>35</em>(6), 4435–4465. (<a
href="https://doi.org/10.1007/s00521-022-07932-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Rao algorithms, which have been proposed for solving complex and continuous optimization problems lately, are described as metaphor-less optimization algorithms because they do not contain algorithm-specific parameters. The Rao algorithms have variants called Rao-1, Rao-2 and Rao-3, respectively, depending on different population updating procedures. In Rao 1–3 algorithms, random interactions between candidate solutions and the best and worst solution in the whole population for solving optimizations problems were determined as the basic principle. Although this situation makes the Rao 1–3 algorithms increase the speed of convergence, it can cause the diversity of candidate solutions to decrease and the local search capacity to reduce. In this study, a new elite local search procedure was added to the population updating procedure of Rao algorithms to expand the capacity of Rao 1–3 algorithms and develop their solutions. The proposed method was called ELSRao-1, ELSRao-2 and ELSRao-3. Fifteen unconstrained unimodal, fifteen unconstrained multimodal functions and twenty-nine unconstrained CEC 2017 benchmark test functions were used to analyze the performance of the proposed ELSRao 1–3 algorithms. Jaya, dragonfly algorithm, arithmetic optimization algorithm, whale optimization algorithm and standard Rao 1–3 algorithms which are all state-of-the-art algorithms were used to compare the superiority and success of the proposed ELSRao 1–3 algorithms in benchmark functions. Friedman&#39;s mean rank test and Tukey–Kramer post hoc test were applied for statistical analysis. According to the experimental studies and statistical analysis, it was concluded that the proposed ELSRao 1–3 algorithms proved to be efficient and robust in the solution to unconstrained optimization problems.},
  archive      = {J_NCA},
  author       = {Tefek, Mehmet Fatih},
  doi          = {10.1007/s00521-022-07932-9},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4435-4465},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rao algorithms based on elite local search method},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symmetry-structured convolutional neural networks.
<em>NCA</em>, <em>35</em>(6), 4421–4434. (<a
href="https://doi.org/10.1007/s00521-022-08168-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider convolutional neural networks (CNNs) with 2D structured features that are symmetric in the spatial dimensions. Such networks arise in modeling pairwise relationships for a sequential recommendation problem, as well as secondary structure inference problems of RNA and protein sequences. We develop a CNN architecture that generates and preserves the symmetry structure in the network’s convolutional layers. We present parameterizations for the convolutional kernels that produce update rules to maintain symmetry throughout the training. We apply this architecture to the sequential recommendation problem, the RNA secondary structure inference problem, and the protein contact map prediction problem, showing that the symmetric structured networks produce improved results using fewer numbers of machine parameters.},
  archive      = {J_NCA},
  author       = {Maduranga, Kehelwala Dewage Gayan and Zadorozhnyy, Vasily and Ye, Qiang},
  doi          = {10.1007/s00521-022-08168-3},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4421-4434},
  shortjournal = {Neural Comput. Appl.},
  title        = {Symmetry-structured convolutional neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sports video analysis system based on dynamic image
analysis. <em>NCA</em>, <em>35</em>(6), 4409–4420. (<a
href="https://doi.org/10.1007/s00521-022-07131-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the quality of sports training and competitions, it is necessary to analyze sports videos. Therefore, this paper builds a sports video analysis system based on image recognition technology. To improve the data fusion effect of the system, this article starts from the time and space scale and frequency scale of the dynamic image to comprehensively use the technologies of motion estimation, multi-scale transformation, and visual attention to realize the comprehensive analysis of the dynamic image. Moreover, this paper constructs a dynamic image analysis method and applies it to dynamic image fusion to improve the quality of the fused dynamic image. In addition, this article combines the needs of sports image analysis to construct system function modules and compares the input video action decomposition with the standard database to correct the sports action. Finally, this article designs experiments to verify the performance of the system. The research results show that the system constructed in this paper has a certain effect.},
  archive      = {J_NCA},
  author       = {Li, Zhen and Ye, Xinjiang and Liang, Huawei},
  doi          = {10.1007/s00521-022-07131-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4409-4420},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sports video analysis system based on dynamic image analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent control system of physical strength in sports
based on independent component analysis. <em>NCA</em>, <em>35</em>(6),
4397–4408. (<a
href="https://doi.org/10.1007/s00521-022-07093-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People are paying more and more attention to factors that damage health in daily life. After a lot of physical labor or sports activities, the human body will produce sports fatigue. According to the characteristics of sports physical strength in sports, this paper conducts monitoring and analysis of physical strength in sports on the basis of independent component analysis. Moreover, according to the characteristics of the physical fatigue, the physical fatigue is systematically analyzed. In addition, this paper combines the ergonomics theory to determine the influencing factors of physical fatigue, puts forward a set of evaluation index system for the effectiveness analysis of physical fatigue, and establishes a more objective and systematic independent component analysis and evaluation model of physical fatigue. Finally, this paper constructs a model of an intelligent control system of physical strength in sports according to the actual situation of physical strength in sports, and analyzes the performance of the system through case test analysis. The experimental results verify the reliability of the system model constructed in this paper.},
  archive      = {J_NCA},
  author       = {Lu, Bingxu},
  doi          = {10.1007/s00521-022-07093-9},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4397-4408},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent control system of physical strength in sports based on independent component analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design and innovation of audio IoT technology using music
teaching intelligent mode. <em>NCA</em>, <em>35</em>(6), 4383–4396. (<a
href="https://doi.org/10.1007/s00521-022-07025-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional music teaching model cannot meet the needs of modern music teaching. Therefore, this paper combines machine learning technology and Internet of Things audio technology to improve the music audio recognition algorithm. In order to ensure the smoothness between music frames and the continuity of speech, when the remaining length of the music audio stream tail is less than one frame length, it is directly discarded and no framing processing is performed. The main end of the integrated platform can communicate with the sub-end systems of each smart music classroom through a standard communication protocol by the front communication server, and access the information and data of each device subsystem in the smart music classroom. In addition, this paper combines the needs of music teaching to construct the layout of the smart music classroom and the software system architecture. After constructing the system, this paper designs experiments to verify the performance of the teaching system constructed in this paper. The experimental research results show that the audio technology based on the Internet of Things proposed in this paper can play an important role in music teaching.},
  archive      = {J_NCA},
  author       = {Li, Lintao and Han, Zhongling},
  doi          = {10.1007/s00521-022-07025-7},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4383-4396},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design and innovation of audio IoT technology using music teaching intelligent mode},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cheerleading athlete’s action safety in sports competition
based on kohonen neural network. <em>NCA</em>, <em>35</em>(6),
4369–4382. (<a
href="https://doi.org/10.1007/s00521-022-07133-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skill cheerleading is a sport with high difficulty, high skill and relatively high injury probability. This study mainly discusses the judgment of Cheerleading athletes&#39; action safety in sports competition based on Kohonen neural network. The Kohonen network consists of an input unit layer and a two-dimensional output network of processing units. During the training process, each element competes with other units to obtain each record. When a yuan obtains a record, its weight is adjusted to more closely match the predicted category of the record. The Kohonen neural network&#39;s analysis of data is divided into roughly two processes. One is the tentative evaluation process of the network model to obtain the overall pattern of the data, and the other is the process of adjusting and optimizing the network to obtain a better model for the features contained in the data. Athletes&#39; injuries are not only caused by their own factors, but also caused by technical factors, poor protection and improper cooperation. Of course, skill cheerleading is not only difficult, but also includes many people participating in the completion of transition connection and some single person dance combinations, hand position combinations, jumps, etc., which may also become potential factors for athletes&#39; injury. According to the characteristics of skill cheerleading team, the injury of athletes is divided into three parts. The first part is the injury of multi person cooperative action unique to skill cheerleading team, including throwing, lifting, pyramid, top and base in transition and connection. The second part is the injury of difficult somersault completed by a single person. The third part is the factors other than difficulty, including jumping, dance combination and hand position combination. The fuzzy Kohonen clustering algorithm proposed in this study adopts batch processing for motion risk data samples, eliminates the dependence of clustering results on the order of input samples, and makes it suitable for dealing with the problem of fuzziness. Finally, the judgment matrix is introduced to judge the risk index weight of the action safety of skilled cheerleaders in sports competitions. The injury rate of skill cheerleading athletes is different, and the injury rate of somersault difficult movement is 67.92\%. The injury rate of external factors such as jumping, dancing and hand position combination was 48.15\%. This study will help to provide useful theoretical guidance for the standardized, scientific, sustainable and good development of skill cheerleading team.},
  archive      = {J_NCA},
  author       = {Chen, Bingxin and Kuang, Lifei and He, Wei},
  doi          = {10.1007/s00521-022-07133-4},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4369-4382},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cheerleading athlete&#39;s action safety in sports competition based on kohonen neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A deep learning algorithm for fast motion video sequences
based on improved codebook model. <em>NCA</em>, <em>35</em>(6),
4353–4368. (<a
href="https://doi.org/10.1007/s00521-022-07079-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast motion video sequence processing is quite difficult. In order to improve the effect of fast motion video sequence processing, this paper improves the traditional codebook model algorithm and proposes an improved codebook model algorithm. Moreover, this paper analyzes and summarizes the development and application of background modeling-based methods in moving target detection, and points out the applicability and limitations of traditional methods, which lays the foundation for the further research of moving target detection based on background modeling in the complex background. In addition, this paper analyzes the characteristics of fast motion videos, and combines deep learning algorithms to improve the feature recognition effect of fast motion video sequences. Finally, this paper verifies the effect of this method through experimental research. Through experimental research, we know that the improved algorithm proposed in this paper can realize effective processing of fast motion video, and can improve the feature recognition effect of motion video frames.},
  archive      = {J_NCA},
  author       = {Zhou, Kai and Zhang, Zhendong and Yuan, Rui and Chen, Enqing},
  doi          = {10.1007/s00521-022-07079-7},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4353-4368},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning algorithm for fast motion video sequences based on improved codebook model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characteristics of different swimming styles of swimming
events based on artificial neural network data acquisition system.
<em>NCA</em>, <em>35</em>(6), 4337–4352. (<a
href="https://doi.org/10.1007/s00521-022-07130-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, remote data collection and remote monitoring technologies based on artificial neural networks have been increasingly used in various industries. In order to in-depth study whether the data collection system based on artificial neural network theory can analyze the characteristics of different strokes in swimming events, this paper uses simulation comparison method, data integration method, and step-by-step construction method to collect samples, analyze the data collection system, and streamline the algorithm. And integrate and create a data collection system that can analyze the characteristics of swimming styles. After constructing the system, select the image frequency 450 ms once, and set the signal frequency to 2.5 KHZ. Set the waveforms to sawtooth wave and sine wave, respectively; the voltage range of sine wave is − 6 to 8 V, and the sampling frequency is 250. The voltage range of the sawtooth wave is − 8 to 6 V, and the sampling frequency is 45 KHZ. Experiments show that the system basically works normally during the sampling process. To further study the stability of the system, this test is in a swimming pool with a one-story building with a relative humidity of 85\%. It is set to send 110 data frames from the coordinator segment to the normal segment every 2.5 s. The acquisition success rate is 88\% when there is interference and 96\% when there is no interference, which is much higher than that when there is interference. Therefore, a retransmission mechanism must be used when designing the software for common segment points to ensure reliable data transmission. In general, the data acquisition system we designed basically meets the design standards. It is basically realized that starting from the artificial neural network, a data acquisition system that can analyze swimming styles is designed.},
  archive      = {J_NCA},
  author       = {Xu, Wei and Xu, Lie},
  doi          = {10.1007/s00521-022-07130-7},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4337-4352},
  shortjournal = {Neural Comput. Appl.},
  title        = {Characteristics of different swimming styles of swimming events based on artificial neural network data acquisition system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supply chain management model based on machine learning.
<em>NCA</em>, <em>35</em>(6), 4319–4335. (<a
href="https://doi.org/10.1007/s00521-022-06986-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The supply chain management process in the Internet of Things and the information age needs to deal with massive amounts of data and several influencing factors. Therefore, traditional supply chain management models cannot cope with the needs of modern supply chain management. Based on this, this paper combines machine learning and human–computer interaction technology to construct a supply chain management model, and uses wireless sensor networks as the basis of machine learning and human–computer interaction supply chain models. Combine human–computer interaction algorithms with smart learning algorithms, use machine learning for wireless sensor network data processing, and combine smart learning for data analysis. Moreover, this paper combines the actual needs of the supply chain model to improve the wireless sensor network so that it can meet the operational needs of the supply chain model. In addition, this paper starts with the construction of multiple module functions from the aspects of supply chain management risk, supply chain logistics, supply chain management, and supply chain information transmission. Finally, this paper designs experiments to verify the performance of the system in this paper. The experimental research results show that the supply chain management model based on machine learning and human–computer interaction constructed in this paper has good results.},
  archive      = {J_NCA},
  author       = {Yuan, Guanghui and Wu, Shan and Wang, Bin},
  doi          = {10.1007/s00521-022-06986-z},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4319-4335},
  shortjournal = {Neural Comput. Appl.},
  title        = {Supply chain management model based on machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Animated ink and wash character modeling and simulation
based on automatic intelligent matching of local pixel blocks.
<em>NCA</em>, <em>35</em>(6), 4307–4317. (<a
href="https://doi.org/10.1007/s00521-022-06991-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animation ink is a unique form of artistic expression, which is taken from traditional ink painting, and through the continuous exploration and advancement of animators, it has gradually formed its language system and formed a unique artistic style in expression and mood shaping. In this paper, the spatial domain noise reduction method and the transform domain noise reduction method are integrated, and the two types of algorithms complement each other to obtain a better denoising effect. The local pixel block matching algorithm is used to select similar block samples, which makes the covariance calculated by a principal component analysis more accurate in the next step, and then distinguishes the signal from the noise well. The adaptive bilateral filtering algorithm based on residual noise variance estimation uses the spatial proximity and pixel value similarity in the animated ink and wash image under the premise of the optimal set of filtering parameters, and adopts the local weighted average method to obtain the recovered animated ink and wash image. To effectively protect and enhance the detail information such as edges of the animated ink and wash image for animated ink and wash character modeling design. The method in this paper makes full use of the properties between spatial pixels of animated ink and wash images with both rotation invariance and translation invariance. The experimental results on the test database show that the method in this paper can extract features better. The purpose of this paper is to explore how to inherit and bring into play the fine cultural and artistic essence of ink art, to uncover the expressive elements applicable to animation ink character modeling design, and to make them reasonably and effectively used in the creation of animation ink character modeling to maintain the vitality of animation ink character modeling design.},
  archive      = {J_NCA},
  author       = {Zhang, Xinghua},
  doi          = {10.1007/s00521-022-06991-2},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4307-4317},
  shortjournal = {Neural Comput. Appl.},
  title        = {Animated ink and wash character modeling and simulation based on automatic intelligent matching of local pixel blocks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization and system implementation of fuzzy integrated
algorithm model for logistics supply chain under supply and demand
uncertainty background. <em>NCA</em>, <em>35</em>(6), 4295–4305. (<a
href="https://doi.org/10.1007/s00521-022-07135-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While improving the operational efficiency of the enterprise, the logistics supply chain directly or indirectly affects the performance of the enterprise because of its own and external uncertainty, resulting in tangible or intangible losses. In this era of rapid change and increasing competition, reducing the impact of uncertainty can reduce the risk and vulnerability of the entire logistics service supply chain, and can gain or maintain a competitive advantage. Therefore, based on the background of supply and demand uncertainty, this paper establishes the fuzzy integrated optimization model of logistics supply chain system by using LR fuzzy numbers. In order to solve this model, the study carried out deterministic processing and transformed it into a deterministic multi-objective linear programming model. At the same time, this study also designed a genetic algorithm to solve the model, in order to solve the choice of potential supply and demand uncertainty in the system, and achieve the global optimization of the network. Finally, the calculations are carried out by numerical examples. The results prove the effectiveness of the model and algorithm.},
  archive      = {J_NCA},
  author       = {Li, Yanfen and Yang, Jingyi and Wang, Yuancong},
  doi          = {10.1007/s00521-022-07135-2},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4295-4305},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization and system implementation of fuzzy integrated algorithm model for logistics supply chain under supply and demand uncertainty background},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social image aesthetic classification and optimization
algorithm in machine learning. <em>NCA</em>, <em>35</em>(6), 4283–4293.
(<a href="https://doi.org/10.1007/s00521-022-07128-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of digital cameras and social networks has greatly enriched people&#39;s spiritual life, and we can easily obtain massive amounts of digital photos. However, due to the lack of professional guidance and differences in aesthetic appreciation, the photos taken many photographers lack aesthetics. This article is dedicated to the research of image aesthetics, using computers to simulate human perception, and realize the evaluation or beautification of images in line with human aesthetics. In terms of image classification, this article examines the unique perception of human vision on images and proposes new aesthetic features. Combining visual features and semantic features, the SVM algorithm is utilized to build an aesthetic classifier. In the aspect of image optimization, this paper uses the detection of the main image area and the division line of the area and adjusts the main body size and position of the image according to common aesthetic rules, so as to realize the optimization adjustment of the composition of the social image. The experimental results show that the accuracy of social image classification is 97.7\%, and the optimized and adjusted images are more aesthetic.},
  archive      = {J_NCA},
  author       = {Luo, Pan},
  doi          = {10.1007/s00521-022-07128-1},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4283-4293},
  shortjournal = {Neural Comput. Appl.},
  title        = {Social image aesthetic classification and optimization algorithm in machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Basketball motion video target tracking algorithm based on
improved gray neural network. <em>NCA</em>, <em>35</em>(6), 4267–4282.
(<a href="https://doi.org/10.1007/s00521-022-07026-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article takes the basketball game video with high attention in sports video as an example to analyze the feature extraction of basketball game video, improve the gray neural network algorithm, and disassemble the basketball video. Moreover, this paper takes basketball, basket, and athletes as the feature extraction objects. Considering that the basketball is a round sphere and the object in the image is a circle, as well as the edge is added to the original image and saved. In addition, this paper combines the improved gray neural network algorithm to construct a basketball motion video target tracking algorithm. Finally, this paper designs experiments to verify the performance of this method. The experimental test results show that this method can effectively recognize basketball gestures with high recognition accuracy, which provides a new method for basketball posture recognition.},
  archive      = {J_NCA},
  author       = {Wang, Tianyi and Shi, Cuiping},
  doi          = {10.1007/s00521-022-07026-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4267-4282},
  shortjournal = {Neural Comput. Appl.},
  title        = {Basketball motion video target tracking algorithm based on improved gray neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of artistic graphic symbols based on intelligent
guidance marking system. <em>NCA</em>, <em>35</em>(6), 4255–4266. (<a
href="https://doi.org/10.1007/s00521-022-07088-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an in-depth study and analysis of the design of the symbolization of art graphics through a linear regression algorithm. The improved method first selects a suitable range of learning rate and lets the learning rate transform in the range of values according to the characteristics of cosine function transformation, so that the learning rate gradually decreases at different rates in different periods of training to achieve the effect of a faster convergence of logistic regression loss function and better convergence value and improve the training efficiency and classification accuracy of logistic regression algorithm. At the same time, the modules of data reordering and regularization penalty method are added to make the logistic regression algorithm model have better generalization ability. Based on the interrelationship between guidance signage system, graphic symbols, and emotional expression, we focus on the emotional characteristics and presentation of graphic symbols and explore their emotional transmission in the guidance signage system, thus the impact on human cognitive behavior. We will summarize the significance of the emotional expression of graphic symbols in the guidance signage system. Graphic symbols as the soul of the guidance signage system, are also the most impactful visual elements, their rich expression, presenting a unique visual aesthetic, more in line with the aesthetic interests of modern people. It conveys information, plays a guiding function at the same time, establishes a sense of place, creates a specific emotional atmosphere to convey a certain emotional experience; the message is more deeply rooted.},
  archive      = {J_NCA},
  author       = {Guo, Yongqiang},
  doi          = {10.1007/s00521-022-07088-6},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4255-4266},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design of artistic graphic symbols based on intelligent guidance marking system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on simulation of 3D human animation vision
technology based on an enhanced machine learning algorithm.
<em>NCA</em>, <em>35</em>(6), 4243–4254. (<a
href="https://doi.org/10.1007/s00521-022-07083-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides an in-depth analysis and study of the simulation of 3D human animation visualization techniques by enhancing machine learning algorithms. Based on the statistical analysis of the data obtained from different measurement methods, the extraction of human body feature parameters based on millimeter-wave point cloud data is realized, and the 3D reconstruction and simulation of the human body are realized using parametric human modeling software. In video-based action recognition, most methods are data-driven and use deep networks to automatically learn features of the entire video image. In this process, specific research on human actions is not included or reflected. However, human action recognition is a processing of the semantic level of video content. Realizing universal human action recognition requires a semantic understanding of human behavior. Firstly, the geometric feature analysis of the 3D scanned human model is performed to extract the human body shape characteristic parameters, and the research on the analysis and estimation methods of body shape characteristic parameters is carried out to establish the human body shape parameter relationship model; then, the millimeter-wave point cloud is calculated and measured, the Li group features extracted using the group skeletal representation model with high data dimensionality, to be able to process the high-dimensional data, while reducing the complexity of the recognition process and speeding up the computation, feature learning and classification are performed with convolutional neural networks. To verify the better library portability and robustness of the method in this paper, the method was tested on a self-built human action database in the laboratory, and an average recognition rate of 97.26\% was achieved. Meanwhile, this paper investigates the natural interaction application of virtual characters in a virtual learning environment based on human action recognition. Four testers tested the virtual human–computer interaction system of this paper, respectively, and the final test results show that the system has flexibility and stability.},
  archive      = {J_NCA},
  author       = {Yuan, Henning and Lee, Jong Han and Zhang, Sai},
  doi          = {10.1007/s00521-022-07083-x},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4243-4254},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on simulation of 3D human animation vision technology based on an enhanced machine learning algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent unsupervised learning method of physical
education image resources based on genetic algorithm. <em>NCA</em>,
<em>35</em>(6), 4225–4242. (<a
href="https://doi.org/10.1007/s00521-022-07021-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effect of intelligent processing of physical education resources, this paper combines genetic algorithms and unsupervised learning methods to study the processing of physical education videos and images, which approximately maintains the neighbor structure relationship of the original sample data and reduces the loss of sample local information. Moreover, this paper constructs a graph model structure between the comprehensive compressed data and the input data. In order to reduce the complexity of the solution method of the graph model and reduce the impact of the method of decomposing the spectrogram into the characteristic function on the hash algorithm, this paper designs an intelligent physical education resource processing method based on genetic algorithms and unsupervised learning methods and constructs system functional modules. Finally, this paper designs experiments to verify the performance of the method proposed in this paper. Through comparative analysis of experiments, it can be known that the method proposed in this paper has good results.},
  archive      = {J_NCA},
  author       = {Li, Chengbao and Liu, Bowen and Kim, Kitak},
  doi          = {10.1007/s00521-022-07021-x},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4225-4242},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent unsupervised learning method of physical education image resources based on genetic algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sports training auxiliary decision support system based on
neural network algorithm. <em>NCA</em>, <em>35</em>(6), 4211–4224. (<a
href="https://doi.org/10.1007/s00521-022-07137-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effect of sports training auxiliary decision, this paper combines the needs of sports training auxiliary system to carry out functional analysis and improve the traditional machine learning algorithm. The domain adversarial neural network based on maximum entropy loss combines the ability of maximum entropy loss to process misclassified samples and uses classification loss and domain adversarial loss to solve the problem of inconsistent edge distribution of category features between domains. Moreover, this paper takes sports decision as the core and introduces tasks of different difficulty and video training into research. In addition, this paper uses simulation software to measure the correctness of sports training in different scenarios and the data of the response latency and applies the neural network algorithm to the construction of the sports training auxiliary decision system. Finally, this paper designs experiments to study sports training recognition and sports training decision-making and builds an intelligent system through a simulation platform. The experimental research results show that the system constructed in this paper has a good sports training auxiliary decision function. The reliability of the method in this article can be verified in practice in the future.},
  archive      = {J_NCA},
  author       = {Wang, Tianyi},
  doi          = {10.1007/s00521-022-07137-0},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4211-4224},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sports training auxiliary decision support system based on neural network algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sports video athlete detection based on deep learning.
<em>NCA</em>, <em>35</em>(6), 4201–4210. (<a
href="https://doi.org/10.1007/s00521-022-07077-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep fusion of sports and machine vision has become a research hot spot in sports video target detection, athlete state recovery and sports promotion. On the basis of in-depth study, it can detect a large number of sports videos, complete the drawing and analysis of human body detection model, and detect and evaluate the posture of corresponding athletes in the video, which can save a lot of costs and maximize the more professional training of athletes. In order to solve the above problems, this paper innovatively completes the automatic language description of sports video based on time-sharing memory algorithm. Its principle is to realize the accurate decomposition of athletes&#39; sports data through the mapping relationship between the corresponding letter sequence and video sequence in time-sharing memory. In order to capture the key posture of athletes&#39; sports video, this paper innovatively proposes an object extraction algorithm based on athletes&#39; skeleton motion enhancement. In practical application, based on the key pose capture, it is necessary to train the depth selection network in time to extract the key pose of the skeleton. Based on this network, it can enhance the key posture of bone information and accurately express its related features. After extracting the actual athlete&#39;s bone information, we need to fine-tune the training network to realize the accurate recognition of key features. Based on the above key algorithms, this paper designs a sports video athlete detection system based on deep learning and makes an experimental research on the related sports video. The experimental results show that the detection accuracy of athletes&#39; sports video is improved by nearly 10\% compared with the traditional convolution network recognition algorithm, so the algorithm has obvious advantages in recognition accuracy.},
  archive      = {J_NCA},
  author       = {Ren, Hao},
  doi          = {10.1007/s00521-022-07077-9},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4201-4210},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sports video athlete detection based on deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editorial: Special issue on artificial intelligence
technologies in sports and art data applications. <em>NCA</em>,
<em>35</em>(6), 4199–4200. (<a
href="https://doi.org/10.1007/s00521-022-08124-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Xu, Zheng and Zhang, Shunxiang},
  doi          = {10.1007/s00521-022-08124-1},
  journal      = {Neural Computing and Applications},
  number       = {6},
  pages        = {4199-4200},
  shortjournal = {Neural Comput. Appl.},
  title        = {Editorial: Special issue on artificial intelligence technologies in sports and art data applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Smart IoT information transmission and
security optimization model based on chaotic neural computing.
<em>NCA</em>, <em>35</em>(5), 4197. (<a
href="https://doi.org/10.1007/s00521-022-08156-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Deng, Lianbing and Li, Daming and Cai, Zhiming and Hong, Lin},
  doi          = {10.1007/s00521-022-08156-7},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4197},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Smart IoT information transmission and security optimization model based on chaotic neural computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Retraction note: Research on image classification method
based on convolutional neural network. <em>NCA</em>, <em>35</em>(5),
4195. (<a href="https://doi.org/10.1007/s00521-022-08155-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Li, Daming and Deng, Lianbing and Cai, Zhiming},
  doi          = {10.1007/s00521-022-08155-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4195},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Research on image classification method based on convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Hybrid method for mining rules based on
enhanced apriori algorithm with sequential minimal optimization in
healthcare industry. <em>NCA</em>, <em>35</em>(5), 4193. (<a
href="https://doi.org/10.1007/s00521-022-08154-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sornalakshmi, M. and Balamurali, S. and Venkatesulu, M. and Krishnan, M. Navaneetha and Ramasamy, Lakshmana Kumar and Kadry, Seifedine and Manogaran, Gunasekaran and Hsu, Ching-Hsien and Muthu, Bala Anand},
  doi          = {10.1007/s00521-022-08154-9},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4193},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Hybrid method for mining rules based on enhanced apriori algorithm with sequential minimal optimization in healthcare industry},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Machine learning in explaining nonprofit
organizations’ participation: A driving factors analysis approach.
<em>NCA</em>, <em>35</em>(5), 4191. (<a
href="https://doi.org/10.1007/s00521-022-08153-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Gong, Zhanxue and Li, Xiyuan and Liu, Jiawen and Gong, Yeming},
  doi          = {10.1007/s00521-022-08153-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4191},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: machine learning in explaining nonprofit organizations’ participation: a driving factors analysis approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: An efficient technique for mitigating
stealthy attacks using MNDA in MANET. <em>NCA</em>, <em>35</em>(5),
4189. (<a href="https://doi.org/10.1007/s00521-022-08152-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Muruganandam, D. and Manickam, J. Martin Leo},
  doi          = {10.1007/s00521-022-08152-x},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4189},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: An efficient technique for mitigating stealthy attacks using MNDA in MANET},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Risk analysis method of bank microfinance
based on multiple genetic artificial neural networks. <em>NCA</em>,
<em>35</em>(5), 4187. (<a
href="https://doi.org/10.1007/s00521-022-08151-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhong, Xiong and Zhou, Sheng},
  doi          = {10.1007/s00521-022-08151-y},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4187},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Risk analysis method of bank microfinance based on multiple genetic artificial neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Optimization analysis of sport pattern
driven by machine learning and multi-agent. <em>NCA</em>,
<em>35</em>(5), 4185. (<a
href="https://doi.org/10.1007/s00521-022-08150-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Wang, Hao and Dong, Chen and Fu, Yuming},
  doi          = {10.1007/s00521-022-08150-z},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4185},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Optimization analysis of sport pattern driven by machine learning and multi-agent},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Retraction note: Intelligent traffic monitoring and traffic
diagnosis analysis based on neural network algorithm. <em>NCA</em>,
<em>35</em>(5), 4183. (<a
href="https://doi.org/10.1007/s00521-022-08149-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Wang, Yantao and Wang, Quan and Suo, Daxiang and Wang, Tiezheng},
  doi          = {10.1007/s00521-022-08149-6},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4183},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Intelligent traffic monitoring and traffic diagnosis analysis based on neural network algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward human activity recognition: A survey. <em>NCA</em>,
<em>35</em>(5), 4145–4182. (<a
href="https://doi.org/10.1007/s00521-022-07937-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a complex and multifaceted problem. The research community has reported numerous approaches to perform HAR. Along with HAR approaches, various surveys have revealed HAR trends in various environments and applications. HAR is linked to a variety of technology-dependent daily life systems, such as human–computer interaction systems, security surveillance, video surveillance, healthcare surveillance, robotics, content-based information retrieval, and monitoring systems. Because of technological advancements, HAR trends change quickly and necessitate an up-to-date and broader perspective. This study offers an HAR taxonomy, which includes online/offline HAR, multimodal/unimodal HAR, handcrafted feature-based, and learning-based approaches. This study attempts to present the multidisciplinary nature of HAR, such as application areas, activity types, task complexities, benchmark datasets, and/methods. This research includes a comparative analysis of state-of-the-art HAR methods and a discussion of popular datasets. The selected studies have been categorized using taxonomy, and different attributes such as activity complexity, dataset size, and recognition rate have been used for their analysis. The comparative analysis of HAR approaches has also helped to highlight domain challenges and open research directions for HAR researchers to follow.},
  archive      = {J_NCA},
  author       = {Saleem, Gulshan and Bajwa, Usama Ijaz and Raza, Rana Hammad},
  doi          = {10.1007/s00521-022-07937-4},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4145-4182},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward human activity recognition: A survey},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bipartite leader–follower consensus for nonlinear signed
networks with impulsive control. <em>NCA</em>, <em>35</em>(5),
4133–4143. (<a
href="https://doi.org/10.1007/s00521-022-07860-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bipartite leader–follower consensus for nonlinear signed networks with impulse control is investigated. Based on the controllability of leader–follower, the leader selection scheme is given for different nonlinear cases, and the inclusion of a dynamic control set allows the impulsive control of leader–follower to control the whole system. In the framework of Lyapunov’s stability method, sufficient conditions for bipartite leader–follower consensus and stability based on time and event triggers are derived. The combination of impulsive control and leader–follower controllability reduces the cost of control, and the choice of leaders’ sets is easier to use compared to pinning control. This makes our study more practical. Finally, four numerical examples validate the correctness of the proposed control strategy.},
  archive      = {J_NCA},
  author       = {Zhou, Zichuan and Zhang, Wei and Xiu, Ruihong},
  doi          = {10.1007/s00521-022-07860-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4133-4143},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bipartite leader–follower consensus for nonlinear signed networks with impulsive control},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gazelle optimization algorithm: A novel nature-inspired
metaheuristic optimizer. <em>NCA</em>, <em>35</em>(5), 4099–4131. (<a
href="https://doi.org/10.1007/s00521-022-07854-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel population-based metaheuristic algorithm called the Gazelle Optimization Algorithm (GOA), inspired by the gazelles’ survival ability in their predator-dominated environment. Every day, the gazelle knows that if it does not outrun and outmaneuver its predators, it becomes meat for the day, and to survive, the gazelles have to escape from their predators consistently. This information is vital to proposing a new metaheuristic algorithm that uses the gazelle’s survival abilities to solve real-world optimization problems. The exploitation phase of the algorithm simulates the gazelles grazing peacefully in the absence of the predator or while the predator is stalking it. The GOA goes into the exploration phase once a predator is spotted. The exploration phase consists of the gazelle outrunning and outmaneuvering the predator to a safe haven. These two phases are iteratively repeated, subject to the termination criteria, and finding optimal solutions to the optimization problems. The robustness and efficiency of the developed algorithm as an optimization tool were tested using benchmark optimization test functions and selected engineering design problems (fifteen classical, ten composited functions, and four mechanical engineering design problems). The results of the GOA are compared with nine other state-of-the-art algorithms. The simulation results obtained confirm the superiority and competitiveness of the GOA algorithm over nine state-of-the-art algorithms available in the literature. Also, the standard statistical analysis test carried out on the results further confirmed the ability of GOA to find solutions to the selected optimization problems. It also showed that GOA performed better or, in some cases, was very competitive with some state-of-the-art algorithms. Also, the results show that GOA is a potent tool for optimization that can be adapted to solve problems in different optimization domains.},
  archive      = {J_NCA},
  author       = {Agushaka, Jeffrey O. and Ezugwu, Absalom E. and Abualigah, Laith},
  doi          = {10.1007/s00521-022-07854-6},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4099-4131},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gazelle optimization algorithm: A novel nature-inspired metaheuristic optimizer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anomaly detection for process monitoring based on machine
learning technique. <em>NCA</em>, <em>35</em>(5), 4073–4097. (<a
href="https://doi.org/10.1007/s00521-022-07901-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is critical to process modeling, monitoring, and control since successful execution of these engineering tasks depends on access to validated data. The industrial process is uncertain in several situations, and the available information is formalized in terms of intervals. This article deals with the diagnostic of uncertain systems by multivariate static analysis. Linear Principal Component Analysis (PCA) and nonlinear Kernel PCA (KPCA) are generally used to deal with certain systems; they exploit single-valued variables. While in real situations these data are marred by uncertainties, these uncertainties cause difficulties in making decision in relation to the presence of defects. Thus, we have studied a recent and robust solution which consists in capturing the variability of multivariate observations by interval variables. In the first part, we treated a fault detection strategy based on interval PCA in the case of static linear systems. It includes first of all a comparative study between the deferent methods of detection of faults with interval PCA in which we proposed a new detection statistics of faults. In the second part, we studied a fault detection strategy based on interval KPCA method; we propose a reduction approach to solve the problem of nonlinearity and uncertainty and the problem of large data. The proposed fault detection methods are illustrated by synthetic data with an in-depth study and comparison using simulations of the air quality monitoring network and the Tennessee Eastman process.},
  archive      = {J_NCA},
  author       = {Hamrouni, Imen and Lahdhiri, Hajer and Ben Abdellafou, Khaoula and Aljuhani, Ahamed and Taouali, Okba},
  doi          = {10.1007/s00521-022-07901-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4073-4097},
  shortjournal = {Neural Comput. Appl.},
  title        = {Anomaly detection for process monitoring based on machine learning technique},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utilizing the roulette wheel based social network search
algorithm for substitution box construction and optimization.
<em>NCA</em>, <em>35</em>(5), 4051–4071. (<a
href="https://doi.org/10.1007/s00521-022-07899-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new variant of a recent metaheuristic algorithm based on the Social Network Search algorithm (SNS), which is called the Roulette Wheel Social Network Search algorithm (SNS). As the name indicates, the main feature of RWSNS is the fact that the algorithm allows proportionate selection of its search operators (i.e., from imitation, conversation, disputation and innovation) through exploiting the roulette wheel. Additionally, RWSNS also incorporates the Piecewise map as replacement for the pseudo random generator during the population initialisation to ensure high nonlinearity and allow further solution diversification. Finally, unlike its predecessor, RWSNS also permits the systematic manipulation of candidate solutions around the global best agent through the swap operator to boost its search intensification process, as the global best candidate solution is often clustered and always lurking around the current local best. Results based on the construction of 8 × 8 substitution-box demonstrate that the proposed RWSNS exceeds other competing metaheuristic algorithms in two main S-box criteria, namely, the average nonlinearity score and strict avalanche criteria (i.e., SAC offset), whilst maintaining a commendable performance on bits independence criteria, differential approximation probability and linear approximation probability.},
  archive      = {J_NCA},
  author       = {Zamli, Kamal Z. and Alhadawi, Hussam S. and Din, Fakhrud},
  doi          = {10.1007/s00521-022-07899-7},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4051-4071},
  shortjournal = {Neural Comput. Appl.},
  title        = {Utilizing the roulette wheel based social network search algorithm for substitution box construction and optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disturbance-observer-based adaptive dynamic surface control
for nonlinear systems with input dead-zone and delay using neural
networks. <em>NCA</em>, <em>35</em>(5), 4027–4049. (<a
href="https://doi.org/10.1007/s00521-022-07865-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disturbance-observer-based adaptive neural control approach is proposed for nonlinear systems. Considering the effect caused by long input delay and dead-zone, a novel auxiliary system has been introduced to degrade the design difficult. Based on the auxiliary system, a novel disturbance observer is developed to estimate the unknown time-varying external disturbance and the approximation error. What is more, the priori knowledge on the boundary of the disturbance and approximation error is not required for the disturbance observer. The “explosion of complexity” problem has been overcome by using dynamic surface control (DSC) scheme. By combing DSC scheme with backstepping technique, an adaptive neural dynamic surface controller is correctly devised to improve the disturbance rejection performance of the closed-loop system. Finally, the simulations of two examples show the superiority of the proposed scheme.},
  archive      = {J_NCA},
  author       = {Zhai, Junchang and Wang, Huanqing and Tao, Jiaqing},
  doi          = {10.1007/s00521-022-07865-3},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4027-4049},
  shortjournal = {Neural Comput. Appl.},
  title        = {Disturbance-observer-based adaptive dynamic surface control for nonlinear systems with input dead-zone and delay using neural networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DRE: Density-based data selection with entropy for
adversarial-robust deep learning models. <em>NCA</em>, <em>35</em>(5),
4009–4026. (<a
href="https://doi.org/10.1007/s00521-022-07812-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning helps software developers reduce the labeling cost when building high-quality machine learning models. A core component of active learning is the acquisition function that determines which data should be selected to annotate.State-of-the-art (SOTA) acquisition functions focus on clean performance (e.g. accuracy) but disregard robustness (an important quality property), leading to fragile models with negligible robustness (less than 0.20\%). In this paper, we first propose to integrate adversarial training into active learning (adversarial-robust active learning, ARAL) to produce robust models. Our empirical study on 11 acquisition functions and 15105 trained deep neural networks (DNNs) shows that ARAL can produce models with robustness ranging from 2.35\% to 63.85\%. Our study also reveals, however, that the acquisition functions that perform well on accuracy are worse than random sampling when it comes to robustness. Via examining the reasons behind this, we devise the density-based robust sampling with entropy (DRE) to target both clean performance and robustness. The core idea of DRE is to maintain a balance between selected data and the entire set based on the entropy density distribution. DRE outperforms SOTA functions in terms of robustness by up to 24.40\%, while remaining competitive on accuracy. Additionally, the in-depth evaluation shows that DRE is applicable as a test selection metric for model retraining and stands out from all compared functions by up to 8.21\% robustness.},
  archive      = {J_NCA},
  author       = {Guo, Yuejun and Hu, Qiang and Cordy, Maxime and Papadakis, Michail and Le Traon, Yves},
  doi          = {10.1007/s00521-022-07812-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {4009-4026},
  shortjournal = {Neural Comput. Appl.},
  title        = {DRE: Density-based data selection with entropy for adversarial-robust deep learning models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Travel time prediction based on route links’ similarity.
<em>NCA</em>, <em>35</em>(5), 3991–4007. (<a
href="https://doi.org/10.1007/s00521-022-07926-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate travel time prediction allows passengers to schedule their journeys efficiently. However, cyclical factors (time intervals of the day, weather conditions, and holidays), unpredictable factors (incidents, abnormal weather), and other complicated factors (dynamic traffic conditions, dwell times, and variation in travel demand) make accurate bus travel time prediction complicated. This paper aims to achieve accurate travel time prediction. To do so, we propose a clustering method that identifies travel time paradigms of different route links and clusters them based on their similarity using the nonnegative matrix factorization algorithm. Additionally, we propose a deep learning model based on CNN with spatial–temporal attention and gating mechanisms to select the most relevant features and capture their dependencies and correlations. For each defined cluster, we train a separate model to predict the travel time at various time intervals over the day. As a result, the travel times of all journey links from related prediction models are aggregated to predict the total journey time. Extensive experiments using data collected from four different bus lines in Beijing show that our method outperforms the compared baselines.},
  archive      = {J_NCA},
  author       = {Alkilane, Khaled and Alfateh, M. Tag Elsir and Yanming, Shen},
  doi          = {10.1007/s00521-022-07926-7},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3991-4007},
  shortjournal = {Neural Comput. Appl.},
  title        = {Travel time prediction based on route links’ similarity},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Segmentation on remote sensing imagery for atmospheric air
pollution using divergent differential evolution algorithm.
<em>NCA</em>, <em>35</em>(5), 3977–3990. (<a
href="https://doi.org/10.1007/s00521-022-07922-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution is a global issue causing major health hazards. By proper monitoring of air quality, actions can be taken to control air pollution. Satellite remote sensing is an effective way to monitor global atmosphere. Various sensors and instruments fitted to satellites and airplanes are used to obtain the radar images. These images are quite complex with various wavelength differentiated by very close color differences. Clustering of such images based on its wavelengths can provide the much-needed relief in better understanding of these complex images. Such task related to image segmentation is a universal optimization issue that can be resolved with evolutionary techniques. Differential Evolution (DE) is a fairly fast and operative parallel search algorithm. Though classical DE algorithm is popular, there is a need for varying the mutation strategy for enhancing the performance for varied applications. Several alternatives of classical DE are considered by altering the trial vector and control parameter. In this work, a new alteration of DE technique labeled as DiDE (Divergent Differential Evolution Algorithm) is anticipated. The outcomes of this algorithm were tested and verified with the traditional DE techniques using fifteen benchmark functions. The new variant DiDE exhibited much superior outcomes compared to traditional approaches. The novel approach was then applied on remote sensing imagery collected form TEMIS, a web based service for atmospheric satellite images and the image was segmented. Fuzzy Tsallis entropy method of multi-level thresholding technique is applied over DiDE to develop image segmentation. The outcomes obtained were related with the segmented results using traditional DE and the outcome attained was found to be improved profoundly. Experimental results illustrate that by acquainting DiDE in multilevel thresholding, the computational delay was greatly condensed and the image quality was significantly improved.},
  archive      = {J_NCA},
  author       = {Ramadas, Meera and Abraham, Ajith},
  doi          = {10.1007/s00521-022-07922-x},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3977-3990},
  shortjournal = {Neural Comput. Appl.},
  title        = {Segmentation on remote sensing imagery for atmospheric air pollution using divergent differential evolution algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning regression approach for analysis of bearing
capacity of conical foundations in heterogenous and anisotropic clays.
<em>NCA</em>, <em>35</em>(5), 3955–3976. (<a
href="https://doi.org/10.1007/s00521-022-07893-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An upper bound (UB) and lower bound (LB) finite element limit analysis cooperating with a machine learning method is adopted as a new solution for predicting the bearing capacity of conical foundations embedded in anisotropic and heterogenous clays. The anisotropic and heterogenous clays are simulated by anisotropic undrained strength (AUS) model for capturing the anisotropic strengths of clays. The bearing capacity of the conical foundation is investigated using the dimensionless parameter approach. The bearing capacity factors, as well as the failure mechanisms of conical foundations, are examined through 1296 numerical cases with changing of four input dimensionless parameters, namely cone apex angle, embedded depth ratio, the anisotropic ratio, and the strength gradient ratio. Based on numerical results, a machine learning technique of multivariate adaptive regression splines (MARS) model is used for accessing the sensitivity of each investigated dimensionless parameter and functioning the relationship between input parameters and output bearing capacity factors. The results of the analysis are prepared in charts, design tables, and empirical equations from MARS. The paper can be the theory guidelines for initial design and provide an effective tool for practitioners in determining the bearing capacity of conical foundation embedded in anisotropic and heterogenous clays.},
  archive      = {J_NCA},
  author       = {Nguyen Van, Chung and Keawsawasvong, Suraparb and Nguyen, Dang Khoa and Lai, Van Qui},
  doi          = {10.1007/s00521-022-07893-z},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3955-3976},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning regression approach for analysis of bearing capacity of conical foundations in heterogenous and anisotropic clays},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated intuitionistic fuzzy set and stochastic
multi-criteria acceptability analysis approach for supplier selection.
<em>NCA</em>, <em>35</em>(5), 3937–3953. (<a
href="https://doi.org/10.1007/s00521-022-07919-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the challenging and complicate processes in supply chain management is to select best supplier from the set of suppliers since they have direct and indirect effects on the core functions of the companies. The supplier selection problem is generally accepted as multi-criteria decision-making (MCDM) since it includes conflict criteria which include uncertain and ambiguous data. Therefore, fuzzy set and its extensions such as intuitionistic fuzzy set have been integrated with MCDM methods in past two decades as they have great capability to handle uncertainty. In this study, hybrid method based on intuitionistic fuzzy preference relation (IFPR) and stochastic multi-criteria acceptability analysis (SMAA-2) is introduced to select best supplier. In the first stage, IFPR is exploited to obtain the criteria weights using the preference of decision-makers (DMs). SMAA-2 method has been utilized to rank alternatives which are rated based on the individual preferences of DMs. The proposed method has been implemented to the selection of the most suitable supplier for effective purchasing the vehicle rental service needed by the armed forces considering the eight criteria. Furthermore, sensitivity analysis has been conducted under eight different scenarios obtained by changing the criteria weights. The results illustrate that IFPR-SMAA-2 method is more capable of discriminating in ranking of alternatives and provides more reliable solutions.},
  archive      = {J_NCA},
  author       = {İlbaş, Ahmet and Gürdere, Atilla and Boran, Fatih Emre},
  doi          = {10.1007/s00521-022-07919-6},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3937-3953},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated intuitionistic fuzzy set and stochastic multi-criteria acceptability analysis approach for supplier selection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-rank GAT: Toward robust quantification of neighborhood
influence. <em>NCA</em>, <em>35</em>(5), 3925–3936. (<a
href="https://doi.org/10.1007/s00521-022-07914-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph attention networks stack self-attention layers to compute the neighbor-specific weights. Due to inherent noise and artificially correlated dimensions, attention scores fail to create optimal linear combinations for feature aggregation from the neighborhood. Multiple attention heads solve the problem to an extent but at the cost of additional memory overhead and larger variance in results. In this work, we introduce a novel concept of computing attention scores using a low-rank approximation of the intended neighborhood. The sub-space feature representation of the neighborhood discards the adverse effect of noise and artificially correlated dimensions. Extensive experiments on graph datasets show that the proposed framework outperforms the state-of-the-art methods. The reduced variance in our metrics Kruskal–Wallis test also indicates that the proposed model is able to give stable results as compared to other state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Yadav, Rakesh Kumar and Abhishek and Verma, Abhishek and Shukla, Prashant and Verma, Katyayani and Verma, Shekhar},
  doi          = {10.1007/s00521-022-07914-x},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3925-3936},
  shortjournal = {Neural Comput. Appl.},
  title        = {Low-rank GAT: Toward robust quantification of neighborhood influence},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boosting archimedes optimization algorithm using
trigonometric operators based on feature selection for facial analysis.
<em>NCA</em>, <em>35</em>(5), 3903–3923. (<a
href="https://doi.org/10.1007/s00521-022-07925-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to technical advancements and the proliferation of mobile applications, facial analysis (FA) of humans has recently become an important area for computer vision research. FA investigates a variety of difficulties, including gender recognition, facial expression recognition, age and race recognition, with the goal of automatically comprehending social interactions. Due to the dimensional challenge posed by pre-trained CNN networks, the scientific community has developed numerous techniques inspired by biology, swarm intelligence theory, physics, and mathematical rules. This article presents a gender recognition system based on scAOA, that is a modified version of the Archimedes optimization algorithm (AOA). The latest variant (scAOA) enhances the exploitation stage by using trigonometric operators inspired by the sine cosine algorithm (SCA) in order to prevent local optima and to accelerate the convergence. The main purpose of this paper is to apply scAOA to select the relevant deep features provided by two pretrained models of CNN (AlexNet &amp; ResNet) to recognize the gender of a human person categorized into two classes (men and women). Two datasets are used to evaluate the proposed approach (scAOA): the Brazilian FEI dataset and the Georgia Tech Face dataset (GT). In terms of accuracy, Fscore and statistical test, the comparison analysis demonstrates that scAOA outperforms other modern and competitive optimizers such as AOA, SCA, Ant lion optimizer (ALO), Salp swarm algorithm (SSA), Grey wolf optimizer (GWO), Simple genetic algorithm (SGA), Grasshopper optimization algorithm (GOA) and Particle swarm optimizer (PSO).},
  archive      = {J_NCA},
  author       = {Neggaz, Imène and Neggaz, Nabil and Fizazi, Hadria},
  doi          = {10.1007/s00521-022-07925-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3903-3923},
  shortjournal = {Neural Comput. Appl.},
  title        = {Boosting archimedes optimization algorithm using trigonometric operators based on feature selection for facial analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint semantic embedding with structural knowledge and
entity description for knowledge representation learning. <em>NCA</em>,
<em>35</em>(5), 3883–3902. (<a
href="https://doi.org/10.1007/s00521-022-07923-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous works mainly employ triple structural information in learning representations for knowledge graph, which results in poor performance of link prediction especially when it predicts new or few-fact entities. It is intuitive to introduce text information to supplement the missing semantic information for knowledge representation. However, existing methods only make alignment on the level of word or score function, and have not yet considered textual and structural information. Moreover, since the textual information is potentially redundant to represent the entities, how to extract relevant information and simultaneously alleviate the irrelevant information contained in the text is a challenging task. To tackle the above problems, this paper proposes a novel knowledge representation learning framework of joint semantic embedding using structural knowledge and entity description (JointSE). Firstly, we design a mutual attention mechanism to filter the effective information of fact triples and entity descriptions with respect to specific relationships. Secondly, we project the triples into the text semantic space using dot product to connect the triple with the relevant text description. In addition, we enhance triple-based entity representation and text-based entity representation using graph neural network to capture more useful graph structure information. Finally, extensive experiments on benchmark datasets and Chinese legal provisions dataset demonstrate that JointSE realizes the effective fusion of triple information, text semantic information, and graph structure information. We observe that JointSE is superior to previous methods in entity prediction and relationship prediction tasks.},
  archive      = {J_NCA},
  author       = {Wei, Xiao and Zhang, Yunong and Wang, Hao},
  doi          = {10.1007/s00521-022-07923-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3883-3902},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint semantic embedding with structural knowledge and entity description for knowledge representation learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiobjective problem modeling of the capacitated vehicle
routing problem with urgency in a pandemic period. <em>NCA</em>,
<em>35</em>(5), 3865–3882. (<a
href="https://doi.org/10.1007/s00521-022-07921-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research is based on the capacitated vehicle routing problem with urgency where each vertex corresponds to a medical facility with a urgency level and the traveling vehicle could be contaminated. This contamination is defined as the infectiousness rate, which is defined for each vertex and each vehicle. At each visited vertex, this rate for the vehicle will be increased. Therefore time-total distance it is desired to react to vertex as fast as possible- and infectiousness rate are main issues in the problem. This problem is solved with multiobjective optimization algorithms in this research. As a multiobjective problem, two objectives are defined for this model: the time and the infectiousness, and will be solved using multiobjective optimization algorithms which are nondominated sorting genetic algorithm (NSGAII), grid-based evolutionary algorithm GrEA, hypervolume estimation algorithm HypE, strength Pareto evolutionary algorithm shift-based density estimation SPEA2-SDE, and reference points-based evolutionary algorithm.},
  archive      = {J_NCA},
  author       = {Altinoz, Mehmet and Altinoz, O. Tolga},
  doi          = {10.1007/s00521-022-07921-y},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3865-3882},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multiobjective problem modeling of the capacitated vehicle routing problem with urgency in a pandemic period},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot learning for modeling cyber physical systems in
non-stationary environments. <em>NCA</em>, <em>35</em>(5), 3853–3863.
(<a href="https://doi.org/10.1007/s00521-022-07903-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a modeling scheme for cyber physical systems operating in non-stationary, small data environments. Unlike the traditional modeling logic, we introduce the few-shot learning paradigm, the operation of which is based on quantifying both similarities and dissimilarities. As such, we designed a suitable change detection mechanism able to reveal previously unknown operational states, which are incorporated in the dictionary online. We elaborate on spectrograms extracted from high-resolution ultrasound depth sensor timeseries, while the backbone of the proposed method is a Siamese Neural Network. The experimental scenario considers data representing liquid containers for fuel/water when the following five operational states are present: normal, accident, breakdown, sabotage, and cyber-attack. Thorough experiments were carried out assessing every aspect of the present framework and demonstrating its efficacy even when very few samples per class are available. In addition, we propose a probabilistic data selection scheme facilitating one-shot learning. Last but not least, responding to the wide requirement for interpretable AI, we explain the obtained predictions by examining the layer-wise activation maps.},
  archive      = {J_NCA},
  author       = {Ntalampiras, Stavros and Potamitis, Ilyas},
  doi          = {10.1007/s00521-022-07903-0},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3853-3863},
  shortjournal = {Neural Comput. Appl.},
  title        = {Few-shot learning for modeling cyber physical systems in non-stationary environments},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel whale optimization algorithm optimized XGBoost
regression for estimating bearing capacity of concrete piles.
<em>NCA</em>, <em>35</em>(5), 3825–3852. (<a
href="https://doi.org/10.1007/s00521-022-07896-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a hybrid model combining the extreme gradient boosting machine (XGBoost) and the whale optimization algorithm (WOA) to predict the bearing capacity of concrete piles. The XGBoost provides the ultimate prediction from a set of explanatory experiment variables. The WOA, which is configured to search for an optimal set of XGBoost parameters, helps increase the model’s accuracy and robustness. The hybrid method is constructed by a dataset of 472 samples collected from static load tests in Vietnam. The results indicate that the hybrid model consistently outperforms the default XGBoost model and deep neural network (DNN) regression. In an experiment of 20 runs, the proposed model has gained roughly 12, 11.7, 9, and 12\% reductions in root mean square error compared to the DNN with 2, 3, 4, and 5 hidden layers, respectively. The Wilcoxon signed-rank tests confirm that the proposed model is highly suitable for concrete pile capacity prediction.},
  archive      = {J_NCA},
  author       = {Nguyen, Hieu and Cao, Minh-Tu and Tran, Xuan-Linh and Tran, Thu-Hien and Hoang, Nhat-Duc},
  doi          = {10.1007/s00521-022-07896-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3825-3852},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel whale optimization algorithm optimized XGBoost regression for estimating bearing capacity of concrete piles},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated fabric inspection through convolutional neural
network: An approach. <em>NCA</em>, <em>35</em>(5), 3805–3823. (<a
href="https://doi.org/10.1007/s00521-022-07891-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automating the fabric inspection process has been attempted by several researchers in the past. However, the numerous variants of fabric, such as their construction, texture, print, and colour along with the huge gamut of fabric defects which exist, complicate the process of automating defect detection, thus making it an open challenge for researchers to come up with a one-stop, full proof robust automation solution. In the present study, an attempt has been made to detect, classify, and locate four different types of fabric defects on solid wovens, hole, knot, slub and stain, which contributes 86\% of total fabric defects; using the convolutional neural network (CNN) through transfer learning on the MATLAB® platform and computer vision technology. The image dataset in this study consists of 5000 images, which is one of the largest reported till date and collected from real working environments of different apparel manufacturing units. The methodology involves four different approaches—detection approach, hierarchical approach, classification approach, and object location approach. For algorithm development, transfer learning has been adopted in which the pre-trained deep learning architectures are fine-tuned as per specific case requirement. In this study, 4 state-of-the-art deep learning models were selected as follows: VGG16, VGG19, ResNet101 and DarkNet53. This study not only focuses on defect detection and classification but also on defect location which is detailed in its fourth approach. For object location, YOLOv3 architecture was used. The defect detection, classification and location identification systems attained an accuracy of 95\%, 88\% and 97\%, respectively. The developed model was tested on different platforms viz. Internet-based webcam and MATLAB® cloud. Detailed investigation towards challenges faced by models specific to class of defect was carried out and reported thus adding insights for probable modification required in the model. The study proposes an industry ready system for real-time implementation.},
  archive      = {J_NCA},
  author       = {Thakur, Rashmi and Panghal, Deepak and Jana, Prabir and Rajan and Prasad, Ankit},
  doi          = {10.1007/s00521-022-07891-1},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3805-3823},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated fabric inspection through convolutional neural network: An approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DAE-PINN: A physics-informed neural network model for
simulating differential algebraic equations with application to power
networks. <em>NCA</em>, <em>35</em>(5), 3789–3804. (<a
href="https://doi.org/10.1007/s00521-022-07886-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based surrogate modeling is becoming a promising approach for learning and simulating dynamical systems. However, deep-learning methods find it very challenging to learn stiff dynamics. In this paper, we develop DAE-PINN, the first effective physics-informed deep-learning framework for learning and simulating the solution trajectories of nonlinear differential-algebraic equations (DAE). DAEs are used to model complex engineering systems, e.g., power networks, and present a “form” of infinite stiffness, which makes learning their solution trajectories challenging. Our DAE-PINN bases its effectiveness on the synergy between implicit Runge–Kutta time-stepping schemes (designed specifically for solving DAEs) and physics-informed neural networks (PINN) (deep neural networks that we train to satisfy the dynamics of the underlying problem). Furthermore, our framework (i) enforces the neural network to satisfy the DAEs as (approximate) hard constraints using a penalty-based method and (ii) enables simulating DAEs for long-time horizons. We showcase the effectiveness and accuracy of DAE-PINN by learning the solution trajectories of a three-bus power network.},
  archive      = {J_NCA},
  author       = {Moya, Christian and Lin, Guang},
  doi          = {10.1007/s00521-022-07886-y},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3789-3804},
  shortjournal = {Neural Comput. Appl.},
  title        = {DAE-PINN: A physics-informed neural network model for simulating differential algebraic equations with application to power networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dual decomposition strategy for large-scale multiobjective
evolutionary optimization. <em>NCA</em>, <em>35</em>(5), 3767–3788. (<a
href="https://doi.org/10.1007/s00521-022-08133-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective evolutionary algorithms (MOEAs) have received much attention in multiobjective optimization in recent years due to their practicality. With limited computational resources, most existing MOEAs cannot efficiently solve large-scale multiobjective optimization problems (LSMOPs) that widely exist in the real world. This paper innovatively proposes a dual decomposition strategy (DDS) that can be embedded into many existing MOEAs to improve their performance in solving LSMOPs. Firstly, the outer decomposition uses a sliding window to divide large-scale decision variables into overlapped subsets of small-scale ones. A small-scale multiobjective optimization problem (MOP) is generated every time the sliding window slides. Then, once a small-scale MOP is generated, the inner decomposition immediately creates a set of global direction vectors to transform it into a set of single-objective optimization problems (SOPs). At last, all SOPs are optimized by adopting a block coordinate descent strategy, ensuring the solution’s integrity and improving the algorithm’s performance to some extent. Comparative experiments on benchmark test problems with seven state-of-the-art evolutionary algorithms and a deep learning-based algorithm framework have shown the remarkable efficiency and solution quality of the proposed DDS. Meanwhile, experiments on two real-world problems show that DDS can achieve the best performance beyond at least one order of magnitude with up to 3072 decision variables.},
  archive      = {J_NCA},
  author       = {Yang, Cuicui and Wang, Peike and Ji, Junzhong},
  doi          = {10.1007/s00521-022-08133-0},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3767-3788},
  shortjournal = {Neural Comput. Appl.},
  title        = {A dual decomposition strategy for large-scale multiobjective evolutionary optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient locality-sensitive hashing over high-dimensional
streaming data. <em>NCA</em>, <em>35</em>(5), 3753–3766. (<a
href="https://doi.org/10.1007/s00521-020-05336-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate nearest neighbor (ANN) search in high-dimensional spaces is fundamental in many applications. Locality-sensitive hashing (LSH) is a well-known methodology to solve the ANN problem. Existing LSH-based ANN solutions typically employ a large number of individual indexes optimized for searching efficiency. Updating such indexes might be impractical when processing high-dimensional streaming data. In this paper, we present a novel disk-based LSH index that offers efficient support for both searches and updates. The contributions of our work are threefold. First, we use the write-friendly LSM-trees to store the LSH projections to facilitate efficient updates. Second, we develop a novel estimation scheme to estimate the number of required LSH functions, with which the disk storage and access costs are effectively reduced. Third, we exploit both the collision number and the projection distance to improve the efficiency of candidate selection, improving the search performance with theoretical guarantees on the result quality. Experiments on four real-world datasets show that our proposal outperforms the state-of-the-art schemes.},
  archive      = {J_NCA},
  author       = {Wang, Hao and Yang, Chengcheng and Zhang, Xiangliang and Gao, Xin},
  doi          = {10.1007/s00521-020-05336-1},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3753-3766},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient locality-sensitive hashing over high-dimensional streaming data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scale-free heterogeneous cycleGAN for defogging from a
single image for autonomous driving in fog. <em>NCA</em>,
<em>35</em>(5), 3737–3751. (<a
href="https://doi.org/10.1007/s00521-021-06296-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, convolutional neural networks have been widely used in image defogging and achieved remarkable performance. However, most of the learning-based defogging methods using pairs of synthetic foggy and corresponding ground-truth images for training. Due to the gap between the distribution of real-word foggy and synthetic foggy images, there are limits to apply these defogging methods to autonomous driving in practice. CycleGAN is a two-way GANs network that could using unpaired real-word images to train image defogging models. However, there are several problems when CycleGAN is directly used for image defogging: (1) Using two different distributed data to train the same generator will confuse the learning of generators, which reduce the convergence speed and defogging results of the network. (2) The generator ignores the global features exploration which is very important for learning the scene and lighting information and needs the post-processing to restore the original image scales, which will result in a decrease in the quality of the generated image. To address these issues, we propose a Scale-free Heterogeneous CycleGAN (SH-CycleGAN) to utilize unpaired real-word images for boosting image defogging. The SH-CycleGAN contains a Heterogeneous Learning CycleGAN (HLCG) framework, and a generator with a Global Features Fusion module and an Adaptive Pooling module(GFFAP). Specifically, in the proposed HLCF framework, each BatchNorm layer learning in the generator is independent, which can solve the problem of confusion caused by learning different distributed data. Furthermore, the development of the GFFAP model can deal with image of any scales and improve the generated images. The experiments compared with eight state-of-the-art image defogging methods on both synthetic and real-world images demonstrate that our proposed method outperforms state-of-the-art performance and obtains more pleasing visually defogging results.},
  archive      = {J_NCA},
  author       = {Sun, Hang and Zhang, Yan and Chen, Peng and Dan, Zhiping and Sun, Shuifa and Wan, Jun and Li, Weisheng},
  doi          = {10.1007/s00521-021-06296-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3737-3751},
  shortjournal = {Neural Comput. Appl.},
  title        = {Scale-free heterogeneous cycleGAN for defogging from a single image for autonomous driving in fog},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). PAENL: Personalized attraction enhanced network learning
for recommendation. <em>NCA</em>, <em>35</em>(5), 3725–3735. (<a
href="https://doi.org/10.1007/s00521-021-05812-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reviews and user–item interactions have been widely used to predict the behaviors of users. However, the sparsity of user–item interactions on datasets remains a major challenge in predicting user behavior. Most of the fusion user–item information and review information is predicted for user behavior prediction in a linear sense. However, this coarse-grained data fusion encounters difficulty in finding the complex relationship between different modal features. In this study, we propose a personalized attraction enhanced network learning for recommendation PAENL. The model consists of two modules: a user–item feature learning module and a review feature interaction module. In addition to the capability of modeling heterogeneity information by convolutional neural networks, PAENL can capture the essence of different users’ emotional reviews by the attention neural model in a nonlinear sense. Experiments are conducted on three real datasets and compared with a variety of mainstream advanced algorithms. The results demonstrate that the proposed algorithm PAENL significantly outperforms all state-of-the-art methods, and the attention mechanism can increase the interpretability of the user behavior prediction.},
  archive      = {J_NCA},
  author       = {Xu, Yangyang and Wang, Zengmao and Shang, Jedi S.},
  doi          = {10.1007/s00521-021-05812-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3725-3735},
  shortjournal = {Neural Comput. Appl.},
  title        = {PAENL: Personalized attraction enhanced network learning for recommendation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geo-SPS: Bipartite graph representation for GeoSpatial
prenatal survey data. <em>NCA</em>, <em>35</em>(5), 3709–3724. (<a
href="https://doi.org/10.1007/s00521-021-06371-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstetric studies had long revealed that the human female mental state, although subjective, has a nonlinear relation to the gestation, which could eventually leads to eugenics characteristics. Due to the difference of regions, there are differences between the data, people want to analyze the correlation between the survey data of different regions. Traditional obstetric studies explore health information on understanding and predicting this psychological state. However, most traditional research is based on statistical methods that exploring the correlation between numbers. This type of method lacks an understanding of the natural semantics of obstetric data, so it is prone to problems such as deviation or missing data (such as missing geospatial information) in data analysis. To tackle this problem, we study the use of a generic graph representation on gynecology and obstetric surveys with geospatial features, and propose a bipartite approach, or Geo-SPS, to mine the semantic relationship between low quality health information data. Our solution highlights our unconventional adaptation of novel graph theory from computational physics into biomedical ontology, that carefully maps semantic objects into a bipartite graph. With this tool, Geo-SPS provides a unique approach to semantic similarity metrics. The method supports fast and understandable processing of mixed textual data under different geographic spaces in a graph convolutional neural network. We further evaluate and validate the feasibility of Geo-SPS using a case study on obstetric surveys and health information data from over 3000 pregnant women in three different places from China. Results show that Geo-SPS can effectively represent prenatal mental state from this mixed data set, with an accurate classification on birth defects.},
  archive      = {J_NCA},
  author       = {Cheng, Jie and Lian, Lu and Xu, Zichen and Wu, Dan and Zhu, Haoyang and Sun, Xiao and Wang, Yuhao},
  doi          = {10.1007/s00521-021-06371-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3709-3724},
  shortjournal = {Neural Comput. Appl.},
  title        = {Geo-SPS: Bipartite graph representation for GeoSpatial prenatal survey data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recurrent multi-level residual and global attention network
for single image deraining. <em>NCA</em>, <em>35</em>(5), 3697–3708. (<a
href="https://doi.org/10.1007/s00521-021-06814-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deraining is an essential preprocess for many computer vision tasks, e.g., vision-based autonomous driving. The existing methods usually depend on the prior information or specified network structures and correspondingly suffer from high computational costs. To enhance the performance to meet the real-time requirement of autonomous driving, we propose a novel end-to-end recurrent multi-level residual learning deraining network featured with the global attention mechanism and residual network architecture. In the proposed Recurrent Multi-level Residual and Global Attention Network (RMRGN in short), we employ a recurrent stage scheme to gradually utilize global contextual information and image details to remove the rain streaks progressively. The global-attention mechanism enables us to focus on the meaningful context in every recurrent stage, which further benefits the network to distinguish the rain streaks and the rain-free images. By exploring the attention information, we further propose a deep multi-level residual learning network to eliminate rain streaks in a single image. Comprehensive experimental results demonstrate that RMRGN performs favorably against the state-of-the-art methods for removing rain streaks.},
  archive      = {J_NCA},
  author       = {Wang, Meihua and Li, Chao and Ke, Fanhui},
  doi          = {10.1007/s00521-021-06814-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3697-3708},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recurrent multi-level residual and global attention network for single image deraining},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SmartDL: Energy-aware decremental learning in a mobile-based
federation for geo-spatial system. <em>NCA</em>, <em>35</em>(5),
3677–3696. (<a
href="https://doi.org/10.1007/s00521-021-06378-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is designed to collaboratively train a shared model based on a large number of mobile devices while preserving data privacy, which has been widely adopted to support different geo-spatial systems. However, two critical issues prevent federated learning to be effectively deployed on resource-constrained devices in large scale. First, federated learning causes high energy consumption which can badly hurt the battery lifetime of mobile devices. Second, leakage of sensitive personal information still occurs during the training process. Thus, a system that can effectively protect the sensitive information while improving the energy efficiency is urgently required for a mobile-based federated learning system. This paper proposes SmartDL, an energy-aware decremental learning framework that well balances the energy efficiency and data privacy in an efficient manner. SmartDL improves the energy efficiency from two levels: (1) global layer, which adopts an optimization approach to select a subset of participating devices with sufficient capacity and maximum reward. (2) local layer, which adopts a novel decremental learning algorithm to actively provides the decremental and incremental updates, and can adaptively tune the local DVFS at the same time. We prototyped SmartDL on physical testbed and evaluated its performance using several learning benchmarks with real-world traces. The evaluation results show that compared with the original federated learning, SmartDL can reduce energy consumption by 75.6–82.4\% in different datasets. Moreover, SmartDL achieves a speedup of 2–4 orders of magnitude in model convergence while ensuring the accuracy of the model.},
  archive      = {J_NCA},
  author       = {Zou, Wenting and Li, Li and Xu, Zichen and Wu, Dan and Xu, ChengZhong and Wang, Yuhao and Zhu, Haoyang and Sun, Xiao},
  doi          = {10.1007/s00521-021-06378-9},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3677-3696},
  shortjournal = {Neural Comput. Appl.},
  title        = {SmartDL: Energy-aware decremental learning in a mobile-based federation for geo-spatial system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint image and feature adaptative attention-aware networks
for cross-modality semantic segmentation. <em>NCA</em>, <em>35</em>(5),
3665–3676. (<a
href="https://doi.org/10.1007/s00521-021-06064-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based methods are widely used for the task of semantic segmentation in recent years. However, due to the difficulty and labor cost of collecting pixel-level annotations, it is hard to acquire sufficient training images for a certain imaging modality, which greatly hinders the performance of these methods. The intuitive solution to this issue is to train a pre-trained model on label-rich imaging modality (source domain) and then apply the pre-trained model to the label-poor imaging modality (target domain). Unsurprisingly, since the severe domain shift between different modalities, the pre-trained model would perform poorly on the target imaging modality. To this end, we propose a novel unsupervised domain adaptation framework, called Joint Image and Feature Adaptive Attention-aware Networks (JIFAAN), to alleviate the domain shift for cross-modality semantic segmentation. The proposed framework mainly consists of two procedures. The first procedure is image adaptation, which transforms the source domain images into target-like images using the adversarial learning with cycle-consistency constraint. For further bridging the gap between transformed images and target domain images, the second procedure employs feature adaptation to extract the domain-invariant features and thus aligns the distribution in feature space. In particular, we introduce an attention module in the feature adaptation to focus on noteworthy regions and generate attention-aware results. Lastly, we combine two procedures in an end-to-end manner. Experiments on two cross-modality semantic segmentation datasets demonstrate the effectiveness of our proposed framework. Specifically, JIFAAN surpasses the cutting-edge domain adaptation methods and achieves the state-of-the-art performance.},
  archive      = {J_NCA},
  author       = {Zhong, Qihuang and Zeng, Fanzhou and Liao, Fei and Liu, Juhua and Du, Bo and Shang, Jedi S.},
  doi          = {10.1007/s00521-021-06064-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3665-3676},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint image and feature adaptative attention-aware networks for cross-modality semantic segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EDense: A convolutional neural network with ELM-based dense
connections. <em>NCA</em>, <em>35</em>(5), 3651–3663. (<a
href="https://doi.org/10.1007/s00521-020-05181-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth of geospatial data is increasing requirements for automatic and efficient data learning abilities. Many deep learning methods have been widely applied for geospatial data understanding tasks, such as road networks and geospatial object detection. However, the demands for more accurate learning of high-level features require the use of deeper neural networks. To further improve the learning efficiency of deep neural networks, in this paper, we propose an improved convolutional neural network named EDense. First, we use its dense connectivity to integrate a CNN with an extreme learning machine. Then, we expand the kernels in the convolutional layers to increase the width of the network model. Furthermore, we propose one-feature EDense (OF-EDense), which is a simplified version of EDense, to fit conditions in which the number of parameters is strictly limited. Finally, the experimental results fully demonstrate the strong learning ability and high learning efficiency of EDense.},
  archive      = {J_NCA},
  author       = {Zhao, Xiangguo and Bi, Xin and Zeng, Xiangyu and Zhang, Yingchun and Fang, Qiusheng},
  doi          = {10.1007/s00521-020-05181-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3651-3663},
  shortjournal = {Neural Comput. Appl.},
  title        = {EDense: A convolutional neural network with ELM-based dense connections},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Fuzzy time-series prediction model based on text features
and network features. <em>NCA</em>, <em>35</em>(5), 3639–3649. (<a
href="https://doi.org/10.1007/s00521-021-05834-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of time-series data is a challenging and complex issue. For many practical applications, network topology information and text information can play a perfect role in time-series prediction. This article takes stock data as an example by constructing a graph, connecting each stock’s upstream and downstream industries, and obtaining useful text features and topological features to predict the stock time-series. Based on the time-series data features, text features, and the topological features of the stock industry chain of machine learning, we compared our prediction model with other fuzzy time-series prediction methods, which are only based on historical features. The experiment shows that our method is better than the other methods in terms of the performance of multiple stocks in each stock’s time-series prediction. The experimental results show that the stock topology based on the industrial chain effectively improved time-series forecasting accuracy.},
  archive      = {J_NCA},
  author       = {Liu, Zeguang and Li, Yao and Liu, Huilin},
  doi          = {10.1007/s00521-021-05834-w},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3639-3649},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy time-series prediction model based on text features and network features},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RUTOD: Real-time urban traffic outlier detection on
streaming trajectory. <em>NCA</em>, <em>35</em>(5), 3625–3637. (<a
href="https://doi.org/10.1007/s00521-021-06294-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of internet technology and mobile devices, massive streaming data of spatiotemporal information is available for real-time data mining. Outlier detection is playing as one of the most important analysis tasks for trajectory stream processing, such as traffic control and urban planning. Existing work about this issue can be divided into two main categories: individual outlier detection (IOD) and group outlier detection (GOD). IOD focuses on detecting an individual trajectory outlier generated by a single moving object (e.g., an over-speeding car), while GOD aims to detect a group outlier generated by various moving objects (e.g., a group of cars influenced by a traffic jam). However, existing studies only support one of them and cannot comprehensively understand the traffic conditions by combining both of them. To this end, we propose a novel framework for real-time urban traffic outlier detection (RUTOD) in this paper. RUTOD contains IOD based on current traffic conditions and GOD according to historical data. In addition, we adopt a street-based trajectory division to accelerate investigation. Experimental results show that our proposal is not only effective but also efficient for detecting both individual outliers and group outliers in real-time scenario.},
  archive      = {J_NCA},
  author       = {Shi, Juntian and Pan, Zhicheng and Fang, Junhua and Chao, Pingfu},
  doi          = {10.1007/s00521-021-06294-y},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3625-3637},
  shortjournal = {Neural Comput. Appl.},
  title        = {RUTOD: Real-time urban traffic outlier detection on streaming trajectory},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding the causal structure among the tags in
marketing systems. <em>NCA</em>, <em>35</em>(5), 3615–3624. (<a
href="https://doi.org/10.1007/s00521-020-05552-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tagging system has become the basis of various systems, e.g., geo-social system, marketing system. Understanding the structure among the tags is one of the crucial tasks to the performance of various downstream marketing tasks, such as user behavior understanding, advertising, and recommendation. However, most of the existing methods mainly focus on the association among the tags, which usually results in false intervention suggestions, e.g., recommending a similar item after having bought one. To address this problem, we propose an Iterative Causal Structure Search (ICSS in short) algorithm for the high-dimensional social tags. In each iteration of the proposed approach, we first employ the constraint-based method to discover the skeleton of the causal structure and further employ the additive noise assumption to infer the edges whose directions are unknown in the previous stage. The proposed approach not only benefits from the good scalability of the constraint-based approach but also avoids the Markov equivalence class problem with the help of the additive noise assumption. We also theoretically show the correctness of the proposed algorithm. We test the ICSS and the baselines on both the simulated data and real-world data, further discover some interesting causal structures among the tags in a real-world marketing system.},
  archive      = {J_NCA},
  author       = {Zheng, Jiabi and Yang, Zhenguo and Liu, Wenyin},
  doi          = {10.1007/s00521-020-05552-9},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3615-3624},
  shortjournal = {Neural Comput. Appl.},
  title        = {Understanding the causal structure among the tags in marketing systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Influence maximization based on maximum inner product
search. <em>NCA</em>, <em>35</em>(5), 3605–3613. (<a
href="https://doi.org/10.1007/s00521-021-06595-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of social networks, the scale of social networks has grown dramatically. The relationship of people in social networks plays a key role in information propagation. Due to its huge social value, the issue of influence maximization has attracted more and more researchers’ attention. With the increase of network scale, the running time has become a key issue. To resolve it, many heuristic algorithms for the influence maximization problem has been proposed. These algorithms have been verified to be be very efficient, but their effectiveness cannot be guaranteed for many networks in the real word. Therefore, it has become highly urgent to choose an influence maximization algorithm that is simultaneously efficient and effective. This paper proposes an algorithm based on the greedy algorithm framework, which converts the influence maximization problem into a maximum inner product search problem. This method can complete the selection of seed nodes for large-scale networks in nearly linear time. Compared with other algorithms, this algorithm has more application value.},
  archive      = {J_NCA},
  author       = {Liu, Zeguang and Li, Yao and Liu, Huilin},
  doi          = {10.1007/s00521-021-06595-2},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3605-3613},
  shortjournal = {Neural Comput. Appl.},
  title        = {Influence maximization based on maximum inner product search},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High spatial resolution remote sensing image segmentation
based on the multiclassification model and the binary classification
model. <em>NCA</em>, <em>35</em>(5), 3597–3604. (<a
href="https://doi.org/10.1007/s00521-020-05561-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation technology is an important step in the interpretation of remote sensing images. High spatial resolution remote sensing images have clear features. Traditional image segmentation methods cannot fully represent the information in high spatial resolution images and tend to yield unsatisfactory segmentation accuracy. With the rapid development of deep learning, many researchers have tried to use deep learning algorithms for remote sensing image segmentation. This paper uses U-Net for multiclassification and binary classification of Gaofen-2 high spatial resolution remote sensing image data. Six types of features, which were build-up, farmland, water, meadow, forest and others, were labeled in the image. A “neighborhood voting” method was used to determine the category of uncertain pixels based on spatial heterogeneity and homogeneity. Through U-Net neural network multiclassification, the overall accuracy of the training data is 93.83\%; the overall accuracy of the test data is 82.27\%; and the test accuracy of the binary classification algorithm is 79.75\%. The results show that the two models yield high accuracy and credibility in remote sensing image segmentation.},
  archive      = {J_NCA},
  author       = {Zheng, Xiaoxiong and Chen, Tao},
  doi          = {10.1007/s00521-020-05561-8},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3597-3604},
  shortjournal = {Neural Comput. Appl.},
  title        = {High spatial resolution remote sensing image segmentation based on the multiclassification model and the binary classification model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised active learning with loss prediction.
<em>NCA</em>, <em>35</em>(5), 3587–3595. (<a
href="https://doi.org/10.1007/s00521-021-06480-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning is an effective technique to reduce the cost of labeling data by selecting the most beneficial samples. Most existing active learning methods use linear models to select the most representative points to approximate other points. However, they only select samples from the perspective of informativeness or representativeness and cannot model the nonlinearity of data well. In this paper, we propose a novel unsupervised active learning method with a loss prediction module, called UALL. Specifically, UALL uses a deep neural network to model the nonlinearity of data and considers simultaneously the representativeness, informativeness, and diversity, three essential criteria in active learning. Furthermore, we introduce an autoencoder and a loss prediction module to evaluate the representativeness and informativeness and combine K-means and simple calculations to measure the diversity. We compare with the state-of-the-art on eight publicly available datasets from different fields, and the experimental results demonstrate the effectiveness of our method.},
  archive      = {J_NCA},
  author       = {Wan, Chuanbing and Jin, Fusheng and Qiao, Zhuang and Zhang, Weiwei and Yuan, Ye},
  doi          = {10.1007/s00521-021-06480-y},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3587-3595},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsupervised active learning with loss prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep understanding of big geo-social data for autonomous
vehicles. <em>NCA</em>, <em>35</em>(5), 3585–3586. (<a
href="https://doi.org/10.1007/s00521-022-08001-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Shang, Shuo and Shen, Jianbing and Wen, Ji-Rong and Kalnis, Panos},
  doi          = {10.1007/s00521-022-08001-x},
  journal      = {Neural Computing and Applications},
  number       = {5},
  pages        = {3585-3586},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep understanding of big geo-social data for autonomous vehicles},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Retraction note: Design of traffic object recognition
system based on machine learning. <em>NCA</em>, <em>35</em>(4), 3583.
(<a href="https://doi.org/10.1007/s00521-022-08148-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Li, Daming and Deng, Lianbing and Cai, Zhiming},
  doi          = {10.1007/s00521-022-08148-7},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3583},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Design of traffic object recognition system based on machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Engineering vehicle management system based
on the internet of things. <em>NCA</em>, <em>35</em>(4), 3581. (<a
href="https://doi.org/10.1007/s00521-022-08147-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhang, Guanhong and Odbal},
  doi          = {10.1007/s00521-022-08147-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3581},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Engineering vehicle management system based on the internet of things},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Image object detection and semantic
segmentation based on convolutional neural network. <em>NCA</em>,
<em>35</em>(4), 3579. (<a
href="https://doi.org/10.1007/s00521-022-08146-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhang, Laigang and Sheng, Zhou and Li, Yibin and Sun, Qun and Zhao, Ying and Feng, Deying},
  doi          = {10.1007/s00521-022-08146-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3579},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Image object detection and semantic segmentation based on convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Image simulation of urban landscape in
coastal areas based on geographic information system and machine
learning. <em>NCA</em>, <em>35</em>(4), 3577. (<a
href="https://doi.org/10.1007/s00521-022-08145-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhou, Junling and Wang, Pohsun},
  doi          = {10.1007/s00521-022-08145-w},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3577},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Image simulation of urban landscape in coastal areas based on geographic information system and machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: An automatic tamil speech recognition
system by using bidirectional recurrent neural network with
self-organizing map. <em>NCA</em>, <em>35</em>(4), 3575. (<a
href="https://doi.org/10.1007/s00521-022-08144-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Lokesh, S. and Kumar, Priyan Malarvizhi and Devi, M. Ramya and Parthasarathy, P. and Gokulnath, C.},
  doi          = {10.1007/s00521-022-08144-x},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3575},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: An automatic tamil speech recognition system by using bidirectional recurrent neural network with self-organizing map},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Hybrid optimization with cryptography
encryption for medical image security in internet of things.
<em>NCA</em>, <em>35</em>(4), 3573. (<a
href="https://doi.org/10.1007/s00521-022-08143-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Elhoseny, Mohamed and Shankar, K. and Lakshmanaprabu, S. K. and Maseleno, Andino and Arunkumar, N.},
  doi          = {10.1007/s00521-022-08143-y},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3573},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Hybrid optimization with cryptography encryption for medical image security in internet of things},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retraction note: Lung cancer prediction using higher-order
recurrent neural network based on glowworm swarm optimization.
<em>NCA</em>, <em>35</em>(4), 3571. (<a
href="https://doi.org/10.1007/s00521-022-08142-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Selvanambi, Ramani and Natarajan, Jaisankar and Karuppiah, Marimuthu and Islam, SK Hafizul and Hassan, Mohammad Mehedi and Fortino, Giancarlo},
  doi          = {10.1007/s00521-022-08142-z},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3571},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Lung cancer prediction using higher-order recurrent neural network based on glowworm swarm optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring density rectification and domain adaption method
for crowd counting. <em>NCA</em>, <em>35</em>(4), 3551–3569. (<a
href="https://doi.org/10.1007/s00521-022-07917-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting has received increasing attention due to its important roles in multiple fields, such as social security, commercial applications, epidemic prevention and control. To this end, we explore two critical issues that seriously affect the performance of crowd counting including nonuniform crowd density distribution and cross-domain problems. Aiming at the nonuniform crowd density distribution issue, we propose a density rectifying network (DRNet) that consists of several dual-layer pyramid fusion modules (DPFM) and a density rectification map (DRmap) auxiliary learning module. The proposed DPFM is embedded into DRNet to integrate multi-scale crowd density features through dual-layer pyramid fusion. The devised DRmap auxiliary learning module further rectifies the incorrect crowd density estimation by adaptively weighting the initial crowd density maps. With respect to the cross-domain issue, we develop a domain adaptation method of randomly cutting mixed dual-domain images, which learns domain-invariance features and decreases the domain gap between the source domain and the target domain from global and local perspectives. Experimental results indicate that the devised DRNet achieves the best mean absolute error (MAE) and competitive mean squared error (MSE) compared with other excellent methods on four benchmark datasets. Additionally, a series of cross-domain experiments are conducted to demonstrate the effectiveness of the proposed domain adaption method. Significantly, when the A and B parts of the Shanghaitech dataset are the source domain and target domain respectively, the proposed domain adaption method decreases the MAE of DRNet by $$47.6\%$$ .},
  archive      = {J_NCA},
  author       = {Peng, Sifan and Yin, Baoqun and Yang, Qianqian and He, Qing and Wang, Luyang},
  doi          = {10.1007/s00521-022-07917-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3551-3569},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring density rectification and domain adaption method for crowd counting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DSF-net: Occluded person re-identification based on dual
structure features. <em>NCA</em>, <em>35</em>(4), 3537–3550. (<a
href="https://doi.org/10.1007/s00521-022-07927-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many person re-identification application scenarios, such as supermarkets, subway stations, and streets, it is necessary to solve an occlusion problem. We propose a dual branch named Dual structural Features Network to solve the problem. Our method obtains features embedding from two types of structural data, that is, Euclidean structural data and non-Euclidean structural data. We argue that the features of these two structures are equally important to ease the occlusion problem. In our first branch, we introduce a Position Attention Drop Block to extract the Euclidean structural feature. This branch focuses on the information that pixels can represent within a certain receptive field. In order to better target our network at the occlusion problem, we propose a drop method based on the pixel attention score of the person image, in which the area with the highest score is lost. In this way, we design a network that pays more attention to other more detailed information. In the other branch, a new U-shaped Residual Graph Convolutional Network is used to extract the features from non-Euclidean structural data, which is an effective multilayer graph convolution. We argue that good non-Euclidean structural data can express more topological correlation information, thereby reducing the interference of the occluded part. From the experimental results, we have achieved competitive performance with state-of-the-art methods, and our method is especially effective for person re-identification with occluded body parts.},
  archive      = {J_NCA},
  author       = {Fan, Yueqiao and Gong, Xun and He, Yuning},
  doi          = {10.1007/s00521-022-07927-6},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3537-3550},
  shortjournal = {Neural Comput. Appl.},
  title        = {DSF-net: Occluded person re-identification based on dual structure features},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalization to unseen viewpoint images of objects via
alleviated pose attentive capsule agreement. <em>NCA</em>,
<em>35</em>(4), 3521–3536. (<a
href="https://doi.org/10.1007/s00521-022-07900-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their achievements in object recognition, Convolutional Neural Networks (CNNs) particularly fail to generalize to unseen viewpoints of a learned object even with substantial samples. On the other hand, recently emerged capsule networks outperform CNNs in novel viewpoint generalization tasks even with significantly fewer parameters. Capsule networks group the neuron activations for representing higher level attributes and their interactions for achieving equivariance to visual transformations. However, capsule networks have a high computational cost for learning the interactions of capsules in consecutive layers via the, so called, routing algorithm. To address these issues, we propose a novel routing algorithm, Alleviated Pose Attentive Capsule Agreement (ALPACA) which is tailored for capsules that contain pose, feature and existence probability information together to enhance novel viewpoint generalization of capsules on 2D images. For this purpose, we have created a Novel ViewPoint Dataset (NVPD) a viewpoint-controlled texture-free dataset that has 8 different setups where training and test samples are formed by different viewpoints. In addition to NVPD, we have conducted experiments on iLab2M dataset where the dataset is split in terms of the object instances. Experimental results show that ALPACA outperforms its capsule network counterparts and state-of-the-art CNNs on iLab2M and NVPD datasets. Moreover, ALPACA is 10 times faster when compared to routing-based capsule networks. It also outperforms attention-based routing algorithms of the domain while keeping the inference and training times comparable. Lastly, our code, the NVPD dataset, test setups, and implemented models are freely available at https://github.com/Boazrciasn/ALPACA .},
  archive      = {J_NCA},
  author       = {Özcan, Barış and Kınlı, Furkan and Kıraç, Furkan},
  doi          = {10.1007/s00521-022-07900-3},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3521-3536},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generalization to unseen viewpoint images of objects via alleviated pose attentive capsule agreement},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MJS: A modified artificial jellyfish search algorithm for
continuous optimization problems. <em>NCA</em>, <em>35</em>(4),
3483–3519. (<a
href="https://doi.org/10.1007/s00521-022-07842-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial jellyfish search algorithm (JS) is a recently proposed optimization algorithm inspired by the search behavior of jellyfish in the ocean. There are two different search behaviors in JS: the motion of the jellyfish due to ocean currents (global search) and the motion of the jellyfish within the swarm (local search). In this study, two modifications, one in the local and the other in the global search formula, were made to strengthen the search capability of the standard algorithm. By means of the modification made in the global search, the search direction was directed toward the best and elite set individuals and higher quality solutions were found. A more detailed search around the individuals and the longer preservation of diversity in the population were ensured by another modification to the local search. In addition, it was studied to find the most ideal value for the time control mechanism that provides the transition between local and global search. The new modified algorithm (MJS), obtained as a result of all these modifications, was tested on a total of eighty minimization problems, including standard benchmark functions, Congress of Evolutionary Computation 2013 (CEC2013) test function, and Congress of Evolutionary Computation 2017 (CEC2017) test functions. The results of these tests for different dimensions were compared to the standard JS algorithm and the algorithms selected from the literature. Also, the results were interpreted by means of statistical tests. These comparisons and statistical tests showed that the proposed MJS algorithm produced acceptable, successful, and competitive results.},
  archive      = {J_NCA},
  author       = {Yildizdan, Gülnur},
  doi          = {10.1007/s00521-022-07842-w},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3483-3519},
  shortjournal = {Neural Comput. Appl.},
  title        = {MJS: A modified artificial jellyfish search algorithm for continuous optimization problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring class-agnostic pixels for scribble-supervised
high-resolution salient object detection. <em>NCA</em>, <em>35</em>(4),
3469–3482. (<a
href="https://doi.org/10.1007/s00521-022-07915-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successful salient object detection is largely dependent on large-scale fine-grained annotated datasets. However, pixel-level annotation is a laborious process compared with weak labels and scant research has been done on high-resolution images. To mitigate these drawbacks, we propose a distinctive network to explore salient object in high-resolution images under scribble-supervised and relabel a previous high-resolution dataset with scribbles, namely Scr-HRSOD, in which each image is labelled in a few seconds. Since scribble labels lack structural information about objects, a boundary structure maintenance branch with shallow layers is introduced to capture low-level spatial details. Within the constraint of boundary branches, a lightweight contextual semantic branch process compressed inputs to obtain high-level semantic context and iteratively propagates the partially annotated pixels to surrounding similar regions, which are then employed as pseudo-labels to supervise the network. Extensive evaluations on five datasets illustrate the effectiveness of our introduced method. On HRSOD datasets, we achieve higher 0.861 Fmax and 0.887 Sm values, which outperforms the existing foremost weakly supervised methods and even the fully supervised methods.},
  archive      = {J_NCA},
  author       = {Yang, Qingpeng and Zhou, Yi and Chai, Xiuli and Zhang, Miaohui and Zhang, Wanjun and Wang, Jun},
  doi          = {10.1007/s00521-022-07915-w},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3469-3482},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring class-agnostic pixels for scribble-supervised high-resolution salient object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparison of hybrid machine learning model for the analysis
of black carbon in air around the major coal mines of india.
<em>NCA</em>, <em>35</em>(4), 3449–3468. (<a
href="https://doi.org/10.1007/s00521-022-07909-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air is the basis for the existence of life on Earth; but in the present age of modernization the degrading quality of air year by year, due to the growth of Industrialization, urbanization, automobiles, coal-fired thermal power plants, and various other factories is the matter of real concern. To predict the future growth of air pollutants numerous prediction models have been developed by researchers. Time-series ARIMA model although quite useful for forecasting but fails to handle non-stationary problems. Among all the existing forecasting models, wavelets along with the Machine learning models have proved to be very successful and have been widely used in various fields like mathematical modeling, signal recognition, image recognition, classification, function approximation, data processing, filtering, clustering, compression, robotics, and decision making. It is also used in the field of mathematical forecasting for developing efficient prediction models. This paper aims to develop a wavelet-ANFIS conjugation model and a wavelet-ARIMA coupled model along with the time-series ARIMA model for the prediction of black carbon concentration over the Raniganj, Jharia, and Bokaro coal mines of India, by considering a long term data obtained by NASA ( http://nasa.gov/ ) and compare the results obtained by these models for determining the best prediction model. The validity of the results is tested with the help of error measures like RMSE, MSE, MAPE, MAE, and relative error. Results over the three sample sites conclude that the Wavelet-ANFIS conjugation approach outperforms the wavelet-ARIMA coupled approach and the simple time-series ARIMA model.},
  archive      = {J_NCA},
  author       = {Makkhan, Sidhu Jitendra Singh and Singh, Sarbjit and Parmar, Kulwinder Singh and Kaushal, Sachin and Soni, Kirti},
  doi          = {10.1007/s00521-022-07909-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3449-3468},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparison of hybrid machine learning model for the analysis of black carbon in air around the major coal mines of india},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learned gaussian ProtoNet for improved cross-domain few-shot
classification and generalization. <em>NCA</em>, <em>35</em>(4),
3435–3448. (<a
href="https://doi.org/10.1007/s00521-022-07897-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To imitate intelligent human behaviour, computer vision introduces a fundamental task called Few-Shot learning (FSL) that carries the promise of alleviating the need for exhaustively labeled data. Using prior knowledge few-shot learning aims to learn and generalize to novel tasks containing limited examples with supervised information. Although metric-based methods demonstrated promising performance but due to the large disparity of feature distributions across domains they often fail to generalize. In this work, we propose a learned Gaussian ProtoNet model for fine-grained few-shot classification via meta-learning for both in-domain and cross-domain scenarios. Gaussian ProtoNet encoder helps to map an image into an embedding vector and Gaussian covariance matrix predicts the confidence region about individual data points. Direction and class-dependent distance metrics are adopted to estimate the distances to distinct class prototypes. Feature-wise modulated layers are embedded in the encoder to augment the feature distribution of images. The learning-to-learn approach is adopted for fine-tuning the hyper-parameters of incorporated feature-wise modulated layers for better generalization on unseen domains. Experimental results justify that our proposed model performs better than many state-of-the-art models and feature-wise modulation improves the performance under domain shifts.},
  archive      = {J_NCA},
  author       = {Khanday, Nadeem Yousuf and Sofi, Shabir Ahmad},
  doi          = {10.1007/s00521-022-07897-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3435-3448},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learned gaussian ProtoNet for improved cross-domain few-shot classification and generalization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust thermal infrared tracking via an adaptively
multi-feature fusion model. <em>NCA</em>, <em>35</em>(4), 3423–3434. (<a
href="https://doi.org/10.1007/s00521-022-07867-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When dealing with complex thermal infrared (TIR) tracking scenarios, the single category feature is not sufficient to portray the appearance of the target, which drastically affects the accuracy of the TIR target tracking method. In order to address these problems, we propose an adaptively multi-feature fusion model (AMFT) for the TIR tracking task. Specifically, our AMFT tracking method adaptively integrates hand-crafted features and deep convolutional neural network (CNN) features. In order to accurately locate the target position, it takes advantage of the complementarity between different features. Additionally, the model is updated using a simple but effective model update strategy to adapt to changes in the target during tracking. In addition, a simple but effective model update strategy is adopted to adapt the model to the changes of the target during the tracking process. We have shown through ablation studies that the adaptively multi-feature fusion model in our AMFT tracking method is very effective. Our AMFT tracker performs favorably on PTB-TIR and LSOTB-TIR benchmarks compared with state-of-the-art trackers.},
  archive      = {J_NCA},
  author       = {Yuan, Di and Shu, Xiu and Liu, Qiao and Zhang, Xinming and He, Zhenyu},
  doi          = {10.1007/s00521-022-07867-1},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3423-3434},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust thermal infrared tracking via an adaptively multi-feature fusion model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Keyword extraction as sequence labeling with classification
algorithms. <em>NCA</em>, <em>35</em>(4), 3413–3422. (<a
href="https://doi.org/10.1007/s00521-022-07906-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyword extraction is one of the main problems in clustering and linking textual content. In literature, several machine learning approaches were proposed for keyword and keyphrase extraction. However, the state-of-the-art performance results are still below the expectations. In this paper, we propose a novel hybrid keyword extraction model, HybridKEM. The proposed model addresses the keyword extraction problem as a sequence labelling task. Naive Bayes (NB), Polynomial Regression (PR) Support Vector Machine (SVM), Multi-Layer Perceptron (MLP), and Random Forest (RF) classification algorithms were trained separately in the Token Classification module of the model. The Token Classification process was performed by using text, graphic, embedding, and set features in the model. The performance of the model was evaluated using the Inspec, Semeval-2017, 500N-KPCrowd datasets, which are widely used in studies in the literature, and two newly collected, TRDizinEn and DergiParkEn datasets. The model achieved an average $$F_1$$ -score of 0.664 for all datasets. The highest $$F_1$$ -score (0.74) was obtained with the TRDizinEn dataset.},
  archive      = {J_NCA},
  author       = {Kılıç Ünlü, Hüma and Çetin, Aydın},
  doi          = {10.1007/s00521-022-07906-x},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3413-3422},
  shortjournal = {Neural Comput. Appl.},
  title        = {Keyword extraction as sequence labeling with classification algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network-based correlation and statistical
identification of data outliers in H2S-alkanolamine-H2O and
CO2-alkanolamine-H2O datasets. <em>NCA</em>, <em>35</em>(4), 3395–3412.
(<a href="https://doi.org/10.1007/s00521-022-07904-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throughout the published literature for phase equilibrium data of CO2-alkanolamine-H2O and H2S-alkanolamine-H2O systems, it is common to find some discrepant data, called data outliers. The presence of these erroneous values induces inaccuracies and prediction errors in the models and simulation studies developed using such experimental datasets. Hence, it is important that the data outliers are identified and later corrected or removed before developing a model or simulation. This study proposes a modified approach to identifying data outliers present in the phase equilibrium data of CO2-alkanolamine-H2O and H2S-alkanolamine-H2O systems using an artificial neural network and data outlier identification methods. Firstly, the suggested approach correlates the experimental phase equilibrium data (2152 data points) of CO2 and H2S-loaded monoethanolamine, diethanolamine, and N-methyldiethanolamine solutions by developing an artificial neural network. Following this, the data outliers are identified by applying a modified IQR method and compared graphically to 2.5 standard deviation method. The identified data outliers can then be truncated or winsorised for developing reliable and accurate models/simulations. The modified IQR method coupled with a neural network (based on the normalised data values) can robustly identify data outliers within a large experimental dataset. The proposed approach is superior to the previous data outlier identification techniques that used 2.5 standard deviations method, as it alleviates the need for a human decision in determining the congruence of experimental values. The results also indicate that the developed method can be reliably extended to other/larger non-linear experimental datasets having similar correlative complexity.},
  archive      = {J_NCA},
  author       = {Imai, Bruno and Nasir, Qazi and Maulud, Abdulhalim Shah and Nawaz, Muhammad and Nasir, Rizwan and Suleman, Humbul},
  doi          = {10.1007/s00521-022-07904-z},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3395-3412},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network-based correlation and statistical identification of data outliers in H2S-alkanolamine-H2O and CO2-alkanolamine-H2O datasets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). ClassSum: A deep learning model for class-level code
summarization. <em>NCA</em>, <em>35</em>(4), 3373–3393. (<a
href="https://doi.org/10.1007/s00521-022-07877-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code summaries are clear and concise natural language descriptions of program entities. Meaningful code summaries assist developers in better understanding. Code summarization refers to the task of generating a natural language summary from a code snippet. Most researches on code summarization focus on automatically generating summaries for methods or functions. However, in an object-oriented language such as Java, class is the basic programming unit rather than method. To fill this gap, in this paper, we investigate how to generate summaries for Java classes utilizing deep learning-based approaches. We propose a novel encoder–decoder model called ClassSum to generate functionality descriptions for Java classes and build a dataset containing 172,639 pairs from 3185 repositories hosted on Github. Since the code of class is much longer and more complicated, encoding a whole class via neural network is more challenging than encoding a method. On the other hand, the content within a class may be incomplete. To overcome this difficulty, we reduce the code of a class by only keeping its key elements, namely class signatures, method signatures and attribute names. To utilize both lexical and structural information of code, our model takes token sequence and abstract syntax tree of the reduced class content as inputs. ClassSum and five baselines (designed for method-level code summarization) are evaluated on our dataset. Experiment results show that summaries generated by ClassSum are more accurate and readable than those generated by baselines. Our dataset is available at https://github.com/classsum/ClassSum .},
  archive      = {J_NCA},
  author       = {Li, Mingchen and Yu, Huiqun and Fan, Guisheng and Zhou, Ziyi and Huang, Jiawen},
  doi          = {10.1007/s00521-022-07877-z},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3373-3393},
  shortjournal = {Neural Comput. Appl.},
  title        = {ClassSum: A deep learning model for class-level code summarization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal heterogeneous graph attention network.
<em>NCA</em>, <em>35</em>(4), 3357–3372. (<a
href="https://doi.org/10.1007/s00521-022-07862-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real world involves many graphs and networks that are essentially heterogeneous, in which various types of relations connect multiple types of vertices. With the development of information networks, node features can be described by data of different modalities, resulting in multimodal heterogeneous graphs. However, most existed methods can only handle unimodal heterogeneous graphs. Moreover, most existing heterogeneous graph mining methods are based on meta-paths that depend on domain experts for modeling. In this paper, we propose a novel multimodal heterogeneous graph attention network (MHGAT) to address these problems. Specifically, we exploit edge-level aggregation to capture graph heterogeneity information to achieve more informative representations adaptively. Further, we use the modality-level attention mechanism to obtain multimodal fusion information. Because plain graph convolutional networks can not capture higher-order neighborhood information, we utilize the residual connection and the dense connection access to obtain it. Extensive experimental results show that the MHGAT outperforms state-of-the-art baselines on three datasets for node classification, clustering, and visualization tasks.},
  archive      = {J_NCA},
  author       = {Jia, Xiangen and Jiang, Min and Dong, Yihong and Zhu, Feng and Lin, Haocai and Xin, Yu and Chen, Huahui},
  doi          = {10.1007/s00521-022-07862-6},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3357-3372},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal heterogeneous graph attention network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PairGNNs: Enabling graph neural networks with pair-based
view. <em>NCA</em>, <em>35</em>(4), 3343–3355. (<a
href="https://doi.org/10.1007/s00521-022-07817-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) is widely used in graph structure data and has achieved specific effects in downstream tasks such as node classification. Most existing GNN approaches are designed with a node-based view and homophily assumption during learning. They mainly preserve the similarity between a node and its surrounding context by intensifying low-frequency information in between. The main drawback of such node-view is its lack of support for expressing the compound relationships between nodes. The lack of discrimination of closed nodes makes it hard to handle tasks, e.g., edge classification that demands the high-frequency signals between connected nodes. To preserve the differences between connected nodes during aggregation, a new view, pairGNNs, is proposed, which replaces the node with a paired structure (two adjacent nodes) as the primary learning and information aggregation unit. Paired Nodes form neighbors based on the same node. Aiming at the “neighbor explosion” situation resulting from those designs, we propose a neighbor sampling strategy that significantly reduces the computational complexity by using k minimum degree paired nodes. We apply this model to three off-the-shelf GNNs: GCN, GAT, and GraphSage. Extensive experiments have been performed on nine different datasets and three different downstream tasks. Results prove that GNNs with a paired-view can significantly improve performance compared to their node-view peers and outperform seven strong compared baselines in major downstream tasks, especially on datasets with complex structures.},
  archive      = {J_NCA},
  author       = {Yu, Chenhuan and Deng, Gangda and Gui, Ning},
  doi          = {10.1007/s00521-022-07817-x},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3343-3355},
  shortjournal = {Neural Comput. Appl.},
  title        = {PairGNNs: Enabling graph neural networks with pair-based view},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Completion and augmentation-based spatiotemporal deep
learning approach for short-term metro origin-destination matrix
prediction under limited observable data. <em>NCA</em>, <em>35</em>(4),
3325–3341. (<a
href="https://doi.org/10.1007/s00521-022-07866-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of short-term origin-destination (OD) matrix is crucial for operations in metro systems. Recently, some deep learning-based models have been proposed for OD matrix forecasting in ride-hailing or high-way scenarios. However, the metro OD matrix forecasting receives less attention, and it has different prior knowledge and complex spatiotemporal contextual setting; for example, the sparse destination distribution and the incomplete OD matrices collection in recent time intervals due to unfinished trips before the predicted time interval. This paper designs a deep learning approach for metro OD matrix prediction by addressing the recent destination distribution availability, augmenting the flow presentation for each station, and digging out the global spatial dependency and multiple temporal scale correlations in the mobility patterns of metro passengers. Specifically, it first proposes to complete the recent OD matrices by combining some empirical knowledge including the historical mobility pattern and arrival time distribution. Then, it learns the complementary spatiotemporal contextual features by embedding methods to enrich the station representation. Finally, it captures global mobility trend of metro passengers at each origin station through aggregating the trend of all other origin stations by self-attention mechanism since the mobility synchronizes among stations from spatial perspective. Three temporal convolutional networks are leveraged to extract three temporal trends in passenger mobility data, i.e., recent trend, daily trend, and weekly trend. Smart card data from Shenzhen and Hangzhou metro systems are utilized to demonstrate the superiority of our model over other competitors.},
  archive      = {J_NCA},
  author       = {Ye, Jiexia and Zhao, Juanjuan and Zheng, Furong and Xu, Chengzhong},
  doi          = {10.1007/s00521-022-07866-2},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3325-3341},
  shortjournal = {Neural Comput. Appl.},
  title        = {Completion and augmentation-based spatiotemporal deep learning approach for short-term metro origin-destination matrix prediction under limited observable data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced feature selection technique using slime mould
algorithm: A case study on chemical data. <em>NCA</em>, <em>35</em>(4),
3307–3324. (<a
href="https://doi.org/10.1007/s00521-022-07852-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection techniques are considered one of the most important preprocessing steps, which has the most significant influence on the performance of data analysis and decision making. These FS techniques aim to achieve several objectives (such as reducing classification error and minimizing the number of features) at the same time to increase the classification rate. FS based on Metaheuristic (MH) is considered one of the most promising techniques to improve the classification process. This paper presents a modified method of the Slime mould algorithm depending on the Marine Predators Algorithm (MPA) operators as a local search strategy, which leads to increasing the convergence rate of the developed method, named SMAMPA and avoiding the attraction to local optima. The efficiency of SMAMPA is evaluated using twenty datasets and compared its results with the state-of-the-art FS methods. In addition, the applicability of SMAMPA to work with real-world problems is evaluated by using it as a quantitative structure-activity relationship (QSAR) model. The obtained results show the high ability of the developed SMAMPA method to reduce the dimension of the tested datasets by increasing the prediction rate. In addition, it provides results better than other FS techniques in terms of performance metrics.},
  archive      = {J_NCA},
  author       = {Ewees, Ahmed A. and Al-qaness, Mohammed A. A. and Abualigah, Laith and Algamal, Zakariya Yahya and Oliva, Diego and Yousri, Dalia and Elaziz, Mohamed Abd},
  doi          = {10.1007/s00521-022-07852-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3307-3324},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced feature selection technique using slime mould algorithm: A case study on chemical data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clustered design-model generation from a program source code
using chaos-based metaheuristic algorithms. <em>NCA</em>,
<em>35</em>(4), 3283–3305. (<a
href="https://doi.org/10.1007/s00521-022-07781-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comprehension of the structure of software will facilitate maintaining the software more efficiently. Clustering software modules, as a reverse engineering technique, is assumed to be an effective technique in extracting comprehensible structural-models of software from the source code. Finding the best clustering model of a software system is regarded as a NP-complete problem. Minimizing the connections among the created clusters, maximizing the internal connections within the created clusters and maximizing the clustering quality are considered to be the most important objectives in software module clustering (SMC). Poor success rate, low stability and modularization quality are regarded as the major drawbacks of the previously proposed methods. In this paper, five different heuristic algorithms (Bat, Cuckoo, Teaching–Learning-Based, Black Widow and Grasshopper algorithms) are proposed for optimal clustering of software modules. Also, the effects of chaos theory in the performance of these algorithms in this problem have been experimentally investigated. The results of conducted experiments on the eight standard and real-world applications indicate that performance of the BWO, PSO, and TLB algorithms are higher than the other algorithms in SMC problem; also, the performance of these algorithm increased when their initial population were generated with logistic chaos method instead of random method. The average MQ of the generated clusters for the selected benchmark set by BWO, PSO and TLB are 3.155, 3.120 and 2.778, respectively.},
  archive      = {J_NCA},
  author       = {Arasteh, Bahman},
  doi          = {10.1007/s00521-022-07781-6},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3283-3305},
  shortjournal = {Neural Comput. Appl.},
  title        = {Clustered design-model generation from a program source code using chaos-based metaheuristic algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-dimensional feature extraction-based deep
encoder–decoder network for automatic surface defect detection.
<em>NCA</em>, <em>35</em>(4), 3263–3282. (<a
href="https://doi.org/10.1007/s00521-022-07885-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of surface defects is of critical importance in manufacturing quality control systems. Today, automatic defects detection using imaging and deep learning algorithms has produced more successful results than manual inspections. Thanks to these automatic applications, manufacturing systems will increase the production quality, and thus financial losses will be prevented. However, since the appearance and dimensions of the defects on the surface are very variable, automatic surface defect detection is a complex problem. In this study, multi-dimensional feature extraction-based deep encoder–decoder network (MFE-DEDNet) network developed to solve such problems. An effective encoder–decoder model with lower parameters compared to the state-of-the-art methods is developed using the depthwise separable convolutions (DSC) layers in the proposed model. In addition, the 3D spectral and spatial features extract (3DFE) module of the proposed model is developed to extract deep spectral and spatial features, as well as deep semantic features. During the combination of these features, the multi-input attention gate (MIAG) module is used so that important details are not lost. As a result, the proposed MFE-DEDNet model based on these structures enabled the extraction of powerful and effective features for defect detection in surface datasets containing few images. In experimental studies, MVTec and MT datasets were used to evaluate the performance of the MFE-DEDNet. The experimental results achieved 80.01\% and 56\% mean intersection-over-union (mIoU) scores for the MT and MVTec datasets, respectively. In these results, it was observed that the proposed model produced higher success compared to other state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Uzen, Huseyin and Turkoglu, Muammer and Hanbay, Davut},
  doi          = {10.1007/s00521-022-07885-z},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3263-3282},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-dimensional feature extraction-based deep encoder–decoder network for automatic surface defect detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A non-convex robust small sphere and large margin support
vector machine for imbalanced data classification. <em>NCA</em>,
<em>35</em>(4), 3245–3261. (<a
href="https://doi.org/10.1007/s00521-022-07882-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small sphere and large margin support vector machine (SSLM) is an effective method for imbalanced data classification. However, the hinge loss used in SSLM easily leads to sensitivity to the noises and thus yields poor generalization performance since the outliers gain the largest penalties. In this paper, we propose a Ramp loss small sphere and large margin support vector machine (Ramp SSLM) for imbalanced data classification to improve the performance of SSLM. In comparison with SSLM, our model can incorporate noises, has less support vectors and thus owns better scaling properties. The non-convexity of Ramp SSLM can be efficiently solved by the concave-convex procedure (CCCP), which contains a sequence of convex problems. Furthermore, a sequential minimal optimization (SMO) decomposition method is employed to deal with the large-scale datasets. Experiments on an artificial, ten benchmark datasets and Chinese wine dataset are conducted and evaluation metrics such as g-means and $$F_1$$ score are adopted. Our method achieves better performance than other state-of-the-art algorithms, which shows the stability and effectiveness of our proposed algorithm.},
  archive      = {J_NCA},
  author       = {Wang, Yahui and Xu, Yitian},
  doi          = {10.1007/s00521-022-07882-2},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3245-3261},
  shortjournal = {Neural Comput. Appl.},
  title        = {A non-convex robust small sphere and large margin support vector machine for imbalanced data classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Animorphic ensemble optimization: A large-scale island
model. <em>NCA</em>, <em>35</em>(4), 3221–3243. (<a
href="https://doi.org/10.1007/s00521-022-07878-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a flexible large-scale ensemble-based optimization algorithm is presented for complex optimization problems. According to the no free lunch theorem, no single optimization algorithm demonstrates superior performance across all optimization problems. Therefore, with the animorphic ensemble optimization (AEO) algorithm presented here, a set of algorithms can be used as an ensemble which demonstrate stronger performance across a wider range of optimization problems than any standalone algorithm. AEO is a high-level ensemble designed to handle large ensembles using a well-defined stochastic migration process. The high-level nature of AEO allows for an arbitrary number of diverse standalone algorithms to interface with one another through an island model interface strategy, where various populations change size according to the performance of the algorithm associated with each population. In this study, AEO is demonstrated using ensembles of both evolutionary and swarm algorithms such as differential evolution, particle swarm, gray wolf optimization, moth-flame optimization, and more, and strong performance is observed. Quantitative diagnostics metrics to describe the migration of individuals across populations are also presented and observed with application to some test problems. In the end, AEO demonstrated strong consistent performance across more than 150 benchmark functions of 10–50 dimensions.},
  archive      = {J_NCA},
  author       = {Price, Dean and Radaideh, Majdi I.},
  doi          = {10.1007/s00521-022-07878-y},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3221-3243},
  shortjournal = {Neural Comput. Appl.},
  title        = {Animorphic ensemble optimization: A large-scale island model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep multi-view subspace clustering via structure-preserved
multi-scale features fusion. <em>NCA</em>, <em>35</em>(4), 3203–3219.
(<a href="https://doi.org/10.1007/s00521-022-07864-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering has received widespread attention. Since data may violate the linear assumption in many practical applications, multi-view subspace clustering methods based on deep neural network are developed in recent years. However, most existing DNN based methods only focus on the utilization of the deepest features (i.e., features extracted from the deepest layer), regardless of the informative shallow features (i.e., features extracted from the shallow ones) and the fusion of multi-scale features (i.e., deep and shallow features), which may make their clustering performance suboptimal. In addition, these methods usually do not impose appropriate constraints on the extracted features to ensure that they can maintain the inherent local geometric structure of multi-view data, which is unfavorable for subspace learning. To deal with the limitations mentioned above, we propose a novel DNN based subspace clustering method for multi-view data called Deep Multi-view Subspace Clustering via Structure-preserved Multi-scale Features Fusion. Specifically, the graph knowledge of multi-view data is introduced to constrain the extracted features so that they have the structure-preserved property. Simultaneously, by fully exploiting the consistency of the extracted structure-preserved multi-scale features, DMSC-SMFF can learn the more discriminative common shared subspace representation, which can be employed by the spectral clustering module to obtain clustering results. Moreover, the optimization algorithm based on the Alternating Direction Method (ADM) is developed to optimize our objective function. Furthermore, DMSC-SMFF can also be applied to single-view data. Plentiful experimental results on five benchmark datasets demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_NCA},
  author       = {Xu, Kaiqiang and Tang, Kewei and Su, Zhixun},
  doi          = {10.1007/s00521-022-07864-4},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3203-3219},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep multi-view subspace clustering via structure-preserved multi-scale features fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional hybrid GAN for melody generation from lyrics.
<em>NCA</em>, <em>35</em>(4), 3191–3202. (<a
href="https://doi.org/10.1007/s00521-022-07863-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional sequence generation aims to instruct the generation procedure by conditioning the model with additional context information, which is an interesting research issue in AI and machine learning. Unfortunately, current state-of-the-art generative models for music fail to generate good melodies due to the discrete-valued property of music attributes. In this paper, we propose a novel conditional hybrid GAN (C-Hybrid-GAN) for melody generation from lyrics. Three discrete sequences corresponding to music attributes, namely pitch, duration, and rest, are separately generated by melody generation model conditioned on the same lyrics. Gumbel-Softmax is used to approximate the distribution of discrete-valued samples so as to directly generate discrete melody attributes. Most importantly, a hybrid structure is proposed, which contains three independent branches (each for one melody attribute) in the generator and one branch for distinguishing concatenated attributes in the discriminator. Relational memory core is exploited to model not only the dependency inside each sequence of attribute during the training of the generator, but also the consistency among three sequences of attributes during the training of the discriminator. Through extensive experiments using evaluation metrics, e.g., maximum mean discrepancy, average rest value, and MIDI number transition, we demonstrate that the proposed C-Hybrid-GAN outperforms the existing methods in melody generation from lyrics.},
  archive      = {J_NCA},
  author       = {Yu, Yi and Zhang, Zhe and Duan, Wei and Srivastava, Abhishek and Shah, Rajiv and Ren, Yi},
  doi          = {10.1007/s00521-022-07863-5},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3191-3202},
  shortjournal = {Neural Comput. Appl.},
  title        = {Conditional hybrid GAN for melody generation from lyrics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An investigation of feature selection methods for soil
liquefaction prediction based on tree-based ensemble algorithms using
AdaBoost, gradient boosting, and XGBoost. <em>NCA</em>, <em>35</em>(4),
3173–3190. (<a
href="https://doi.org/10.1007/s00521-022-07856-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous major earthquake events have revealed that soils susceptible to liquefaction are one of the factors causing significant damages to the structures. Therefore, accurate prediction of the liquefaction phenomenon is an important task in earthquake engineering. Over the past decade, several researchers have been extensively applied machine learning (ML) methods to predict soil liquefaction. This paper presents the prediction of soil liquefaction from the SPT dataset by using relatively new and robust tree-based ensemble algorithms, namely Adaptive Boosting, Gradient Boosting Machine, and eXtreme Gradient Boosting (XGBoost). The innovation points introduced in this paper are presented briefly as follows. Firstly, Stratified Random Sampling was utilized to ensure equalized sampling between each class selection. Secondly, feature selection methods such as Recursive Feature Elimination, Boruta, and Stepwise Regression were applied to develop models with a high degree of accuracy and minimal complexity by selecting the variables with significant predictive features. Thirdly, the performance of ML algorithms with feature selection methods was compared in terms of four performance metrics, Overall Accuracy, Precision, Recall, and F-measure to select the best model. Lastly, the best predictive model was determined using a statistical significance test called Wilcoxon’s sign rank test. Furthermore, computational cost analyses of the tree-based ensemble algorithms were performed based on parallel and non-parallel processing. The results of the study suggest that all developed tree-based ensemble models could reliably estimate soil liquefaction. In conclusion, according to both validation and statistical results, the XGBoost with the Boruta model achieved the most stable and better prediction performance than the other models in all considered cases.},
  archive      = {J_NCA},
  author       = {Demir, Selçuk and Sahin, Emrehan Kutlug},
  doi          = {10.1007/s00521-022-07856-4},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3173-3190},
  shortjournal = {Neural Comput. Appl.},
  title        = {An investigation of feature selection methods for soil liquefaction prediction based on tree-based ensemble algorithms using AdaBoost, gradient boosting, and XGBoost},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparing the latent space of generative models.
<em>NCA</em>, <em>35</em>(4), 3155–3172. (<a
href="https://doi.org/10.1007/s00521-022-07890-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different encodings of datapoints in the latent space of latent-vector generative models may result in more or less effective and disentangled characterizations of the different explanatory factors of variation behind the data. Many works have been recently devoted to the exploration of the latent space of specific models, mostly focused on the study of how features are disentangled and of how trajectories producing desired alterations of data in the visible space can be found. In this work we address the more general problem of comparing the latent spaces of different models, looking for transformations between them. We confined the investigation to the familiar and largely investigated case of generative models for the data manifold of human faces. The surprising, preliminary result reported in this article is that (provided models have not been taught or explicitly conceived to act differently) a simple linear mapping is enough to pass from a latent space to another while preserving most of the information. This is full of consequences for representation learning, potentially paving the way to the transformation of editing trajectories from one space to another, or the adaptation of disentanglement techniques between different generative domains.},
  archive      = {J_NCA},
  author       = {Asperti, Andrea and Tonelli, Valerio},
  doi          = {10.1007/s00521-022-07890-2},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3155-3172},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparing the latent space of generative models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mix-attention approximation for homogeneous large-scale
multi-agent reinforcement learning. <em>NCA</em>, <em>35</em>(4),
3143–3154. (<a
href="https://doi.org/10.1007/s00521-022-07880-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale multi-agent environments with homogeneous agents, most works provided approximation methods to simplify the interaction among agents. In this work, we propose a new approximation, termed mix-attention approximation, to enhance multi-agent reinforcement learning. The approximation is made by a mix-attention module, used to form consistent consensuses for agents in partially observable environments. We leverage the hard attention to compress the perception of each agent to some more partial regions. These partial regions can engage the attention of several agents at the same time, and the correlation among these partial regions is generated by a soft-attention module. We give the training method for the mix-attention mechanism and discuss the consistency between the mix-attention module and the policy network. Then we analyze the feasibility of this mix-attention-based approximation, attempting to build integrated models of our method into other approximation methods. In large-scale multi-agent environments, the proposal can be embedded into most reinforcement learning methods, and extensive experiments on multi-agent scenarios demonstrate the effectiveness of the proposed approach.},
  archive      = {J_NCA},
  author       = {Shike, Yang and Jingchen, Li and Haobin, Shi},
  doi          = {10.1007/s00521-022-07880-4},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3143-3154},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mix-attention approximation for homogeneous large-scale multi-agent reinforcement learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of mass transfer during osmotically treated
zucchini fruit product using advanced fuzzy inference system.
<em>NCA</em>, <em>35</em>(4), 3125–3141. (<a
href="https://doi.org/10.1007/s00521-022-07870-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the main goal is to develop and apply a robust adaptive fuzzy inference system (ANFIS) and Analysis of Variance (ANOVA) models to predict the mass transfer during osmotically treated zucchini samples as a heat-sensitive product. Maltose, fructose, lactose, and fructo-oligosaccharide (FoS), as osmotic agents at various concentrations and at constant temperature, were applied. In this study, the investigated concentrations were 30\%, 40\%, and 50\% and the temperature was at 26 °C. Three performance outputs were considered: Dimensionless Moisture Content (DMC), Water Loss (WL), and Solid Gain (SG). Using the dataset obtained from the experiments, both ANFIS and ANOVA models were proposed to describe osmotic dehydration behavior. The inputs to the models are the time (min), the concentrations (\%) and the osmotic agents. During the training and testing phases, the ANFIS showed significant modeling performances relative to the ANOVA in terms of the coefficient-of-determination (R2) and the RMSE values. In particular, for the whole dataset, the RMSE values are improved using ANFIS compared to the ANOVA where they are decreased by 99.03\%, 93.5\% and 79.08\%, for the DMC, SG and WL, respectively. On the other hand, the coefficient-of-determination showed significant increases for the ANFIS models over the ANOVA models for both training and testing phases. The comparison between the two modeling techniques revealed that the ANFIS is found more suitable for predicting all three performance outputs during the Osmotic Dehydration (OD) process of the zucchini food product. The results showed that the maltose, as an osmotic agent, with a concentration of 30\% is the most suitable solution among the four osmotic agents that produced the best performance for the three performance outputs. In sum, the obtained results demonstrated the superiority of ANFIS modeling of the DMC, SG, and WL in comparison with ANOVA. Accordingly, the prediction from the ANFIS model has an excellent agreement with the experimental dataset. This confirms the accuracy of the ANFIS model.},
  archive      = {J_NCA},
  author       = {Rahman, S. M. Atiqure and Rezk, Hegazy and Shaikh, Bismah and Abdelkareem, Mohammad Ali and Olabi, A. G. and Nassef, Ahmed M.},
  doi          = {10.1007/s00521-022-07870-6},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3125-3141},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of mass transfer during osmotically treated zucchini fruit product using advanced fuzzy inference system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task-specific method-agnostic metric for few-shot learning.
<em>NCA</em>, <em>35</em>(4), 3115–3124. (<a
href="https://doi.org/10.1007/s00521-022-07858-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric-based few-shot learning (FSL) methods have been attracting more and more research attention since they reflect a simpler and more effective inductive bias in the limited-data regime. The episodic evaluating method is widely used in the metric-based FSL methods, and the task-wise relative metric is critical to improving the performance of the episodic method. However, the commonly used metrics in existing metric-based FSL methods typically measure the absolute distance in a smooth and uniform feature space. Observing this, this paper proposed mapping the features into the task-specific sub-space by designing the correlation matrix of task-specific prototypical vectors, which induces a task-specific method-agnostic (TSMA) metric. The TSMA can be viewed as an adaptive linear classifier and hence is method-agnostic. In addition, the TSMA is manually designed and thus is parameter-free. The extensive experiments evaluated on various datasets show that TSMA outperformed the SOTA methods by 1.5–4.4\%. And the ablation study shows that TSMA could adaptively adjust the scale of the similarity items and the scaling items, allowing for the models to easily optimized.},
  archive      = {J_NCA},
  author       = {Wang, Heng and Li, Yong},
  doi          = {10.1007/s00521-022-07858-2},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3115-3124},
  shortjournal = {Neural Comput. Appl.},
  title        = {Task-specific method-agnostic metric for few-shot learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel fractional operator application for neural networks
using proportional caputo derivative. <em>NCA</em>, <em>35</em>(4),
3101–3114. (<a
href="https://doi.org/10.1007/s00521-022-07728-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning models, one of the most popular models is artificial neural networks. The activation function is one of the important parameters of neural networks. In this paper, the sigmoid function is used as an activation function with a fractional derivative approach to minimize the convergence error in backpropagation and to maximize the generalization performance of neural networks. The proportional Caputo definition is considered a fractional derivative. We evaluated three neural network models on the usage of the proportional Caputo derivative. The results show that the proportional Caputo derivative approach has higher classification accuracy than traditional derivative models in backpropagation for neural networks with and without L2 regularization.},
  archive      = {J_NCA},
  author       = {Altan, Gokhan and Alkan, Sertan and Baleanu, Dumitru},
  doi          = {10.1007/s00521-022-07728-x},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3101-3114},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel fractional operator application for neural networks using proportional caputo derivative},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Maize crop disease detection using NPNet-19 convolutional
neural network. <em>NCA</em>, <em>35</em>(4), 3075–3099. (<a
href="https://doi.org/10.1007/s00521-022-07722-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural network, a strong deep learning technique, is used to detect diseases and perform image processing, recognition, and disease classification. The neural network is a breakthrough in technology that can process large sets of images in both 2D and 3D. In this paper, a novel Deep CNN model named NPNet-19 is proposed to determine maize crop infections. The model&#39;s accuracy and robustness are tested using an enhanced dataset of 15,960 images to classify six disease classes and one healthy class. The primary data source for testing the model has been acquired from the maize fields situated in the state of Telangana. The model was trained using images from the Plant Village and Kaggle repositories. On training datasets, the learning model showed an accuracy of 97.51\%, and on testing datasets, it achieved an accuracy of 88.72\%. The proposed model is empirically compared with pre-trained models such as DenseNet-121, Inception V2, ShallowNet-8, and CNN-SVM, and it showed a 10.57, 1.74, 2.15, and 1.1\% improvement in classification accuracy, respectively. When compared to transfer learning models including Modified LeNet, DICNN, SoyNet, Adaptive CNN, 9-layer, and 13-layered architectures, the proposed model showed a 10.12, 14.52, 8.17, 3.88, 7.25, and 3.39\% improvement in classification accuracy, respectively. Classification Prediction Analysis also has been used for statistical analysis of prediction data on testing and training images using error metrics such as RMSE, MSE, and MAE. It is observed that the performance of the proposed model is better in the detection of real-time diseases and their classification.},
  archive      = {J_NCA},
  author       = {Nagaraju, M. and Chawla, Priyanka},
  doi          = {10.1007/s00521-022-07722-3},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3075-3099},
  shortjournal = {Neural Comput. Appl.},
  title        = {Maize crop disease detection using NPNet-19 convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing the end-to-end transmission scheme for hybrid
satellite and multihop networks. <em>NCA</em>, <em>35</em>(4),
3063–3074. (<a
href="https://doi.org/10.1007/s00521-021-06156-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite networks can communicate with the outside world from anywhere in the world, and multihop networks are suitable for occasions in which infrastructure is lacking or for emergencies. Heterogeneous networks formed by satellite and multihop networks can further expand the communication range of wireless networks; this expansion is conducive to communication with the outside world in remote areas and in emergency situations. However, the formation of heterogeneous networks also brings new challenges to wireless network research. To improve the transmission performance of heterogeneous networks composed of satellite and multihop networks, this paper first introduces the heterogeneous network model of satellite and multihop networks, then analyzes the bandwidth delay products of heterogeneous networks and proposes an end-to-end transmission control algorithm for heterogeneous networks. The algorithm incorporates different congestion window settings in the slow start through a threshold and through the size of the receiver notification window by increasing the amount of data transmitted in the slow start to improve the throughput of the satellite link. The algorithm then differentiates packet losses in congestion avoidance through the sizes of unacknowledged data in the heterogeneous network, using different threshold settings for different unacknowledged data sizes. The simulation results show that the proposed algorithm has some advantages over the TCP Hybla, TCP Veno and TCP Reno schemes in terms of the throughput of the satellite link, the download response time of the multihop network and the queue delay of nodes.},
  archive      = {J_NCA},
  author       = {Zong, Liang and Wang, Han and Du, Wencai and Zhao, Chenglin and Luo, Gaofeng},
  doi          = {10.1007/s00521-021-06156-7},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3063-3074},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing the end-to-end transmission scheme for hybrid satellite and multihop networks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Black-box error diagnosis in deep neural networks for
computer vision: A survey of tools. <em>NCA</em>, <em>35</em>(4),
3041–3062. (<a
href="https://doi.org/10.1007/s00521-022-08100-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of Deep Neural Networks (DNNs) to a broad variety of tasks demands methods for coping with the complex and opaque nature of these architectures. When a gold standard is available, performance assessment treats the DNN as a black box and computes standard metrics based on the comparison of the predictions with the ground truth. A deeper understanding of performances requires going beyond such evaluation metrics to diagnose the model behavior and the prediction errors. This goal can be pursued in two complementary ways. On one side, model interpretation techniques “open the box” and assess the relationship between the input, the inner layers and the output, so as to identify the architecture modules most likely to cause the performance loss. On the other hand, black-box error diagnosis techniques study the correlation between the model response and some properties of the input not used for training, so as to identify the features of the inputs that make the model fail. Both approaches give hints on how to improve the architecture and/or the training process. This paper focuses on the application of DNNs to computer vision (CV) tasks and presents a survey of the tools that support the black-box performance diagnosis paradigm. It illustrates the features and gaps of the current proposals, discusses the relevant research directions and provides a brief overview of the diagnosis tools in sectors other than CV.},
  archive      = {J_NCA},
  author       = {Fraternali, Piero and Milani, Federico and Torres, Rocio Nahime and Zangrando, Niccolò},
  doi          = {10.1007/s00521-022-08100-9},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3041-3062},
  shortjournal = {Neural Comput. Appl.},
  title        = {Black-box error diagnosis in deep neural networks for computer vision: A survey of tools},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). XGBoost based residual life prediction in the presence of
human error in maintenance. <em>NCA</em>, <em>35</em>(4), 3025–3039. (<a
href="https://doi.org/10.1007/s00521-022-07216-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate maintenance decision making is essential for organizations like military and aviation. Immensely demanding situations like limited time availability for maintenance in strenuous conditions escalate the possibility of human errors in maintaining such equipment. Human errors in maintenance negatively impact the life of the systems. Human Reliability Analysis methodologies have evolved to systematically quantify the human error in terms of Human Error Probability. However, the exact effect of human error on every component’s life is unknown yet. In the presence of the diverse operating profiles for equipment, estimating such effects becomes a complex and mathematically challenging problem to be handled by conventional statistical techniques. This paper presents a machine learning approach to estimate the residual life of a component by incorporating the effect of human error in maintenance. Based on the nature of the maintenance data, a gradient boosting ensemble model (XGBoost) is developed, which predicts the residual life of the component while considering error induced by maintenance personnel during its maintenance. The model recommends the maintenance decision considering the predicted residual life and the user-defined future mission profile. Additionally, provision is made to capture the stochastic future operating profile. The developed model effectively handles the uncertainties and variabilities in expected future mission profiles and the correlation of multiple influencing parameters without increasing mathematical complexity. The developed model is illustrated in the decision making of replacement of a component in a mission-critical military system in pre-mission maintenance break. From the perspective of managerial implications, some of the key findings from numerical experiments on the developed model are presented.},
  archive      = {J_NCA},
  author       = {Mohril, Ram S. and Solanki, Bhupendra S. and Kulkarni, Makarand S. and Lad, Bhupesh K.},
  doi          = {10.1007/s00521-022-07216-2},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3025-3039},
  shortjournal = {Neural Comput. Appl.},
  title        = {XGBoost based residual life prediction in the presence of human error in maintenance},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weibull recurrent neural networks for failure prognosis
using histogram data. <em>NCA</em>, <em>35</em>(4), 3011–3024. (<a
href="https://doi.org/10.1007/s00521-022-07667-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weibull time-to-event recurrent neural networks (WTTE-RNN) is a simple and versatile prognosis algorithm that works by optimising a Weibull survival function using a recurrent neural network. It offers the combined benefits of the sequential nature of the recurrent neural network, and the ability of the Weibull loss function to incorporate censored data. The goal of this paper is to present the first industrial use case of WTTE-RNN for prognosis. Prognosis of turbocharger conditions in a fleet of heavy-duty trucks is presented here, where the condition data used in the case study were recorded as a time series of sparsely sampled histograms. The experiments include comparison of the prediction models trained using data from the entire fleet of trucks vs data from clustered sub-fleets, where it is concluded that clustering is only beneficial as long as the training dataset is large enough for the model to not overfit. Moreover, the censored data from assets that did not fail are also shown to be incorporated while optimising the Weibull loss function and improve prediction performance. Overall, this paper concludes that WTTE-RNN-based failure predictions enable predictive maintenance policies, which are enhanced by identifying the sub-fleets of similar trucks.},
  archive      = {J_NCA},
  author       = {Dhada, Maharshi and Parlikad, Ajith Kumar and Steinert, Olof and Lindgren, Tony},
  doi          = {10.1007/s00521-022-07667-7},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {3011-3024},
  shortjournal = {Neural Comput. Appl.},
  title        = {Weibull recurrent neural networks for failure prognosis using histogram data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A rare failure detection model for aircraft predictive
maintenance using a deep hybrid learning approach. <em>NCA</em>,
<em>35</em>(4), 2991–3009. (<a
href="https://doi.org/10.1007/s00521-022-07167-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of aircraft operation logs to develop a data-driven model to predict probable failures that could cause interruption poses many challenges and has yet to be fully explored. Given that aircraft is high-integrity assets, failures are exceedingly rare. Hence, the distribution of relevant log data containing prior signs will be heavily skewed towards the typical (healthy) scenario. Thus, this study presents a novel deep learning technique based on the auto-encoder and bidirectional gated recurrent unit networks to handle extremely rare failure predictions in aircraft predictive maintenance modelling. The auto-encoder is modified and trained to detect rare failures, and the result from the auto-encoder is fed into the convolutional bidirectional gated recurrent unit network to predict the next occurrence of failure. The proposed network architecture with the rescaled focal loss addresses the imbalance problem during model training. The effectiveness of the proposed method is evaluated using real-world test cases of log-based warning and failure messages obtained from the fleet database of aircraft central maintenance system records. The proposed model is compared to other similar deep learning approaches. The results indicated an 18\% increase in precision, a 5\% increase in recall, and a 10\% increase in G-mean values. It also demonstrates reliability in anticipating rare failures within a predetermined, meaningful time frame.},
  archive      = {J_NCA},
  author       = {Dangut, Maren David and Jennions, Ian K. and King, Steve and Skaf, Zakwan},
  doi          = {10.1007/s00521-022-07167-8},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2991-3009},
  shortjournal = {Neural Comput. Appl.},
  title        = {A rare failure detection model for aircraft predictive maintenance using a deep hybrid learning approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A machine learning-based clustering approach to diagnose
multi-component degradation of aircraft fuel systems. <em>NCA</em>,
<em>35</em>(4), 2973–2989. (<a
href="https://doi.org/10.1007/s00521-021-06531-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate fault diagnosis and prognosis can significantly reduce maintenance costs, increase the safety and availability of engineering systems that have become increasingly complex. It has been observed that very limited researches have been reported on fault diagnosis where multi-component degradation are presented. This is essentially a challenging Complex Systems problem where features multiple components interacting simultaneously and nonlinearly with each other and its environment on multiple levels. Even the degradation of a single component can lead to a misidentification of the fault severity level. This paper introduces a new test rig to simulate the multi-component degradation of the aircraft fuel system. A machine learning-based data analytical approach based on the classification of clustering features from both time and frequency domains is proposed. The scope of this framework is the identification of the location and severity of not only the system fault but also the multi-component degradation. The results illustrate that (a) the fault can be detected with accuracy &gt; 99\%; (b) the severity of fault can be identified with an accuracy of almost 100\%; (c) the degradation level can be successfully identified with the R-square value &gt; 0.9.},
  archive      = {J_NCA},
  author       = {Liu, Haochen and Zhao, Yifan and Zaporowska, Anna and Skaf, Zakwan},
  doi          = {10.1007/s00521-021-06531-4},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2973-2989},
  shortjournal = {Neural Comput. Appl.},
  title        = {A machine learning-based clustering approach to diagnose multi-component degradation of aircraft fuel systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A prediction-based cycle life test optimization method for
cross-formula batteries using instance transfer and
variable-length-input deep learning model. <em>NCA</em>, <em>35</em>(4),
2947–2971. (<a
href="https://doi.org/10.1007/s00521-022-07322-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cycle life is a key performance indicator in the design and development of lithium-ion power batteries. In order to obtain an appropriate formula, developers need to conduct a large number of cycle life tests (CLTs). However, the high test cost and unbearable time overhead of CLT have seriously hindered the upgrade and development of lithium-ion power batteries. In this paper, a prediction-based CLT optimization method for cross-formula batteries is proposed, which can shorten the number of test cycles by predicting the remaining cycle life of batteries. Specifically, we design an AED-based instance transferability measurement method to select reference battery from the historical database according to curves distance and trend consistent. Then, a highly robust deep learning method named variable-length-input stacked denoising autoencoder (VLI-SDA) is proposed to achieve remaining useful life prediction. The VLI-SDA model adopts a variable-length input strategy to expand the receptive field, fully learn the degradation trend, and ensure an appropriate number of training samples. Combined with the inherent noise reduction capability of the SDA model, the VLI-SDA model can effectively solve the problem of cycle life prediction under high-temperature stress test and small sample conditions. The actual CLT data at three temperatures from a battery company verify the effectiveness of the proposed method. The test temperature, curve shape and other influencing factors are analyzed to help determine optimization strategies.},
  archive      = {J_NCA},
  author       = {Ma, Jian and Zou, XinYu and Sun, Lulu and Cheng, Yujie and Lu, Chen and Su, Yuzhuan and Chong, Jin and Jin, Haizu and Lin, Yongshou},
  doi          = {10.1007/s00521-022-07322-1},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2947-2971},
  shortjournal = {Neural Comput. Appl.},
  title        = {A prediction-based cycle life test optimization method for cross-formula batteries using instance transfer and variable-length-input deep learning model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Topical collection “applications of machine learning in
maintenance engineering and management.” <em>NCA</em>, <em>35</em>(4),
2945–2946. (<a
href="https://doi.org/10.1007/s00521-022-08031-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Emmanouilidis, Christos},
  doi          = {10.1007/s00521-022-08031-5},
  journal      = {Neural Computing and Applications},
  number       = {4},
  pages        = {2945-2946},
  shortjournal = {Neural Comput. Appl.},
  title        = {Topical collection “applications of machine learning in maintenance engineering and management”},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnosis of alzheimer’s, parkinson’s disease and
frontotemporal dementia using a generative adversarial deep
convolutional neural network. <em>NCA</em>, <em>35</em>(3), 2845–2854.
(<a href="https://doi.org/10.1007/s00521-022-07750-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dementia is the key term used to define any brain-related issues that affect memory. It is caused by physical changes in the human brain. This severely affects thinking, remembering activities and daily routines of a human being. In the span of the last three decades, many studies have been conducted on designing highly accurate systems for the classification of dementia. But this is limited to the diagnosis of a single type of dementia (either Alzheimer&#39;s or Parkinson&#39;s but not both). The proposed system focuses on revealing the multiple dementias with a single type of dataset that is FDG-PET brain scans. This work concentrates on the diagnosis of different types of dementia namely Alzheimer’s disease (AD), Frontotemporal Dementia (FTD) and Parkinson’s disease (PD). A generative adversarial Deep Convolutional Neural Network (DCNN) is designed to diagnose AD, PD and FTD. The GAN (Generative Adversarial Network) technology is practiced to generate NIFD virtual samples to solve the uniform distribution problems among the categories of images in the dataset. The DCNN is used for feature learning and classification. The designed model achieves an overall accuracy of 97.7\% with 0.97- sensitivity and 0.97- specificity values.},
  archive      = {J_NCA},
  author       = {Noella, R. S. Nancy and Priyadarshini, J.},
  doi          = {10.1007/s00521-022-07750-z},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2845-2854},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diagnosis of alzheimer’s, parkinson’s disease and frontotemporal dementia using a generative adversarial deep convolutional neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A BERT-based model for coupled biological strategies in
biomimetic design. <em>NCA</em>, <em>35</em>(3), 2827–2843. (<a
href="https://doi.org/10.1007/s00521-022-07734-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biomimetic design provides an adequate solution to attain an excellent design. However, the prototype space for biomimetic design is relatively large, and it becomes more and more challenging to find the required biological prototypes efficiently and accurately. To improve the design efficiency and enrich the biomimetic information, this paper proposes a coupled biological strategies-enabled bidirectional encoder representation from transformers (BERT) model to assist biomimetic design, namely BioDesign. We extract the biological strategies and extract dimensional information from AskNature as a part of the database. The linguistic expression model-BERT helps to search for biological strategy. Based on the coupled biological strategies analysis, the quantitative results of biomimetic strategies are given by BioDesign. Finally, we take the erosion wear-resistant design of the control valve core as an example to demonstrate the utilization based on the proposed BioDesign. The erosion wear experiment demonstrated the feasibility and effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Sun, Feng and Xu, He and Meng, Yihan and Lu, Zhimao},
  doi          = {10.1007/s00521-022-07734-z},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2827-2843},
  shortjournal = {Neural Comput. Appl.},
  title        = {A BERT-based model for coupled biological strategies in biomimetic design},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AW-GAN: Face aging and rejuvenation using attention with
wavelet GAN. <em>NCA</em>, <em>35</em>(3), 2811–2825. (<a
href="https://doi.org/10.1007/s00521-022-07721-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing state-of-the-art face aging models primarily focus on an adult or long-span aging and modeling age transformation in the image domain. This work proposes a child and adult face aging framework that captures more texture and shape information using attention with a wavelet-transformation-based generative adversarial network in the frequency domain. To facilitate child and adult age synthesis, we adopt a wavelet-based multi-scale patch discriminator, which increases the stability of model training and captures local texture details of the child and adult faces. Moreover, we introduce a modified convolutional block attention module, emphasizing only facial regions related to a target attribute and preserving the attribute-excluding details. Our new objective function, modified attention generator, and wavelet multi-scale patch discrimination has shown qualitative and quantitative improvements over the state-of-the-art approaches in terms of face recognition and age estimation on benchmarked children and adult datasets.},
  archive      = {J_NCA},
  author       = {Chandaliya, Praveen Kumar and Nain, Neeta},
  doi          = {10.1007/s00521-022-07721-4},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2811-2825},
  shortjournal = {Neural Comput. Appl.},
  title        = {AW-GAN: Face aging and rejuvenation using attention with wavelet GAN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel discrete-time neurodynamic algorithm for future
constrained quadratic programming with wheeled mobile robot control.
<em>NCA</em>, <em>35</em>(3), 2795–2809. (<a
href="https://doi.org/10.1007/s00521-022-07757-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of discrete-time dynamic constrained quadratic programming including equality and inequality constraints is formulated and investigated, simply termed future constrained quadratic programming (FCQP) problem in this paper. To obtain the optimal solution of such an FCQP problem in real time and with high precision, a novel discrete-time zeroing neurodynamic (DTZN) algorithm, which is developed by combining the corresponding continuous-time zeroing neurodynamic model and a five-step explicit linear multi-step (ELMS) rule, is proposed and termed ELMS-type five-step DTZN (5SDTZN) algorithm. Then, the convergence and precision of the ELMS-type 5SDTZN algorithm are analyzed theoretically. For comparison, three other DTZN algorithms as well as discrete-time gradient and varying-parameter neurodynamic algorithms are also presented. Afterward, through numerical verifications and comparisons, the efficacy and superiority of the ELMS-type 5SDTZN algorithm for solving the FCQP problem are illustrated. Finally, the applicability of the ELMS-type 5SDTZN algorithm for the coordinated repetitive motion control of a wheeled mobile robot with physical constraints is demonstrated.},
  archive      = {J_NCA},
  author       = {Qiu, Binbin and Li, Xiao-Dong and Yang, Song},
  doi          = {10.1007/s00521-022-07757-6},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2795-2809},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel discrete-time neurodynamic algorithm for future constrained quadratic programming with wheeled mobile robot control},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy rough assisted missing value imputation and feature
selection. <em>NCA</em>, <em>35</em>(3), 2773–2793. (<a
href="https://doi.org/10.1007/s00521-022-07754-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presence of missing values and irrelevant features are commonplace issues that need to be handled effectively. Missing value imputation and feature selection is an efficient technique for redressing such problems. Fuzzy rough set-based approaches provide a handful of solutions for further dealing with vagueness and uncertainty available in the data. The present paper introduces the notion of imputing missing values followed by feature selection utilizing fuzzy rough set-based approaches. The idea of missing value estimation and instance ignorance are combined for fuzzy rough missing value imputation employing only correlated features followed by feature selection with a search heuristic. The experimental evaluation on benchmark datasets demonstrates the applicability and robustness of the proposed work. It significantly reduces data dimensionality after imputing missing values maintaining high performances. A comparative analysis demonstrates the superiority of the proposed methodology.},
  archive      = {J_NCA},
  author       = {Jain, Pankhuri and Tiwari, Anoop and Som, Tanmoy},
  doi          = {10.1007/s00521-022-07754-9},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2773-2793},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy rough assisted missing value imputation and feature selection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convolutional neural network based tea leaf disease
prediction system on smart phone using paas cloud. <em>NCA</em>,
<em>35</em>(3), 2755–2771. (<a
href="https://doi.org/10.1007/s00521-022-07743-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) and cloud computing are modern and fast-growing areas across all domains of applications. In agriculture, automated detection and diagnosis of plant diseases in the early stage are still challenging tasks. This work focuses on developing and implementing a real-time disease prediction system using a convolutional neural network (CNN) on the Platform-as-a-Service (PaaS) cloud. The CNN model is implemented to predict the tea leaf disease and achieved excellent accuracy of 100\% for training, validation, and test datasets. The same dataset is also applied to the deep convolutional neural network (DCNN) such as ResNet50, Xception, and NASNetMobile to predict tea leaf disease. The performance analysis of all models was evaluated with the confusion matrix and K-fold cross-validation methods. The comparative results confirm that the CNN model outperforms the DCNN and literature-reported models to its remarkable accuracy. After the evaluation, the model was successfully deployed to the Platform-as-a-Service (PaaS) cloud. The smartphone may have access to the deployed model hyperlink. The tea leaf image can be captured with the smartphone camera and uploaded to the cloud. The cloud system automatically predicts the disease and displays it on a mobile display.},
  archive      = {J_NCA},
  author       = {Lanjewar, Madhusudan G. and Panchbhai, Kamini G.},
  doi          = {10.1007/s00521-022-07743-y},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2755-2771},
  shortjournal = {Neural Comput. Appl.},
  title        = {Convolutional neural network based tea leaf disease prediction system on smart phone using paas cloud},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Adaptive 1-dimensional time invariant learning for inertial
sensor-based gait authentication. <em>NCA</em>, <em>35</em>(3),
2737–2753. (<a
href="https://doi.org/10.1007/s00521-022-07741-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable-sensor gait signals processed using advanced machine learning algorithms are shown to be reliable for user authentication. However, no study has been reported to investigate the influence of elapsed time on wearable sensor-based gait authentication performance. This work is the first exploratory study that presents accelerometer and gyroscope signals from 144 participants with slow, normal, and fast walking speeds from 2 sessions (1-month elapse time) to evaluate IMU gait-based authentication performance. Gait signals are recorded in six positions (i.e., left and right pocket, left and right hand, handbag, and backpack). The users&#39; identities are verified using a robust gait authentication method called Adaptive 1-Dimensional Time Invariant Learning (A1TIL). In A1TIL, 1D Local Ternary Patterns (LTP) with an adaptive threshold is proposed to extract discriminative time-invariant features from a gait cycle. In addition, a new unsupervised learning method called Kernelized Domain Adaptation (KDA) is applied to match two gait signals from different time spans for user verification. Comprehensive experiments have been conducted to assess the effectiveness of the proposed approach on a newly developed time invariant inertial sensor dataset. The promising result with an Equal Error Rate (EER) of 4.38\% from slow walking speed and right pocket position across 1 month demonstrates that gait signals extracted from inertial sensors can be used as a reliable means of biometrics across time.},
  archive      = {J_NCA},
  author       = {Permatasari, Jessica and Connie, Tee and Ong, Thian Song and Teoh, Andrew Beng Jin},
  doi          = {10.1007/s00521-022-07741-0},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2737-2753},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive 1-dimensional time invariant learning for inertial sensor-based gait authentication},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge-aware attentional neural network for review-based
movie recommendation with explanations. <em>NCA</em>, <em>35</em>(3),
2717–2735. (<a
href="https://doi.org/10.1007/s00521-022-07689-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a knowledge-aware attentional neural network (KANN) for dealing with movie recommendation tasks by extracting knowledge entities from movie reviews and capturing understandable interactions between users and movies at the knowledge level. In most recommendation systems, review information is already widely utilized to uncover the explicit preferences of users for items, especially for domains including movie recommendations, music recommendations, and book recommendations, as reviews are full of knowledge entities relevant to the domain. When processing review information, current methods usually use word embeddings to represent reviews for modeling users and items. As a result, they may split the meaning of a phrase, and thereby induce erroneous predictions. Moreover, most methods capture high-order interactions between users and items after obtaining latent low-dimensional representations, which means they cannot discover understandable interactions or provide knowledge-level explanations. By incorporating knowledge graph representation into movie recommendation tasks, the proposed KANN can not only capture the inner attention among user (movie) reviews but also compute the outer attention values between users and movies before generating corresponding latent vector representations. These characteristics enable the explicit preferences of users for movies to be learned and understood. We test our model on two datasets (IMDb and Amazon) for the movie rating prediction task and the click-through rate prediction task and show that it outperforms some of the existing state-of-the-art models and gains outstanding prediction performances in cases with a very small amount of reviews. Furthermore, we demonstrate the high explainability of the proposed KANN by visualizing the interaction between users and movies through a case study. Our results and analyses highlight the relatively high effectiveness and reliability of KANN for movie recommendation tasks.},
  archive      = {J_NCA},
  author       = {Liu, Yun and Miyazaki, Jun},
  doi          = {10.1007/s00521-022-07689-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2717-2735},
  shortjournal = {Neural Comput. Appl.},
  title        = {Knowledge-aware attentional neural network for review-based movie recommendation with explanations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MLP neural network with an optimal architecture for modeling
the ECAP-c process. <em>NCA</em>, <em>35</em>(3), 2701–2715. (<a
href="https://doi.org/10.1007/s00521-022-07685-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Equal Channel Angular Pressing-Conform (ECAP-C) process is one of the Severe Plastic Deformation (SPD) methods used to create the ultrafine-grained structure. The current study investigates an optimized artificial neural network for modeling the ECAP-C process based on experimental tests and finite element methods. The ECAP-C process of AA 7075 was performed for validation of the finite element model. After validating, the design of experiments was carried out using the response surface method. The process parameters include the rotary wheel radius, the rod contact angle, the die channel angle, outer corner angle of die, the friction coefficient (between rod and roller, and between rod and die), and the aspect ratio of the die channel. Moreover, the responses are the required torque, yield strength, output rod curvature, and strain non-uniformity at the rod cross section. For modeling with the neural network, a Multi-Layer Perceptron (MLP) network is considered, while its structure is optimized using two metaheuristic methods, i.e., Particle Swarm Optimization (PSO) and Whale Optimization Algorithm (WOA). It was found that the MLP network with two hidden layers can efficiently predict the process outputs, with 40 and 7 neurons in its first and second hidden layers, respectively. Furthermore, the comparison of experimental and numerical results has an acceptable agreement.},
  archive      = {J_NCA},
  author       = {Moradi, Sadegh and Gerdooei, Mahdi and Varedi-Koulaei, Seyyed Mojtaba and Nosrati, Hasan Ghaforian},
  doi          = {10.1007/s00521-022-07685-5},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2701-2715},
  shortjournal = {Neural Comput. Appl.},
  title        = {MLP neural network with an optimal architecture for modeling the ECAP-C process},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Levy flight-particle swarm optimization-assisted BiLSTM +
dropout deep learning model for short-term load forecasting.
<em>NCA</em>, <em>35</em>(3), 2679–2700. (<a
href="https://doi.org/10.1007/s00521-022-07751-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new optimized Deep Learning (DL) network design for time series load forecasting. At first, DL’s hyper parameters are optimized using the Levy flight-particle swarm optimization (LF-PSO) technique; then, the optimized DL model is used for load prediction. Furthermore, the results are compared with the existing state-of-the-art techniques to show prediction accuracy. Experiment and measured values indicate that the proposed new DL model is highly efficient for load prediction.},
  archive      = {J_NCA},
  author       = {Kiruthiga, D. and Manikandan, V.},
  doi          = {10.1007/s00521-022-07751-y},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2679-2700},
  shortjournal = {Neural Comput. Appl.},
  title        = {Levy flight-particle swarm optimization-assisted BiLSTM + dropout deep learning model for short-term load forecasting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced PSO algorithm to configure a
responsive-resilient supply chain network considering environmental
issues: A case study of the oxygen concentrator device. <em>NCA</em>,
<em>35</em>(3), 2647–2678. (<a
href="https://doi.org/10.1007/s00521-022-07739-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the hyper-competitive marketplace has led to a drastic enhancement in the importance of the supply chain problem. Hence, the attention of managers and researchers has been attracted to one of the most crucial problems in the supply chain management area called the supply chain network design problem. In this regard, this research attempts to design an integrated forward and backward logistics network by proposing a multi-objective mathematical model. The suggested model aims at minimizing the environmental impacts and the costs while maximizing the resilience and responsiveness of the supply chain. Since uncertainty is a major issue in the supply chain problem, the present paper studies the research problem under the mixed uncertainty and utilizes the robust possibilistic stochastic method to cope with the uncertainty. On the other side, since configuring a supply chain is known as an NP-Hard problem, this research develops an enhanced particle swarm optimization algorithm to obtain optimal/near-optimal solutions in a reasonable time. Based on the achieved results, the developed algorithm can obtain high-quality solutions (i.e. solutions with zero or a very small gap from the optimal solution) in a reasonable amount of time. The achieved results demonstrate the negative impact of the enhancement of the demand on environmental damages and the total cost. Also, according to the outputs, by increasing the service level, the total cost and environmental impacts have increased by 41\% and 10\%, respectively. On the other hand, the results show that increasing the disrupted capacity parameters has led to a 17\% increase in the total costs and a 7\% increase in carbon emissions.},
  archive      = {J_NCA},
  author       = {Nasrollah, Soodeh and Najafi, S. Esmaeil and Bagherzadeh, Hadi and Rostamy-Malkhalifeh, Mohsen},
  doi          = {10.1007/s00521-022-07739-8},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2647-2678},
  shortjournal = {Neural Comput. Appl.},
  title        = {An enhanced PSO algorithm to configure a responsive-resilient supply chain network considering environmental issues: A case study of the oxygen concentrator device},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective hybrid graph and hypergraph convolution network
for collaborative filtering. <em>NCA</em>, <em>35</em>(3), 2633–2646.
(<a href="https://doi.org/10.1007/s00521-022-07735-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, graph convolution networks and hypergraph convolution networks have become a research hotspot in collaborative filtering (CF) because of their information extraction ability in dealing with the user-item interaction information. In particular, hypergraph can model high-order correlation of users and items to achieve better performance. However, the existing graph-based CF methods for mining interactive information remain incomplete and limit the expressiveness of the model. Moreover, they directly use low-order Chebyshev polynomials to fit the convolution kernel of graph and hypergraph without experimental proof or analysis, lacking interpretability. We propose an effective hybrid graph and hypergraph convolutional network (EHGCN) for CF to obtain a capable and interpretable framework. In EHGCN, the graph and the hypergraph are used to model the correlation among nodes in the interaction graph for multilevel learning. EHGCN also optimizes the information flow framework to match the improved convolution strategy of the graph and hypergraph we proposed. Extensive experiments on four real-world datasets show the considerable improvements of EHGCN over other state-of-the-art methods. Moreover, we analyze the graph and hypergraph convolution kernel in terms of the spectral domain to reveal the core of the graph-based CF, which has a heuristic effect on future work.},
  archive      = {J_NCA},
  author       = {Li, Xunkai and Guo, Ronghui and Chen, Jianwen and Hu, Youpeng and Qu, Meixia and Jiang, Bin},
  doi          = {10.1007/s00521-022-07735-y},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2633-2646},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effective hybrid graph and hypergraph convolution network for collaborative filtering},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MEDIC: A multi-task learning dataset for disaster image
classification. <em>NCA</em>, <em>35</em>(3), 2609–2632. (<a
href="https://doi.org/10.1007/s00521-022-07717-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research in disaster informatics demonstrates a practical and important use case of artificial intelligence to save human lives and suffering during natural disasters based on social media contents (text and images). While notable progress has been made using texts, research on exploiting the images remains relatively under-explored. To advance image-based approaches, we propose MEDIC ( https://crisisnlp.qcri.org/medic/index.html ), which is the largest social media image classification dataset for humanitarian response consisting of 71,198 images to address four different tasks in a multi-task learning setup. This is the first dataset of its kind: social media images, disaster response, and multi-task learning research. An important property of this dataset is its high potential to facilitate research on multi-task learning, which recently receives much interest from the machine learning community and has shown remarkable results in terms of memory, inference speed, performance, and generalization capability. Therefore, the proposed dataset is an important resource for advancing image-based disaster management and multi-task machine learning research. We experiment with different deep learning architectures and report promising results, which are above the majority baselines for all tasks. Along with the dataset, we also release all relevant scripts ( https://github.com/firojalam/medic ).},
  archive      = {J_NCA},
  author       = {Alam, Firoj and Alam, Tanvirul and Hasan, Md. Arid and Hasnat, Abul and Imran, Muhammad and Ofli, Ferda},
  doi          = {10.1007/s00521-022-07717-0},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2609-2632},
  shortjournal = {Neural Comput. Appl.},
  title        = {MEDIC: A multi-task learning dataset for disaster image classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A CNN-based android application for plant leaf
classification at remote locations. <em>NCA</em>, <em>35</em>(3),
2601–2607. (<a
href="https://doi.org/10.1007/s00521-022-07740-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Earth has witnessed the evolution of thousands of plant species in the kingdom named Plantae. Due to the diversity and subtle differences in each plant, it becomes difficult for a novice to identify a particular plant and to know the properties associated with it. We propose a classification model that can solve this issue by categorizing the input plant image. Our methodology can classify up to 79 different plant species found predominantly in Himachal Pradesh located in India. A Deep Learning-based model is used to carry out the classification. Our model is optimized to work efficiently without a live internet connection on smartphones and other devices with limited computational power. A total of 79 distinct classes were classified using the Convolution neural network DenseNet-161 model architecture with a testing accuracy of 97.3\%. The application works on any android platform and can classify the input plant image with an average latency of 1.98 s. Our application built on this model assists farmers and locals to get in-depth knowledge about the species including the local name, scientific name, description, and the care requirements by uploading or taking a picture of the plant leaf.},
  archive      = {J_NCA},
  author       = {Shelke, Ankita and Mehendale, Ninad},
  doi          = {10.1007/s00521-022-07740-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2601-2607},
  shortjournal = {Neural Comput. Appl.},
  title        = {A CNN-based android application for plant leaf classification at remote locations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Automatic detection of indoor occupancy based on improved
YOLOv5 model. <em>NCA</em>, <em>35</em>(3), 2575–2599. (<a
href="https://doi.org/10.1007/s00521-022-07730-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor occupancy detection is essential for energy efficiency control and Coronavirus Disease 2019 traceability. The number and location of people can be accurately identified and determined through classroom surveillance video analysis. This information is used to manage environmental equipment such as HVAC and lighting systems to reduce energy use. However, the mainstream one-stage YOLO algorithm still uses an anchor-based mechanism and couples detection heads to predict. This results in slow model convergence and poor detection performance for densely occluded targets. Therefore, this paper proposed a novel decoupled anchor-free VariFocal loss convolutional network algorithm DFV-YOLOv5 for occupancy detection to tackle these problems. The proposed method uses the YOLOv5 algorithm as a baseline. It uses the anchor-free mechanism to reduce the number of design parameters needing heuristic tuning. Afterwards, to reduce the coupling of the model, speed up the model’s convergence ability, and improve the model detection performance, the detection head is decoupled based on the YOLOv5 model. It can resolve the conflict between classification and regression tasks. In addition, we use the VariFocal loss to assign more weights to difficult data points to optimize the class imbalance problem and use the training target q to measure positive samples, treating positive and negative samples asymmetrically. The total loss function is redesigned, the $$L_{1}$$ loss is increased, and the ablation experiment verifies the effect of the improved loss. By applying a hybrid activation function of the sigmoid linear unit and rectified linear unit, we improved the model’s nonlinear representation and reduced the model’s inference time. Finally, a classroom dataset was constructed to validate the occupancy detection performance of the model. The proposed model was compared with mainstream target detection models regarding average mean precision, memory allocation, execution time, and the number of parameters on the VOC2012, CrowdHuman and self-built datasets. The experimental results show that the method significantly improves the detection accuracy and robustness, shortens the inference time, and proves the practicality of the algorithm in occupancy detection compared with the mainstream target detection model and related variants of the model.},
  archive      = {J_NCA},
  author       = {Wang, Chao and Zhang, Yunchu and Zhou, Yanfei and Sun, Shaohan and Zhang, Hanyuan and Wang, Yepeng},
  doi          = {10.1007/s00521-022-07730-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2575-2599},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic detection of indoor occupancy based on improved YOLOv5 model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-head adjacent attention-based pyramid layered model
for nested named entity recognition. <em>NCA</em>, <em>35</em>(3),
2561–2574. (<a
href="https://doi.org/10.1007/s00521-022-07747-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is one of the widely studied natural language processing tasks in recent years. Conventional solutions treat the NER as a sequence labeling problem, but these approaches cannot handle nested NER. This is due to the fact that nested NER refers to the case where one entity contains another entity and it is not feasible to tag each token with a single tag. The pyramid model stacks L flat NER layers for prediction, which subtly enumerates all spans with length less than or equal to L. However, the original model introduces a block consisting of a convolutional layer and a bidirectional long short-term memory (Bi-LSTM) layer as the decoder, which does not consider the dependency between adjacent inputs and the Bi-LSTM cannot perform parallel computation on sequential inputs. For the purpose of improving performance and reducing the forward computation, we propose a Multi-Head Adjacent Attention-based Pyramid Layered model. In addition, when constructing a pyramid structure for span representation, the information of the intermediate words has more proportion than words on the two sides. To address this imbalance in the span representation, we fuse the output of the attention layer with the features of head and tail words when doing classification. We conducted experiments on nested NER datasets such as GENIA, SciERC, and ADE to validate the effectiveness of our proposed model.},
  archive      = {J_NCA},
  author       = {Cui, Shengmin and Joe, Inwhee},
  doi          = {10.1007/s00521-022-07747-8},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2561-2574},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-head adjacent attention-based pyramid layered model for nested named entity recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An attention-guided convolutional neural network for
automated classification of brain tumor from MRI. <em>NCA</em>,
<em>35</em>(3), 2541–2560. (<a
href="https://doi.org/10.1007/s00521-022-07742-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis of brain tumor using magnetic resonance imaging (MRI) is vital for timely medication and effective treatment. But, most people living in remote areas do not have access to medical experts and diagnosis facilities. Nevertheless, recent advancement in the Internet of Thing and artificial intelligence is transforming the healthcare system and has led to the development of the Internet of Medical Things (IoMT). An automated brain tumor classification system integrated with the IoMT framework can aid in remotely diagnosing brain tumors. However, the existing methods for brain tumor classification in MRI based on traditional machine learning and deep learning are compute-intensive. Deployment of these methods in the real-world clinical setup poses a serious challenge. Therefore, there is a requirement for robust and compute-efficient techniques for brain tumor classification. To this end, this paper presents a novel lightweight attention-guided convolutional neural network (AG-CNN) for brain tumor classification in magnetic resonance (MR) images. The designed architecture uses channel-attention blocks to focus on relevant regions of the image for tumor classification. Besides, AG-CNN uses skip connections via global-average pooling to fuse features from different stages. This approach helps the network extract enhanced features essential to differentiate tumor and normal brain MR images. To access the efficacy of the designed neural network, we evaluated it on four benchmark brain tumor MRI datasets. The comparison results with the existing state-of-the-art methods revealed the robustness and computational efficiency of the proposed AG-CNN model. The designed brain tumor classification pipeline can be easily deployed on a resource-constrained embedded platform and used in real-world clinical settings to quickly classify brain tumors in MR images.},
  archive      = {J_NCA},
  author       = {Saurav, Sumeet and Sharma, Ayush and Saini, Ravi and Singh, Sanjay},
  doi          = {10.1007/s00521-022-07742-z},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2541-2560},
  shortjournal = {Neural Comput. Appl.},
  title        = {An attention-guided convolutional neural network for automated classification of brain tumor from MRI},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed fixed-time NN tracking control of vehicular
platoon systems with singularity-free. <em>NCA</em>, <em>35</em>(3),
2527–2540. (<a
href="https://doi.org/10.1007/s00521-022-07725-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on a distributed adaptive singularity-free fixed-time neural network tracking control problem for vehicular platoon with model uncertainties. The reference trajectory of platoon is modeled based on the actual driving conditions including four stages. Moreover, the adaptive neural network and $$H_\infty $$ control theory are adopted to tackle unknown nonlinearities and mismatched complete disturbances of third-order vehicle dynamics. Bying integrating fixed-time control with backstepping technology, a distributed adaptive singularity-free fixed-time control protocol is constructed. Meanwhile, a smooth switching function is designed to effectively deal with the conventional fixed-time singularity problem caused by differentiation of a virtual control law. Compared with the existing results, both cases of the designed switching function are practically fixed-time stable. Finally, the effectiveness of the presented control strategy is further attested by simulation experiments of four different scenarios that may take place in actual traffic, including simulation comparisons and one noise analysis.},
  archive      = {J_NCA},
  author       = {An, Jiaxin and Liu, Yang and Sun, Jize and Wang, Lijie and Xue, Hong},
  doi          = {10.1007/s00521-022-07725-0},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2527-2540},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distributed fixed-time NN tracking control of vehicular platoon systems with singularity-free},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Β-CapsNet: Learning disentangled representation for CapsNet
by information bottleneck. <em>NCA</em>, <em>35</em>(3), 2503–2525. (<a
href="https://doi.org/10.1007/s00521-022-07729-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a framework for learning disentangled representation of CapsNet by information bottleneck constraint that distills information into a compact form and motivates to learn an interpretable capsule. In our β-CapsNet framework, the hyperparameter β is utilized to trade off disentanglement and other tasks, and variational inference is utilized to convert the information bottleneck constraint into a KL divergence term that is approximated as a constraint on the mean of the capsule. For supervised learning, class-independent mask vector is used for understanding the types of variations synthetically irrespective of the image class, and we carry out extensive quantitative and qualitative experiments by tuning the parameter β to figure out the relationship between disentanglement, reconstruction and classification performance. Furthermore, the unsupervised β-CapsNet and the corresponding dynamic routing algorithm are proposed for learning disentangled capsule in an unsupervised manner, and extensive empirical evaluations suggest that our β-CapsNet achieves state-of-the-art disentanglement performance compared to CapsNet and various baselines on several complex datasets both in supervision and unsupervised scenes.},
  archive      = {J_NCA},
  author       = {Hu, Ming-fei and Liu, Jian-wei},
  doi          = {10.1007/s00521-022-07729-w},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2503-2525},
  shortjournal = {Neural Comput. Appl.},
  title        = {β-CapsNet: Learning disentangled representation for CapsNet by information bottleneck},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Düzen: Generating the structural model from the software
source code using shuffled frog leaping algorithm. <em>NCA</em>,
<em>35</em>(3), 2487–2502. (<a
href="https://doi.org/10.1007/s00521-022-07716-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cost of software maintenance is heavily influenced by program understanding. When the source code is the only product accessible, maintainers spend a significant amount of effort trying to understand the structure and behavior of the software. Program module clustering is a useful reverse-engineering technique for obtaining the software structural model from source code. Finding the best clustering is regarded as an NP-hard optimization problem, and several meta-heuristic methods have been employed to solve it. The fundamental flaws of the prior approaches were their insufficient performance and effectiveness. The major goals of this research are to achieve improved software clustering quality and stability. A new method (Düzen) is proposed in this research for improving software module clustering. As a meta-heuristic memetic algorithm, this technique employs the shuffled frog-leaping algorithm. The Düzen results were investigated and compared to those produced using earlier approaches. In terms of obtaining the best clustering quality, the proposed method was shown to be better and more successful than the others; it also had higher data stability and data convergence to optimal replies in a fewer number of repetitions. Furthermore, it acquired a higher data mean and a faster clustering execution time.},
  archive      = {J_NCA},
  author       = {Arasteh, Bahman and Karimi, Mohammad Bagher and Sadegi, Razieh},
  doi          = {10.1007/s00521-022-07716-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2487-2502},
  shortjournal = {Neural Comput. Appl.},
  title        = {Düzen: Generating the structural model from the software source code using shuffled frog leaping algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integration of global and local information for text
classification. <em>NCA</em>, <em>35</em>(3), 2471–2486. (<a
href="https://doi.org/10.1007/s00521-022-07727-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is the most fundamental and foundational problem in many natural language processing applications. Recently, the graph-based model (e.g., GNN-based model and GCN-based model) has been applied to this task and achieved excellent performance because of their superior capacity of modeling context from the global perspective. However, a multitude of existing graph-based models constructs a corpus-level graph structure which causes a high memory consumption and overlooks the local contextual information. To address these issues, we present a novel GNN-based model which contains a new model for building a text graph for text classification. The proposed model is called two sliding windows text GNN-based model (TSW-GNN). To be more specific, a unique text-level graph is constructed for each text, which contains a dynamic global window and a local sliding window. The local window slides inside the text to construct local word connections. Additionally, the dynamic global window slides between texts to determine word edge weights, which conquers the limitation of a single local sliding window and provides more abundant global information. We perform extensive experiments on seven benchmark datasets, and the experimental results manifest the amelioration of TSW-GNN over the most advanced models in terms of the classification accuracy.},
  archive      = {J_NCA},
  author       = {Li, Xianghua and Wu, Xinyu and Luo, Zheng and Du, Zhanwei and Wang, Zhen and Gao, Chao},
  doi          = {10.1007/s00521-022-07727-y},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2471-2486},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integration of global and local information for text classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards an efficient backbone for preserving features in
speech emotion recognition: Deep-shallow convolution with recurrent
neural network. <em>NCA</em>, <em>35</em>(3), 2457–2469. (<a
href="https://doi.org/10.1007/s00521-022-07723-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion recognition (SER) has attracted a great deal of research interest, which plays as a critical role in human-machine interactions. Unlike other visual tasks, SER becomes intractable when the convolutional neural networks (CNNs) are employed, owing to their limitation in handling log-mel spectrograms. Therefore, it is useful to establish a feature-extraction backbone that allows CNNs to maintain information integrity of speech utterances when utilizing log-mel spectrograms. Moreover, a neural network with a deep stack of layers can lead to a performance degradation due to various challenges, including information loss, overfitting, or vanishing gradient issues. Many studies employ hybrid/multi-modal methods or specialized network designs to mitigate these obstacles. However, those methods often are unstable, hard to configure and non-adaptive to different tasks. In this research, we propose a reusable backbone pertaining to CNN blocks for undertaking SER tasks, as inspired by the FishNet model. denoted as deep-swallow convolution with RNN (DSCRNN), this proposed backbone method preserves features from both deep and shallow layers, which is effective in improving quality of features extracted from log-mel spectrograms. Simulation results indicate that our proposed DSCRNN backbone achieves improved accuracy rates of 2\% and 11\% when comparing with those from a baseline model with traditional CNN blocks in a speaker-independent evaluation utilizing the RAVDESS dataset with 4 classes and 8 classes, respectively.},
  archive      = {J_NCA},
  author       = {Goel, Dev Priya and Mahajan, Kushagra and Nguyen, Ngoc Duy and Srinivasan, Natesan and Lim, Chee Peng},
  doi          = {10.1007/s00521-022-07723-2},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2457-2469},
  shortjournal = {Neural Comput. Appl.},
  title        = {Towards an efficient backbone for preserving features in speech emotion recognition: Deep-shallow convolution with recurrent neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimation of seepage velocity and piping resistance of
fiber-reinforced soil by using artificial neural network-based approach.
<em>NCA</em>, <em>35</em>(3), 2443–2455. (<a
href="https://doi.org/10.1007/s00521-022-07708-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seepage erosion is one of the most important parameters leading to the failure of hydraulic structures like embankments or dams. The present study therefore focuses on developing artificial neural network-based models for preliminary prediction of seepage velocity and piping resistance of fiber-reinforced soil. A wide range of input data with variations in fiber type, soil type, fiber length, and fiber content is taken into account for developing artificial neural network (ANN) models. The performance of ANN models is also compared to that of popular regression models. Moreover, the sensitivity analyses based on Garson’s algorithm and connection weight approach are conducted to rank effective input parameters in ANN formulas. The results indicate that ANN models show great performance in predicting these problems with high coefficient of determination (R2 = 0.995 for seepage velocity and R2 = 0.998 for piping resistance). ANN models are more accurate than regression models in predicting seepage velocity and piping resistance. For example, the root-mean-square error of ANN model for seepage velocity (0.013 cm/s) is significantly smaller than that of the quadratic regression model (0.099 cm/s). According to the connection weight approach, the top three effective parameters on seepage velocity are hydraulic gradient, gravel-sand, and silt–clay, while gravel-sand, critical hydraulic gradient, and specific gravity of soil are three parameters affecting piping resistance the most. In summary, the reliability and precision of ANN models for the estimation of seepage velocity and piping resistance are authenticated.},
  archive      = {J_NCA},
  author       = {Duong, Nga Thanh and Tran, Khiem Quang},
  doi          = {10.1007/s00521-022-07708-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2443-2455},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimation of seepage velocity and piping resistance of fiber-reinforced soil by using artificial neural network-based approach},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical decoding with latent context for image
captioning. <em>NCA</em>, <em>35</em>(3), 2429–2442. (<a
href="https://doi.org/10.1007/s00521-022-07726-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining more rich visual features and analyzing the context information from image for decoding part has become a challenging problem in image captioning. Some recent works employ other knowledge bases to obtain the additional objects semantic relationships by constructing scene graph, which spend much time on pre-training scene graph and these artificial defined relationships may not be comprehensive. In this paper, a novel hierarchical decoding with latent context method is proposed for image captioning, which analyzes the visual context information and decodes multi-level visual features by a hierarchical decoding method to achieve more accurate caption words. In our proposed method, a novel Latent Context Generation Network (LCGN) is proposed to infer latent relationships between objects without any external knowledge, and meanwhile, a context vector which contains rich neighbor information for each object is constructed. Then a graph convolutional network with attention is used to further aggregate latent context information for achieving high-level context features by combining objects features and their context vectors. Finally, hierarchical decoding based on Triple Long Short-Term Memory (Tri-LSTM) is proposed to decode global features, local features and object features hierarchically, which gradually analyzes the content of the image from the whole to the local to the object. Experiments on MSCOCO dataset prove that our proposed method can achieve extremely competitive results in image captioning and outperform most CNN-RNN architecture methods.},
  archive      = {J_NCA},
  author       = {Zhang, Jing and Xie, Yingshuai and Li, Kangkang and Wang, Zhe and Du, Wen},
  doi          = {10.1007/s00521-022-07726-z},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2429-2442},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical decoding with latent context for image captioning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical conversation flow transition and reasoning for
conversational machine comprehension. <em>NCA</em>, <em>35</em>(3),
2413–2428. (<a
href="https://doi.org/10.1007/s00521-022-07720-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational Machine Comprehension (CMC) is a challenging task with a broad range of applications in natural language processing. Early approaches deal with CMC in a single-turn setting as traditional MRC. Recent studies have proposed multi-turn models by introducing the information flow mechanism to consider the temporal dependencies among the follow-up questions along with a conversation. However, previous methods merely consider shallow semantic dependencies at the “token-to-token” level and short-term temporal dependencies, and ignore the global transition information during the understanding and reasoning process. In this paper, we propose a Hierarchical Conversation Flow Transition and Reasoning (HCFTR) model for conversational machine comprehension. A multi-flow transition mechanism is designed to integrate the globally-aware information flow transition and make dynamic reasoning. In addition, another multi-level flow-context attention mechanism is developed to fuse multiple levels of hierarchical fine-grained representations and perform advanced reasoning. Experimental results on two benchmark datasets show that our model outperforms the strong baseline methods.},
  archive      = {J_NCA},
  author       = {Liu, Xiao and Yang, Min and Lyu, Ziyu and Lin, Dongding and Li, Piji and Xu, Ruifeng},
  doi          = {10.1007/s00521-022-07720-5},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2413-2428},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical conversation flow transition and reasoning for conversational machine comprehension},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Face enhancement and hallucination in the wild.
<em>NCA</em>, <em>35</em>(3), 2399–2412. (<a
href="https://doi.org/10.1007/s00521-022-07713-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering facial details from dark images has attracted increasing attention due to its potential in various applications such as video surveillance. We propose the first approach to detect and enhance human faces in extremely low-light images. We at first propose an attention module (AM) to detect the facial skin which is relatively robust to the low-quality condition. The AM further locates the landmarks as the prior knowledge to facilitate the reconstruction. Then, with the detected face position, our face hallucination module (FHM) could focus on enhancing the resolution and quality of the face. Moreover, we also introduce a low-light enhancement module to enhance the global image to merge with the hallucinated face from FHM for the final images. Extensive experiments show our method is quantitatively and qualitatively superior to the state-of-the-art in terms of enhancement quality and face hallucination.},
  archive      = {J_NCA},
  author       = {Ding, Xin and Hu, Ruimin and Wang, Zhongyuan},
  doi          = {10.1007/s00521-022-07713-4},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2399-2412},
  shortjournal = {Neural Comput. Appl.},
  title        = {Face enhancement and hallucination in the wild},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A siamese network-based tracking framework for hyperspectral
video. <em>NCA</em>, <em>35</em>(3), 2381–2397. (<a
href="https://doi.org/10.1007/s00521-022-07712-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of hyperspectral imaging techniques, hyperspectral video visual tracking comes to a breakthrough because its abundant material-based spectral information has strong discrimination ability in complex background. Most existing hyperspectral trackers use hand-craft features to represent the appearances of targets, but their performances are limited for the lack of semantic information in those low-level features. Despite the successes of deep networks on color video, the limited training samples bring difficulties to train a deep learning model-based hyperspectral tracker. To handle well with above problems, we present a novel deep hyperspectral tracker based on Siamese network (SiamHT). In our proposed method, heterogeneous encoder–decoder (HED) and spectral semantic representation (SSR) modules are designed to extract the spatial and spectral semantic features, respectively. After that parameters in HED and SSR modules are learned with a designed two-stage training strategy. Finally, the well-learned spatial and spectral semantic representations are fused to estimate the state of a target. Extensive comparison experiments on hyperspectral object tracking dataset are performed to prove the robustness of our method.},
  archive      = {J_NCA},
  author       = {Tang, Yiming and Huang, Hong and Liu, Yufei and Li, Yuan},
  doi          = {10.1007/s00521-022-07712-5},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2381-2397},
  shortjournal = {Neural Comput. Appl.},
  title        = {A siamese network-based tracking framework for hyperspectral video},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal fractional-order PID controller based on
fractional-order actor-critic algorithm. <em>NCA</em>, <em>35</em>(3),
2347–2380. (<a
href="https://doi.org/10.1007/s00521-022-07710-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an online optimization approach of a fractional-order PID controller based on a fractional-order actor-critic algorithm (FOPID-FOAC) is proposed. The proposed FOPID-FOAC scheme exploits the advantages of the FOPID controller and FOAC approaches to improve the performance of nonlinear systems. The proposed FOAC is built by developing a FO-based learning approach for the actor-critic neural network with adaptive learning rates. Moreover, a FO rectified linear unit (RLU) is introduced to enable the AC neural network to define and optimize its own activation function. By the means of the Lyapunov theorem, the convergence and the stability analysis of the proposed algorithm are investigated. The FO operators for the FOAC learning algorithm are obtained using the gray wolf optimization (GWO) algorithm. The effectiveness of the proposed approach is proven by extensive simulations based on the tracking problem of the two degrees of freedom (2-DOF) helicopter system and the stabilization issue of the inverted pendulum (IP) system. Moreover, the performance of the proposed algorithm is compared against optimized FOPID control approaches in different system conditions, namely when the system is subjected to parameter uncertainties and external disturbances. The performance comparison is conducted in terms of two types of performance indices, the error performance indices, and the time response performance indices. The first one includes the integral absolute error (IAE), and the integral squared error (ISE), whereas the second type involves the rising time, the maximum overshoot (Max. OS), and the settling time. The simulation results explicitly indicate the high effectiveness of the proposed FOPID-FOAC controller in terms of the two types of performance measurements under different scenarios compared with the other control algorithms.},
  archive      = {J_NCA},
  author       = {Shalaby, Raafat and El-Hossainy, Mohammad and Abo-Zalam, Belal and Mahmoud, Tarek A.},
  doi          = {10.1007/s00521-022-07710-7},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2347-2380},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal fractional-order PID controller based on fractional-order actor-critic algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method of constructing a fine-grained sentiment lexicon
for the humanities computing of classical chinese poetry. <em>NCA</em>,
<em>35</em>(3), 2325–2346. (<a
href="https://doi.org/10.1007/s00521-022-07690-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Chinese classics, the sentiment attitudes or thoughts of the ancients regarding specific environments, people, and events were generally expressed in the form of poetry. Compared with previous attempts to classify the polarity of poetry, sentiment terms can be used to detect more fine-grained humanity knowledge in literary information resources. However, the existing techniques of domain sentiment lexicon construction fail to take full advantage of deep learning and linguistic knowledge, which cannot ensure the term integrity and accuracy. To this end, this work proposes a novel approach for the construction of a sentiment lexicon via the combination of supervised sentiment term extraction and classification, aiming at incorporating multi-dimensional linguistic knowledge into a two-phase deep learning model. A character-sequence labeling model for term extraction is first constructed by fusing the emotion radical features of Chinese characters, and term embedding augmentation via word knowledge is then carried out to classify the extracted terms. Experiments on Chinese poetry and its appreciation texts validate the superiority of the proposed method, and the model incorporating linguistic knowledge is found to outperform the benchmark models in different metrics. A fine-grained sentiment lexicon with two first classes, five-second classes, 15 third classes, and 14,368 domain terms and unregistered terms is constructed via hierarchical term classification, thereby contributing to the advancement of the interpretability of the humanities computing of classical Chinese poetry.},
  archive      = {J_NCA},
  author       = {Zhang, Wei and Wang, Hao and Song, Min and Deng, Sanhong},
  doi          = {10.1007/s00521-022-07690-8},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2325-2346},
  shortjournal = {Neural Comput. Appl.},
  title        = {A method of constructing a fine-grained sentiment lexicon for the humanities computing of classical chinese poetry},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on deep learning applied to medical images: From
simple artificial neural networks to generative models. <em>NCA</em>,
<em>35</em>(3), 2291–2323. (<a
href="https://doi.org/10.1007/s00521-022-07953-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques, in particular generative models, have taken on great importance in medical image analysis. This paper surveys fundamental deep learning concepts related to medical image generation. It provides concise overviews of studies which use some of the latest state-of-the-art models from last years applied to medical images of different injured body areas or organs that have a disease associated with (e.g., brain tumor and COVID-19 lungs pneumonia). The motivation for this study is to offer a comprehensive overview of artificial neural networks (NNs) and deep generative models in medical imaging, so more groups and authors that are not familiar with deep learning take into consideration its use in medicine works. We review the use of generative models, such as generative adversarial networks and variational autoencoders, as techniques to achieve semantic segmentation, data augmentation, and better classification algorithms, among other purposes. In addition, a collection of widely used public medical datasets containing magnetic resonance (MR) images, computed tomography (CT) scans, and common pictures is presented. Finally, we feature a summary of the current state of generative models in medical image including key features, current challenges, and future research paths.},
  archive      = {J_NCA},
  author       = {Celard, P. and Iglesias, E. L. and Sorribes-Fdez, J. M. and Romero, R. and Vieira, A. Seara and Borrajo, L.},
  doi          = {10.1007/s00521-022-07953-4},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2291-2323},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey on deep learning applied to medical images: From simple artificial neural networks to generative models},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contracting and timing for outsourcing of information system
with uncertain requirements. <em>NCA</em>, <em>35</em>(3), 2279–2289.
(<a href="https://doi.org/10.1007/s00521-022-07355-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research examined the impacts of market conditions on the choice of contract and timing for information system outsourcing. Real options approach is applied to develop several analytical models to investigate the decision making for outsourcing information system. The results show that the information asymmetry, requirement uncertainty, cost structure and vendor’s competition have important impacts on the client’s cost reduction, value of outsourcing option and probability of outsourcing. With symmetric information, the cost reduction, value of outsourcing option and probability of outsourcing under cost-plus contract and fixed-price contract are indifferent. With asymmetric information, however, the two contracts will generate different cost reductions and values of outsourcing option. We identify market conditions under which a contract is superior to others and also characterize the market conditions under which the client can switch to outsourcing or postpone outsourcing.},
  archive      = {J_NCA},
  author       = {Zhang, Zongming and Liao, Rundong and Zhou, Qingyuan},
  doi          = {10.1007/s00521-022-07355-6},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2279-2289},
  shortjournal = {Neural Comput. Appl.},
  title        = {Contracting and timing for outsourcing of information system with uncertain requirements},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multiagent deep deterministic policy gradient-based
distributed protection method for distribution network. <em>NCA</em>,
<em>35</em>(3), 2267–2278. (<a
href="https://doi.org/10.1007/s00521-022-06982-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relay protection system plays an important role in the safe and stable operation of distribution network (DN), and the traditional model-based relay protection algorithms are difficult to solve the impact of the increasing uncertainty caused by distributed generation (DG) access on the security of DN. To solve this issue, first, the relay protection characteristics of DN under DG access are analyzed; second, the DN relay protection problem is transformed into multiagent reinforcement learning (RL) problem; third, a DN distributed protection method based on multiagent deep deterministic policy gradient (MADDPG) is proposed. The advantage of this method is that there is no need to build a DN security model in advance; therefore, it can effectively overcome the impact of uncertainty caused by DG access on DN security . Extensive experiments show the effectiveness of the proposed algorithm.},
  archive      = {J_NCA},
  author       = {Zeng, Peng and Cui, Shijie and Song, Chunhe and Wang, Zhongfeng and Li, Guangye},
  doi          = {10.1007/s00521-022-06982-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2267-2278},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multiagent deep deterministic policy gradient-based distributed protection method for distribution network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information flow-based second-order cone programming model
for big data using rough concept lattice. <em>NCA</em>, <em>35</em>(3),
2257–2266. (<a
href="https://doi.org/10.1007/s00521-022-07289-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to study the rough concept lattice and use the information flow to construct a second-order cone programming model for big data. Through the construction of the model, attribute reduction is performed on the original data of the noise in the formal background. Then, construct the concept lattice according to the reduced formal background, and then analyze the big data in the form of information flow. Then, based on the advantages of the β-upper and lower distribution reduction algorithms of the variable-precision rough set, combine the rough concept. The characteristics of the background of the lattice form, the second-order cone thought method theory is applied, and then a second-order cone calculation model is constructed. The rough concept lattice is applied to the processing of big data, and then it is analyzed and researched through concrete examples. The time required in traditional mode is between 118.3 min and 123.6 min, while the time required for second-order cone and concept lattice fitting is 92.4 min and 98.5 min. Experimental data show that the rough concept lattice uses information flow to construct a second-order cone programming model for big data, which results in a greatly reduced number of nodes in the rough concept lattice and an enhanced anti-noise capability of the system, which saves data statistics and calculation time. The traditional concept lattice algorithm can be traced back to the purification of the formal background, and the purification of the formal background can simplify the concept connotation and study attribute reduction from the perspective of lattice isomorphism. Experimental data show that the rough concept lattice uses information flow to construct a second-order cone programming model for big data, which greatly guarantees the integrity and security of the data by about 15\%, and saves 20\% of the data processing time compared with traditional and algorithms. It has guiding significance for the efficient and secure development of big data in the future. In this paper, data feature mining and information flow model construction are carried out, the power spectral density feature extraction of big data is carried out from a large number of noisy and fuzzy data, and the second-order cone programming model of big data information flow is carried out by rough concept lattice method.},
  archive      = {J_NCA},
  author       = {Wang, Pin and Wu, Wei and Zeng, Lingyu and Zhong, Hongmei},
  doi          = {10.1007/s00521-022-07289-z},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2257-2266},
  shortjournal = {Neural Comput. Appl.},
  title        = {Information flow-based second-order cone programming model for big data using rough concept lattice},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Simulation of AC drive control for supercapacitor trams
based on high-order neural network pattern discrimination algorithm.
<em>NCA</em>, <em>35</em>(3), 2243–2255. (<a
href="https://doi.org/10.1007/s00521-022-07548-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an in-depth study and analysis of the AC drive control simulation of a supercapacitor tram using a high-order neural network pattern discrimination algorithm. Firstly, the line conditions and shunting locomotive operation conditions of a freight coal loading station are analyzed, the capacity of the onboard supercapacitor energy storage device is estimated using traction simulation calculations, the supercapacitor is formed by the series–parallel connection of supercapacitor monoliths group module, and the mathematical model of the supercapacitor energy storage system is obtained. In response to the existence of fuzzy controllers with human-set parameters and potential errors when writing fuzzy rules, the self-learning capability possessed by the adaptive neuro-fuzzy network (ANFIS) is used to improve the accuracy of the prediction model by training and learning to the model a large amount of experimental data with the ANFIS controller, and the simulation model of the dynamic setting of the supercapacitor voltage threshold of the urban rail energy storage system is built using the software, and the comparison and analysis show that the traction network voltage amplitude under the adaptive neuro-fuzzy network control strategy is smaller than the traction network voltage amplitude under the fuzzy control strategy. The global searchability of the optimization algorithm is ensured. In the middle of the search, a medium-precision simplex is used for parallel local search to prevent the searcher from skipping the global optimum in the process of rapid convergence. In the later stage of the search, the optimization range is already within the global optimal range. Subsequently, the advantages and disadvantages of various locomotive topologies are analyzed by using software, and the topology of the supercapacitor shunting locomotive is analyzed according to the design requirements and the actual situation, and the supercapacitor power system scheme of the shunting locomotive is designed, and the traction electric drive system of the supercapacitor shunting locomotive is designed, and its main structural performance parameters are determined. Finally, the overall modeling of supercapacitor shunting locomotive is carried out, including the whole vehicle dynamics model, automatic charging model, supercapacitor model, and motor model, and then, simulation analysis is carried out based on building a relatively perfect model, followed by further stimulation through software to verify the rationality of the design.},
  archive      = {J_NCA},
  author       = {Li, Ling},
  doi          = {10.1007/s00521-022-07548-z},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2243-2255},
  shortjournal = {Neural Comput. Appl.},
  title        = {Simulation of AC drive control for supercapacitor trams based on high-order neural network pattern discrimination algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale memory-enhanced method for predicting the
remaining useful life of aircraft engines. <em>NCA</em>, <em>35</em>(3),
2225–2241. (<a
href="https://doi.org/10.1007/s00521-022-07378-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To guarantee the safe operation of machinery and reduce its maintenance costs, estimating its remaining useful life (RUL) is a crucial task. Hence, in this study, a multi-scale memory-enhanced prediction method is proposed to describe fully characteristics of the data. This method is based on a deep learning algorithm and is designed to estimate the RUL of aircraft engines. To handle the complex and multi-fault operating conditions with uncertain properties in RUL estimation, a hybrid model that combines a multi-scale deep convolutional neural network and long short-term memory is presented. Experimental verification was carried out with the Commercial Modular Aero-Propulsion System Simulation dataset from NASA. Compared with multi-scale deep convolutional and long short-term memory networks, the hybrid model performed more efficiently. Furthermore, compared with other state-of-the-art methods, the multi-scale memory-enhanced prediction method can achieve better prognostics, especially for equipment with multiple operating conditions and failure modes.},
  archive      = {J_NCA},
  author       = {Chen, Wenbai and Liu, Chang and Chen, Qili and Wu, Peiliang},
  doi          = {10.1007/s00521-022-07378-z},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2225-2241},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale memory-enhanced method for predicting the remaining useful life of aircraft engines},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on the improvement of transportation efficiency of
smart city by traffic visualization based on pattern recognition.
<em>NCA</em>, <em>35</em>(3), 2211–2224. (<a
href="https://doi.org/10.1007/s00521-022-07222-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the traffic visualization management technology of smart cities, this paper applies machine learning to smart traffic management, and uses machine learning methods to process and analyze traffic data generated in smart cities. Moreover, this paper uses it to understand the distribution law of traffic data and the internal connections between data, excavate traffic characteristics in smart cities, and accurately predict the future traffic situation, so as to solve the problems of traffic congestion and route planning in smart cities. Moreover, this paper combines improved machine learning algorithms to construct a traffic visualization management system, and designs experiments to verify the performance of the system proposed in this paper. It can be seen from the experimental research results that the method proposed in this paper can play an important role in the traffic management of smart cities.},
  archive      = {J_NCA},
  author       = {Zhang, Yong and Wang, Hao and Wang, Xuede},
  doi          = {10.1007/s00521-022-07222-4},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2211-2224},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on the improvement of transportation efficiency of smart city by traffic visualization based on pattern recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vehicle detection and tracking based on video image
processing in intelligent transportation system. <em>NCA</em>,
<em>35</em>(3), 2197–2209. (<a
href="https://doi.org/10.1007/s00521-022-06979-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an integral part of intelligent transportation system, vehicle detection and tracking system is of great research significance and practical application value. In this paper, based on the mixed Gaussian background model, the detection target is segmented by the different methods, and the most matching target track is found by using the location information and color information of the detection target, so as to realize the vehicle tracking. The experiment results show that for the same target, the centroid distance is less than 0.2, the color distance of HSV (hue saturation value) is less than 0.3, the centroid distance of different targets is less than 0.2, the HSV distance is less than 0.3, and the rest are distributed to some extent. When the centroid distance is 0.01, 0.02, 0.03, 0.04, 0.05 and 0.06, respectively, the matching results are 250, 150, 100, 50, 25 and 10, respectively; when the HSV color distance is 0.02, 0.06, 0.1, 0.14 and 0.18, respectively, the matching results are 160, 200, 100, 80 and 50, respectively. Therefore, for the normalized distance between the same targets, including the centroid distance and HSV color, in each possible matching area, the greater the distance is, the less the distribution of matching results. Experimental verification shows that when the vehicle is detected in the detection area, the effective contour is sequentially accessed and tracked through the memory pointer, and the relatively accurate contour of the moving vehicle can be obtained through the improved Gaussian mixture model. The vehicle detection algorithm based on regional method has high real-time accuracy and strong practical value, can meet the needs of intelligent transportation system, and has strong practical value.},
  archive      = {J_NCA},
  author       = {Ge, Dong-yuan and Yao, Xi-fan and Xiang, Wen-jiang and Chen, Yue-ping},
  doi          = {10.1007/s00521-022-06979-y},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2197-2209},
  shortjournal = {Neural Comput. Appl.},
  title        = {Vehicle detection and tracking based on video image processing in intelligent transportation system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on deep learning image processing technology of
second-order partial differential equations. <em>NCA</em>,
<em>35</em>(3), 2183–2195. (<a
href="https://doi.org/10.1007/s00521-022-07017-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification can effectively manage and organize images, laying a good foundation for the work in multiple fields of image processing. With the rise of Internet technology and social networks, the number of digital images has increased dramatically and there are more and more applications. People also use intuitive pictures instead of words when expressing emotions and information. A large number of digital images need to be managed, analyzed, and retrieved. This urgently requires more efficient and accurate image classification technology. Deep learning is a learning method that extends traditional neural networks, simulating the process of gradual abstraction of human brain cognition. The number of hidden layers is deepened, and features can be learned automatically. This paper has completed the traditional image noise detection and segmentation experiment based on convolutional neural network. We introduced the various parts of the convolutional neural network, including the convolutional layer, activation function, fully connected layer, etc. Noise detection is completed based on Fast RCNN on the MSTAR data set containing the background. The model fully combines the advantages of the isotropic model, the Perona-Malik model, and the second-order directional derivative. In order to better maintain the edge structure information of the image, the structure information is extracted based on the original noise image, and the improved ID model and the improved PM model are directionally diffused along the edge tangent direction of the original noise image. Considering the local structure information of the image, we use the slice similarity modulus value as the edge detector of the improved PM model, and use the slice similarity modulus value to construct a new weighting function to adaptively balance the relative weights of the improved ID model and the improved PM model. Simulation and measured data verify the effectiveness of this network in removing image coherent speckle noise. We compare and analyze it with existing denoising methods. The use of visual evaluation and objective evaluation indicators to evaluate the denoising effect and calculation efficiency shows the advantages of the network in this paper in terms of denoising effect, calculation time and space complexity.},
  archive      = {J_NCA},
  author       = {Wu, Qingzhe},
  doi          = {10.1007/s00521-022-07017-7},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2183-2195},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on deep learning image processing technology of second-order partial differential equations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk decision analysis of commercial insurance based on
neural network algorithm. <em>NCA</em>, <em>35</em>(3), 2169–2182. (<a
href="https://doi.org/10.1007/s00521-022-07199-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the effect of commercial insurance risk decision, this paper applies neural network algorithms to commercial insurance risk decision under the guidance of machine learning ideas, and selects the neural network algorithm based on the actual situation. Moreover, this paper analyzes the nature of risks of commercial insurance, analyzes the types of risks and risk relevance, constructs a commercial insurance risk decision model based on neural network algorithms, and determines the system process. In addition, this paper uses a combination method of qualitative and quantitative to identify the influencing factors of risk estimation to obtain relevant influencing factors, and verify the model proposed in this paper in combination with experimental research. From the experimental research results, it can be seen that the commercial insurance risk decision system based on neural network algorithm is very good in terms of decision effect.},
  archive      = {J_NCA},
  author       = {Wang, Shanshan and Zhao, Zhenwang},
  doi          = {10.1007/s00521-022-07199-0},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2169-2182},
  shortjournal = {Neural Comput. Appl.},
  title        = {Risk decision analysis of commercial insurance based on neural network algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gesture recognition of graph convolutional neural network
based on spatial domain. <em>NCA</em>, <em>35</em>(3), 2157–2167. (<a
href="https://doi.org/10.1007/s00521-022-07040-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the iterative update of computer technology, the penetration of computer and other Internet technologies in human–computer interaction systems has become more and more extensive, and the human–computer interaction methods have quietly undergone huge changes. Gesture recognition has gradually become a hot spot in the field of human–computer interaction now, which has a wide range of application prospects and research value. The color segmentation experiment shows that the skin color of the gesture in the YCrCg space has better clustering properties than in the YCrCb space. In the preprocessing of gesture images, an improved Otsu method is proposed to improve the real-time performance to realize the threshold segmentation of the human hand; then the morphological processing is carried out, and the median filter method is used to achieve image denoising to improve image quality. A gesture recognition algorithm is designed: First, use Graph-SAGE to recognize the graph-structured data of the gesture, and then use the Adaboost algorithm to combine the two strong classifiers of the random forest and the support vector machine into a cascade classifier through the cascade structure. The output information of Graph-SAGE is classified and the meaning of the gesture is analyzed. On the test set, the average detection accuracy of the algorithm is 91.70\%, the recall rate is 94.23\%, and the average detection time per frame is 330 ms.},
  archive      = {J_NCA},
  author       = {Chen, Hong and Zhao, Hongdong and Qi, Baoqiang and Zhang, Shuai and Yu, Zhanghong},
  doi          = {10.1007/s00521-022-07040-8},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2157-2167},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gesture recognition of graph convolutional neural network based on spatial domain},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of loan lost-linking customer path correlated
index model and network sorting search algorithm based on big data
environment. <em>NCA</em>, <em>35</em>(3), 2129–2156. (<a
href="https://doi.org/10.1007/s00521-022-07189-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to track the loan lost-linking customers, we analyzed their historical daily consumption transaction network records (DCTNR), which include bank card transaction records, third-party payment transaction records, and network trading system order details records. We extracted the transaction date, time and address information from their daily consumption transaction path, analyzed the key factors affecting the tracking work, and constructed loan lost-linking customer path correlated index model which is applied to quantify the correlation between the initial search address and other addresses. In addition, we also establish loan customer daily consumption transaction network based on big data environment, propose the network sorting rules and searching rules, and construct the network sorting search algorithm to track loan lost-linking customers in different address types. In the case study, we analyzed the historical DCTNR data of a Chinese bank’s loan lost-linking customer, and applied loan lost-linking customer path correlated index model and network sorting search algorithm to track him in big data environment. The results represent that the method can achieve the purpose of tracking, and the tracking time and cost can be reduced by using network sorting rules and searching rules. It is of great practical significance and scientific guiding significance for banks, financial institutions and major financial platforms to apply big data, artificial intelligence and other information technologies to track loan lost-linking customers and recover economic losses.},
  archive      = {J_NCA},
  author       = {Pang, Sulin and Wang, Jiaqi and Yi, Xiaoshuang},
  doi          = {10.1007/s00521-022-07189-2},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2129-2156},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of loan lost-linking customer path correlated index model and network sorting search algorithm based on big data environment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CNN-based architecture recognition and contour
standardization based on aerial images. <em>NCA</em>, <em>35</em>(3),
2119–2127. (<a
href="https://doi.org/10.1007/s00521-022-07288-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difference between the convolutional neural network and the ordinary neural network is that the convolutional neural network contains a feature extractor composed of a convolutional layer and a subsampling layer. With the development of society and economy, the pace of urbanization is accelerating, and the number and types of urban buildings are also growing rapidly. Digital management has put forward higher requirements for 3D reconstruction of urban buildings. Aiming at explanation the question that sharpness form are proetrate to be blea or bewildered in CNN-supported structure birth from lofty-separation airy conception, an optimise construction birth algorithmic rule is converse to increase the construction brink of proud-resoluteness atmospheric semblance and the twist projection. Remote sensing image target recognition, as the main research content in the current remote sensing image application field, has important theoretical significance and extensive application value. In recent years, deep learning has become an emerging research direction in the field of machine learning, and convolutional neural network is a deep learning model that has been widely studied and applied. More specifically, the construction brink is better by realm vary recursive filter out, and the better appearance is fed into the U-Net nerval netting for making. Afterward, in custom to plentifully take advantage of the sumptuous detail shape of buildings on supercilious sake picture, we tempt to en plot impair from the manage copy and pigeonhole supported on the origin U-Net edifice to increase the school data. These beauty spot can remarkably fortify the procurement of edifice hie viterbilt characteristic in eager and invert intense lore. Finally, construction essence is instrument by mechanical advantage the quotation intense characteristic. The trial effect of edifice extract from the Panjin City have demonstrated that for the hoagie-optimum pattern data with division of shade areas, the everywhere assortment propriety of buildings recognized by U-Net is above 80\%, and the zenith everywhere assortment truth of the amended regularity extension 83\%. In this paper, through the research on the application of convolutional neural network in the field of image segmentation, the problems of low segmentation accuracy, long time and high cost in the task of aerial image building image segmentation are solved to a certain extent. The detection and segmentation method of buildings in aerial images based on CNN can automatically detect and segment buildings, and can segment a large number of buildings in aerial images in batches. In scenarios with high segmentation efficiency requirements.},
  archive      = {J_NCA},
  author       = {Deng, Yi and Xie, Xiaodan and Xing, Chengyue},
  doi          = {10.1007/s00521-022-07288-0},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2119-2127},
  shortjournal = {Neural Comput. Appl.},
  title        = {CNN-based architecture recognition and contour standardization based on aerial images},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cloud-native-based flexible value generation mechanism of
public health platform using machine learning. <em>NCA</em>,
<em>35</em>(3), 2103–2117. (<a
href="https://doi.org/10.1007/s00521-022-07221-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public health machinery learning platform based on cloud-native is a system platform that combines machine learning frameworks and cloud-native technology for public health services. The problem of how its flexible value is realized has been widely concerned by all public health network intelligent researchers. Thus, this article examines the relationship between cloud-native architecture flexibility and cloud provider value and the processes and the boundary condition by which cloud-native architecture flexibility affects cloud provider value based on innovation theory and dynamic capability theory. The results of a survey of 509 platform-related respondents in China show that cloud-native architecture flexibility is positively related to cloud provider value, and both absorptive capacity and supply chain agility mediate the above-mentioned effect. Moreover, R&amp;D subsidies strengthen both the positive relationship between absorptive capacity and cloud provider value and the relationship between supply chain agility and cloud provider value. In this study, cloud-native architecture flexibility, unit absorptive capacity, supply chain agility and R&amp;D subsidies are considered into a flexible value generation mechanism model that extend the relevant research on the value generation mechanism of information system under the background of network intelligence, and to provide relevant enterprises with suggestions on upgrade strategies.},
  archive      = {J_NCA},
  author       = {Jiang, Ming and Wu, Lingzhi and Lin, Liming and Xu, Qiaozhi and Zhang, Weiguo and Wu, Zeyan},
  doi          = {10.1007/s00521-022-07221-5},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2103-2117},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cloud-native-based flexible value generation mechanism of public health platform using machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-analysis of the efficacy of acupuncture and moxibustion
in the treatment of non-motor symptoms of parkinson’s disease.
<em>NCA</em>, <em>35</em>(3), 2089–2101. (<a
href="https://doi.org/10.1007/s00521-022-07198-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the new century, there have been more and more survey reports on the use of acupuncture in the field of tremor and paralysis, reflect the health and accuracy of acupuncture in the field of tremor and paralysis, this article discusses the comparison of the therapeutic effects of acupuncture treatment for tremor paralysis with non-exercise disease, and proposes clinical guiding significance for the treatment of tremor paralysis by acupuncture and moxibustion, and the future-related clinical research can be improved. This paper aims to make acupuncture give full play to its own advantages in the treatment of non-motor symptoms of Parkinson&#39;s disease by studying the Meta-analysis of the efficacy of acupuncture and moxibustion in the treatment of non-motor symptoms of Parkinson&#39;s disease. This paper proposes a classification model of fifty-layer cyclotron neural network based on deep residual framework. After more than 80,000 clinical ECG assessments, the accurate classification of positive abnormal tremor paralysis has been achieved. In this study, a simple random method was used to randomly divide 120 patients into the treatment group (combined governor tremor group), the control group one (Tongdu acupuncture group), and the control group two (tremor three-needle group). After maintaining modern treatment, three types of acupuncture treatments with different main points are added. The combined group of governor and tremor takes Baihui, Shenting, Yintang, Suliao, Houxi, Shenmai, Sishenzhen, Fengchi, Hegu, and Taichong, Xingping replenishing and reducing technique; Tongdu acupuncture group takes Baihui, Shenting, Yintang, Suliao, Houxi, Shenmai, Xingping replenishing and reducing technique; trembling three-needle group takes Sishen needle, Fengchi, Hegu, Tai Chong, the method of replenishing, replenishing and reducing. Meta-analysis uniformly uses tremor paralysis NMS, SCOPA-UT, PDS and several other efficacy observation indicators. This article uses a fixed-effects model to meta-analyze the experimental conclusions. RR = 1.26, 94\% CI is [1.24, 1.71], P = 0.0001 &lt; 0.05, it is considered that the combined effect size is statistically significant, and the effectiveness of acupuncture.},
  archive      = {J_NCA},
  author       = {Huang, Guoli and Guo, Mingang},
  doi          = {10.1007/s00521-022-07198-1},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2089-2101},
  shortjournal = {Neural Comput. Appl.},
  title        = {Meta-analysis of the efficacy of acupuncture and moxibustion in the treatment of non-motor symptoms of parkinson&#39;s disease},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy rule-based neural network for high-speed train
manufacturing system scheduling problem. <em>NCA</em>, <em>35</em>(3),
2077–2088. (<a
href="https://doi.org/10.1007/s00521-022-07190-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our country has a vast territory, and rail transit is very important to the development of our country&#39;s national economy. In this paper, key technologies for a digital twin-based shop floor management and control system are investigated, and the concept is designed and implemented. By adding a digital twin between the business management layer and the production execution layer of the traditional workshop management and control system through the fuzzy rule neural network, a new workshop management and control system architecture on the basis of the virtual is formed, enabling intellectual management and control of the workshop. The results of the study found that the integration of the digital twin into the conventional shop floor management and control system led to changes in the composition, processes and information integration of the management and support system. For the purpose of comparing the system scheduling of the high-speed railway on the basis of the vague rule neural network with the traditional method, we made statistics on the system scheduling before and after the transformation. In terms of manufacturing volume, after the output exceeds 200, the speed of the traditional manufacturing method lags behind the fuzzy rule neural network by nearly 50\%.},
  archive      = {J_NCA},
  author       = {Peng, Fei and Zheng, Li},
  doi          = {10.1007/s00521-022-07190-9},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2077-2088},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy rule-based neural network for high-speed train manufacturing system scheduling problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An intelligent traceability method of water pollution based
on dynamic multi-mode optimization. <em>NCA</em>, <em>35</em>(3),
2059–2076. (<a
href="https://doi.org/10.1007/s00521-022-07002-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drinking water safety is a safety issue that the whole society attaches great importance to currently. For sudden water pollution accidents, it is necessary to trace the water pollution source in real time to determine the pollution source’s characteristic information and provide technical support to emergency management departments for decision making. The problems of water pollution’s real-time traceability are as follows: non-uniqueness and dynamic real time of pollution sources. Aiming at these two difficulties, an intelligent traceability algorithm based on dynamic multi-mode optimization was designed and proposed in the work. As a multi-mode optimization problem, pollution traceability could have multiple similar optimal solutions. Firstly, the new algorithm divided the population reasonably through the optimal subpopulation division strategy, which made the nodes’ distribution in a single subpopulation more similar and conducive to local optimization. Then, a similar peak penalty strategy was used to eliminate similar solutions and reduce the non-unique solutions’ number, since real-time traceability required higher algorithm convergence than traditional offline traceability and dynamic problems with parameter changes, historical information preservation, and adaptive initialization strategies could make reasonable use of the algorithm’s historical knowledge to improve the population space and increase the population convergence rate when the problem changed. The experimental results showed the proposed new algorithm’s effectiveness in solving problems—accurately tracing the source of pollution, and obtain corresponding characteristic information in a short time.},
  archive      = {J_NCA},
  author       = {Wu, Qinghua and Wu, Bin and Yan, Xuesong},
  doi          = {10.1007/s00521-022-07002-0},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2059-2076},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligent traceability method of water pollution based on dynamic multi-mode optimization},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk prediction in financial management of listed companies
based on optimized BP neural network under digital economy.
<em>NCA</em>, <em>35</em>(3), 2045–2058. (<a
href="https://doi.org/10.1007/s00521-022-07377-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of &quot;Internet plus,&quot; the world economy is becoming more and more globalized and informationalized. China&#39;s enterprises are facing unprecedented opportunities for their operation and development. However, it is also facing the financial uncertainties brought about by the fluctuations of the general economic environment, and the company is facing increasing financial risks. The reason why most enterprises encounter a serious financial crisis or even close down in the later stage is that they do not pay full attention to the initial financial problems and do not take effective measures to deal with the crisis in time. Financial risk warning has become an important part of modern enterprise financial management. This paper mainly puts forward the optimized BP neural system as the financial early warning model and ensures its high prediction accuracy. In the research, the operation principle and related reasoning process of the model are described, its shortcomings are analyzed, and solutions are put forward. Through the financial risk analysis of listed companies from 2017 to 2020, we find that the correct rate of the prediction results of the financial distress of normal companies in the selected companies based on the optimized BPNN has reached more than 80\%, which proves the effectiveness of the optimized BPNN.},
  archive      = {J_NCA},
  author       = {Li, Xuetao and Wang, Jia and Yang, Chengying},
  doi          = {10.1007/s00521-022-07377-0},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2045-2058},
  shortjournal = {Neural Comput. Appl.},
  title        = {Risk prediction in financial management of listed companies based on optimized BP neural network under digital economy},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CT manifestations of gallbladder carcinoma based on neural
network. <em>NCA</em>, <em>35</em>(3), 2039–2044. (<a
href="https://doi.org/10.1007/s00521-022-06973-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gallbladder cancer is a relatively rare but highly malignant tumor. This study mainly explores the CT findings of gallbladder cancer based on neural networks. This study designed a gallbladder cancer LDCT image denoising network. Ability to process different doses of gallbladder cancer LDCT images with significant differences in noise and artifact distribution, this study designed the noise level estimation sub-network as a codec structure; the decoding part is used to generate the noise level of the gallbladder cancer LDCT image Artifact image. Artificial neural network is a kind of artificial neural network that simulates the behavior characteristics of animal neural network and achieves the purpose of processing information by adjusting the interconnection between a large number of internal nodes. In order to meet the requirements of medical diagnosis for gallbladder cancer LDCT image quality, this study designed the backbone noise reduction network as a GAN framework that can be internally optimized. The discriminator network structure of this study is a multi-scale inception structure. As a sub-network of GAN, the discriminator network is used to distinguish true and false images and constrain the generator to make the generated images close to real images. In addition, it can be used as a noise evaluation sub-network to evaluate the noise gallbladder cancer LDCT. The treatment methods of gallbladder cancer include surgery, chemotherapy, radiation therapy, arterial interventional perfusion therapy, targeted therapy, etc. Surgery is currently the first choice for the treatment of gallbladder cancer, and the choice of surgery depends on the stage and growth site of gallbladder cancer. The image denoising network was used to evaluate the quality of the noise-reduced image. The average precision of GAN network for gallbladder cancer area is 91.0\%, and the highest value is 95.2\%. This study will provide a reliable reference value for the auxiliary diagnosis of gallbladder cancer.},
  archive      = {J_NCA},
  author       = {Chang, Yigang and Wu, Qian and Chi, Limin and Huo, Huaying},
  doi          = {10.1007/s00521-022-06973-4},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2039-2044},
  shortjournal = {Neural Comput. Appl.},
  title        = {CT manifestations of gallbladder carcinoma based on neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The design of an affordable fault-tolerant control system of
the brushless DC motor for an active waist exoskeleton. <em>NCA</em>,
<em>35</em>(3), 2027–2037. (<a
href="https://doi.org/10.1007/s00521-022-07362-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brushless DC (BLDC) motor is a widely used method of powering various active exoskeletons such as waist exoskeleton devices. In this study, an affordable three-phase BLDC motor was designed using three 120° Hall-effect sensors to actuate an active waist exoskeleton. The fault in a Hall-effect sensor may cause the system failure. Thus, taking safety measures for the operating BLDC is a very important aspect for the device. This paper presents a model-based single-phase fault-tolerant control as a safety measure that is able to estimate speed and signal delay for Hall-effect sensors of BLDC motors used in the active waist exoskeleton. Because of motor inertia that resists changing rotational speed, the exoskeleton controller can estimate the time interval of the signal edge between the fault Hall-effect sensor and its adjacent sensor based on the sampled values of the average speed at the previous motor status. The signal delay can be used to reconstruct the faulty Hall signals. Then, the rotor position and velocity information can be corrected in time to restore the motor operation. The BLDC motor along with the controller was modeled, and a simulation was conducted to evaluate the effectiveness of the control strategy. The result showed that the fault-tolerant control could rapidly reconstruct the Hall signal required for motor rotation in the case of a single Hall-effect sensor failure, and ensured the stable operation for the BLDC motor on the exoskeleton.},
  archive      = {J_NCA},
  author       = {Yang, Liang and Qu, Chenxi and Jia, Bochen and Qu, Shengguan},
  doi          = {10.1007/s00521-022-07362-7},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2027-2037},
  shortjournal = {Neural Comput. Appl.},
  title        = {The design of an affordable fault-tolerant control system of the brushless DC motor for an active waist exoskeleton},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Special issue on 2021 international conference on machine
learning and big data analytics for iot security and privacy.
<em>NCA</em>, <em>35</em>(3), 2025–2026. (<a
href="https://doi.org/10.1007/s00521-022-07706-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhao, Jinghua},
  doi          = {10.1007/s00521-022-07706-3},
  journal      = {Neural Computing and Applications},
  number       = {3},
  pages        = {2025-2026},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on 2021 international conference on machine learning and big data analytics for iot security and privacy},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Demand forecasting model for time-series pharmaceutical data
using shallow and deep neural network model. <em>NCA</em>,
<em>35</em>(2), 1945–1957. (<a
href="https://doi.org/10.1007/s00521-022-07889-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demand forecasting is a scientific and methodical assessment of future demand for a critical product.The effective Demand Forecast Model (DFM) enables pharmaceutical companies to be successful in the global market. The purpose of this research paper is to validate various shallow and deep neural network methods for demand forecasting, with the aim of recommending sales and marketing strategies based on the trend/seasonal effects of eight different groups of pharmaceutical products with different characteristics. The root mean squared error (RMSE) is used as the predictive accuracy of DFMs. This study also found that the mean RMSE value of the shallow neural network-based DFMs was 6.27 for all drug categories, which was lower than deep neural network models. According to the findings, DFMs based on shallow neural networks can effectively estimate future demand for pharmaceutical products.},
  archive      = {J_NCA},
  author       = {Rathipriya, R. and Abdul Rahman, Abdul Aziz and Dhamodharavadhani, S. and Meero, Abdelrhman and Yoganandan, G.},
  doi          = {10.1007/s00521-022-07889-9},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1945-1957},
  shortjournal = {Neural Comput. Appl.},
  title        = {Demand forecasting model for time-series pharmaceutical data using shallow and deep neural network model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). D-former: A u-shaped dilated transformer for 3D medical
image segmentation. <em>NCA</em>, <em>35</em>(2), 1931–1944. (<a
href="https://doi.org/10.1007/s00521-022-07859-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided medical image segmentation has been applied widely in diagnosis and treatment to obtain clinically useful information of shapes and volumes of target organs and tissues. In the past several years, convolutional neural network (CNN)-based methods (e.g., U-Net) have dominated this area, but still suffered from inadequate long-range information capturing. Hence, recent work presented computer vision Transformer variants for medical image segmentation tasks and obtained promising performances. Such Transformers modeled long-range dependency by computing pair-wise patch relations. However, they incurred prohibitive computational costs, especially on 3D medical images (e.g., CT and MRI). In this paper, we propose a new method called Dilated Transformer, which conducts self-attention alternately in local and global scopes for pair-wise patch relations capturing. Inspired by dilated convolution kernels, we conduct the global self-attention in a dilated manner, enlarging receptive fields without increasing the patches involved and thus reducing computational costs. Based on this design of Dilated Transformer, we construct a U-shaped encoder–decoder hierarchical architecture called D-Former for 3D medical image segmentation. Experiments on the Synapse and ACDC datasets show that our D-Former model, trained from scratch, outperforms various competitive CNN-based or Transformer-based segmentation models at a low computational cost without time-consuming per-training process.},
  archive      = {J_NCA},
  author       = {Wu, Yixuan and Liao, Kuanlun and Chen, Jintai and Wang, Jinhong and Chen, Danny Z. and Gao, Honghao and Wu, Jian},
  doi          = {10.1007/s00521-022-07859-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1931-1944},
  shortjournal = {Neural Comput. Appl.},
  title        = {D-former: A U-shaped dilated transformer for 3D medical image segmentation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning the transfer function in binary metaheuristic
algorithm for feature selection in classification problems.
<em>NCA</em>, <em>35</em>(2), 1915–1929. (<a
href="https://doi.org/10.1007/s00521-022-07869-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most challenging issues in pattern recognition is the data attribution selection process. Feature selection plays a key role in solving problems with high-dimensional data and is a fundamental step in pre-processing many classifications and machine learning problems. The feature selection method reduces the amount of data and increases the category precision. Unrelated data, which can lead to inappropriate classification, is thus removed to obtain fewer features. In this paper, the Binary Gray Wolf Optimization algorithm uses the Wrapper method for feature selection. The transfer function is an essential part of BGWO to map a continuous value to a binary value. In this study, eight transfer functions are divided into two families: S-shaped and V-shaped. Previous research has used only one transfer function for the whole algorithm, and all wolves in the whole algorithm deal with this transfer function. In this paper, each wolf has its own transfer function. Because algorithms are evolutionary meta-innovations and can optimize themselves, each wolf can play a role in the whole algorithm at any stage while optimizing itself and adapting to its community, and not just depend on one transfer function. In the proposed method, eight transfer functions are divided into two families, S-shaped and V-shaped. This article proposes two approaches for learning the transfer function, by selecting the transfer function and the slope of these functions. In the first approach, we add three or two binary bits to the initial population. If two bits are added, four modes of the transfer function are available, and if three bits are added, eight transfer functions are achievable. These bits are used as a criterion for selecting a predefined transfer function for each wolf. So, in the proposed method, each wolf has its transfer function. During the implementation of the algorithm, the wolves update their position according to the evaluation function and learning. In the second approach, ten or twenty-one binary bits are added to the initial population. If ten binary bits are used, we will have a transfer function, and $$2^{10}$$ coefficient modes are available for the slope of the transfer function. If twenty-one binary bits are used, we have two transfer functions available. So, there are $$2^{10}$$ modes for the gradient of the transfer function. These bits are used as a criterion for selecting the transfer function and the coefficient affecting the slope of these functions. In both ideas, after each iteration of the algorithm, the position of the wolves is updated and based on the evaluation function, the alpha wolf is identified and the transfer function is selected. With subsequent iterations, the algorithm learns and optimizes the transfer function to achieve the best feature selection with the smallest error. Experimental results on ten UCI datasets show that selecting the obtained feature subset with high classification accuracy is efficient.},
  archive      = {J_NCA},
  author       = {Nassiri, Zahra and Omranpour, Hesam},
  doi          = {10.1007/s00521-022-07869-z},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1915-1929},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning the transfer function in binary metaheuristic algorithm for feature selection in classification problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward reliable machine learning with congruity: A quality
measure based on formal concept analysis. <em>NCA</em>, <em>35</em>(2),
1899–1913. (<a
href="https://doi.org/10.1007/s00521-022-07853-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spreading of machine learning (ML) and deep learning (DL) methods in different and critical application domains, like medicine and healthcare, introduces many opportunities but raises risks and opens ethical issues, mainly attaining to the lack of transparency. This contribution deals with the lack of transparency of ML and DL models focusing on the lack of trust in predictions and decisions generated. In this sense, this paper establishes a measure, namely Congruity, to provide information about the reliability of ML/DL model results. Congruity is defined by the lattice extracted through the formal concept analysis built on the training data. It measures how much the incoming data items are close to the ones used at the training stage of the ML and DL models. The general idea is that the reliability of trained model results is highly correlated with the similarity of input data and the training set. The objective of the paper is to demonstrate the correlation between the Congruity and the well-known Accuracy of the whole ML/DL model. Experimental results reveal that the value of correlation between Congruity and Accuracy of ML model is greater than 80\% by varying ML models.},
  archive      = {J_NCA},
  author       = {De Maio, Carmen and Fenza, Giuseppe and Gallo, Mariacristina and Loia, Vincenzo and Stanzione, Claudio},
  doi          = {10.1007/s00521-022-07853-7},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1899-1913},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward reliable machine learning with congruity: A quality measure based on formal concept analysis},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-grained image retrieval by combining attention
mechanism and context information. <em>NCA</em>, <em>35</em>(2),
1881–1897. (<a
href="https://doi.org/10.1007/s00521-022-07873-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, fine-grained image retrieval (FGIR) has become a hot topic in computer vision. Most of the advanced retrieval algorithms in this field mainly focus on the construction of loss function and the design of hard sample mining strategy. In this paper, we improve the performance of the FGIR algorithm from another perspective and propose an attention mechanism and context Information constraints-based image retrieval (AMCICIR) method for FGIR. It first applies an attention learning mechanism to gradually refine object location and extracts useful local features from coarse to fine. Then, it uses an improved graph convolutional network (GCN), where the adjacency matrix is dynamically adjusted with the current features and model retrieval performances during the model learning, to model the internal semantic interactions of the learned local features, so as to obtain a more discriminative and fine-grained image representation. Finally, various experiments are conducted on two fine-grained image datasets, CUB-200-2011 and Cars-196, and the experimental results show that the AMCICIR algorithm can outperform pervious state-of-the-art works remarkably.},
  archive      = {J_NCA},
  author       = {Li, Xiaoqing and Ma, Jinwen},
  doi          = {10.1007/s00521-022-07873-3},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1881-1897},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fine-grained image retrieval by combining attention mechanism and context information},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving TSP by using combinatorial bees algorithm with
nearest neighbor method. <em>NCA</em>, <em>35</em>(2), 1863–1879. (<a
href="https://doi.org/10.1007/s00521-022-07816-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bees Algorithm (BA) is a popular meta-heuristic method that has been used in many different optimization areas for years. In this study, a new version of combinatorial BA is proposed and explained in detail to solve Traveling Salesman Problems (TSPs). The nearest neighbor method was used in the population generation section of BA, and the Multi-Insert function was added to the local search section instead of the Swap function. To see the efficiency of the proposed method, 24 different TSPs were used in experimentation and the obtained results were compared with both classical combinatorial BA and other successful meta-heuristic methods. After detailed analyses and experimental studies on different problems, it has been observed that the proposed method performs well for TSPs and competes well with other methods.},
  archive      = {J_NCA},
  author       = {Sahin, Murat},
  doi          = {10.1007/s00521-022-07816-y},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1863-1879},
  shortjournal = {Neural Comput. Appl.},
  title        = {Solving TSP by using combinatorial bees algorithm with nearest neighbor method},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved deep convolutional neural network-based COOT
optimization for multimodal disease risk prediction. <em>NCA</em>,
<em>35</em>(2), 1849–1862. (<a
href="https://doi.org/10.1007/s00521-022-07767-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During recent years, maintaining scientific and medical databases has turned out to be a major challenge in the medical sector. The medical data regarding the patients comprise diverse diagnostic medical reports and features for such disease need to be recorded carefully for providing high-quality treatments. Therefore, this paper proposes a hybrid deep convolutional neural network (HDCNN)-based COOT approach to predict the risk of diseases. Initially, an improved crossover-based levy flight optimization algorithm (ICLFDO) algorithm is employed in selecting and processing the unstructured textual data. Then later, the HDCNN-COOT approach predicts the diseases more accurately. In addition to this, the classifier predicts whether the patient is at risk of disease in the future or not. The efficiency of the proposed model is evaluated by using a dataset obtained from University Hospital of Ludwig Maximilian University of Munich, Germany. The data collected in the data center include 29,477,035 data items from 36,082 patients. The proposed model is capable of using structured data and uses textual data of the patients. Finally, the higher classification accuracy and improved performance of the classifiers can be viewed using the experimental results conducted on five different datasets.},
  archive      = {J_NCA},
  author       = {Irene, D. Shiny and Lakshmi, M. and Kinol, A. Mary Joy and Kumar, A. Joseph Selva},
  doi          = {10.1007/s00521-022-07767-4},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1849-1862},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved deep convolutional neural network-based COOT optimization for multimodal disease risk prediction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3 s-STNet: Three-stream spatial–temporal network with
appearance and skeleton information learning for action recognition.
<em>NCA</em>, <em>35</em>(2), 1835–1848. (<a
href="https://doi.org/10.1007/s00521-022-07763-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition (HAR) is one of the active research areas in computer vision. Although significant progress has been made in the field of action recognition in recent years, most research methods focus on classification of action through single type of data, and with a need to explore spatial–temporal features systematically. Therefore, this paper proposes a three-stream spatial–temporal network with appearance and skeletal information learning for action recognition, briefly coined as 3 s-STNet, which aims to fully learn action spatial–temporal features by extracting, learning and fusing different types of data. The method is divided into two consecutive stages; the first stage uses spatial–temporal graph convolutional network (ST-GCN) and two Res2Net-101 to extract the spatial–temporal features of the action from the spatial–temporal graph, RGB appearance image, and tree-structure-reference-joints image (TSRJI), respectively. The spatial–temporal graph and TSRJI image are converted from human skeleton data. The second stage fine-tunes and fuses the spatial–temporal features obtained by the independent learning of the three-stream network to make full use of the complementarity and diversity among the three output features. The action recognition method proposed in this paper is tested on the challenging NTU RGB + D 60 and NTU RGB + D 120 dataset, and the accuracy of 97.63\% (cross-subject), 99.30\% (cross-view) and 95.17\% (cross-subject), 96.20\%(cross-setup), respectively, are obtained, which achieves the state-of-the-art action recognition results in our experiments.},
  archive      = {J_NCA},
  author       = {Fang, Ming and Peng, Siyu and Zhao, Yang and Yuan, Haibo and Hung, Chih-Cheng and Liu, Shuhua},
  doi          = {10.1007/s00521-022-07763-8},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1835-1848},
  shortjournal = {Neural Comput. Appl.},
  title        = {3 s-STNet: Three-stream spatial–temporal network with appearance and skeleton information learning for action recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge tracing based on multi-feature fusion.
<em>NCA</em>, <em>35</em>(2), 1819–1833. (<a
href="https://doi.org/10.1007/s00521-022-07834-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing involves modeling student knowledge states over time so that we can accurately predict student performance in future interactions and recommend personalized student learning paths. However, existing methods, such as deep knowledge tracing and dynamic key-value memory networks (DKVMN), fail to comprehensively consider some key features that may influence the prediction results of knowledge tracing. To solve this problem, we propose a new model called knowledge tracing based on multi-feature fusion (KTMFF), which introduces features of the question text, the knowledge point difficulty, the student ability, and the duration time, etc., provides feature extraction methods, and uses a multi-head self-attention mechanism to combine the above features. This model predicts student mastery levels of knowledge points more accurately. Experiments show that the area under curve (AUC) of the KTMFF model is 3.06\% higher than that of the DKVMN model. Furthermore, the ablation study indicates that each of the above features can improve the AUC of the model.},
  archive      = {J_NCA},
  author       = {Xiao, Yongkang and Xiao, Rong and Huang, Ning and Hu, Yixin and Li, Huan and Sun, Bo},
  doi          = {10.1007/s00521-022-07834-w},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1819-1833},
  shortjournal = {Neural Comput. Appl.},
  title        = {Knowledge tracing based on multi-feature fusion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved parameter learning methodology for RVFL based on
pseudoinverse learners. <em>NCA</em>, <em>35</em>(2), 1803–1818. (<a
href="https://doi.org/10.1007/s00521-022-07824-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a compact and effective learning model, the random vector functional link neural network (RVFL) has been confirmed with universal approximation capabilities. It has gained considerable attention in various fields. However, the randomly generated parameters in RVFL often lead to the loss of valid information and data redundancy, which severely degrades the model performance in practice. This paper first proposes an efficient network parameters learning approach for the original RVFL with pseudoinverse learner (RVFL-PL). Instead of taking the random feature mapping directly, RVFL-PL adopts a non-iterative manner to obtain influential enhancement nodes implanted with valuable information from input data, which realizes to improve the quality of the enhancement nodes and ease the problem caused by the randomly assigned parameters in the standard RVFL. Since the network parameters are optimized analytically, this improved variant can maintain the efficiency of the standard RVFL. Further, the RVFL-PL is extended to a multilayered structure (mRVFL-PL) to obtain high-level representations from the input data. The results of comprehensive experiments on some benchmarks indicate the performance improvement of the proposed method compared to other corresponding methods.},
  archive      = {J_NCA},
  author       = {Sun, Xiaoxuan and Deng, Xiaodan and Yin, Qian and Guo, Ping},
  doi          = {10.1007/s00521-022-07824-y},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1803-1818},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved parameter learning methodology for RVFL based on pseudoinverse learners},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep-learning-based human activity recognition for
alzheimer’s patients’ daily life activities assistance. <em>NCA</em>,
<em>35</em>(2), 1777–1802. (<a
href="https://doi.org/10.1007/s00521-022-07883-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease is considered as one of the most well-known illnesses in the elderly. It is a neurodegenerative and irreversible brain disorder that slowly destroys memory, thinking ability, and ultimately the ability to perform even basic daily tasks. In fact, people suffering from this disorder have difficulty remembering events, recognizing objects and faces, remembering the meaning of words, and developing judgment. As a result, their cognitive abilities are impaired and they are unable to perform activities of daily living independently. Therefore, patients need constant support to carry out their daily activities. In this study, we propose a new support system to support patients with Alzheimer’s disease to carry out their daily tasks independently. The proposed assistance systems are composed of two parts. The first is a human activity recognition (HAR) module to monitor the patient behaviour. Here, we proposed two HAR systems. The first is based on 2D skeleton data and convolution neural network, and the second is based on 3D skeleton and transformers. The second part of the assistance systems consists of a support module that recognizes the patient’s behavioural abnormalities and issues appropriate warnings. Here, we also proposed two methods. The first is based on a simple conditional structure, and the second is based on a reinforcement learning technique. As a result, we obtain four different assistance systems for Alzheimer’s patients. Finally, a comparative study between the four systems was carried out in terms of performance and time complexity using the DemCare dataset.},
  archive      = {J_NCA},
  author       = {Snoun, Ahmed and Bouchrika, Tahani and Jemai, Olfa},
  doi          = {10.1007/s00521-022-07883-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1777-1802},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep-learning-based human activity recognition for alzheimer’s patients’ daily life activities assistance},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient high-dimensional feature selection approach
driven by enhanced multi-strategy grey wolf optimizer for biological
data classification. <em>NCA</em>, <em>35</em>(2), 1749–1775. (<a
href="https://doi.org/10.1007/s00521-022-07836-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological data generally contain complex and high-dimensional samples. In addition, the number of samples in biological datasets is much fewer than the number of features, so the vast number of features should be selected carefully and determine the optimal subset of features. Feature selection (FS) is a vital stage in biological data mining applications (e.g., classification) for dealing with the curse of dimensionality problems and finding highly informative features. This work proposes an effective FS approach based on a new version of Gray Wolf Optimizer (GWO) called Multi-strategy Gray Wolf Optimizer (MSGWO) for better features selection for biological data classification. The use of MSGWO in feature selection is to find the optimal subset of features between classes, solve premature convergence, and enhance the local search ability of the GWO algorithm. Multiple exploration and exploitation strategies are proposed to enhance the global search and local search abilities of the GWO algorithm through the optimization process. The support vector machine (SVM) classifier is used to evaluate the proposed GWO-based FS approaches. MSGWO was evaluated on thirteen high-dimensional biological datasets obtained from the UCI repository with a smaller number of instances. The reported results confirm that employing multiple exploration and multiple exploitation strategies is highly useful for enhancing the search tendency of the MSGWO in the FS domain. Statistical tests proved that the superiority of the proposed approach is statistically significant as compared to the basic GWO and similar wrapper-based FS techniques, including binary particle swarm optimization (BPSO), binary bat algorithm (BBA), binary gravitational search algorithm (BGSA), and binary whale optimization algorithm (BWOA). In terms of classification accuracy, MSGWO yielded better accuracy rates than the standard GWO algorithm on 84\% of applied biological datasets. MSGWO also recorded better accuracy rates than its other competitors in all 13 cases. In terms of the lowest number of selected features, MSGWO yielded excellent reduction rates compared to its peers.},
  archive      = {J_NCA},
  author       = {Mafarja, Majdi and Thaher, Thaer and Too, Jingwei and Chantar, Hamouda and Turabieh, Hamza and Houssein, Essam H. and Emam, Marwa M.},
  doi          = {10.1007/s00521-022-07836-8},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1749-1775},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient high-dimensional feature selection approach driven by enhanced multi-strategy grey wolf optimizer for biological data classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulating a complete tritonia escape swim network using a
novel event-based spiking neural network algorithm. <em>NCA</em>,
<em>35</em>(2), 1733–1748. (<a
href="https://doi.org/10.1007/s00521-022-07829-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tritonia has been studied in the laboratory by several studies, which have led to significant advances in identifying the biological components that participate in the Tritonia escape swim network. There are also studies, which have artificially reproduced the neuronal patterns of the Tritonia escape swim circuit. These studies simulated the interneurons of the swim central pattern generator (CPG) known as dorsal swim interneuron, ventral swim interneuron, and cerebral 2. In this research, other neurons that participate in the Tritonia escape swim network were simulated. In addition to the main CPG components, sensory, ramp, and dorsal/ventral flexion neurons are all included in the neural network (NN). The objective of the study was to artificially reconstruct a more representative image of the Tritonia escape swim NN, its neuronal activities, and synaptic connections. The network was simulated using a spiking neural network (SNN) simulator named Synapse, which has been implemented based on a novel event-based SNN algorithm. After tuning synaptic delays, weights, and membrane potential properties, the expected spike patterns were successfully reproduced for each involved neuron. The spike patterns from this study were validated using the laboratory recorded signals as well as the existing simulated patterns.},
  archive      = {J_NCA},
  author       = {Miri, Fatemehossadat and Miles, Carol I. and Lewis, Harold W.},
  doi          = {10.1007/s00521-022-07829-7},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1733-1748},
  shortjournal = {Neural Comput. Appl.},
  title        = {Simulating a complete tritonia escape swim network using a novel event-based spiking neural network algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective memetic differential evolution optimization
algorithm for text clustering problems. <em>NCA</em>, <em>35</em>(2),
1711–1731. (<a
href="https://doi.org/10.1007/s00521-022-07888-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most text clustering algorithms adopt a single criterion optimization approach, which often fails to find good clustering solutions for a wide diversity of datasets with different clustering characteristics. The multi-objective meta-heuristic approach is utilized to seek optimal clustering by maximizing (or minimizing) more than two objective functions. In this paper, we propose a multi-objective memetic differential evolution algorithm (MOMDE) for text clustering. The MOMDE text clustering algorithm combines memetic and differential evolution algorithms to improve the search for optimal clustering by improving the balance between exploitation and exploration. Moreover, a combination with the dominance-based multi-objective approach is employed, which may improve the search for optimal clustering by maximizing or/and minimizing two cluster quality measures. The proposed algorithm is tested on six text clustering datasets from the Laboratory of Computational Intelligence. Our experimental results revealed that the performance of the MOMDE algorithm is better than state-of-the-art text clustering algorithms. Further validation is provided using the F-measure to assess the efficiency of the obtained clustering of MOMDE, whilst the multi-objective performance assessment matrices are used to evaluate the quality of Pareto-optimality.},
  archive      = {J_NCA},
  author       = {Mustafa, Hossam M. J. and Ayob, Masri and Shehadeh, Hisham A. and Abu-Taleb, Sawsan},
  doi          = {10.1007/s00521-022-07888-w},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1711-1731},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective memetic differential evolution optimization algorithm for text clustering problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GIMIRec: Global interaction-aware multi-interest framework
for sequential recommendation. <em>NCA</em>, <em>35</em>(2), 1695–1709.
(<a href="https://doi.org/10.1007/s00521-022-07827-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation based on multi-interest framework is to model the user’s recent interaction sequence into multiple different interest vectors instead of a single low-dimensional vector, so as to fully represent the diversity of user interests. However, most of the existing models only intercept each user’s recent interaction behaviors as training data, without exploring the user’s historical interaction data and the co-occurrence relationship between items in the entire dataset. To address the problem, this paper proposes a Global Interaction-aware Multi-Interest framework for sequential Recommendation (GIMIRec). Specifically, a global context extraction module is firstly proposed to calculate a weighted co-occurrence matrix from the historical interaction sequences of all users to obtain the global context embedding of each item. Secondly, the time interval of each item pair in the recent interaction sequence of each user is captured and combined with the global context embeddings to get the personalized embeddings. Finally, a self-attention-based multi-interest framework is applied to learn the diverse interests of users for sequential recommendation. Extensive experiments on three real-world datasets show that GIMIRec significantly outperforms state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Chen, Ke-Jia and Zhang, Jie and Chen, Jingqiang},
  doi          = {10.1007/s00521-022-07827-9},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1695-1709},
  shortjournal = {Neural Comput. Appl.},
  title        = {GIMIRec: Global interaction-aware multi-interest framework for sequential recommendation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-global fixed/predefined-time RNN models with
comprehensive comparisons for time-variant neural computing.
<em>NCA</em>, <em>35</em>(2), 1675–1693. (<a
href="https://doi.org/10.1007/s00521-022-07820-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns with the time-variant neural computing in a semi-global sense, taking into account initial conditions located within a region with a definitely finite radius. Both the conventional single and double power-rate RNN models are characterized and the closed-form expressions of the settling time functions are presented for given initial conditions, by which the fixed/predefined-time convergence can be assured in the semi-global sense. Despite asymptotic convergence behavior, the conventional linear RNN model is examined for comparison purposes. Modified RNN models adopt the inverse of the bound, according to the fixed-time convergence results, and the prescribed time can be an adjustable parameter. A novel two-phase RNN model with the pre-specified transition state is proposed, which has not only semi-global fixed/predefined-time stability but also a faster convergence rate than that of the conventional models. The proposed models are applied and compared, through numerical simulation, for time-variant matrix inversion, linear equation solving, and repeatable motion planning of a redundant manipulator in the presence of initial errors.},
  archive      = {J_NCA},
  author       = {Sun, Mingxuan and Li, Xing and Zhong, Guomin},
  doi          = {10.1007/s00521-022-07820-2},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1675-1693},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semi-global fixed/predefined-time RNN models with comprehensive comparisons for time-variant neural computing},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A feedforward neural network framework for approximating the
solutions to nonlinear ordinary differential equations. <em>NCA</em>,
<em>35</em>(2), 1661–1673. (<a
href="https://doi.org/10.1007/s00521-022-07855-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a method to approximate the solutions to nonlinear ordinary differential equations (ODE) using a deep learning feedforward artificial neural networks (ANNs). The efficiency of the proposed—unsupervised type machine learning—method is shown by solving two boundary value problems (BVPs) from quantum mechanics and nanofluid mechanics. The proposed mean-squared loss function is the sum of two terms: the first term satisfies the differential equation, while the second term satisfies the initial or boundary conditions. The total loss function is minimized by using general type of quasi-Newton optimization methods to get a desired network output. The approximation capability of the proposed method is verified for two sets of boundary value problems: first, a second-order nonlinear ODE and, second, a system of coupled nonlinear third-order ODEs. Point-wise comparison of our approximation shows a strong agreement with the available exact solutions and/or Runge–Kutta-based numerical solutions. We remark that the proposed algorithm minimizes the overall learnable network hyperparameters in a given initial or boundary value problems. More importantly, for the coupled system of third-order nonlinear ordinary differential equations, the proposed method does not need any adjustment with the initial/boundary conditions. Also, the current method does not require any special type of computational mesh. A straightforward minimization of total loss function yields a highly accurate results even with less number of epochs. Therefore, the proposed framework offers an attractive setting for the fluid mechanics community who are interested in studying heat and mass transfer problems.},
  archive      = {J_NCA},
  author       = {Venkatachalapathy, Pavithra and Mallikarjunaiah, S. M.},
  doi          = {10.1007/s00521-022-07855-5},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1661-1673},
  shortjournal = {Neural Comput. Appl.},
  title        = {A feedforward neural network framework for approximating the solutions to nonlinear ordinary differential equations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auto diagnostic system for detecting solitary and
juxtapleural pulmonary nodules in computed tomography images using
machine learning. <em>NCA</em>, <em>35</em>(2), 1645–1659. (<a
href="https://doi.org/10.1007/s00521-022-07844-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is one of the most serious cancers in the world with the minimum survival rate after the diagnosis as it appears in Computed Tomography scans. Lung nodules may be isolated from (solitary) or attached to (juxtapleural) other structures such as blood vessels or the pleura. Diagnosis of lung nodules according to their location increases the survival rate as it achieves diagnostic and therapeutic quality assurance. In this paper, a Computer Aided Diagnosis (CADx) system is proposed to classify solitary nodules and juxtapleural nodules inside the lungs. Two main auto-diagnostic schemes of supervised learning for lung nodules classification are achieved. In the first scheme, (bounding box + Maximum intensity projection) and (Thresholding + K-means clustering) segmentation approaches are proposed then first- and second-order features are extracted. Fisher score ranking is also used in the first scheme as a feature selection method. The higher five, ten, and fifteen ranks of the feature set are selected. In the first scheme, Support Vector Machine (SVM) classifier is used. In the second scheme, the same segmentation approaches are used with Deep Convolutional neural networks (DCNN) which is a successful tool for deep learning classification. Because of the limited data sample and imbalanced data, tenfold cross-validation and random oversampling are used for the two schemes. For diagnosis of the solitary nodule, the first scheme with SVM achieved the highest accuracy and sensitivity 91.4\% and 89.3\%, respectively, with radial basis function and applying the (Thresholding + Kmeans clustering) segmentation approach and the higher 15 ranks of the feature set. In the second scheme, DCNN achieved the highest accuracy and sensitivity 96\% and 95\%, respectively, to detect the solitary nodule when applying the bounding box and maximum intensity projection segmentation approach. Receiver operating characteristic curve is used to evaluate the classifier’s performance. The max. AUC = 90.3\% is achieved with DCNN classifier for detecting solitary nodules. This CAD system acts as a second opinion for the radiologist to help in the early diagnosis of lung cancer. The accuracy, sensitivity, and specificity of scheme I (SVM) and scheme II (DCNN) showed promising results in comparison to other published studies.},
  archive      = {J_NCA},
  author       = {Karrar, Ayat and Mabrouk, Mai S. and Abdel Wahed, Manal and Sayed, Ahmed Y.},
  doi          = {10.1007/s00521-022-07844-8},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1645-1659},
  shortjournal = {Neural Comput. Appl.},
  title        = {Auto diagnostic system for detecting solitary and juxtapleural pulmonary nodules in computed tomography images using machine learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convolutional neural networks combined with runge–kutta
methods. <em>NCA</em>, <em>35</em>(2), 1629–1643. (<a
href="https://doi.org/10.1007/s00521-022-07785-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A convolutional neural network can be constructed using numerical methods for solving dynamical systems, since the forward pass of the network can be regarded as a trajectory of a dynamical system. However, existing models based on numerical solvers cannot avoid the iterations of implicit methods, which makes the models inefficient at inference time. In this paper, we reinterpret the pre-activation Residual Networks (ResNets) and their variants from the dynamical systems view. We consider that the iterations of implicit Runge–Kutta methods are fused into the training of these models. Moreover, we propose a novel approach to constructing network models based on high-order Runge–Kutta methods in order to achieve higher efficiency. Our proposed models are referred to as the Runge–Kutta Convolutional Neural Networks (RKCNNs). The RKCNNs are evaluated on multiple benchmark datasets. The experimental results show that RKCNNs are vastly superior to other dynamical system network models: they achieve higher accuracy with much fewer resources. They also expand the family of network models based on numerical methods for dynamical systems.},
  archive      = {J_NCA},
  author       = {Zhu, Mai and Chang, Bo and Fu, Chong},
  doi          = {10.1007/s00521-022-07785-2},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1629-1643},
  shortjournal = {Neural Comput. Appl.},
  title        = {Convolutional neural networks combined with Runge–Kutta methods},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal tweet classification in disaster response systems
using transformer-based bidirectional attention model. <em>NCA</em>,
<em>35</em>(2), 1607–1627. (<a
href="https://doi.org/10.1007/s00521-022-07790-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this research is to use social media to gain situational awareness in the wake of a crisis. With the developments in information and communication technologies, social media became the de facto norm for gathering and disseminating information. We present a method for classifying informative tweets from the massive volume of user tweets on social media. Once the informative tweets have been found, emergency responders can use them to gain situational awareness so that recovery actions can be carried out efficiently. The majority of previous research has focused on either text data or images in tweets. A thorough review of the literature illustrates that text and image carry complementary information. The proposed method is a deep learning framework which utilizes multiple input modalities, specifically text and image from a user-generated tweet. We mainly focused to devise an improved multimodal fusion strategy. The proposed system has a transformer-based image and text models. The main building blocks include fine-tuned RoBERTa model for text, Vision Transformer model for image, biLSTM and attention mechanism. We put forward a multiplicative fusion strategy for image and text inputs. Extensive experiments have been done on various network architectures with seven datasets spanning different types of disasters, including wildfire, hurricane, earth-quake and flood. Several state-of-the-art approaches were surpassed by our system. It showed good accuracy in the range of 94–98\%. The results showed that identifying the interaction between multiple related modalities will enhance the quality of a deep learning classifier.},
  archive      = {J_NCA},
  author       = {Koshy, Rani and Elango, Sivasankar},
  doi          = {10.1007/s00521-022-07790-5},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1607-1627},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal tweet classification in disaster response systems using transformer-based bidirectional attention model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Empirical validation of ELM trained neural networks for
financial modelling. <em>NCA</em>, <em>35</em>(2), 1581–1605. (<a
href="https://doi.org/10.1007/s00521-022-07792-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this work is to compare predictive performance of neural networks trained using the relatively novel technique of training single hidden layer feedforward neural networks (SFNN), called Extreme Learning Machine (ELM), with commonly used backpropagation-trained recurrent neural networks (RNN) as applied to the task of financial market prediction. Evaluated on a set of large capitalisation stocks on the Australian market, specifically the components of the ASX20, ELM-trained SFNNs showed superior performance over RNNs for individual stock price prediction. While this conclusion of efficacy holds generally, long short-term memory (LSTM) RNNs were found to outperform for a small subset of stocks. Subsequent analysis identified several areas of performance deviations which we highlight as potentially fruitful areas for further research and performance improvement.},
  archive      = {J_NCA},
  author       = {Novykov, Volodymyr and Bilson, Christopher and Gepp, Adrian and Harris, Geoff and Vanstone, Bruce James},
  doi          = {10.1007/s00521-022-07792-3},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1581-1605},
  shortjournal = {Neural Comput. Appl.},
  title        = {Empirical validation of ELM trained neural networks for financial modelling},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully automatic CNN design with inception and ResNet blocks.
<em>NCA</em>, <em>35</em>(2), 1569–1580. (<a
href="https://doi.org/10.1007/s00521-022-07700-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although convolutional neural networks (CNNs) are widely used in image classification tasks and have demonstrated promising classification accuracy results, designing a CNN architecture requires a manual adjustment of parameters through a series of experiments as well as sufficient knowledge both in the problem domain and CNN architecture design. Therefore, it is difficult for users without prior experience to design a CNN for specific purposes. In this paper, we propose a framework for the automatic construction of CNN architectures based on ResNet, DenseNet, and Inception blocks and the roulette wheel selection method with a dynamic learning rate. Compared with the state of the art, the proposed approach has a significant improvement in the domain of image classification. Experimental evaluation of our approach including a comparison with the previous works on three benchmark datasets demonstrates the effectiveness of the overall method. The proposed algorithm not only improves the previous algorithm but also keeps the advantages of automatic CNN construction without requiring manual interventions. The source code of the our framework can be found at https://github.com/btogzhan2000/ea-cnn-complab .},
  archive      = {J_NCA},
  author       = {Barakbayeva, Togzhan and Demirci, Fatih M.},
  doi          = {10.1007/s00521-022-07700-9},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1569-1580},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fully automatic CNN design with inception and ResNet blocks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pattern lock screen detection method based on lightweight
deep feature extraction. <em>NCA</em>, <em>35</em>(2), 1549–1567. (<a
href="https://doi.org/10.1007/s00521-022-07846-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital age, many people have used mobile phones, thus, mobile phones are one of the most commonly used crime tools. Users can take security measures to their mobile devices using various authorization methods such as passwords or screen patterns (touch screen security authentication). The used security measures generally make mobile forensic analysis difficult or even impossible. In order to overcome this problem, a novel intelligent pattern lock detector is presented in this research. The proposed lock detector uses transfer learning to extract deep lightweight features, iterative feature chosen function and a shallow classifier. A feature extraction network has been created by using SqueezeNet and MobileNet-V2, which are among the deep learning architectures in this work. Iterative Minimum Redundancy Maximum Relevance (ImRMR) was used for feature selection. Linear discriminant analysis (LDA) was selected for the classifier. The proposed model has been developed on three image datasets. These datasets are named clean, slightly dirty and medium dirty. 99.75\%, 98.55\% and 96.50\% classification accuracies have been reached on the used three datasets, respectively. The findings clearly denote that the success of the presented deep lightweight features and ImRMR-based detector.},
  archive      = {J_NCA},
  author       = {Ertam, Fatih and Yakut, Omer Faruk and Tuncer, Turker},
  doi          = {10.1007/s00521-022-07846-6},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1549-1567},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pattern lock screen detection method based on lightweight deep feature extraction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transparent deep machine learning framework for predicting
traffic crash severity. <em>NCA</em>, <em>35</em>(2), 1535–1547. (<a
href="https://doi.org/10.1007/s00521-022-07769-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis of crash injury severity is a promising research target in highway safety studies. A better understanding of crash severity risk factors is vital for the proactive implementation of suitable countermeasures. In literature, crash injury severity was widely studied using statistical models. Though these models have a sound theoretical basis and interpretability, they were based on several unrealistic assumptions, which, if flouted, may yield biased model estimations. To overcome the limitations of statistical models, applied machine learning has rapidly emerged on the horizon of highway safety analysis. This study aims to model injury severity of motor vehicle crashes using three advanced machine learning approaches, i.e., vanilla multi-layer perceptron (MLP) using Keras, MLP with embedding layers, and TabNet. Among the three models, TabNet may be considered a fairly complex framework which is based on attention-based network for tabular data. To improve the predictive performance of proposed models, hyperparameter tuning was carried out using the Bayesian optimization technique. Different evaluation metrics (i.e., accuracy, precision, recall, F−1 score, AUC, and training time) were utilized to compare all the models&#39; injury severity classification performance. Experimental results showed that all the models yielded similar and adequate performance based on most of the evaluation metrics. However, based on training time, the Keras (MLP) model outperformed other models with a training time of 3.45 s which represents a reduction of 51\% and 93\% compared to MLP with embedding layers and TabNet, respectively. Feature importance analysis conducted using TabNet revealed that predictors such as number of vehicles involved, number of casualties, speed limit, junction location, vehicle type, and road type are the most sensitive variables aggravating the injury severity. The proposed supervised deep learning models supported by feature importance analysis make the modeling framework transparent and interpretable. The outcome of this study could provide essential guidance for practitioners for taking timely and concrete steps to improve highway safety. Moreover, this research will allow trauma and emergency centers to predict possible damage from a traffic accident and deploy the necessary emergency units to offer appropriate emergency treatment.},
  archive      = {J_NCA},
  author       = {Sattar, Karim and Chikh Oughali, Feras and Assi, Khaled and Ratrout, Nedal and Jamal, Arshad and Masiur Rahman, Syed},
  doi          = {10.1007/s00521-022-07769-2},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1535-1547},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transparent deep machine learning framework for predicting traffic crash severity},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). JSMix: A holistic algorithm for learning with label noise.
<em>NCA</em>, <em>35</em>(2), 1519–1533. (<a
href="https://doi.org/10.1007/s00521-022-07770-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of deep learning is mainly dependent on large-scale and accurately labeled datasets. However, real-world datasets are marked with much noise. Directly training on datasets with label noise may lead to the overfitting. Recent research is under the spotlight on how to design algorithms that can learn robust models from noisy datasets, via designing the loss function and integrating the idea of Semi-supervised learning (SSL). This paper proposes a robust algorithm for learning with label noise that does not require additional clean data and an auxiliary model. Specifically, on the one hand, Jensen–Shannon (JS) divergence is introduced as a component of the loss function, which measures the distance between the predicted distribution and the noisy label distribution. It can alleviate the overfitting problem caused by the traditional cross entropy loss theoretically and experimentally. On the other hand, a dynamic sample selection mechanism is also proposed. The dataset is divided into the pseudo-clean labeled subset and the pseudo-noisy labeled subset. Two subsets are treated differently to exploit prior information about the data, and then learned by SSL. The dynamic sample selection is performed with the iteration between two subsets and the model parameters, which are different from the conventional training. Considering the label of the pseudo-clean labeled subset is not correct entirely, they are also refined by linear interpolation. Furthermore, we experimentally show that the integration of SSL helps the model divide two subsets more precise and build decision boundaries more explicit. Extensive experimental results on corrupted data from benchmark datasets and the real-world dataset, including CIFAR-10, CIFAR-100, and Clothing1M, demonstrate that our method is superior to many state-of-the-art approaches for learning with label noise.},
  archive      = {J_NCA},
  author       = {Wen, Zhijie and Xu, Hui and Ying, Shihui},
  doi          = {10.1007/s00521-022-07770-9},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1519-1533},
  shortjournal = {Neural Comput. Appl.},
  title        = {JSMix: A holistic algorithm for learning with label noise},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating the performance of meta-heuristic algorithms on
CEC 2021 benchmark problems. <em>NCA</em>, <em>35</em>(2), 1493–1517.
(<a href="https://doi.org/10.1007/s00521-022-07788-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To develop new meta-heuristic algorithms and evaluate on the benchmark functions is the most challenging task. In this paper, performance of the various developed meta-heuristic algorithms are evaluated on the recently developed CEC 2021 benchmark functions. The objective functions are parametrized by inclusion of the operators, such as bias, shift and rotation. The different combinations of the binary operators are applied to the objective functions which leads to the CEC2021 benchmark functions. Therefore, different meta-heuristic algorithms are considered which solve the benchmark functions with different dimensions. The performance of some basic, advanced meta-heuristics algorithms and the algorithms that participated in the CEC2021 competition have been experimentally investigated and many observations, recommendations, conclusions have been reached. The experimental results show the performance of meta-heuristic algorithms on the different combinations of binary parameterized operators.},
  archive      = {J_NCA},
  author       = {Mohamed, Ali Wagdy and Sallam, Karam M. and Agrawal, Prachi and Hadi, Anas A. and Mohamed, Ali Khater},
  doi          = {10.1007/s00521-022-07788-z},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1493-1517},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluating the performance of meta-heuristic algorithms on CEC 2021 benchmark problems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adapting deep learning models between regional markets.
<em>NCA</em>, <em>35</em>(2), 1483–1492. (<a
href="https://doi.org/10.1007/s00521-022-07805-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends a series of deep learning models developed on US equity data to the Australian market. The model architectures are retrained, without structural modification, and tested on Australian data comparable with the original US data. Relative to the original US-based results, the retrained models are statistically less accurate at predicting next day returns. The models were also modified in the standard train/validate manner on the Australian data, and these models yielded significantly better predictive results on the holdout data. It was determined that the best-performing models were a CNN and LSTM, attaining highly significant Z-scores of 6.154 and 8.789, respectively. Due to the relative structural similarity across all models, the improvement is ascribed to regional influences within the respective training data sets. Such unique regional differences are consistent with views in the literature stating that deep learning models in computational finance that are developed and trained on a single market will always contain market-specific bias. Given this finding, future research into the development of deep learning models trained on global markets is recommended.},
  archive      = {J_NCA},
  author       = {Tonkin, Isaac and Gepp, Adrian and Harris, Geoff and Vanstone, Bruce},
  doi          = {10.1007/s00521-022-07805-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1483-1492},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adapting deep learning models between regional markets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep sign language recognition system for indian sign
language. <em>NCA</em>, <em>35</em>(2), 1469–1481. (<a
href="https://doi.org/10.1007/s00521-022-07840-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deaf people face major challenges during communication with normal people. Employing a human interpreter (a person who converts Sign language (SL) into a language that the normal/hearing community can understand) is not an effective solution to this problem due to the unavailability of professional interpreters. Thus, the Sign Language Recognition System (SLRS) is the most efficient and effective choice because it automatically converts SL into text/speech without an interpreter and reduces the communication barrier between deaf and normal people. This paper reports a work on Indian Sign Language (ISL) word recognition using a vision-based technique. The existing vision-based solutions for ISL word recognition are ineffective due to excessive pre-processing such as extracting features from a large sequence of frames. Therefore, a vision-based SLRS named Hybrid CNN-BiLSTM SLR (HCBSLR) is proposed, which overcomes the drawback of excessive pre-processing. The proposed model uses a Histogram Difference (HD) based key-frame extraction method to improve the accuracy and efficiency of the system by eliminating redundant or useless frames. The HCBSLR system uses VGG-19 for spatial feature extraction and Bidirectional Long Short Term Memory (BiLSTM) for temporal feature extraction. The proposed HCBSLR system has achieved an average accuracy of 87.67\%, which is compared with some of the existing SLRS. The experimental results show that the proposed HCBSLR system is more accurate and efficient than the existing SLRS.},
  archive      = {J_NCA},
  author       = {Das, Soumen and Biswas, Saroj Kr. and Purkayastha, Biswajit},
  doi          = {10.1007/s00521-022-07840-y},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1469-1481},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep sign language recognition system for indian sign language},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heap-based optimizer embedded with search strategies applied
to high-order analog filter designs: A comparative study with up-to-date
metaheuristics. <em>NCA</em>, <em>35</em>(2), 1447–1467. (<a
href="https://doi.org/10.1007/s00521-022-07835-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heap-Based Optimizer (HBO) is one of the recently proposed metaheuristic algorithms inspired by the corporate rank hierarchy. In this study, opposition and Cauchy-based search mechanisms are integrated into HBO which is applied for the design of high-order Butterworth active filters, for the first time, comparing with six outstanding metaheuristics introduced for the last year (2020). In addition, the proposed algorithm has been adapted to solve the benchmark presented in the IEEE-CEC 2020 competition to demonstrate its effectiveness against numerical functions. The analog filter design is a challenging problem due to its discrete topology and complex search space. This study provides a comprehensive review for the design of these filters with the up-to-date algorithms: firstly, the performance of each metaheuristic is analyzed by its error value performance, the required number of iterations to achieve this error value; secondly, a statistical test is conducted to validate its performances; as the third, convergence abilities of algorithms are compared with respect to the total design process error values versus an iteration number graph. The passive component values of the Butterworth active filter are selected within the E24 and E96 industrial series so as to make the realization of designs easier to the real world. To demonstrate the suitability of the components obtained by the algorithms to the real world, the amplitude response of the associated design is given. The simulation results demonstrate the effectiveness of the proposed algorithm over the contestant algorithms, and its capability of solving these case design problems. This extensive work can also provide guidelines to the researchers for future studies.},
  archive      = {J_NCA},
  author       = {Kuyu, Yiğit Çağatay and Vatansever, Fahri},
  doi          = {10.1007/s00521-022-07835-9},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1447-1467},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heap-based optimizer embedded with search strategies applied to high-order analog filter designs: A comparative study with up-to-date metaheuristics},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new common spatial pattern-based unified channels
algorithm for driver’s fatigue EEG signals classification. <em>NCA</em>,
<em>35</em>(2), 1423–1445. (<a
href="https://doi.org/10.1007/s00521-022-07833-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The common spatial pattern (CSP) algorithm is efficient and accurate for channels selection and features extraction for electroencephalogram (EEG) signals classification. The CSP algorithm is usually applied on a subject-by-subject basis by measuring only intra-subject variations for selecting the most significant channels; we refer to this algorithm as CSP-based customized channels selection (CSP-CC). In practice, deploying the CSP-CC algorithm requires to set up a customized EEG device for each subject separately, which can be very costly. In this paper, we propose a new algorithm, called CSP-based unified channels (CSP-UC), for overcoming the aforementioned difficulties. The aim of the proposed algorithm is to extract unified channels that are valid for any subject; hence, one EEG device can be deployed for all subjects. Moreover, a methodology for developing both binary-class and ternary-class EEG signals classification models using either customized or unified channels is introduced. This methodology is applicable for both subject-by-subject and cross-subjects basis. In ternary-class classification models, the traditional “Max_Vote” method, used for voting the predicted class labels, has been modified to a more accurate method called “Max_Vote_then_Max_Probability.” On a subject-by-subject basis, the experimental results on EEG-based driver’s fatigue dataset have shown that the accuracy of the classification models that are based on the proposed CSP-UC algorithm is slightly lower than that of those based on the CSP-CC algorithm. Nevertheless, the former algorithm is more practical and cost-effective than the latter. But in cross-subjects, the classification models based on the CSP-UC algorithm outperform those based on the CSP-CC algorithm in both accuracy and the number of used channels.},
  archive      = {J_NCA},
  author       = {Zeng, Hong and Zakaria, Wael},
  doi          = {10.1007/s00521-022-07833-x},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1423-1445},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new common spatial pattern-based unified channels algorithm for driver’s fatigue EEG signals classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emotion recognition in EEG signals using the continuous
wavelet transform and CNNs. <em>NCA</em>, <em>35</em>(2), 1409–1422. (<a
href="https://doi.org/10.1007/s00521-022-07843-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions are mental states associated with changes that influence people’s behavior, thinking, and health. Emotional changes can also appear in the organs and tissues of the human body as electrical potential differences gathered as biosignals in datasets. This work proposes the classification of emotions in electroencephalographical signals, transforming these discrete signals into a time-scale representation by spectral analysis. Our approach uses the wavelet transform to obtain scalogram images of electroencephalographic signals, treating these images as the scaled distribution of energy associated with a sign. Feature extraction from the scalograms is performed using convolutional neural networks (CNNs), leading to the proposal of two classification models. The threshold values in primitive emotions define one model of four emotions and the second of eight. The data augmentation technique increases the dataset size to compensate for the extra classes added in the second CNN model. The classification results were evaluated using different performance metrics and compared with related works in the literature.},
  archive      = {J_NCA},
  author       = {Almanza-Conejo, Oscar and Almanza-Ojeda, Dora Luz and Contreras-Hernandez, Jose Luis and Ibarra-Manzano, Mario Alberto},
  doi          = {10.1007/s00521-022-07843-9},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1409-1422},
  shortjournal = {Neural Comput. Appl.},
  title        = {Emotion recognition in EEG signals using the continuous wavelet transform and CNNs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modal traffic event detection using shapelets.
<em>NCA</em>, <em>35</em>(2), 1395–1408. (<a
href="https://doi.org/10.1007/s00521-022-07837-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic management continues to be one of the most critical challenges facing smart cities. Timely detection of incidents plays an important role in reducing fatality rates, avoiding congestion and improving traffic conditions. Currently, traditional traffic event detection approaches often rely on one source of data, such as road sensor readings or social media posts. However, there is a need for new approaches that can combine these channels and benefit from the diversity of the collected data for better event detection performance. This paper presents a new framework for near real-time event detection based on the fusion of sensor readings and social media data. The shapelets technique, used for sensor readings, generates sub-sequences of the time series representing distinctive patterns. Each pattern is called a shapelet and is selected based on the maximal differentiation achieved between the different classes of a time series set. In traffic events, shapelets can represent patterns of incidents/congestion as well as normal traffic situations that the framework utilizes to detect the occurrence of events. Similarly, social media posts can be featured as shapelets to enable the combination of both media channels creating a multi-modal solution. In the proposed framework, two pipelines are defined : sensor readings detection pipeline and social media detection pipeline. In addition, two multi-modal fusion techniques based on Shapelet Transform are suggested and compared, namely early fusion and late fusion. They help in combining the two pipelines either at the data level or at the decision level. Validation using the M25 London Circular road data shows that early fusion of both sources has better detection rate and better performance over late fusion.},
  archive      = {J_NCA},
  author       = {AlDhanhani, Ahmed and Damiani, Ernesto and Mizouni, Rabeb and Wang, Di and Al-Rubaie, Ahmad},
  doi          = {10.1007/s00521-022-07837-7},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1395-1408},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-modal traffic event detection using shapelets},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep reinforcement learning for automated search of model
parameters: Photo-fenton wastewater disinfection case study.
<em>NCA</em>, <em>35</em>(2), 1379–1394. (<a
href="https://doi.org/10.1007/s00521-022-07803-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical optimization solves problems that are analytically intractable at the cost of arriving at a sufficiently good but rarely optimal solution. To maximize the result, optimization algorithms are run with the guidance and supervision of a human, usually an expert in the problem. Recent advances in deep reinforcement learning motivate interest in an artificial agent capable of learning to do the expert’s task. Specifically, we present a proximal policy optimization agent that learns to optimize in a real case study such as the modeling of the photo-fenton disinfection process, which involves a number of parameters that have to be adjusted to minimize the error of the model with respect to the experimental data collected in several trials. The expert spends an average of 4 h to find a suitable set of parameters. On the other hand, the agent we present does not require a human expert to guide or validate the optimization procedure and achieves similar results in $$2.5\times$$ less time.},
  archive      = {J_NCA},
  author       = {Hernández-García, Sergio and Cuesta-Infante, Alfredo and Moreno-SanSegundo, José Ángel and Montemayor, Antonio S.},
  doi          = {10.1007/s00521-022-07803-3},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1379-1394},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep reinforcement learning for automated search of model parameters: Photo-fenton wastewater disinfection case study},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSSPP: Modified sparrow search algorithm based mobile sink
path planning for WSNs. <em>NCA</em>, <em>35</em>(2), 1363–1378. (<a
href="https://doi.org/10.1007/s00521-022-07794-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Past studies reveal the benefits of using Mobile Sink in Wireless Sensor Networks to bring about increased data collection efficiency and overall network performance in numerous applications. While several MS data gathering methods have been proposed, most of them are less adaptive to changes in network topology and fails to modify the MS path suitably in response to node failures. In this paper, we propose a Modified Sparrow Search Algorithm-based Mobile Sink Path Planning for WSNs (MSSPP) to create shorter travel route for MS and minimize data gathering latency. The proposed method helps in improving the performance of basic SSA by enhancing the quality of initial sparrow population, population diversity and search ability through modified strategies and is adaptive to node failure scenarios. In the first phase, we introduce a modified Sparrow Search-based algorithm to select a set of RPs that maximizes the coverage of nodes and minimizes the overlap in RP coverage. Then, an ACO-based path planning algorithm is utilized to determine the shortest tour through the RPs. The results reveal the effectiveness of MSSPP against other related approaches in terms of number of RPs, data gathering time, MS path, energy utilization and network lifetime.},
  archive      = {J_NCA},
  author       = {Khedr, Ahmed M. and Al Aghbari, Zaher and Raj, Pravija P. V.},
  doi          = {10.1007/s00521-022-07794-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1363-1378},
  shortjournal = {Neural Comput. Appl.},
  title        = {MSSPP: Modified sparrow search algorithm based mobile sink path planning for WSNs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced binary particle swarm optimization (e-BPSO)
algorithm for service placement in hybrid cloud platforms. <em>NCA</em>,
<em>35</em>(2), 1343–1361. (<a
href="https://doi.org/10.1007/s00521-022-07839-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid cloud platforms offer an attractive solution to organizations interested in implementing integrated private and public cloud applications to meet their profitability requirements. However, this can only be achieved by utilizing available resources while speeding up execution processes. Accordingly, deploying new applications entails dedicating some of these processes to a private cloud while allocating others to the public cloud. In this context, the current work aims to minimize relevant costs and deliver effective choices for an optimal service placement solution within minimal execution time. To date, several evolutionary algorithms have been applied to solve the challenging service placement problem by dealing with complex solution spaces to provide an optimal placement with relatively short execution times. In particular, the standard BPSO algorithm has been found to display a significant disadvantage, namely getting trapped in local optima and demonstrating a noticeable lack of robustness in dealing with service placement problems. Hence, to overcome the critical shortcomings associated with the standard BPSO, an enhanced binary particle swarm optimization (E-BPSO) algorithm is proposed, comprising a modification inspired by the continuous PSO for the particle position updating equation. Our proposed E-BPSO algorithm is shown to outperform state-of-the-art approaches using a real benchmark task in terms of both cost and execution time.},
  archive      = {J_NCA},
  author       = {Abbes, Wissem and Kechaou, Zied and Hussain, Amir and Qahtani, Abdulrahman M. and Almutiry, Omar and Dhahri, Habib and Alimi, Adel M.},
  doi          = {10.1007/s00521-022-07839-5},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1343-1361},
  shortjournal = {Neural Comput. Appl.},
  title        = {An enhanced binary particle swarm optimization (E-BPSO) algorithm for service placement in hybrid cloud platforms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distance-based arranging oversampling technique for
imbalanced data. <em>NCA</em>, <em>35</em>(2), 1323–1342. (<a
href="https://doi.org/10.1007/s00521-022-07828-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance data sets are common in a vast variety of real-world application areas. Synthetic minority oversampling technique (SMOTE) is an important technique for processing imbalanced data sets. SMOTE requires the user to preset the number of nearest neighbor instances before synthesizing instances, which is often difficult to choose accurately. Moreover, SMOTE is easy to synthesize minority instances in the majority areas, which leads to the performance degradation of the classifier. To address these issues, in this paper, a novel distance-based arranging oversampling (DAO) technique is proposed. DAO can effectively prevent users from selecting inaccurate hyperparameters, and DAO can be used as an alternative algorithm to replace the SMOTE-based oversampling technique. We further filter the synthesized instances by setting appropriate conditions to avoid generating minority instances in the majority domain. In our experiments, we collect 25 public benchmark data sets from the KEEL database and HDDT database, and apply CART and ID3 classification models on the oversampling training set of each data set to assess our DAO technique. Under the two evaluation metrics, F-measure and kappa, compared with the state-of-the-art oversampling techniques, our proposed method is superior or partially superior to them.},
  archive      = {J_NCA},
  author       = {Dai, Qi and Liu, Jian-wei and Zhao, Jia-Liang},
  doi          = {10.1007/s00521-022-07828-8},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1323-1342},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distance-based arranging oversampling technique for imbalanced data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating ten BCI commands using four simple motor
imageries and classification by divergence-based DNN. <em>NCA</em>,
<em>35</em>(2), 1303–1322. (<a
href="https://doi.org/10.1007/s00521-022-07787-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain computer interface (BCI) systems are utilized for transferring information among humans and computers by analyzing electroencephalogram (EEG) recordings. However, in this emerging research field, the number of commands in the BCI is limited in relation to the number of motor imagery (MI) tasks; in the current literature, mostly two or four commands (classes) are studied. As a solution to this problem, it is recommended to use mental tasks as well as MI tasks. Unfortunately, the use of this approach reduces the classification performance of MI EEG signals. The fMRI analyses show that the resources in the brain associated with the motor imagery can be activated independently. It is assumed that the activity of the brain produced by the MI of the combination of body parts corresponds to the superposition of the activities generated during each body part’s simple MI. In this study, in order to create more than four BCI commands, we suggest to generate combined MI EEG signals artificially by using tongue, feet, left and right hands’ motor imageries in pairs. For the first time in the literature, combined MI EEG signal is artificially generated by using the superposition of simple MI EEG signals from two different sources. We observe in the literature that the classification performances are adversely affected as the number of classes is increased, and the classification performances for the MI with more than four classes are poor. The aim of this study is to increase the BCI commands by generating artificially combined MI EEG signals and to achieve high success rates for ten BCI commands by using a small-sized deep neural network (DNN). In this context, by analyzing the ERD signal of combined MI tasks, we investigate how to generate combined MI signals artificially using the superposition of simple MI signals. The proposed method is validated on real data which consist of simple and combined MI EEG signals, and average classification performance of 81.8\% is achieved for ten BCI commands generated from the BCI Competition 3 and 4 datasets.},
  archive      = {J_NCA},
  author       = {Korhan, Nuri and Olmez, Tamer and Dokur, Zümray},
  doi          = {10.1007/s00521-022-07787-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1303-1322},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generating ten BCI commands using four simple motor imageries and classification by divergence-based DNN},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The application of neural network for software vulnerability
detection: A review. <em>NCA</em>, <em>35</em>(2), 1279–1301. (<a
href="https://doi.org/10.1007/s00521-022-08046-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, being benefited from the ability of automated feature extraction and the performance of software vulnerability identification, deep learning techniques have attracted extensive attention in data-driven software vulnerability detection. Many methods based on deep learning have been proposed to speed up and intelligentize the process of vulnerability identification. Although these methods have shown significant advantages over traditional machine learning ones, there is an apparent gap between the deep learning-based detection systems and human experts in understanding potentially vulnerable code semantics. In some real-world vulnerability prediction scenarios, the performance of deep learning-based methods drops by more than 50\% compared to these methods’ performance in experimental scenarios. We define this phenomenon as the perception gap by examining and reviewing the early software vulnerability detection approaches. Then, from the perspective of the perception gap, this paper profoundly explores the current software vulnerability detection methods and how existing solutions endeavor to narrow the perception gap and push forward the development of the field of interest. Finally, we summarize the challenges of this new field and discuss the possible future.},
  archive      = {J_NCA},
  author       = {Zhu, Yuhui and Lin, Guanjun and Song, Lipeng and Zhang, Jun},
  doi          = {10.1007/s00521-022-08046-y},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1279-1301},
  shortjournal = {Neural Comput. Appl.},
  title        = {The application of neural network for software vulnerability detection: A review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of streaming analytics for artificial lift
systems: A human-in-the-loop approach for analysing clustered
time-series data from progressive cavity pumps. <em>NCA</em>,
<em>35</em>(2), 1247–1277. (<a
href="https://doi.org/10.1007/s00521-022-07995-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing real-time performance of Artificial Lift Pumps is a prevalent time-series problem to tackle for natural gas operators in Eastern Australia. Multiple physics, data-driven, and hybrid approaches have been investigated to analyse or predict pump performance. However, these methods present a challenge in running compute-heavy algorithms on streaming time-series data. As there is limited research on novel approaches to tackle multivariate time-series analytics for Artificial Lift systems, this paper introduces a human-in-the-loop approach, where petroleum engineers label clustered time-series data to aid in streaming analytics. We rely on our recently developed novel approach of converting streaming time-series data into heatmap images to assist with real-time pump performance analytics. During this study, we were able to automate the labelling of streaming time-series data, which helped petroleum and well surveillance engineers better manage Artificial Lift Pumps through machine learning supported exception-based surveillance. The streaming analytics system developed as part of this research used historical time-series data from three hundred and fifty-nine (359) coal seam gas wells. The developed method is currently used by two natural gas operators, where the operators can accurately detect ten (10) performance-related events and five (5) anomalous events. This paper serves a two-fold purpose; first, we describe a step-by-step methodology that readers can use to reproduce the clustering method for multivariate time-series data. Second, we demonstrate how a human-in-the-loop approach adds value to the proposed method and achieves real-world results.},
  archive      = {J_NCA},
  author       = {Saghir, Fahd and Gonzalez Perdomo, M. E. and Behrenbruch, Peter},
  doi          = {10.1007/s00521-022-07995-8},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1247-1277},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of streaming analytics for artificial lift systems: A human-in-the-loop approach for analysing clustered time-series data from progressive cavity pumps},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance analysis of stirling engine using computational
intelligence techniques (ANN &amp; fuzzy mamdani model) and hybrid
algorithms (ANN-PSO &amp; ANFIS). <em>NCA</em>, <em>35</em>(2),
1225–1245. (<a
href="https://doi.org/10.1007/s00521-022-07385-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stirling engine is considered as one of the most promising alternatives to conventional combustion units due to its versatility and potential to achieve relatively high efficiency. The output power and torque are the main performance indicators that depend on many variables. Many studies have pointed out that the relationship between the performance indicators of the Stirling engine and its input variables was nonlinear. This study analyses the prediction performance of power and torque in a Stirling engine system using soft computing techniques—artificial neural network (ANN) and Fuzzy Mamdani Model (FMM) and hybrid algorithms—adaptive neuro-fuzzy inference system (ANFIS) and artificial neural network trained with particle swarm optimization (ANN-PSO). The performance of these approaches has been discussed using a dataset from a test conducted on an existing Stirling engine. The performance indicators of the different models considering the power and the torque were predicted and analysed. A parametric analysis has been performed for the ANN-PSO model to identify the best model configuration considering the number of neurons in hidden layers, the number of swarm size and acceleration factors. A detailed description of the process leading to the identification of the best networks architecture for the power and torque model has been provided. The comparison of the four approaches indicates that FMM exhibits the highest performance prediction considering the power while the ANN-PSO and ANFIS model exhibit the highest performance considering the torque. This study demonstrates the suitability of soft computing techniques and hybrid algorithms for the prediction of Stirling engine characteristics and its potential to optimize time and experimental cost.},
  archive      = {J_NCA},
  author       = {Machesa, M. G. K. and Tartibu, L. K. and Okwu, M. O.},
  doi          = {10.1007/s00521-022-07385-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1225-1245},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance analysis of stirling engine using computational intelligence techniques (ANN &amp; fuzzy mamdani model) and hybrid algorithms (ANN-PSO &amp; ANFIS)},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary algorithm applied to time-series landing flight
path and control optimization of supersonic transport. <em>NCA</em>,
<em>35</em>(2), 1211–1223. (<a
href="https://doi.org/10.1007/s00521-021-06264-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An evolutionary algorithm (EA) was applied in this study to optimize the landing flight path of a delta-winged supersonic transport (SST). However, it is difficult for a delta wing with a large sweepback angle to reduce the aerodynamic drag during supersonic cruising to gain sufficient lift force at low speeds, particularly during takeoff and landing. Besides, high-fidelity computational fluid dynamics is required to evaluate the flight path with a complex flowfield. This study performed an efficient flight simulation based on the Kriging model-assisted aerodynamic estimation to carry out global optimization. Then, the designs of the flight and control sequence were realized for time-series optimization of effective SST landing. To develop the EA, two design scenarios were considered; one involved only the elevator, which is an aerodynamic control surface that controls the aircraft, and the other involved introducing thrust control in addition to elevator control. In the scenario involving only elevator control, feasible solutions could not be obtained owing to the poor low-speed aerodynamic performance of the SST. This paper presents several feasible solutions enabling reasonable SST landing performance in the scenario involving the elevator and thrust controls along with descriptions regarding the optimum flight and control sequences. In addition, we analyzed the solutions by analyzing the variance to obtain qualitative information. Consequently, we determined that elevator control was considerably effective in cases with the microburst effect than in cases without the microburst effect.},
  archive      = {J_NCA},
  author       = {Kanazaki, Masahiro and Setoguchi, Nao and Saisyo, Ryouta},
  doi          = {10.1007/s00521-021-06264-4},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1211-1223},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evolutionary algorithm applied to time-series landing flight path and control optimization of supersonic transport},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effect of learning strategies in an evolutionary method: The
case of the bi-objective quadratic multiple knapsack problem.
<em>NCA</em>, <em>35</em>(2), 1183–1209. (<a
href="https://doi.org/10.1007/s00521-022-07555-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we solve the bi-objective quadratic multiple knapsack problem, an NP-Hard combinatorial optimization problem, with a cooperative evolutionary method. The proposed method starts by generating a first approximate Pareto front by using the $$\varepsilon $$ -constraint operator-based approach, that is, the first stage of the evolutionary method. The second stage is based upon an iterative procedure, where the non-dominated sorting genetic algorithm is employed for generating a series of populations. In order to avoid a premature convergence, at each step of the iterative procedure, learning strategies are added: (i) the fusion operator and (ii) the $$\varepsilon $$ -constraint operator. These learning strategies are introduced for maintaining the diversity of the series of populations and so trying to avoid premature convergence and stagnations on local optima. The performance of the proposed evolutionary method with learning strategies is evaluated on a set of benchmark instances of the literature containing both medium- and large-scale instances. Its provided results are compared to those achieved by the best methods available in the literature. New results have been obtained.},
  archive      = {J_NCA},
  author       = {Aïder, Méziane and Gacem, Oussama and Hifi, Mhand},
  doi          = {10.1007/s00521-022-07555-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1183-1209},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effect of learning strategies in an evolutionary method: The case of the bi-objective quadratic multiple knapsack problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fake review and reviewer detection through behavioral graph
partitioning integrating deep neural network. <em>NCA</em>,
<em>35</em>(2), 1169–1182. (<a
href="https://doi.org/10.1007/s00521-021-05948-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a profound effect of online reviews on customers’ decisions about purchasing products or services, untruthful (fake) reviews written to deceive product quality and receive unfair commercial benefits have become a crucial problem. In this work, we propose a graph partitioning approach (BeGP) and its extension (BeGPX) to distinguish fake reviewers from benign ones. The main idea of BeGP is to first construct a behavioral graph in which reviewers are connected if they share common characteristic features that capture their similar behavior. Then, the algorithm starts with a small subgraph of known fake reviewers and afterwards repeatedly expands the subgraph by inducing other connected suspicious reviewers. Subsequently, all reviews of those suspects are hypothesized to be untruthful. Moreover, to enhance the performance of fake review(er) detection, BeGPX employs additional analysis of semantic content and emotions expressed in reviews. In particular, we use the deep neural network to learn word embeddings representation and lexicon-based emotion indicators in order to integrate into the graph construction process. We demonstrate the effectiveness of BeGP and BeGPX on two real-world review datasets from Yelp.com. The results show that both approaches outperform state-of-the-art methods with accurately identifying fake review(er)s within the k-first order of rankings. In addition, BeGPX shows significant enhancement although being provided with only a few amount of learning labeled data.},
  archive      = {J_NCA},
  author       = {Manaskasemsak, Bundit and Tantisuwankul, Jirateep and Rungsawang, Arnon},
  doi          = {10.1007/s00521-021-05948-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1169-1182},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fake review and reviewer detection through behavioral graph partitioning integrating deep neural network},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A flexible framework for anomaly detection via
dimensionality reduction. <em>NCA</em>, <em>35</em>(2), 1157–1167. (<a
href="https://doi.org/10.1007/s00521-021-05839-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is challenging, especially for large datasets in high dimensions. Here, we explore a general anomaly detection framework based on dimensionality reduction and unsupervised clustering. DRAMA is released as a general python package that implements the general framework with a wide range of built-in options. This approach identifies the primary prototypes in the data with anomalies detected by their large distances from the prototypes, either in the latent space or in the original, high-dimensional space. DRAMA is tested on a wide variety of simulated and real datasets, in up to 3000 dimensions, and is found to be robust and highly competitive with commonly used anomaly detection algorithms, especially in high dimensions. The flexibility of the DRAMA framework allows for significant optimization once some examples of anomalies are available, making it ideal for online anomaly detection, active learning, and highly unbalanced datasets. Besides, DRAMA naturally provides clustering of outliers for subsequent analysis.},
  archive      = {J_NCA},
  author       = {Vafaei Sadr, Alireza and Bassett, Bruce A. and Kunz, M.},
  doi          = {10.1007/s00521-021-05839-5},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1157-1167},
  shortjournal = {Neural Comput. Appl.},
  title        = {A flexible framework for anomaly detection via dimensionality reduction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The effect of different stopping criteria on multi-objective
optimization algorithms. <em>NCA</em>, <em>35</em>(2), 1125–1155. (<a
href="https://doi.org/10.1007/s00521-021-05805-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multi-objective optimization (EMO) refers to the domain in which an evolutionary algorithm is applied to tackle an optimization problem with multiple objective functions. The literature is rich with many approaches proposed to solve multi-objective problems including the NSGA-II, MOEA/D, and MOPSO algorithms. The proposed approaches include stand-alone as well as hybrid techniques. One critical aspect of any evolutionary algorithm (EA) is the stopping criterion. The selection of a specific stopping criterion can have a considerable effect on the performance and the final solution provided by the EA. A number of different stopping criteria, specifically designed for EMO, have been proposed in the literature. In this paper, the performance of six different EMO algorithms is tested and compared using four stopping criteria. The experiments are performed using the ZDT, DTLZ, CEC2009, Tanaka and Srivana test functions. Experimental results are analyzed to highlight the proper stopping criteria for different algorithms.},
  archive      = {J_NCA},
  author       = {Abu Doush, Iyad and El-Abd, Mohammed and Hammouri, Abdelaziz I. and Bataineh, Mohammad Qasem},
  doi          = {10.1007/s00521-021-05805-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1125-1155},
  shortjournal = {Neural Comput. Appl.},
  title        = {The effect of different stopping criteria on multi-objective optimization algorithms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Investigation of PCA as a compression pre-processing tool
for x-ray image classification. <em>NCA</em>, <em>35</em>(2), 1099–1109.
(<a href="https://doi.org/10.1007/s00521-020-05668-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification has rapidly gained interest in the medical field with the ability to assist practitioners to diagnose a variety of conditions. Due to the critical nature of the application, any pre-processing function that may compromise the fitness of the classifier requires careful assessment. Image compression, albeit necessary in terms of volume-based goals, is an example of such a preprocessing function that can deeply affect data veracity. In this work, the trade-off between volume and veracity in bone fracture classification using X-ray images is investigated. The impacts of the dimensionality reduction technique—via Principal Component Analysis—as a compression tool on X-ray image classification are explored. The effects of the compression technique on the detection of fractures are assessed by evaluating how reductions in principal components of the X-ray image, and subsequently its volume, affect the accuracy of the fracture classification. Varying levels of compression are applied to both healthy and fracture image sets with tests conducted using ANFIS, SVM and ANN classifiers. Results indicate that a potentially feasible compression range exists whereby classification accuracy is acceptably diminished, after which further compression yields are marginal and classification accuracies drastically decrease. Overall results demonstrate the suitability of the method which yields compression levels of up to 94\% with a corresponding minimal drop in classification accuracy of 2\%.},
  archive      = {J_NCA},
  author       = {Doorsamy, W. and Rameshar, V.},
  doi          = {10.1007/s00521-020-05668-y},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1099-1109},
  shortjournal = {Neural Comput. Appl.},
  title        = {Investigation of PCA as a compression pre-processing tool for X-ray image classification},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selection of optimal wavelet features for epileptic EEG
signal classification with LSTM. <em>NCA</em>, <em>35</em>(2),
1077–1097. (<a
href="https://doi.org/10.1007/s00521-020-05666-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy remains one of the most common chronic neurological disorders; hence, there is a need to further investigate various models for automatic detection of seizure activity. An effective detection model can be achieved by minimizing the complexity of the model in terms of trainable parameters while still maintaining high accuracy. One way to achieve this is to select the minimum possible number of features. In this paper, we propose a long short-term memory (LSTM) network for the classification of epileptic EEG signals. Discrete wavelet transform (DWT) is employed to remove noise and extract 20 eigenvalue features. The optimal features were then identified using correlation and P value analysis. The proposed method significantly reduces the number of trainable LSTM parameters required to attain high accuracy. Finally, our model outperforms other proposed frameworks, including popular classifiers such as logistic regression (LR), support vector machine (SVM), K-nearest neighbor (K-NN) and decision tree (DT).},
  archive      = {J_NCA},
  author       = {Aliyu, Ibrahim and Lim, Chang Gyoon},
  doi          = {10.1007/s00521-020-05666-0},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1077-1097},
  shortjournal = {Neural Comput. Appl.},
  title        = {Selection of optimal wavelet features for epileptic EEG signal classification with LSTM},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonparametric method of topic identification using
granularity concept and graph-based modeling. <em>NCA</em>,
<em>35</em>(2), 1055–1075. (<a
href="https://doi.org/10.1007/s00521-020-05662-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to classify the large unstructured documents into different topics without involving huge computational resources and a priori knowledge. The concept of granularity is employed here to extract contextual information from the documents by generating granules of words (GoWs), hierarchically. The proposed granularity-based word grouping (GBWG) algorithm in a computationally efficient way group the words at different layers by using co-occurrence measure between the words of different granules. The GBWG algorithm terminates when no new GoW is generated at any layer of the hierarchical structure. Thus multiple GoWs are obtained, each of which contains contextually related words, representing different topics. However, the GoWs may contain common words and creating ambiguity in topic identification. Louvain graph clustering algorithm has been employed to automatically identify the topics, containing unique words by using mutual information as an association measure between the words (nodes) of each GoW. A test document is classified into a particular topic based on the probability of its unique words belong to different topics. The performance of the proposed method has been compared with other unsupervised, semi-supervised, and supervised topic modeling algorithms. Experimentally, it has been shown that the proposed method is comparable or better than the state-of-the-art topic modeling algorithms which further statistically verified with the Wilcoxon Rank-sum Test.},
  archive      = {J_NCA},
  author       = {Ganguli, Isha and Sil, Jaya and Sengupta, Nandita},
  doi          = {10.1007/s00521-020-05662-4},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1055-1075},
  shortjournal = {Neural Comput. Appl.},
  title        = {Nonparametric method of topic identification using granularity concept and graph-based modeling},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 2019 india international congress on computational
intelligence. <em>NCA</em>, <em>35</em>(2), 1053–1054. (<a
href="https://doi.org/10.1007/s00521-022-07955-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Deb, Suash and Wong, Ka-Chun and Hanne, Thomas},
  doi          = {10.1007/s00521-022-07955-2},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1053-1054},
  shortjournal = {Neural Comput. Appl.},
  title        = {2019 india international congress on computational intelligence},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hypothesis derivation and its verification by a wholly
automated many-objective evolutionary optimization system. <em>NCA</em>,
<em>35</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s00521-021-05786-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study has constructed a fully automated multidisciplinary and many-objective evolutionary design optimization system independent of computer environments to evaluate objective functions; the research applied it to a geometric design problem of a flyback booster for next-generation space transportation. In optimization involving objective functions to appraise the aero-/structural-dynamic performance with high fidelity, spatial discretization hinders the overall automation. This research has facilitated an efficient optimal design by wholly automating high-fidelity assessments, which designers had to implement manually, and has accomplished optimizations that directly contribute to real-world design problems. Moreover, this study would accumulate design knowledge for space transportation that the market is reviving. The total automated system yielded the embedding of geometric trait lines to ensure the discretization even for large curvature surfaces; the system innovated a robust automatic error-checking mechanism in the system’s preprocess. Consequently, the entirely automatized optimization procured nondominated solution sets for more precise data analyses in a pragmatic execution period. Design informatics, a framework combining optimization and data analysis, functioned usefully in real-world design on flyback-booster geometry by materializing smooth deriving and verifying a design hypothesis; eventually, the research gained a new design principle.},
  archive      = {J_NCA},
  author       = {Chiba, Kazuhisa and Sawahara, Masataka and Sumimoto, Tsuyoshi and Hatta, Taiki and Kanazaki, Masahiro},
  doi          = {10.1007/s00521-021-05786-1},
  journal      = {Neural Computing and Applications},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hypothesis derivation and its verification by a wholly automated many-objective evolutionary optimization system},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symmetric mean binary pattern-based pakistan sign language
recognition using multiclass support vector machines. <em>NCA</em>,
<em>35</em>(1), 949–972. (<a
href="https://doi.org/10.1007/s00521-022-07804-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign languages are a fundamental source of communication for the deaf community, generated through movements of the human body. Similar to the natural languages, sign languages vary from region to region, and from nation to nation. Pakistan sign language (PSL) is inspired by Urdu, national language of Pakistan. It has 38 alphabet signs, and out of them, 36 are represented by the static hand gestures. Automatic recognition of a sign language helps in interaction between the hearing and deaf individuals. The number of quality efforts in context of Pakistan sign language recognition is quite limited, leaving a fair room for addressing open issues of research, i.e., (i) efficient hand detection under complex backgrounds and (ii) extracting signer independent feature vector that should not only be discriminant for all the PSL alphabets but reduced dimension as well. In this research, recognition of PSL static alphabets is addressed where the task of hand localization is accomplished through faster regional-convolutional neural networks (faster R-CNN). Feature extraction is achieved through presenting symmetric mean-based binary patterns (sMBP) that extend uniform local binary patterns. The proposed feature vector not only suppresses the noise but preserves the rotation invariance as well. Classification task is accomplished through error correction output codes (ECOC)-based support vector machines using linear, polynomial and radial basis function kernels with one-vs-one and one-vs-all modalities. The proposed technique is validated through PSL dataset, created by seven native signers, having 7174 images. The comparative results clearly demonstrate the authority of the proposed technique over all of its baseline and competitor techniques.},
  archive      = {J_NCA},
  author       = {Shah, Syed Muhammad Saqlain and Khan, Javed I. and Abbas, Syed Husnain and Ghani, Anwar},
  doi          = {10.1007/s00521-022-07804-2},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {949-972},
  shortjournal = {Neural Comput. Appl.},
  title        = {Symmetric mean binary pattern-based pakistan sign language recognition using multiclass support vector machines},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early automated prediction model for the diagnosis and
detection of children with autism spectrum disorders based on effective
sociodemographic and family characteristic features. <em>NCA</em>,
<em>35</em>(1), 921–947. (<a
href="https://doi.org/10.1007/s00521-022-07822-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Children with autism spectrum disorders (ASDs) tremendously impact people’s lives, and the incidence and prevalence of ASDs are increasing globally. Global health organisations and other autism-treatment centres specialising in autism diagnosis and detection are encountering challenges on how to provide an appropriate ASD diagnosis system that enables accurate analyses and early detection of autism. Information about ASD detection is affected by unknown aetiology of the disease, and an urgent solution is required to investigate its aetiological factors. Accordingly, increasing the opportunities to provide evidence of the ‘sociodemographic and family characteristics’ risk factors in predicting ASD is a scientific complex problem that needs to be solved. This study developed an early prediction model for diagnosing and detecting children with ASD based on effective sociodemographic and family characteristic features related to ASD using the machine learning (ML) model. The proposed methodology involves three phases. The identification phase is first accomplished by identifying a large-scale ASD dataset and preprocessing stages: 1-NN model for imputing missing data, feature-selection methods using Chi2 and Relief, and adaptive balancing data approach using Synthetic Minority Oversampling Technique. Chi2 and Relief are applied to determine the most effective sociodemographic and family characteristic features and produce a new balanced ASD dataset. The second development phase trains and tests the newly prepared ASD dataset through eight ML methods: decision tree, random forest, Naive Bayes, kNN, SVM, logistic regression, AdaBoost, and neural network multilayer perceptron (MLP). The developed model is evaluated in the third phase using five metrics: accuracy, precision, recall, F1 and AUROC, and test time in seconds. Results indicated the following: (1) Out of 10 highly effective sociodemographic and family characteristic features, seven related to autism cases are extracted. (2) Correlation sensitivity analysis reveals that the ‘Mom_age_at_child_birth’ has the highest positive correlation with ‘Father_age_at_child_birth,’ with an r-value of 0.751. Moreover, ‘child_birth_month’ and ‘Birth_number’ have the highest negative correlation with ‘Ses_points_1_10’, with an r-value of (− 0.07). (3) AdaBoost, neural network, K-nearest neighbour, and decision tree methods show higher accuracy results (0.9995, 0.9925, 0.9834, and 0.9786, respectively), whereas random forest, logistic regression, and Naive Bayes methods show relatively lower accuracy (0.8297, 0.8199 and 0.8002, respectively). However, the support vector machine method shows the lowest accuracy (0.7105). AdaBoost obtained the highest accuracy on the basis of four other evaluation metrics (AUC = 0.9999, F1 = 0.9995, precision = 0.9995 and recall = 0.9995). Accordingly, the new preprocessed and balanced ASD dataset can be utilised as a data source for autism research. The preprocessing stages can be considered correct and successfully perform better results than the original ASD dataset. Similar results from Chi2 and Relief in the feature-selection approaches substantially improved the classification accuracy. The study confirms the efficacy of the proposed prediction model compared with previous models in different comparative points. Early prediction of autism is possible through this proposed model.},
  archive      = {J_NCA},
  author       = {Albahri, A. S. and Hamid, Rula A. and Zaidan, A. A. and Albahri, O. S.},
  doi          = {10.1007/s00521-022-07822-0},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {921-947},
  shortjournal = {Neural Comput. Appl.},
  title        = {Early automated prediction model for the diagnosis and detection of children with autism spectrum disorders based on effective sociodemographic and family characteristic features},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond fixed time and space: Next POI recommendation via
multi-grained context and correlation. <em>NCA</em>, <em>35</em>(1),
907–920. (<a href="https://doi.org/10.1007/s00521-022-07825-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {POI recommendation is significant for discovering attractive locations, crime prediction, and smart city construction. Most existing methods only consider the fixed time and space between successive check-in points when capturing sequential patterns from trajectory history. However, single granularity is inadequate to mine the spatial-temporal influence on sequential patterns in sparse and incomplete check-in data. Besides, they neglect the relevance between non-adjacent check-ins and fail to fully exploit factors for the correlation mining. To tackle the above issues, we propose a novel model for the next POI recommendation via multi-granularity context and correlation. It focuses on exploring vital factors for modeling effective spatial-temporal contexts and mining potential correlations among check-ins. Specifically, for context modeling, we explore effective spatial-temporal contexts to learn mobility patterns locally and globally by introducing hierarchical regions and slots. For correlation modeling, we only focus on the geographical influence. We employ a spatial-aware function to measure the correlations among check-ins to find the predictive ones for the recommendation. Extensive experiments on widely used datasets indicate that our MGCOCO consistently and significantly outperforms the state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Li, Xixi and Hu, Ruimin and Wang, Zheng},
  doi          = {10.1007/s00521-022-07825-x},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {907-920},
  shortjournal = {Neural Comput. Appl.},
  title        = {Beyond fixed time and space: Next POI recommendation via multi-grained context and correlation},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting of solar radiation using different machine
learning approaches. <em>NCA</em>, <em>35</em>(1), 887–906. (<a
href="https://doi.org/10.1007/s00521-022-07841-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, monthly solar radiation (SR) estimation was performed using five different machine learning-based approaches. The models used are support vector machine regression (SVMR), long short-term memory (LSTM), Gaussian process regression (GPR), extreme learning machines (ELM) and K-nearest neighbors (KNN). Modeling of these approaches was carried out in two stages. In the first stage, VIF analysis was carried out to develop the model. Thus, the input parameters that decrease the performance of the model are removed. In the second stage, remaining input parameters such as meteorological data, station location data and spatial and temporal information were used in the forecasting modeling according to the correlation SR. In this study, the data set is divided into two parts as test and training. 30\% was used in the testing phase, and 70\% of the data was used in the training phase. When comparing models, the following error statistics were used: Nash–Sutcliffe efficiency coefficient (NSE), mean absolute error (MAE), mean absolute relative error (MARE), root-mean-square error (RMSE) and coefficient of determination (R2). In addition, Taylor diagrams, violin plots, box error, spider plot and Kruskal–Wallis (KW) and ANOVA test were utilized to determine robustness of model&#39;s forecast. As a result of the study, the KW test and ANOVA test results showed that the data of many models were from the same population with observations, and it has proved that LSTM and GPR algorithms are applicable, valid and an alternative for SR forecasting in Turkey, which has arid and semi-arid climatic regions.},
  archive      = {J_NCA},
  author       = {Demir, Vahdettin and Citakoglu, Hatice},
  doi          = {10.1007/s00521-022-07841-x},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {887-906},
  shortjournal = {Neural Comput. Appl.},
  title        = {Forecasting of solar radiation using different machine learning approaches},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multilevel thresholding satellite image segmentation using
chaotic coronavirus optimization algorithm with hybrid fitness function.
<em>NCA</em>, <em>35</em>(1), 855–886. (<a
href="https://doi.org/10.1007/s00521-022-07718-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is a critical step in digital image processing applications. One of the most preferred methods for image segmentation is multilevel thresholding, in which a set of threshold values is determined to divide an image into different classes. However, the computational complexity increases when the required thresholds are high. Therefore, this paper introduces a modified Coronavirus Optimization algorithm for image segmentation. In the proposed algorithm, the chaotic map concept is added to the initialization step of the naive algorithm to increase the diversity of solutions. A hybrid of the two commonly used methods, Otsu’s and Kapur’s entropy, is applied to form a new fitness function to determine the optimum threshold values. The proposed algorithm is evaluated using two different datasets, including six benchmarks and six satellite images. Various evaluation metrics are used to measure the quality of the segmented images using the proposed algorithm, such as mean square error, peak signal-to-noise ratio, Structural Similarity Index, Feature Similarity Index, and Normalized Correlation Coefficient. Additionally, the best fitness values are calculated to demonstrate the proposed method&#39;s ability to find the optimum solution. The obtained results are compared to eleven powerful and recent metaheuristics and prove the superiority of the proposed algorithm in the image segmentation problem.},
  archive      = {J_NCA},
  author       = {Hosny, Khalid M. and Khalid, Asmaa M. and Hamza, Hanaa M. and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-022-07718-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {855-886},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multilevel thresholding satellite image segmentation using chaotic coronavirus optimization algorithm with hybrid fitness function},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Skin cancer diagnosis based on deep transfer learning and
sparrow search algorithm. <em>NCA</em>, <em>35</em>(1), 815–853. (<a
href="https://doi.org/10.1007/s00521-022-07762-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer affects the lives of millions of people every year, as it is considered the most popular form of cancer. In the USA alone, approximately three and a half million people are diagnosed with skin cancer annually. The survival rate diminishes steeply as the skin cancer progresses. Despite this, it is an expensive and difficult procedure to discover this cancer type in the early stages. In this study, a threshold-based automatic approach for skin cancer detection, classification, and segmentation utilizing a meta-heuristic optimizer named sparrow search algorithm (SpaSA) is proposed. Five U-Net models (i.e., U-Net, U-Net++, Attention U-Net, V-net, and Swin U-Net) with different configurations are utilized to perform the segmentation process. Besides this, the meta-heuristic SpaSA optimizer is used to perform the optimization of the hyperparameters using eight pre-trained CNN models (i.e., VGG16, VGG19, MobileNet, MobileNetV2, MobileNetV3Large, MobileNetV3Small, NASNetMobile, and NASNetLarge). The dataset is gathered from five public sources in which two types of datasets are generated (i.e., 2-classes and 10-classes). For the segmentation, concerning the “skin cancer segmentation and classification” dataset, the best reported scores by U-Net++ with DenseNet201 as a backbone architecture are 0.104, $$94.16\%$$ , $$91.39\%$$ , $$99.03\%$$ , $$96.08\%$$ , $$96.41\%$$ , $$77.19\%$$ , $$75.47\%$$ in terms of loss, accuracy, F1-score, AUC, IoU, dice, hinge, and squared hinge, respectively, while for the “PH2” dataset, the best reported scores by the Attention U-Net with DenseNet201 as backbone architecture are 0.137, $$94.75\%$$ , $$92.65\%$$ , $$92.56\%$$ , $$92.74\%$$ , $$96.20\%$$ , $$86.30\%$$ , $$92.65\%$$ , $$69.28\%$$ , and $$68.04\%$$ in terms of loss, accuracy, F1-score, precision, sensitivity, specificity, IoU, dice, hinge, and squared hinge, respectively. For the “ISIC 2019 and 2020 Melanoma” dataset, the best reported overall accuracy from the applied CNN experiments is $$98.27\%$$ by the MobileNet pre-trained model. Similarly, for the “Melanoma Classification (HAM10K)” dataset, the best reported overall accuracy from the applied CNN experiments is $$98.83\%$$ by the MobileNet pre-trained model. For the “skin diseases image” dataset, the best reported overall accuracy from the applied CNN experiments is $$85.87\%$$ by the MobileNetV2 pre-trained model. After computing the results, the suggested approach is compared with 13 related studies.},
  archive      = {J_NCA},
  author       = {Balaha, Hossam Magdy and Hassan, Asmaa El-Sayed},
  doi          = {10.1007/s00521-022-07762-9},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {815-853},
  shortjournal = {Neural Comput. Appl.},
  title        = {Skin cancer diagnosis based on deep transfer learning and sparrow search algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel robust nonparallel support vector classifier based
on one optimization problem. <em>NCA</em>, <em>35</em>(1), 799–814. (<a
href="https://doi.org/10.1007/s00521-022-07814-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real data is often contaminated by outliers (label noises), which lead to the deviation of the final separating hyperplane and reduce the prediction accuracy. In this paper, we propose a novel robust geometric twin parametric-margin support vector machine (RGTPSVM) to tackle this issue. The method constructs classifier directly based on the average of two resulting nonparallel boundary hyperplanes, which are obtained by solving one single quadratic programming problem. We show that the boundary hyperplanes sought by RGTPSVM are less sensitive to the outliers, producing a more reasonable and robust final separating hyperplane. To further strengthen the robustness, we also design a rescaled squared hinge loss function for the model, since the hinge loss function is linear related to the margin variable and diverges to infinity. Extensive experiments are conducted to demonstrate the prediction performance of RGTPSVM. Compared with several popular SVMs, our method is stable and outperforms others in most cases.},
  archive      = {J_NCA},
  author       = {Qi, Kai and Yang, Hu},
  doi          = {10.1007/s00521-022-07814-0},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {799-814},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel robust nonparallel support vector classifier based on one optimization problem},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularized online tensor factorization for sparse knowledge
graph embeddings. <em>NCA</em>, <em>35</em>(1), 787–797. (<a
href="https://doi.org/10.1007/s00521-022-07796-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs represent real-world facts and are used in several applications; however, they are often incomplete and have many missing facts. Link prediction is the task of completing these missing facts from existing ones. Embedding models based on Tensor Factorization attain state-of-the-art results in link prediction. Nevertheless, the embeddings they produce can not be easily interpreted. Inspired by previous work on word embeddings, we propose inducing sparsity in the bilinear tensor factorization model, RESCAL, to build interpretable Knowledge Graph embeddings. To overcome the difficulties that stochastic gradient descent has when producing sparse solutions, we add $$l_1$$ regularization to the learning objective by using the generalized Regularized Dual Averaging online optimization algorithm. The proposed method substantially improves the interpretability of the learned embeddings while maintaining competitive performance in the standard metrics.},
  archive      = {J_NCA},
  author       = {Zulaika, Unai and Almeida, Aitor and López-de-Ipiña, Diego},
  doi          = {10.1007/s00521-022-07796-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {787-797},
  shortjournal = {Neural Comput. Appl.},
  title        = {Regularized online tensor factorization for sparse knowledge graph embeddings},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust medical image steganography approach based on
particle swarm optimization algorithm and quantum walks. <em>NCA</em>,
<em>35</em>(1), 773–785. (<a
href="https://doi.org/10.1007/s00521-022-07830-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical information plays an essential task in our everyday lives, in which medical data privacy and security constitute an important issue. The confidentiality of medical data can be achieved by applying one or more encryption and data hiding methods. Amidst the development of quantum computers, most medical data confidentiality techniques may be hacked because their construction is based on mathematical models. Most medical data have a long lifetime exceeding 25 years. Therefore, it is an important issue to design a new medical data hiding technique that has the capability to withstand the probable attacks from the side of quantum or digital devices. In this article, we aim to present a novel medical image steganography strategy based on quantum walks, chaotic systems, and particle swarm optimization algorithm. A 3-D chaotic system and quantum walks are utilized for operating particle swarm optimization algorithm, in which the generated velocity sequence is utilized for substituting the confidential data, and the position sequence is utilized for selecting which position in the hosting image will be employed to host the substituted confidential data. The payload capacity of the suggested mechanism is 2 bits per 1 byte, and the average value for PSNR is 44.1, which is big enough for the naked eye to not differentiate the difference between the carrier image and its stego one.},
  archive      = {J_NCA},
  author       = {Abd-El-Atty, Bassem},
  doi          = {10.1007/s00521-022-07830-0},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {773-785},
  shortjournal = {Neural Comput. Appl.},
  title        = {A robust medical image steganography approach based on particle swarm optimization algorithm and quantum walks},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recurrent self-optimizing proposals for weakly supervised
object detection. <em>NCA</em>, <em>35</em>(1), 757–771. (<a
href="https://doi.org/10.1007/s00521-022-07818-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised object detection (WSOD) has attracted attention increasingly in object detection, as it only requires image-level annotations to train the detector. A typical paradigm for WSOD is to first generate candidate region proposals for the training data, and then each image is treated as a bag of proposals to conduct the training based on the multiple instance learning (MIL). Most methods focus on optimizing the training process, but rarely consider the influence of pre-generated proposals that directly affect the learning of the detector, due to the overwhelming noisy proposals (e.g., negative or background proposals) and positive proposals with inaccurate locations. In this paper, we focus on improving the quality of proposals, and propose a recurrent self-optimizing proposal framework, a new paradigm for WSOD, to iteratively optimize the pre-generated proposals. In each iteration, all detection results (i.e., the object-aware coordinate offsets and the confidence scores) are accumulated for proposal optimization. To achieve accurate object location, we design a proposal self-transformation module to transform the locations of pre-generated proposals based on the coordinate offsets. To alleviate the impact of noise proposals, we design a proposal self-sampling module to mine object instances through confidence scores to filter out noisy proposals. Furthermore, these optimized proposals are fed into a decoupled proposal learner, which contains two parallel proposal training branches. A MIL module and an instance refinement module are supervised by the image label and the mined object instances, respectively. In addition, the instance refinement module contains an instance regression refinement module, which is proposed to generate object-aware coordinate offsets. In turn, the decoupled proposal learner produces the new detection results to optimize proposals in the next iteration. Extensive experiments on PASCAL VOC and MS-COCO datasets demonstrate the effectiveness of our method.},
  archive      = {J_NCA},
  author       = {Zhang, Ming and Zeng, Bing},
  doi          = {10.1007/s00521-022-07818-w},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {757-771},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recurrent self-optimizing proposals for weakly supervised object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Facial emotion recognition and encoding application for the
visually impaired. <em>NCA</em>, <em>35</em>(1), 749–755. (<a
href="https://doi.org/10.1007/s00521-022-07807-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual impairment refers to any kind of vision loss ranging from complete blindness to the partial loss of vision. Studies have shown that social understanding can be severely affected due to visual impairment. This paper tries to address this gap by presenting a socially assistive application for the visually impaired. The study develops the application using deep learning and app development technologies. A transfer learning Facial Expression Recognition (FER) model is embedded in a mobile application to recognize facial expressions. Guided by haptic feedback, the application developed in this study helps users perceive expressions of the person(s) they are interacting with. The practical value of this work lies in assisting and enhancing the social understanding of visually impaired individuals. On the other hand, the research value of the current study lies in the development of a novel application which is faster, lighter, implementable on low-end devices, and achieves better accuracy, on par with state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Pushpalatha, M. N and Meherishi, Harshubh and Vaishnav, Avani and Anurag Pillai, R. and Gupta, Aman},
  doi          = {10.1007/s00521-022-07807-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {749-755},
  shortjournal = {Neural Comput. Appl.},
  title        = {Facial emotion recognition and encoding application for the visually impaired},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring vision transformer: Classifying
electron-microscopy pollen images with transformer. <em>NCA</em>,
<em>35</em>(1), 735–748. (<a
href="https://doi.org/10.1007/s00521-022-07789-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pollen identification is a sub-discipline of Palynology, which has broad applications in several fields such as allergy control, paleoclimate reconstruction, criminal investigation, and petroleum exploration. Among these, pollen allergy is a common and frequent disease worldwide. Accurate and rapid identification of pollen species under the electron microscope help medical staff in pollen forecast and interrupt the natural course of pollen allergy. The current pollen species identification needs to rely on professional researchers to identify pollen particles in pictures manually, and this time-consuming and laborious way cannot meet the requirements of pollen forecasting. Recently, the self-attention based Transformer has attracted considerable attention in vision tasks, such as image classification. However, pure self-attention lacks local operations on pixels and requires large-scale dataset pretraining to achieve comparable performance to convolutional neural networks (CNN). In this study, we propose a new Vision Transformer pipeline for image classification. First, we design a FeatureMap-to-Token (F2T) module to perform token embedding on the input image. A global self-attention operation is performed on the basis of tokens with local information, and the hierarchical design of CNN is applied to the Vision Transformer, combining local and global strengths in multiscale spaces. Second, we use a distillation strategy to learn the feature representation in the output space of the teacher network to further learn the inductive bias in the CNN to improve the recognition accuracy. Experiments demonstrate that the proposed model achieves CNN-equivalent performance under the same conditions after being trained from scratch on the electron-microscopic pollen dataset. It also requires less model parameters and training time. Code for the model is available at https://github.com/dkbshuai/PyTorch-Our-S .},
  archive      = {J_NCA},
  author       = {Duan, Kaibo and Bao, Shi and Liu, Zhiqiang and Cui, Shaodong},
  doi          = {10.1007/s00521-022-07789-y},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {735-748},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring vision transformer: Classifying electron-microscopy pollen images with transformer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Genetic algorithm to optimize the SVM and k-means algorithms
for mapping of mineral prospectivity. <em>NCA</em>, <em>35</em>(1),
719–733. (<a href="https://doi.org/10.1007/s00521-022-07766-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised clustering (e.g., K-means) and supervised machine learning [e.g., support vector machines (SVMs)] methods can be used in data-driven classification and predictive mapping of mineral prospectivity. In this study, the conceptual model of porphyry-type Cu deposits in Varzaghan district, Northwest Iran, was utilized to translate mineralization-related processes into mappable targeting criteria, resulting in six evidence layers derived from geochemical, geological, structural and remote sensing data. Then, traditional K-means clustering (KMC) method and a supervised SVM were employed to construct GIS-based mineral prospectivity maps. One of the challenging issues for generation of mineral prospectivity maps using clustering algorithms is to select suitable cluster centers (called centroids) in order to circumscribe the similar spatial features into meaningful clusters. Machine learning methods are strongly sensitive to hyperparameter values that contribute to prediction, as the prediction accuracy can significantly enhance when the optimized hyperparameters are calibrated to training procedure. To reach these goals, a genetic algorithm was incorporated into K-means and SVM in order to automatically select the optimized cluster centroids and tuned hyperparameters, respectively, and two new prospectivity models namely GKMC and genetic-based SVM were then generated. To evaluate the performance accuracy in training procedures of SVM and genetic-based SVM, K-fold cross-validation and confusion matrix were employed. Moreover, success-rate curves were plotted to compare the overall performance of unsupervised clustering models comprising KMC and GKMC and also supervised machine learning models comprising SVM and genetic-based SVM for detection of favorable areas associated with porphyry-type Cu mineralization. The results suggested the superiority of genetic-based SVM model over other models.},
  archive      = {J_NCA},
  author       = {Ghezelbash, Reza and Maghsoudi, Abbas and Shamekhi, Mehdi and Pradhan, Biswajeet and Daviran, Mehrdad},
  doi          = {10.1007/s00521-022-07766-5},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {719-733},
  shortjournal = {Neural Comput. Appl.},
  title        = {Genetic algorithm to optimize the SVM and K-means algorithms for mapping of mineral prospectivity},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of covid-19 misinformation on social media
based on neuro-fuzzy and neural network: A systematic review.
<em>NCA</em>, <em>35</em>(1), 699–717. (<a
href="https://doi.org/10.1007/s00521-022-07797-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of Covid-19 misinformation on social media had significant real-world consequences, and it raised fears among internet users since the pandemic has begun. Researchers from all over the world have shown an interest in developing deception classification methods to reduce the issue. Despite numerous obstacles that can thwart the efforts, the researchers aim to create an automated, stable, accurate, and effective mechanism for misinformation classification. In this paper, a systematic literature review is conducted to analyse the state-of-the-art related to the classification of misinformation on social media. IEEE Xplore, SpringerLink, ScienceDirect, Scopus, Taylor &amp; Francis, Wiley, Google Scholar are used as databases to find relevant papers since 2018–2021. Firstly, the study begins by reviewing the history of the issues surrounding Covid-19 misinformation and its effects on social media users. Secondly, various neuro-fuzzy and neural network classification methods are identified. Thirdly, the strength, limitations, and challenges of neuro-fuzzy and neural network approaches are verified for the classification misinformation specially in case of Covid-19. Finally, the most efficient hybrid method of neuro-fuzzy and neural networks in terms of performance accuracy is discovered. This study is wrapped up by suggesting a hybrid ANFIS-DNN model for improving Covid-19 misinformation classification. The results of this study can be served as a roadmap for future research on misinformation classification.},
  archive      = {J_NCA},
  author       = {Ravichandran, Bhavani Devi and Keikhosrokiani, Pantea},
  doi          = {10.1007/s00521-022-07797-y},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {699-717},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of covid-19 misinformation on social media based on neuro-fuzzy and neural network: A systematic review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved load frequency control of interconnected power
systems using energy storage devices and a new cost function.
<em>NCA</em>, <em>35</em>(1), 681–697. (<a
href="https://doi.org/10.1007/s00521-022-07813-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the use of energy storage devices (ESDs) as back-up sources to escalate load frequency control (LFC) of power systems (PSs). The PS models implemented here are 2-area linear and nonlinear non-reheat thermal PSs besides 3-area nonlinear hydro-thermal PS. PID controller is employed as secondary controller in each control area and ESDs such as battery energy storage system, flywheel energy storage system and ultra-capacitor are employed to assist LFC task during crest load disturbances. PID controller parameters are optimized by salp swarm algorithm (SSA) using a new cost function. This function is innovative, improving system stability by increasing stability margin of the system. Contribution of the proposed approach are thoroughly justified by contrasting it against the renowned works in the state-of-the-art. The comparison analysis clearly unveils that SSA optimized PID controller with ESDs is able to significantly reduce settling time and unwanted oscillations of frequency and tie-line power deviations with a greater stability margin. Our proposal is also more economic than the existing solutions considering the trade-off between simplicity and effectiveness.},
  archive      = {J_NCA},
  author       = {Çelik, Emre and Öztürk, Nihat and Houssein, Essam H.},
  doi          = {10.1007/s00521-022-07813-1},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {681-697},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved load frequency control of interconnected power systems using energy storage devices and a new cost function},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simplified artificial neural network based online adaptive
control scheme for nonlinear systems. <em>NCA</em>, <em>35</em>(1),
663–679. (<a href="https://doi.org/10.1007/s00521-022-07760-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex neural network structures may not be appropriate for adaptive control applications, as large number of variable adaptive parameters have to be updated in each time step, thus increasing the computational burden, which makes the real-time implementation of the controller difficult. In this study, the ability of the neural networks to approximate non-linear dynamic systems is used to derive a neuro-based adaptive control with minimalistic architecture. A linear neural identifier is devised, which emulates a local linear model of the system by online adjustment of its parameters. Stability and optimal rate of convergence is ensured through an adaptive learning rate, determined using Lyapunov stability theorems. The novelty of the control scheme lies in its minimalistic neural structure comprising of a single-linear neuron and, therefore, does not impose excessive computational burden on the system, making it feasible for real-time application. To assert our claims, benchmark examples from different domains are used to illustrate the effectiveness of the proposed controller. The neuro-controller is used in a water-lift plant to control the height of the water in a storage tank. Another example of a moving cart holding an inverted pendulum, an inherently unstable system that forms the basis of the robot-control mechanism, is also used. The controller is also tested on a complex non-linear higher-order power system to enhance stability by effectively damping the electromechanical oscillations. The superior performance of the controller is demonstrated by comparing with other recently reported controllers. Additional advantages of the proposed scheme include model-free control and requirement of only local measurements. The proposed method has potential applications in control problems that require adaptability, computational simplicity, and quick response.},
  archive      = {J_NCA},
  author       = {Jamsheed, Faisal and Iqbal, Sheikh Javed},
  doi          = {10.1007/s00521-022-07760-x},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {663-679},
  shortjournal = {Neural Comput. Appl.},
  title        = {Simplified artificial neural network based online adaptive control scheme for nonlinear systems},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CDFF: A fast and highly accurate method for recognizing
traffic signs. <em>NCA</em>, <em>35</em>(1), 643–662. (<a
href="https://doi.org/10.1007/s00521-022-07782-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks method is a commonly used traffic sign recognition method based on deep learning over recent years. However, traffic signs contain objects of different sizes. Since small objects occupy a small input image area, the features that can be extracted are less, and the detection difficulty is greater than that of medium and large objects, and it is still challenging to achieve high-speed and high-accuracy detection of all objects of different sizes at the same time. In this paper, a model for detecting traffic signs is proposed, namely CDFF and CDFF-s. The model contains the following four modules: (1) in the backbone part of the model, we apply an improved activation function FMish to increase training stability, (2) after the backbone of the model, we apply the DFb-SPP module to perform context and semantic fusion, (3) in the neck part of the model, we use the DFb module for feature fusion, which also reduces the number of parameters, and (4) in the head part of the model, we propose a loss function SCIoU, which is optimized for small objects and the model is converged faster. The experimental results on the general traffic sign datasets TT100K and LISA show that the proposed two models can achieve accurate small object detection without losing the detection accuracy of medium and large objects. In addition, excellent results are also obtained on the remote sensing dataset RSOD with similar object size distribution. Meanwhile, the detection speed is faster than YOLOv4, which can meet the accuracy and real-time requirements of automatic driving systems and assisted driving systems.},
  archive      = {J_NCA},
  author       = {Wang, Lanmei and Wang, Lizhe and Zhu, Yanbo and Chu, Anliang and Wang, Guibao},
  doi          = {10.1007/s00521-022-07782-5},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {643-662},
  shortjournal = {Neural Comput. Appl.},
  title        = {CDFF: A fast and highly accurate method for recognizing traffic signs},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximizing coverage and maintaining connectivity in WSN and
decentralized IoT: An efficient metaheuristic-based method for
environment-aware node deployment. <em>NCA</em>, <em>35</em>(1),
611–641. (<a href="https://doi.org/10.1007/s00521-022-07786-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The node deployment problem is a non-deterministic polynomial time (NP-hard). This study proposes a new and efficient method to solve this problem without the need for predefined circumstances about the environments independent of terrain. The proposed method is based on a metaheuristic algorithm and mimics the grey wolf optimizer (GWO) algorithm. In this study, we also suggested an enhanced version of the GWO algorithm to work adaptively in such problems and named it Mutant-GWO (MuGWO). Also, the suggested model ensures connectivity by generating topology graphs and potentially supports data transmission mechanisms. Therefore, the proposed method based on MuGWO can enhance resources utilization, such as reducing the number of nodes, by maximizing the coverage rate and maintaining the connectivity. While most studies assume classical rectangle uniform environments, this study also focuses on custom (environment-aware) maps in line with the importance and requirements of the real world. The motivation of supporting custom maps by this study is that environments can consist of custom shapes with prioritized and critical areas. In this way, environment awareness halts the deployment of nodes in undesired regions and averts resource waste. Besides, novel multi-purpose fitness functions of the proposed method satisfy a convenient approach to calculate costs instead of using complicated processes. Accordingly, this method is suitable for large-scale networks thanks to the capability of the distributed architecture and the metaheuristic-based approach. This study justifies the improvements in the suggested model by presenting comparisons with a Deterministic Grid-based approach and the Original GWO. Moreover, this method outperforms the fruit fly optimization algorithm, bat algorithm (BA), Optimized BA, harmony search, and improved dynamic deployment technique based on genetic algorithm methods in declared scenarios in literature, considering the results of simulations.},
  archive      = {J_NCA},
  author       = {Nematzadeh, Sajjad and Torkamanian-Afshar, Mahsa and Seyyedabbasi, Amir and Kiani, Farzad},
  doi          = {10.1007/s00521-022-07786-1},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {611-641},
  shortjournal = {Neural Comput. Appl.},
  title        = {Maximizing coverage and maintaining connectivity in WSN and decentralized IoT: An efficient metaheuristic-based method for environment-aware node deployment},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SL-net: Self-learning and mutual attention-based
distinguished window for RGBD complex salient object detection.
<em>NCA</em>, <em>35</em>(1), 595–609. (<a
href="https://doi.org/10.1007/s00521-022-07772-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant improvement has been noticed in salient object detection by multi-modal cross-complementary fusion between Depth and RGB features. The multi-modal feature extracting backbone of existing networks cannot extract complex RGB and color images effectively, which limits the performance of salient object detection in complex and challenging situations. In this paper, a composite backbone network with a mutual attention-based distinguished window is proposed to enhance the salient region and minimize the non-salient region. The distinguished window based on the channel-wise, spatial, mutual, and feature-level attention is inserted in each encoder stage to enhance the saliency features. Finally, a novel self-learning-based decoder, which is capable of utilizing multi-level features is designed to get the accurately dense prediction. The multi-level fusion is guided by deep global localized features. The performance of salient object detection could significantly be enhanced in this way. The extensive comparative and ablation experiments for the proposed framework have been conducted on the seven publicly available datasets for visual saliency. Experimental results have illustrated the effectiveness of the proposed framework and show better performance in comparison with the closely related state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Singh, Surya Kant and Srivastava, Rajeev},
  doi          = {10.1007/s00521-022-07772-7},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {595-609},
  shortjournal = {Neural Comput. Appl.},
  title        = {SL-net: Self-learning and mutual attention-based distinguished window for RGBD complex salient object detection},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vietnamese hate and offensive detection using PhoBERT-CNN
and social media streaming data. <em>NCA</em>, <em>35</em>(1), 573–594.
(<a href="https://doi.org/10.1007/s00521-022-07745-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Society needs to develop a system to detect hate and offense to build a healthy and safe environment. However, current research in this field still faces four major shortcomings, including deficient pre-processing techniques, indifference to data imbalance issues, modest performance models, and lacking practical applications. This paper focused on developing an intelligent system capable of addressing these shortcomings. Firstly, we proposed an efficient pre-processing technique to clean comments collected from Vietnamese social media. Secondly, a novel hate speech detection (HSD) model, which is the combination of a pre-trained PhoBERT model and a Text-CNN model, was proposed for solving tasks in Vietnamese. Thirdly, EDA techniques are applied to deal with imbalanced data to improve the performance of classification models. Besides, various experiments were conducted as baselines to compare and investigate the proposed model’s performance against state-of-the-art methods. The experiment results show that the proposed PhoBERT-CNN model outperforms SOTA methods and achieves an F1-score of 67.46\% and 98.45\% on two benchmark datasets, ViHSD and HSD-VLSP, respectively. Finally, we also built a streaming HSD application to demonstrate the practicality of our proposed system.},
  archive      = {J_NCA},
  author       = {Quoc Tran, Khanh and Trong Nguyen, An and Hoang, Phu Gia and Luu, Canh Duc and Do, Trong-Hop and Van Nguyen, Kiet},
  doi          = {10.1007/s00521-022-07745-w},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {573-594},
  shortjournal = {Neural Comput. Appl.},
  title        = {Vietnamese hate and offensive detection using PhoBERT-CNN and social media streaming data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time structural damage assessment using LSTM networks:
Regression and classification approaches. <em>NCA</em>, <em>35</em>(1),
557–572. (<a href="https://doi.org/10.1007/s00521-022-07773-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring(SHM) techniques rarely consider the effect of ambient temperature, even though its impact on the structures being substantial. Moreover, typical modal or time-domain SHM approaches may delay the detection of damages endangering human lives due to their requirement of response time histories of sufficient length. Targeting prompt detection of structural anomalies, this article proposes a Long-Short-Term-Memory (LSTM)-based real-time approach that employs unsupervised LSTM prediction network for detection, followed by a supervised classifier network for localization. The prediction network is trained for one-step-ahead response prediction under ambient temperature conditions, and a novelty measure is devised using the usual prediction error threshold. Subsequently, damage is alarmed on encountering significant departure beyond this threshold. The damage is further localized with the classifier network. The approach is tested on a real bridge subjected to substantial thermal variation and the performance has been observed to be prompt and reliable under different operating conditions.},
  archive      = {J_NCA},
  author       = {Sharma, Smriti and Sen, Subhamoy},
  doi          = {10.1007/s00521-022-07773-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {557-572},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time structural damage assessment using LSTM networks: Regression and classification approaches},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel hybrid multilayer perceptron neural network with
improved grey wolf optimizer. <em>NCA</em>, <em>35</em>(1), 529–556. (<a
href="https://doi.org/10.1007/s00521-022-07775-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multilayer perceptron (MLP), a type of feed-forward neural network, is widely used in various artificial intelligence problems in the literature. Backpropagation is the most common learning method used in MLPs. The gradient-based backpropagation method, which is one of the classical methods, has some disadvantages such as entrapment in local minima, convergence speed, and initialization sensitivity. To eliminate or minimize these disadvantages, there are many studies in the literature that use metaheuristic optimization methods instead of classical methods. These methods are constantly being developed. One of these is an improved grey wolf optimizer (IMP-GWO) proposed to eliminate the disadvantages of the grey wolf optimizer (GWO), which suffers from a lack of search agent diversity, premature convergence, and imbalance between exploitation and exploration. In this study, a new hybrid method, IMP-GWO-MLP, machine learning method was designed for the first time by combining IMP-GWO and MLP. IMP-GWO was used to determine the weight and bias values, which are the most challenging parts of the MLP training phase. The proposed IMP-GWO-MLP was applied to 20 datasets consisting of three different approximations, eight regression problems, and nine classification problems. The results obtained have been suggested in the literature and compared with the gradient descent-based MLP, commonly used GWO, particle swarm optimization, whale optimization algorithm, ant lion algorithm, and genetic algorithm-based MLP methods. The experimental results show that the proposed method is superior to other state-of-the-art methods in the literature. In addition, it is thought that the proposed method can be modeled with high success in real-world problems.},
  archive      = {J_NCA},
  author       = {Altay, Osman and Varol Altay, Elif},
  doi          = {10.1007/s00521-022-07775-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {529-556},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel hybrid multilayer perceptron neural network with improved grey wolf optimizer},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Output synchronization analysis of coupled fractional-order
neural networks with fixed and adaptive couplings. <em>NCA</em>,
<em>35</em>(1), 517–528. (<a
href="https://doi.org/10.1007/s00521-022-07752-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the output synchronization of coupled fractional-order neural networks is investigated. Based on the Lyapunov stability theorem and the properties of fractional calculus, sufficient conditions for guaranteeing the output synchronization of coupled fractional-order neural networks with fixed coupling are derived. Moreover, the adaptive strategy with adjusting the coupling weights is introduced, and sufficient conditions are proposed for guaranteeing the output synchronization of fractional-order neural networks with adaptive couplings. In comparison with previous results, the results obtained in this paper are suitable for fractional-order systems, including the output synchronization of integer-order systems as a special case. Two numerical examples are given to verify the validity of the results.},
  archive      = {J_NCA},
  author       = {Liu, Peng and Li, Yunliu and Sun, Junwei and Wang, Yanfeng},
  doi          = {10.1007/s00521-022-07752-x},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {517-528},
  shortjournal = {Neural Comput. Appl.},
  title        = {Output synchronization analysis of coupled fractional-order neural networks with fixed and adaptive couplings},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary mating algorithm. <em>NCA</em>, <em>35</em>(1),
487–516. (<a href="https://doi.org/10.1007/s00521-022-07761-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new evolutionary algorithm namely Evolutionary Mating Algorithm (EMA) to solve constrained optimization problems. The algorithm is based on the adoption of random mating concept from Hardy–Weinberg equilibrium and crossover index in order to produce new offspring. In this algorithm, effect of the environmental factor (i.e. the presence of predator) has also been considered and treated as an exploratory mechanism. The EMA is initially tested on the 23 benchmark functions to analyze its effectiveness in finding optimal solutions for different search spaces. It is then applied to Optimal Power Flow (OPF) problems with the incorporation of Flexible AC Transmission Systems (FACTS) devices and stochastic wind power generation. The extensive comparative studies with other algorithms demonstrate that EMA provides better results and can be used in solving real optimization problems from various fields.},
  archive      = {J_NCA},
  author       = {Sulaiman, Mohd Herwan and Mustaffa, Zuriani and Saari, Mohd Mawardi and Daniyal, Hamdan and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-022-07761-w},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {487-516},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evolutionary mating algorithm},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information theoretic and neural computational tools for
meta-analysis of cumulative databases in the age of big physics
experiments. <em>NCA</em>, <em>35</em>(1), 469–486. (<a
href="https://doi.org/10.1007/s00521-022-07768-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of Big Data, many scientific disciplines and engineering activities rely on cumulative databases, consisting of many entries derived from different experiments and studies, to investigate complex problems. Their contents can be analysed with much finer granularity than with the usual meta-analytic tools, based on summary statistics such as means and standard deviations. At the same time, not being primary studies, also traditional statistical techniques are not adequate to investigate them. New meta-analysis methods have therefore been adapted to study these cumulative databases and to ensure their validity and consistency. Information theoretic and neural computational tools represent a series of complementary techniques, which can be deployed to identify the most important variables to analyse the problem at hand, to detect whether quantities are missing and to determine the coherence between the entries provided by the individual experiments and studies. The performances of the developed methodologies are verified with a systematic series of tests with synthetic data. An application to thermonuclear fusion proves the capability of the tools to handle real data, in one of the most complex fields of modern physics.},
  archive      = {J_NCA},
  author       = {Murari, A. and Lungaroni, M. and Spolladore, L. and Peluso, E. and Rossi, R. and Gelfusa, M.},
  doi          = {10.1007/s00521-022-07768-3},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {469-486},
  shortjournal = {Neural Comput. Appl.},
  title        = {Information theoretic and neural computational tools for meta-analysis of cumulative databases in the age of big physics experiments},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Policy-based optimization: Single-step policy gradient
method seen as an evolution strategy. <em>NCA</em>, <em>35</em>(1),
449–467. (<a href="https://doi.org/10.1007/s00521-022-07779-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research reports on the recent development of black-box optimization methods based on single-step deep reinforcement learning and their conceptual similarity to evolution strategy (ES) techniques. It formally introduces policy-based optimization (PBO), a policy-gradient-based optimization algorithm that relies on a policy network to describe the density function of its forthcoming evaluations, and uses covariance estimation to steer the policy improvement process in the right direction. The specifics of the PBO algorithm are detailed, and the connections to evolutionary strategies are discussed. Relevance is assessed by benchmarking PBO against classical ES techniques on analytic functions minimization problems, and by optimizing various parametric control laws intended for the Lorenz attractor and the classical cartpole problem. Given the scarce existing literature on the topic, this contribution definitely establishes PBO as a valid, versatile black-box optimization technique, and opens the way to multiple future improvements building on the inherent flexibility of the neural networks approach.},
  archive      = {J_NCA},
  author       = {Viquerat, J. and Duvigneau, R. and Meliga, P. and Kuhnle, A. and Hachem, E.},
  doi          = {10.1007/s00521-022-07779-0},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {449-467},
  shortjournal = {Neural Comput. Appl.},
  title        = {Policy-based optimization: Single-step policy gradient method seen as an evolution strategy},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Object classification on noise-reduced and augmented
micro-doppler radar spectrograms. <em>NCA</em>, <em>35</em>(1), 429–447.
(<a href="https://doi.org/10.1007/s00521-022-07776-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of targets is one of the most challenging tasks in radar signal processing. Classifying a target can help radar operators figure out the nature of the target, such as its source and activity. However, it is very difficult to find the labeled data necessary to develop radar target classification models. Generating a radar dataset is an expensive and time-consuming process. To address these issues, we propose a noise reduction method that can be applied to micro-Doppler radar datasets. This method is carried out by averaging the spectrogram of each class in the RadEch micro-Doppler radar datasets and subtracting pixel by pixel from each sample. RadEch dataset has also been augmented with traditional and learning-based data augmentation methods. The learning-based data augmentation method was carried out by using Generative Adversarial Networks. Raw spectrograms, augmented spectrograms and noise-reduced spectrograms have been classified using 5-layer Convolutional Neural Network, VGG-16, and VGG-19. Classification results are compared with state-of-the-art studies. Comparison results show that the classification on noise-reduced spectrogram performs better than current state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Erdoğan, Alperen and Güney, Selda},
  doi          = {10.1007/s00521-022-07776-3},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {429-447},
  shortjournal = {Neural Comput. Appl.},
  title        = {Object classification on noise-reduced and augmented micro-doppler radar spectrograms},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting and tracking using 2D laser range finders and deep
learning. <em>NCA</em>, <em>35</em>(1), 415–428. (<a
href="https://doi.org/10.1007/s00521-022-07765-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting and tracking people using 2D laser rangefinders (LRFs) is challenging due to the features of the human leg motion, high levels of self-occlusion and the existence of objects which are similar to the human legs. Previous approaches use datasets that are manually labelled with support of images of the scenes. We propose a system with a calibrated monocular camera and 2D LRF mounted on a mobile robot in order to generate a dataset of leg patterns through automatic labelling which is valid to achieve a robust and efficient 2D LRF-based people detector and tracker. First, both images and 2D laser data are recorded during the robot navigation in indoor environments. Second, the people detection boxes and keypoints obtained by a deep learning-based object detector are used to locate both people and their legs on the images. The coordinates frame of 2D laser is extrinsically calibrated to the camera coordinates allowing our system to automatically label the leg instances. The automatically labelled dataset is then used to achieve a leg detector by machine learning techniques. To validate the proposal, the leg detector is used to develop a Kalman filter-based people detection and tracking algorithm which is experimentally assessed. The experimentation shows that the proposed system overcomes the Angus Leigh’s detector and tracker which is considered the state of the art on 2D LRF-based people detector and tracker.},
  archive      = {J_NCA},
  author       = {Aguirre, Eugenio and García-Silvente, Miguel},
  doi          = {10.1007/s00521-022-07765-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {415-428},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detecting and tracking using 2D laser range finders and deep learning},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-guided neural network and GPU-accelerated nonlinear
model predictive control for quadcopter. <em>NCA</em>, <em>35</em>(1),
393–413. (<a href="https://doi.org/10.1007/s00521-022-07783-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a physics-guided residual recurrent neural network (PGRRNN) and graphics processing unit (GPU)-accelerated model predictive control (MPC) framework to combat two specific challenges in artificial neural network (ANN)-based nonlinear MPC of high-rate dynamics systems, i.e., low control latency and insufficient model accuracy or generalization ability. Different from traditional ANN models, PGRRNN utilizes approximate physics-based (PB) models (with parameter uncertainty) as a backbone to impose physical constraints/guidance for future state prediction, and reconciles the difference between PB model approximation and data collected from actual systems by propagating their residuals through a multilayer recurrent neural network, hence improving its accuracy and generalization and alleviating data volume requirement. For computing acceleration, both PGRRNN and particle swarm optimization (PSO) are implemented on a GPU platform to make use of its massive parallel processing threads. Numerical experiments for MPC trajectory tracking of a quadcopter are used to examine accuracy and robustness of PGRRNN, and its performance is compared with other ANN models and approximate PB models. PGRRNN outperforms the other models in both ideal and realistic environments, exhibiting 2–3 times lower tracking error than the pure data-driven model. Furthermore, it is demonstrated that GPU-based PSO is able to synthesize control signals at a rate of greater than 50 Hz and can be a promising approach for ANN-based nonlinear MPC.},
  archive      = {J_NCA},
  author       = {Hong, Seong Hyeon and Ou, Junlin and Wang, Yi},
  doi          = {10.1007/s00521-022-07783-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {393-413},
  shortjournal = {Neural Comput. Appl.},
  title        = {Physics-guided neural network and GPU-accelerated nonlinear model predictive control for quadcopter},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale confusion and filling mechanism for pressure
footprint recognition. <em>NCA</em>, <em>35</em>(1), 375–392. (<a
href="https://doi.org/10.1007/s00521-022-07777-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Footprint data have large intra-class variances and small inter-class variances; therefore, the key to the footprint recognition problem is to mine and learn the discriminative local details in the footprint images. In this paper, an algorithm based on a multi-scale confusion and filling mechanism is proposed to address the problem of footprint recognition from the perspective of fine-grained image recognition. Firstly, the pressure footprint image is divided evenly into several sub-regions, and the score of each sub-region is calculated by a joint confidence function. Secondly, using the filling mechanism of the Region Filling Module, the region with the lowest score in the split image is filled with a higher one for data enhancement. Then, the filled image is confused once using the Multi-Scale Region Confusion Module, and the regions with high confidence score are confused again to obtain an image with multi-scale information. Finally, the footprint features of the filled image and the confused image are extracted by the backbone network and optimized by the joint loss function to carry out the task of footprint recognition. Comprehensive experiments show that the proposed algorithm achieves 89.3\%, 93.4\% and 86.5\% on three benchmark dataset including CUB-200-2011, Aircraft and Stanford Dogs. Meanwhile, it obtains 97.8\% on the footprint dataset.},
  archive      = {J_NCA},
  author       = {Zhang, Yan and Sun, Yongsheng and Wang, Nian and Gao, Zijian and Zhu, Jing and Tang, Jun},
  doi          = {10.1007/s00521-022-07777-2},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {375-392},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale confusion and filling mechanism for pressure footprint recognition},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid binary COOT algorithm with simulated annealing for
feature selection in high-dimensional microarray data. <em>NCA</em>,
<em>35</em>(1), 353–374. (<a
href="https://doi.org/10.1007/s00521-022-07780-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microarray analysis of gene expression can help with disease and cancer diagnosis and prognosis. Identification of gene biomarkers is one of the most difficult issues in microarray cancer classification due to the diverse complexity of different cancers and the high dimensionality of data. In this paper, a new gene selection strategy based on the binary COOT (BCOOT) optimization algorithm is proposed. The COOT algorithm is a newly proposed optimizer whose ability to solve gene selection problems has yet to be explored. Three binary variants of the COOT algorithm are suggested to search for the targeting genes to classify cancer and diseases. The proposed algorithms are BCOOT, BCOOT-C, and BCOOT-CSA. In the first method, a hyperbolic tangent transfer function is used to convert the continuous version of the COOT algorithm to binary. In the second approach, a crossover operator (C) is used to improve the global search of the BCOOT algorithm. In the third method, BCOOT-C is hybridized with simulated annealing (SA) to boost the algorithm’s local exploitation capabilities in order to find robust and stable informative genes. Furthermore, minimum redundancy maximum relevance (mRMR) is used as a prefiltering technique to eliminate redundant genes. The proposed algorithms are tested on ten well-known microarray datasets and then compared to other powerful optimization algorithms, and recent state-of-the-art gene selection techniques. The experimental results demonstrate that the BCOOT-CSA approach surpasses BCOOT and BCOOT-C and outperforms other techniques in terms of prediction accuracy and the number of selected genes in most cases.},
  archive      = {J_NCA},
  author       = {Pashaei, Elnaz and Pashaei, Elham},
  doi          = {10.1007/s00521-022-07780-7},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {353-374},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid binary COOT algorithm with simulated annealing for feature selection in high-dimensional microarray data},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft sensor for the prediction of oxygen content in boiler
flue gas using neural networks and extreme gradient boosting.
<em>NCA</em>, <em>35</em>(1), 345–352. (<a
href="https://doi.org/10.1007/s00521-022-07771-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oxygen content in the flue gas system of power plants is an essential factor affecting boiler efficiency. Accurate oxygen content measurement is vital in evaluating boiler combustion efficiency. The device measuring oxygen content in flue gases at an oil refinery uses a Zirconia oxygen analyzer. This sensor utilization without sensor redundancy makes the oxygen content measurement conducted manually. Workers’ manual measurement is risky because it is a high-risk work area. In addition, the oxygen content in flue gas also indicates boiler combustion efficiency and the amount of other harmful gases produced by the boiler. This paper proposes a soft sensor using artificial neural networks (ANN) and extreme gradient boosting (XGBoost) to predict oxygen content. The dataset used is collected from the historical data of the distributed control system of an oil refinery system boiler. The experimental results show that the one hidden layer ANN model achieves an MAE of 0.0715 and RMSE of 0.0935, while the XGBoost model with hyperparameter tuning and seven features achieves an MAE of 0.0452 and RMSE of 0.0642. The results suggest that the XGBoost model with hyperparameter tuning and seven features outperforms the one hidden layer ANN model. The use of the seven features of the XGBoost model is the result of optimization between computational complexity and system performance.},
  archive      = {J_NCA},
  author       = {Kurniawan, Eko David and Effendy, Nazrul and Arif, Agus and Dwiantoro, Kenny and Muddin, Nidlom},
  doi          = {10.1007/s00521-022-07771-8},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {345-352},
  shortjournal = {Neural Comput. Appl.},
  title        = {Soft sensor for the prediction of oxygen content in boiler flue gas using neural networks and extreme gradient boosting},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurocomputing intelligence models for lakes water level
forecasting: A comprehensive review. <em>NCA</em>, <em>35</em>(1),
303–343. (<a href="https://doi.org/10.1007/s00521-022-07699-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydrological processes forecasting is an essential step for better water management and sustainability. Among several hydrological processes, lake water level (LWL) forecasting is one of the significant processes within a particular catchment. The complexity of the LWL fluctuation is owing to the diversity of the influential parameters including climate, hydrology and some other morphology. In this study, several versions of neurocomputing intelligence models are developed for LWL fluctuation forecasting at five great lakes Lake Superior, Lake Michigan, Lake Huron, Lake Erie, and Lake Ontario, located at the north of USA. The applied models are including M5-Tree, multivariate adaptive regression spline (MARS) and least square support vector regression (LSSVR). The models are developed using several input combinations that are configured based on the correlated lags in addition to the periodicity of time series. The sequential influence of the lakes order is considered in the modeling development. Also, cross-station modeling where lag time series of upstream lakes are used to forecast downstream LWL. Results are assessed using several statistical metrics and graphical visualization. Overall, the results indicated that the applied forecasting models efficient and trustworthy. The component of the periodicity time series enhances the forecasting performance. Cross-station modeling revealed an optimistic modeling strategy for learning transfer modeling of using information of nearby site.},
  archive      = {J_NCA},
  author       = {Demir, Vahdettin and Yaseen, Zaher Mundher},
  doi          = {10.1007/s00521-022-07699-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {303-343},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neurocomputing intelligence models for lakes water level forecasting: A comprehensive review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved firefly algorithm for feature selection with the
ReliefF-based initialization and the weighted voting mechanism.
<em>NCA</em>, <em>35</em>(1), 275–301. (<a
href="https://doi.org/10.1007/s00521-022-07755-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has become popular in data mining tasks currently for its ability of improving the performance of the algorithm and gaining more information about the dataset. Although the firefly algorithm is a well-performed heuristic algorithm, there is still much room for improvement as to the feature selection problem. In this research, an improved firefly algorithm designed for feature selection with the ReliefF-based initialization method and the weighted voting mechanism is proposed. First of all, a feature grouping initialization method that combines the results of the ReliefF algorithm and the cosine similarity is designed to take place of random initialization. Then, the direction of the firefly is modified to move toward the optimal solution. Finally, inspired by the ensemble algorithm, a weighted voter is proposed to build recommended positions for fireflies, which is also integrated with the elite crossover operator and the mutation operator to improve the diversity of the population. Selected from the mixed swarm, a new population is constructed to replace the original population in the next stage. To verify the effectiveness of the algorithm proposed in this paper, 18 datasets are utilized and 9 comparison algorithms (e.g., Black Hole Algorithm, Grey Wolf Optimizer and Pigeon Inspired Optimizer) from state-of-the-art related works are selected for the simulating experiments. The experimental results demonstrate the superiority of the proposed algorithm applied to the feature selection problem.},
  archive      = {J_NCA},
  author       = {Yong, Xin and Gao, Yue-lin},
  doi          = {10.1007/s00521-022-07755-8},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {275-301},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved firefly algorithm for feature selection with the ReliefF-based initialization and the weighted voting mechanism},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A shapelet-based framework for large-scale word-level sign
language database auto-construction. <em>NCA</em>, <em>35</em>(1),
253–274. (<a href="https://doi.org/10.1007/s00521-022-08018-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language recognition is a challenging and often underestimated problem that includes the asynchronous integration of multimodal articulators. Learning powerful applied statistical models requires much training data. However, well-labelled sign language databases are a scarce resource due to the high cost of manual labelling and performing. On the other hand, there exist a lot of sign language-interpreted videos on the Internet. This work aims to propose a framework to automatically learn a large-scale sign language database from sign language-interpreted videos. We achieved this by exploring the correspondence between subtitles and motions by discovering shapelets which are the most discriminative subsequences within the data sequences. In this paper, two modified shapelet methods were used to identify the target signs for 1000 words from 89 (96 h, 8 naive signers) sign language-interpreted videos in terms of brute force search and parameter learning. Then, an augmented (3–5 times larger) large-scale word-level sign database was finally constructed using an adaptive sample augmentation strategy that collected all similar video clips of the target sign as valid samples. Experiments on a subset of 100 words revealed a considerable speedup and 14\% improvement in recall rate. The evaluation of three state-of-the-art sign language classifiers demonstrates the good discrimination of the database, and the sample augmentation strategy can significantly increase the recognition accuracy of all classifiers by 10–33\% by increasing the number, variety, and balance of the data.},
  archive      = {J_NCA},
  author       = {Ma, Xiang and Wang, Qiang and Zheng, Tianyou and Yuan, Lin},
  doi          = {10.1007/s00521-022-08018-2},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {253-274},
  shortjournal = {Neural Comput. Appl.},
  title        = {A shapelet-based framework for large-scale word-level sign language database auto-construction},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Challenges and opportunities of deep learning-based process
fault detection and diagnosis: A review. <em>NCA</em>, <em>35</em>(1),
211–252. (<a href="https://doi.org/10.1007/s00521-022-08017-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process fault detection and diagnosis (FDD) is a predominant task to ensure product quality and process reliability in modern industrial systems. Those traditional FDD techniques are largely based on diagnostic experience. These methods have met significant challenges with immense expansion of plant scale and large numbers of process variables. Recently, deep learning has become the newest trends in process control. The upsurge of deep neural networks (DNNs) in leaning highly discriminative features from complicated process data has provided practitioners with effective process monitoring tools. This paper is to present a review and full developing route of deep learning-based FDD in complex process industries. Firstly, the nature of traditional data projection-based and machine learning-based FDD methods is discussed in process FDD. Secondly, the characteristics of deep learning and their applications in process FDD are illustrated. Thirdly, these typical deep learning techniques, e.g., transfer learning, generative adversarial network, capsule network, graph neural network, are presented for process FDD. These DNNs will effectively solve these problems of fault detection, fault classification, and fault isolation in process. Finally, the developing route of DNN-based process FDD techniques is highlighted for future work.},
  archive      = {J_NCA},
  author       = {Yu, Jianbo and Zhang, Yue},
  doi          = {10.1007/s00521-022-08017-3},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {211-252},
  shortjournal = {Neural Comput. Appl.},
  title        = {Challenges and opportunities of deep learning-based process fault detection and diagnosis: A review},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving collaborative filtering’s rating prediction
accuracy by introducing the experiencing period criterion. <em>NCA</em>,
<em>35</em>(1), 193–210. (<a
href="https://doi.org/10.1007/s00521-020-05460-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering algorithms take into account users’ tastes and interests, expressed as ratings, in order to formulate personalized recommendations. These algorithms initially identify each user’s “near neighbors,” i.e., users having highly similar tastes and likings. Then, their already entered ratings are used, in order to formulate rating predictions, and predictions are typically used thereafter to drive the recommendation formulation process, e.g., by selecting the items with the top-K rating predictions; henceforth, the quality of the rating predictions significantly affects the quality of the generated recommendations. However, certain types of users prefer to experience (purchase, listen to, watch, play) items the moment they become available in the stores, or even preorder, while other types of users prefer to wait for a period of time before experiencing, until a satisfactory amount of feedback (reviews and/or evaluations) becomes available for the item of interest. Notably, a user may apply varying practices on different item categories, i.e., be keen to experience new items in some categories while being uneager in other categories. To formulate successful recommendations, a recommender system should align with users’ patterns of practice and avoid recommending a newly released item to users that delay to experience new items in the particular category, and vice versa. Insofar, however, no algorithm that takes into account this aspect has been proposed. In this work, we (1) present the Experiencing Period Criterion rating prediction algorithm (CFEPC) which modifies the rating prediction value based on the combination of the users’ experiencing wait period in a certain item category and the period the rating to be predicted belongs to, so as to enhance the prediction accuracy of recommender systems and (2) evaluate the accuracy of the proposed algorithm using seven widely used datasets, considering two widely employed user similarity metrics, as well as four accuracy metrics. The results show that the CFEPC algorithm, presented in this paper, achieves a considerable rating prediction quality improvement, in all the datasets tested, indicating that the CFEPC algorithm can provide a basis for formulating more successful recommendations.},
  archive      = {J_NCA},
  author       = {Margaris, Dionisis and Spiliotopoulos, Dimitris and Vassilakis, Costas and Vasilopoulos, Dionysios},
  doi          = {10.1007/s00521-020-05460-y},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {193-210},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving collaborative filtering’s rating prediction accuracy by introducing the experiencing period criterion},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Correction to: Improvement of similarity–diversity
trade-off in recommender systems based on a facility location model.
<em>NCA</em>, <em>35</em>(1), 191. (<a
href="https://doi.org/10.1007/s00521-022-07095-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest in the offering of novel alternative choices to users of recommender systems.},
  archive      = {J_NCA},
  author       = {Panteli, Antiopi and Boutsinas, Basilis},
  doi          = {10.1007/s00521-022-07095-7},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {191},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Improvement of similarity–diversity trade-off in recommender systems based on a facility location model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Improvement of similarity–diversity trade-off in
recommender systems based on a facility location model. <em>NCA</em>,
<em>35</em>(1), 177–189. (<a
href="https://doi.org/10.1007/s00521-020-05613-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest in the offering of novel alternative choices to users of recommender systems. These recommendations should match the target query while at the same time they should be diverse with each other in order to provide useful alternatives to the user, i.e., novel recommendations. In this paper, the problem of extracting novel recommendations, under the similarity–diversity trade-off, is modeled as a facility location problem. The results from tests in the benchmark Travel Case Base were satisfactory when compared to well-known recommender techniques, in terms of both similarity and diversity. It is shown that the proposed method is flexible enough, since a parameter of the adopted facility location model constitutes a regulator for the trade-off between similarity and diversity. Also, our work can broaden the perspectives of the interaction and combination of different scientific fields in order to achieve the best possible results.},
  archive      = {J_NCA},
  author       = {Panteli, Antiopi and Boutsinas, Basilis},
  doi          = {10.1007/s00521-020-05613-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {177-189},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improvement of similarity–diversity trade-off in recommender systems based on a facility location model},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Classifying MOOC forum posts using corpora semantic
similarities: A study on transferability across different courses.
<em>NCA</em>, <em>35</em>(1), 161–175. (<a
href="https://doi.org/10.1007/s00521-021-05750-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information overload in MOOC discussion forums is a major problem that hinders the effectiveness of learner facilitation by the course staff. To address this issue, supervised classification models have been studied and developed in order to assist course facilitators in detecting forum discussions that seek for their intervention. A key issue studied by the literature refers to the transferability of these models to domains other than the domain in which they were initially trained. Typically these models employ domain-dependent features, and therefore they fail to transfer to other subject matters. In this study, we propose and evaluate an alternative way of building supervised models in this context, by using the semantic similarities of the forum transcripts with the dynamically created corpora from the MOOC environment as training features. Specifically, in this study, we analyze the case of two MOOCs, in which the models that we built are classifying forum discussions into three categories, course logistics, content-related and no action required. Furthermore, we evaluate the transferability of the derived models and interpret which features can be effectively transferred to other unseen courses. The findings of this study reveal the main benefits and trade-offs of the proposed approach and provide MOOC developers with insights about the main issues that inhibit the transferability of these models.},
  archive      = {J_NCA},
  author       = {Ntourmas, Anastasios and Daskalaki, Sophia and Dimitriadis, Yannis and Avouris, Nikolaos},
  doi          = {10.1007/s00521-021-05750-z},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {161-175},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classifying MOOC forum posts using corpora semantic similarities: A study on transferability across different courses},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical multiagent reinforcement learning schemes for
air traffic management. <em>NCA</em>, <em>35</em>(1), 147–159. (<a
href="https://doi.org/10.1007/s00521-021-05748-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we investigate the use of hierarchical multiagent reinforcement learning methods for the computation of policies to resolve congestion problems in the air traffic management domain. To address cases where the demand of airspace use exceeds capacity, we consider agents representing flights, who need to decide on ground delays at the pre-tactical stage of operations, towards executing their trajectories while adhering to airspace capacity constraints. Hierarchical reinforcement learning manages to handle real-world problems with high complexity, by partitioning the task into hierarchies of states and/or actions. This provides an efficient way of exploring the state–action space and constructing an advantageous decision-making mechanism. We first establish a general framework of hierarchical multiagent reinforcement learning, and then, we further formulate four alternative schemes of abstractions, on states, actions, or both. To quantitatively assess the quality of solutions of the proposed approaches and show the potential of the hierarchical methods in resolving the demand–capacity balance problem, we provide experimental results on real-world evaluation cases, where we measure the average delay per flight and the number of flights with delays.},
  archive      = {J_NCA},
  author       = {Spatharis, Christos and Bastas, Alevizos and Kravaris, Theocharis and Blekas, Konstantinos and Vouros, George A. and Cordero, Jose Manuel},
  doi          = {10.1007/s00521-021-05748-7},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {147-159},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical multiagent reinforcement learning schemes for air traffic management},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HyR-tree: A spatial index for hybrid flash/3D XPoint
storage. <em>NCA</em>, <em>35</em>(1), 133–145. (<a
href="https://doi.org/10.1007/s00521-021-05804-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flash-based SSDs have become well established in the storage market, replacing magnetic disks in both enterprise and consumer computer systems. The performance characteristics of these new devices have prompted a considerable amount of research that aims at developing efficient data access methods. Early works attempted to reduce the expensive random writes, exploiting logging and batch write techniques, while more recent ones addressed query processing, taking advantage of the high internal parallelism of SSDs. 3D XPoint is a new nonvolatile memory technology that has emerged recently, featuring smaller access times and higher durability compared with flash. It is available both as block addressable secondary storage and as byte addressable persistent main memory. However, the high cost of 3D XPoint prevents, for the moment, its adoption in large scales. This renders hybrid storage systems utilizing NAND flash and 3D XPoint a sufficient alternative. In this work, we propose HyR-tree, a hybrid variant of R-tree that persists a part of the tree in the high performing 3D XPoint storage. HyR-tree identifies repeated access pattern to the data and uses these patterns to locate the most important nodes. The importance of a node is determined by the performance gain that derives from its placement within a 3D XPoint-based device. We experimentally evaluated HyR-tree using real devices and four different datasets. The acquired results show that our proposal achieves significant performance gains up to 40\% in tree construction and up to 56\% in range queries.},
  archive      = {J_NCA},
  author       = {Fevgas, Athanasios and Akritidis, Leonidas and Alamaniotis, Miltiadis and Tsompanopoulou, Panagiota and Bozanis, Panayiotis},
  doi          = {10.1007/s00521-021-05804-2},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {133-145},
  shortjournal = {Neural Comput. Appl.},
  title        = {HyR-tree: A spatial index for hybrid flash/3D XPoint storage},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the non-intrusive extraction of residents’ privacy- and
security-sensitive information from energy smart meters. <em>NCA</em>,
<em>35</em>(1), 119–132. (<a
href="https://doi.org/10.1007/s00521-020-05608-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy smart meters have become very popular in monitoring and smart energy management applications. However, the acquired measurements except the energy consumption information may also carry information about the residents’ daily routine, preferences and profile. In this article, we investigate the potential of extracting information from smart meters related to residents’ security- and privacy-sensitive information. Specifically, using methodologies for load demand prediction, non-intrusive load monitoring and elastic matching, evaluation of extraction of information related to house occupancy, multimedia watching detection, socioeconomic and health profiling of residents was performed. The evaluation results showed that the aggregated energy consumption signals contain information related to residents’ privacy and security, which can be extracted from the smart meter measurements.},
  archive      = {J_NCA},
  author       = {Schirmer, Pascal Alexander and Mporas, Iosif},
  doi          = {10.1007/s00521-020-05608-w},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {119-132},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the non-intrusive extraction of residents’ privacy- and security-sensitive information from energy smart meters},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time multiple object tracking using deep learning
methods. <em>NCA</em>, <em>35</em>(1), 89–118. (<a
href="https://doi.org/10.1007/s00521-021-06391-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple-object tracking is a fundamental computer vision task which is gaining increasing attention due to its academic and commercial potential. Multiple-object detection, recognition and tracking are quite desired in many domains and applications. However, accurate object tracking is very challenging, and things are even more challenging when multiple objects are involved. The main challenges that multiple-object tracking is facing include the similarity and the high density of detected objects, while also occlusions and viewpoint changes can occur as the objects move. In this article, we introduce a real-time multiple-object tracking framework that is based on a modified version of the Deep SORT algorithm. The modification concerns the process of the initialization of the objects, and its rationale is to consider an object as tracked if it is detected in a set of previous frames. The modified Deep SORT is coupled with YOLO detection methods, and a concrete and multi-dimensional analysis of the performance of the framework is performed in the context of real-time multiple tracking of vehicles and pedestrians in various traffic videos from datasets and various real-world footage. The results are quite interesting and highlight that our framework has very good performance and that the improvements on Deep SORT algorithm are functional. Lastly, we show improved detection and execution performance by custom training YOLO on the UA-DETRAC dataset and provide a new vehicle dataset consisting of 7 scenes, 11.025 frames and 25.193 bounding boxes.},
  archive      = {J_NCA},
  author       = {Meimetis, Dimitrios and Daramouskas, Ioannis and Perikos, Isidoros and Hatzilygeroudis, Ioannis},
  doi          = {10.1007/s00521-021-06391-y},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {89-118},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time multiple object tracking using deep learning methods},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A better robustness and fast convergence zeroing neural
network for solving dynamic nonlinear equations. <em>NCA</em>,
<em>35</em>(1), 77–87. (<a
href="https://doi.org/10.1007/s00521-020-05617-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a better fast convergence zeroing neural network (BFCZNN) model with a new activation function (AF) for solving dynamic nonlinear equations (DNE) and applying to control of robot manipulator is presented. The proposed BFCZNN model not only finds the solutions of DNE in fixed time, but also has better robustness than most of the previously reported studies. The numerical simulation results of the proposed BFCZNN and the previously reported robust nonlinear zeroing neural network (RNZNN) for solving third-order DNE in the same condition are presented to demonstrate the better robustness of our new BFCZNN model. Moreover, a successful kinematic control of robot manipulator of our new BFCZNN model is used to verify the realistic availability of the proposed BFCZNN model.},
  archive      = {J_NCA},
  author       = {Gong, Jianqiang and Jin, Jie},
  doi          = {10.1007/s00521-020-05617-9},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {77-87},
  shortjournal = {Neural Comput. Appl.},
  title        = {A better robustness and fast convergence zeroing neural network for solving dynamic nonlinear equations},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multilayer inference engine for individualized tutoring
model: Adapting learning material and its granularity. <em>NCA</em>,
<em>35</em>(1), 61–75. (<a
href="https://doi.org/10.1007/s00521-021-05740-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-supported approaches have been widely used for enriching the learning process. The technological advances have led tutoring systems to embody intelligence in their functionalities. However, so far, they fail to adequately incorporate intelligence and adaptivity in their diagnostic and reasoning mechanisms. In view of the above, this paper presents a novel expert system for the instruction of the programming language Java. A multilayer inference engine was developed and used in this system to provide individualized instruction to students according to their needs and preferences. The multilayer inference engine incorporates a set of algorithmic methods in different layers promoting personalization in the tutoring strategies. In particular, an artificial neural network and multi-criteria decision analysis are used in one layer for adapting the learning units based on students’ learning style, and a fuzzy logic model is applied in the other layer for defining the granularity of learning units according to students’ profile characteristics, such as learning style, knowledge level and misconceptions. The students’ learning style is based on the Honey and Mumford model. The evaluation of the system was conducted using an established framework and Student’s t test, and the results showed a high level of acceptance of the presented model.},
  archive      = {J_NCA},
  author       = {Troussas, Christos and Krouska, Akrivi and Virvou, Maria},
  doi          = {10.1007/s00521-021-05740-1},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {61-75},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multilayer inference engine for individualized tutoring model: Adapting learning material and its granularity},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultra-short-term trading system using a neural network-based
ensemble of financial technical indicators. <em>NCA</em>,
<em>35</em>(1), 35–60. (<a
href="https://doi.org/10.1007/s00521-021-05945-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proposed paper presents the analysis, design, implementation and evaluation of an ultra-short-term frequency trading system for the foreign exchange (FOREX) market, which features all stages of the trading process (Pretrade Analysis, Trend Forecasting, Transaction Execution) substantially exploiting artificial intelligence techniques. Our goal is to simulate the judgment and decision making of the human expert (technical analyst or broker) with a system that responds in a timely manner to changes in market conditions, thus allowing the optimization of ultra-short-term transactions. We designed and implemented a series of technical indicator simulators, which are fed to a novel artificial neural network architecture, to eventually generate the trend forecasting signal. We also designed and implemented a series of customizable ultra-short-term automated trading machines, which receive as inputs the generated forecasting signals and perform real-time virtual transactions. A comparative analysis of the results of both automated trading machines and each machine is carried out for a comprehensive variety of trend forecasting sources.},
  archive      = {J_NCA},
  author       = {Zafeiriou, Theodoros and Kalles, Dimitris},
  doi          = {10.1007/s00521-021-05945-4},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {35-60},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ultra-short-term trading system using a neural network-based ensemble of financial technical indicators},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dense neural networks in knee osteoarthritis classification:
A study on accuracy and fairness. <em>NCA</em>, <em>35</em>(1), 21–33.
(<a href="https://doi.org/10.1007/s00521-020-05459-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense neural networks (DNNs) are a powerful class of learning algorithms that uses multiple layers to progressively extract higher level features from raw input. Either deep or shallow, their outstanding capabilities made a very significant impact on improving the diagnostic potential in multiple applications including medical data classification. In this research work, DNN and Machine Learning (ML) models are explored to address the diagnosis problem of knee osteoarthritis classification which is a common complex problem in older adults. Knee OA diagnosis is a highly complex problem being related to a large number of medical risk factors including advanced age, gender, hormonal status, body weight or size, family history of disease, etc. The main research objective of this study is to apply DNN in knee osteoarthritis classification and validate it for the first time with respect to both accuracy and fairness. To accomplish this, a hybrid criterion including accuracies, confusion matrix and two fairness metrics (demographic parity (DP) and balanced equalized odds (BEO)) were employed to validate the performance of the proposed methodology. Different subgroups of control participants from self-reported clinical data were considered to prove the performance of the proposed methodology. The best performing DNN method is compared with some popular and well-known machine learning techniques for classification with respect to accuracy and fairness. The results of the conducted experimental analysis show the efficacy of the proposed DNN approach improving the classification accuracy (up to 79.6\%) and fairness (BEO: ~ 92\% and DP: 98.5\%) in the OA case study.},
  archive      = {J_NCA},
  author       = {Moustakidis, Serafeim and Papandrianos, Nikolaos I. and Christodolou, Eirini and Papageorgiou, Elpiniki and Tsaopoulos, Dimitrios},
  doi          = {10.1007/s00521-020-05459-5},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {21-33},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dense neural networks in knee osteoarthritis classification: A study on accuracy and fairness},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification of acoustical signals by combining active
learning strategies with semi-supervised learning schemes. <em>NCA</em>,
<em>35</em>(1), 3–20. (<a
href="https://doi.org/10.1007/s00521-021-05749-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world cases, handling both labeled and unlabeled data has raised the interest of several Data Scientists and Machine Learning engineers, leading to several demonstrations that apply data-augmenting approaches in order to obtain a robust and, at the same time, accurate enough learning behavior. The main reason is the existence of much unlabeled data that are ignored by conventional supervised approaches, reducing the chance of enriching the final formatted hypothesis. However, the majority of the proposed methods that operate using both kinds of these data are oriented toward exploiting only one category of these algorithms, without combining their strategies. Since the most popular of them regarding the classification task are Active and Semi-supervised Learning approaches, we aim to design a framework that combines both of them trying to fuse their advantages during the main core of the learning process. Thus, we conduct an empirical evaluation of such a combinatory approach over three problems, which stem from various fields but are all tackled through the use of acoustical signals, operating under the pool-based scenario: gender identification, emotion detection and automatic speaker recognition. Into the proposed combinatory framework, which operates under training sets with small cardinality, our results prove the benefits of adopting such kind of semi-automated approaches regarding both the achieved predictive correctness when reduced consumption of resources takes place, as well as the smoothness of the learning convergence. Several learners have been examined for reaching to more general conclusions, and a variant of self-training scheme has been also examined.},
  archive      = {J_NCA},
  author       = {Karlos, Stamatis and Aridas, Christos and Kanas, Vasileios G. and Kotsiantis, Sotiris},
  doi          = {10.1007/s00521-021-05749-6},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {3-20},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of acoustical signals by combining active learning strategies with semi-supervised learning schemes},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Special issue on information, intelligence, systems and
applications. <em>NCA</em>, <em>35</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s00521-022-07954-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Hatzilygeroudis, Ioannis and Tsihrintzis, George and Virvou, Maria and Perikos, Isidoros},
  doi          = {10.1007/s00521-022-07954-3},
  journal      = {Neural Computing and Applications},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on information, intelligence, systems and applications},
  volume       = {35},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
